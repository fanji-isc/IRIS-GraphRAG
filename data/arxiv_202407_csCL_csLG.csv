title,summary,published,authors,pdf_url,category
Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens,"While large language models (LLMs) are extensively used, there are raising
concerns regarding privacy, security, and copyright due to their opaque
training data, which brings the problem of detecting pre-training data on the
table. Current solutions to this problem leverage techniques explored in
machine learning privacy such as Membership Inference Attacks (MIAs), which
heavily depend on LLMs' capability of verbatim memorization. However, this
reliance presents challenges, especially given the vast amount of training data
and the restricted number of effective training epochs. In this paper, we
propose an adaptive pre-training data detection method which alleviates this
reliance and effectively amplify the identification. Our method adaptively
locates \textit{surprising tokens} of the input. A token is surprising to a LLM
if the prediction on the token is ""certain but wrong"", which refers to low
Shannon entropy of the probability distribution and low probability of the
ground truth token at the same time. By using the prediction probability of
surprising tokens to measure \textit{surprising}, the detection method is
achieved based on the simple hypothesis that seeing seen data is less
surprising for the model compared with seeing unseen data. The method can be
applied without any access to the the pre-training data corpus or additional
training like reference models. Our approach exhibits a consistent enhancement
compared to existing methods in diverse experiments conducted on various
benchmarks and models, achieving a maximum improvement of 29.5\%. We also
introduce a new benchmark Dolma-Book developed upon a novel framework, which
employs book data collected both before and after model training to provide
further evaluation.",2024-07-30,"Anqi Zhang, Chaofeng Wu",http://arxiv.org/pdf/2407.21248v1,cs.CL
Advancing Vietnamese Visual Question Answering with Transformer and Convolutional Integration,"Visual Question Answering (VQA) has recently emerged as a potential research
domain, captivating the interest of many in the field of artificial
intelligence and computer vision. Despite the prevalence of approaches in
English, there is a notable lack of systems specifically developed for certain
languages, particularly Vietnamese. This study aims to bridge this gap by
conducting comprehensive experiments on the Vietnamese Visual Question
Answering (ViVQA) dataset, demonstrating the effectiveness of our proposed
model. In response to community interest, we have developed a model that
enhances image representation capabilities, thereby improving overall
performance in the ViVQA system. Specifically, our model integrates the
Bootstrapping Language-Image Pre-training with frozen unimodal models (BLIP-2)
and the convolutional neural network EfficientNet to extract and process both
local and global features from images. This integration leverages the strengths
of transformer-based architectures for capturing comprehensive contextual
information and convolutional networks for detailed local features. By freezing
the parameters of these pre-trained models, we significantly reduce the
computational cost and training time, while maintaining high performance. This
approach significantly improves image representation and enhances the
performance of existing VQA systems. We then leverage a multi-modal fusion
module based on a general-purpose multi-modal foundation model (BEiT-3) to fuse
the information between visual and textual features. Our experimental findings
demonstrate that our model surpasses competing baselines, achieving promising
performance. This is particularly evident in its accuracy of $71.04\%$ on the
test set of the ViVQA dataset, marking a significant advancement in our
research area. The code is available at https://github.com/nngocson2002/ViVQA.",2024-07-30,"Ngoc Son Nguyen, Van Son Nguyen, Tung Le",http://arxiv.org/pdf/2407.21229v1,cs.CL
GenRec: Generative Sequential Recommendation with Large Language Models,"Sequential recommendation is a task to capture hidden user preferences from
historical user item interaction data and recommend next items for the user.
Significant progress has been made in this domain by leveraging classification
based learning methods. Inspired by the recent paradigm of 'pretrain, prompt
and predict' in NLP, we consider sequential recommendation as a sequence to
sequence generation task and propose a novel model named Generative
Recommendation (GenRec). Unlike classification based models that learn explicit
user and item representations, GenRec utilizes the sequence modeling capability
of Transformer and adopts the masked item prediction objective to effectively
learn the hidden bidirectional sequential patterns. Different from existing
generative sequential recommendation models, GenRec does not rely on manually
designed hard prompts. The input to GenRec is textual user item sequence and
the output is top ranked next items. Moreover, GenRec is lightweight and
requires only a few hours to train effectively in low-resource settings, making
it highly applicable to real-world scenarios and helping to democratize large
language models in the sequential recommendation domain. Our extensive
experiments have demonstrated that GenRec generalizes on various public
real-world datasets and achieves state-of-the-art results. Our experiments also
validate the effectiveness of the the proposed masked item prediction objective
that improves the model performance by a large margin.",2024-07-30,"Panfeng Cao, Pietro Lio",http://arxiv.org/pdf/2407.21191v2,cs.CL
Decomposed Prompting to Answer Questions on a Course Discussion Board,"We propose and evaluate a question-answering system that uses decomposed
prompting to classify and answer student questions on a course discussion
board. Our system uses a large language model (LLM) to classify questions into
one of four types: conceptual, homework, logistics, and not answerable. This
enables us to employ a different strategy for answering questions that fall
under different types. Using a variant of GPT-3, we achieve $81\%$
classification accuracy. We discuss our system's performance on answering
conceptual questions from a machine learning course and various failure modes.",2024-07-30,"Brandon Jaipersaud, Paul Zhang, Jimmy Ba, Andrew Petersen, Lisa Zhang, Michael R. Zhang",http://arxiv.org/pdf/2407.21170v1,cs.CL
Event-Arguments Extraction Corpus and Modeling using BERT for Arabic,"Event-argument extraction is a challenging task, particularly in Arabic due
to sparse linguistic resources. To fill this gap, we introduce the \hadath
corpus ($550$k tokens) as an extension of Wojood, enriched with event-argument
annotations. We used three types of event arguments: $agent$, $location$, and
$date$, which we annotated as relation types. Our inter-annotator agreement
evaluation resulted in $82.23\%$ $Kappa$ score and $87.2\%$ $F_1$-score.
Additionally, we propose a novel method for event relation extraction using
BERT, in which we treat the task as text entailment. This method achieves an
$F_1$-score of $94.01\%$. To further evaluate the generalization of our
proposed method, we collected and annotated another out-of-domain corpus (about
$80$k tokens) called \testNLI and used it as a second test set, on which our
approach achieved promising results ($83.59\%$ $F_1$-score). Last but not
least, we propose an end-to-end system for event-arguments extraction. This
system is implemented as part of SinaTools, and both corpora are publicly
available at {\small \url{https://sina.birzeit.edu/wojood}}",2024-07-30,"Alaa Aljabari, Lina Duaibes, Mustafa Jarrar, Mohammed Khalilia",http://arxiv.org/pdf/2407.21153v1,cs.CL
Enhancing Semantic Similarity Understanding in Arabic NLP with Nested Embedding Learning,"This work presents a novel framework for training Arabic nested embedding
models through Matryoshka Embedding Learning, leveraging multilingual,
Arabic-specific, and English-based models, to highlight the power of nested
embeddings models in various Arabic NLP downstream tasks. Our innovative
contribution includes the translation of various sentence similarity datasets
into Arabic, enabling a comprehensive evaluation framework to compare these
models across different dimensions. We trained several nested embedding models
on the Arabic Natural Language Inference triplet dataset and assessed their
performance using multiple evaluation metrics, including Pearson and Spearman
correlations for cosine similarity, Manhattan distance, Euclidean distance, and
dot product similarity. The results demonstrate the superior performance of the
Matryoshka embedding models, particularly in capturing semantic nuances unique
to the Arabic language. Results demonstrated that Arabic Matryoshka embedding
models have superior performance in capturing semantic nuances unique to the
Arabic language, significantly outperforming traditional models by up to
20-25\% across various similarity metrics. These results underscore the
effectiveness of language-specific training and highlight the potential of
Matryoshka models in enhancing semantic textual similarity tasks for Arabic
NLP.",2024-07-30,"Omer Nacar, Anis Koubaa",http://arxiv.org/pdf/2407.21139v2,cs.CL
LLMs for Enhanced Agricultural Meteorological Recommendations,"Agricultural meteorological recommendations are crucial for enhancing crop
productivity and sustainability by providing farmers with actionable insights
based on weather forecasts, soil conditions, and crop-specific data. This paper
presents a novel approach that leverages large language models (LLMs) and
prompt engineering to improve the accuracy and relevance of these
recommendations. We designed a multi-round prompt framework to iteratively
refine recommendations using updated data and feedback, implemented on ChatGPT,
Claude2, and GPT-4. Our method was evaluated against baseline models and a
Chain-of-Thought (CoT) approach using manually collected datasets. The results
demonstrate significant improvements in accuracy and contextual relevance, with
our approach achieving up to 90\% accuracy and high GPT-4 scores. Additional
validation through real-world pilot studies further confirmed the practical
benefits of our method, highlighting its potential to transform agricultural
practices and decision-making.",2024-07-30,"Ji-jun Park, Soo-joon Choi",http://arxiv.org/pdf/2408.04640v1,cs.CL
ThinK: Thinner Key Cache by Query-Driven Pruning,"Large Language Models (LLMs) have revolutionized the field of natural
language processing, achieving unprecedented performance across a variety of
applications. However, their increased computational and memory demands present
significant challenges, especially when handling long sequences. This paper
focuses on the long-context scenario, addressing the inefficiencies in KV cache
memory consumption during inference. Unlike existing approaches that optimize
the memory based on the sequence length, we identify substantial redundancy in
the channel dimension of the KV cache, as indicated by an uneven magnitude
distribution and a low-rank structure in the attention weights. In response, we
propose ThinK, a novel query-dependent KV cache pruning method designed to
minimize attention weight loss while selectively pruning the least significant
channels. Our approach not only maintains or enhances model accuracy but also
achieves a reduction in KV cache memory costs by over 20% compared with vanilla
KV cache eviction and quantization methods. For instance, ThinK integrated with
KIVI can achieve a 2.8x reduction in peak memory usage while maintaining nearly
the same quality, enabling up to a 5x increase in batch size when using a
single GPU. Extensive evaluations on the LLaMA and Mistral models across
various long-sequence datasets verified the efficiency of ThinK, establishing a
new baseline algorithm for efficient LLM deployment without compromising
performance. Our code has been made available at
https://github.com/SalesforceAIResearch/ThinK.",2024-07-30,"Yuhui Xu, Zhanming Jie, Hanze Dong, Lei Wang, Xudong Lu, Aojun Zhou, Amrita Saha, Caiming Xiong, Doyen Sahoo",http://arxiv.org/pdf/2407.21018v3,cs.CL
Evolver: Chain-of-Evolution Prompting to Boost Large Multimodal Models for Hateful Meme Detection,"Recent advances show that two-stream approaches have achieved outstanding
performance in hateful meme detection. However, hateful memes constantly evolve
as new memes emerge by fusing progressive cultural ideas, making existing
methods obsolete or ineffective. In this work, we explore the potential of
Large Multimodal Models (LMMs) for hateful meme detection. To this end, we
propose Evolver, which incorporates LMMs via Chain-of-Evolution (CoE)
Prompting, by integrating the evolution attribute and in-context information of
memes. Specifically, Evolver simulates the evolving and expressing process of
memes and reasons through LMMs in a step-by-step manner. First, an evolutionary
pair mining module retrieves the top-k most similar memes in the external
curated meme set with the input meme. Second, an evolutionary information
extractor is designed to summarize the semantic regularities between the paired
memes for prompting. Finally, a contextual relevance amplifier enhances the
in-context hatefulness information to boost the search for evolutionary
processes. Extensive experiments on public FHM, MAMI, and HarM datasets show
that CoE prompting can be incorporated into existing LMMs to improve their
performance. More encouragingly, it can serve as an interpretive tool to
promote the understanding of the evolution of social memes. [Homepage]
(https://github.com/inFaaa/Evolver)",2024-07-30,"Jinfa Huang, Jinsheng Pan, Zhongwei Wan, Hanjia Lyu, Jiebo Luo",http://arxiv.org/pdf/2407.21004v3,cs.CL
From Feature Importance to Natural Language Explanations Using LLMs with RAG,"As machine learning becomes increasingly integral to autonomous
decision-making processes involving human interaction, the necessity of
comprehending the model's outputs through conversational means increases. Most
recently, foundation models are being explored for their potential as post hoc
explainers, providing a pathway to elucidate the decision-making mechanisms of
predictive models. In this work, we introduce traceable question-answering,
leveraging an external knowledge repository to inform the responses of Large
Language Models (LLMs) to user queries within a scene understanding task. This
knowledge repository comprises contextual details regarding the model's output,
containing high-level features, feature importance, and alternative
probabilities. We employ subtractive counterfactual reasoning to compute
feature importance, a method that entails analysing output variations resulting
from decomposing semantic features. Furthermore, to maintain a seamless
conversational flow, we integrate four key characteristics - social, causal,
selective, and contrastive - drawn from social science research on human
explanations into a single-shot prompt, guiding the response generation
process. Our evaluation demonstrates that explanations generated by the LLMs
encompassed these elements, indicating its potential to bridge the gap between
complex model outputs and natural language expressions.",2024-07-30,"Sule Tekkesinoglu, Lars Kunze",http://arxiv.org/pdf/2407.20990v1,cs.CL
"Entropy, Thermodynamics and the Geometrization of the Language Model","In this paper, we discuss how pure mathematics and theoretical physics can be
applied to the study of language models. Using set theory and analysis, we
formulate mathematically rigorous definitions of language models, and introduce
the concept of the moduli space of distributions for a language model. We
formulate a generalized distributional hypothesis using functional analysis and
topology. We define the entropy function associated with a language model and
show how it allows us to understand many interesting phenomena in languages. We
argue that the zero points of the entropy function and the points where the
entropy is close to 0 are the key obstacles for an LLM to approximate an
intelligent language model, which explains why good LLMs need billions of
parameters. Using the entropy function, we formulate a conjecture about AGI.
  Then, we show how thermodynamics gives us an immediate interpretation to
language models. In particular we will define the concepts of partition
function, internal energy and free energy for a language model, which offer
insights into how language models work. Based on these results, we introduce a
general concept of the geometrization of language models and define what is
called the Boltzmann manifold. While the current LLMs are the special cases of
the Boltzmann manifold.",2024-07-30,Wenzhe Yang,http://arxiv.org/pdf/2407.21092v1,cs.CL
Abstractive summarization from Audio Transcription,"Currently, large language models are gaining popularity, their achievements
are used in many areas, ranging from text translation to generating answers to
queries. However, the main problem with these new machine learning algorithms
is that training such models requires large computing resources that only large
IT companies have. To avoid this problem, a number of methods (LoRA,
quantization) have been proposed so that existing models can be effectively
fine-tuned for specific tasks. In this paper, we propose an E2E (end to end)
audio summarization model using these techniques. In addition, this paper
examines the effectiveness of these approaches to the problem under
consideration and draws conclusions about the applicability of these methods.",2024-07-30,Ilia Derkach,http://arxiv.org/pdf/2408.04639v1,cs.CL
Enabling Contextual Soft Moderation on Social Media through Contrastive Textual Deviation,"Automated soft moderation systems are unable to ascertain if a post supports
or refutes a false claim, resulting in a large number of contextual false
positives. This limits their effectiveness, for example undermining trust in
health experts by adding warnings to their posts or resorting to vague warnings
instead of granular fact-checks, which result in desensitizing users. In this
paper, we propose to incorporate stance detection into existing automated
soft-moderation pipelines, with the goal of ruling out contextual false
positives and providing more precise recommendations for social media content
that should receive warnings. We develop a textual deviation task called
Contrastive Textual Deviation (CTD) and show that it outperforms existing
stance detection approaches when applied to soft moderation.We then integrate
CTD into the stateof-the-art system for automated soft moderation Lambretta,
showing that our approach can reduce contextual false positives from 20% to
2.1%, providing another important building block towards deploying reliable
automated soft moderation tools on social media.",2024-07-30,"Pujan Paudel, Mohammad Hammas Saeed, Rebecca Auger, Chris Wells, Gianluca Stringhini",http://arxiv.org/pdf/2407.20910v1,cs.CL
Automated Review Generation Method Based on Large Language Models,"Literature research, vital for scientific work, faces the challenge of
surging information volumes exceeding researchers' processing capabilities. We
present an automated review generation method based on large language models
(LLMs) to overcome efficiency bottlenecks and reduce cognitive load. Our
statistically validated evaluation framework demonstrates that the generated
reviews match or exceed manual quality, offering broad applicability across
research fields without requiring users' domain knowledge. Applied to propane
dehydrogenation (PDH) catalysts, our method swiftly analyzed 343 articles,
averaging seconds per article per LLM account, producing comprehensive reviews
spanning 35 topics, with extended analysis of 1041 articles providing insights
into catalysts' properties. Through multi-layered quality control, we
effectively mitigated LLMs' hallucinations, with expert verification confirming
accuracy and citation integrity while demonstrating hallucination risks reduced
to below 0.5\% with 95\% confidence. Released Windows application enables
one-click review generation, enhancing research productivity and literature
recommendation efficiency while setting the stage for broader scientific
explorations.",2024-07-30,"Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Changying Du, Zhi-Jian Zhao, Jinlong Gong",http://arxiv.org/pdf/2407.20906v5,cs.CL
Faithful and Plausible Natural Language Explanations for Image Classification: A Pipeline Approach,"Existing explanation methods for image classification struggle to provide
faithful and plausible explanations. This paper addresses this issue by
proposing a post-hoc natural language explanation method that can be applied to
any CNN-based classifier without altering its training process or affecting
predictive performance. By analysing influential neurons and the corresponding
activation maps, the method generates a faithful description of the
classifier's decision process in the form of a structured meaning
representation, which is then converted into text by a language model. Through
this pipeline approach, the generated explanations are grounded in the neural
network architecture, providing accurate insight into the classification
process while remaining accessible to non-experts. Experimental results show
that the NLEs constructed by our method are significantly more plausible and
faithful. In particular, user interventions in the neural network structure
(masking of neurons) are three times more effective than the baselines.",2024-07-30,"Adam Wojciechowski, Mateusz Lango, Ondrej Dusek",http://arxiv.org/pdf/2407.20899v3,cs.CL
"Effects of a Prompt Engineering Intervention on Undergraduate Students' AI Self-Efficacy, AI Knowledge and Prompt Engineering Ability: A Mixed Methods Study","Prompt engineering is critical for effective interaction with large language
models (LLMs) such as ChatGPT. However, efforts to teach this skill to students
have been limited. This study designed and implemented a prompt engineering
intervention, examining its influence on undergraduate students' AI
self-efficacy, AI knowledge, and proficiency in creating effective prompts. The
intervention involved 27 students who participated in a 100-minute workshop
conducted during their history course at a university in Hong Kong. During the
workshop, students were introduced to prompt engineering strategies, which they
applied to plan the course's final essay task. Multiple data sources were
collected, including students' responses to pre- and post-workshop
questionnaires, pre- and post-workshop prompt libraries, and written
reflections. The study's findings revealed that students demonstrated a higher
level of AI self-efficacy, an enhanced understanding of AI concepts, and
improved prompt engineering skills because of the intervention. These findings
have implications for AI literacy education, as they highlight the importance
of prompt engineering training for specific higher education use cases. This is
a significant shift from students haphazardly and intuitively learning to
engineer prompts. Through prompt engineering education, educators can faciitate
students' effective navigation and leverage of LLMs to support their
coursework.",2024-07-30,"David James Woo, Deliang Wang, Tim Yung, Kai Guo",http://arxiv.org/pdf/2408.07302v1,cs.CL
Effective Black Box Testing of Sentiment Analysis Classification Networks,"Transformer-based neural networks have demonstrated remarkable performance in
natural language processing tasks such as sentiment analysis. Nevertheless, the
issue of ensuring the dependability of these complicated architectures through
comprehensive testing is still open. This paper presents a collection of
coverage criteria specifically designed to assess test suites created for
transformer-based sentiment analysis networks. Our approach utilizes input
space partitioning, a black-box method, by considering emotionally relevant
linguistic features such as verbs, adjectives, adverbs, and nouns. In order to
effectively produce test cases that encompass a wide range of emotional
elements, we utilize the k-projection coverage metric. This metric minimizes
the complexity of the problem by examining subsets of k features at the same
time, hence reducing dimensionality. Large language models are employed to
generate sentences that display specific combinations of emotional features.
The findings from experiments obtained from a sentiment analysis dataset
illustrate that our criteria and generated tests have led to an average
increase of 16\% in test coverage. In addition, there is a corresponding
average decrease of 6.5\% in model accuracy, showing the ability to identify
vulnerabilities. Our work provides a foundation for improving the dependability
of transformer-based sentiment analysis systems through comprehensive test
evaluation.",2024-07-30,"Parsa Karbasizadeh, Fathiyeh Faghih, Pouria Golshanrad",http://arxiv.org/pdf/2407.20884v1,cs.CL
Lyrics Transcription for Humans: A Readability-Aware Benchmark,"Writing down lyrics for human consumption involves not only accurately
capturing word sequences, but also incorporating punctuation and formatting for
clarity and to convey contextual information. This includes song structure,
emotional emphasis, and contrast between lead and background vocals. While
automatic lyrics transcription (ALT) systems have advanced beyond producing
unstructured strings of words and are able to draw on wider context, ALT
benchmarks have not kept pace and continue to focus exclusively on words. To
address this gap, we introduce Jam-ALT, a comprehensive lyrics transcription
benchmark. The benchmark features a complete revision of the JamendoLyrics
dataset, in adherence to industry standards for lyrics transcription and
formatting, along with evaluation metrics designed to capture and assess the
lyric-specific nuances, laying the foundation for improving the readability of
lyrics. We apply the benchmark to recent transcription systems and present
additional error analysis, as well as an experimental comparison with a
classical music dataset.",2024-07-30,"Ondřej Cífka, Hendrik Schreiber, Luke Miner, Fabian-Robert Stöter",http://arxiv.org/pdf/2408.06370v1,cs.CL
SynthVLM: High-Efficiency and High-Quality Synthetic Data for Vision Language Models,"Vision-Language Models (VLMs) have recently emerged, demonstrating remarkable
vision-understanding capabilities. However, training these models requires
large-scale datasets, which brings challenges related to efficiency,
effectiveness, quality, and privacy of web data. In this paper, we introduce
SynthVLM, a novel data synthesis and curation method for generating
image-caption pairs. Unlike traditional methods, where captions are generated
from images, SynthVLM utilizes advanced diffusion models and high-quality
captions to automatically synthesize and select high-resolution images from
text descriptions, thereby creating precisely aligned image-text pairs. To
demonstrate the power of SynthVLM, we introduce SynthVLM-100K, a high-quality
dataset consisting of 100,000 curated and synthesized image-caption pairs. In
both model and human evaluations, SynthVLM-100K outperforms traditional
real-world datasets. Leveraging this dataset, we develop a new family of
multimodal large language models (MLLMs), SynthVLM-7B and SynthVLM-13B, which
achieve state-of-the-art (SOTA) performance on various vision
question-answering (VQA) tasks. Notably, our models outperform LLaVA across
most metrics with only 18\% pretrain data. Furthermore, SynthVLM-7B and
SynthVLM-13B attain SOTA performance on the MMLU benchmark, demonstrating that
the high-quality SynthVLM-100K dataset preserves language abilities. To
facilitate future research, our dataset and the complete data generating and
curating methods are open-sourced at
https://github.com/starriver030515/SynthVLM.",2024-07-30,"Zheng Liu, Hao Liang, Bozhou Li, Tianyi Bai, Wentao Xiong, Chong Chen, Conghui He, Wentao Zhang, Bin Cui",http://arxiv.org/pdf/2407.20756v4,cs.CL
JaColBERTv2.5: Optimising Multi-Vector Retrievers to Create State-of-the-Art Japanese Retrievers with Constrained Resources,"Neural Information Retrieval has advanced rapidly in high-resource languages,
but progress in lower-resource ones such as Japanese has been hindered by data
scarcity, among other challenges. Consequently, multilingual models have
dominated Japanese retrieval, despite their computational inefficiencies and
inability to capture linguistic nuances. While recent multi-vector monolingual
models like JaColBERT have narrowed this gap, they still lag behind
multilingual methods in large-scale evaluations. This work addresses the
suboptimal training methods of multi-vector retrievers in lower-resource
settings, focusing on Japanese. We systematically evaluate and improve key
aspects of the inference and training settings of JaColBERT, and more broadly,
multi-vector models. We further enhance performance through a novel checkpoint
merging step, showcasing it to be an effective way of combining the benefits of
fine-tuning with the generalization capabilities of the original checkpoint.
Building on our analysis, we introduce a novel training recipe, resulting in
the JaColBERTv2.5 model. JaColBERTv2.5, with only 110 million parameters and
trained in under 15 hours on 4 A100 GPUs, significantly outperforms all
existing methods across all common benchmarks, reaching an average score of
0.754, significantly above the previous best of 0.720. To support future
research, we make our final models, intermediate checkpoints and all data used
publicly available.",2024-07-30,Benjamin Clavié,http://arxiv.org/pdf/2407.20750v1,cs.CL
Meltemi: The first open Large Language Model for Greek,"We describe the development and capabilities of Meltemi 7B, the first open
Large Language Model for the Greek language. Meltemi 7B has 7 billion
parameters and is trained on a 40 billion token Greek corpus. For the
development of Meltemi 7B, we adapt Mistral, by continuous pretraining on the
Greek Corpus. Meltemi 7B contains up-to-date information up to September 2023.
Furthermore, we have translated and curated a Greek instruction corpus, which
has been used for the instruction-tuning of a chat model, named Meltemi 7B
Instruct. Special care has been given to the alignment and the removal of toxic
content for the Meltemi 7B Instruct. The developed models are evaluated on a
broad set of collected evaluation corpora, and examples of prompts and
responses are presented. Both Meltemi 7B and Meltemi 7B Instruct are available
at https://huggingface.co/ilsp under the Apache 2.0 license.",2024-07-30,"Leon Voukoutis, Dimitris Roussis, Georgios Paraskevopoulos, Sokratis Sofianopoulos, Prokopis Prokopidis, Vassilis Papavasileiou, Athanasios Katsamanis, Stelios Piperidis, Vassilis Katsouros",http://arxiv.org/pdf/2407.20743v1,cs.CL
Adapting Safe-for-Work Classifier for Malaysian Language Text: Enhancing Alignment in LLM-Ops Framework,"As large language models (LLMs) become increasingly integrated into
operational workflows (LLM-Ops), there is a pressing need for effective
guardrails to ensure safe and aligned interactions, including the ability to
detect potentially unsafe or inappropriate content across languages. However,
existing safe-for-work classifiers are primarily focused on English text. To
address this gap for the Malaysian language, we present a novel safe-for-work
text classifier tailored specifically for Malaysian language content. By
curating and annotating a first-of-its-kind dataset of Malaysian text spanning
multiple content categories, we trained a classification model capable of
identifying potentially unsafe material using state-of-the-art natural language
processing techniques. This work represents an important step in enabling safer
interactions and content filtering to mitigate potential risks and ensure
responsible deployment of LLMs. To maximize accessibility and promote further
research towards enhancing alignment in LLM-Ops for the Malaysian context, the
model is publicly released at
https://huggingface.co/malaysia-ai/malaysian-sfw-classifier.",2024-07-30,"Aisyah Razak, Ariff Nazhan, Kamarul Adha, Wan Adzhar Faiq Adzlan, Mas Aisyah Ahmad, Ammar Azman",http://arxiv.org/pdf/2407.20729v1,cs.CL
Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept,"This paper describes the development of a causal diagnosis approach for
troubleshooting an industrial environment on the basis of the technical
language expressed in Return on Experience records. The proposed method
leverages the vectorized linguistic knowledge contained in the distributed
representation of a Large Language Model, and the causal associations entailed
by the embedded failure modes and mechanisms of the industrial assets. The
paper presents the elementary but essential concepts of the solution, which is
conceived as a causality-aware retrieval augmented generation system, and
illustrates them experimentally on a real-world Predictive Maintenance setting.
Finally, it discusses avenues of improvement for the maturity of the utilized
causal technology to meet the robustness challenges of increasingly complex
scenarios in the industry.",2024-07-30,"Alexandre Trilla, Ossee Yiboe, Nenad Mijatovic, Jordi Vitrià",http://arxiv.org/pdf/2407.20700v1,cs.CL
CultureVo: The Serious Game of Utilizing Gen AI for Enhancing Cultural Intelligence,"CultureVo, Inc. has developed the Integrated Culture Learning Suite (ICLS) to
deliver foundational knowledge of world cultures through a combination of
interactive lessons and gamified experiences. This paper explores how
Generative AI powered by open source Large Langauge Models are utilized within
the ICLS to enhance cultural intelligence. The suite employs Generative AI
techniques to automate the assessment of learner knowledge, analyze behavioral
patterns, and manage interactions with non-player characters using real time
learner assessment. Additionally, ICLS provides contextual hint and recommend
course content by assessing learner proficiency, while Generative AI
facilitates the automated creation and validation of educational content.",2024-07-30,"Ajita Agarwala, Anupam Purwar, Viswanadhasai Rao",http://arxiv.org/pdf/2407.20685v2,cs.CL
Label-Guided Prompt for Multi-label Few-shot Aspect Category Detection,"Multi-label few-shot aspect category detection aims at identifying multiple
aspect categories from sentences with a limited number of training instances.
The representation of sentences and categories is a key issue in this task.
Most of current methods extract keywords for the sentence representations and
the category representations. Sentences often contain many category-independent
words, which leads to suboptimal performance of keyword-based methods. Instead
of directly extracting keywords, we propose a label-guided prompt method to
represent sentences and categories. To be specific, we design label-specific
prompts to represent sentences by combining crucial contextual and semantic
information. Further, the label is introduced into a prompt to obtain category
descriptions by utilizing a large language model. This kind of category
descriptions contain the characteristics of the aspect categories, guiding the
construction of discriminative category prototypes. Experimental results on two
public datasets show that our method outperforms current state-of-the-art
methods with a 3.86% - 4.75% improvement in the Macro-F1 score.",2024-07-30,"ChaoFeng Guan, YaoHui Zhu, Yu Bai, LingYun Wang",http://arxiv.org/pdf/2407.20673v1,cs.CL
ArabicNLU 2024: The First Arabic Natural Language Understanding Shared Task,"This paper presents an overview of the Arabic Natural Language Understanding
(ArabicNLU 2024) shared task, focusing on two subtasks: Word Sense
Disambiguation (WSD) and Location Mention Disambiguation (LMD). The task aimed
to evaluate the ability of automated systems to resolve word ambiguity and
identify locations mentioned in Arabic text. We provided participants with
novel datasets, including a sense-annotated corpus for WSD, called SALMA with
approximately 34k annotated tokens, and the IDRISI-DA dataset with 3,893
annotations and 763 unique location mentions. These are challenging tasks. Out
of the 38 registered teams, only three teams participated in the final
evaluation phase, with the highest accuracy being 77.8% for WSD and the highest
MRR@1 being 95.0% for LMD. The shared task not only facilitated the evaluation
and comparison of different techniques, but also provided valuable insights and
resources for the continued advancement of Arabic NLU technologies.",2024-07-30,"Mohammed Khalilia, Sanad Malaysha, Reem Suwaileh, Mustafa Jarrar, Alaa Aljabari, Tamer Elsayed, Imed Zitouni",http://arxiv.org/pdf/2407.20663v1,cs.CL
Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks,"Recent vision-language foundation models, such as CLIP, have demonstrated
superior capabilities in learning representations that can be transferable
across diverse range of downstream tasks and domains. With the emergence of
such powerful models, it has become crucial to effectively leverage their
capabilities in tackling challenging vision tasks. On the other hand, only a
few works have focused on devising adversarial examples that transfer well to
both unknown domains and model architectures. In this paper, we propose a novel
transfer attack method called PDCL-Attack, which leverages the CLIP model to
enhance the transferability of adversarial perturbations generated by a
generative model-based attack framework. Specifically, we formulate an
effective prompt-driven feature guidance by harnessing the semantic
representation power of text, particularly from the ground-truth class labels
of input images. To the best of our knowledge, we are the first to introduce
prompt learning to enhance the transferable generative attacks. Extensive
experiments conducted across various cross-domain and cross-model settings
empirically validate our approach, demonstrating its superiority over
state-of-the-art methods.",2024-07-30,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",http://arxiv.org/pdf/2407.20657v2,cs.CL
Prompting Encoder Models for Zero-Shot Classification: A Cross-Domain Study in Italian,"Addressing the challenge of limited annotated data in specialized fields and
low-resource languages is crucial for the effective use of Language Models
(LMs). While most Large Language Models (LLMs) are trained on general-purpose
English corpora, there is a notable gap in models specifically tailored for
Italian, particularly for technical and bureaucratic jargon. This paper
explores the feasibility of employing smaller, domain-specific encoder LMs
alongside prompting techniques to enhance performance in these specialized
contexts. Our study concentrates on the Italian bureaucratic and legal
language, experimenting with both general-purpose and further pre-trained
encoder-only models. We evaluated the models on downstream tasks such as
document classification and entity typing and conducted intrinsic evaluations
using Pseudo-Log-Likelihood. The results indicate that while further
pre-trained models may show diminished robustness in general knowledge, they
exhibit superior adaptability for domain-specific tasks, even in a zero-shot
setting. Furthermore, the application of calibration techniques and in-domain
verbalizers significantly enhances the efficacy of encoder models. These
domain-specialized models prove to be particularly advantageous in scenarios
where in-domain resources or expertise are scarce. In conclusion, our findings
offer new insights into the use of Italian models in specialized contexts,
which may have a significant impact on both research and industrial
applications in the digital transformation era.",2024-07-30,"Serena Auriemma, Martina Miliani, Mauro Madeddu, Alessandro Bondielli, Lucia Passaro, Alessandro Lenci",http://arxiv.org/pdf/2407.20654v1,cs.CL
Affective Computing in the Era of Large Language Models: A Survey from the NLP Perspective,"Affective Computing (AC), integrating computer science, psychology, and
cognitive science knowledge, aims to enable machines to recognize, interpret,
and simulate human emotions.To create more value, AC can be applied to diverse
scenarios, including social media, finance, healthcare, education, etc.
Affective Computing (AC) includes two mainstream tasks, i.e., Affective
Understanding (AU) and Affective Generation (AG). Fine-tuning Pre-trained
Language Models (PLMs) for AU tasks has succeeded considerably. However, these
models lack generalization ability, requiring specialized models for specific
tasks. Additionally, traditional PLMs face challenges in AG, particularly in
generating diverse and emotionally rich responses. The emergence of Large
Language Models (LLMs), such as the ChatGPT series and LLaMA models, brings new
opportunities and challenges, catalyzing a paradigm shift in AC. LLMs possess
capabilities of in-context learning, common sense reasoning, and advanced
sequence generation, which present unprecedented opportunities for AU. To
provide a comprehensive overview of AC in the LLMs era from an NLP perspective,
we summarize the development of LLMs research in this field, aiming to offer
new insights. Specifically, we first summarize the traditional tasks related to
AC and introduce the preliminary study based on LLMs. Subsequently, we outline
the relevant techniques of popular LLMs to improve AC tasks, including
Instruction Tuning and Prompt Engineering. For Instruction Tuning, we discuss
full parameter fine-tuning and parameter-efficient methods such as LoRA,
P-Tuning, and Prompt Tuning. In Prompt Engineering, we examine Zero-shot,
Few-shot, Chain of Thought (CoT), and Agent-based methods for AU and AG. To
clearly understand the performance of LLMs on different Affective Computing
tasks, we further summarize the existing benchmarks and evaluation methods.",2024-07-30,"Yiqun Zhang, Xiaocui Yang, Xingle Xu, Zeran Gao, Yijie Huang, Shiyi Mu, Shi Feng, Daling Wang, Yifei Zhang, Kaisong Song, Ge Yu",http://arxiv.org/pdf/2408.04638v1,cs.CL
Accelerating Large Language Model Inference with Self-Supervised Early Exits,"This paper presents a novel technique for accelerating inference in large,
pre-trained language models (LLMs) by introducing early exits during inference.
The computational demands of these models, used across a wide range of
applications, can be substantial. By capitalizing on the inherent variability
in token complexity, our approach enables selective acceleration of the
inference process. Specifically, we propose the integration of early exit
''heads'' atop existing transformer layers, which facilitate conditional
terminations based on a confidence metric. These heads are trained in a
self-supervised manner using the model's own predictions as training data,
thereby eliminating the need for additional annotated data. The confidence
metric, established using a calibration set, ensures a desired level of
accuracy while enabling early termination when confidence exceeds a
predetermined threshold. Notably, our method preserves the original accuracy
and reduces computational time on certain tasks, leveraging the existing
knowledge of pre-trained LLMs without requiring extensive retraining. This
lightweight, modular modification has the potential to greatly enhance the
practical usability of LLMs, particularly in applications like real-time
language processing in resource-constrained environments.",2024-07-30,Florian Valade,http://arxiv.org/pdf/2407.21082v1,cs.CL
Decoding Linguistic Representations of Human Brain,"Language, as an information medium created by advanced organisms, has always
been a concern of neuroscience regarding how it is represented in the brain.
Decoding linguistic representations in the evoked brain has shown
groundbreaking achievements, thanks to the rapid improvement of neuroimaging,
medical technology, life sciences and artificial intelligence. In this work, we
present a taxonomy of brain-to-language decoding of both textual and speech
formats. This work integrates two types of research: neuroscience focusing on
language understanding and deep learning-based brain decoding. Generating
discernible language information from brain activity could not only help those
with limited articulation, especially amyotrophic lateral sclerosis (ALS)
patients but also open up a new way for the next generation's brain-computer
interface (BCI). This article will help brain scientists and deep-learning
researchers to gain a bird's eye view of fine-grained language perception, and
thus facilitate their further investigation and research of neural process and
language decoding.",2024-07-30,"Yu Wang, Heyang Liu, Yuhao Wang, Chuan Xuan, Yixuan Hou, Sheng Feng, Hongcheng Liu, Yusheng Liao, Yanfeng Wang",http://arxiv.org/pdf/2407.20622v1,cs.CL
Questionnaires for Everyone: Streamlining Cross-Cultural Questionnaire Adaptation with GPT-Based Translation Quality Evaluation,"Adapting questionnaires to new languages is a resource-intensive process
often requiring the hiring of multiple independent translators, which limits
the ability of researchers to conduct cross-cultural research and effectively
creates inequalities in research and society. This work presents a prototype
tool that can expedite the questionnaire translation process. The tool
incorporates forward-backward translation using DeepL alongside GPT-4-generated
translation quality evaluations and improvement suggestions. We conducted two
online studies in which participants translated questionnaires from English to
either German (Study 1; n=10) or Portuguese (Study 2; n=20) using our
prototype. To evaluate the quality of the translations created using the tool,
evaluation scores between conventionally translated and tool-supported versions
were compared. Our results indicate that integrating LLM-generated translation
quality evaluations and suggestions for improvement can help users
independently attain results similar to those provided by conventional,
non-NLP-supported translation methods. This is the first step towards more
equitable questionnaire-based research, powered by AI.",2024-07-30,"Otso Haavisto, Robin Welsch",http://arxiv.org/pdf/2407.20608v1,cs.CL
Harvesting Textual and Structured Data from the HAL Publication Repository,"HAL (\textit{Hyper Articles en Ligne}) is the French national publication
repository, used by most higher education and research organizations for their
open science policy. Although it is a rich repository of academic documents,
its potential for advanced research has not been fully explored. We present
HALvest, a unique dataset that bridges the gap between citation networks and
the full text of HAL-submitted articles to help with authorship attribution and
verification. This first iteration consists of approximately 700,000 documents,
spanning 56 languages across 13 identified domains. We transform articles'
metadata into a citation network, producing a heterogeneous graph. This graph
includes uniquely identified authors on HAL, as well as all open-access
documents and their references. Finally, we mine 14.5 million high-quality
sequence pairs from HALvest for contrastive learning purposes. By providing
different views of HAL, suited for modern machine learning, we aim to assist
practitioners in better analyzing and interpreting research dynamics.",2024-07-30,"Francis Kulumba, Wissam Antoun, Guillaume Vimont, Laurent Romary",http://arxiv.org/pdf/2407.20595v2,cs.CL
Enhancing Agricultural Machinery Management through Advanced LLM Integration,"The integration of artificial intelligence into agricultural practices,
specifically through Consultation on Intelligent Agricultural Machinery
Management (CIAMM), has the potential to revolutionize efficiency and
sustainability in farming. This paper introduces a novel approach that
leverages large language models (LLMs), particularly GPT-4, combined with
multi-round prompt engineering to enhance decision-making processes in
agricultural machinery management. We systematically developed and refined
prompts to guide the LLMs in generating precise and contextually relevant
outputs. Our approach was evaluated using a manually curated dataset from
various online sources, and performance was assessed with accuracy and GPT-4
Scores. Comparative experiments were conducted using LLama-2-70B, ChatGPT, and
GPT-4 models, alongside baseline and state-of-the-art methods such as Chain of
Thought (CoT) and Thought of Thought (ThoT). The results demonstrate that our
method significantly outperforms these approaches, achieving higher accuracy
and relevance in generated responses. This paper highlights the potential of
advanced prompt engineering techniques in improving the robustness and
applicability of AI in agricultural contexts.",2024-07-30,"Emily Johnson, Noah Wilson",http://arxiv.org/pdf/2407.20588v1,cs.CL
Pruning Large Language Models with Semi-Structural Adaptive Sparse Training,"The remarkable success of Large Language Models (LLMs) relies heavily on
their substantial scale, which poses significant challenges during model
deployment in terms of latency and memory consumption. Recently, numerous
studies have attempted to compress LLMs using one-shot pruning methods.
However, these methods often suffer from considerable performance degradation
on complex language understanding tasks, raising concerns about the feasibility
of pruning in LLMs. To address this issue, we propose Adaptive Sparse Trainer
(AST), a novel and efficient retraining framework tailored for semi-structured
sparse models. AST enables models to learn optimal masks during the weight
update process without incurring additional computational overhead.
Furthermore, we demonstrate that incorporating knowledge distillation
significantly improves retraining efficiency and enhances model performance
under fixed computational constraints. Additionally, a supplementary set of
well-initialized parameters is integrated to further augment the model's
efficacy. AST achieves state-of-the-art performance with minimal training cost.
When applied to the LLaMA2-7B model, AST reduces the perplexity and zero-shot
accuracy gap between dense and 2:4 semi-structured sparse models to 0.6 and
1.16%, respectively, utilizing less than 0.4% of the pretraining tokens and GPU
hours. Our work demonstrates the feasibility of deploying semi-structured
sparse LLMs and offers a promising alternative for achieving highly compressed
models when combined with existing quantization techniques.",2024-07-30,"Weiyu Huang, Yuezhou Hu, Guohao Jian, Jun Zhu, Jianfei Chen",http://arxiv.org/pdf/2407.20584v3,cs.CL
Knesset-DictaBERT: A Hebrew Language Model for Parliamentary Proceedings,"We present Knesset-DictaBERT, a large Hebrew language model fine-tuned on the
Knesset Corpus, which comprises Israeli parliamentary proceedings. The model is
based on the DictaBERT architecture and demonstrates significant improvements
in understanding parliamentary language according to the MLM task. We provide a
detailed evaluation of the model's performance, showing improvements in
perplexity and accuracy over the baseline DictaBERT model.",2024-07-30,"Gili Goldin, Shuly Wintner",http://arxiv.org/pdf/2407.20581v1,cs.CL
Comparison of Large Language Models for Generating Contextually Relevant Questions,"This study explores the effectiveness of Large Language Models (LLMs) for
Automatic Question Generation in educational settings. Three LLMs are compared
in their ability to create questions from university slide text without
fine-tuning. Questions were obtained in a two-step pipeline: first, answer
phrases were extracted from slides using Llama 2-Chat 13B; then, the three
models generated questions for each answer. To analyze whether the questions
would be suitable in educational applications for students, a survey was
conducted with 46 students who evaluated a total of 246 questions across five
metrics: clarity, relevance, difficulty, slide relation, and question-answer
alignment. Results indicate that GPT-3.5 and Llama 2-Chat 13B outperform Flan
T5 XXL by a small margin, particularly in terms of clarity and question-answer
alignment. GPT-3.5 especially excels at tailoring questions to match the input
answers. The contribution of this research is the analysis of the capacity of
LLMs for Automatic Question Generation in education.",2024-07-30,"Ivo Lodovico Molina, Valdemar Švábenský, Tsubasa Minematsu, Li Chen, Fumiya Okubo, Atsushi Shimada",http://arxiv.org/pdf/2407.20578v2,cs.CL
CLR-Fact: Evaluating the Complex Logical Reasoning Capability of Large Language Models over Factual Knowledge,"While large language models (LLMs) have demonstrated impressive capabilities
across various natural language processing tasks by acquiring rich factual
knowledge from their broad training data, their ability to synthesize and
logically reason with this knowledge in complex ways remains underexplored. In
this work, we present a systematic evaluation of state-of-the-art LLMs' complex
logical reasoning abilities through a novel benchmark of automatically
generated complex reasoning questions over general domain and biomedical
knowledge graphs. Our extensive experiments, employing diverse in-context
learning techniques, reveal that LLMs excel at reasoning over general world
knowledge but face significant challenges with specialized domain-specific
knowledge. We find that prompting with explicit Chain-of-Thought demonstrations
can substantially improve LLM performance on complex logical reasoning tasks
with diverse logical operations. Interestingly, our controlled evaluations
uncover an asymmetry where LLMs display proficiency at set union operations,
but struggle considerably with set intersections - a key building block of
logical reasoning. To foster further work, we will publicly release our
evaluation benchmark and code.",2024-07-30,"Tianshi Zheng, Jiaxin Bai, Yicheng Wang, Tianqing Fang, Yue Guo, Yauwai Yim, Yangqiu Song",http://arxiv.org/pdf/2407.20564v1,cs.CL
Survey of Design Paradigms for Social Robots,"The demand for social robots in fields like healthcare, education, and
entertainment increases due to their emotional adaptation features. These
robots leverage multimodal communication, incorporating speech, facial
expressions, and gestures to enhance user engagement and emotional support. The
understanding of design paradigms of social robots is obstructed by the
complexity of the system and the necessity to tune it to a specific task. This
article provides a structured review of social robot design paradigms,
categorizing them into cognitive architectures, role design models, linguistic
models, communication flow, activity system models, and integrated design
models. By breaking down the articles on social robot design and application
based on these paradigms, we highlight the strengths and areas for improvement
in current approaches. We further propose our original integrated design model
that combines the most important aspects of the design of social robots. Our
approach shows the importance of integrating operational, communicational, and
emotional dimensions to create more adaptive and empathetic interactions
between robots and humans.",2024-07-30,"Rita Frieske, Xiaoyu Mo, Yini Fang, Jay Nieles, Bertram E. Shi",http://arxiv.org/pdf/2407.20556v1,cs.CL
Contrastive Feedback Mechanism for Simultaneous Speech Translation,"Recent advances in simultaneous speech translation (SST) focus on the
decision policies that enable the use of offline-trained ST models for
simultaneous inference. These decision policies not only control the
quality-latency trade-off in SST but also mitigate the impact of unstable
predictions on translation quality by delaying translation for more context or
discarding these predictions through stable hypothesis detection. However,
these policies often overlook the potential benefits of utilizing unstable
predictions. We introduce the contrastive feedback mechanism (CFM) for SST, a
novel method that leverages these unstable predictions as feedback to improve
translation quality. CFM guides the system to eliminate undesired model
behaviors from these predictions through a contrastive objective. The
experiments on 3 state-of-the-art decision policies across 8 languages in the
MuST-C v1.0 dataset show that CFM effectively improves the performance of SST.",2024-07-30,"Haotian Tan, Sakriani Sakti",http://arxiv.org/pdf/2407.20524v2,cs.CL
Machine Unlearning in Generative AI: A Survey,"Generative AI technologies have been deployed in many places, such as
(multimodal) large language models and vision generative models. Their
remarkable performance should be attributed to massive training data and
emergent reasoning abilities. However, the models would memorize and generate
sensitive, biased, or dangerous information originated from the training data
especially those from web crawl. New machine unlearning (MU) techniques are
being developed to reduce or eliminate undesirable knowledge and its effects
from the models, because those that were designed for traditional
classification tasks could not be applied for Generative AI. We offer a
comprehensive survey on many things about MU in Generative AI, such as a new
problem formulation, evaluation methods, and a structured discussion on the
advantages and limitations of different kinds of MU techniques. It also
presents several critical challenges and promising directions in MU research. A
curated list of readings can be found:
https://github.com/franciscoliu/GenAI-MU-Reading.",2024-07-30,"Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang",http://arxiv.org/pdf/2407.20516v1,cs.CL
Prompt2DeModel: Declarative Neuro-Symbolic Modeling with Natural Language,"This paper presents a conversational pipeline for crafting domain knowledge
for complex neuro-symbolic models through natural language prompts. It
leverages large language models to generate declarative programs in the
DomiKnowS framework. The programs in this framework express concepts and their
relationships as a graph in addition to logical constraints between them. The
graph, later, can be connected to trainable neural models according to those
specifications. Our proposed pipeline utilizes techniques like dynamic
in-context demonstration retrieval, model refinement based on feedback from a
symbolic parser, visualization, and user interaction to generate the tasks'
structure and formal knowledge representation. This approach empowers domain
experts, even those not well-versed in ML/AI, to formally declare their
knowledge to be incorporated in customized neural models in the DomiKnowS
framework.",2024-07-30,"Hossein Rajaby Faghihi, Aliakbar Nafar, Andrzej Uszok, Hamid Karimian, Parisa Kordjamshidi",http://arxiv.org/pdf/2407.20513v1,cs.CL
A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder,"Recently, large language models (LLM) based on transformers are facing memory
bottleneck issues due to KV cache, especially in long sequence handling.
Previous researches proposed KV cache compression techniques that identify
insignificant tokens based on Accumulative Attention Scores and removes their
items from KV cache, noting that only few tokens play an important role in
attention operations. However, we have observed that the existing Accumulative
Attention Score is not suitable for the transformer decoder structure. In the
decoder model, the number of times the Attention Score accumulates varies
depending on the order of token appearance due to the effect of masking,
causing an uneven comparison between tokens. To solve this, we propose
Accumulative Attention Score with Forgetting Factor (A2SF) technique, which
introduces a Forgetting Factor in the Attention Score accumulation process.
A2SF applies a penalty to the past Attention Score generated from old tokens by
repeatedly multiplying the Forgetting Factor to the Attention Score over time.
Therefore, older tokens receive a larger penalty, providing fairness among
different ages of tokens. Through the fair comparison among tokens, we can more
effectively select important tokens. We have verified the accuracy improvement
through A2SF in the OPT and LLaMA models and A2SF improves the accuracy of
LLaMA 2 by up to 7.8% and 5.1% on 1-shot and 0-shot.",2024-07-30,"Hyun-rae Jo, Dongkun Shin",http://arxiv.org/pdf/2407.20485v2,cs.CL
CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models,"Instruction tuning in multimodal large language models (MLLMs) aims to
smoothly integrate a backbone LLM with a pre-trained feature encoder for
downstream tasks. The major challenge is how to efficiently find the synergy
through cooperative learning where LLMs adapt their reasoning abilities in
downstream tasks while feature encoders adjust their encoding to provide more
relevant modal information. In this paper, we analyze the MLLM instruction
tuning from both theoretical and empirical perspectives, where we find
unbalanced learning between the two components, i.e., the feature encoder and
the LLM, can cause diminishing learning gradients that slow the model
convergence and often lead to sub-optimal results due to insufficient learning.
Inspired by our findings, we propose a measurement to quantitatively evaluate
the learning balance, based on which we further design a dynamic learning
scheduler that better coordinates the learning. In addition, we introduce an
auxiliary loss regularization method to promote updating of the generation
distribution of MLLMs considering the learning state of each model component,
which potentially prevents each component from gradient diminishing and enables
a more accurate estimation of the learning balance coefficient. We conduct
experiments with multiple LLM backbones and feature encoders, where our
techniques are model-agnostic and can be generically integrated with various
MLLM backbones. Experiment results on multiple downstream tasks and modalities
in vision and audio, demonstrate the proposed method's better efficiency and
effectiveness in MLLM instruction tuning.",2024-07-29,"Junda Wu, Xintong Li, Tong Yu, Yu Wang, Xiang Chen, Jiuxiang Gu, Lina Yao, Jingbo Shang, Julian McAuley",http://arxiv.org/pdf/2407.20454v1,cs.CL
APE: Active Learning-based Tooling for Finding Informative Few-shot Examples for LLM-based Entity Matching,"Prompt engineering is an iterative procedure often requiring extensive manual
effort to formulate suitable instructions for effectively directing large
language models (LLMs) in specific tasks. Incorporating few-shot examples is a
vital and effective approach to providing LLMs with precise instructions,
leading to improved LLM performance. Nonetheless, identifying the most
informative demonstrations for LLMs is labor-intensive, frequently entailing
sifting through an extensive search space. In this demonstration, we showcase a
human-in-the-loop tool called APE (Active Prompt Engineering) designed for
refining prompts through active learning. Drawing inspiration from active
learning, APE iteratively selects the most ambiguous examples for human
feedback, which will be transformed into few-shot examples within the prompt.
The demo recording can be found with the submission or be viewed at
https://youtu.be/OwQ6MQx53-Y.",2024-07-29,"Kun Qian, Yisi Sang, Farima Fatahi Bayat, Anton Belyi, Xianqi Chu, Yash Govind, Samira Khorshidi, Rahul Khot, Katherine Luna, Azadeh Nikfarjam, Xiaoguang Qi, Fei Wu, Xianhan Zhang, Yunyao Li",http://arxiv.org/pdf/2408.04637v1,cs.CL
Generating Gender Alternatives in Machine Translation,"Machine translation (MT) systems often translate terms with ambiguous gender
(e.g., English term ""the nurse"") into the gendered form that is most prevalent
in the systems' training data (e.g., ""enfermera"", the Spanish term for a female
nurse). This often reflects and perpetuates harmful stereotypes present in
society. With MT user interfaces in mind that allow for resolving gender
ambiguity in a frictionless manner, we study the problem of generating all
grammatically correct gendered translation alternatives. We open source train
and test datasets for five language pairs and establish benchmarks for this
task. Our key technical contribution is a novel semi-supervised solution for
generating alternatives that integrates seamlessly with standard MT models and
maintains high performance without requiring additional components or
increasing inference overhead.",2024-07-29,"Sarthak Garg, Mozhdeh Gheini, Clara Emmanuel, Tatiana Likhomanenko, Qin Gao, Matthias Paulik",http://arxiv.org/pdf/2407.20438v1,cs.CL
"Through the Looking Glass, and what Horn Clause Programs Found There","Dual Horn clauses mirror key properties of Horn clauses. This paper explores
the ``other side of the looking glass'' to reveal some expected and unexpected
symmetries and their practical uses.
  We revisit Dual Horn clauses as enablers of a form of constructive negation
that supports goal-driven forward reasoning and is valid both
intuitionistically and classically. In particular, we explore the ability to
falsify a counterfactual hypothesis in the context of a background theory
expressed as a Dual Horn clause program.
  With Dual Horn clause programs, by contrast to negation as failure, the
variable bindings in their computed answers provide explanations for the
reasons why a statement is successfully falsified. Moreover, in the
propositional case, by contrast to negation as failure as implemented with
stable models semantics in ASP systems, and similarly to Horn clause programs,
Dual Horn clause programs have polynomial complexity.
  After specifying their execution model with a metainterpreter, we devise a
compilation scheme from Dual Horn clause programs to Horn clause programs,
ensuring their execution with no performance penalty and we design the embedded
SymLP language to support combined Horn clause and Dual Horn clause programs.
  As a (motivating) application, we cast LLM reasoning chains into
propositional Horn and Dual Horn clauses that work together to constructively
prove and disprove goals and enhance Generative AI with explainability of
reasoning chains.",2024-07-29,Paul Tarau,http://arxiv.org/pdf/2407.20413v1,cs.CL
Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models,"Large Language Models (LLMs) require high quality instruction data for
effective alignment, particularly in code generation tasks where expert curated
datasets are expensive to produce. We present Genetic-Instruct, a scalable
algorithm for synthesizing large-scale, high quality coding instructions using
evolutionary principles. Starting from a small set of seed instructions,
Genetic-Instruct generates diverse and challenging instruction-code pairs by
leveraging an Instructor-LLM for generation, a Coder-LLM for code synthesis,
and a Judge-LLM for automatic quality evaluation. Our proposed approach is
highly parallelizable and effective even with a small seed data and weaker
generator models. We generated more than 7.5 million coding instructions with
the proposed approach. Then we evaluated it by fine-tuning LLMs with the
synthetic samples and demonstrated a significant improvement in their code
generation capability compared to the other synthetic generation approaches and
publicly available datasets. Our results highlight the efficiency, scalability,
and generalizability of the Genetic-Instruct framework.",2024-07-29,"Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg",http://arxiv.org/pdf/2407.21077v3,cs.CL
What if Red Can Talk? Dynamic Dialogue Generation Using Large Language Models,"Role-playing games (RPGs) provide players with a rich, interactive world to
explore. Dialogue serves as the primary means of communication between
developers and players, manifesting in various forms such as guides, NPC
interactions, and storytelling. While most games rely on written scripts to
define the main story and character personalities, player immersion can be
significantly enhanced through casual interactions between characters. With the
advent of large language models (LLMs), we introduce a dialogue filler
framework that utilizes LLMs enhanced by knowledge graphs to generate dynamic
and contextually appropriate character interactions. We test this framework
within the environments of Final Fantasy VII Remake and Pokemon, providing
qualitative and quantitative evidence that demonstrates GPT-4's capability to
act with defined personalities and generate dialogue. However, some flaws
remain, such as GPT-4 being overly positive or more subtle personalities, such
as maturity, tend to be of lower quality compared to more overt traits like
timidity. This study aims to assist developers in crafting more nuanced filler
dialogues, thereby enriching player immersion and enhancing the overall RPG
experience.",2024-07-29,"Navapat Nananukul, Wichayaporn Wongkamjan",http://arxiv.org/pdf/2407.20382v1,cs.CL
"Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval","Artificial intelligence (AI) hiring tools have revolutionized resume
screening, and large language models (LLMs) have the potential to do the same.
However, given the biases which are embedded within LLMs, it is unclear whether
they can be used in this scenario without disadvantaging groups based on their
protected attributes. In this work, we investigate the possibilities of using
LLMs in a resume screening setting via a document retrieval framework that
simulates job candidate selection. Using that framework, we then perform a
resume audit study to determine whether a selection of Massive Text Embedding
(MTE) models are biased in resume screening scenarios. We simulate this for
nine occupations, using a collection of over 500 publicly available resumes and
500 job descriptions. We find that the MTEs are biased, significantly favoring
White-associated names in 85.1\% of cases and female-associated names in only
11.1\% of cases, with a minority of cases showing no statistically significant
differences. Further analyses show that Black males are disadvantaged in up to
100\% of cases, replicating real-world patterns of bias in employment settings,
and validate three hypotheses of intersectionality. We also find an impact of
document length as well as the corpus frequency of names in the selection of
resumes. These findings have implications for widely used AI tools that are
automating employment, fairness, and tech policy.",2024-07-29,"Kyra Wilson, Aylin Caliskan",http://arxiv.org/pdf/2407.20371v2,cs.CL
Apple Intelligence Foundation Language Models,"We present foundation language models developed to power Apple Intelligence
features, including a ~3 billion parameter model designed to run efficiently on
devices and a large server-based language model designed for Private Cloud
Compute. These models are designed to perform a wide range of tasks
efficiently, accurately, and responsibly. This report describes the model
architecture, the data used to train the model, the training process, how the
models are optimized for inference, and the evaluation results. We highlight
our focus on Responsible AI and how the principles are applied throughout the
model development.",2024-07-29,"Tom Gunter, Zirui Wang, Chong Wang, Ruoming Pang, Andy Narayanan, Aonan Zhang, Bowen Zhang, Chen Chen, Chung-Cheng Chiu, David Qiu, Deepak Gopinath, Dian Ang Yap, Dong Yin, Feng Nan, Floris Weers, Guoli Yin, Haoshuo Huang, Jianyu Wang, Jiarui Lu, John Peebles, Ke Ye, Mark Lee, Nan Du, Qibin Chen, Quentin Keunebroek, Sam Wiseman, Syd Evans, Tao Lei, Vivek Rathod, Xiang Kong, Xianzhi Du, Yanghao Li, Yongqiang Wang, Yuan Gao, Zaid Ahmed, Zhaoyang Xu, Zhiyun Lu, Al Rashid, Albin Madappally Jose, Alec Doane, Alfredo Bencomo, Allison Vanderby, Andrew Hansen, Ankur Jain, Anupama Mann Anupama, Areeba Kamal, Bugu Wu, Carolina Brum, Charlie Maalouf, Chinguun Erdenebileg, Chris Dulhanty, Dominik Moritz, Doug Kang, Eduardo Jimenez, Evan Ladd, Fangping Shi, Felix Bai, Frank Chu, Fred Hohman, Hadas Kotek, Hannah Gillis Coleman, Jane Li, Jeffrey Bigham, Jeffery Cao, Jeff Lai, Jessica Cheung, Jiulong Shan, Joe Zhou, John Li, Jun Qin, Karanjeet Singh, Karla Vega, Kelvin Zou, Laura Heckman, Lauren Gardiner, Margit Bowler, Maria Cordell, Meng Cao, Nicole Hay, Nilesh Shahdadpuri, Otto Godwin, Pranay Dighe, Pushyami Rachapudi, Ramsey Tantawi, Roman Frigg, Sam Davarnia, Sanskruti Shah, Saptarshi Guha, Sasha Sirovica, Shen Ma, Shuang Ma, Simon Wang, Sulgi Kim, Suma Jayaram, Vaishaal Shankar, Varsha Paidi, Vivek Kumar, Xin Wang, Xin Zheng, Walker Cheng, Yael Shrager, Yang Ye, Yasu Tanaka, Yihao Guo, Yunsong Meng, Zhao Tang Luo, Zhi Ouyang, Alp Aygar, Alvin Wan, Andrew Walkingshaw, Andy Narayanan, Antonie Lin, Arsalan Farooq, Brent Ramerth, Colorado Reed, Chris Bartels, Chris Chaney, David Riazati, Eric Liang Yang, Erin Feldman, Gabriel Hochstrasser, Guillaume Seguin, Irina Belousova, Joris Pelemans, Karen Yang, Keivan Alizadeh Vahid, Liangliang Cao, Mahyar Najibi, Marco Zuliani, Max Horton, Minsik Cho, Nikhil Bhendawade, Patrick Dong, Piotr Maj, Pulkit Agrawal, Qi Shan, Qichen Fu, Regan Poston, Sam Xu, Shuangning Liu, Sushma Rao, Tashweena Heeramun, Thomas Merth, Uday Rayala, Victor Cui, Vivek Rangarajan Sridhar, Wencong Zhang, Wenqi Zhang, Wentao Wu, Xingyu Zhou, Xinwen Liu, Yang Zhao, Yin Xia, Zhile Ren, Zhongzheng Ren",http://arxiv.org/pdf/2407.21075v1,cs.CL
BRIDGE: Bridging Gaps in Image Captioning Evaluation with Stronger Visual Cues,"Effectively aligning with human judgment when evaluating machine-generated
image captions represents a complex yet intriguing challenge. Existing
evaluation metrics like CIDEr or CLIP-Score fall short in this regard as they
do not take into account the corresponding image or lack the capability of
encoding fine-grained details and penalizing hallucinations. To overcome these
issues, in this paper, we propose BRIDGE, a new learnable and reference-free
image captioning metric that employs a novel module to map visual features into
dense vectors and integrates them into multi-modal pseudo-captions which are
built during the evaluation process. This approach results in a multimodal
metric that properly incorporates information from the input image without
relying on reference captions, bridging the gap between human judgment and
machine-generated image captions. Experiments spanning several datasets
demonstrate that our proposal achieves state-of-the-art results compared to
existing reference-free evaluation scores. Our source code and trained models
are publicly available at: https://github.com/aimagelab/bridge-score.",2024-07-29,"Sara Sarto, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara",http://arxiv.org/pdf/2407.20341v1,cs.CL
Can Editing LLMs Inject Harm?,"Knowledge editing has been increasingly adopted to correct the false or
outdated knowledge in Large Language Models (LLMs). Meanwhile, one critical but
under-explored question is: can knowledge editing be used to inject harm into
LLMs? In this paper, we propose to reformulate knowledge editing as a new type
of safety threat for LLMs, namely Editing Attack, and conduct a systematic
investigation with a newly constructed dataset EditAttack. Specifically, we
focus on two typical safety risks of Editing Attack including Misinformation
Injection and Bias Injection. For the risk of misinformation injection, we
first categorize it into commonsense misinformation injection and long-tail
misinformation injection. Then, we find that editing attacks can inject both
types of misinformation into LLMs, and the effectiveness is particularly high
for commonsense misinformation injection. For the risk of bias injection, we
discover that not only can biased sentences be injected into LLMs with high
effectiveness, but also one single biased sentence injection can cause a bias
increase in general outputs of LLMs, which are even highly irrelevant to the
injected sentence, indicating a catastrophic impact on the overall fairness of
LLMs. Then, we further illustrate the high stealthiness of editing attacks,
measured by their impact on the general knowledge and reasoning capacities of
LLMs, and show the hardness of defending editing attacks with empirical
evidence. Our discoveries demonstrate the emerging misuse risks of knowledge
editing techniques on compromising the safety alignment of LLMs and the
feasibility of disseminating misinformation or bias with LLMs as new channels.",2024-07-29,"Canyu Chen, Baixiang Huang, Zekun Li, Zhaorun Chen, Shiyang Lai, Xiongxiao Xu, Jia-Chen Gu, Jindong Gu, Huaxiu Yao, Chaowei Xiao, Xifeng Yan, William Yang Wang, Philip Torr, Dawn Song, Kai Shu",http://arxiv.org/pdf/2407.20224v3,cs.CL
"Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process","Recent advances in language models have demonstrated their capability to
solve mathematical reasoning problems, achieving near-perfect accuracy on
grade-school level math benchmarks like GSM8K. In this paper, we formally study
how language models solve these problems. We design a series of controlled
experiments to address several fundamental questions: (1) Can language models
truly develop reasoning skills, or do they simply memorize templates? (2) What
is the model's hidden (mental) reasoning process? (3) Do models solve math
questions using skills similar to or different from humans? (4) Do models
trained on GSM8K-like datasets develop reasoning skills beyond those necessary
for solving GSM8K problems? (5) What mental process causes models to make
reasoning mistakes? (6) How large or deep must a model be to effectively solve
GSM8K-level math questions?
  Our study uncovers many hidden mechanisms by which language models solve
mathematical questions, providing insights that extend beyond current
understandings of LLMs.",2024-07-29,"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu",http://arxiv.org/pdf/2407.20311v1,cs.CL
QAEA-DR: A Unified Text Augmentation Framework for Dense Retrieval,"In dense retrieval, embedding long texts into dense vectors can result in
information loss, leading to inaccurate query-text matching. Additionally,
low-quality texts with excessive noise or sparse key information are unlikely
to align well with relevant queries. Recent studies mainly focus on improving
the sentence embedding model or retrieval process. In this work, we introduce a
novel text augmentation framework for dense retrieval. This framework
transforms raw documents into information-dense text formats, which supplement
the original texts to effectively address the aforementioned issues without
modifying embedding or retrieval methodologies. Two text representations are
generated via large language models (LLMs) zero-shot prompting: question-answer
pairs and element-driven events. We term this approach QAEA-DR: unifying
question-answer generation and event extraction in a text augmentation
framework for dense retrieval. To further enhance the quality of generated
texts, a scoring-based evaluation and regeneration mechanism is introduced in
LLM prompting. Our QAEA-DR model has a positive impact on dense retrieval,
supported by both theoretical analysis and empirical experiments.",2024-07-29,"Hongming Tan, Shaoxiong Zhan, Hai Lin, Hai-Tao Zheng, Wai Kin Chan",http://arxiv.org/pdf/2407.20207v2,cs.CL
Aligning Query Representation with Rewritten Query and Relevance Judgments in Conversational Search,"Conversational search supports multi-turn user-system interactions to solve
complex information needs. Different from the traditional single-turn ad-hoc
search, conversational search encounters a more challenging problem of
context-dependent query understanding with the lengthy and long-tail
conversational history context. While conversational query rewriting methods
leverage explicit rewritten queries to train a rewriting model to transform the
context-dependent query into a stand-stone search query, this is usually done
without considering the quality of search results. Conversational dense
retrieval methods use fine-tuning to improve a pre-trained ad-hoc query
encoder, but they are limited by the conversational search data available for
training. In this paper, we leverage both rewritten queries and relevance
judgments in the conversational search data to train a better query
representation model. The key idea is to align the query representation with
those of rewritten queries and relevant documents. The proposed model -- Query
Representation Alignment Conversational Dense Retriever, QRACDR, is tested on
eight datasets, including various settings in conversational search and ad-hoc
search. The results demonstrate the strong performance of QRACDR compared with
state-of-the-art methods, and confirm the effectiveness of representation
alignment.",2024-07-29,"Fengran Mo, Chen Qu, Kelong Mao, Yihong Wu, Zhan Su, Kaiyu Huang, Jian-Yun Nie",http://arxiv.org/pdf/2407.20189v1,cs.CL
MindSearch: Mimicking Human Minds Elicits Deep AI Searcher,"Information seeking and integration is a complex cognitive task that consumes
enormous time and effort. Inspired by the remarkable progress of Large Language
Models, recent works attempt to solve this task by combining LLMs and search
engines. However, these methods still obtain unsatisfying performance due to
three challenges: (1) complex requests often cannot be accurately and
completely retrieved by the search engine once (2) corresponding information to
be integrated is spread over multiple web pages along with massive noise, and
(3) a large number of web pages with long contents may quickly exceed the
maximum context length of LLMs. Inspired by the cognitive process when humans
solve these problems, we introduce MindSearch to mimic the human minds in web
information seeking and integration, which can be instantiated by a simple yet
effective LLM-based multi-agent framework. The WebPlanner models the human mind
of multi-step information seeking as a dynamic graph construction process: it
decomposes the user query into atomic sub-questions as nodes in the graph and
progressively extends the graph based on the search result from WebSearcher.
Tasked with each sub-question, WebSearcher performs hierarchical information
retrieval with search engines and collects valuable information for WebPlanner.
The multi-agent design of MindSearch enables the whole framework to seek and
integrate information parallelly from larger-scale (e.g., more than 300) web
pages in 3 minutes, which is worth 3 hours of human effort. MindSearch
demonstrates significant improvement in the response quality in terms of depth
and breadth, on both close-set and open-set QA problems. Besides, responses
from MindSearch based on InternLM2.5-7B are preferable by humans to ChatGPT-Web
and Perplexity.ai applications, which implies that MindSearch can already
deliver a competitive solution to the proprietary AI search engine.",2024-07-29,"Zehui Chen, Kuikun Liu, Qiuchen Wang, Jiangning Liu, Wenwei Zhang, Kai Chen, Feng Zhao",http://arxiv.org/pdf/2407.20183v1,cs.CL
AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs,"Domain reweighting is an emerging research area aimed at adjusting the
relative weights of different data sources to improve the effectiveness and
efficiency of LLM pre-training. We show that data mixtures that perform well at
smaller scales may not retain their advantage at larger scales, challenging the
existing practice of determining competitive mixtures in small-scale
experiments and directly applying them at much larger scales. To address this,
we propose AutoScale, a two-stage, scale-aware data composition framework.
First, AutoScale fits a parametric model that predicts the model's loss under
different data compositions, then uses it to find an approximate best
allocation at smaller, more manageable budgets. Next, leveraging a novel
theoretical analysis of how optimal compositions evolve with scale, AutoScale
extrapolates that composition to larger budgets without further retraining.
Empirically, AutoScale accelerates convergence and improves downstream
performance. For instance, when pre-training GPT-2 Large, it achieves a 28%
faster perplexity reduction than baselines and up to a 38% speed-up over
unweighted training, while yielding best-average results on various downstream
tasks. Overall, our findings illustrate how domain importance shifts with
training scale, underscoring the need for scale-dependent data curation in LLM
training. Our code is open-sourced.",2024-07-29,"Feiyang Kang, Yifan Sun, Bingbing Wen, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia",http://arxiv.org/pdf/2407.20177v4,cs.CL
An Energy-based Model for Word-level AutoCompletion in Computer-aided Translation,"Word-level AutoCompletion(WLAC) is a rewarding yet challenging task in
Computer-aided Translation. Existing work addresses this task through a
classification model based on a neural network that maps the hidden vector of
the input context into its corresponding label (i.e., the candidate target word
is treated as a label). Since the context hidden vector itself does not take
the label into account and it is projected to the label through a linear
classifier, the model can not sufficiently leverage valuable information from
the source sentence as verified in our experiments, which eventually hinders
its overall performance. To alleviate this issue, this work proposes an
energy-based model for WLAC, which enables the context hidden vector to capture
crucial information from the source sentence. Unfortunately, training and
inference suffer from efficiency and effectiveness challenges, thereby we
employ three simple yet effective strategies to put our model into practice.
Experiments on four standard benchmarks demonstrate that our reranking-based
approach achieves substantial improvements (about 6.07%) over the previous
state-of-the-art model. Further analyses show that each strategy of our
approach contributes to the final performance.",2024-07-29,"Cheng Yang, Guoping Huang, Mo Yu, Zhirui Zhang, Siheng Li, Mingming Yang, Shuming Shi, Yujiu Yang, Lemao Liu",http://arxiv.org/pdf/2407.20083v1,cs.CL
Investigating the Impact of Semi-Supervised Methods with Data Augmentation on Offensive Language Detection in Romanian Language,"Offensive language detection is a crucial task in today's digital landscape,
where online platforms grapple with maintaining a respectful and inclusive
environment. However, building robust offensive language detection models
requires large amounts of labeled data, which can be expensive and
time-consuming to obtain. Semi-supervised learning offers a feasible solution
by utilizing labeled and unlabeled data to create more accurate and robust
models. In this paper, we explore a few different semi-supervised methods, as
well as data augmentation techniques. Concretely, we implemented eight
semi-supervised methods and ran experiments for them using only the available
data in the RO-Offense dataset and applying five augmentation techniques before
feeding the data to the models. Experimental results demonstrate that some of
them benefit more from augmentations than others.",2024-07-29,"Elena-Beatrice Nicola, Dumitru-Clementin Cercel, Florin Pop",http://arxiv.org/pdf/2407.20076v1,cs.CL
Exploring Large Language Models to generate Easy to Read content,"Ensuring text accessibility and understandability are essential goals,
particularly for individuals with cognitive impairments and intellectual
disabilities, who encounter challenges in accessing information across various
mediums such as web pages, newspapers, administrative tasks, or health
documents. Initiatives like Easy to Read and Plain Language guidelines aim to
simplify complex texts; however, standardizing these guidelines remains
challenging and often involves manual processes. This work presents an
exploratory investigation into leveraging Artificial Intelligence (AI) and
Natural Language Processing (NLP) approaches to systematically simplify Spanish
texts into Easy to Read formats, with a focus on utilizing Large Language
Models (LLMs) for simplifying texts, especially in generating Easy to Read
content. The study contributes a parallel corpus of Spanish adapted for Easy To
Read format, which serves as a valuable resource for training and testing text
simplification systems. Additionally, several text simplification experiments
using LLMs and the collected corpus are conducted, involving fine-tuning and
testing a Llama2 model to generate Easy to Read content. A qualitative
evaluation, guided by an expert in text adaptation for Easy to Read content, is
carried out to assess the automatically simplified texts. This research
contributes to advancing text accessibility for individuals with cognitive
impairments, highlighting promising strategies for leveraging LLMs while
responsibly managing energy usage.",2024-07-29,"Paloma Martínez, Lourdes Moreno, Alberto Ramos",http://arxiv.org/pdf/2407.20046v1,cs.CL
Do LLMs Really Adapt to Domains? An Ontology Learning Perspective,"Large Language Models (LLMs) have demonstrated unprecedented prowess across
various natural language processing tasks in various application domains.
Recent studies show that LLMs can be leveraged to perform lexical semantic
tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL).
However, it has not effectively been verified whether their success is due to
their ability to reason over unstructured or semi-structured data, or their
effective learning of linguistic patterns and senses alone. This unresolved
question is particularly crucial when dealing with domain-specific data, where
the lexical senses and their meaning can completely differ from what a LLM has
learned during its training stage. This paper investigates the following
question: Do LLMs really adapt to domains and remain consistent in the
extraction of structured knowledge, or do they only learn lexical senses
instead of reasoning? To answer this question and, we devise a controlled
experiment setup that uses WordNet to synthesize parallel corpora, with English
and gibberish terms. We examine the differences in the outputs of LLMs for each
corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical
results show that, while adapting to the gibberish corpora, off-the-shelf LLMs
do not consistently reason over semantic relationships between concepts, and
instead leverage senses and their frame. However, fine-tuning improves the
performance of LLMs on lexical semantic tasks even when the domain-specific
terms are arbitrary and unseen during pre-training, hinting at the
applicability of pre-trained LLMs for OL.",2024-07-29,"Huu Tan Mai, Cuong Xuan Chu, Heiko Paulheim",http://arxiv.org/pdf/2407.19998v1,cs.CL
Confidence Estimation for Automatic Detection of Depression and Alzheimer's Disease Based on Clinical Interviews,"Speech-based automatic detection of Alzheimer's disease (AD) and depression
has attracted increased attention. Confidence estimation is crucial for a
trust-worthy automatic diagnostic system which informs the clinician about the
confidence of model predictions and helps reduce the risk of misdiagnosis. This
paper investigates confidence estimation for automatic detection of AD and
depression based on clinical interviews. A novel Bayesian approach is proposed
which uses a dynamic Dirichlet prior distribution to model the second-order
probability of the predictive distribution. Experimental results on the
publicly available ADReSS and DAIC-WOZ datasets demonstrate that the proposed
method outperforms a range of baselines for both classification accuracy and
confidence estimation.",2024-07-29,"Wen Wu, Chao Zhang, Philip C. Woodland",http://arxiv.org/pdf/2407.19984v1,cs.CL
A Temporal Psycholinguistics Approach to Identity Resolution of Social Media Users,"In this thesis, we propose an approach to identity resolution across social
media platforms using the topics, sentiments, and timings of the posts on the
platforms. After collecting the public posts of around 5000 profiles from
Disqus and Twitter, we analyze their posts to match their profiles across the
two platforms. We pursue both temporal and non-temporal methods in our
analysis. While neither approach proves definitively superior, the temporal
approach generally performs better. We found that the temporal window size
influences results more than the shifting amount. On the other hand, our
sentiment analysis shows that the inclusion of sentiment makes little
difference, probably due to flawed data extraction methods. We also
experimented with a distance-based reward-and-punishment-focused scoring model,
which achieved an accuracy of 24.198% and an average rank of 158.217 out of
2525 in our collected corpus. Future work includes refining sentiment analysis
by evaluating sentiments per topic, extending temporal analysis with additional
phases, and improving the scoring model through weight adjustments and modified
rewards.",2024-07-29,Md Touhidul Islam,http://arxiv.org/pdf/2407.19967v1,cs.CL
"Inference acceleration for large language models using ""stairs"" assisted greedy generation","Large Language Models (LLMs) with billions of parameters are known for their
impressive predicting capabilities but require lots of resources to run. With
their massive rise in popularity, even a small reduction in required resources
could have an impact on environment. On the other hand, smaller models require
fewer resources but may sacrifice accuracy. In this work, we are proposing an
implementation of ``stairs'' assisted greedy generation. It is a modified
assisted generation methodology that makes use of a smaller model's fast
generation, large model's batch prediction, and ""stairs"" validation in order to
achieve a speed up in prediction generation. Results show between 9.58 and
17.24 percent inference time reduction compared to a stand-alone large LLM
prediction in a text generation task without a loss in accuracy.",2024-07-29,"Domas Grigaliūnas, Mantas Lukoševičius",http://arxiv.org/pdf/2407.19947v1,cs.CL
Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models,"Sentiment analysis is a widely researched area within Natural Language
Processing (NLP), attracting significant interest due to the advent of
automated solutions. Despite this, the task remains challenging because of the
inherent complexity of languages and the subjective nature of sentiments. It is
even more challenging for less-studied and less-resourced languages such as
Lithuanian. Our review of existing Lithuanian NLP research reveals that
traditional machine learning methods and classification algorithms have limited
effectiveness for the task. In this work, we address sentiment analysis of
Lithuanian five-star-based online reviews from multiple domains that we collect
and clean. We apply transformer models to this task for the first time,
exploring the capabilities of pre-trained multilingual Large Language Models
(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the
inherent difficulty of the task, the fine-tuned models perform quite well,
especially when the sentiments themselves are less ambiguous: 80.74% and 89.61%
testing recognition accuracy of the most popular one- and five-star reviews
respectively. They significantly outperform current commercial state-of-the-art
general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.",2024-07-29,"Brigita Vileikytė, Mantas Lukoševičius, Lukas Stankevičius",http://arxiv.org/pdf/2407.19914v1,cs.CL
BEExAI: Benchmark to Evaluate Explainable AI,"Recent research in explainability has given rise to numerous post-hoc
attribution methods aimed at enhancing our comprehension of the outputs of
black-box machine learning models. However, evaluating the quality of
explanations lacks a cohesive approach and a consensus on the methodology for
deriving quantitative metrics that gauge the efficacy of explainability
post-hoc attribution methods. Furthermore, with the development of increasingly
complex deep learning models for diverse data applications, the need for a
reliable way of measuring the quality and correctness of explanations is
becoming critical. We address this by proposing BEExAI, a benchmark tool that
allows large-scale comparison of different post-hoc XAI methods, employing a
set of selected evaluation metrics.",2024-07-29,"Samuel Sithakoul, Sara Meftah, Clément Feutry",http://arxiv.org/pdf/2407.19897v1,cs.CL
Preliminary WMT24 Ranking of General MT Systems and LLMs,"This is the preliminary ranking of WMT24 General MT systems based on
automatic metrics. The official ranking will be a human evaluation, which is
superior to the automatic ranking and supersedes it. The purpose of this report
is not to interpret any findings but only provide preliminary results to the
participants of the General MT task that may be useful during the writing of
the system submission.",2024-07-29,"Tom Kocmi, Eleftherios Avramidis, Rachel Bawden, Ondrej Bojar, Anton Dvorkovich, Christian Federmann, Mark Fishel, Markus Freitag, Thamme Gowda, Roman Grundkiewicz, Barry Haddow, Marzena Karpinska, Philipp Koehn, Benjamin Marie, Kenton Murray, Masaaki Nagata, Martin Popel, Maja Popovic, Mariya Shmatova, Steinþór Steingrímsson, Vilém Zouhar",http://arxiv.org/pdf/2407.19884v1,cs.CL
Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability,"Large Language Models (LLMs), characterized by being trained on broad amounts
of data in a self-supervised manner, have shown impressive performance across a
wide range of tasks. Indeed, their generative abilities have aroused interest
on the application of LLMs across a wide range of contexts. However, neural
networks in general, and LLMs in particular, are known to be vulnerable to
adversarial attacks, where an imperceptible change to the input can mislead the
output of the model. This is a serious concern that impedes the use of LLMs on
high-stakes applications, such as healthcare, where a wrong prediction can
imply serious consequences. Even though there are many efforts on making LLMs
more robust to adversarial attacks, there are almost no works that study
\emph{how} and \emph{where} these vulnerabilities that make LLMs prone to
adversarial attacks happen. Motivated by these facts, we explore how to
localize and understand vulnerabilities, and propose a method, based on
Mechanistic Interpretability (MI) techniques, to guide this process.
Specifically, this method enables us to detect vulnerabilities related to a
concrete task by (i) obtaining the subset of the model that is responsible for
that task, (ii) generating adversarial samples for that task, and (iii) using
MI techniques together with the previous samples to discover and understand the
possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small
model carrying out the task of predicting 3-letter acronyms to demonstrate its
effectiveness on locating and understanding concrete vulnerabilities of the
model.",2024-07-29,"Jorge García-Carrasco, Alejandro Maté, Juan Trujillo",http://arxiv.org/pdf/2407.19842v1,cs.CL
ATHAR: A High-Quality and Diverse Dataset for Classical Arabic to English Translation,"Classical Arabic represents a significant era, encompassing the golden age of
Arab culture, philosophy, and scientific literature. With a broad consensus on
the importance of translating these literatures to enrich knowledge
dissemination across communities, the advent of large language models (LLMs)
and translation systems offers promising tools to facilitate this goal.
However, we have identified a scarcity of translation datasets in Classical
Arabic, which are often limited in scope and topics, hindering the development
of high-quality translation systems. In response, we present the ATHAR dataset,
comprising 66,000 high-quality Classical Arabic to English translation samples
that cover a wide array of subjects including science, culture, and philosophy.
Furthermore, we assess the performance of current state-of-the-art LLMs under
various settings, concluding that there is a need for such datasets in current
systems. Our findings highlight how models can benefit from fine-tuning or
incorporating this dataset into their pretraining pipelines. The dataset is
publicly available on the HuggingFace Data Hub at
\url{https://huggingface.co/datasets/mohamed-khalil/ATHAR}.",2024-07-29,"Mohammed Khalil, Mohammed Sabry",http://arxiv.org/pdf/2407.19835v1,cs.CL
ML-Mamba: Efficient Multi-Modal Large Language Model Utilizing Mamba-2,"Multimodal Large Language Models (MLLMs) have attracted much attention for
their multifunctionality. However, traditional Transformer architectures incur
significant overhead due to their secondary computational complexity. To
address this issue, we introduce ML-Mamba, a multimodal language model, which
utilizes the latest and efficient Mamba-2 model for inference. Mamba-2 is known
for its linear scalability and fast processing of long sequences. We replace
the Transformer-based backbone with a pre-trained Mamba-2 model and explore
methods for integrating 2D visual selective scanning mechanisms into multimodal
learning while also trying various visual encoders and Mamba-2 model variants.
Our extensive experiments in various multimodal benchmark tests demonstrate the
competitive performance of ML-Mamba and highlight the potential of state space
models in multimodal tasks. The experimental results show that: (1) we
empirically explore how to effectively apply the 2D vision selective scan
mechanism for multimodal learning. We propose a novel multimodal connector
called the Mamba-2 Scan Connector (MSC), which enhances representational
capabilities. (2) ML-Mamba achieves performance comparable to state-of-the-art
methods such as TinyLaVA and MobileVLM v2 through its linear sequential
modeling while faster inference speed; (3) Compared to multimodal models
utilizing Mamba-1, the Mamba-2-based ML-Mamba exhibits superior inference
performance and effectiveness.",2024-07-29,"Wenjun Huang, Jiakai Pan, Jiahao Tang, Yanyu Ding, Yifei Xing, Yuhe Wang, Zhengzhuo Wang, Jianguo Hu",http://arxiv.org/pdf/2407.19832v3,cs.CL
Concise Thoughts: Impact of Output Length on LLM Reasoning and Cost,"Today's large language models (LLMs) can solve challenging question-answering
tasks, and prompt engineering techniques, such as chain-of-thought (CoT), have
gained attention for enhancing the explanation and correctness of outputs.
However, many models and techniques tend to produce excessively verbose and
lengthy answers, leading to issues with both conciseness and generation time.
To address this, this paper analyzes the impact of output lengths on LLM
inference pipelines by introducing and proposing novel metrics to evaluate the
\textit{correct conciseness} of a model and related prompting techniques. Then,
we examine the impact of controlling output length through a refined prompt
engineering strategy, Constrained-CoT (CCoT), which encourages the model to
produce more concise outputs. To better understand the effects of such a
prompt, we also introduce two additional scores for analyzing the conciseness,
measured in terms of redundancy and information flow in generated answers.
Experiments on pretrained LLMs and multiple datasets demonstrate the benefits
of the proposed metrics and the effectiveness of CCoT across different models.",2024-07-29,"Sania Nayab, Giulio Rossolini, Marco Simoni, Andrea Saracino, Giorgio Buttazzo, Nicolamaria Manes, Fabrizio Giacomelli",http://arxiv.org/pdf/2407.19825v2,cs.CL
Comparative Analysis of Encoder-Based NER and Large Language Models for Skill Extraction from Russian Job Vacancies,"The labor market is undergoing rapid changes, with increasing demands on job
seekers and a surge in job openings. Identifying essential skills and
competencies from job descriptions is challenging due to varying employer
requirements and the omission of key skills. This study addresses these
challenges by comparing traditional Named Entity Recognition (NER) methods
based on encoders with Large Language Models (LLMs) for extracting skills from
Russian job vacancies. Using a labeled dataset of 4,000 job vacancies for
training and 1,472 for testing, the performance of both approaches is
evaluated. Results indicate that traditional NER models, especially DeepPavlov
RuBERT NER tuned, outperform LLMs across various metrics including accuracy,
precision, recall, and inference time. The findings suggest that traditional
NER models provide more effective and efficient solutions for skill extraction,
enhancing job requirement clarity and aiding job seekers in aligning their
qualifications with employer expectations. This research contributes to the
field of natural language processing (NLP) and its application in the labor
market, particularly in non-English contexts.",2024-07-29,"Nikita Matkin, Aleksei Smirnov, Mikhail Usanin, Egor Ivanov, Kirill Sobyanin, Sofiia Paklina, Petr Parshakov",http://arxiv.org/pdf/2407.19816v2,cs.CL
Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent,"Adversarial attacks against deep learning models represent a major threat to
the security and reliability of natural language processing (NLP) systems. In
this paper, we propose a modification to the BERT-Attack framework, integrating
Projected Gradient Descent (PGD) to enhance its effectiveness and robustness.
The original BERT-Attack, designed for generating adversarial examples against
BERT-based models, suffers from limitations such as a fixed perturbation budget
and a lack of consideration for semantic similarity. The proposed approach in
this work, PGD-BERT-Attack, addresses these limitations by leveraging PGD to
iteratively generate adversarial examples while ensuring both imperceptibility
and semantic similarity to the original input. Extensive experiments are
conducted to evaluate the performance of PGD-BERT-Attack compared to the
original BERT-Attack and other baseline methods. The results demonstrate that
PGD-BERT-Attack achieves higher success rates in causing misclassification
while maintaining low perceptual changes. Furthermore, PGD-BERT-Attack produces
adversarial instances that exhibit greater semantic resemblance to the initial
input, enhancing their applicability in real-world scenarios. Overall, the
proposed modification offers a more effective and robust approach to
adversarial attacks on BERT-based models, thus contributing to the advancement
of defense against attacks on NLP systems.",2024-07-29,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",http://arxiv.org/pdf/2407.21073v1,cs.CL
Improving Retrieval Augmented Language Model with Self-Reasoning,"The Retrieval-Augmented Language Model (RALM) has shown remarkable
performance on knowledge-intensive tasks by incorporating external knowledge
during inference, which mitigates the factual hallucinations inherited in large
language models (LLMs). Despite these advancements, challenges persist in the
implementation of RALMs, particularly concerning their reliability and
traceability. To be specific, the irrelevant document retrieval may result in
unhelpful response generation or even deteriorate the performance of LLMs,
while the lack of proper citations in generated outputs complicates efforts to
verify the trustworthiness of the models. To this end, we propose a novel
self-reasoning framework aimed at improving the reliability and traceability of
RALMs, whose core idea is to leverage reasoning trajectories generated by the
LLM itself. The framework involves constructing self-reason trajectories with
three processes: a relevance-aware process, an evidence-aware selective
process, and a trajectory analysis process. We have evaluated our framework
across four public datasets (two short-form QA datasets, one long-form QA
dataset, and one fact verification dataset) to demonstrate the superiority of
our method, which can outperform existing state-of-the-art models and can
achieve comparable performance with GPT-4, while only using 2,000 training
samples.",2024-07-29,"Yuan Xia, Jingbo Zhou, Zhenhui Shi, Jun Chen, Haifeng Huang",http://arxiv.org/pdf/2407.19813v3,cs.CL
Segmentation en phrases : ouvrez les guillemets sans perdre le fil,"This paper presents a graph cascade for sentence segmentation of XML
documents. Our proposal offers sentences inside sentences for cases introduced
by quotation marks and hyphens, and also pays particular attention to
situations involving incises introduced by parentheses and lists introduced by
colons. We present how the tool works and compare the results obtained with
those available in 2019 on the same dataset, together with an evaluation of the
system's performance on a test corpus",2024-07-29,"Sandrine Ollinger, Denis Maurel",http://arxiv.org/pdf/2407.19808v1,cs.CL
Cool-Fusion: Fuse Large Language Models without Training,"We focus on the problem of fusing two or more heterogeneous large language
models (LLMs) to facilitate their complementary strengths. One of the
challenges on model fusion is high computational load, i.e. to fine-tune or to
align vocabularies via combinatorial optimization. To this end, we propose
\emph{Cool-Fusion}, a simple yet effective approach that fuses the knowledge of
heterogeneous source LLMs to leverage their complementary strengths.
\emph{Cool-Fusion} is the first method that does not require any type of
training like the ensemble approaches. But unlike ensemble methods, it is
applicable to any set of source LLMs that have different vocabularies. The
basic idea is to have each source LLM individually generate tokens until the
tokens can be decoded into a text segment that ends at word boundaries common
to all source LLMs. Then, the source LLMs jointly rerank the generated text
segment and select the best one, which is the fused text generation in one
step. Extensive experiments are conducted across a variety of benchmark
datasets. On \emph{GSM8K}, \emph{Cool-Fusion} increases accuracy from three
strong source LLMs by a significant 8\%-17.8\%.",2024-07-29,"Cong Liu, Xiaojun Quan, Yan Pan, Liang Lin, Weigang Wu, Xu Chen",http://arxiv.org/pdf/2407.19807v1,cs.CL
Teaching LLMs at Charles University: Assignments and Activities,"This paper presents teaching materials, particularly assignments and ideas
for classroom activities, from a new course on large language models (LLMs)
taught at Charles University. The assignments include experiments with LLM
inference for weather report generation and machine translation. The classroom
activities include class quizzes, focused research on downstream tasks and
datasets, and an interactive ""best paper"" session aimed at reading and
comprehension of research papers.",2024-07-29,"Jindřich Helcl, Zdeněk Kasner, Ondřej Dušek, Tomasz Limisiewicz, Dominik Macháček, Tomáš Musil, Jindřich Libovický",http://arxiv.org/pdf/2407.19798v1,cs.CL
VolDoGer: LLM-assisted Datasets for Domain Generalization in Vision-Language Tasks,"Domain generalizability is a crucial aspect of a deep learning model since it
determines the capability of the model to perform well on data from unseen
domains. However, research on the domain generalizability of deep learning
models for vision-language tasks remains limited, primarily because of the lack
of required datasets. To address these challenges, we propose VolDoGer:
Vision-Language Dataset for Domain Generalization, a dedicated dataset designed
for domain generalization that addresses three vision-language tasks: image
captioning, visual question answering, and visual entailment. We constructed
VolDoGer by extending LLM-based data annotation techniques to vision-language
tasks, thereby alleviating the burden of recruiting human annotators. We
evaluated the domain generalizability of various models, ranging from
fine-tuned models to a recent multimodal large language model, through
VolDoGer.",2024-07-29,"Juhwan Choi, Junehyoung Kwon, JungMin Yun, Seunguk Yu, YoungBin Kim",http://arxiv.org/pdf/2407.19795v1,cs.CL
Introducing a new hyper-parameter for RAG: Context Window Utilization,"This paper introduces a new hyper-parameter for Retrieval-Augmented
Generation (RAG) systems called Context Window Utilization. RAG systems enhance
generative models by incorporating relevant information retrieved from external
knowledge bases, improving the factual accuracy and contextual relevance of
generated responses. The size of the text chunks retrieved and processed is a
critical factor influencing RAG performance. This study aims to identify the
optimal chunk size that maximizes answer generation quality. Through systematic
experimentation, we analyze the effects of varying chunk sizes on the
efficiency and effectiveness of RAG frameworks. Our findings reveal that an
optimal chunk size balances the trade-off between providing sufficient context
and minimizing irrelevant information. These insights are crucial for enhancing
the design and implementation of RAG systems, underscoring the importance of
selecting an appropriate chunk size to achieve superior performance.",2024-07-29,"Kush Juvekar, Anupam Purwar",http://arxiv.org/pdf/2407.19794v2,cs.CL
Synthesizing Scientific Summaries: An Extractive and Abstractive Approach,"The availability of a vast array of research papers in any area of study,
necessitates the need of automated summarisation systems that can present the
key research conducted and their corresponding findings. Scientific paper
summarisation is a challenging task for various reasons including token length
limits in modern transformer models and corresponding memory and compute
requirements for long text. A significant amount of work has been conducted in
this area, with approaches that modify the attention mechanisms of existing
transformer models and others that utilise discourse information to capture
long range dependencies in research papers. In this paper, we propose a hybrid
methodology for research paper summarisation which incorporates an extractive
and abstractive approach. We use the extractive approach to capture the key
findings of research, and pair it with the introduction of the paper which
captures the motivation for research. We use two models based on unsupervised
learning for the extraction stage and two transformer language models,
resulting in four combinations for our hybrid approach. The performances of the
models are evaluated on three metrics and we present our findings in this
paper. We find that using certain combinations of hyper parameters, it is
possible for automated summarisation systems to exceed the abstractiveness of
summaries written by humans. Finally, we state our future scope of research in
extending this methodology to summarisation of generalised long documents.",2024-07-29,"Grishma Sharma, Aditi Paretkar, Deepak Sharma",http://arxiv.org/pdf/2407.19779v1,cs.CL
Model Agnostic Hybrid Sharding For Heterogeneous Distributed Inference,"The rapid growth of large-scale AI models, particularly large language models
has brought significant challenges in data privacy, computational resources,
and accessibility. Traditional centralized architectures often struggle to meet
required data security and scalability needs which hinders the democratization
of AI systems. Nesa introduces a model-agnostic sharding framework designed for
decentralized AI inference. Our framework uses blockchain-based sequential deep
neural network sharding to distribute computational tasks across a diverse
network of nodes based on a personalised heuristic and routing mechanism. This
enables efficient distributed training and inference for recent large-scale
models even on consumer-grade hardware. We use compression techniques like
dynamic blockwise quantization and mixed matrix decomposition to reduce data
transfer and memory needs. We also integrate robust security measures,
including hardware-based trusted execution environments to ensure data
integrity and confidentiality. Evaluating our system across various natural
language processing and vision tasks shows that these compression strategies do
not compromise model accuracy. Our results highlight the potential to
democratize access to cutting-edge AI technologies by enabling secure and
efficient inference on a decentralized network.",2024-07-29,"Claudio Angione, Yue Zhao, Harry Yang, Ahmad Farhan, Fielding Johnston, James Buban, Patrick Colangelo",http://arxiv.org/pdf/2407.19775v1,cs.CL
"Legal Minds, Algorithmic Decisions: How LLMs Apply Constitutional Principles in Complex Scenarios","In this paper, we conduct an empirical analysis of how large language models
(LLMs), specifically GPT-4, interpret constitutional principles in complex
decision-making scenarios. We examine rulings from the Italian Constitutional
Court on bioethics issues that involve trade-offs between competing values and
compare model-generated legal arguments on these issues to those presented by
the State, the Court, and the applicants. Our results indicate that GPT-4
consistently aligns more closely with progressive interpretations of the
Constitution, often overlooking competing values and mirroring the applicants'
views rather than the more conservative perspectives of the State or the
Court's moderate positions. Our experiments reveal a distinct tendency of GPT-4
to favor progressive legal interpretations, underscoring the influence of
underlying data biases. We thus underscore the importance of testing alignment
in real-world scenarios and considering the implications of deploying LLMs in
decision-making processes.",2024-07-29,"Camilla Bignotti, Carolina Camassa",http://arxiv.org/pdf/2407.19760v2,cs.CL
KNOWCOMP POKEMON Team at DialAM-2024: A Two-Stage Pipeline for Detecting Relations in Dialogical Argument Mining,"Dialogical Argument Mining(DialAM) is an important branch of Argument
Mining(AM). DialAM-2024 is a shared task focusing on dialogical argument
mining, which requires us to identify argumentative relations and illocutionary
relations among proposition nodes and locution nodes. To accomplish this, we
propose a two-stage pipeline, which includes the Two-Step S-Node Prediction
Model in Stage 1 and the YA-Node Prediction Model in Stage 2. We also augment
the training data in both stages and introduce context in Stage 2. We
successfully completed the task and achieved good results. Our team Pokemon
ranked 1st in the ARI Focused score and 4th in the Global Focused score.",2024-07-29,"Zihao Zheng, Zhaowei Wang, Qing Zong, Yangqiu Song",http://arxiv.org/pdf/2407.19740v1,cs.CL
Do Text-to-Vis Benchmarks Test Real Use of Visualisations?,"Large language models are able to generate code for visualisations in
response to simple user requests. This is a useful application and an appealing
one for NLP research because plots of data provide grounding for language.
However, there are relatively few benchmarks, and those that exist may not be
representative of what users do in practice. This paper investigates whether
benchmarks reflect real-world use through an empirical study comparing
benchmark datasets with code from public repositories. Our findings reveal a
substantial gap, with evaluations not testing the same distribution of chart
types, attributes, and actions as real-world examples. One dataset is
representative, but requires extensive modification to become a practical
end-to-end benchmark. This shows that new benchmarks are needed to support the
development of systems that truly address users' visualisation needs. These
observations will guide future data creation, highlighting which features hold
genuine significance for users.",2024-07-29,"Hy Nguyen, Xuefei He, Andrew Reeson, Cecile Paris, Josiah Poon, Jonathan K. Kummerfeld",http://arxiv.org/pdf/2407.19726v4,cs.CL
CollectiveSFT: Scaling Large Language Models for Chinese Medical Benchmark with Collective Instructions in Healthcare,"The rapid progress in Large Language Models (LLMs) has prompted the creation
of numerous benchmarks to evaluate their capabilities.This study focuses on the
Comprehensive Medical Benchmark in Chinese (CMB), showcasing how dataset
diversity and distribution in supervised fine-tuning (SFT) may enhance LLM
performance.Remarkably, We successfully trained a smaller base model to achieve
scores comparable to larger models, indicating that a diverse and
well-distributed dataset can optimize performance regardless of model size.This
study suggests that even smaller models may reach high performance levels with
carefully curated and varied datasets. By integrating a wide range of
instructional content, our approach addresses potential issues such as data
quality inconsistencies. Our results imply that a broader spectrum of training
data may enhance a model's ability to generalize and perform effectively across
different medical scenarios, highlighting the importance of dataset quality and
diversity in fine-tuning processes. We open-source the model for future
research at https://github.com/CAS-SIAT-XinHai/CollectiveSFT",2024-07-29,"Jingwei Zhu, Minghuan Tan, Min Yang, Ruixue Li, Hamid Alinejad-Rokny",http://arxiv.org/pdf/2407.19705v3,cs.CL
Efficiently and Effectively: A Two-stage Approach to Balance Plaintext and Encrypted Text for Traffic Classification,"Encrypted traffic classification is the task of identifying the application
or service associated with encrypted network traffic. One effective approach
for this task is to use deep learning methods to encode the raw traffic bytes
directly and automatically extract features for classification (byte-based
models). However, current byte-based models input raw traffic bytes, whether
plaintext or encrypted text, for automated feature extraction, neglecting the
distinct impacts of plaintext and encrypted text on downstream tasks.
Additionally, these models primarily focus on improving classification
accuracy, with little emphasis on the efficiency of models. In this paper, for
the first time, we analyze the impact of plaintext and encrypted text on the
model's effectiveness and efficiency. Based on our observations and findings,
we propose a two-phase approach to balance the trade-off between plaintext and
encrypted text in traffic classification. Specifically, Stage one is to
Determine whether the Plain text is enough to be accurately Classified (DPC)
using the proposed DPC Selector. This stage quickly identifies samples that can
be classified using plaintext, leveraging explicit byte features in plaintext
to enhance model's efficiency. Stage two aims to adaptively make a
classification with the result from stage one. This stage incorporates
encrypted text information for samples that cannot be classified using
plaintext alone, ensuring the model's effectiveness on traffic classification
tasks. Experiments on two datasets demonstrate that our proposed model achieves
state-of-the-art results in both effectiveness and efficiency.",2024-07-29,"Wei Peng, Lei Cui, Wei Cai, Zhenquan Ding, Zhiyu Hao, Xiaochun Yun",http://arxiv.org/pdf/2407.19687v3,cs.CL
Beyond Metrics: A Critical Analysis of the Variability in Large Language Model Evaluation Frameworks,"As large language models (LLMs) continue to evolve, the need for robust and
standardized evaluation benchmarks becomes paramount. Evaluating the
performance of these models is a complex challenge that requires careful
consideration of various linguistic tasks, model architectures, and
benchmarking methodologies. In recent years, various frameworks have emerged as
noteworthy contributions to the field, offering comprehensive evaluation tests
and benchmarks for assessing the capabilities of LLMs across diverse domains.
This paper provides an exploration and critical analysis of some of these
evaluation methodologies, shedding light on their strengths, limitations, and
impact on advancing the state-of-the-art in natural language processing.",2024-07-29,"Marco AF Pimentel, Clément Christophe, Tathagata Raha, Prateek Munjal, Praveen K Kanithi, Shadab Khan",http://arxiv.org/pdf/2407.21072v1,cs.CL
SeaLLMs 3: Open Foundation and Chat Multilingual Large Language Models for Southeast Asian Languages,"Large Language Models (LLMs) have shown remarkable abilities across various
tasks, yet their development has predominantly centered on high-resource
languages like English and Chinese, leaving low-resource languages underserved.
To address this disparity, we present SeaLLMs 3, the latest iteration of the
SeaLLMs model family, tailored for Southeast Asian languages. This region,
characterized by its rich linguistic diversity, has lacked adequate language
technology support. SeaLLMs 3 aims to bridge this gap by covering a
comprehensive range of languages spoken in this region, including English,
Chinese, Indonesian, Vietnamese, Thai, Tagalog, Malay, Burmese, Khmer, Lao,
Tamil, and Javanese. Leveraging efficient language enhancement techniques and a
specially constructed instruction tuning dataset, SeaLLMs 3 significantly
reduces training costs while maintaining high performance and versatility. Our
model excels in tasks such as world knowledge, mathematical reasoning,
translation, and instruction following, achieving state-of-the-art performance
among similarly sized models. Additionally, we prioritized safety and
reliability by addressing both general and culture-specific considerations and
incorporated mechanisms to reduce hallucinations. This work underscores the
importance of inclusive AI, showing that advanced LLM capabilities can benefit
underserved linguistic and cultural communities.",2024-07-29,"Wenxuan Zhang, Hou Pong Chan, Yiran Zhao, Mahani Aljunied, Jianyu Wang, Chaoqun Liu, Yue Deng, Zhiqiang Hu, Weiwen Xu, Yew Ken Chia, Xin Li, Lidong Bing",http://arxiv.org/pdf/2407.19672v1,cs.CL
Overview of PerpectiveArg2024: The First Shared Task on Perspective Argument Retrieval,"Argument retrieval is the task of finding relevant arguments for a given
query. While existing approaches rely solely on the semantic alignment of
queries and arguments, this first shared task on perspective argument retrieval
incorporates perspectives during retrieval, accounting for latent influences in
argumentation. We present a novel multilingual dataset covering demographic and
socio-cultural (socio) variables, such as age, gender, and political attitude,
representing minority and majority groups in society. We distinguish between
three scenarios to explore how retrieval systems consider explicitly (in both
query and corpus) and implicitly (only in query) formulated perspectives. This
paper provides an overview of this shared task and summarizes the results of
the six submitted systems. We find substantial challenges in incorporating
perspectivism, especially when aiming for personalization based solely on the
text of arguments without explicitly providing socio profiles. Moreover,
retrieval systems tend to be biased towards the majority group but partially
mitigate bias for the female gender. While we bootstrap perspective argument
retrieval, further research is essential to optimize retrieval systems to
facilitate personalization and reduce polarization.",2024-07-29,"Neele Falk, Andreas Waldis, Iryna Gurevych",http://arxiv.org/pdf/2407.19670v1,cs.CL
mGTE: Generalized Long-Context Text Representation and Reranking Models for Multilingual Text Retrieval,"We present systematic efforts in building long-context multilingual text
representation model (TRM) and reranker from scratch for text retrieval. We
first introduce a text encoder (base size) enhanced with RoPE and unpadding,
pre-trained in a native 8192-token context (longer than 512 of previous
multilingual encoders). Then we construct a hybrid TRM and a cross-encoder
reranker by contrastive learning. Evaluations show that our text encoder
outperforms the same-sized previous state-of-the-art XLM-R. Meanwhile, our TRM
and reranker match the performance of large-sized state-of-the-art BGE-M3
models and achieve better results on long-context retrieval benchmarks. Further
analysis demonstrate that our proposed models exhibit higher efficiency during
both training and inference. We believe their efficiency and effectiveness
could benefit various researches and industrial applications.",2024-07-29,"Xin Zhang, Yanzhao Zhang, Dingkun Long, Wen Xie, Ziqi Dai, Jialong Tang, Huan Lin, Baosong Yang, Pengjun Xie, Fei Huang, Meishan Zhang, Wenjie Li, Min Zhang",http://arxiv.org/pdf/2407.19669v2,cs.CL
From Pre-training Corpora to Large Language Models: What Factors Influence LLM Performance in Causal Discovery Tasks?,"Recent advances in artificial intelligence have seen Large Language Models
(LLMs) demonstrate notable proficiency in causal discovery tasks. This study
explores the factors influencing the performance of LLMs in causal discovery
tasks. Utilizing open-source LLMs, we examine how the frequency of causal
relations within their pre-training corpora affects their ability to accurately
respond to causal discovery queries. Our findings reveal that a higher
frequency of causal mentions correlates with better model performance,
suggesting that extensive exposure to causal information during training
enhances the models' causal discovery capabilities. Additionally, we
investigate the impact of context on the validity of causal relations. Our
results indicate that LLMs might exhibit divergent predictions for identical
causal relations when presented in different contexts. This paper provides the
first comprehensive analysis of how different factors contribute to LLM
performance in causal discovery tasks.",2024-07-29,"Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari",http://arxiv.org/pdf/2407.19638v1,cs.CL
LoginMEA: Local-to-Global Interaction Network for Multi-modal Entity Alignment,"Multi-modal entity alignment (MMEA) aims to identify equivalent entities
between two multi-modal knowledge graphs (MMKGs), whose entities can be
associated with relational triples and related images. Most previous studies
treat the graph structure as a special modality, and fuse different modality
information with separate uni-modal encoders, neglecting valuable relational
associations in modalities. Other studies refine each uni-modal information
with graph structures, but may introduce unnecessary relations in specific
modalities. To this end, we propose a novel local-to-global interaction network
for MMEA, termed as LoginMEA. Particularly, we first fuse local multi-modal
interactions to generate holistic entity semantics and then refine them with
global relational interactions of entity neighbors. In this design, the
uni-modal information is fused adaptively, and can be refined with relations
accordingly. To enrich local interactions of multi-modal entity information, we
device modality weights and low-rank interactive fusion, allowing diverse
impacts and element-level interactions among modalities. To capture global
interactions of graph structures, we adopt relation reflection graph attention
networks, which fully capture relational associations between entities.
Extensive experiments demonstrate superior results of our method over 5
cross-KG or bilingual benchmark datasets, indicating the effectiveness of
capturing local and global interactions.",2024-07-29,"Taoyu Su, Xinghua Zhang, Jiawei Sheng, Zhenyu Zhang, Tingwen Liu",http://arxiv.org/pdf/2407.19625v1,cs.CL
TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs,"Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.",2024-07-29,"Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov",http://arxiv.org/pdf/2407.19616v1,cs.CL
You shall know a piece by the company it keeps. Chess plays as a data for word2vec models,"In this paper, I apply linguistic methods of analysis to non-linguistic data,
chess plays, metaphorically equating one with the other and seeking analogies.
Chess game notations are also a kind of text, and one can consider the records
of moves or positions of pieces as words and statements in a certain language.
In this article I show how word embeddings (word2vec) can work on chess game
texts instead of natural language texts. I don't see how this representation of
chess data can be used productively. It's unlikely that these vector models
will help engines or people choose the best move. But in a purely academic
sense, it's clear that such methods of information representation capture
something important about the very nature of the game, which doesn't
necessarily lead to a win.",2024-07-28,Boris Orekhov,http://arxiv.org/pdf/2407.19600v1,cs.CL
Meta-Rewarding Language Models: Self-Improving Alignment with LLM-as-a-Meta-Judge,"Large Language Models (LLMs) are rapidly surpassing human knowledge in many
domains. While improving these models traditionally relies on costly human
data, recent self-rewarding mechanisms (Yuan et al., 2024) have shown that LLMs
can improve by judging their own responses instead of relying on human
labelers. However, existing methods have primarily focused on improving model
responses rather than judgment capabilities, resulting in rapid saturation
during iterative training. To address this issue, we introduce a novel
Meta-Rewarding step to the self-improvement process, where the model judges its
own judgements and uses that feedback to refine its judgment skills.
Surprisingly, this unsupervised approach improves the model's ability to judge
{\em and} follow instructions, as demonstrated by a win rate improvement of
Llama-3-8B-Instruct from 22.9% to 39.4% on AlpacaEval 2, and 20.6% to 29.1% on
Arena-Hard. These results strongly suggest the potential for self-improving
models without human supervision.",2024-07-28,"Tianhao Wu, Weizhe Yuan, Olga Golovneva, Jing Xu, Yuandong Tian, Jiantao Jiao, Jason Weston, Sainbayar Sukhbaatar",http://arxiv.org/pdf/2407.19594v2,cs.CL
SaulLM-54B & SaulLM-141B: Scaling Up Domain Adaptation for the Legal Domain,"In this paper, we introduce SaulLM-54B and SaulLM-141B, two large language
models (LLMs) tailored for the legal sector. These models, which feature
architectures of 54 billion and 141 billion parameters, respectively, are based
on the Mixtral architecture. The development of SaulLM-54B and SaulLM-141B is
guided by large-scale domain adaptation, divided into three strategies: (1) the
exploitation of continued pretraining involving a base corpus that includes
over 540 billion of legal tokens, (2) the implementation of a specialized legal
instruction-following protocol, and (3) the alignment of model outputs with
human preferences in legal interpretations. The integration of synthetically
generated data in the second and third steps enhances the models' capabilities
in interpreting and processing legal texts, effectively reaching
state-of-the-art performance and outperforming previous open-source models on
LegalBench-Instruct. This work explores the trade-offs involved in
domain-specific adaptation at this scale, offering insights that may inform
future studies on domain adaptation using strong decoder models. Building upon
SaulLM-7B, this study refines the approach to produce an LLM better equipped
for legal tasks. We are releasing base, instruct, and aligned versions on top
of SaulLM-54B and SaulLM-141B under the MIT License to facilitate reuse and
collaborative research.",2024-07-28,"Pierre Colombo, Telmo Pires, Malik Boudiaf, Rui Melo, Dominic Culver, Sofia Morgado, Etienne Malaboeuf, Gabriel Hautreux, Johanne Charpentier, Michael Desa",http://arxiv.org/pdf/2407.19584v1,cs.CL
Mini-batch Coresets for Memory-efficient Language Model Training on Data Mixtures,"Training with larger mini-batches improves the convergence rate and can yield
superior performance. However, training with large mini-batches becomes
prohibitive for Large Language Models (LLMs), due to the large GPU memory
requirement. To address this problem, an effective approach is finding small
mini-batch coresets that closely match the gradient of larger mini-batches.
However, this approach becomes infeasible and ineffective for LLMs, due to the
highly imbalanced mixture of sources in language data, use of the Adam
optimizer, and the very large gradient dimensionality of LLMs. In this work, we
address the above challenges by proposing Coresets for Training LLMs (CoLM).
First, we show that mini-batch coresets found by gradient matching do not
contain representative examples of the small sources w.h.p., and thus including
all examples of the small sources in the mini-batch coresets is crucial for
optimal performance. Second, we normalize the gradients by their historical
exponential to find mini-batch coresets for training with Adam. Finally, we
leverage zeroth-order methods to find smooth gradient of the last V-projection
matrix and sparsify it to keep the dimensions with the largest normalized
gradient magnitude. We apply CoLM to fine-tuning Phi-2, Phi-3, Zephyr, and
Llama-3 models with LoRA on MathInstruct and SuperGLUE benchmark. Remarkably,
CoLM reduces the memory requirement of fine-tuning by 2x and even outperforms
training with 4x larger mini-batches. Moreover, CoLM seamlessly integrates with
existing memory-efficient training methods like LoRA, further reducing the
memory requirements of training LLMs.",2024-07-28,"Dang Nguyen, Wenhan Yang, Rathul Anand, Yu Yang, Baharan Mirzasoleiman",http://arxiv.org/pdf/2407.19580v3,cs.CL
Are LLMs Good Annotators for Discourse-level Event Relation Extraction?,"Large Language Models (LLMs) have demonstrated proficiency in a wide array of
natural language processing tasks. However, its effectiveness over
discourse-level event relation extraction (ERE) tasks remains unexplored. In
this paper, we assess the effectiveness of LLMs in addressing discourse-level
ERE tasks characterized by lengthy documents and intricate relations
encompassing coreference, temporal, causal, and subevent types. Evaluation is
conducted using an commercial model, GPT-3.5, and an open-source model,
LLaMA-2. Our study reveals a notable underperformance of LLMs compared to the
baseline established through supervised learning. Although Supervised
Fine-Tuning (SFT) can improve LLMs performance, it does not scale well compared
to the smaller supervised baseline model. Our quantitative and qualitative
analysis shows that LLMs have several weaknesses when applied for extracting
event relations, including a tendency to fabricate event mentions, and failures
to capture transitivity rules among relations, detect long distance relations,
or comprehend contexts with dense event mentions. Code available at:
https://github.com/WeiKangda/LLM-ERE.git.",2024-07-28,"Kangda Wei, Aayush Gautam, Ruihong Huang",http://arxiv.org/pdf/2407.19568v3,cs.CL
Occam's Razor and Bender and Koller's Octopus,"We discuss the teaching of the discussion surrounding Bender and Koller's
prominent ACL 2020 paper, ""Climbing toward NLU: on meaning form, and
understanding in the age of data"" \cite{bender2020climbing}. We present what we
understand to be the main contentions of the paper, and then recommend that the
students engage with the natural counter-arguments to the claims in the paper.
We attach teaching materials that we use to facilitate teaching this topic to
undergraduate students.",2024-07-28,Michael Guerzhoy,http://arxiv.org/pdf/2407.21070v2,cs.CL
Motamot: A Dataset for Revealing the Supremacy of Large Language Models over Transformer Models in Bengali Political Sentiment Analysis,"Sentiment analysis is the process of identifying and categorizing people's
emotions or opinions regarding various topics. Analyzing political sentiment is
critical for understanding the complexities of public opinion processes,
especially during election seasons. It gives significant information on voter
preferences, attitudes, and current trends. In this study, we investigate
political sentiment analysis during Bangladeshi elections, specifically
examining how effectively Pre-trained Language Models (PLMs) and Large Language
Models (LLMs) capture complex sentiment characteristics. Our study centers on
the creation of the ""Motamot"" dataset, comprising 7,058 instances annotated
with positive and negative sentiments, sourced from diverse online newspaper
portals, forming a comprehensive resource for political sentiment analysis. We
meticulously evaluate the performance of various PLMs including BanglaBERT,
Bangla BERT Base, XLM-RoBERTa, mBERT, and sahajBERT, alongside LLMs such as
Gemini 1.5 Pro and GPT 3.5 Turbo. Moreover, we explore zero-shot and few-shot
learning strategies to enhance our understanding of political sentiment
analysis methodologies. Our findings underscore BanglaBERT's commendable
accuracy of 88.10% among PLMs. However, the exploration into LLMs reveals even
more promising results. Through the adept application of Few-Shot learning
techniques, Gemini 1.5 Pro achieves an impressive accuracy of 96.33%,
surpassing the remarkable performance of GPT 3.5 Turbo, which stands at 94%.
This underscores Gemini 1.5 Pro's status as the superior performer in this
comparison.",2024-07-28,"Fatema Tuj Johora Faria, Mukaffi Bin Moin, Rabeya Islam Mumu, Md Mahabubul Alam Abir, Abrar Nawar Alfy, Mohammad Shafiul Alam",http://arxiv.org/pdf/2407.19528v1,cs.CL
Open Sentence Embeddings for Portuguese with the Serafim PT* encoders family,"Sentence encoder encode the semantics of their input, enabling key downstream
applications such as classification, clustering, or retrieval. In this paper,
we present Serafim PT*, a family of open-source sentence encoders for
Portuguese with various sizes, suited to different hardware/compute budgets.
Each model exhibits state-of-the-art performance and is made openly available
under a permissive license, allowing its use for both commercial and research
purposes. Besides the sentence encoders, this paper contributes a systematic
study and lessons learned concerning the selection criteria of learning
objectives and parameters that support top-performing encoders.",2024-07-28,"Luís Gomes, António Branco, João Silva, João Rodrigues, Rodrigo Santos",http://arxiv.org/pdf/2407.19527v1,cs.CL
Impact of Decoding Methods on Human Alignment of Conversational LLMs,"To be included into chatbot systems, Large language models (LLMs) must be
aligned with human conversational conventions. However, being trained mainly on
web-scraped data gives existing LLMs a voice closer to informational text than
actual human speech. In this paper, we examine the effect of decoding methods
on the alignment between LLM-generated and human conversations, including Beam
Search, Top K Sampling, and Nucleus Sampling. We present new measures of
alignment in substance, style, and psychometric orientation, and experiment
with two conversation datasets. Our results provide subtle insights: better
alignment is attributed to fewer beams in Beam Search and lower values of P in
Nucleus Sampling. We also find that task-oriented and open-ended datasets
perform differently in terms of alignment, indicating the significance of
taking into account the context of the interaction.",2024-07-28,"Shaz Furniturewala, Kokil Jaidka, Yashvardhan Sharma",http://arxiv.org/pdf/2407.19526v1,cs.CL
Towards a Universal Method for Meaningful Signal Detection,"It is known that human speech and certain animal vocalizations can convey
meaningful content because we can decipher the content that a given utterance
does convey. This paper explores an alternative approach to determining whether
a signal is meaningful, one that analyzes only the signal itself and is
independent of what the conveyed meaning might be. We devise a method that
takes a waveform as input and outputs a score indicating its degree of
`meaningfulness`. We cluster contiguous portions of the input to minimize the
total description length, and then take the length of the code of the assigned
cluster labels as meaningfulness score. We evaluate our method empirically,
against several baselines, and show that it is the only one to give a high
score to human speech in various languages and with various speakers, a
moderate score to animal vocalizations from birds and orcas, and a low score to
ambient noise from various sources.",2024-07-28,Louis Mahon,http://arxiv.org/pdf/2408.00016v3,cs.CL
Exploring Genre and Success Classification through Song Lyrics using DistilBERT: A Fun NLP Venture,"This paper presents a natural language processing (NLP) approach to the
problem of thoroughly comprehending song lyrics, with particular attention on
genre classification, view-based success prediction, and approximate release
year. Our tests provide promising results with 65\% accuracy in genre
classification and 79\% accuracy in success prediction, leveraging a DistilBERT
model for genre classification and BERT embeddings for release year prediction.
Support Vector Machines outperformed other models in predicting the release
year, achieving the lowest root mean squared error (RMSE) of 14.18. Our study
offers insights that have the potential to revolutionize our relationship with
music by addressing the shortcomings of current approaches in properly
understanding the emotional intricacies of song lyrics.",2024-07-28,"Servando Pizarro Martinez, Moritz Zimmermann, Miguel Serkan Offermann, Florian Reither",http://arxiv.org/pdf/2407.21068v1,cs.CL
Visual Riddles: a Commonsense and World Knowledge Challenge for Large Vision and Language Models,"Imagine observing someone scratching their arm; to understand why, additional
context would be necessary. However, spotting a mosquito nearby would
immediately offer a likely explanation for the person's discomfort, thereby
alleviating the need for further information. This example illustrates how
subtle visual cues can challenge our cognitive skills and demonstrates the
complexity of interpreting visual scenarios. To study these skills, we present
Visual Riddles, a benchmark aimed to test vision and language models on visual
riddles requiring commonsense and world knowledge. The benchmark comprises 400
visual riddles, each featuring a unique image created by a variety of
text-to-image models, question, ground-truth answer, textual hint, and
attribution. Human evaluation reveals that existing models lag significantly
behind human performance, which is at 82% accuracy, with Gemini-Pro-1.5 leading
with 40% accuracy. Our benchmark comes with automatic evaluation tasks to make
assessment scalable. These findings underscore the potential of Visual Riddles
as a valuable resource for enhancing vision and language models' capabilities
in interpreting complex visual scenarios.",2024-07-28,"Nitzan Bitton-Guetta, Aviv Slobodkin, Aviya Maimon, Eliya Habba, Royi Rassin, Yonatan Bitton, Idan Szpektor, Amir Globerson, Yuval Elovici",http://arxiv.org/pdf/2407.19474v2,cs.CL
ASI-Seg: Audio-Driven Surgical Instrument Segmentation with Surgeon Intention Understanding,"Surgical instrument segmentation is crucial in surgical scene understanding,
thereby facilitating surgical safety. Existing algorithms directly detected all
instruments of pre-defined categories in the input image, lacking the
capability to segment specific instruments according to the surgeon's
intention. During different stages of surgery, surgeons exhibit varying
preferences and focus toward different surgical instruments. Therefore, an
instrument segmentation algorithm that adheres to the surgeon's intention can
minimize distractions from irrelevant instruments and assist surgeons to a
great extent. The recent Segment Anything Model (SAM) reveals the capability to
segment objects following prompts, but the manual annotations for prompts are
impractical during the surgery. To address these limitations in operating
rooms, we propose an audio-driven surgical instrument segmentation framework,
named ASI-Seg, to accurately segment the required surgical instruments by
parsing the audio commands of surgeons. Specifically, we propose an
intention-oriented multimodal fusion to interpret the segmentation intention
from audio commands and retrieve relevant instrument details to facilitate
segmentation. Moreover, to guide our ASI-Seg segment of the required surgical
instruments, we devise a contrastive learning prompt encoder to effectively
distinguish the required instruments from the irrelevant ones. Therefore, our
ASI-Seg promotes the workflow in the operating rooms, thereby providing
targeted support and reducing the cognitive load on surgeons. Extensive
experiments are performed to validate the ASI-Seg framework, which reveals
remarkable advantages over classical state-of-the-art and medical SAMs in both
semantic segmentation and intention-oriented segmentation. The source code is
available at https://github.com/Zonmgin-Zhang/ASI-Seg.",2024-07-28,"Zhen Chen, Zongming Zhang, Wenwu Guo, Xingjian Luo, Long Bai, Jinlin Wu, Hongliang Ren, Hongbin Liu",http://arxiv.org/pdf/2407.19435v1,cs.CL
LLAVADI: What Matters For Multimodal Large Language Models Distillation,"The recent surge in Multimodal Large Language Models (MLLMs) has showcased
their remarkable potential for achieving generalized intelligence by
integrating visual understanding into Large Language Models.Nevertheless, the
sheer model size of MLLMs leads to substantial memory and computational demands
that hinder their widespread deployment. In this work, we do not propose a new
efficient model structure or train small-scale MLLMs from scratch. Instead, we
focus on what matters for training small-scale MLLMs through knowledge
distillation, which is the first step from the multimodal distillation
perspective. Our extensive studies involve training strategies, model choices,
and distillation algorithms in the knowledge distillation process. These
results show that joint alignment for both tokens and logit alignment plays
critical roles in teacher-student frameworks. In addition, we draw a series of
intriguing observations from this study. By evaluating different benchmarks and
proper strategy, even a 2.7B small-scale model can perform on par with larger
models with 7B or 13B parameters. Our code and models will be publicly
available for further research.",2024-07-28,"Shilin Xu, Xiangtai Li, Haobo Yuan, Lu Qi, Yunhai Tong, Ming-Hsuan Yang",http://arxiv.org/pdf/2407.19409v1,cs.CL
ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech Processing Tasks,"Self-supervised learning has emerged as a key approach for learning generic
representations from speech data. Despite promising results in downstream tasks
such as speech recognition, speaker verification, and emotion recognition, a
significant number of parameters is required, which makes fine-tuning for each
task memory-inefficient. To address this limitation, we introduce ELP-adapter
tuning, a novel method for parameter-efficient fine-tuning using three types of
adapter, namely encoder adapters (E-adapters), layer adapters (L-adapters), and
a prompt adapter (P-adapter). The E-adapters are integrated into
transformer-based encoder layers and help to learn fine-grained speech
representations that are effective for speech recognition. The L-adapters
create paths from each encoder layer to the downstream head and help to extract
non-linguistic features from lower encoder layers that are effective for
speaker verification and emotion recognition. The P-adapter appends pseudo
features to CNN features to further improve effectiveness and efficiency. With
these adapters, models can be quickly adapted to various speech processing
tasks. Our evaluation across four downstream tasks using five backbone models
demonstrated the effectiveness of the proposed method. With the WavLM backbone,
its performance was comparable to or better than that of full fine-tuning on
all tasks while requiring 90% fewer learnable parameters.",2024-07-28,"Nakamasa Inoue, Shinta Otake, Takumi Hirose, Masanari Ohi, Rei Kawakami",http://arxiv.org/pdf/2407.21066v1,cs.CL
"Word Segmentation for Asian Languages: Chinese, Korean, and Japanese","We provide a detailed overview of various approaches to word segmentation of
Asian Languages, specifically Chinese, Korean, and Japanese languages. For each
language, approaches to deal with word segmentation differs. We also include
our analysis about certain advantages and disadvantages to each method. In
addition, there is room for future work in this field.",2024-07-28,"Matthew Rho, Yexin Tian, Qin Chen",http://arxiv.org/pdf/2407.19400v1,cs.CL
Polynomial Regression as a Task for Understanding In-context Learning Through Finetuning and Alignment,"Simple function classes have emerged as toy problems to better understand
in-context-learning in transformer-based architectures used for large language
models. But previously proposed simple function classes like linear regression
or multi-layer-perceptrons lack the structure required to explore things like
prompting and alignment within models capable of in-context-learning. We
propose univariate polynomial regression as a function class that is just rich
enough to study prompting and alignment, while allowing us to visualize and
understand what is going on clearly.",2024-07-27,"Max Wilcoxson, Morten Svendgård, Ria Doshi, Dylan Davis, Reya Vir, Anant Sahai",http://arxiv.org/pdf/2407.19346v1,cs.CL
Inference-Time Selective Debiasing to Enhance Fairness in Text Classification Models,"We propose selective debiasing -- an inference-time safety mechanism designed
to enhance the overall model quality in terms of prediction performance and
fairness, especially in scenarios where retraining the model is impractical.
The method draws inspiration from selective classification, where at inference
time, predictions with low quality, as indicated by their uncertainty scores,
are discarded. In our approach, we identify the potentially biased model
predictions and, instead of discarding them, we remove bias from these
predictions using LEACE -- a post-processing debiasing method. To select
problematic predictions, we propose a bias quantification approach based on KL
divergence, which achieves better results than standard uncertainty
quantification methods. Experiments on text classification datasets with
encoder-based classification models demonstrate that selective debiasing helps
to reduce the performance gap between post-processing methods and debiasing
techniques from the at-training and pre-processing categories.",2024-07-27,"Gleb Kuzmin, Neemesh Yadav, Ivan Smirnov, Timothy Baldwin, Artem Shelmanov",http://arxiv.org/pdf/2407.19345v4,cs.CL
LawLLM: Law Large Language Model for the US Legal System,"In the rapidly evolving field of legal analytics, finding relevant cases and
accurately predicting judicial outcomes are challenging because of the
complexity of legal language, which often includes specialized terminology,
complex syntax, and historical context. Moreover, the subtle distinctions
between similar and precedent cases require a deep understanding of legal
knowledge. Researchers often conflate these concepts, making it difficult to
develop specialized techniques to effectively address these nuanced tasks. In
this paper, we introduce the Law Large Language Model (LawLLM), a multi-task
model specifically designed for the US legal domain to address these
challenges. LawLLM excels at Similar Case Retrieval (SCR), Precedent Case
Recommendation (PCR), and Legal Judgment Prediction (LJP). By clearly
distinguishing between precedent and similar cases, we provide essential
clarity, guiding future research in developing specialized strategies for these
tasks. We propose customized data preprocessing techniques for each task that
transform raw legal data into a trainable format. Furthermore, we also use
techniques such as in-context learning (ICL) and advanced information retrieval
methods in LawLLM. The evaluation results demonstrate that LawLLM consistently
outperforms existing baselines in both zero-shot and few-shot scenarios,
offering unparalleled multi-task capabilities and filling critical gaps in the
legal domain.",2024-07-27,"Dong Shu, Haoran Zhao, Xukun Liu, David Demeter, Mengnan Du, Yongfeng Zhang",http://arxiv.org/pdf/2407.21065v1,cs.CL
Parameter-Efficient Fine-Tuning via Circular Convolution,"Low-Rank Adaptation (LoRA) has gained popularity for fine-tuning large
foundation models, leveraging low-rank matrices $\mathbf{A}$ and $\mathbf{B}$
to represent weight changes (i.e., $\Delta \mathbf{W} = \mathbf{B}
\mathbf{A}$). This method reduces trainable parameters and mitigates heavy
memory consumption associated with full delta matrices by sequentially
multiplying $\mathbf{A}$ and $\mathbf{B}$ with the activation. Despite its
success, the intrinsic low-rank characteristic may limit its performance.
Although several variants have been proposed to address this issue, they often
overlook the crucial computational and memory efficiency brought by LoRA. In
this paper, we propose Circular Convolution Adaptation (C$^3$A), which not only
achieves high-rank adaptation with enhanced performance but also excels in both
computational power and memory utilization. Extensive experiments demonstrate
that C$^3$A consistently outperforms LoRA and its variants across various
fine-tuning tasks.",2024-07-27,"Aochuan Chen, Jiashun Cheng, Zijing Liu, Ziqi Gao, Fugee Tsung, Yu Li, Jia Li",http://arxiv.org/pdf/2407.19342v3,cs.CL
Investigating Critical Period Effects in Language Acquisition through Neural Language Models,"Humans appear to have a critical period (CP) for language acquisition: Second
language (L2) acquisition becomes harder after early childhood, and ceasing
exposure to a first language (L1) after this period (but not before) typically
does not lead to substantial loss of L1 proficiency. It is unknown whether
these CP effects result from innately determined brain maturation or as a
stabilization of neural connections naturally induced by experience. In this
study, we use language models (LMs) to test the extent to which these phenomena
are peculiar to humans, or shared by a broader class of language learners. We
vary the age of exposure by training LMs on language pairs in various
experimental conditions, and find that LMs, which lack any direct analog to
innate maturational stages, do not show CP effects when the age of exposure of
L2 is delayed. Our results contradict the claim that CP effects are an
inevitable result of statistical learning, and they are consistent with an
innate mechanism for CP effects. We show that we can reverse-engineer the CP by
introducing a regularizer partway through training to simulate a maturational
decrease in plasticity. All in all, our results suggest that L1 learning on its
own may not be enough to induce a CP, and additional engineering is necessary
to make language models more cognitively plausible.",2024-07-27,"Ionut Constantinescu, Tiago Pimentel, Ryan Cotterell, Alex Warstadt",http://arxiv.org/pdf/2407.19325v2,cs.CL
IBMEA: Exploring Variational Information Bottleneck for Multi-modal Entity Alignment,"Multi-modal entity alignment (MMEA) aims to identify equivalent entities
between multi-modal knowledge graphs (MMKGs), where the entities can be
associated with related images. Most existing studies integrate multi-modal
information heavily relying on the automatically-learned fusion module, rarely
suppressing the redundant information for MMEA explicitly. To this end, we
explore variational information bottleneck for multi-modal entity alignment
(IBMEA), which emphasizes the alignment-relevant information and suppresses the
alignment-irrelevant information in generating entity representations.
Specifically, we devise multi-modal variational encoders to generate
modal-specific entity representations as probability distributions. Then, we
propose four modal-specific information bottleneck regularizers, limiting the
misleading clues in refining modal-specific entity representations. Finally, we
propose a modal-hybrid information contrastive regularizer to integrate all the
refined modal-specific representations, enhancing the entity similarity between
MMKGs to achieve MMEA. We conduct extensive experiments on two cross-KG and
three bilingual MMEA datasets. Experimental results demonstrate that our model
consistently outperforms previous state-of-the-art methods, and also shows
promising and robust performance in low-resource and high-noise data scenarios.",2024-07-27,"Taoyu Su, Jiawei Sheng, Shicheng Wang, Xinghua Zhang, Hongbo Xu, Tingwen Liu",http://arxiv.org/pdf/2407.19302v1,cs.CL
The Impact of LoRA Adapters for LLMs on Clinical NLP Classification Under Data Limitations,"Fine-tuning Large Language Models (LLMs) for clinical Natural Language
Processing (NLP) poses significant challenges due to the domain gap and limited
data availability. This study investigates the effectiveness of various adapter
techniques, equivalent to Low-Rank Adaptation (LoRA), for fine-tuning LLMs in a
resource-constrained hospital environment. We experimented with four
structures-Adapter, Lightweight, TinyAttention, and Gated Residual Network
(GRN)-as final layers for clinical notes classification. We fine-tuned
biomedical pre-trained models, including CamemBERT-bio, AliBERT, and DrBERT,
alongside two Transformer-based models. Our extensive experimental results
indicate that i) employing adapter structures does not yield significant
improvements in fine-tuning biomedical pre-trained LLMs, and ii) simpler
Transformer-based models, trained from scratch, perform better under resource
constraints. Among the adapter structures, GRN demonstrated superior
performance with accuracy, precision, recall, and an F1 score of 0.88.
Moreover, the total training time for LLMs exceeded 1000 hours, compared to
under 6 hours for simpler transformer-based models, highlighting that LLMs are
more suitable for environments with extensive computational resources and
larger datasets. Consequently, this study demonstrates that simpler
Transformer-based models can be effectively trained from scratch, providing a
viable solution for clinical NLP tasks in low-resource environments with
limited data availability. By identifying the GRN as the most effective adapter
structure, we offer a practical approach to enhance clinical note
classification without requiring extensive computational resources.",2024-07-27,"Thanh-Dung Le, Ti Ti Nguyen, Vu Nguyen Ha, Symeon Chatzinotas, Philippe Jouvet, Rita Noumeir",http://arxiv.org/pdf/2407.19299v2,cs.CL
"Understanding Memorisation in LLMs: Dynamics, Influencing Factors, and Implications","Understanding whether and to what extent large language models (LLMs) have
memorised training data has important implications for the reliability of their
output and the privacy of their training data. In order to cleanly measure and
disentangle memorisation from other phenomena (e.g. in-context learning), we
create an experimental framework that is based on repeatedly exposing LLMs to
random strings. Our framework allows us to better understand the dynamics,
i.e., the behaviour of the model, when repeatedly exposing it to random
strings. Using our framework, we make several striking observations: (a) we
find consistent phases of the dynamics across families of models (Pythia, Phi
and Llama2), (b) we identify factors that make some strings easier to memorise
than others, and (c) we identify the role of local prefixes and global context
in memorisation. We also show that sequential exposition to different random
strings has a significant effect on memorisation. Our results, often
surprising, have significant downstream implications in the study and usage of
LLMs.",2024-07-27,"Till Speicher, Mohammad Aflah Khan, Qinyuan Wu, Vedant Nanda, Soumi Das, Bishwamittra Ghosh, Krishna P. Gummadi, Evimaria Terzi",http://arxiv.org/pdf/2407.19262v1,cs.CL
Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review,"With the rapid development of artificial intelligence (AI), large language
models (LLMs) have shown strong capabilities in natural language understanding,
reasoning, and generation, attracting amounts of research interest in applying
LLMs to health and medicine. Critical care medicine (CCM) provides diagnosis
and treatment for critically ill patients who often require intensive
monitoring and interventions in intensive care units (ICUs). Can LLMs be
applied to CCM? Are LLMs just like stochastic parrots or ICU experts in
assisting clinical decision-making? This scoping review aims to provide a
panoramic portrait of the application of LLMs in CCM. Literature in seven
databases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE
Xplore, and ACM Digital Library, were searched from January 1, 2019, to June
10, 2024. Peer-reviewed journal and conference articles that discussed the
application of LLMs in critical care settings were included. From an initial
619 articles, 24 were selected for final review. This review grouped
applications of LLMs in CCM into three categories: clinical decision support,
medical documentation and reporting, and medical education and doctor-patient
communication. LLMs have advantages in handling unstructured data and do not
require manual feature engineering. Meanwhile, applying LLMs to CCM faces
challenges, including hallucinations, poor interpretability, bias and alignment
challenges, and privacy and ethics issues. Future research should enhance model
reliability and interpretability, integrate up-to-date medical knowledge, and
strengthen privacy and ethical guidelines. As LLMs evolve, they could become
key tools in CCM to help improve patient outcomes and optimize healthcare
delivery. This study is the first review of LLMs in CCM, aiding researchers,
clinicians, and policymakers to understand the current status and future
potentials of LLMs in CCM.",2024-07-27,"Tongyue Shi, Jun Ma, Zihan Yu, Haowei Xu, Minqi Xiong, Meirong Xiao, Yilin Li, Huiying Zhao, Guilan Kong",http://arxiv.org/pdf/2407.19256v1,cs.CL
On Behalf of the Stakeholders: Trends in NLP Model Interpretability in the Era of LLMs,"Recent advancements in NLP systems, particularly with the introduction of
LLMs, have led to widespread adoption of these systems by a broad spectrum of
users across various domains, impacting decision-making, the job market,
society, and scientific research. This surge in usage has led to an explosion
in NLP model interpretability and analysis research, accompanied by numerous
technical surveys. Yet, these surveys often overlook the needs and perspectives
of explanation stakeholders. In this paper, we address three fundamental
questions: Why do we need interpretability, what are we interpreting, and how?
By exploring these questions, we examine existing interpretability paradigms,
their properties, and their relevance to different stakeholders. We further
explore the practical implications of these paradigms by analyzing trends from
the past decade across multiple research fields. To this end, we retrieved
thousands of papers and employed an LLM to characterize them. Our analysis
reveals significant disparities between NLP developers and non-developer users,
as well as between research fields, underscoring the diverse needs of
stakeholders. For example, explanations of internal model components are rarely
used outside the NLP field. We hope this paper informs the future design,
development, and application of methods that align with the objectives and
requirements of various stakeholders.",2024-07-27,"Nitay Calderon, Roi Reichart",http://arxiv.org/pdf/2407.19200v2,cs.CL
Towards the Dynamics of a DNN Learning Symbolic Interactions,"This study proves the two-phase dynamics of a deep neural network (DNN)
learning interactions. Despite the long disappointing view of the faithfulness
of post-hoc explanation of a DNN, a series of theorems have been proven in
recent years to show that for a given input sample, a small set of interactions
between input variables can be considered as primitive inference patterns that
faithfully represent a DNN's detailed inference logic on that sample.
Particularly, Zhang et al. have observed that various DNNs all learn
interactions of different complexities in two distinct phases, and this
two-phase dynamics well explains how a DNN changes from under-fitting to
over-fitting. Therefore, in this study, we mathematically prove the two-phase
dynamics of interactions, providing a theoretical mechanism for how the
generalization power of a DNN changes during the training process. Experiments
show that our theory well predicts the real dynamics of interactions on
different DNNs trained for various tasks.",2024-07-27,"Qihan Ren, Junpeng Zhang, Yang Xu, Yue Xin, Dongrui Liu, Quanshi Zhang",http://arxiv.org/pdf/2407.19198v2,cs.CL
Why Misinformation is Created? Detecting them by Integrating Intent Features,"Various social media platforms, e.g., Twitter and Reddit, allow people to
disseminate a plethora of information more efficiently and conveniently.
However, they are inevitably full of misinformation, causing damage to diverse
aspects of our daily lives. To reduce the negative impact, timely
identification of misinformation, namely Misinformation Detection (MD), has
become an active research topic receiving widespread attention. As a complex
phenomenon, the veracity of an article is influenced by various aspects. In
this paper, we are inspired by the opposition of intents between misinformation
and real information. Accordingly, we propose to reason the intent of articles
and form the corresponding intent features to promote the veracity
discrimination of article features. To achieve this, we build a hierarchy of a
set of intents for both misinformation and real information by referring to the
existing psychological theories, and we apply it to reason the intent of
articles by progressively generating binary answers with an encoder-decoder
structure. We form the corresponding intent features and integrate it with the
token features to achieve more discriminative article features for MD. Upon
these ideas, we suggest a novel MD method, namely Detecting Misinformation by
Integrating Intent featuRes (DM-INTER). To evaluate the performance of
DM-INTER, we conduct extensive experiments on benchmark MD datasets. The
experimental results validate that DM-INTER can outperform the existing
baseline MD methods.",2024-07-27,"Bing Wang, Ximing Li, Changchun Li, Bo Fu, Songwen Pei, Shengsheng Wang",http://arxiv.org/pdf/2407.19196v1,cs.CL
Harmfully Manipulated Images Matter in Multimodal Misinformation Detection,"Nowadays, misinformation is widely spreading over various social media
platforms and causes extremely negative impacts on society. To combat this
issue, automatically identifying misinformation, especially those containing
multimodal content, has attracted growing attention from the academic and
industrial communities, and induced an active research topic named Multimodal
Misinformation Detection (MMD). Typically, existing MMD methods capture the
semantic correlation and inconsistency between multiple modalities, but neglect
some potential clues in multimodal content. Recent studies suggest that
manipulated traces of the images in articles are non-trivial clues for
detecting misinformation. Meanwhile, we find that the underlying intentions
behind the manipulation, e.g., harmful and harmless, also matter in MMD.
Accordingly, in this work, we propose to detect misinformation by learning
manipulation features that indicate whether the image has been manipulated, as
well as intention features regarding the harmful and harmless intentions of the
manipulation. Unfortunately, the manipulation and intention labels that make
these features discriminative are unknown. To overcome the problem, we propose
two weakly supervised signals as alternatives by introducing additional
datasets on image manipulation detection and formulating two classification
tasks as positive and unlabeled learning problems. Based on these ideas, we
propose a novel MMD method, namely Harmfully Manipulated Images Matter in MMD
(HAMI-M3D). Extensive experiments across three benchmark datasets can
demonstrate that HAMI-M3D can consistently improve the performance of any MMD
baselines.",2024-07-27,"Bing Wang, Shengsheng Wang, Changchun Li, Renchu Guan, Ximing Li",http://arxiv.org/pdf/2407.19192v1,cs.CL
LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models,"The proliferation of large language models (LLMs) requires robust evaluation
of their alignment with local values and ethical standards, especially as
existing benchmarks often reflect the cultural, legal, and ideological values
of their creators. \textsc{LocalValueBench}, introduced in this paper, is an
extensible benchmark designed to assess LLMs' adherence to Australian values,
and provides a framework for regulators worldwide to develop their own LLM
benchmarks for local value alignment. Employing a novel typology for ethical
reasoning and an interrogation approach, we curated comprehensive questions and
utilized prompt engineering strategies to probe LLMs' value alignment. Our
evaluation criteria quantified deviations from local values, ensuring a
rigorous assessment process. Comparative analysis of three commercial LLMs by
USA vendors revealed significant insights into their effectiveness and
limitations, demonstrating the critical importance of value alignment. This
study offers valuable tools and methodologies for regulators to create tailored
benchmarks, highlighting avenues for future research to enhance ethical AI
development.",2024-07-27,"Gwenyth Isobel Meadows, Nicholas Wai Long Lau, Eva Adelina Susanto, Chi Lok Yu, Aditya Paul",http://arxiv.org/pdf/2408.01460v1,cs.CL
AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools,"Addressing school bullying effectively and promptly is crucial for the mental
health of students. This study examined the potential of large language models
(LLMs) to empower students by discerning between bullying and joking in school
peer interactions. We employed ChatGPT-4, Gemini 1.5 Pro, and Claude 3 Opus,
evaluating their effectiveness through human review. Our results revealed that
not all LLMs were suitable for an agentic approach, with ChatGPT-4 showing the
most promise. We observed variations in LLM outputs, possibly influenced by
political overcorrectness, context window limitations, and pre-existing bias in
their training data. ChatGPT-4 excelled in context-specific accuracy after
implementing the agentic approach, highlighting its potential to provide
continuous, real-time support to vulnerable students. This study underlines the
significant social impact of using agentic AI in educational settings, offering
a new avenue for reducing the negative consequences of bullying and enhancing
student well-being.",2024-07-27,"Aditya Paul, Chi Lok Yu, Eva Adelina Susanto, Nicholas Wai Long Lau, Gwenyth Isobel Meadows",http://arxiv.org/pdf/2408.01459v1,cs.CL
FarSSiBERT: A Novel Transformer-based Model for Semantic Similarity Measurement of Persian Social Networks Informal Texts,"One fundamental task for NLP is to determine the similarity between two texts
and evaluate the extent of their likeness. The previous methods for the Persian
language have low accuracy and are unable to comprehend the structure and
meaning of texts effectively. Additionally, these methods primarily focus on
formal texts, but in real-world applications of text processing, there is a
need for robust methods that can handle colloquial texts. This requires
algorithms that consider the structure and significance of words based on
context, rather than just the frequency of words. The lack of a proper dataset
for this task in the Persian language makes it important to develop such
algorithms and construct a dataset for Persian text. This paper introduces a
new transformer-based model to measure semantic similarity between Persian
informal short texts from social networks. In addition, a Persian dataset named
FarSSiM has been constructed for this purpose, using real data from social
networks and manually annotated and verified by a linguistic expert team. The
proposed model involves training a large language model using the BERT
architecture from scratch. This model, called FarSSiBERT, is pre-trained on
approximately 104 million Persian informal short texts from social networks,
making it one of a kind in the Persian language. Moreover, a novel specialized
informal language tokenizer is provided that not only performs tokenization on
formal texts well but also accurately identifies tokens that other Persian
tokenizers are unable to recognize. It has been demonstrated that our proposed
model outperforms ParsBERT, laBSE, and multilingual BERT in the Pearson and
Spearman's coefficient criteria. Additionally, the pre-trained large language
model has great potential for use in other NLP tasks on colloquial text and as
a tokenizer for less-known informal words.",2024-07-27,"Seyed Mojtaba Sadjadi, Zeinab Rajabi, Leila Rabiei, Mohammad-Shahram Moin",http://arxiv.org/pdf/2407.19173v1,cs.CL
Addressing Topic Leakage in Cross-Topic Evaluation for Authorship Verification,"Authorship verification (AV) aims to identify whether a pair of texts has the
same author. We address the challenge of evaluating AV models' robustness
against topic shifts. The conventional evaluation assumes minimal topic overlap
between training and test data. However, we argue that there can still be topic
leakage in test data, causing misleading model performance and unstable
rankings. To address this, we propose an evaluation method called
Heterogeneity-Informed Topic Sampling (HITS), which creates a smaller dataset
with a heterogeneously distributed topic set. Our experimental results
demonstrate that HITS-sampled datasets yield a more stable ranking of models
across random seeds and evaluation splits. Our contributions include: 1. An
analysis of causes and effects of topic leakage. 2. A demonstration of the HITS
in reducing the effects of topic leakage, and 3. The Robust Authorship
Verification bENchmark (RAVEN) that allows topic shortcut test to uncover AV
models' reliance on topic-specific features.",2024-07-27,"Jitkapat Sawatphol, Can Udomcharoenchaikit, Sarana Nutanong",http://arxiv.org/pdf/2407.19164v1,cs.CL
Many-Shot In-Context Learning for Molecular Inverse Design,"Large Language Models (LLMs) have demonstrated great performance in few-shot
In-Context Learning (ICL) for a variety of generative and discriminative
chemical design tasks. The newly expanded context windows of LLMs can further
improve ICL capabilities for molecular inverse design and lead optimization. To
take full advantage of these capabilities we developed a new semi-supervised
learning method that overcomes the lack of experimental data available for
many-shot ICL. Our approach involves iterative inclusion of LLM generated
molecules with high predicted performance, along with experimental data. We
further integrated our method in a multi-modal LLM which allows for the
interactive modification of generated molecular structures using text
instructions. As we show, the new method greatly improves upon existing ICL
methods for molecular design while being accessible and easy to use for
scientists.",2024-07-26,"Saeed Moayedpour, Alejandro Corrochano-Navarro, Faryad Sahneh, Shahriar Noroozizadeh, Alexander Koetter, Jiri Vymetal, Lorenzo Kogler-Anele, Pablo Mas, Yasser Jangjou, Sizhen Li, Michael Bailey, Marc Bianciotto, Hans Matter, Christoph Grebner, Gerhard Hessler, Ziv Bar-Joseph, Sven Jager",http://arxiv.org/pdf/2407.19089v1,cs.CL
OfficeBench: Benchmarking Language Agents across Multiple Applications for Office Automation,"Office automation significantly enhances human productivity by automatically
finishing routine tasks in the workflow. Beyond the basic information
extraction studied in much of the prior document AI literature, the office
automation research should be extended to more realistic office tasks which
require to integrate various information sources in the office system and
produce outputs through a series of decision-making processes. We introduce
OfficeBench, one of the first office automation benchmarks for evaluating
current LLM agents' capability to address office tasks in realistic office
workflows. OfficeBench requires LLM agents to perform feasible long-horizon
planning, proficiently switch between applications in a timely manner, and
accurately ground their actions within a large combined action space, based on
the contextual demands of the workflow. Applying our customized evaluation
methods on each task, we find that GPT-4 Omni achieves the highest pass rate of
47.00%, demonstrating a decent performance in handling office tasks. However,
this is still far below the human performance and accuracy standards required
by real-world office workflows. We further observe that most issues are related
to operation redundancy and hallucinations, as well as limitations in switching
between multiple applications, which may provide valuable insights for
developing effective agent frameworks for office automation.",2024-07-26,"Zilong Wang, Yuedong Cui, Li Zhong, Zimin Zhang, Da Yin, Bill Yuchen Lin, Jingbo Shang",http://arxiv.org/pdf/2407.19056v1,cs.CL
Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models,"The legal landscape encompasses a wide array of lawsuit types, presenting
lawyers with challenges in delivering timely and accurate information to
clients, particularly concerning critical aspects like potential imprisonment
duration or financial repercussions. Compounded by the scarcity of legal
experts, there's an urgent need to enhance the efficiency of traditional legal
workflows. Recent advances in deep learning, especially Large Language Models
(LLMs), offer promising solutions to this challenge. Leveraging LLMs'
mathematical reasoning capabilities, we propose a novel approach integrating
LLM-based methodologies with specially designed prompts to address precision
requirements in legal Artificial Intelligence (LegalAI) applications. The
proposed work seeks to bridge the gap between traditional legal practices and
modern technological advancements, paving the way for a more accessible,
efficient, and equitable legal system. To validate this method, we introduce a
curated dataset tailored to precision-oriented LegalAI tasks, serving as a
benchmark for evaluating LLM-based approaches. Extensive experimentation
confirms the efficacy of our methodology in generating accurate numerical
estimates within the legal domain, emphasizing the role of LLMs in streamlining
legal processes and meeting the evolving demands of LegalAI.",2024-07-26,"Jia-Hong Huang, Chao-Chun Yang, Yixian Shen, Alessio M. Pacces, Evangelos Kanoulas",http://arxiv.org/pdf/2407.19041v1,cs.CL
Wolf: Dense Video Captioning with a World Summarization Framework,"We propose Wolf, a WOrLd summarization Framework for accurate video
captioning. Wolf is an automated captioning framework that adopts a
mixture-of-experts approach, leveraging complementary strengths of Vision
Language Models (VLMs). By utilizing both image and video models, our framework
captures different levels of information and summarizes them efficiently. Our
approach can be applied to enhance video understanding, auto-labeling, and
captioning. To evaluate caption quality, we introduce CapScore, an LLM-based
metric to assess the similarity and quality of generated captions compared to
the ground truth captions. We further build four human-annotated datasets in
three domains: autonomous driving, general scenes, and robotics, to facilitate
comprehensive comparisons. We show that Wolf achieves superior captioning
performance compared to state-of-the-art approaches from the research community
(VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For
instance, in comparison with GPT-4V, Wolf improves CapScore both quality-wise
by 55.6% and similarity-wise by 77.4% on challenging driving videos. Finally,
we establish a benchmark for video captioning and introduce a leaderboard,
aiming to accelerate advancements in video understanding, captioning, and data
alignment. Webpage: https://wolfv0.github.io/.",2024-07-26,"Boyi Li, Ligeng Zhu, Ran Tian, Shuhan Tan, Yuxiao Chen, Yao Lu, Yin Cui, Sushant Veer, Max Ehrlich, Jonah Philion, Xinshuo Weng, Fuzhao Xue, Linxi Fan, Yuke Zhu, Jan Kautz, Andrew Tao, Ming-Yu Liu, Sanja Fidler, Boris Ivanovic, Trevor Darrell, Jitendra Malik, Song Han, Marco Pavone",http://arxiv.org/pdf/2407.18908v2,cs.CL
AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents,"Autonomous agents that address day-to-day digital tasks (e.g., ordering
groceries for a household), must not only operate multiple apps (e.g., notes,
messaging, shopping app) via APIs, but also generate rich code with complex
control flow in an iterative manner based on their interaction with the
environment. However, existing benchmarks for tool use are inadequate, as they
only cover tasks that require a simple sequence of API calls.
  To remedy this gap, we built $\textbf{AppWorld Engine}$, a high-quality
execution environment (60K lines of code) of 9 day-to-day apps operable via 457
APIs and populated with realistic digital activities simulating the lives of
~100 fictitious users. We then created $\textbf{AppWorld Benchmark}$ (40K lines
of code), a suite of 750 natural, diverse, and challenging autonomous agent
tasks requiring rich and interactive code generation. It supports robust
programmatic evaluation with state-based unit tests, allowing for different
ways of completing a task while also checking for unexpected changes, i.e.,
collateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our
'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least
16% fewer. This highlights the benchmark's difficulty and AppWorld's potential
to push the frontiers of interactive coding agents. The project website is
available at https://appworld.dev/.",2024-07-26,"Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian",http://arxiv.org/pdf/2407.18901v1,cs.CL
Embedding And Clustering Your Data Can Improve Contrastive Pretraining,"Recent studies of large-scale contrastive pretraining in the text embedding
domain show that using single-source minibatches, rather than mixed-source
minibatches, can substantially improve overall model accuracy. In this work, we
explore extending training data stratification beyond source granularity by
leveraging a pretrained text embedding model and the classic k-means clustering
algorithm to further split training data apart by the semantic clusters within
each source. Experimentally, we observe a notable increase in NDCG@10 when
pretraining a BERT-based text embedding model on query-passage pairs from the
MSMARCO passage retrieval dataset. Additionally, we conceptually connect our
clustering approach to both the Topic Aware Sampling (TAS) aspect of the TAS-B
methodology and the nearest-neighbor-based hard-negative mining aspect of the
ANCE methodology and discuss how this unified view motivates future lines of
research on the organization of contrastive pretraining data.",2024-07-26,Luke Merrick,http://arxiv.org/pdf/2407.18887v1,cs.CL
Granularity is crucial when applying differential privacy to text: An investigation for neural machine translation,"Applying differential privacy (DP) by means of the DP-SGD algorithm to
protect individual data points during training is becoming increasingly popular
in NLP. However, the choice of granularity at which DP is applied is often
neglected. For example, neural machine translation (NMT) typically operates on
the sentence-level granularity. From the perspective of DP, this setup assumes
that each sentence belongs to a single person and any two sentences in the
training dataset are independent. This assumption is however violated in many
real-world NMT datasets, e.g., those including dialogues. For proper
application of DP we thus must shift from sentences to entire documents. In
this paper, we investigate NMT at both the sentence and document levels,
analyzing the privacy/utility trade-off for both scenarios, and evaluating the
risks of not using the appropriate privacy granularity in terms of leaking
personally identifiable information (PII). Our findings indicate that the
document-level NMT system is more resistant to membership inference attacks,
emphasizing the significance of using the appropriate granularity when working
with DP.",2024-07-26,"Doan Nam Long Vu, Timour Igamberdiev, Ivan Habernal",http://arxiv.org/pdf/2407.18789v2,cs.CL
The power of Prompts: Evaluating and Mitigating Gender Bias in MT with LLMs,"This paper studies gender bias in machine translation through the lens of
Large Language Models (LLMs). Four widely-used test sets are employed to
benchmark various base LLMs, comparing their translation quality and gender
bias against state-of-the-art Neural Machine Translation (NMT) models for
English to Catalan (En $\rightarrow$ Ca) and English to Spanish (En
$\rightarrow$ Es) translation directions. Our findings reveal pervasive gender
bias across all models, with base LLMs exhibiting a higher degree of bias
compared to NMT models. To combat this bias, we explore prompting engineering
techniques applied to an instruction-tuned LLM. We identify a prompt structure
that significantly reduces gender bias by up to 12% on the WinoMT evaluation
dataset compared to more straightforward prompts. These results significantly
reduce the gender bias accuracy gap between LLMs and traditional NMT systems.",2024-07-26,"Aleix Sant, Carlos Escolano, Audrey Mash, Francesca De Luca Fornaciari, Maite Melero",http://arxiv.org/pdf/2407.18786v1,cs.CL
Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-based Causal Discovery,"Causal discovery aims to estimate causal structures among variables based on
observational data. Large Language Models (LLMs) offer a fresh perspective to
tackle the causal discovery problem by reasoning on the metadata associated
with variables rather than their actual data values, an approach referred to as
knowledge-based causal discovery. In this paper, we investigate the
capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1
billion parameters) with prompt-based learning for knowledge-based causal
discovery. Specifically, we present KG Structure as Prompt, a novel approach
for integrating structural information from a knowledge graph, such as common
neighbor nodes and metapaths, into prompt-based learning to enhance the
capabilities of SLMs. Experimental results on three types of biomedical and
open-domain datasets under few-shot settings demonstrate the effectiveness of
our approach, surpassing most baselines and even conventional fine-tuning
approaches trained on full datasets. Our findings further highlight the strong
capabilities of SLMs: in combination with knowledge graphs and prompt-based
learning, SLMs demonstrate the potential to surpass LLMs with larger number of
parameters. Our code and datasets are available on GitHub.",2024-07-26,"Yuni Susanti, Michael Färber",http://arxiv.org/pdf/2407.18752v3,cs.CL
Towards Effective and Efficient Continual Pre-training of Large Language Models,"Continual pre-training (CPT) has been an important approach for adapting
language models to specific domains or tasks. To make the CPT approach more
traceable, this paper presents a technical report for continually pre-training
Llama-3 (8B), which significantly enhances the Chinese language ability and
scientific reasoning ability of the backbone model. To enhance the new
abilities while retaining the original abilities, we design specific data
mixture and curriculum strategies by utilizing existing datasets and
synthesizing high-quality datasets. Specifically, we synthesize
multidisciplinary scientific question and answer (QA) pairs based on related
web pages, and subsequently incorporate these synthetic data to improve the
scientific reasoning ability of Llama-3. We refer to the model after CPT as
Llama-3-SynE (Synthetic data Enhanced Llama-3). We also present the tuning
experiments with a relatively small model -- TinyLlama, and employ the derived
findings to train the backbone model. Extensive experiments on a number of
evaluation benchmarks show that our approach can largely improve the
performance of the backbone models, including both the general abilities (+8.81
on C-Eval and +6.31 on CMMLU) and the scientific reasoning abilities (+12.00 on
MATH and +4.13 on SciEval), without hurting the original capacities. Our model,
data, and codes are available at https://github.com/RUC-GSAI/Llama-3-SynE.",2024-07-26,"Jie Chen, Zhipeng Chen, Jiapeng Wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Wayne Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen",http://arxiv.org/pdf/2407.18743v1,cs.CL
Towards Generalized Offensive Language Identification,"The prevalence of offensive content on the internet, encompassing hate speech
and cyberbullying, is a pervasive issue worldwide. Consequently, it has
garnered significant attention from the machine learning (ML) and natural
language processing (NLP) communities. As a result, numerous systems have been
developed to automatically identify potentially harmful content and mitigate
its impact. These systems can follow two approaches; (1) Use publicly available
models and application endpoints, including prompting large language models
(LLMs) (2) Annotate datasets and train ML models on them. However, both
approaches lack an understanding of how generalizable they are. Furthermore,
the applicability of these systems is often questioned in off-domain and
practical environments. This paper empirically evaluates the generalizability
of offensive language detection models and datasets across a novel generalized
benchmark. We answer three research questions on generalizability. Our findings
will be useful in creating robust real-world offensive language detection
systems.",2024-07-26,"Alphaeus Dmonte, Tejas Arya, Tharindu Ranasinghe, Marcos Zampieri",http://arxiv.org/pdf/2407.18738v1,cs.CL
Creating an Aligned Corpus of Sound and Text: The Multimodal Corpus of Shakespeare and Milton,"In this work we present a corpus of poems by William Shakespeare and John
Milton that have been enriched with readings from the public domain. We have
aligned all the lines with their respective audio segments, at the line, word,
syllable and phone level, and we have included their scansion. We make a basic
visualization platform for these poems and we conclude by conjecturing possible
future directions.",2024-07-26,Manex Agirrezabal,http://arxiv.org/pdf/2407.18730v1,cs.CL
ChatSchema: A pipeline of extracting structured information with Large Multimodal Models based on schema,"Objective: This study introduces ChatSchema, an effective method for
extracting and structuring information from unstructured data in medical paper
reports using a combination of Large Multimodal Models (LMMs) and Optical
Character Recognition (OCR) based on the schema. By integrating predefined
schema, we intend to enable LMMs to directly extract and standardize
information according to the schema specifications, facilitating further data
entry. Method: Our approach involves a two-stage process, including
classification and extraction for categorizing report scenarios and structuring
information. We established and annotated a dataset to verify the effectiveness
of ChatSchema, and evaluated key extraction using precision, recall, F1-score,
and accuracy metrics. Based on key extraction, we further assessed value
extraction. We conducted ablation studies on two LMMs to illustrate the
improvement of structured information extraction with different input modals
and methods. Result: We analyzed 100 medical reports from Peking University
First Hospital and established a ground truth dataset with 2,945 key-value
pairs. We evaluated ChatSchema using GPT-4o and Gemini 1.5 Pro and found a
higher overall performance of GPT-4o. The results are as follows: For the
result of key extraction, key-precision was 98.6%, key-recall was 98.5%,
key-F1-score was 98.6%. For the result of value extraction based on correct key
extraction, the overall accuracy was 97.2%, precision was 95.8%, recall was
95.8%, and F1-score was 95.8%. An ablation study demonstrated that ChatSchema
achieved significantly higher overall accuracy and overall F1-score of
key-value extraction, compared to the Baseline, with increases of 26.9% overall
accuracy and 27.4% overall F1-score, respectively.",2024-07-26,"Fei Wang, Yuewen Zheng, Qin Li, Jingyi Wu, Pengfei Li, Luxia Zhang",http://arxiv.org/pdf/2407.18716v1,cs.CL
Cluster-norm for Unsupervised Probing of Knowledge,"The deployment of language models brings challenges in generating reliable
information, especially when these models are fine-tuned using human
preferences. To extract encoded knowledge without (potentially) biased human
labels, unsupervised probing techniques like Contrast-Consistent Search (CCS)
have been developed (Burns et al., 2022). However, salient but unrelated
features in a given dataset can mislead these probes (Farquhar et al., 2023).
Addressing this, we propose a cluster normalization method to minimize the
impact of such features by clustering and normalizing activations of contrast
pairs before applying unsupervised probing techniques. While this approach does
not address the issue of differentiating between knowledge in general and
simulated knowledge - a major issue in the literature of latent knowledge
elicitation (Christiano et al., 2021) - it significantly improves the ability
of unsupervised probes to identify the intended knowledge amidst distractions.",2024-07-26,"Walter Laurito, Sharan Maiya, Grégoire Dhimoïla, Owen, Yeung, Kaarel Hänni",http://arxiv.org/pdf/2407.18712v2,cs.CL
Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation,"Decoding from the output distributions of large language models to produce
high-quality text is a complex challenge in language modeling. Various
approaches, such as beam search, sampling with temperature, $k-$sampling,
nucleus $p-$sampling, typical decoding, contrastive decoding, and contrastive
search, have been proposed to address this problem, aiming to improve
coherence, diversity, as well as resemblance to human-generated text. In this
study, we introduce adaptive contrastive search, a novel decoding strategy
extending contrastive search by incorporating an adaptive degeneration penalty,
guided by the estimated uncertainty of the model at each generation step. This
strategy is designed to enhance both the creativity and diversity of the
language modeling process while at the same time producing coherent and
high-quality generated text output. Our findings indicate performance
enhancement in both aspects, across different model architectures and datasets,
underscoring the effectiveness of our method in text generation tasks. Our code
base, datasets, and models are publicly available.",2024-07-26,"Esteban Garces Arias, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher",http://arxiv.org/pdf/2407.18698v2,cs.CL
The BIAS Detection Framework: Bias Detection in Word Embeddings and Language Models for European Languages,"The project BIAS: Mitigating Diversity Biases of AI in the Labor Market is a
four-year project funded by the European commission and supported by the Swiss
State Secretariat for Education, Research and Innovation (SERI). As part of the
project, novel bias detection methods to identify societal bias in language
models and word embeddings in European languages are developed, with particular
attention to linguistic and geographic particularities. This technical report
describes the overall architecture and components of the BIAS Detection
Framework. The code described in this technical report is available and will be
updated and expanded continuously with upcoming results from the BIAS project.
The details about the datasets for the different languages are described in
corresponding papers at scientific venues.",2024-07-26,"Alexandre Puttick, Leander Rankwiler, Catherine Ikae, Mascha Kurpicz-Briki",http://arxiv.org/pdf/2407.18689v1,cs.CL
Improving noisy student training for low-resource languages in End-to-End ASR using CycleGAN and inter-domain losses,"Training a semi-supervised end-to-end speech recognition system using noisy
student training has significantly improved performance. However, this approach
requires a substantial amount of paired speech-text and unlabeled speech, which
is costly for low-resource languages. Therefore, this paper considers a more
extreme case of semi-supervised end-to-end automatic speech recognition where
there are limited paired speech-text, unlabeled speech (less than five hours),
and abundant external text. Firstly, we observe improved performance by
training the model using our previous work on semi-supervised learning
""CycleGAN and inter-domain losses"" solely with external text. Secondly, we
enhance ""CycleGAN and inter-domain losses"" by incorporating automatic
hyperparameter tuning, calling it ""enhanced CycleGAN inter-domain losses.""
Thirdly, we integrate it into the noisy student training approach pipeline for
low-resource scenarios. Our experimental results, conducted on six non-English
languages from Voxforge and Common Voice, show a 20% word error rate reduction
compared to the baseline teacher model and a 10% word error rate reduction
compared to the baseline best student model, highlighting the significant
improvements achieved through our proposed method.",2024-07-26,"Chia-Yu Li, Ngoc Thang Vu",http://arxiv.org/pdf/2407.21061v1,cs.CL
Every Part Matters: Integrity Verification of Scientific Figures Based on Multimodal Large Language Models,"This paper tackles a key issue in the interpretation of scientific figures:
the fine-grained alignment of text and figures. It advances beyond prior
research that primarily dealt with straightforward, data-driven visualizations
such as bar and pie charts and only offered a basic understanding of diagrams
through captioning and classification. We introduce a novel task, Figure
Integrity Verification, designed to evaluate the precision of technologies in
aligning textual knowledge with visual elements in scientific figures. To
support this, we develop a semi-automated method for constructing a large-scale
dataset, Figure-seg, specifically designed for this task. Additionally, we
propose an innovative framework, Every Part Matters (EPM), which leverages
Multimodal Large Language Models (MLLMs) to not only incrementally improve the
alignment and verification of text-figure integrity but also enhance integrity
through analogical reasoning. Our comprehensive experiments show that these
innovations substantially improve upon existing methods, allowing for more
precise and thorough analysis of complex scientific figures. This progress not
only enhances our understanding of multimodal technologies but also stimulates
further research and practical applications across fields requiring the
accurate interpretation of complex visual data.",2024-07-26,"Xiang Shi, Jiawei Liu, Yinpeng Liu, Qikai Cheng, Wei Lu",http://arxiv.org/pdf/2407.18626v1,cs.CL
Large Language Model Agent in Financial Trading: A Survey,"Trading is a highly competitive task that requires a combination of strategy,
knowledge, and psychological fortitude. With the recent success of large
language models(LLMs), it is appealing to apply the emerging intelligence of
LLM agents in this competitive arena and understanding if they can outperform
professional traders. In this survey, we provide a comprehensive review of the
current research on using LLMs as agents in financial trading. We summarize the
common architecture used in the agent, the data inputs, and the performance of
LLM trading agents in backtesting as well as the challenges presented in these
research. This survey aims to provide insights into the current state of
LLM-based financial trading agents and outline future research directions in
this field.",2024-07-26,"Han Ding, Yinheng Li, Junhao Wang, Hang Chen",http://arxiv.org/pdf/2408.06361v1,cs.CL
Using Large Language Models for the Interpretation of Building Regulations,"Compliance checking is an essential part of a construction project. The
recent rapid uptake of building information models (BIM) in the construction
industry has created more opportunities for automated compliance checking
(ACC). BIM enables sharing of digital building design data that can be used for
compliance checking with legal requirements, which are conventionally conveyed
in natural language and not intended for machine processing. Creating a
computable representation of legal requirements suitable for ACC is complex,
costly, and time-consuming. Large language models (LLMs) such as the generative
pre-trained transformers (GPT), GPT-3.5 and GPT-4, powering OpenAI's ChatGPT,
can generate logically coherent text and source code responding to user
prompts. This capability could be used to automate the conversion of building
regulations into a semantic and computable representation. This paper evaluates
the performance of LLMs in translating building regulations into LegalRuleML in
a few-shot learning setup. By providing GPT-3.5 with only a few example
translations, it can learn the basic structure of the format. Using a system
prompt, we further specify the LegalRuleML representation and explore the
existence of expert domain knowledge in the model. Such domain knowledge might
be ingrained in GPT-3.5 through the broad pre-training but needs to be brought
forth by careful contextualisation. Finally, we investigate whether strategies
such as chain-of-thought reasoning and self-consistency could apply to this use
case. As LLMs become more sophisticated, the increased common sense, logical
coherence, and means to domain adaptation can significantly support ACC,
leading to more efficient and effective checking processes.",2024-07-26,"Stefan Fuchs, Michael Witbrock, Johannes Dimyadi, Robert Amor",http://arxiv.org/pdf/2407.21060v1,cs.CL
Dynamic Language Group-Based MoE: Enhancing Code-Switching Speech Recognition with Hierarchical Routing,"The Mixture of Experts (MoE) model is a promising approach for handling
code-switching speech recognition (CS-ASR) tasks. However, the existing CS-ASR
work on MoE has yet to leverage the advantages of MoE's parameter scaling
ability fully. This work proposes DLG-MoE, a Dynamic Language Group-based MoE,
which can effectively handle the CS-ASR task and leverage the advantages of
parameter scaling. DLG-MoE operates based on a hierarchical routing mechanism.
First, the language router explicitly models the language attribute and
dispatches the representations to the corresponding language expert groups.
Subsequently, the unsupervised router within each language group implicitly
models attributes beyond language and coordinates expert routing and
collaboration. DLG-MoE outperforms the existing MoE methods on CS-ASR tasks
while demonstrating great flexibility. It supports different top-$k$ inference
and streaming capabilities and can also prune the model parameters flexibly to
obtain a monolingual sub-model. The code has been released.",2024-07-26,"Hukai Huang, Shenghui Lu, Yahui Shan, He Qu, Fengrun Zhang, Wenhao Guan, Qingyang Hong, Lin Li",http://arxiv.org/pdf/2407.18581v4,cs.CL
Learning Robust Named Entity Recognizers From Noisy Data With Retrieval Augmentation,"Named entity recognition (NER) models often struggle with noisy inputs, such
as those with spelling mistakes or errors generated by Optical Character
Recognition processes, and learning a robust NER model is challenging. Existing
robust NER models utilize both noisy text and its corresponding gold text for
training, which is infeasible in many real-world applications in which gold
text is not available. In this paper, we consider a more realistic setting in
which only noisy text and its NER labels are available. We propose to retrieve
relevant text of the noisy text from a knowledge corpus and use it to enhance
the representation of the original noisy input. We design three retrieval
methods: sparse retrieval based on lexicon similarity, dense retrieval based on
semantic similarity, and self-retrieval based on task-specific text. After
retrieving relevant text, we concatenate the retrieved text with the original
noisy text and encode them with a transformer network, utilizing self-attention
to enhance the contextual token representations of the noisy text using the
retrieved text. We further employ a multi-view training framework that improves
robust NER without retrieving text during inference. Experiments show that our
retrieval-augmented model achieves significant improvements in various noisy
NER settings.",2024-07-26,"Chaoyi Ai, Yong Jiang, Shen Huang, Pengjun Xie, Kewei Tu",http://arxiv.org/pdf/2407.18562v1,cs.CL
Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention,"Understanding emotions is a fundamental aspect of human communication.
Integrating audio and video signals offers a more comprehensive understanding
of emotional states compared to traditional methods that rely on a single data
source, such as speech or facial expressions. Despite its potential, multimodal
emotion recognition faces significant challenges, particularly in
synchronization, feature extraction, and fusion of diverse data sources. To
address these issues, this paper introduces a novel transformer-based model
named Audio-Video Transformer Fusion with Cross Attention (AVT-CA). The AVT-CA
model employs a transformer fusion approach to effectively capture and
synchronize interlinked features from both audio and video inputs, thereby
resolving synchronization problems. Additionally, the Cross Attention mechanism
within AVT-CA selectively extracts and emphasizes critical features while
discarding irrelevant ones from both modalities, addressing feature extraction
and fusion challenges. Extensive experimental analysis conducted on the
CMU-MOSEI, RAVDESS and CREMA-D datasets demonstrates the efficacy of the
proposed model. The results underscore the importance of AVT-CA in developing
precise and reliable multimodal emotion recognition systems for practical
applications.",2024-07-26,"Joe Dhanith P R, Shravan Venkatraman, Vigya Sharma, Santhosh Malarvannan, Modigari Narendra",http://arxiv.org/pdf/2407.18552v3,cs.CL
A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text using Large Language Models,"Over the past decade, extensive research efforts have been dedicated to the
extraction of information from textual process descriptions. Despite the
remarkable progress witnessed in natural language processing (NLP), information
extraction within the Business Process Management domain remains predominantly
reliant on rule-based systems and machine learning methodologies. Data scarcity
has so far prevented the successful application of deep learning techniques.
However, the rapid progress in generative large language models (LLMs) makes it
possible to solve many NLP tasks with very high quality without the need for
extensive data. Therefore, we systematically investigate the potential of LLMs
for extracting information from textual process descriptions, targeting the
detection of process elements such as activities and actors, and relations
between them. Using a heuristic algorithm, we demonstrate the suitability of
the extracted information for process model generation. Based on a novel
prompting strategy, we show that LLMs are able to outperform state-of-the-art
machine learning approaches with absolute performance improvements of up to 8\%
$F_1$ score across three different datasets. We evaluate our prompting strategy
on eight different LLMs, showing it is universally applicable, while also
analyzing the impact of certain prompt parts on extraction quality. The number
of example texts, the specificity of definitions, and the rigour of format
instructions are identified as key for improving the accuracy of extracted
information. Our code, prompts, and data are publicly available.",2024-07-26,"Julian Neuberger, Lars Ackermann, Han van der Aa, Stefan Jablonski",http://arxiv.org/pdf/2407.18540v1,cs.CL
Towards a Multidimensional Evaluation Framework for Empathetic Conversational Systems,"Empathetic Conversational Systems (ECS) are built to respond empathetically
to the user's emotions and sentiments, regardless of the application domain.
Current ECS studies evaluation approaches are restricted to offline evaluation
experiments primarily for gold standard comparison & benchmarking, and user
evaluation studies for collecting human ratings on specific constructs. These
methods are inadequate in measuring the actual quality of empathy in
conversations. In this paper, we propose a multidimensional empathy evaluation
framework with three new methods for measuring empathy at (i) structural level
using three empathy-related dimensions, (ii) behavioral level using empathy
behavioral types, and (iii) overall level using an empathy lexicon, thereby
fortifying the evaluation process. Experiments were conducted with the
state-of-the-art ECS models and large language models (LLMs) to show the
framework's usefulness.",2024-07-26,"Aravind Sesagiri Raamkumar, Siyuan Brandon Loh",http://arxiv.org/pdf/2407.18538v1,cs.CL
ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks,"Large Language Models (LLMs) are increasingly deployed in medicine. However,
their utility in non-generative clinical prediction, often presumed inferior to
specialized models, remains under-evaluated, leading to ongoing debate within
the field and potential for misuse, misunderstanding, or over-reliance due to a
lack of systematic benchmarking. Our ClinicRealm study addresses this by
benchmarking 9 GPT-based LLMs, 5 BERT-based models, and 7 traditional methods
on unstructured clinical notes and structured Electronic Health Records (EHR).
Key findings reveal a significant shift: for clinical note predictions, leading
LLMs (e.g., DeepSeek R1/V3, GPT o3-mini-high) in zero-shot settings now
decisively outperform finetuned BERT models. On structured EHRs, while
specialized models excel with ample data, advanced LLMs (e.g., GPT-4o, DeepSeek
R1/V3) show potent zero-shot capabilities, often surpassing conventional models
in data-scarce settings. Notably, leading open-source LLMs can match or exceed
proprietary counterparts. These results establish modern LLMs as powerful
non-generative clinical prediction tools, particularly with unstructured text
and offering data-efficient structured data options, thus necessitating a
re-evaluation of model selection strategies. This research should serve as an
important insight for medical informaticists, AI developers, and clinical
researchers, potentially prompting a reassessment of current assumptions and
inspiring new approaches to LLM application in predictive healthcare.",2024-07-26,"Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma",http://arxiv.org/pdf/2407.18525v2,cs.CL
The formation of perceptual space in early phonetic acquisition: a cross-linguistic modeling approach,"This study investigates how learners organize perceptual space in early
phonetic acquisition by advancing previous studies in two key aspects. Firstly,
it examines the shape of the learned hidden representation as well as its
ability to categorize phonetic categories. Secondly, it explores the impact of
training models on context-free acoustic information, without involving
contextual cues, on phonetic acquisition, closely mimicking the early language
learning stage. Using a cross-linguistic modeling approach, autoencoder models
are trained on English and Mandarin and evaluated in both native and non-native
conditions, following experimental conditions used in infant language
perception studies. The results demonstrate that unsupervised bottom-up
training on context-free acoustic information leads to comparable learned
representations of perceptual space between native and non-native conditions
for both English and Mandarin, resembling the early stage of universal
listening in infants. These findings provide insights into the organization of
perceptual space during early phonetic acquisition and contribute to our
understanding of the formation and representation of phonetic categories.",2024-07-26,"Frank Lihui Tan, Youngah Do",http://arxiv.org/pdf/2407.18501v1,cs.CL
A Reliable Common-Sense Reasoning Socialbot Built Using LLMs and Goal-Directed ASP,"The development of large language models (LLMs), such as GPT, has enabled the
construction of several socialbots, like ChatGPT, that are receiving a lot of
attention for their ability to simulate a human conversation. However, the
conversation is not guided by a goal and is hard to control. In addition,
because LLMs rely more on pattern recognition than deductive reasoning, they
can give confusing answers and have difficulty integrating multiple topics into
a cohesive response. These limitations often lead the LLM to deviate from the
main topic to keep the conversation interesting. We propose AutoCompanion, a
socialbot that uses an LLM model to translate natural language into predicates
(and vice versa) and employs commonsense reasoning based on Answer Set
Programming (ASP) to hold a social conversation with a human. In particular, we
rely on s(CASP), a goal-directed implementation of ASP as the backend. This
paper presents the framework design and how an LLM is used to parse user
messages and generate a response from the s(CASP) engine output. To validate
our proposal, we describe (real) conversations in which the chatbot's goal is
to keep the user entertained by talking about movies and books, and s(CASP)
ensures (i) correctness of answers, (ii) coherence (and precision) during the
conversation, which it dynamically regulates to achieve its specific purpose,
and (iii) no deviation from the main topic.",2024-07-26,"Yankai Zeng, Abhiramon Rajashekharan, Kinjal Basu, Huaduo Wang, Joaquín Arias, Gopal Gupta",http://arxiv.org/pdf/2407.18498v1,cs.CL
"Towards More Accurate Prediction of Human Empathy and Emotion in Text and Multi-turn Conversations by Combining Advanced NLP, Transformers-based Networks, and Linguistic Methodologies","Based on the WASSA 2022 Shared Task on Empathy Detection and Emotion
Classification, we predict the level of empathic concern and personal distress
displayed in essays. For the first stage of this project we implemented a
Feed-Forward Neural Network using sentence-level embeddings as features. We
experimented with four different embedding models for generating the inputs to
the neural network. The subsequent stage builds upon the previous work and we
have implemented three types of revisions. The first revision focuses on the
enhancements to the model architecture and the training approach. The second
revision focuses on handling class imbalance using stratified data sampling.
The third revision focuses on leveraging lexical resources, where we apply four
different resources to enrich the features associated with the dataset. During
the final stage of this project, we have created the final end-to-end system
for the primary task using an ensemble of models to revise primary task
performance. Additionally, as part of the final stage, these approaches have
been adapted to the WASSA 2023 Shared Task on Empathy Emotion and Personality
Detection in Interactions, in which the empathic concern, emotion polarity, and
emotion intensity in dyadic text conversations are predicted.",2024-07-26,"Manisha Singh, Divy Sharma, Alonso Ma, Nora Goldfine",http://arxiv.org/pdf/2407.18496v1,cs.CL
Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable Frameworks,"Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities
of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The
increasing demands of application scenarios have driven the evolution of RAG,
leading to the integration of advanced retrievers, LLMs and other complementary
technologies, which in turn has amplified the intricacy of RAG systems.
However, the rapid advancements are outpacing the foundational RAG paradigm,
with many methods struggling to be unified under the process of
""retrieve-then-generate"". In this context, this paper examines the limitations
of the existing RAG paradigm and introduces the modular RAG framework. By
decomposing complex RAG systems into independent modules and specialized
operators, it facilitates a highly reconfigurable framework. Modular RAG
transcends the traditional linear architecture, embracing a more advanced
design that integrates routing, scheduling, and fusion mechanisms. Drawing on
extensive research, this paper further identifies prevalent RAG
patterns-linear, conditional, branching, and looping-and offers a comprehensive
analysis of their respective implementation nuances. Modular RAG presents
innovative opportunities for the conceptualization and deployment of RAG
systems. Finally, the paper explores the potential emergence of new operators
and paradigms, establishing a solid theoretical foundation and a practical
roadmap for the continued evolution and practical deployment of RAG
technologies.",2024-07-26,"Yunfan Gao, Yun Xiong, Meng Wang, Haofen Wang",http://arxiv.org/pdf/2407.21059v1,cs.CL
A Role-specific Guided Large Language Model for Ophthalmic Consultation Based on Stylistic Differentiation,"Ophthalmology consultations are crucial for diagnosing, treating, and
preventing eye diseases. However, the growing demand for consultations exceeds
the availability of ophthalmologists. By leveraging large pre-trained language
models, we can design effective dialogues for specific scenarios, aiding in
consultations. Traditional fine-tuning strategies for question-answering tasks
are impractical due to increasing model size and often ignoring patient-doctor
role function during consultations. In this paper, we propose EyeDoctor, an
ophthalmic medical questioning large language model that enhances accuracy
through doctor-patient role perception guided and an augmented knowledge base
with external disease information. Experimental results show EyeDoctor achieves
higher question-answering precision in ophthalmology consultations. Notably,
EyeDoctor demonstrated a 7.25% improvement in Rouge-1 scores and a 10.16%
improvement in F1 scores on multi-round datasets compared to second best model
ChatGPT, highlighting the importance of doctor-patient role differentiation and
dynamic knowledge base expansion for intelligent medical consultations. EyeDoc
also serves as a free available web based service and souce code is available
at https://github.com/sperfu/EyeDoc.",2024-07-26,"Laiyi Fu, Binbin Fan, Hongkai Du, Yanxiang Feng, Chunhua Li, Huping Song",http://arxiv.org/pdf/2407.18483v4,cs.CL
Multi-turn Response Selection with Commonsense-enhanced Language Models,"As a branch of advanced artificial intelligence, dialogue systems are
prospering. Multi-turn response selection is a general research problem in
dialogue systems. With the assistance of background information and pre-trained
language models, the performance of state-of-the-art methods on this problem
gains impressive improvement. However, existing studies neglect the importance
of external commonsense knowledge. Hence, we design a Siamese network where a
pre-trained Language model merges with a Graph neural network (SinLG). SinLG
takes advantage of Pre-trained Language Models (PLMs) to catch the word
correlations in the context and response candidates and utilizes a Graph Neural
Network (GNN) to reason helpful common sense from an external knowledge graph.
The GNN aims to assist the PLM in fine-tuning, and arousing its related
memories to attain better performance. Specifically, we first extract related
concepts as nodes from an external knowledge graph to construct a subgraph with
the context response pair as a super node for each sample. Next, we learn two
representations for the context response pair via both the PLM and GNN. A
similarity loss between the two representations is utilized to transfer the
commonsense knowledge from the GNN to the PLM. Then only the PLM is used to
infer online so that efficiency can be guaranteed. Finally, we conduct
extensive experiments on two variants of the PERSONA-CHAT dataset, which proves
that our solution can not only improve the performance of the PLM but also
achieve an efficient inference.",2024-07-26,"Yuandong Wang, Xuhui Ren, Tong Chen, Yuxiao Dong, Nguyen Quoc Viet Hung, Jie Tang",http://arxiv.org/pdf/2407.18479v1,cs.CL
Constructing the CORD-19 Vaccine Dataset,"We introduce new dataset 'CORD-19-Vaccination' to cater to scientists
specifically looking into COVID-19 vaccine-related research. This dataset is
extracted from CORD-19 dataset [Wang et al., 2020] and augmented with new
columns for language detail, author demography, keywords, and topic per paper.
Facebook's fastText model is used to identify languages [Joulin et al., 2016].
To establish author demography (author affiliation, lab/institution location,
and lab/institution country columns) we processed the JSON file for each paper
and then further enhanced using Google's search API to determine country
values. 'Yake' was used to extract keywords from the title, abstract, and body
of each paper and the LDA (Latent Dirichlet Allocation) algorithm was used to
add topic information [Campos et al., 2020, 2018a,b]. To evaluate the dataset,
we demonstrate a question-answering task like the one used in the CORD-19
Kaggle challenge [Goldbloom et al., 2022]. For further evaluation, sequential
sentence classification was performed on each paper's abstract using the model
from Dernoncourt et al. [2016]. We partially hand annotated the training
dataset and used a pre-trained BERT-PubMed layer. 'CORD- 19-Vaccination'
contains 30k research papers and can be immensely valuable for NLP research
such as text mining, information extraction, and question answering, specific
to the domain of COVID-19 vaccine research.",2024-07-26,"Manisha Singh, Divy Sharma, Alonso Ma, Bridget Tyree, Margaret Mitchell",http://arxiv.org/pdf/2407.18471v1,cs.CL
Enhancing Dysarthric Speech Recognition for Unseen Speakers via Prototype-Based Adaptation,"Dysarthric speech recognition (DSR) presents a formidable challenge due to
inherent inter-speaker variability, leading to severe performance degradation
when applying DSR models to new dysarthric speakers. Traditional speaker
adaptation methodologies typically involve fine-tuning models for each speaker,
but this strategy is cost-prohibitive and inconvenient for disabled users,
requiring substantial data collection. To address this issue, we introduce a
prototype-based approach that markedly improves DSR performance for unseen
dysarthric speakers without additional fine-tuning. Our method employs a
feature extractor trained with HuBERT to produce per-word prototypes that
encapsulate the characteristics of previously unseen speakers. These prototypes
serve as the basis for classification. Additionally, we incorporate supervised
contrastive learning to refine feature extraction. By enhancing representation
quality, we further improve DSR performance, enabling effective personalized
DSR. We release our code at https://github.com/NKU-HLT/PB-DSR.",2024-07-26,"Shiyao Wang, Shiwan Zhao, Jiaming Zhou, Aobo Kong, Yong Qin",http://arxiv.org/pdf/2407.18461v1,cs.CL
Fairness Definitions in Language Models Explained,"Language Models (LMs) have demonstrated exceptional performance across
various Natural Language Processing (NLP) tasks. Despite these advancements,
LMs can inherit and amplify societal biases related to sensitive attributes
such as gender and race, limiting their adoption in real-world applications.
Therefore, fairness has been extensively explored in LMs, leading to the
proposal of various fairness notions. However, the lack of clear agreement on
which fairness definition to apply in specific contexts (\textit{e.g.,}
medium-sized LMs versus large-sized LMs) and the complexity of understanding
the distinctions between these definitions can create confusion and impede
further progress. To this end, this paper proposes a systematic survey that
clarifies the definitions of fairness as they apply to LMs. Specifically, we
begin with a brief introduction to LMs and fairness in LMs, followed by a
comprehensive, up-to-date overview of existing fairness notions in LMs and the
introduction of a novel taxonomy that categorizes these concepts based on their
foundational principles and operational distinctions. We further illustrate
each definition through experiments, showcasing their practical implications
and outcomes. Finally, we discuss current research challenges and open
questions, aiming to foster innovative ideas and advance the field. The
implementation and additional resources are publicly available at
https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.",2024-07-26,"Thang Viet Doan, Zhibo Chu, Zichong Wang, Wenbin Zhang",http://arxiv.org/pdf/2407.18454v1,cs.CL
Guidance-Based Prompt Data Augmentation in Specialized Domains for Named Entity Recognition,"While the abundance of rich and vast datasets across numerous fields has
facilitated the advancement of natural language processing, sectors in need of
specialized data types continue to struggle with the challenge of finding
quality data. Our study introduces a novel guidance data augmentation technique
utilizing abstracted context and sentence structures to produce varied
sentences while maintaining context-entity relationships, addressing data
scarcity challenges. By fostering a closer relationship between context,
sentence structure, and role of entities, our method enhances data
augmentation's effectiveness. Consequently, by showcasing diversification in
both entity-related vocabulary and overall sentence structure, and
simultaneously improving the training performance of named entity recognition
task.",2024-07-26,"Hyeonseok Kang, Hyein Seo, Jeesu Jung, Sangkeun Jung, Du-Seong Chang, Riwoo Chung",http://arxiv.org/pdf/2407.18442v1,cs.CL
"Understanding the Interplay of Scale, Data, and Bias in Language Models: A Case Study with BERT","In the current landscape of language model research, larger models, larger
datasets and more compute seems to be the only way to advance towards
intelligence. While there have been extensive studies of scaling laws and
models' scaling behaviors, the effect of scale on a model's social biases and
stereotyping tendencies has received less attention. In this study, we explore
the influence of model scale and pre-training data on its learnt social biases.
We focus on BERT -- an extremely popular language model -- and investigate
biases as they show up during language modeling (upstream), as well as during
classification applications after fine-tuning (downstream). Our experiments on
four architecture sizes of BERT demonstrate that pre-training data
substantially influences how upstream biases evolve with model scale. With
increasing scale, models pre-trained on large internet scrapes like Common
Crawl exhibit higher toxicity, whereas models pre-trained on moderated data
sources like Wikipedia show greater gender stereotypes. However, downstream
biases generally decrease with increasing model scale, irrespective of the
pre-training data. Our results highlight the qualitative role of pre-training
data in the biased behavior of language models, an often overlooked aspect in
the study of scale. Through a detailed case study of BERT, we shed light on the
complex interplay of data and model scale, and investigate how it translates to
concrete biases.",2024-07-25,"Muhammad Ali, Swetasudha Panda, Qinlan Shen, Michael Wick, Ari Kobren",http://arxiv.org/pdf/2407.21058v1,cs.CL
Self-Directed Synthetic Dialogues and Revisions Technical Report,"Synthetic data has become an important tool in the fine-tuning of language
models to follow instructions and solve complex problems. Nevertheless, the
majority of open data to date is often lacking multi-turn data and collected on
closed models, limiting progress on advancing open fine-tuning methods. We
introduce Self Directed Synthetic Dialogues (SDSD), an experimental dataset
consisting of guided conversations of language models talking to themselves.
The dataset consists of multi-turn conversations generated with DBRX, Llama 2
70B, and Mistral Large, all instructed to follow a conversation plan generated
prior to the conversation. We also explore including principles from
Constitutional AI and other related works to create synthetic preference data
via revisions to the final conversation turn. We hope this work encourages
further exploration in multi-turn data and the use of open models for expanding
the impact of synthetic data.",2024-07-25,"Nathan Lambert, Hailey Schoelkopf, Aaron Gokaslan, Luca Soldaini, Valentina Pyatkin, Louis Castricato",http://arxiv.org/pdf/2407.18421v1,cs.CL
Know Your Limits: A Survey of Abstention in Large Language Models,"Abstention, the refusal of large language models (LLMs) to provide an answer,
is increasingly recognized for its potential to mitigate hallucinations and
enhance safety in LLM systems. In this survey, we introduce a framework to
examine abstention from three perspectives: the query, the model, and human
values. We organize the literature on abstention methods, benchmarks, and
evaluation metrics using this framework, and discuss merits and limitations of
prior work. We further identify and motivate areas for future research, such as
whether abstention can be achieved as a meta-capability that transcends
specific tasks or domains, and opportunities to optimize abstention abilities
in specific contexts. In doing so, we aim to broaden the scope and impact of
abstention methodologies in AI systems.",2024-07-25,"Bingbing Wen, Jihan Yao, Shangbin Feng, Chenjun Xu, Yulia Tsvetkov, Bill Howe, Lucy Lu Wang",http://arxiv.org/pdf/2407.18418v3,cs.CL
PersonaGym: Evaluating Persona Agents and LLMs,"Persona agents, which are LLM agents conditioned to act according to an
assigned persona, enable contextually rich and user aligned interactions across
domains like education and healthcare. However, evaluating how faithfully these
agents adhere to their personas remains a significant challenge, particularly
in free-form settings that demand consistency across diverse, persona-relevant
environments. We introduce PersonaGym, the first dynamic evaluation framework
for persona agents, and PersonaScore, a human-aligned automatic metric grounded
in decision theory that enables comprehensive large-scale evaluation. Our
evaluation of 10 leading LLMs across 200 personas and 10,000 questions reveals
significant advancement opportunities. For example, GPT-4.1 had the exact same
PersonaScore as LLaMA-3-8b despite being a more recent and advanced closed
source model. Importantly, increased model size and complexity do not
necessarily enhance persona agent capabilities, underscoring the need for
algorithmic and architectural innovation toward faithful, performant persona
agents.",2024-07-25,"Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak Murahari",http://arxiv.org/pdf/2407.18416v4,cs.CL
Exploring Bengali Religious Dialect Biases in Large Language Models with Evaluation Perspectives,"While Large Language Models (LLM) have created a massive technological impact
in the past decade, allowing for human-enabled applications, they can produce
output that contains stereotypes and biases, especially when using low-resource
languages. This can be of great ethical concern when dealing with sensitive
topics such as religion. As a means toward making LLMS more fair, we explore
bias from a religious perspective in Bengali, focusing specifically on two main
religious dialects: Hindu and Muslim-majority dialects. Here, we perform
different experiments and audit showing the comparative analysis of different
sentences using three commonly used LLMs: ChatGPT, Gemini, and Microsoft
Copilot, pertaining to the Hindu and Muslim dialects of specific words and
showcasing which ones catch the social biases and which do not. Furthermore, we
analyze our findings and relate them to potential reasons and evaluation
perspectives, considering their global impact with over 300 million speakers
worldwide. With this work, we hope to establish the rigor for creating more
fairness in LLMs, as these are widely used as creative writing agents.",2024-07-25,"Azmine Toushik Wasi, Raima Islam, Mst Rafia Islam, Taki Hasan Rafi, Dong-Kyu Chae",http://arxiv.org/pdf/2407.18376v1,cs.CL
Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement,"We present a principled approach to provide LLM-based evaluation with a
rigorous guarantee of human agreement. We first propose that a reliable
evaluation method should not uncritically rely on model preferences for
pairwise evaluation, but rather assess the confidence of judge models and
selectively decide when to trust its judgement. We then show that under this
selective evaluation framework, human agreement can be provably guaranteed --
such that the model evaluation aligns with that of humans to a user-specified
agreement level. As part of our framework, we also introduce Simulated
Annotators, a novel confidence estimation method that significantly improves
judge calibration and thus enables high coverage of evaluated instances.
Finally, we propose Cascaded Selective Evaluation, where we use cheaper models
as initial judges and escalate to stronger models only when necessary -- again,
while still providing a provable guarantee of human agreement. Experimental
results show that Cascaded Selective Evaluation guarantees strong alignment
with humans, far beyond what LLM judges could achieve without selective
evaluation. For example, on a subset of Chatbot Arena where GPT-4 almost never
achieves 80% human agreement, our method, even while employing substantially
cost-effective models such as Mistral-7B, guarantees over 80% human agreement
with almost 80% test coverage.",2024-07-25,"Jaehun Jung, Faeze Brahman, Yejin Choi",http://arxiv.org/pdf/2407.18370v1,cs.CL
Robust Claim Verification Through Fact Detection,"Claim verification can be a challenging task. In this paper, we present a
method to enhance the robustness and reasoning capabilities of automated claim
verification through the extraction of short facts from evidence. Our novel
approach, FactDetect, leverages Large Language Models (LLMs) to generate
concise factual statements from evidence and label these facts based on their
semantic relevance to the claim and evidence. The generated facts are then
combined with the claim and evidence. To train a lightweight supervised model,
we incorporate a fact-detection task into the claim verification process as a
multitasking approach to improve both performance and explainability. We also
show that augmenting FactDetect in the claim verification prompt enhances
performance in zero-shot claim verification using LLMs. Our method demonstrates
competitive results in the supervised claim verification model by 15% on the F1
score when evaluated for challenging scientific claim verification datasets. We
also demonstrate that FactDetect can be augmented with claim and evidence for
zero-shot prompting (AugFactDetect) in LLMs for verdict prediction. We show
that AugFactDetect outperforms the baseline with statistical significance on
three challenging scientific claim verification datasets with an average of
17.3% performance gain compared to the best performing baselines.",2024-07-25,"Nazanin Jafari, James Allan",http://arxiv.org/pdf/2407.18367v1,cs.CL
Self-Training with Direct Preference Optimization Improves Chain-of-Thought Reasoning,"Effective training of language models (LMs) for mathematical reasoning tasks
demands high-quality supervised fine-tuning data. Besides obtaining annotations
from human experts, a common alternative is sampling from larger and more
powerful LMs. However, this knowledge distillation approach can be costly and
unstable, particularly when relying on closed-source, proprietary LMs like
GPT-4, whose behaviors are often unpredictable. In this work, we demonstrate
that the reasoning abilities of small-scale LMs can be enhanced through
self-training, a process where models learn from their own outputs. We also
show that the conventional self-training can be further augmented by a
preference learning algorithm called Direct Preference Optimization (DPO). By
integrating DPO into self-training, we leverage preference data to guide LMs
towards more accurate and diverse chain-of-thought reasoning. We evaluate our
method across various mathematical reasoning tasks using different base models.
Our experiments show that this approach not only improves LMs' reasoning
performance but also offers a more cost-effective and scalable solution
compared to relying on large proprietary LMs.",2024-07-25,"Tianduo Wang, Shichen Li, Wei Lu",http://arxiv.org/pdf/2407.18248v1,cs.CL
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,"Low-rank adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning of foundation models. Despite its
computational efficiency, LoRA still yields inferior performance compared to
full fine-tuning. In this paper, we first uncover a fundamental connection
between the optimization processes of LoRA and full fine-tuning: using LoRA for
optimization is mathematically equivalent to full fine-tuning using a low-rank
gradient for parameter updates. And this low-rank gradient can be expressed in
terms of the gradients of the two low-rank matrices in LoRA. Leveraging this
insight, we introduce LoRA-Pro, a method that enhances LoRA's performance by
strategically adjusting the gradients of these low-rank matrices. This
adjustment allows the low-rank gradient to more accurately approximate the full
fine-tuning gradient, thereby narrowing the performance gap between LoRA and
full fine-tuning. Furthermore, we theoretically derive the optimal solutions
for adjusting the gradients of the low-rank matrices, applying them during
fine-tuning in LoRA-Pro. We conduct extensive experiments across natural
language understanding, dialogue generation, mathematical reasoning, code
generation, and image classification tasks, demonstrating that LoRA-Pro
substantially improves LoRA's performance, effectively narrowing the gap with
full fine-tuning. Code is publicly available at
https://github.com/mrflogs/LoRA-Pro.",2024-07-25,"Zhengbo Wang, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",http://arxiv.org/pdf/2407.18242v3,cs.CL
Recursive Introspection: Teaching Language Model Agents How to Self-Improve,"A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.",2024-07-25,"Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar",http://arxiv.org/pdf/2407.18219v2,cs.CL
Scaling Trends in Language Model Robustness,"Language models exhibit scaling laws, whereby increasing model and dataset
size predictably decrease negative log likelihood, unlocking a dazzling array
of capabilities. At the same time, even the most capable systems are currently
vulnerable to adversarial inputs such as jailbreaks and prompt injections,
despite concerted efforts to make them robust. As compute becomes more
accessible to both attackers and defenders, which side will benefit more from
scale? We attempt to answer this question with a detailed study of robustness
on language models spanning three orders of magnitude in parameter count. From
the defender's perspective, we find that in the absence of other interventions,
increasing model size alone does not consistently improve robustness. In
adversarial training, we find that larger models are more sample-efficient and
less compute-efficient than smaller models, and often better generalize their
defense to new threat models. From the attacker's perspective, we find that
increasing attack compute smoothly and reliably increases attack success rate
against both finetuned and adversarially trained models. Finally, we show that
across model sizes studied, doubling compute on adversarial training only
forces an attacker to less than double attack compute to maintain the same
attack success rate. However, adversarial training becomes more and more
effective on larger models, suggesting that defenders could eventually have the
advantage with increasing model size. These results underscore the value of
adopting a scaling lens when discussing robustness of frontier models.",2024-07-25,"Nikolaus Howe, Ian McKenzie, Oskar Hollinsworth, Michał Zajac, Tom Tseng, Aaron Tucker, Pierre-Luc Bacon, Adam Gleave",http://arxiv.org/pdf/2407.18213v4,cs.CL
The FIGNEWS Shared Task on News Media Narratives,"We present an overview of the FIGNEWS shared task, organized as part of the
ArabicNLP 2024 conference co-located with ACL 2024. The shared task addresses
bias and propaganda annotation in multilingual news posts. We focus on the
early days of the Israel War on Gaza as a case study. The task aims to foster
collaboration in developing annotation guidelines for subjective tasks by
creating frameworks for analyzing diverse narratives highlighting potential
bias and propaganda. In a spirit of fostering and encouraging diversity, we
address the problem from a multilingual perspective, namely within five
languages: English, French, Arabic, Hebrew, and Hindi. A total of 17 teams
participated in two annotation subtasks: bias (16 teams) and propaganda (6
teams). The teams competed in four evaluation tracks: guidelines development,
annotation quality, annotation quantity, and consistency. Collectively, the
teams produced 129,800 data points. Key findings and implications for the field
are discussed.",2024-07-25,"Wajdi Zaghouani, Mustafa Jarrar, Nizar Habash, Houda Bouamor, Imed Zitouni, Mona Diab, Samhaa R. El-Beltagy, Muhammed AbuOdeh",http://arxiv.org/pdf/2407.18147v1,cs.CL
Dallah: A Dialect-Aware Multimodal Large Language Model for Arabic,"Recent advancements have significantly enhanced the capabilities of
Multimodal Large Language Models (MLLMs) in generating and understanding
image-to-text content. Despite these successes, progress is predominantly
limited to English due to the scarcity of high quality multimodal resources in
other languages. This limitation impedes the development of competitive models
in languages such as Arabic. To alleviate this situation, we introduce an
efficient Arabic multimodal assistant, dubbed Dallah, that utilizes an advanced
language model based on LLaMA-2 to facilitate multimodal interactions. Dallah
demonstrates state-of-the-art performance in Arabic MLLMs. Through fine-tuning
six Arabic dialects, Dallah showcases its capability to handle complex
dialectal interactions incorporating both textual and visual elements. The
model excels in two benchmark tests: one evaluating its performance on Modern
Standard Arabic (MSA) and another specifically designed to assess dialectal
responses. Beyond its robust performance in multimodal interaction tasks,
Dallah has the potential to pave the way for further development of
dialect-aware Arabic MLLMs.",2024-07-25,"Fakhraddin Alwajih, Gagan Bhatia, Muhammad Abdul-Mageed",http://arxiv.org/pdf/2407.18129v2,cs.CL
Tracking linguistic information in transformer-based sentence embeddings through targeted sparsification,"Analyses of transformer-based models have shown that they encode a variety of
linguistic information from their textual input. While these analyses have shed
a light on the relation between linguistic information on one side, and
internal architecture and parameters on the other, a question remains
unanswered: how is this linguistic information reflected in sentence
embeddings? Using datasets consisting of sentences with known structure, we
test to what degree information about chunks (in particular noun, verb or
prepositional phrases), such as grammatical number, or semantic role, can be
localized in sentence embeddings. Our results show that such information is not
distributed over the entire sentence embedding, but rather it is encoded in
specific regions. Understanding how the information from an input text is
compressed into sentence embeddings helps understand current transformer models
and help build future explainable neural models.",2024-07-25,"Vivi Nastase, Paola Merlo",http://arxiv.org/pdf/2407.18119v1,cs.CL
PEFT-U: Parameter-Efficient Fine-Tuning for User Personalization,"The recent emergence of Large Language Models (LLMs) has heralded a new era
of human-AI interaction. These sophisticated models, exemplified by Chat-GPT
and its successors, have exhibited remarkable capabilities in language
understanding. However, as these LLMs have undergone exponential growth, a
crucial dimension that remains understudied is the personalization of these
models. Large foundation models such as GPT-3 etc. focus on creating a
universal model that serves a broad range of tasks and users. This approach
emphasizes the model's generalization capabilities, treating users as a
collective rather than as distinct individuals. While practical for many common
applications, this one-size-fits-all approach often fails to address the rich
tapestry of human diversity and individual needs. To explore this issue we
introduce the PEFT-U Benchmark: a new dataset for building and evaluating NLP
models for user personalization. \datasetname{} consists of a series of
user-centered tasks containing diverse and individualized expressions where the
preferences of users can potentially differ for the same input. Using PEFT-U,
we explore the challenge of efficiently personalizing LLMs to accommodate
user-specific preferences in the context of diverse user-centered tasks.",2024-07-25,"Christopher Clarke, Yuzhao Heng, Lingjia Tang, Jason Mars",http://arxiv.org/pdf/2407.18078v1,cs.CL
Difficulty Estimation and Simplification of French Text Using LLMs,"We leverage generative large language models for language learning
applications, focusing on estimating the difficulty of foreign language texts
and simplifying them to lower difficulty levels. We frame both tasks as
prediction problems and develop a difficulty classification model using labeled
examples, transfer learning, and large language models, demonstrating superior
accuracy compared to previous approaches. For simplification, we evaluate the
trade-off between simplification quality and meaning preservation, comparing
zero-shot and fine-tuned performances of large language models. We show that
meaningful text simplifications can be obtained with limited fine-tuning. Our
experiments are conducted on French texts, but our methods are
language-agnostic and directly applicable to other foreign languages.",2024-07-25,"Henri Jamet, Yash Raj Shrestha, Michalis Vlachos",http://arxiv.org/pdf/2407.18061v1,cs.CL
I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition,"Music two-tower multimodal systems integrate audio and text modalities into a
joint audio-text space, enabling direct comparison between songs and their
corresponding labels. These systems enable new approaches for classification
and retrieval, leveraging both modalities. Despite the promising results they
have shown for zero-shot classification and retrieval tasks, closer inspection
of the embeddings is needed. This paper evaluates the inherent zero-shot
properties of joint audio-text spaces for the case-study of instrument
recognition. We present an evaluation and analysis of two-tower systems for
zero-shot instrument recognition and a detailed analysis of the properties of
the pre-joint and joint embeddings spaces. Our findings suggest that audio
encoders alone demonstrate good quality, while challenges remain within the
text encoder or joint space projection. Specifically, two-tower systems exhibit
sensitivity towards specific words, favoring generic prompts over musically
informed ones. Despite the large size of textual encoders, they do not yet
leverage additional textual context or infer instruments accurately from their
descriptions. Lastly, a novel approach for quantifying the semantic
meaningfulness of the textual space leveraging an instrument ontology is
proposed. This method reveals deficiencies in the systems' understanding of
instruments and provides evidence of the need for fine-tuning text encoders on
musical data.",2024-07-25,"Yannis Vasilakis, Rachel Bittner, Johan Pauwels",http://arxiv.org/pdf/2407.18058v1,cs.CL
RestoreAgent: Autonomous Image Restoration Agent via Multimodal Large Language Models,"Natural images captured by mobile devices often suffer from multiple types of
degradation, such as noise, blur, and low light. Traditional image restoration
methods require manual selection of specific tasks, algorithms, and execution
sequences, which is time-consuming and may yield suboptimal results. All-in-one
models, though capable of handling multiple tasks, typically support only a
limited range and often produce overly smooth, low-fidelity outcomes due to
their broad data distribution fitting. To address these challenges, we first
define a new pipeline for restoring images with multiple degradations, and then
introduce RestoreAgent, an intelligent image restoration system leveraging
multimodal large language models. RestoreAgent autonomously assesses the type
and extent of degradation in input images and performs restoration through (1)
determining the appropriate restoration tasks, (2) optimizing the task
sequence, (3) selecting the most suitable models, and (4) executing the
restoration. Experimental results demonstrate the superior performance of
RestoreAgent in handling complex degradation, surpassing human experts.
Furthermore, the system modular design facilitates the fast integration of new
tasks and models, enhancing its flexibility and scalability for various
applications.",2024-07-25,"Haoyu Chen, Wenbo Li, Jinjin Gu, Jingjing Ren, Sixiang Chen, Tian Ye, Renjing Pei, Kaiwen Zhou, Fenglong Song, Lei Zhu",http://arxiv.org/pdf/2407.18035v1,cs.CL
GermanPartiesQA: Benchmarking Commercial Large Language Models for Political Bias and Sycophancy,"LLMs are changing the way humans create and interact with content,
potentially affecting citizens' political opinions and voting decisions. As
LLMs increasingly shape our digital information ecosystems, auditing to
evaluate biases, sycophancy, or steerability has emerged as an active field of
research. In this paper, we evaluate and compare the alignment of six LLMs by
OpenAI, Anthropic, and Cohere with German party positions and evaluate
sycophancy based on a prompt experiment. We contribute to evaluating political
bias and sycophancy in multi-party systems across major commercial LLMs. First,
we develop the benchmark dataset GermanPartiesQA based on the Voting Advice
Application Wahl-o-Mat covering 10 state and 1 national elections between 2021
and 2023. In our study, we find a left-green tendency across all examined LLMs.
We then conduct our prompt experiment for which we use the benchmark and
sociodemographic data of leading German parliamentarians to evaluate changes in
LLMs responses. To differentiate between sycophancy and steerabilty, we use 'I
am [politician X], ...' and 'You are [politician X], ...' prompts. Against our
expectations, we do not observe notable differences between prompting 'I am'
and 'You are'. While our findings underscore that LLM responses can be
ideologically steered with political personas, they suggest that observed
changes in LLM outputs could be better described as personalization to the
given context rather than sycophancy.",2024-07-25,"Jan Batzner, Volker Stocker, Stefan Schmid, Gjergji Kasneci",http://arxiv.org/pdf/2407.18008v1,cs.CL
Keep the Cost Down: A Review on Methods to Optimize LLM' s KV-Cache Consumption,"Large Language Models (LLMs), epitomized by ChatGPT's release in late 2022,
have revolutionized various industries with their advanced language
comprehension. However, their efficiency is challenged by the Transformer
architecture's struggle with handling long texts. KV Cache has emerged as a
pivotal solution to this issue, converting the time complexity of token
generation from quadratic to linear, albeit with increased GPU memory overhead
proportional to conversation length. With the development of the LLM community
and academia, various KV Cache compression methods have been proposed. In this
review, we dissect the various properties of KV Cache and elaborate on various
methods currently used to optimize the KV Cache space usage of LLMs. These
methods span the pre-training phase, deployment phase, and inference phase, and
we summarize the commonalities and differences among these methods.
Additionally, we list some metrics for evaluating the long-text capabilities of
large language models, from both efficiency and capability perspectives. Our
review thus sheds light on the evolving landscape of LLM optimization, offering
insights into future advancements in this dynamic field. Links to the papers
mentioned in this review can be found in our Github Repo
https://github.com/zcli-charlie/Awesome-KV-Cache.",2024-07-25,"Luohe Shi, Hongyi Zhang, Yao Yao, Zuchao Li, Hai Zhao",http://arxiv.org/pdf/2407.18003v4,cs.CL
On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures,"In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.",2024-07-25,"Benedikt Hilmes, Nick Rossenbach, and Ralf Schlüter",http://arxiv.org/pdf/2407.17997v2,cs.CL
What does Kiki look like? Cross-modal associations between speech sounds and visual shapes in vision-and-language models,"Humans have clear cross-modal preferences when matching certain novel words
to visual shapes. Evidence suggests that these preferences play a prominent
role in our linguistic processing, language learning, and the origins of
signal-meaning mappings. With the rise of multimodal models in AI, such as
vision- and-language (VLM) models, it becomes increasingly important to uncover
the kinds of visio-linguistic associations these models encode and whether they
align with human representations. Informed by experiments with humans, we probe
and compare four VLMs for a well-known human cross-modal preference, the
bouba-kiki effect. We do not find conclusive evidence for this effect but
suggest that results may depend on features of the models, such as architecture
design, model size, and training details. Our findings inform discussions on
the origins of the bouba-kiki effect in human cognition and future developments
of VLMs that align well with human cross-modal associations.",2024-07-25,"Tessa Verhoef, Kiana Shahrasbi, Tom Kouwenhoven",http://arxiv.org/pdf/2407.17974v1,cs.CL
Stay Tuned: An Empirical Study of the Impact of Hyperparameters on LLM Tuning in Real-World Applications,"Fine-tuning Large Language Models (LLMs) is an effective method to enhance
their performance on downstream tasks. However, choosing the appropriate
setting of tuning hyperparameters (HPs) is a labor-intensive and
computationally expensive process. Here, we provide recommended HP
configurations for practical use-cases that represent a better starting point
for practitioners, when considering two SOTA LLMs and two commonly used tuning
methods. We describe Coverage-based Search (CBS), a process for ranking HP
configurations based on an offline extensive grid search, such that the top
ranked configurations collectively provide a practical robust recommendation
for a wide range of datasets and domains. We focus our experiments on
Llama-3-8B and Mistral-7B, as well as full fine-tuning and LoRa, conducting a
total of > 10,000 tuning experiments. Our results suggest that, in general,
Llama-3-8B and LoRA should be preferred, when possible. Moreover, we show that
for both models and tuning methods, exploring only a few HP configurations, as
recommended by our analysis, can provide excellent results in practice, making
this work a valuable resource for practitioners.",2024-07-25,"Alon Halfon, Shai Gretz, Ofir Arviv, Artem Spector, Orith Toledo-Ronen, Yoav Katz, Liat Ein-Dor, Michal Shmueli-Scheuer, Noam Slonim",http://arxiv.org/pdf/2407.18990v2,cs.CL
The Curious Case of Representational Alignment: Unravelling Visio-Linguistic Tasks in Emergent Communication,"Natural language has the universal properties of being compositional and
grounded in reality. The emergence of linguistic properties is often
investigated through simulations of emergent communication in referential
games. However, these experiments have yielded mixed results compared to
similar experiments addressing linguistic properties of human language. Here we
address representational alignment as a potential contributing factor to these
results. Specifically, we assess the representational alignment between agent
image representations and between agent representations and input images. Doing
so, we confirm that the emergent language does not appear to encode human-like
conceptual visual features, since agent image representations drift away from
inputs whilst inter-agent alignment increases. We moreover identify a strong
relationship between inter-agent alignment and topographic similarity, a common
metric for compositionality, and address its consequences. To address these
issues, we introduce an alignment penalty that prevents representational drift
but interestingly does not improve performance on a compositional
discrimination task. Together, our findings emphasise the key role
representational alignment plays in simulations of language emergence.",2024-07-25,"Tom Kouwenhoven, Max Peeperkorn, Bram van Dijk, Tessa Verhoef",http://arxiv.org/pdf/2407.17960v1,cs.CL
Positive Text Reframing under Multi-strategy Optimization,"Differing from sentiment transfer, positive reframing seeks to substitute
negative perspectives with positive expressions while preserving the original
meaning. With the emergence of pre-trained language models (PLMs), it is
possible to achieve acceptable results by fine-tuning PLMs. Nevertheless,
generating fluent, diverse and task-constrained reframing text remains a
significant challenge. To tackle this issue, a \textbf{m}ulti-\textbf{s}trategy
\textbf{o}ptimization \textbf{f}ramework (MSOF) is proposed in this paper.
Starting from the objective of positive reframing, we first design positive
sentiment reward and content preservation reward to encourage the model to
transform the negative expressions of the original text while ensuring the
integrity and consistency of the semantics. Then, different decoding
optimization approaches are introduced to improve the quality of text
generation. Finally, based on the modeling formula of positive reframing, we
propose a multi-dimensional re-ranking method that further selects candidate
sentences from three dimensions: strategy consistency, text similarity and
fluency. Extensive experiments on two Seq2Seq PLMs, BART and T5, demonstrate
our framework achieves significant improvements on unconstrained and controlled
positive reframing tasks.",2024-07-25,"Shutong Jia, Biwei Cao, Qingqing Gao, Jiuxin Cao, Bo Liu",http://arxiv.org/pdf/2407.17940v3,cs.CL
Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI,"In this paper we investigate the explainability of transformer models and
their plausibility for hate speech and counter speech detection. We compare
representatives of four different explainability approaches, i.e.,
gradient-based, perturbation-based, attention-based, and prototype-based
approaches, and analyze them quantitatively with an ablation study and
qualitatively in a user study. Results show that perturbation-based
explainability performs best, followed by gradient-based and attention-based
explainability. Prototypebased experiments did not yield useful results.
Overall, we observe that explainability strongly supports the users in better
understanding the model predictions.",2024-07-25,"Adrian Jaques Böck, Djordje Slijepčević, Matthias Zeppelzauer",http://arxiv.org/pdf/2407.20274v1,cs.CL
Modelling Multimodal Integration in Human Concept Processing with Vision-Language Models,"Text representations from language models have proven remarkably predictive
of human neural activity involved in language processing, with the recent
transformer-based models outperforming previous architectures in downstream
tasks and prediction of brain responses. However, the word representations
learnt by language-only models may be limited in that they lack sensory
information from other modalities, which several cognitive and neuroscience
studies showed to be reflected in human meaning representations. Here, we
leverage current pre-trained vision-language models (VLMs) to investigate
whether the integration of visuo-linguistic information they operate leads to
representations that are more aligned with human brain activity than those
obtained by models trained with language-only input. We focus on fMRI responses
recorded while participants read concept words in the context of either a full
sentence or a picture. Our results reveal that VLM representations correlate
more strongly than those by language-only models with activations in brain
areas functionally related to language processing. Additionally, we find that
transformer-based vision-language encoders -- e.g., LXMERT and VisualBERT --
yield more brain-aligned representations than generative VLMs, whose
autoregressive abilities do not seem to provide an advantage when modelling
single words. Finally, our ablation analyses suggest that the high brain
alignment achieved by some of the VLMs we evaluate results from semantic
information acquired specifically during multimodal pretraining as opposed to
being already encoded in their unimodal modules. Altogether, our findings
indicate an advantage of multimodal models in predicting human brain
activations, which reveals that modelling language and vision integration has
the potential to capture the multimodal nature of human concept
representations.",2024-07-25,"Anna Bavaresco, Marianne de Heer Kloots, Sandro Pezzelle, Raquel Fernández",http://arxiv.org/pdf/2407.17914v2,cs.CL
The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer,"Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.778 and an AP value of 0.426 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.",2024-07-25,"Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu",http://arxiv.org/pdf/2407.17900v5,cs.CL
A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations,"The semantic similarity between documents of a text corpus can be visualized
using map-like metaphors based on two-dimensional scatterplot layouts. These
layouts result from a dimensionality reduction on the document-term matrix or a
representation within a latent embedding, including topic models. Thereby, the
resulting layout depends on the input data and hyperparameters of the
dimensionality reduction and is therefore affected by changes in them.
Furthermore, the resulting layout is affected by changes in the input data and
hyperparameters of the dimensionality reduction. However, such changes to the
layout require additional cognitive efforts from the user. In this work, we
present a sensitivity study that analyzes the stability of these layouts
concerning (1) changes in the text corpora, (2) changes in the hyperparameter,
and (3) randomness in the initialization. Our approach has two stages: data
measurement and data analysis. First, we derived layouts for the combination of
three text corpora and six text embeddings and a grid-search-inspired
hyperparameter selection of the dimensionality reductions. Afterward, we
quantified the similarity of the layouts through ten metrics, concerning local
and global structures and class separation. Second, we analyzed the resulting
42817 tabular data points in a descriptive statistical analysis. From this, we
derived guidelines for informed decisions on the layout algorithm and highlight
specific hyperparameter settings. We provide our implementation as a Git
repository at
https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study
and results as Zenodo archive at https://doi.org/10.5281/zenodo.12772898.",2024-07-25,"Daniel Atzberger, Tim Cech, Willy Scheibel, Jürgen Döllner, Michael Behrisch, Tobias Schreck",http://arxiv.org/pdf/2407.17876v1,cs.CL
Improving Domain-Specific ASR with LLM-Generated Contextual Descriptions,"End-to-end automatic speech recognition (E2E ASR) systems have significantly
improved speech recognition through training on extensive datasets. Despite
these advancements, they still struggle to accurately recognize domain specific
words, such as proper nouns and technical terminologies. To address this
problem, we propose a method to utilize the state-of-the-art Whisper without
modifying its architecture, preserving its generalization performance while
enabling it to leverage descriptions effectively. Moreover, we propose two
additional training techniques to improve the domain specific ASR: decoder
fine-tuning, and context perturbation. We also propose a method to use a Large
Language Model (LLM) to generate descriptions with simple metadata, when
descriptions are unavailable. Our experiments demonstrate that proposed methods
notably enhance domain-specific ASR accuracy on real-life datasets, with
LLM-generated descriptions outperforming human-crafted ones in effectiveness.",2024-07-25,"Jiwon Suh, Injae Na, Woohwan Jung",http://arxiv.org/pdf/2407.17874v1,cs.CL
Is the Digital Forensics and Incident Response Pipeline Ready for Text-Based Threats in LLM Era?,"In the era of generative AI, the widespread adoption of Neural Text
Generators (NTGs) presents new cybersecurity challenges, particularly within
the realms of Digital Forensics and Incident Response (DFIR). These challenges
primarily involve the detection and attribution of sources behind advanced
attacks like spearphishing and disinformation campaigns. As NTGs evolve, the
task of distinguishing between human and NTG-authored texts becomes critically
complex. This paper rigorously evaluates the DFIR pipeline tailored for
text-based security systems, specifically focusing on the challenges of
detecting and attributing authorship of NTG-authored texts. By introducing a
novel human-NTG co-authorship text attack, termed CS-ACT, our study uncovers
significant vulnerabilities in traditional DFIR methodologies, highlighting
discrepancies between ideal scenarios and real-world conditions. Utilizing 14
diverse datasets and 43 unique NTGs, up to the latest GPT-4, our research
identifies substantial vulnerabilities in the forensic profiling phase,
particularly in attributing authorship to NTGs. Our comprehensive evaluation
points to factors such as model sophistication and the lack of distinctive
style within NTGs as significant contributors for these vulnerabilities. Our
findings underscore the necessity for more sophisticated and adaptable
strategies, such as incorporating adversarial learning, stylizing NTGs, and
implementing hierarchical attribution through the mapping of NTG lineages to
enhance source attribution. This sets the stage for future research and the
development of more resilient text-based security systems.",2024-07-25,"Avanti Bhandarkar, Ronald Wilson, Anushka Swarup, Mengdi Zhu, Damon Woodard",http://arxiv.org/pdf/2407.17870v1,cs.CL
Financial Statement Analysis with Large Language Models,"We investigate whether large language models (LLMs) can successfully perform
financial statement analysis in a way similar to a professional human analyst.
We provide standardized and anonymous financial statements to GPT4 and instruct
the model to analyze them to determine the direction of firms' future earnings.
Even without narrative or industry-specific information, the LLM outperforms
financial analysts in its ability to predict earnings changes directionally.
The LLM exhibits a relative advantage over human analysts in situations when
the analysts tend to struggle. Furthermore, we find that the prediction
accuracy of the LLM is on par with a narrowly trained state-of-the-art ML
model. LLM prediction does not stem from its training memory. Instead, we find
that the LLM generates useful narrative insights about a company's future
performance. Lastly, our trading strategies based on GPT's predictions yield a
higher Sharpe ratio and alphas than strategies based on other models. Our
results suggest that LLMs may take a central role in analysis and
decision-making.",2024-07-25,"Alex Kim, Maximilian Muhn, Valeri Nikolaev",http://arxiv.org/pdf/2407.17866v3,cs.CL
factgenie: A Framework for Span-based Evaluation of Generated Texts,"We present factgenie: a framework for annotating and visualizing word spans
in textual model outputs. Annotations can capture various span-based phenomena
such as semantic inaccuracies or irrelevant text. With factgenie, the
annotations can be collected both from human crowdworkers and large language
models. Our framework consists of a web interface for data visualization and
gathering text annotations, powered by an easily extensible codebase.",2024-07-25,"Zdeněk Kasner, Ondřej Plátek, Patrícia Schmidtová, Simone Balloccu, Ondřej Dušek",http://arxiv.org/pdf/2407.17863v1,cs.CL
Exploring Description-Augmented Dataless Intent Classification,"In this work, we introduce several schemes to leverage description-augmented
embedding similarity for dataless intent classification using current
state-of-the-art (SOTA) text embedding models. We report results of our methods
on four commonly used intent classification datasets and compare against
previous works of a similar nature. Our work shows promising results for
dataless classification scaling to a large number of unseen intents. We show
competitive results and significant improvements (+6.12\% Avg.) over strong
zero-shot baselines, all without training on labelled or task-specific data.
Furthermore, we provide qualitative error analysis of the shortfalls of this
methodology to help guide future research in this area.",2024-07-25,"Ruoyu Hu, Foaad Khosmood, Abbas Edalat",http://arxiv.org/pdf/2407.17862v1,cs.CL
Shapley Value-based Contrastive Alignment for Multimodal Information Extraction,"The rise of social media and the exponential growth of multimodal
communication necessitates advanced techniques for Multimodal Information
Extraction (MIE). However, existing methodologies primarily rely on direct
Image-Text interactions, a paradigm that often faces significant challenges due
to semantic and modality gaps between images and text. In this paper, we
introduce a new paradigm of Image-Context-Text interaction, where large
multimodal models (LMMs) are utilized to generate descriptive textual context
to bridge these gaps. In line with this paradigm, we propose a novel Shapley
Value-based Contrastive Alignment (Shap-CA) method, which aligns both
context-text and context-image pairs. Shap-CA initially applies the Shapley
value concept from cooperative game theory to assess the individual
contribution of each element in the set of contexts, texts and images towards
total semantic and modality overlaps. Following this quantitative evaluation, a
contrastive learning strategy is employed to enhance the interactive
contribution within context-text/image pairs, while minimizing the influence
across these pairs. Furthermore, we design an adaptive fusion module for
selective cross-modal fusion. Extensive experiments across four MIE datasets
demonstrate that our method significantly outperforms existing state-of-the-art
methods.",2024-07-25,"Wen Luo, Yu Xia, Shen Tianshu, Sujian Li",http://arxiv.org/pdf/2407.17854v1,cs.CL
Scaling A Simple Approach to Zero-Shot Speech Recognition,"Despite rapid progress in increasing the language coverage of automatic
speech recognition, the field is still far from covering all languages with a
known writing script. Recent work showed promising results with a zero-shot
approach requiring only a small amount of text data, however, accuracy heavily
depends on the quality of the used phonemizer which is often weak for unseen
languages. In this paper, we present MMS Zero-shot a conceptually simpler
approach based on romanization and an acoustic model trained on data in 1,078
different languages or three orders of magnitude more than prior art. MMS
Zero-shot reduces the average character error rate by a relative 46% over 100
unseen languages compared to the best previous work. Moreover, the error rate
of our approach is only 2.5x higher compared to in-domain supervised baselines,
while our approach uses no labeled data for the evaluation languages at all.",2024-07-25,"Jinming Zhao, Vineel Pratap, Michael Auli",http://arxiv.org/pdf/2407.17852v1,cs.CL
Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review,"Parkinson's disease (PD), the second most prevalent neurodegenerative
disorder worldwide, frequently presents with early-stage speech impairments.
Recent advancements in Artificial Intelligence (AI), particularly deep learning
(DL), have significantly enhanced PD diagnosis through the analysis of speech
data. Nevertheless, the progress of research is restricted by the limited
availability of publicly accessible speech-based PD datasets, primarily due to
privacy concerns. The goal of this systematic review is to explore the current
landscape of speech-based DL approaches for PD classification, based on 33
scientific works published between January 2020 and March 2024. We discuss
their available resources, capabilities, and potential limitations, and issues
related to bias, explainability, and privacy. Furthermore, this review provides
an overview of publicly accessible speech-based datasets and open-source
material for PD. The DL approaches identified are categorized into end-to-end
(E2E) learning, transfer learning (TL), and deep acoustic feature extraction
(DAFE). Among E2E approaches, Convolutional Neural Networks (CNNs) are
prevalent, though Transformers are increasingly popular. E2E approaches face
challenges such as limited data and computational resources, especially with
Transformers. TL addresses these issues by providing more robust PD diagnosis
and better generalizability across languages. DAFE aims to improve the
explainability and interpretability of results by examining the specific
effects of deep features on both other DL approaches and more traditional
machine learning (ML) methods. However, it often underperforms compared to E2E
and TL approaches.",2024-07-25,"Lisanne van Gelderen, Cristian Tejedor-García",http://arxiv.org/pdf/2407.17844v4,cs.CL
An Efficient Inference Framework for Early-exit Large Language Models,"Building efficient inference framework has gained increasing interests for
research community. Early-exit models, a variant of LLMs, improves the
inference efficiency of LLMs by skipping rest layers and directly generate
output tokens when they are confident enough. However, there is no work of LLM
inference framework that takes early-exit models into consideration. This is
non-trivial as prior art on LLM inference cannot be directly applied to
early-exit models. In this work, we solves two key challenges in building
efficient inference framework for early-exit models: (1) batch inference at
iteration-level granularity; and (2) KV cache management. For the former, we
propose to process the batch until all sequences surpass the early-exit
confidence threshold. For the latter, we propose to fill the KV cache of rest
layers before the iteration terminates. Our evaluation shows that, compared
with the original vLLM operating at full layers, our solution achieves up to
1.25x speed up.",2024-07-25,"Ruijie Miao, Yihan Yan, Xinshuo Yao, Tong Yang",http://arxiv.org/pdf/2407.20272v1,cs.CL
Unified Lexical Representation for Interpretable Visual-Language Alignment,"Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's
groundbreaking work. Although CLIP performs well, the typical direct latent
feature alignment lacks clarity in its representation and similarity scores. On
the other hand, lexical representation, a vector whose element represents the
similarity between the sample and a word from the vocabulary, is a natural
sparse representation and interpretable, providing exact matches for individual
words. However, lexical representations are difficult to learn due to no
ground-truth supervision and false-discovery issues, and thus requires complex
design to train effectively. In this paper, we introduce LexVLA, a more
interpretable VLA framework by learning a unified lexical representation for
both modalities without complex design. We use DINOv2 as our visual model for
its local-inclined features and Llama 2, a generative language model, to
leverage its in-context lexical prediction ability. To avoid the false
discovery, we propose an overuse penalty to refrain the lexical representation
from falsely frequently activating meaningless words. We demonstrate that these
two pre-trained uni-modal models can be well-aligned by fine-tuning on the
modest multi-modal dataset and avoid intricate training configurations. On
cross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal
dataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)
and those trained from scratch on even bigger datasets (e.g., 1.1B data,
including CC-12M). We conduct extensive experiments to analyze LexVLA. Codes
are available at https://github.com/Clementine24/LexVLA.",2024-07-25,"Yifan Li, Yikai Wang, Yanwei Fu, Dongyu Ru, Zheng Zhang, Tong He",http://arxiv.org/pdf/2407.17827v2,cs.CL
Demystifying Verbatim Memorization in Large Language Models,"Large Language Models (LLMs) frequently memorize long sequences verbatim,
often with serious legal and privacy implications. Much prior work has studied
such verbatim memorization using observational data. To complement such work,
we develop a framework to study verbatim memorization in a controlled setting
by continuing pre-training from Pythia checkpoints with injected sequences. We
find that (1) non-trivial amounts of repetition are necessary for verbatim
memorization to happen; (2) later (and presumably better) checkpoints are more
likely to verbatim memorize sequences, even for out-of-distribution sequences;
(3) the generation of memorized sequences is triggered by distributed model
states that encode high-level features and makes important use of general
language modeling capabilities. Guided by these insights, we develop stress
tests to evaluate unlearning methods and find they often fail to remove the
verbatim memorized information, while also degrading the LM. Overall, these
findings challenge the hypothesis that verbatim memorization stems from
specific model weights or mechanisms. Rather, verbatim memorization is
intertwined with the LM's general capabilities and thus will be very difficult
to isolate and suppress without degrading model quality.",2024-07-25,"Jing Huang, Diyi Yang, Christopher Potts",http://arxiv.org/pdf/2407.17817v1,cs.CL
Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models,"Recent advances in machine learning, particularly in Natural Language
Processing (NLP), have produced powerful models trained on vast datasets.
However, these models risk leaking sensitive information, raising privacy
concerns. In response, regulatory measures such as the European Union's General
Data Protection Regulation (GDPR) have driven increasing interest in Machine
Unlearning techniques, which enable models to selectively forget specific data
entries. Early unlearning approaches primarily relied on pre-processing
methods, while more recent research has shifted towards training-based
solutions. Despite their effectiveness, a key limitation persists: most methods
require access to original training data, which is often unavailable.
Additionally, directly applying unlearning techniques bears the cost of
undermining the model's expressive capabilities. To address these challenges,
we introduce the Iterative Contrastive Unlearning (ICU) framework, which
consists of three core components: A Knowledge Unlearning Induction module
designed to target specific knowledge for removal using an unlearning loss; A
Contrastive Learning Enhancement module to preserve the model's expressive
capabilities against the pure unlearning goal; And an Iterative Unlearning
Refinement module that dynamically adjusts the unlearning process through
ongoing evaluation and updates. Experimental results demonstrate the efficacy
of our ICU method in unlearning sensitive information while maintaining the
model's overall performance, offering a promising solution for
privacy-conscious machine learning applications.",2024-07-25,"Haoyu Tang, Ye Liu, Xi Zhao, Xukai Liu, Yanghai Zhang, Kai Zhang, Xiaofang Zhou, Enhong Chen",http://arxiv.org/pdf/2407.20271v3,cs.CL
Closing the gap between open-source and commercial large language models for medical evidence summarization,"Large language models (LLMs) hold great promise in summarizing medical
evidence. Most recent studies focus on the application of proprietary LLMs.
Using proprietary LLMs introduces multiple risk factors, including a lack of
transparency and vendor dependency. While open-source LLMs allow better
transparency and customization, their performance falls short compared to
proprietary ones. In this study, we investigated to what extent fine-tuning
open-source LLMs can further improve their performance in summarizing medical
evidence. Utilizing a benchmark dataset, MedReview, consisting of 8,161 pairs
of systematic reviews and summaries, we fine-tuned three broadly-used,
open-sourced LLMs, namely PRIMERA, LongT5, and Llama-2. Overall, the fine-tuned
LLMs obtained an increase of 9.89 in ROUGE-L (95% confidence interval:
8.94-10.81), 13.21 in METEOR score (95% confidence interval: 12.05-14.37), and
15.82 in CHRF score (95% confidence interval: 13.89-16.44). The performance of
fine-tuned LongT5 is close to GPT-3.5 with zero-shot settings. Furthermore,
smaller fine-tuned models sometimes even demonstrated superior performance
compared to larger zero-shot models. The above trends of improvement were also
manifested in both human and GPT4-simulated evaluations. Our results can be
applied to guide model selection for tasks demanding particular domain
knowledge, such as medical evidence summarization.",2024-07-25,"Gongbo Zhang, Qiao Jin, Yiliang Zhou, Song Wang, Betina R. Idnay, Yiming Luo, Elizabeth Park, Jordan G. Nestor, Matthew E. Spotnitz, Ali Soroush, Thomas Campion, Zhiyong Lu, Chunhua Weng, Yifan Peng",http://arxiv.org/pdf/2408.00588v1,cs.CL
KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models,"This paper investigates visual analogical reasoning in large multimodal
models (LMMs) compared to human adults and children. A ""visual analogy"" is an
abstract rule inferred from one image and applied to another. While benchmarks
exist for testing visual reasoning in LMMs, they require advanced skills and
omit basic visual analogies that even young children can make. Inspired by
developmental psychology, we propose a new benchmark of 4,300 visual
transformations of everyday objects to test LMMs on visual analogical reasoning
and compare them to children (ages three to five) and to adults. We structure
the evaluation into three stages: identifying what changed (e.g., color,
number, etc.), how it changed (e.g., added one object), and applying the rule
to new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and
MANTIS identify the ""what"" effectively, they struggle with quantifying the
""how"" and extrapolating this rule to new objects. In contrast, children and
adults exhibit much stronger analogical reasoning at all three stages.
Additionally, the strongest tested model, GPT-o1, performs better in tasks
involving simple surface-level visual attributes like color and size,
correlating with quicker human adult response times. Conversely, more complex
tasks such as number, rotation, and reflection, which necessitate extensive
cognitive processing and understanding of extrinsic spatial properties in the
physical world, present more significant challenges. Altogether, these findings
highlight the limitations of training models on data that primarily consists of
2D images and text.",2024-07-25,"Eunice Yiu, Maan Qraitem, Anisa Noor Majhi, Charlie Wong, Yutong Bai, Shiry Ginosar, Alison Gopnik, Kate Saenko",http://arxiv.org/pdf/2407.17773v3,cs.CL
ERIT Lightweight Multimodal Dataset for Elderly Emotion Recognition and Multimodal Fusion Evaluation,"ERIT is a novel multimodal dataset designed to facilitate research in a
lightweight multimodal fusion. It contains text and image data collected from
videos of elderly individuals reacting to various situations, as well as seven
emotion labels for each data sample. Because of the use of labeled images of
elderly users reacting emotionally, it is also facilitating research on emotion
recognition in an underrepresented age group in machine learning visual emotion
recognition. The dataset is validated through comprehensive experiments
indicating its importance in neural multimodal fusion research.",2024-07-25,"Rita Frieske, Bertram E. Shi",http://arxiv.org/pdf/2407.17772v1,cs.CL
Banyan: Improved Representation Learning with Explicit Structure,"We present Banyan, a model that efficiently learns semantic representations
by leveraging explicit hierarchical structure. While transformers excel at
scale, they struggle in low-resource settings. Conversely recent structured
models have shown promise as efficient learners, but lack performance. Banyan
bridges this gap with two key innovations: an entangled hierarchical tree
structure and diagonalized message passing, enabling it to outperform larger
transformer models with just 14 non-embedding parameters. It excels in
low-resource settings, offering a viable alternative for under-represented
languages and highlighting its potential for efficient, interpretable NLP in
resource-constrained environments.",2024-07-25,"Mattia Opper, N. Siddharth",http://arxiv.org/pdf/2407.17771v3,cs.CL
BotEval: Facilitating Interactive Human Evaluation,"Following the rapid progress in natural language processing (NLP) models,
language models are applied to increasingly more complex interactive tasks such
as negotiations and conversation moderations. Having human evaluators directly
interact with these NLP models is essential for adequately evaluating the
performance on such interactive tasks. We develop BotEval, an easily
customizable, open-source, evaluation toolkit that focuses on enabling
human-bot interactions as part of the evaluation process, as opposed to human
evaluators making judgements for a static input. BotEval balances flexibility
for customization and user-friendliness by providing templates for common use
cases that span various degrees of complexity and built-in compatibility with
popular crowdsourcing platforms. We showcase the numerous useful features of
BotEval through a study that evaluates the performance of various chatbots on
their effectiveness for conversational moderation and discuss how BotEval
differs from other annotation tools.",2024-07-25,"Hyundong Cho, Thamme Gowda, Yuyang Huang, Zixun Lu, Tianli Tong, Jonathan May",http://arxiv.org/pdf/2407.17770v1,cs.CL
Beyond Entity Alignment: Towards Complete Knowledge Graph Alignment via Entity-Relation Synergy,"Knowledge Graph Alignment (KGA) aims to integrate knowledge from multiple
sources to address the limitations of individual Knowledge Graphs (KGs) in
terms of coverage and depth. However, current KGA models fall short in
achieving a ``complete'' knowledge graph alignment. Existing models primarily
emphasize the linkage of cross-graph entities but overlook aligning relations
across KGs, thereby providing only a partial solution to KGA. The semantic
correlations embedded in relations are largely overlooked, potentially
restricting a comprehensive understanding of cross-KG signals. In this paper,
we propose to conceptualize relation alignment as an independent task and
conduct KGA by decomposing it into two distinct but highly correlated
sub-tasks: entity alignment and relation alignment. To capture the mutually
reinforcing correlations between these objectives, we propose a novel
Expectation-Maximization-based model, EREM, which iteratively optimizes both
sub-tasks. Experimental results on real-world datasets demonstrate that EREM
consistently outperforms state-of-the-art models in both entity alignment and
relation alignment tasks.",2024-07-25,"Xiaohan Fang, Chaozhuo Li, Yi Zhao, Qian Zang, Litian Zhang, Jiquan Peng, Xi Zhang, Jibing Gong",http://arxiv.org/pdf/2407.17745v1,cs.CL
Cost-effective Instruction Learning for Pathology Vision and Language Analysis,"The advent of vision-language models fosters the interactive conversations
between AI-enabled models and humans. Yet applying these models into clinics
must deal with daunting challenges around large-scale training data, financial,
and computational resources. Here we propose a cost-effective instruction
learning framework for conversational pathology named as CLOVER. CLOVER only
trains a lightweight module and uses instruction tuning while freezing the
parameters of the large language model. Instead of using costly GPT-4, we
propose well-designed prompts on GPT-3.5 for building generation-based
instructions, emphasizing the utility of pathological knowledge derived from
the Internet source. To augment the use of instructions, we construct a
high-quality set of template-based instructions in the context of digital
pathology. From two benchmark datasets, our findings reveal the strength of
hybrid-form instructions in the visual question-answer in pathology. Extensive
results show the cost-effectiveness of CLOVER in answering both open-ended and
closed-ended questions, where CLOVER outperforms strong baselines that possess
37 times more training parameters and use instruction data generated from
GPT-4. Through the instruction tuning, CLOVER exhibits robustness of few-shot
learning in the external clinical dataset. These findings demonstrate that
cost-effective modeling of CLOVER could accelerate the adoption of rapid
conversational applications in the landscape of digital pathology.",2024-07-25,"Kaitao Chen, Mianxin Liu, Fang Yan, Lei Ma, Xiaoming Shi, Lilong Wang, Xiaosong Wang, Lifeng Zhu, Zhe Wang, Mu Zhou, Shaoting Zhang",http://arxiv.org/pdf/2407.17734v1,cs.CL
Are Large Language Models Possible to Conduct Cognitive Behavioral Therapy?,"In contemporary society, the issue of psychological health has become
increasingly prominent, characterized by the diversification, complexity, and
universality of mental disorders. Cognitive Behavioral Therapy (CBT), currently
the most influential and clinically effective psychological treatment method
with no side effects, has limited coverage and poor quality in most countries.
In recent years, researches on the recognition and intervention of emotional
disorders using large language models (LLMs) have been validated, providing new
possibilities for psychological assistance therapy. However, are LLMs truly
possible to conduct cognitive behavioral therapy? Many concerns have been
raised by mental health experts regarding the use of LLMs for therapy. Seeking
to answer this question, we collected real CBT corpus from online video
websites, designed and conducted a targeted automatic evaluation framework
involving the evaluation of emotion tendency of generated text, structured
dialogue pattern and proactive inquiry ability. For emotion tendency, we
calculate the emotion tendency score of the CBT dialogue text generated by each
model. For structured dialogue pattern, we use a diverse range of automatic
evaluation metrics to compare speaking style, the ability to maintain
consistency of topic and the use of technology in CBT between different models
. As for inquiring to guide the patient, we utilize PQA (Proactive Questioning
Ability) metric. We also evaluated the CBT ability of the LLM after integrating
a CBT knowledge base to explore the help of introducing additional knowledge to
enhance the model's CBT counseling ability. Four LLM variants with excellent
performance on natural language processing are evaluated, and the experimental
result shows the great potential of LLMs in psychological counseling realm,
especially after combining with other technological means.",2024-07-25,"Hao Shen, Zihan Li, Minqiang Yang, Minghui Ni, Yongfeng Tao, Zhengyang Yu, Weihao Zheng, Chen Xu, Bin Hu",http://arxiv.org/pdf/2407.17730v1,cs.CL
Multi-group Uncertainty Quantification for Long-form Text Generation,"While large language models are rapidly moving towards consumer-facing
applications, they are often still prone to factual errors and hallucinations.
In order to reduce the potential harms that may come from these errors, it is
important for users to know to what extent they can trust an LLM when it makes
a factual claim. To this end, we study the problem of uncertainty
quantification of factual correctness in long-form natural language generation.
Given some output from a large language model, we study both uncertainty at the
level of individual claims contained within the output (via calibration) and
uncertainty across the entire output itself (via conformal prediction).
Moreover, we invoke multicalibration and multivalid conformal prediction to
ensure that such uncertainty guarantees are valid both marginally and across
distinct groups of prompts. Using the task of biography generation, we
demonstrate empirically that having access to and making use of additional
group attributes for each prompt improves both overall and group-wise
performance. As the problems of calibration, conformal prediction, and their
multi-group counterparts have not been extensively explored previously in the
context of long-form text generation, we consider these empirical results to
form a benchmark for this setting.",2024-07-25,"Terrance Liu, Zhiwei Steven Wu",http://arxiv.org/pdf/2407.21057v1,cs.CL
Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment,"Speech emotion recognition (SER) systems often struggle in real-world
environments, where ambient noise severely degrades their performance. This
paper explores a novel approach that exploits prior knowledge of testing
environments to maximize SER performance under noisy conditions. To address
this task, we propose a text-guided, environment-aware training where an SER
model is trained with contaminated speech samples and their paired noise
description. We use a pre-trained text encoder to extract the text-based
environment embedding and then fuse it to a transformer-based SER model during
training and inference. We demonstrate the effectiveness of our approach
through our experiment with the MSP-Podcast corpus and real-world additive
noise samples collected from the Freesound repository. Our experiment indicates
that the text-based environment descriptions processed by a large language
model (LLM) produce representations that improve the noise-robustness of the
SER system. In addition, our proposed approach with an LLM yields better
performance than our environment-agnostic baselines, especially in low
signal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our
proposed method shows better performance than our best baseline model by 31.8 %
(arousal), 23.5% (dominance), and 9.5% (valence).",2024-07-25,"Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso",http://arxiv.org/pdf/2407.17716v1,cs.CL
Enhancing Agent Learning through World Dynamics Modeling,"Large language models (LLMs) have been increasingly applied to tasks in
language understanding and interactive decision-making, with their impressive
performance largely attributed to the extensive domain knowledge embedded
within them. However, the depth and breadth of this knowledge can vary across
domains. Many existing approaches assume that LLMs possess a comprehensive
understanding of their environment, often overlooking potential gaps in their
grasp of actual world dynamics. To address this, we introduce Discover, Verify,
and Evolve (DiVE), a framework that discovers world dynamics from a small
number of demonstrations, verifies the accuracy of these dynamics, and evolves
new, advanced dynamics tailored to the current situation. Through extensive
evaluations, we assess the impact of each component on performance and compare
the dynamics generated by DiVE to human-annotated dynamics. Our results show
that LLMs guided by DiVE make more informed decisions, achieving rewards
comparable to human players in the Crafter environment and surpassing methods
that require prior task-specific training in the MiniHack environment.",2024-07-25,"Zhiyuan Sun, Haochen Shi, Marc-Alexandre Côté, Glen Berseth, Xingdi Yuan, Bang Liu",http://arxiv.org/pdf/2407.17695v2,cs.CL
Examining the Influence of Political Bias on Large Language Model Performance in Stance Classification,"Large Language Models (LLMs) have demonstrated remarkable capabilities in
executing tasks based on natural language queries. However, these models,
trained on curated datasets, inherently embody biases ranging from racial to
national and gender biases. It remains uncertain whether these biases impact
the performance of LLMs for certain tasks. In this study, we investigate the
political biases of LLMs within the stance classification task, specifically
examining whether these models exhibit a tendency to more accurately classify
politically-charged stances. Utilizing three datasets, seven LLMs, and four
distinct prompting schemes, we analyze the performance of LLMs on politically
oriented statements and targets. Our findings reveal a statistically
significant difference in the performance of LLMs across various politically
oriented stance classification tasks. Furthermore, we observe that this
difference primarily manifests at the dataset level, with models and prompting
schemes showing statistically similar performances across different stance
classification datasets. Lastly, we observe that when there is greater
ambiguity in the target the statement is directed towards, LLMs have poorer
stance classification accuracy.
  Code & Dataset: http://doi.org/10.5281/zenodo.12938478",2024-07-25,"Lynnette Hui Xian Ng, Iain Cruickshank, Roy Ka-Wei Lee",http://arxiv.org/pdf/2407.17688v2,cs.CL
Transformers on Markov Data: Constant Depth Suffices,"Attention-based transformers have been remarkably successful at modeling
generative processes across various domains and modalities. In this paper, we
study the behavior of transformers on data drawn from \kth Markov processes,
where the conditional distribution of the next symbol in a sequence depends on
the previous $k$ symbols observed. We observe a surprising phenomenon
empirically which contradicts previous findings: when trained for sufficiently
long, a transformer with a fixed depth and $1$ head per layer is able to
achieve low test loss on sequences drawn from \kth Markov sources, even as $k$
grows. Furthermore, this low test loss is achieved by the transformer's ability
to represent and learn the in-context conditional empirical distribution. On
the theoretical side, our main result is that a transformer with a single head
and three layers can represent the in-context conditional empirical
distribution for \kth Markov sources, concurring with our empirical
observations. Along the way, we prove that \textit{attention-only} transformers
with $O(\log_2(k))$ layers can represent the in-context conditional empirical
distribution by composing induction heads to track the previous $k$ symbols in
the sequence. These results provide more insight into our current understanding
of the mechanisms by which transformers learn to capture context, by
understanding their behavior on Markov sources.",2024-07-25,"Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva",http://arxiv.org/pdf/2407.17686v1,cs.CL
S2-Attention: Hardware-Aware Context Sharding Among Attention Heads,"Sparse attention, which selectively attends to a subset of tokens in the
context was supposed to be efficient. However, its theoretical reduction in
FLOPs has rarely translated into wall-clock speed-up over its dense attention
counterparts due to the lack of hardware-aware optimizations like
FlashAttention. Meanwhile, it remains unclear whether sparse attention can
maintain the model's quality at a scale of today's large language models (LLMs)
and how. This paper presents Sparsely-Sharded(S2) Attention, a Triton library
that provides kernel optimization for sparse attention customizable at both
per-head and per-context-range levels. S2-Attention enables the exploration of
novel and high-performance sparse attention techniques, which we demonstrate
through extensive ablations across a wide range of sparse attention designs at
various model scales. From these insights, we present several basic guidelines
to design sparse attention that can achieve not only practical efficiency
improvements, but also strong downstream performance. To achieve high
parallelization and optimized memory IO, sparse attention should shard the
context heterogeneously across attention heads, where each head attends to a
different subset of tokens while collectively covering the full context.
Meanwhile, we find hybrid architectures combining sparse and dense attention
particularly beneficial in practice. S2-Attention achieves wall-clock speedup
of 8.79X, 15.87X, 25.3X compared to the strong FlashAttention-2 baseline with
strong downstream performance on-par with full attention and perfect retrieval
performance at a 128k context length. At inference, for 7B models, our model,
with the help of our S2-Attention kernel, achieves 4.5x speed-up compared to
dense counterparts. S2-Attention is released with easy-to-customize APIs for
direct usage in Megatron and vLLM.",2024-07-25,"Xihui Lin, Yunan Zhang, Suyu Ge, Liliang Ren, Barun Patra, Vishrav Chaudhary, Hao Peng, Xia Song",http://arxiv.org/pdf/2407.17678v7,cs.CL
Time Matters: Examine Temporal Effects on Biomedical Language Models,"Time roots in applying language models for biomedical applications: models
are trained on historical data and will be deployed for new or future data,
which may vary from training data. While increasing biomedical tasks have
employed state-of-the-art language models, there are very few studies have
examined temporal effects on biomedical models when data usually shifts across
development and deployment. This study fills the gap by statistically probing
relations between language model performance and data shifts across three
biomedical tasks. We deploy diverse metrics to evaluate model performance,
distance methods to measure data drifts, and statistical methods to quantify
temporal effects on biomedical language models. Our study shows that time
matters for deploying biomedical language models, while the degree of
performance degradation varies by biomedical tasks and statistical
quantification approaches. We believe this study can establish a solid
benchmark to evaluate and assess temporal effects on deploying biomedical
language models.",2024-07-24,"Weisi Liu, Zhe He, Xiaolei Huang",http://arxiv.org/pdf/2407.17638v2,cs.CL
"IgnitionInnovators at ""Discharge Me!"": Chain-of-Thought Instruction Finetuning Large Language Models for Discharge Summaries","This paper presents our proposed approach to the Discharge Me! shared task,
collocated with the 23th Workshop on Biomedical Natural Language Processing
(BioNLP). In this work, we develop an LLM-based framework for solving the
Discharge Summary Documentation (DSD) task, i.e., generating the two critical
target sections `Brief Hospital Course' and `Discharge Instructions' in the
discharge summary. By streamlining the recent instruction-finetuning process on
LLMs, we explore several prompting strategies for optimally adapting LLMs to
specific generation task of DSD. Experimental results show that providing a
clear output structure, complimented by a set of comprehensive
Chain-of-Thoughts (CoT) questions, effectively improves the model's reasoning
capability, and thereby, enhancing the structural correctness and faithfulness
of clinical information in the generated text. Source code is available at:
https://github.com/antangrocket1312/Discharge_LLM",2024-07-24,"An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh",http://arxiv.org/pdf/2407.17636v1,cs.CL
Papilusion at DAGPap24: Paper or Illusion? Detecting AI-generated Scientific Papers,"This paper presents Papilusion, an AI-generated scientific text detector
developed within the DAGPap24 shared task on detecting automatically generated
scientific papers. We propose an ensemble-based approach and conduct ablation
studies to analyze the effect of the detector configurations on the
performance. Papilusion is ranked 6th on the leaderboard, and we improve our
performance after the competition ended, achieving 99.46 (+9.63) of the
F1-score on the official test set.",2024-07-24,"Nikita Andreev, Alexander Shirnin, Vladislav Mikhailov, Ekaterina Artemova",http://arxiv.org/pdf/2407.17629v2,cs.CL
Forecasting Credit Ratings: A Case Study where Traditional Methods Outperform Generative LLMs,"Large Language Models (LLMs) have been shown to perform well for many
downstream tasks. Transfer learning can enable LLMs to acquire skills that were
not targeted during pre-training. In financial contexts, LLMs can sometimes
beat well-established benchmarks. This paper investigates how well LLMs perform
in the task of forecasting corporate credit ratings. We show that while LLMs
are very good at encoding textual information, traditional methods are still
very competitive when it comes to encoding numeric and multimodal data. For our
task, current LLMs perform worse than a more traditional XGBoost architecture
that combines fundamental and macroeconomic data with high-density text-based
embedding features.",2024-07-24,"Felix Drinkall, Janet B. Pierrehumbert, Stefan Zohren",http://arxiv.org/pdf/2407.17624v2,cs.CL
Accelerating the Low-Rank Decomposed Models,"Tensor decomposition is a mathematically supported technique for data
compression. It consists of applying some kind of a Low Rank Decomposition
technique on the tensors or matrices in order to reduce the redundancy of the
data. However, it is not a popular technique for compressing the AI models duo
to the high number of new layers added to the architecture after decomposition.
Although the number of parameters could shrink significantly, it could result
in the model be more than twice deeper which could add some latency to the
training or inference. In this paper, we present a comprehensive study about
how to modify low rank decomposition technique in AI models so that we could
benefit from both high accuracy and low memory consumption as well as speeding
up the training and inference",2024-07-24,"Habib Hajimolahoseini, Walid Ahmed, Austin Wen, Yang Liu",http://arxiv.org/pdf/2407.20266v1,cs.CL
Coupling Speech Encoders with Downstream Text Models,"We present a modular approach to building cascade speech translation (AST)
models that guarantees that the resulting model performs no worse than the
1-best cascade baseline while preserving state-of-the-art speech recognition
(ASR) and text translation (MT) performance for a given task. Our novel
contribution is the use of an ``exporter'' layer that is trained under L2-loss
to ensure a strong match between ASR embeddings and the MT token embeddings for
the 1-best sequence. The ``exporter'' output embeddings are fed directly to the
MT model in lieu of 1-best token embeddings, thus guaranteeing that the
resulting model performs no worse than the 1-best cascade baseline, while
allowing back-propagation gradient to flow from the MT model into the ASR
components. The matched-embeddings cascade architecture provide a significant
improvement over its 1-best counterpart in scenarios where incremental training
of the MT model is not an option and yet we seek to improve quality by
leveraging (speech, transcription, translated transcription) data provided with
the AST task. The gain disappears when the MT model is incrementally trained on
the parallel text data available with the AST task. The approach holds promise
for other scenarios that seek to couple ASR encoders and immutable text models,
such at large language models (LLM).",2024-07-24,"Ciprian Chelba, Johan Schalkwyk",http://arxiv.org/pdf/2407.17605v1,cs.CL
I Could've Asked That: Reformulating Unanswerable Questions,"When seeking information from unfamiliar documents, users frequently pose
questions that cannot be answered by the documents. While existing large
language models (LLMs) identify these unanswerable questions, they do not
assist users in reformulating their questions, thereby reducing their overall
utility. We curate CouldAsk, an evaluation benchmark composed of existing and
new datasets for document-grounded question answering, specifically designed to
study reformulating unanswerable questions. We evaluate state-of-the-art
open-source and proprietary LLMs on CouldAsk. The results demonstrate the
limited capabilities of these models in reformulating questions. Specifically,
GPT-4 and Llama2-7B successfully reformulate questions only 26% and 12% of the
time, respectively. Error analysis shows that 62% of the unsuccessful
reformulations stem from the models merely rephrasing the questions or even
generating identical questions. We publicly release the benchmark and the code
to reproduce the experiments.",2024-07-24,"Wenting Zhao, Ge Gao, Claire Cardie, Alexander M. Rush",http://arxiv.org/pdf/2407.17469v1,cs.CL
WildHallucinations: Evaluating Long-form Factuality in LLMs with Real-World Entity Queries,"While hallucinations of large language models (LLMs) prevail as a major
challenge, existing evaluation benchmarks on factuality do not cover the
diverse domains of knowledge that the real-world users of LLMs seek information
about. To bridge this gap, we introduce WildHallucinations, a benchmark that
evaluates factuality. It does so by prompting LLMs to generate information
about entities mined from user-chatbot conversations in the wild. These
generations are then automatically fact-checked against a systematically
curated knowledge source collected from web search. Notably, half of these
real-world entities do not have associated Wikipedia pages. We evaluate 118,785
generations from 15 LLMs on 7,919 entities. We find that LLMs consistently
hallucinate more on entities without Wikipedia pages and exhibit varying
hallucination rates across different domains. Finally, given the same base
models, adding a retrieval component only slightly reduces hallucinations but
does not eliminate hallucinations.",2024-07-24,"Wenting Zhao, Tanya Goyal, Yu Ying Chiu, Liwei Jiang, Benjamin Newman, Abhilasha Ravichander, Khyathi Chandu, Ronan Le Bras, Claire Cardie, Yuntian Deng, Yejin Choi",http://arxiv.org/pdf/2407.17468v1,cs.CL
CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models,"Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Considering the balance between efficiency and
effectiveness, CMR can be regarded as the optimal mixture ratio. Through
extensive experiments, we ascertain the predictability of CMR, propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.",2024-07-24,"Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan",http://arxiv.org/pdf/2407.17467v2,cs.CL
Exploring Domain Robust Lightweight Reward Models based on Router Mechanism,"Recent advancements in large language models have heavily relied on the large
reward model from reinforcement learning from human feedback for fine-tuning.
However, the use of a single reward model across various domains may not always
be optimal, often requiring retraining from scratch when new domain data is
introduced. To address these challenges, we explore the utilization of small
language models operating in a domain-specific manner based on router
mechanisms. Our three approaches are: 1) utilize mixture of experts to form a
single reward model by modularizing an internal router and experts, 2)
employing external router to select the appropriate reward model from multiple
domain-specific models, and 3) the framework reduces parameter size by loading
reward models and router adapters onto a single small language model using
adapters. Experimental validation underscores the effectiveness of our
approach, demonstrating performance comparable to baseline methods while also
reducing the total parameter size.",2024-07-24,"Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, Yoonhyung Roh",http://arxiv.org/pdf/2407.17546v1,cs.CL
FLRT: Fluent Student-Teacher Redteaming,"Many publicly available language models have been safety tuned to reduce the
likelihood of toxic or liability-inducing text. To redteam or jailbreak these
models for compliance with toxic requests, users and security analysts have
developed adversarial prompting techniques. One attack method is to apply
discrete optimization techniques to the prompt. However, the resulting attack
strings are often gibberish text, easily filtered by defenders due to high
measured perplexity, and may fail for unseen tasks and/or well-tuned models. In
this work, we improve existing algorithms (primarily GCG and BEAST) to develop
powerful and fluent attacks on safety-tuned models like Llama-2 and Phi-3. Our
technique centers around a new distillation-based approach that encourages the
victim model to emulate a toxified finetune, either in terms of output
probabilities or internal activations. To encourage human-fluent attacks, we
add a multi-model perplexity penalty and a repetition penalty to the objective.
We also enhance optimizer strength by allowing token insertions, token swaps,
and token deletions and by using longer attack sequences. The resulting process
is able to reliably jailbreak the most difficult target models with prompts
that appear similar to human-written prompts. On Advbench we achieve attack
success rates $>93$% for Llama-2-7B, Llama-3-8B, and Vicuna-7B, while
maintaining model-measured perplexity $<33$; we achieve $95$% attack success
for Phi-3, though with higher perplexity. We also find a universally-optimized
single fluent prompt that induces $>88$% compliance on previously unseen tasks
across Llama-2-7B, Phi-3-mini and Vicuna-7B and transfers to other black-box
models.",2024-07-24,"T. Ben Thompson, Michael Sklar",http://arxiv.org/pdf/2407.17447v2,cs.CL
Dependency Transformer Grammars: Integrating Dependency Structures into Transformer Language Models,"Syntactic Transformer language models aim to achieve better generalization
through simultaneously modeling syntax trees and sentences. While prior work
has been focusing on adding constituency-based structures to Transformers, we
introduce Dependency Transformer Grammars (DTGs), a new class of Transformer
language model with explicit dependency-based inductive bias. DTGs simulate
dependency transition systems with constrained attention patterns by modifying
attention masks, incorporate the stack information through relative positional
encoding, and augment dependency arc representation with a combination of token
embeddings and operation embeddings. When trained on a dataset of sentences
annotated with dependency trees, DTGs achieve better generalization while
maintaining comparable perplexity with Transformer language model baselines.
DTGs also outperform recent constituency-based models, showing that dependency
can better guide Transformer language models. Our code is released at
https://github.com/zhaoyd1/Dep_Transformer_Grammars.",2024-07-24,"Yida Zhao, Chao Lou, Kewei Tu",http://arxiv.org/pdf/2407.17406v1,cs.CL
Large Language Models for Anomaly Detection in Computational Workflows: from Supervised Fine-Tuning to In-Context Learning,"Anomaly detection in computational workflows is critical for ensuring system
reliability and security. However, traditional rule-based methods struggle to
detect novel anomalies. This paper leverages large language models (LLMs) for
workflow anomaly detection by exploiting their ability to learn complex data
patterns. Two approaches are investigated: 1) supervised fine-tuning (SFT),
where pre-trained LLMs are fine-tuned on labeled data for sentence
classification to identify anomalies, and 2) in-context learning (ICL) where
prompts containing task descriptions and examples guide LLMs in few-shot
anomaly detection without fine-tuning. The paper evaluates the performance,
efficiency, generalization of SFT models, and explores zero-shot and few-shot
ICL prompts and interpretability enhancement via chain-of-thought prompting.
Experiments across multiple workflow datasets demonstrate the promising
potential of LLMs for effective anomaly detection in complex executions.",2024-07-24,"Hongwei Jin, George Papadimitriou, Krishnan Raghavan, Pawel Zuk, Prasanna Balaprakash, Cong Wang, Anirban Mandal, Ewa Deelman",http://arxiv.org/pdf/2407.17545v1,cs.CL
Reporting and Analysing the Environmental Impact of Language Models on the Example of Commonsense Question Answering with External Knowledge,"Human-produced emissions are growing at an alarming rate, causing already
observable changes in the climate and environment in general. Each year global
carbon dioxide emissions hit a new record, and it is reported that 0.5% of
total US greenhouse gas emissions are attributed to data centres as of 2021.
The release of ChatGPT in late 2022 sparked social interest in Large Language
Models (LLMs), the new generation of Language Models with a large number of
parameters and trained on massive amounts of data. Currently, numerous
companies are releasing products featuring various LLMs, with many more models
in development and awaiting release. Deep Learning research is a competitive
field, with only models that reach top performance attracting attention and
being utilized. Hence, achieving better accuracy and results is often the first
priority, while the model's efficiency and the environmental impact of the
study are neglected. However, LLMs demand substantial computational resources
and are very costly to train, both financially and environmentally. It becomes
essential to raise awareness and promote conscious decisions about algorithmic
and hardware choices. Providing information on training time, the approximate
carbon dioxide emissions and power consumption would assist future studies in
making necessary adjustments and determining the compatibility of available
computational resources with model requirements. In this study, we infused T5
LLM with external knowledge and fine-tuned the model for Question-Answering
task. Furthermore, we calculated and reported the approximate environmental
impact for both steps. The findings demonstrate that the smaller models may not
always be sustainable options, and increased training does not always imply
better performance. The most optimal outcome is achieved by carefully
considering both performance and efficiency factors.",2024-07-24,"Aida Usmanova, Junbo Huang, Debayan Banerjee, Ricardo Usbeck",http://arxiv.org/pdf/2408.01453v1,cs.CL
$T^5Score$: A Methodology for Automatically Assessing the Quality of LLM Generated Multi-Document Topic Sets,"Using LLMs for Multi-Document Topic Extraction has recently gained popularity
due to their apparent high-quality outputs, expressiveness, and ease of use.
However, most existing evaluation practices are not designed for LLM-generated
topics and result in low inter-annotator agreement scores, hindering the
reliable use of LLMs for the task. To address this, we introduce $T^5Score$, an
evaluation methodology that decomposes the quality of a topic set into
quantifiable aspects, measurable through easy-to-perform annotation tasks. This
framing enables a convenient, manual or automatic, evaluation procedure
resulting in a strong inter-annotator agreement score. To substantiate our
methodology and claims, we perform extensive experimentation on multiple
datasets and report the results.",2024-07-24,"Itamar Trainin, Omri Abend",http://arxiv.org/pdf/2407.17390v2,cs.CL
PERSONA: A Reproducible Testbed for Pluralistic Alignment,"The rapid advancement of language models (LMs) necessitates robust alignment
with diverse user values. However, current preference optimization approaches
often fail to capture the plurality of user opinions, instead reinforcing
majority viewpoints and marginalizing minority perspectives. We introduce
PERSONA, a reproducible test bed designed to evaluate and improve pluralistic
alignment of LMs. We procedurally generate diverse user profiles from US census
data, resulting in 1,586 synthetic personas with varied demographic and
idiosyncratic attributes. We then generate a large-scale evaluation dataset
containing 3,868 prompts and 317,200 feedback pairs obtained from our synthetic
personas. Leveraging this dataset, we systematically evaluate LM capabilities
in role-playing diverse users, verified through human judges, and the
establishment of both a benchmark, PERSONA Bench, for pluralistic alignment
approaches as well as an extensive dataset to create new and future benchmarks.
The full dataset and benchmarks are available here:
https://www.synthlabs.ai/research/persona.",2024-07-24,"Louis Castricato, Nathan Lile, Rafael Rafailov, Jan-Philipp Fränken, Chelsea Finn",http://arxiv.org/pdf/2407.17387v1,cs.CL
A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance,"Writing, as an omnipresent form of human communication, permeates nearly
every aspect of contemporary life. Consequently, inaccuracies or errors in
written communication can lead to profound consequences, ranging from financial
losses to potentially life-threatening situations. Spelling mistakes, among the
most prevalent writing errors, are frequently encountered due to various
factors. This research aims to identify and rectify diverse spelling errors in
text using neural networks, specifically leveraging the Bidirectional Encoder
Representations from Transformers (BERT) masked language model. To achieve this
goal, we compiled a comprehensive dataset encompassing both non-real-word and
real-word errors after categorizing different types of spelling mistakes.
Subsequently, multiple pre-trained BERT models were employed. To ensure optimal
performance in correcting misspelling errors, we propose a combined approach
utilizing the BERT masked language model and Levenshtein distance. The results
from our evaluation data demonstrate that the system presented herein exhibits
remarkable capabilities in identifying and rectifying spelling mistakes, often
surpassing existing systems tailored for the Persian language.",2024-07-24,"Amirreza Naziri, Hossein Zeinali",http://arxiv.org/pdf/2407.17383v1,cs.CL
MMRA: A Benchmark for Evaluating Multi-Granularity and Multi-Image Relational Association Capabilities in Large Visual Language Models,"Given the remarkable success that large visual language models (LVLMs) have
achieved in image perception tasks, the endeavor to make LVLMs perceive the
world like humans is drawing increasing attention. Current multi-modal
benchmarks primarily focus on facts or specific topic-related knowledge
contained within individual images. However, they often overlook the
associative relations between multiple images, which require the identification
and analysis of similarities among entities or content present in different
images. Therefore, we propose the multi-image relation association task and a
meticulously curated Multi-granularity Multi-image Relational Association
(MMRA) benchmark, comprising 1,024 samples. In order to systematically and
comprehensively evaluate current LVLMs, we establish an associational relation
system among images that contain 11 subtasks (e.g, UsageSimilarity, SubEvent)
at two granularity levels (i.e., image and entity) according to the relations
in ConceptNet. Our experiments reveal that on the MMRA benchmark, current
multi-image LVLMs exhibit distinct advantages and disadvantages across various
subtasks. Notably, fine-grained, entity-level multi-image perception tasks pose
a greater challenge for LVLMs compared to image-level tasks. Moreover, LVLMs
perform poorly on spatial-related tasks, indicating that LVLMs still have
limited spatial awareness. Additionally, our findings indicate that while LVLMs
demonstrate a strong capability to perceive image details, enhancing their
ability to associate information across multiple images hinges on improving the
reasoning capabilities of their language model component. Moreover, we explored
the ability of LVLMs to perceive image sequences within the context of our
multi-image association task. Our experiments show that the majority of current
LVLMs do not adequately model image sequences during the pre-training process.",2024-07-24,"Siwei Wu, Kang Zhu, Yu Bai, Yiming Liang, Yizhi Li, Haoning Wu, J. H. Liu, Ruibo Liu, Xingwei Qu, Xuxin Cheng, Ge Zhang, Wenhao Huang, Chenghua Lin",http://arxiv.org/pdf/2407.17379v2,cs.CL
Boosting Large Language Models with Socratic Method for Conversational Mathematics Teaching,"With the introduction of large language models (LLMs), automatic math
reasoning has seen tremendous success. However, current methods primarily focus
on providing solutions or using techniques like Chain-of-Thought to enhance
problem-solving accuracy. In this paper, we focus on improving the capability
of mathematics teaching via a Socratic teaching-based LLM
(\texttt{SocraticLLM}), which guides learners toward profound thinking with
clarity and self-discovery via conversation. We collect and release a
high-quality mathematical teaching dataset, named \texttt{SocraticMATH}, which
provides Socratic-style conversations of problems with extra knowledge. Also,
we propose a knowledge-enhanced LLM as a strong baseline to generate reliable
responses with review, guidance/heuristic, rectification, and summarization.
Experimental results show the great advantages of \texttt{SocraticLLM} by
comparing it with several strong generative models. The codes and datasets are
available on \url{https://github.com/ECNU-ICALK/SocraticMath}.",2024-07-24,"Yuyang Ding, Hanglei Hu, Jie Zhou, Qin Chen, Bo Jiang, Liang He",http://arxiv.org/pdf/2407.17349v1,cs.CL
Label Alignment and Reassignment with Generalist Large Language Model for Enhanced Cross-Domain Named Entity Recognition,"Named entity recognition on the in-domain supervised and few-shot settings
have been extensively discussed in the NLP community and made significant
progress. However, cross-domain NER, a more common task in practical scenarios,
still poses a challenge for most NER methods. Previous research efforts in that
area primarily focus on knowledge transfer such as correlate label information
from source to target domains but few works pay attention to the problem of
label conflict. In this study, we introduce a label alignment and reassignment
approach, namely LAR, to address this issue for enhanced cross-domain named
entity recognition, which includes two core procedures: label alignment between
source and target domains and label reassignment for type inference. The
process of label reassignment can significantly be enhanced by integrating with
an advanced large-scale language model such as ChatGPT. We conduct an extensive
range of experiments on NER datasets involving both supervised and zero-shot
scenarios. Empirical experimental results demonstrate the validation of our
method with remarkable performance under the supervised and zero-shot
out-of-domain settings compared to SOTA methods.",2024-07-24,"Ke Bao, Chonghuan Yang",http://arxiv.org/pdf/2407.17344v1,cs.CL
How Good (Or Bad) Are LLMs at Detecting Misleading Visualizations?,"In this study, we address the growing issue of misleading charts, a prevalent
problem that undermines the integrity of information dissemination. Misleading
charts can distort the viewer's perception of data, leading to
misinterpretations and decisions based on false information. The development of
effective automatic detection methods for misleading charts is an urgent field
of research. The recent advancement of multimodal Large Language Models (LLMs)
has introduced a promising direction for addressing this challenge. We explored
the capabilities of these models in analyzing complex charts and assessing the
impact of different prompting strategies on the models' analyses. We utilized a
dataset of misleading charts collected from the internet by prior research and
crafted nine distinct prompts, ranging from simple to complex, to test the
ability of four different multimodal LLMs in detecting over 21 different chart
issues. Through three experiments--from initial exploration to detailed
analysis--we progressively gained insights into how to effectively prompt LLMs
to identify misleading charts and developed strategies to address the
scalability challenges encountered as we expanded our detection range from the
initial five issues to 21 issues in the final experiment. Our findings reveal
that multimodal LLMs possess a strong capability for chart comprehension and
critical thinking in data interpretation. There is significant potential in
employing multimodal LLMs to counter misleading information by supporting
critical thinking and enhancing visualization literacy. This study demonstrates
the applicability of LLMs in addressing the pressing concern of misleading
charts.",2024-07-24,"Leo Yu-Ho Lo, Huamin Qu",http://arxiv.org/pdf/2407.17291v1,cs.CL
What Matters in Explanations: Towards Explainable Fake Review Detection Focusing on Transformers,"Customers' reviews and feedback play crucial role on electronic
commerce~(E-commerce) platforms like Amazon, Zalando, and eBay in influencing
other customers' purchasing decisions. However, there is a prevailing concern
that sellers often post fake or spam reviews to deceive potential customers and
manipulate their opinions about a product. Over the past decade, there has been
considerable interest in using machine learning (ML) and deep learning (DL)
models to identify such fraudulent reviews. Unfortunately, the decisions made
by complex ML and DL models - which often function as \emph{black-boxes} - can
be surprising and difficult for general users to comprehend. In this paper, we
propose an explainable framework for detecting fake reviews with high precision
in identifying fraudulent content with explanations and investigate what
information matters most for explaining particular decisions by conducting
empirical user evaluation. Initially, we develop fake review detection models
using DL and transformer models including XLNet and DistilBERT. We then
introduce layer-wise relevance propagation (LRP) technique for generating
explanations that can map the contributions of words toward the predicted
class. The experimental results on two benchmark fake review detection datasets
demonstrate that our predictive models achieve state-of-the-art performance and
outperform several existing methods. Furthermore, the empirical user evaluation
of the generated explanations concludes which important information needs to be
considered in generating explanations in the context of fake review
identification.",2024-07-24,"Md Shajalal, Md Atabuzzaman, Alexander Boden, Gunnar Stevens, Delong Du",http://arxiv.org/pdf/2407.21056v1,cs.CL
Improving ICD coding using Chapter based Named Entities and Attentional Models,"Recent advancements in natural language processing (NLP) have led to
automation in various domains. However, clinical NLP often relies on benchmark
datasets that may not reflect real-world scenarios accurately. Automatic ICD
coding, a vital NLP task, typically uses outdated and imbalanced datasets like
MIMIC-III, with existing methods yielding micro-averaged F1 scores between 0.4
and 0.7 due to many false positives. Our research introduces an enhanced
approach to ICD coding that improves F1 scores by using chapter-based named
entities and attentional models. This method categorizes discharge summaries
into ICD-9 Chapters and develops attentional models with chapter-specific data,
eliminating the need to consider external data for code identification. For
categorization, we use Chapter-IV to de-bias and influence key entities and
weights without neural networks, creating accurate thresholds and providing
interpretability for human validation. Post-validation, we develop attentional
models for three frequent and three non-frequent codes from Chapter-IV using
Bidirectional-Gated Recurrent Units (GRUs) with Attention and Transformer with
Multi-head Attention architectures. The average Micro-F1 scores of 0.79 and
0.81 from these models demonstrate significant performance improvements in ICD
coding.",2024-07-24,"Abhijith R. Beeravolu, Mirjam Jonkman, Sami Azam, Friso De Boer",http://arxiv.org/pdf/2407.17230v1,cs.CL
LEAN-GitHub: Compiling GitHub LEAN repositories for a versatile LEAN prover,"Recently, large language models have presented promising results in aiding
formal mathematical reasoning. However, their performance is restricted due to
the scarcity of formal theorem-proving data, which requires additional effort
to be extracted from raw formal language corpora. Meanwhile, a significant
amount of human-written formal language corpora remains underutilized. To
address this issue, we propose LEAN-GitHub, a dataset consisting of large-scale
formal data extracted from almost all Lean 4 repositories on GitHub. After
fine-tuning InternLM-math-plus on this dataset, our model achieved accuracies
of 48.8% with a single pass and 54.5% with 64 passes on the Lean 4 miniF2F
test, surpassing state-of-the-art method at 52%. And it also achieves
state-of-the-art on two other Lean 4 benchmarks (ProofNet and Putnam) targeting
different fields/levels of math. These results demonstrate that our proposed
dataset is beneficial for formal reasoning on a wide range of math topics. We
open-source our model at https://GitHub. com/InternLM/InternLM-Math and our
data at https://huggingface.co/ datasets/InternLM/Lean-GitHub",2024-07-24,"Zijian Wu, Jiayu Wang, Dahua Lin, Kai Chen",http://arxiv.org/pdf/2407.17227v1,cs.CL
Bailicai: A Domain-Optimized Retrieval-Augmented Generation Framework for Medical Applications,"Large Language Models (LLMs) have exhibited remarkable proficiency in natural
language understanding, prompting extensive exploration of their potential
applications across diverse domains. In the medical domain, open-source LLMs
have demonstrated moderate efficacy following domain-specific fine-tuning;
however, they remain substantially inferior to proprietary models such as GPT-4
and GPT-3.5. These open-source models encounter limitations in the
comprehensiveness of domain-specific knowledge and exhibit a propensity for
'hallucinations' during text generation. To mitigate these issues, researchers
have implemented the Retrieval-Augmented Generation (RAG) approach, which
augments LLMs with background information from external knowledge bases while
preserving the model's internal parameters. However, document noise can
adversely affect performance, and the application of RAG in the medical field
remains in its nascent stages. This study presents the Bailicai framework: a
novel integration of retrieval-augmented generation with large language models
optimized for the medical domain. The Bailicai framework augments the
performance of LLMs in medicine through the implementation of four sub-modules.
Experimental results demonstrate that the Bailicai approach surpasses existing
medical domain LLMs across multiple medical benchmarks and exceeds the
performance of GPT-3.5. Furthermore, the Bailicai method effectively attenuates
the prevalent issue of hallucinations in medical applications of LLMs and
ameliorates the noise-related challenges associated with traditional RAG
techniques when processing irrelevant or pseudo-relevant documents.",2024-07-24,"Cui Long, Yongbin Liu, Chunping Ouyang, Ying Yu",http://arxiv.org/pdf/2407.21055v1,cs.CL
Sentiment Reasoning for Healthcare,"Transparency in AI healthcare decision-making is crucial for building trust
among AI and users. Incorporating reasoning capabilities enables Large Language
Models (LLMs) to understand emotions in context, handle nuanced language, and
infer unstated sentiments. In this work, we introduce a new task -- Sentiment
Reasoning -- for both speech and text modalities, along with our proposed
multimodal multitask framework and dataset. Sentiment Reasoning is an auxiliary
task in sentiment analysis where the model predicts both the sentiment label
and generates the rationale behind it based on the input transcript. Our study
conducted on both human transcripts and Automatic Speech Recognition (ASR)
transcripts shows that Sentiment Reasoning helps improve model transparency by
providing rationale for model prediction with quality semantically comparable
to humans while also improving model performance (1% increase in both accuracy
and macro-F1) via rationale-augmented fine-tuning. Also, no significant
difference in the semantic quality of generated rationales between human and
ASR transcripts. All code, data (English-translated and Vietnamese) and models
are published online: https://github.com/leduckhai/MultiMed.",2024-07-24,"Khai-Nguyen Nguyen, Khai Le-Duc, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy",http://arxiv.org/pdf/2407.21054v3,cs.CL
NarrationDep: Narratives on Social Media For Automatic Depression Detection,"Social media posts provide valuable insight into the narrative of users and
their intentions, including providing an opportunity to automatically model
whether a social media user is depressed or not. The challenge lies in
faithfully modelling user narratives from their online social media posts,
which could potentially be useful in several different applications. We have
developed a novel and effective model called \texttt{NarrationDep}, which
focuses on detecting narratives associated with depression. By analyzing a
user's tweets, \texttt{NarrationDep} accurately identifies crucial narratives.
\texttt{NarrationDep} is a deep learning framework that jointly models
individual user tweet representations and clusters of users' tweets. As a
result, \texttt{NarrationDep} is characterized by a novel two-layer deep
learning model: the first layer models using social media text posts, and the
second layer learns semantic representations of tweets associated with a
cluster. To faithfully model these cluster representations, the second layer
incorporates a novel component that hierarchically learns from users' posts.
The results demonstrate that our framework outperforms other comparative models
including recently developed models on a variety of datasets.",2024-07-24,"Hamad Zogan, Imran Razzak, Shoaib Jameel, Guandong Xu",http://arxiv.org/pdf/2407.17174v1,cs.CL
Speech Editing -- a Summary,"With the rise of video production and social media, speech editing has become
crucial for creators to address issues like mispronunciations, missing words,
or stuttering in audio recordings. This paper explores text-based speech
editing methods that modify audio via text transcripts without manual waveform
editing. These approaches ensure edited audio is indistinguishable from the
original by altering the mel-spectrogram. Recent advancements, such as
context-aware prosody correction and advanced attention mechanisms, have
improved speech editing quality. This paper reviews state-of-the-art methods,
compares key metrics, and examines widely used datasets. The aim is to
highlight ongoing issues and inspire further research and innovation in speech
editing.",2024-07-24,"Tobias Kässmann, Yining Liu, Danni Liu",http://arxiv.org/pdf/2407.17172v1,cs.CL
Zero-Shot vs. Few-Shot Multi-Speaker TTS Using Pre-trained Czech SpeechT5 Model,"In this paper, we experimented with the SpeechT5 model pre-trained on
large-scale datasets. We pre-trained the foundation model from scratch and
fine-tuned it on a large-scale robust multi-speaker text-to-speech (TTS) task.
We tested the model capabilities in a zero- and few-shot scenario. Based on two
listening tests, we evaluated the synthetic audio quality and the similarity of
how synthetic voices resemble real voices. Our results showed that the SpeechT5
model can generate a synthetic voice for any speaker using only one minute of
the target speaker's data. We successfully demonstrated the high quality and
similarity of our synthetic voices on publicly known Czech politicians and
celebrities.",2024-07-24,"Jan Lehečka, Zdeněk Hanzlíček, Jindřich Matoušek, Daniel Tihelka",http://arxiv.org/pdf/2407.17167v1,cs.CL
A Comparative Analysis of Bilingual and Trilingual Wav2Vec Models for Automatic Speech Recognition in Multilingual Oral History Archives,"In this paper, we are comparing monolingual Wav2Vec 2.0 models with various
multilingual models to see whether we could improve speech recognition
performance on a unique oral history archive containing a lot of mixed-language
sentences. Our main goal is to push forward research on this unique dataset,
which is an extremely valuable part of our cultural heritage. Our results
suggest that monolingual speech recognition models are, in most cases, superior
to multilingual models, even when processing the oral history archive full of
mixed-language sentences from non-native speakers. We also performed the same
experiments on the public CommonVoice dataset to verify our results. We are
contributing to the research community by releasing our pre-trained models to
the public.",2024-07-24,"Jan Lehečka, Josef V. Psutka, Luboš Šmídl, Pavel Ircing, Josef Psutka",http://arxiv.org/pdf/2407.17160v1,cs.CL
SimCT: A Simple Consistency Test Protocol in LLMs Development Lifecycle,"In this work, we report our efforts to advance the standard operation
procedure of developing Large Language Models (LLMs) or LLMs-based systems or
services in industry. We introduce the concept of Large Language Model
Development Lifecycle (LDLC) and then highlight the importance of consistency
test in ensuring the delivery quality. The principled solution of consistency
test, however, is usually overlooked by industrial practitioners and not urgent
in academia, and current practical solutions are insufficiently rigours and
labor-intensive. We thus propose a simple yet effective consistency test
protocol, named SimCT. SimCT is mainly to proactively check the consistency
across different development stages of ""bare metal"" LLMs or associated services
without accessing the model artifacts, in an attempt to expedite the delivery
by reducing the back-and-forth alignment communications among multiple teams
involved in different development stages.
  Specifically, SimCT encompasses response-wise and model-wise tests. We
implement the protocol with LightGBM and Student's t-test for two components
respectively, and perform extensive experiments to substantiate the
effectiveness of SimCT and the involved components.",2024-07-24,"Fufangchen Zhao, Guoqiang Jin, Rui Zhao, Jiangheng Huang, Fei Tan",http://arxiv.org/pdf/2407.17150v2,cs.CL
SDoH-GPT: Using Large Language Models to Extract Social Determinants of Health (SDoH),"Extracting social determinants of health (SDoH) from unstructured medical
notes depends heavily on labor-intensive annotations, which are typically
task-specific, hampering reusability and limiting sharing. In this study we
introduced SDoH-GPT, a simple and effective few-shot Large Language Model (LLM)
method leveraging contrastive examples and concise instructions to extract SDoH
without relying on extensive medical annotations or costly human intervention.
It achieved tenfold and twentyfold reductions in time and cost respectively,
and superior consistency with human annotators measured by Cohen's kappa of up
to 0.92. The innovative combination of SDoH-GPT and XGBoost leverages the
strengths of both, ensuring high accuracy and computational efficiency while
consistently maintaining 0.90+ AUROC scores. Testing across three distinct
datasets has confirmed its robustness and accuracy. This study highlights the
potential of leveraging LLMs to revolutionize medical note classification,
demonstrating their capability to achieve highly accurate classifications with
significantly reduced time and cost.",2024-07-24,"Bernardo Consoli, Xizhi Wu, Song Wang, Xinyu Zhao, Yanshan Wang, Justin Rousseau, Tom Hartvigsen, Li Shen, Huanmei Wu, Yifan Peng, Qi Long, Tianlong Chen, Ying Ding",http://arxiv.org/pdf/2407.17126v1,cs.CL
To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity,"One of the major aspects contributing to the striking performance of large
language models (LLMs) is the vast amount of factual knowledge accumulated
during pre-training. Yet, many LLMs suffer from self-inconsistency, which
raises doubts about their trustworthiness and reliability. This paper focuses
on entity type ambiguity, analyzing the proficiency and consistency of
state-of-the-art LLMs in applying factual knowledge when prompted with
ambiguous entities. To do so, we propose an evaluation protocol that
disentangles knowing from applying knowledge, and test state-of-the-art LLMs on
49 ambiguous entities. Our experiments reveal that LLMs struggle with choosing
the correct entity reading, achieving an average accuracy of only 85%, and as
low as 75% with underspecified prompts. The results also reveal systematic
discrepancies in LLM behavior, showing that while the models may possess
knowledge, they struggle to apply it consistently, exhibit biases toward
preferred readings, and display self-inconsistencies. This highlights the need
to address entity ambiguity in the future for more trustworthy LLMs.",2024-07-24,"Anastasiia Sedova, Robert Litschko, Diego Frassinelli, Benjamin Roth, Barbara Plank",http://arxiv.org/pdf/2407.17125v3,cs.CL
A Survey Forest Diagram : Gain a Divergent Insight View on a Specific Research Topic,"With the exponential growth in the number of papers and the trend of AI
research, the use of Generative AI for information retrieval and
question-answering has become popular for conducting research surveys. However,
novice researchers unfamiliar with a particular field may not significantly
improve their efficiency in interacting with Generative AI because they have
not developed divergent thinking in that field. This study aims to develop an
in-depth Survey Forest Diagram that guides novice researchers in divergent
thinking about the research topic by indicating the citation clues among
multiple papers, to help expand the survey perspective for novice researchers.",2024-07-24,"Jinghong Li, Wen Gu, Koichi Ota, Shinobu Hasegawa",http://arxiv.org/pdf/2407.17081v1,cs.CL
SAFETY-J: Evaluating Safety with Critique,"The deployment of Large Language Models (LLMs) in content generation raises
significant safety concerns, particularly regarding the transparency and
interpretability of content evaluations. Current methods, primarily focused on
binary safety classifications, lack mechanisms for detailed critique, limiting
their utility for model improvement and user trust. To address these
limitations, we introduce SAFETY-J, a bilingual generative safety evaluator for
English and Chinese with critique-based judgment. SAFETY-J utilizes a robust
training dataset that includes diverse dialogues and augmented query-response
pairs to assess safety across various scenarios comprehensively. We establish
an automated meta-evaluation benchmark that objectively assesses the quality of
critiques with minimal human intervention, facilitating scalable and continuous
improvement. Additionally, SAFETY-J employs an iterative preference learning
technique to dynamically refine safety assessments based on meta-evaluations
and critiques. Our evaluations demonstrate that SAFETY-J provides more nuanced
and accurate safety evaluations, thereby enhancing both critique quality and
predictive reliability in complex content scenarios. To facilitate further
research and application, we open-source SAFETY-J's training protocols,
datasets, and code at https://github.com/GAIR-NLP/Safety-J.",2024-07-24,"Yixiu Liu, Yuxiang Zheng, Shijie Xia, Jiajun Li, Yi Tu, Chaoling Song, Pengfei Liu",http://arxiv.org/pdf/2407.17075v3,cs.CL
High Efficiency Image Compression for Large Visual-Language Models,"In recent years, large visual language models (LVLMs) have shown impressive
performance and promising generalization capability in multi-modal tasks, thus
replacing humans as receivers of visual information in various application
scenarios. In this paper, we pioneer to propose a variable bitrate image
compression framework consisting of a pre-editing module and an end-to-end
codec to achieve promising rate-accuracy performance for different LVLMs. In
particular, instead of optimizing an adaptive pre-editing network towards a
particular task or several representative tasks, we propose a new optimization
strategy tailored for LVLMs, which is designed based on the representation and
discrimination capability with token-level distortion and rank. The pre-editing
module and the variable bitrate end-to-end image codec are jointly trained by
the losses based on semantic tokens of the large model, which introduce
enhanced generalization capability for various data and tasks. {Experimental
results demonstrate that the proposed framework could efficiently achieve much
better rate-accuracy performance compared to the state-of-the-art coding
standard, Versatile Video Coding.} Meanwhile, experiments with multi-modal
tasks have revealed the robustness and generalization capability of the
proposed framework.",2024-07-24,"Binzhe Li, Shurun Wang, Shiqi Wang, Yan Ye",http://arxiv.org/pdf/2407.17060v1,cs.CL
DYNAMICQA: Tracing Internal Knowledge Conflicts in Language Models,"Knowledge-intensive language understanding tasks require Language Models
(LMs) to integrate relevant context, mitigating their inherent weaknesses, such
as incomplete or outdated knowledge. However, conflicting knowledge can be
present in the LM's parameters, termed intra-memory conflict, which can affect
a model's propensity to accept contextual knowledge. To study the effect of
intra-memory conflict on an LM's ability to accept relevant context, we utilize
two knowledge conflict measures and a novel dataset containing inherently
conflicting data, DynamicQA. This dataset includes facts with a temporal
dynamic nature where facts can change over time and disputable dynamic facts,
which can change depending on the viewpoint. DynamicQA is the first to include
real-world knowledge conflicts and provide context to study the link between
the different types of knowledge conflicts. We also evaluate several measures
on their ability to reflect the presence of intra-memory conflict: semantic
entropy and a novel coherent persuasion score. With our extensive experiments,
we verify that LMs exhibit a greater degree of intra-memory conflict with
dynamic facts compared to facts that have a single truth value. Furthermore, we
reveal that facts with intra-memory conflict are harder to update with context,
suggesting that retrieval-augmented generation will struggle with the most
commonly adapted facts.",2024-07-24,"Sara Vera Marjanović, Haeun Yu, Pepa Atanasova, Maria Maistro, Christina Lioma, Isabelle Augenstein",http://arxiv.org/pdf/2407.17023v2,cs.CL
Can Language Models Evaluate Human Written Text? Case Study on Korean Student Writing for Education,"Large language model (LLM)-based evaluation pipelines have demonstrated their
capability to robustly evaluate machine-generated text. Extending this
methodology to assess human-written text could significantly benefit
educational settings by providing direct feedback to enhance writing skills,
although this application is not straightforward. In this paper, we investigate
whether LLMs can effectively assess human-written text for educational
purposes. We collected 100 texts from 32 Korean students across 15 types of
writing and employed GPT-4-Turbo to evaluate them using grammaticality,
fluency, coherence, consistency, and relevance as criteria. Our analyses
indicate that LLM evaluators can reliably assess grammaticality and fluency, as
well as more objective types of writing, though they struggle with other
criteria and types of writing. We publicly release our dataset and feedback.",2024-07-24,"Seungyoon Kim, Seungone Kim",http://arxiv.org/pdf/2407.17022v1,cs.CL
Unveiling In-Context Learning: A Coordinate System to Understand Its Working Mechanism,"Large language models (LLMs) exhibit remarkable in-context learning (ICL)
capabilities. However, the underlying working mechanism of ICL remains poorly
understood. Recent research presents two conflicting views on ICL: One
emphasizes the impact of similar examples in the demonstrations, stressing the
need for label correctness and more shots. The other attributes it to LLMs'
inherent ability of task recognition, deeming label correctness and shot
numbers of demonstrations as not crucial. In this work, we provide a
Two-Dimensional Coordinate System that unifies both views into a systematic
framework. The framework explains the behavior of ICL through two orthogonal
variables: whether similar examples are presented in the demonstrations
(perception) and whether LLMs can recognize the task (cognition). We propose
the peak inverse rank metric to detect the task recognition ability of LLMs and
study LLMs' reactions to different definitions of similarity. Based on these,
we conduct extensive experiments to elucidate how ICL functions across each
quadrant on multiple representative classification tasks. Finally, we extend
our analyses to generation tasks, showing that our coordinate system can also
be used to interpret ICL for generation tasks effectively.",2024-07-24,"Anhao Zhao, Fanghua Ye, Jinlan Fu, Xiaoyu Shen",http://arxiv.org/pdf/2407.17011v2,cs.CL
Revisiting Who's Harry Potter: Towards Targeted Unlearning from a Causal Intervention Perspective,"This paper investigates Who's Harry Potter (WHP), a pioneering yet
insufficiently understood method for LLM unlearning. We explore it in two
steps. First, we introduce a new task of LLM targeted unlearning, where given
an unlearning target (e.g., a person) and some unlearning documents, we aim to
unlearn only the information about the target, rather than everything in the
unlearning documents. We further argue that a successful unlearning should
satisfy criteria such as not outputting gibberish, not fabricating facts about
the unlearning target, and not releasing factual information under jailbreak
attacks. Second, we construct a causal intervention framework for targeted
unlearning, where the knowledge of the unlearning target is modeled as a
confounder between LLM input and output, and the unlearning process as a
deconfounding process. This framework justifies and extends WHP, deriving a
simple unlearning algorithm that includes WHP as a special case. Experiments on
existing and new datasets show that our approach, without explicitly optimizing
for the aforementioned criteria, achieves competitive performance in all of
them. Our code is available at
https://github.com/UCSB-NLP-Chang/causal_unlearn.git.",2024-07-24,"Yujian Liu, Yang Zhang, Tommi Jaakkola, Shiyu Chang",http://arxiv.org/pdf/2407.16997v2,cs.CL
A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs,"This paper proposes a new method for preventing unsafe or otherwise low
quality large language model (LLM) outputs, by leveraging the stochasticity of
LLMs. We propose a system whereby LLM checkers vote on the acceptability of a
generated output, regenerating it if a threshold of disapproval is reached,
until sufficient checkers approve. We further propose estimators for cost and
failure rate, and based on those estimators and experimental data tailored to
the application, we propose an algorithm that achieves a desired failure rate
at the least possible cost. We demonstrate that, under these models, failure
rate decreases exponentially as a function of cost when voter count and
threshold are chosen according to the algorithm, and that the models reasonably
estimate the actual performance of such a system in action, even with limited
data.",2024-07-24,"Jake R. Watts, Joel Sokol",http://arxiv.org/pdf/2407.16994v2,cs.CL
Generative artificial intelligence in dentistry: Current approaches and future challenges,"Artificial intelligence (AI) has become a commodity for people because of the
advent of generative AI (GenAI) models that bridge the usability gap of AI by
providing a natural language interface to interact with complex models. These
GenAI models range from text generation - such as two-way chat systems - to the
generation of image or video from textual descriptions input by a user. These
advancements in AI have impacted Dentistry in multiple aspects. In dental
education, the student now has the opportunity to solve a plethora of questions
by only prompting a GenAI model and have the answer in a matter of seconds.
GenAI models can help us deliver better patient healthcare by helping
practitioners gather knowledge quickly and efficiently. Finally, GenAI can also
be used in dental research, where the applications range from new drug
discovery to assistance in academic writing. In this review, we first define
GenAI models and describe their multiple generation modalities; then, we
explain and discuss their current and potential applications in Dentistry; and
finally, we describe the challenges these new technologies impose in our area.",2024-07-24,"Fabián Villena, Claudia Véliz, Rosario García-Huidobro, Sebastián Aguayo",http://arxiv.org/pdf/2407.17532v1,cs.CL
Towards Aligning Language Models with Textual Feedback,"We present ALT (ALignment with Textual feedback), an approach that aligns
language models with user preferences expressed in text. We argue that text
offers greater expressiveness, enabling users to provide richer feedback than
simple comparative preferences and this richer feedback can lead to more
efficient and effective alignment. ALT aligns the model by conditioning its
generation on the textual feedback. Our method relies solely on language
modeling techniques and requires minimal hyper-parameter tuning, though it
still presents the main benefits of RL-based alignment algorithms and can
effectively learn from textual feedback. We explore the efficacy and efficiency
of textual feedback across different tasks such as toxicity reduction,
summarization, and dialog response generation. We find that ALT outperforms PPO
for the task of toxicity reduction while being able to match its performance on
summarization with only 20% of the samples. We also explore how ALT can be used
with feedback provided by an existing LLM where we explore an LLM providing
constrained and unconstrained textual feedback. We also outline future
directions to align models with natural language feedback.",2024-07-24,"Saüc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan",http://arxiv.org/pdf/2407.16970v3,cs.CL
Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation,"Large language models (LLMs) often inherit biases from vast amounts of
training corpora. Traditional debiasing methods, while effective to some
extent, do not completely eliminate memorized biases and toxicity in LLMs. In
this paper, we study an unlearning-based approach to debiasing in LLMs by
performing gradient ascent on hate speech against minority groups, i.e.,
minimizing the likelihood of biased or toxic content. Specifically, we propose
a mask language modeling unlearning technique, which unlearns the harmful part
of the text. This method enables LLMs to selectively forget and disassociate
from biased and harmful content. Experimental results demonstrate the
effectiveness of our approach in diminishing bias while maintaining the
language modeling abilities. Surprisingly, the results also unveil an
unexpected potential for cross-domain transfer unlearning: debiasing in one
bias form (e.g. gender) may contribute to mitigating others (e.g. race and
religion).",2024-07-24,"Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata",http://arxiv.org/pdf/2407.16951v1,cs.CL
Early screening of potential breakthrough technologies with enhanced interpretability: A patent-specific hierarchical attention network model,"Despite the usefulness of machine learning approaches for the early screening
of potential breakthrough technologies, their practicality is often hindered by
opaque models. To address this, we propose an interpretable machine learning
approach to predicting future citation counts from patent texts using a
patent-specific hierarchical attention network (PatentHAN) model. Central to
this approach are (1) a patent-specific pre-trained language model, capturing
the meanings of technical words in patent claims, (2) a hierarchical network
structure, enabling detailed analysis at the claim level, and (3) a claim-wise
self-attention mechanism, revealing pivotal claims during the screening
process. A case study of 35,376 pharmaceutical patents demonstrates the
effectiveness of our approach in early screening of potential breakthrough
technologies while ensuring interpretability. Furthermore, we conduct
additional analyses using different language models and claim types to examine
the robustness of the approach. It is expected that the proposed approach will
enhance expert-machine collaboration in identifying breakthrough technologies,
providing new insight derived from text mining into technological value.",2024-07-24,"Jaewoong Choi, Janghyeok Yoon, Changyong Lee",http://arxiv.org/pdf/2407.16939v1,cs.CL
ScholarChemQA: Unveiling the Power of Language Models in Chemical Research Question Answering,"Question Answering (QA) effectively evaluates language models' reasoning and
knowledge depth. While QA datasets are plentiful in areas like general domain
and biomedicine, academic chemistry is less explored. Chemical QA plays a
crucial role in both education and research by effectively translating complex
chemical information into readily understandable format. Addressing this gap,
we introduce ScholarChemQA, a large-scale QA dataset constructed from chemical
papers. This dataset reflects typical real-world challenges, including an
imbalanced data distribution and a substantial amount of unlabeled data that
can be potentially useful. Correspondingly, we introduce a QAMatch model,
specifically designed to effectively answer chemical questions by fully
leveraging our collected data. We first address the issue of imbalanced label
distribution by re-weighting the instance-wise loss based on the inverse
frequency of each class, ensuring minority classes are not dominated by
majority ones during optimization. Next, we utilize the unlabeled data to
enrich the learning process, generating a variety of augmentations based on a
SoftMix operation and ensuring their predictions align with the same target,
i.e., pseudo-labels. To ensure the quality of the pseudo-labels, we propose a
calibration procedure aimed at closely aligning the pseudo-label estimates of
individual samples with a desired ground truth distribution. Experiments show
that our QAMatch significantly outperforms the recent similar-scale baselines
and Large Language Models (LLMs) not only on our ScholarChemQA dataset but also
on four benchmark datasets. We hope our benchmark and model can facilitate and
promote more research on chemical QA.",2024-07-24,"Xiuying Chen, Tairan Wang, Taicheng Guo, Kehan Guo, Juexiao Zhou, Haoyang Li, Mingchen Zhuge, Jürgen Schmidhuber, Xin Gao, Xiangliang Zhang",http://arxiv.org/pdf/2407.16931v1,cs.CL
Train-Attention: Meta-Learning Where to Focus in Continual Knowledge Learning,"Previous studies on continual knowledge learning (CKL) in large language
models (LLMs) have predominantly focused on approaches such as regularization,
architectural modifications, and rehearsal techniques to mitigate catastrophic
forgetting. However, these methods naively inherit the inefficiencies of
standard training procedures, indiscriminately applying uniform weight across
all tokens, which can lead to unnecessary parameter updates and increased
forgetting. To address these shortcomings, we propose a novel CKL approach
termed Train-Attention-Augmented Language Model (TAALM), which enhances
learning efficiency by dynamically predicting and applying weights to tokens
based on their usefulness. This method employs a meta-learning framework that
optimizes token importance predictions, facilitating targeted knowledge updates
and minimizing forgetting. Also, we observe that existing benchmarks do not
clearly exhibit the trade-off between learning and retaining, therefore we
propose a new benchmark, \textsc{LAMA-ckl}, to address this issue. Through
experiments conducted on both newly introduced and established CKL benchmarks,
TAALM proves the state-of-the-art performance upon the baselines, and also
shows synergistic compatibility when integrated with previous CKL approaches.",2024-07-24,"Yeongbin Seo, Dongha Lee, Jinyoung Yeo",http://arxiv.org/pdf/2407.16920v2,cs.CL
Generation Constraint Scaling Can Mitigate Hallucination,"Addressing the issue of hallucinations in large language models (LLMs) is a
critical challenge. As the cognitive mechanisms of hallucination have been
related to memory, here we explore hallucination for LLM that is enabled with
explicit memory mechanisms. We empirically demonstrate that by simply scaling
the readout vector that constrains generation in a memory-augmented LLM
decoder, hallucination mitigation can be achieved in a training-free manner.
Our method is geometry-inspired and outperforms a state-of-the-art LLM editing
method on the task of generation of Wikipedia-like biography entries both in
terms of generation quality and runtime complexity.",2024-07-23,"Georgios Kollias, Payel Das, Subhajit Chaudhury",http://arxiv.org/pdf/2407.16908v1,cs.CL
$\textit{BenchIE}^{FL}$ : A Manually Re-Annotated Fact-Based Open Information Extraction Benchmark,"Open Information Extraction (OIE) is a field of natural language processing
that aims to present textual information in a format that allows it to be
organized, analyzed and reflected upon. Numerous OIE systems are developed,
claiming ever-increasing performance, marking the need for objective
benchmarks. BenchIE is the latest reference we know of. Despite being very well
thought out, we noticed a number of issues we believe are limiting. Therefore,
we propose $\textit{BenchIE}^{FL}$, a new OIE benchmark which fully enforces
the principles of BenchIE while containing fewer errors, omissions and
shortcomings when candidate facts are matched towards reference ones.
$\textit{BenchIE}^{FL}$ allows insightful conclusions to be drawn on the actual
performance of OIE extractors.",2024-07-23,"Fabrice Lamarche, Philippe Langlais",http://arxiv.org/pdf/2407.16860v1,cs.CL
MLLM-CompBench: A Comparative Reasoning Benchmark for Multimodal LLMs,"The ability to compare objects, scenes, or situations is crucial for
effective decision-making and problem-solving in everyday life. For instance,
comparing the freshness of apples enables better choices during grocery
shopping while comparing sofa designs helps optimize the aesthetics of our
living space. Despite its significance, the comparative capability is largely
unexplored in artificial general intelligence (AGI). In this paper, we
introduce MLLM-CompBench, a benchmark designed to evaluate the comparative
reasoning capability of multimodal large language models (MLLMs).
MLLM-CompBench mines and pairs images through visually oriented questions
covering eight dimensions of relative comparison: visual attribute, existence,
state, emotion, temporality, spatiality, quantity, and quality. We curate a
collection of around 40K image pairs using metadata from diverse vision
datasets and CLIP similarity scores. These image pairs span a broad array of
visual domains, including animals, fashion, sports, and both outdoor and indoor
scenes. The questions are carefully crafted to discern relative characteristics
between two images and are labeled by human annotators for accuracy and
relevance. We use MLLM-CompBench to evaluate recent MLLMs, including
GPT-4V(ision), Gemini-Pro, and LLaVA-1.6. Our results reveal notable
shortcomings in their comparative abilities. We believe MLLM-COMPBENCH not only
sheds light on these limitations but also establishes a solid foundation for
future enhancements in the comparative capability of MLLMs.",2024-07-23,"Jihyung Kil, Zheda Mai, Justin Lee, Zihe Wang, Kerrie Cheng, Lemeng Wang, Ye Liu, Arpita Chowdhury, Wei-Lun Chao",http://arxiv.org/pdf/2407.16837v2,cs.CL
Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach,"Retrieval Augmented Generation (RAG) has been a powerful tool for Large
Language Models (LLMs) to efficiently process overly lengthy contexts. However,
recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to
understand long contexts directly. We conduct a comprehensive comparison
between RAG and long-context (LC) LLMs, aiming to leverage the strengths of
both. We benchmark RAG and LC across various public datasets using three latest
LLMs. Results reveal that when resourced sufficiently, LC consistently
outperforms RAG in terms of average performance. However, RAG's significantly
lower cost remains a distinct advantage. Based on this observation, we propose
Self-Route, a simple yet effective method that routes queries to RAG or LC
based on model self-reflection. Self-Route significantly reduces the
computation cost while maintaining a comparable performance to LC. Our findings
provide a guideline for long-context applications of LLMs using RAG and LC.",2024-07-23,"Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky",http://arxiv.org/pdf/2407.16833v2,cs.CL
VisMin: Visual Minimal-Change Understanding,"Fine-grained understanding of objects, attributes, and relationships between
objects is crucial for visual-language models (VLMs). Existing benchmarks
primarily focus on evaluating VLMs' capability to distinguish between two very
similar captions given an image. In this paper, we introduce a new, challenging
benchmark termed Visual Minimal-Change Understanding (VisMin), which requires
models to predict the correct image-caption match given two images and two
captions. The image pair and caption pair contain minimal changes, i.e., only
one aspect changes at a time from among the following: object, attribute,
count, and spatial relation. These changes test the models' understanding of
objects, attributes (such as color, material, shape), counts, and spatial
relationships between objects. We built an automatic framework using large
language models and diffusion models, followed by a rigorous 4-step
verification process by human annotators. Empirical experiments reveal that
current VLMs exhibit notable deficiencies in understanding spatial
relationships and counting abilities. We also generate a large-scale training
dataset to finetune CLIP and Idefics2, showing significant improvements in
fine-grained understanding across benchmarks and in CLIP's general image-text
alignment. We release all resources, including the benchmark, training data,
and finetuned model checkpoints, at https://vismin.net/.",2024-07-23,"Rabiul Awal, Saba Ahmadi, Le Zhang, Aishwarya Agrawal",http://arxiv.org/pdf/2407.16772v2,cs.CL
Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack,"We introduce Lifelong ICL, a problem setting that challenges long-context
language models (LMs) to learn a sequence of language tasks through in-context
learning (ICL). We further introduce Task Haystack, an evaluation suite
dedicated to assessing and diagnosing how long-context LMs utilizes contexts in
Lifelong ICL. When given a task instruction and test inputs, long-context LMs
are expected to leverage the relevant demonstrations in the Lifelong ICL
prompt, avoid distraction and interference from other tasks, and achieve test
accuracies that are not significantly worse than those of the Single-task ICL
baseline.
  Task Haystack draws inspiration from the widely-adopted
""needle-in-a-haystack"" (NIAH) evaluation, but presents distinct new challenges.
It requires models (1) to utilize the contexts at a deeper level, rather than
resorting to simple copying and pasting; (2) to navigate through long streams
of evolving topics and tasks, proxying the complexities and dynamism of
contexts in real-world scenarios. Additionally, Task Haystack inherits the
controllability of NIAH, providing model developers with tools and
visualizations to identify model vulnerabilities effectively.
  We benchmark 14 long-context LMs using Task Haystack, finding that frontier
models like GPT-4o still struggle with the setting, failing on 15% of cases on
average. Most open-weight models further lack behind by a large margin, with
failure rates reaching up to 61%. In our controlled analysis, we identify
factors such as distraction and recency bias as contributors to these failure
cases. Further, performance declines when task instructions are paraphrased at
test time or when ICL demonstrations are repeated excessively, raising concerns
about the robustness, instruction understanding, and true context utilization
of long-context LMs.",2024-07-23,"Xiaoyue Xu, Qinyuan Ye, Xiang Ren",http://arxiv.org/pdf/2407.16695v2,cs.CL
Explanation Regularisation through the Lens of Attributions,"Explanation regularisation (ER) has been introduced as a way to guide text
classifiers to form their predictions relying on input tokens that humans
consider plausible. This is achieved by introducing an auxiliary explanation
loss that measures how well the output of an input attribution technique for
the model agrees with human-annotated rationales. The guidance appears to
benefit performance in out-of-domain (OOD) settings, presumably due to an
increased reliance on ""plausible"" tokens. However, previous work has
under-explored the impact of guidance on that reliance, particularly when
reliance is measured using attribution techniques different from those used to
guide the model. In this work, we seek to close this gap, and also explore the
relationship between reliance on plausible features and OOD performance. We
find that the connection between ER and the ability of a classifier to rely on
plausible features has been overstated and that a stronger reliance on
plausible tokens does not seem to be the cause for OOD improvements.",2024-07-23,"Pedro Ferreira, Ivan Titov, Wilker Aziz",http://arxiv.org/pdf/2407.16693v3,cs.CL
Can Large Language Models Automatically Jailbreak GPT-4V?,"GPT-4V has attracted considerable attention due to its extraordinary capacity
for integrating and processing multimodal information. At the same time, its
ability of face recognition raises new safety concerns of privacy leakage.
Despite researchers' efforts in safety alignment through RLHF or preprocessing
filters, vulnerabilities might still be exploited. In our study, we introduce
AutoJailbreak, an innovative automatic jailbreak technique inspired by prompt
optimization. We leverage Large Language Models (LLMs) for red-teaming to
refine the jailbreak prompt and employ weak-to-strong in-context learning
prompts to boost efficiency. Furthermore, we present an effective search method
that incorporates early stopping to minimize optimization time and token
expenditure. Our experiments demonstrate that AutoJailbreak significantly
surpasses conventional methods, achieving an Attack Success Rate (ASR)
exceeding 95.3\%. This research sheds light on strengthening GPT-4V security,
underscoring the potential for LLMs to be exploited in compromising GPT-4V
integrity.",2024-07-23,"Yuanwei Wu, Yue Huang, Yixin Liu, Xiang Li, Pan Zhou, Lichao Sun",http://arxiv.org/pdf/2407.16686v2,cs.CL
OpenHands: An Open Platform for AI Software Developers as Generalist Agents,"Software is one of the most powerful tools that we humans have at our
disposal; it allows a skilled programmer to interact with the world in complex
and profound ways. At the same time, thanks to improvements in large language
models (LLMs), there has also been a rapid development in AI agents that
interact with and affect change in their surrounding environments. In this
paper, we introduce OpenHands (f.k.a. OpenDevin), a platform for the
development of powerful and flexible AI agents that interact with the world in
similar ways to those of a human developer: by writing code, interacting with a
command line, and browsing the web. We describe how the platform allows for the
implementation of new agents, safe interaction with sandboxed environments for
code execution, coordination between multiple agents, and incorporation of
evaluation benchmarks. Based on our currently incorporated benchmarks, we
perform an evaluation of agents over 15 challenging tasks, including software
engineering (e.g., SWE-BENCH) and web browsing (e.g., WEBARENA), among others.
Released under the permissive MIT license, OpenHands is a community project
spanning academia and industry with more than 2.1K contributions from over 188
contributors.",2024-07-23,"Xingyao Wang, Boxuan Li, Yufan Song, Frank F. Xu, Xiangru Tang, Mingchen Zhuge, Jiayi Pan, Yueqi Song, Bowen Li, Jaskirat Singh, Hoang H. Tran, Fuqiang Li, Ren Ma, Mingzhang Zheng, Bill Qian, Yanjun Shao, Niklas Muennighoff, Yizhe Zhang, Binyuan Hui, Junyang Lin, Robert Brennan, Hao Peng, Heng Ji, Graham Neubig",http://arxiv.org/pdf/2407.16741v3,cs.CL
RedAgent: Red Teaming Large Language Models with Context-aware Autonomous Language Agent,"Recently, advanced Large Language Models (LLMs) such as GPT-4 have been
integrated into many real-world applications like Code Copilot. These
applications have significantly expanded the attack surface of LLMs, exposing
them to a variety of threats. Among them, jailbreak attacks that induce toxic
responses through jailbreak prompts have raised critical safety concerns. To
identify these threats, a growing number of red teaming approaches simulate
potential adversarial scenarios by crafting jailbreak prompts to test the
target LLM. However, existing red teaming methods do not consider the unique
vulnerabilities of LLM in different scenarios, making it difficult to adjust
the jailbreak prompts to find context-specific vulnerabilities. Meanwhile,
these methods are limited to refining jailbreak templates using a few mutation
operations, lacking the automation and scalability to adapt to different
scenarios. To enable context-aware and efficient red teaming, we abstract and
model existing attacks into a coherent concept called ""jailbreak strategy"" and
propose a multi-agent LLM system named RedAgent that leverages these strategies
to generate context-aware jailbreak prompts. By self-reflecting on contextual
feedback in an additional memory buffer, RedAgent continuously learns how to
leverage these strategies to achieve effective jailbreaks in specific contexts.
Extensive experiments demonstrate that our system can jailbreak most black-box
LLMs in just five queries, improving the efficiency of existing red teaming
methods by two times. Additionally, RedAgent can jailbreak customized LLM
applications more efficiently. By generating context-aware jailbreak prompts
towards applications on GPTs, we discover 60 severe vulnerabilities of these
real-world applications with only two queries per vulnerability. We have
reported all found issues and communicated with OpenAI and Meta for bug fixes.",2024-07-23,"Huiyu Xu, Wenhui Zhang, Zhibo Wang, Feng Xiao, Rui Zheng, Yunhe Feng, Zhongjie Ba, Kui Ren",http://arxiv.org/pdf/2407.16667v1,cs.CL
Towards scalable efficient on-device ASR with transfer learning,"Multilingual pretraining for transfer learning significantly boosts the
robustness of low-resource monolingual ASR models. This study systematically
investigates three main aspects: (a) the impact of transfer learning on model
performance during initial training or fine-tuning, (b) the influence of
transfer learning across dataset domains and languages, and (c) the effect on
rare-word recognition compared to non-rare words. Our finding suggests that
RNNT-loss pretraining, followed by monolingual fine-tuning with Minimum Word
Error Rate (MinWER) loss, consistently reduces Word Error Rates (WER) across
languages like Italian and French. WER Reductions (WERR) reach 36.2% and 42.8%
compared to monolingual baselines for MLS and in-house datasets. Out-of-domain
pretraining leads to 28% higher WERR than in-domain pretraining. Both rare and
non-rare words benefit, with rare words showing greater improvements with
out-of-domain pretraining, and non-rare words with in-domain pretraining.",2024-07-23,"Laxmi Pandey, Ke Li, Jinxi Guo, Debjyoti Paul, Arthur Guo, Jay Mahadeokar, Xuedong Zhang",http://arxiv.org/pdf/2407.16664v1,cs.CL
A Survey of Text Style Transfer: Applications and Ethical Implications,"Text style transfer (TST) is an important task in controllable text
generation, which aims to control selected attributes of language use, such as
politeness, formality, or sentiment, without altering the style-independent
content of the text. The field has received considerable research attention in
recent years and has already been covered in several reviews, but the focus has
mostly been on the development of new algorithms and learning from different
types of data (supervised, unsupervised, out-of-domain, etc.) and not so much
on the application side. However, TST-related technologies are gradually
reaching a production- and deployment-ready level, and therefore, the inclusion
of the application perspective in TST research becomes crucial. Similarly, the
often overlooked ethical considerations of TST technology have become a
pressing issue. This paper presents a comprehensive review of TST applications
that have been researched over the years, using both traditional linguistic
approaches and more recent deep learning methods. We discuss current
challenges, future research directions, and ethical implications of TST
applications in text generation. By providing a holistic overview of the
landscape of TST applications, we hope to stimulate further research and
contribute to a better understanding of the potential as well as ethical
considerations associated with TST.",2024-07-23,"Sourabrata Mukherjee, Mateusz Lango, Zdenek Kasner, Ondrej Dušek",http://arxiv.org/pdf/2407.16737v1,cs.CL
Course-Correction: Safety Alignment Using Synthetic Preferences,"The risk of harmful content generated by large language models (LLMs) becomes
a critical concern. This paper presents a systematic study on assessing and
improving LLMs' capability to perform the task of \textbf{course-correction},
\ie, the model can steer away from generating harmful content autonomously. To
start with, we introduce the \textsc{C$^2$-Eval} benchmark for quantitative
assessment and analyze 10 popular LLMs, revealing varying proficiency of
current safety-tuned LLMs in course-correction. To improve, we propose
fine-tuning LLMs with preference learning, emphasizing the preference for
timely course-correction. Using an automated pipeline, we create
\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to
teach models the concept of timely course-correction through data-driven
preference learning. Experiments on 2 LLMs, \textsc{Llama2-Chat 7B} and
\textsc{Qwen2 7B}, show that our method effectively enhances course-correction
skills without affecting general performance. Additionally, it effectively
improves LLMs' safety, particularly in resisting jailbreak attacks.",2024-07-23,"Rongwu Xu, Yishuo Cai, Zhenhong Zhou, Renjie Gu, Haiqin Weng, Yan Liu, Tianwei Zhang, Wei Xu, Han Qiu",http://arxiv.org/pdf/2407.16637v2,cs.CL
Semantic Change Characterization with LLMs using Rhetorics,"Languages continually evolve in response to societal events, resulting in new
terms and shifts in meanings. These changes have significant implications for
computer applications, including automatic translation and chatbots, making it
essential to characterize them accurately. The recent development of LLMs has
notably advanced natural language understanding, particularly in sense
inference and reasoning. In this paper, we investigate the potential of LLMs in
characterizing three types of semantic change: dimension, relation, and
orientation. We achieve this by combining LLMs' Chain-of-Thought with
rhetorical devices and conducting an experimental assessment of our approach
using newly created datasets. Our results highlight the effectiveness of LLMs
in capturing and analyzing semantic changes, providing valuable insights to
improve computational linguistic applications.",2024-07-23,"Jader Martins Camboim de Sá, Marcos Da Silveira, Cédric Pruski",http://arxiv.org/pdf/2407.16624v1,cs.CL
Lawma: The Power of Specialization for Legal Annotation,"Annotation and classification of legal text are central components of
empirical legal research. Traditionally, these tasks are often delegated to
trained research assistants. Motivated by the advances in language modeling,
empirical legal scholars are increasingly turning to prompting commercial
models, hoping that it will alleviate the significant cost of human annotation.
Despite growing use, our understanding of how to best utilize large language
models for legal annotation remains limited. To bridge this gap, we introduce
CaselawQA, a benchmark comprising 260 legal annotation tasks, nearly all new to
the machine learning community. We demonstrate that commercial models, such as
GPT-4.5 and Claude 3.7 Sonnet, achieve non-trivial yet highly variable
accuracy, generally falling short of the performance required for legal work.
We then demonstrate that small, lightly fine-tuned models outperform commercial
models. A few hundred to a thousand labeled examples are usually enough to
achieve higher accuracy. Our work points to a viable alternative to the
predominant practice of prompting commercial models. For concrete legal
annotation tasks with some available labeled data, researchers are likely
better off using a fine-tuned open-source model.",2024-07-23,"Ricardo Dominguez-Olmedo, Vedant Nanda, Rediet Abebe, Stefan Bechtold, Christoph Engel, Jens Frankenreiter, Krishna Gummadi, Moritz Hardt, Michael Livermore",http://arxiv.org/pdf/2407.16615v2,cs.CL
Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?,"The pretraining data of today's strongest language models is opaque; in
particular, little is known about the proportions of various domains or
languages represented. In this work, we tackle a task which we call data
mixture inference, which aims to uncover the distributional make-up of training
data. We introduce a novel attack based on a previously overlooked source of
information: byte-pair encoding (BPE) tokenizers, used by the vast majority of
modern language models. Our key insight is that the ordered list of merge rules
learned by a BPE tokenizer naturally reveals information about the token
frequencies in its training data. Given a tokenizer's merge list along with
example data for each category of interest, we formulate a linear program that
solves for the proportion of each category in the tokenizer's training set. In
controlled experiments, we show that our attack recovers mixture ratios with
high precision for tokenizers trained on known mixtures of natural languages,
programming languages, and data sources. We then apply our approach to
off-the-shelf tokenizers released with recent LMs. We confirm much publicly
disclosed information about these models, and also make several new inferences:
GPT-4o and Mistral NeMo's tokenizers are much more multilingual than their
predecessors, training on 39% and 47% non-English language data, respectively;
Llama 3 extends GPT-3.5's tokenizer primarily for multilingual (48%) use;
GPT-3.5's and Claude's tokenizers are trained on predominantly code (~60%). We
hope our work sheds light on current design practices for pretraining data, and
inspires continued research into data mixture inference for LMs.",2024-07-23,"Jonathan Hayase, Alisa Liu, Yejin Choi, Sewoong Oh, Noah A. Smith",http://arxiv.org/pdf/2407.16607v4,cs.CL
Shared Imagination: LLMs Hallucinate Alike,"Despite the recent proliferation of large language models (LLMs), their
training recipes -- model architecture, pre-training data and optimization
algorithm -- are often very similar. This naturally raises the question of the
similarity among the resulting models. In this paper, we propose a novel
setting, imaginary question answering (IQA), to better understand model
similarity. In IQA, we ask one model to generate purely imaginary questions
(e.g., on completely made-up concepts in physics) and prompt another model to
answer. Surprisingly, despite the total fictionality of these questions, all
models can answer each other's questions with remarkable success, suggesting a
""shared imagination space"" in which these models operate during such
hallucinations. We conduct a series of investigations into this phenomenon and
discuss implications on model homogeneity, hallucination, and computational
creativity.",2024-07-23,"Yilun Zhou, Caiming Xiong, Silvio Savarese, Chien-Sheng Wu",http://arxiv.org/pdf/2407.16604v1,cs.CL
A Comparative Study on Patient Language across Therapeutic Domains for Effective Patient Voice Classification in Online Health Discussions,"There exists an invisible barrier between healthcare professionals'
perception of a patient's clinical experience and the reality. This barrier may
be induced by the environment that hinders patients from sharing their
experiences openly with healthcare professionals. As patients are observed to
discuss and exchange knowledge more candidly on social media, valuable insights
can be leveraged from these platforms. However, the abundance of non-patient
posts on social media necessitates filtering out such irrelevant content to
distinguish the genuine voices of patients, a task we refer to as patient voice
classification. In this study, we analyse the importance of linguistic
characteristics in accurately classifying patient voices. Our findings
underscore the essential role of linguistic and statistical text similarity
analysis in identifying common patterns among patient groups. These results
allude to even starker differences in the way patients express themselves at a
disease level and across various therapeutic domains. Additionally, we
fine-tuned a pre-trained Language Model on the combined datasets with similar
linguistic patterns, resulting in a highly accurate automatic patient voice
classification. Being the pioneering study on the topic, our focus on
extracting authentic patient experiences from social media stands as a crucial
step towards advancing healthcare standards and fostering a patient-centric
approach.",2024-07-23,"Giorgos Lysandrou, Roma English Owen, Vanja Popovic, Grant Le Brun, Aryo Pradipta Gema, Beatrice Alex, Elizabeth A. L. Fairley",http://arxiv.org/pdf/2407.16593v1,cs.CL
TLCR: Token-Level Continuous Reward for Fine-grained Reinforcement Learning from Human Feedback,"Reinforcement Learning from Human Feedback (RLHF) leverages human preference
data to train language models to align more closely with human essence. These
human preference data, however, are labeled at the sequence level, creating a
mismatch between sequence-level preference labels and tokens, which are
autoregressively generated from the language model. Although several recent
approaches have tried to provide token-level (i.e., dense) rewards for each
individual token, these typically rely on predefined discrete reward values
(e.g., positive: +1, negative: -1, neutral: 0), failing to account for varying
degrees of preference inherent to each token. To address this limitation, we
introduce TLCR (Token-Level Continuous Reward) for RLHF, which incorporates a
discriminator trained to distinguish positive and negative tokens, and the
confidence of the discriminator is used to assign continuous rewards to each
token considering the context. Extensive experiments show that our proposed
TLCR leads to consistent performance improvements over previous sequence-level
or token-level discrete rewards on open-ended generation benchmarks.",2024-07-23,"Eunseop Yoon, Hee Suk Yoon, SooHwan Eom, Gunsoo Han, Daniel Wontae Nam, Daejin Jo, Kyoung-Woon On, Mark A. Hasegawa-Johnson, Sungwoong Kim, Chang D. Yoo",http://arxiv.org/pdf/2407.16574v2,cs.CL
"Retrieve, Generate, Evaluate: A Case Study for Medical Paraphrases Generation with Small Language Models","Recent surge in the accessibility of large language models (LLMs) to the
general population can lead to untrackable use of such models for
medical-related recommendations. Language generation via LLMs models has two
key problems: firstly, they are prone to hallucination and therefore, for any
medical purpose they require scientific and factual grounding; secondly, LLMs
pose tremendous challenge to computational resources due to their gigantic
model size. In this work, we introduce pRAGe, a pipeline for Retrieval
Augmented Generation and evaluation of medical paraphrases generation using
Small Language Models (SLM). We study the effectiveness of SLMs and the impact
of external knowledge base for medical paraphrase generation in French.",2024-07-23,"Ioana Buhnila, Aman Sinha, Mathieu Constant",http://arxiv.org/pdf/2407.16565v1,cs.CL
Quantifying the Role of Textual Predictability in Automatic Speech Recognition,"A long-standing question in automatic speech recognition research is how to
attribute errors to the ability of a model to model the acoustics, versus its
ability to leverage higher-order context (lexicon, morphology, syntax,
semantics). We validate a novel approach which models error rates as a function
of relative textual predictability, and yields a single number, $k$, which
measures the effect of textual predictability on the recognizer. We use this
method to demonstrate that a Wav2Vec 2.0-based model makes greater stronger use
of textual context than a hybrid ASR model, in spite of not using an explicit
language model, and also use it to shed light on recent results demonstrating
poor performance of standard ASR systems on African-American English. We
demonstrate that these mostly represent failures of acoustic--phonetic
modelling. We show how this approach can be used straightforwardly in
diagnosing and improving ASR.",2024-07-23,"Sean Robertson, Gerald Penn, Ewan Dunbar",http://arxiv.org/pdf/2407.16537v2,cs.CL
Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models,"Vision language models (VLMs) demonstrate impressive capabilities in visual
question answering and image captioning, acting as a crucial link between
visual and language models. However, existing open-source VLMs heavily rely on
pretrained and frozen vision encoders (such as CLIP). Despite CLIP's robustness
across diverse domains, it still exhibits non-negligible image understanding
errors. These errors propagate to the VLM responses, resulting in sub-optimal
performance. In our work, we propose an efficient and robust method for
updating vision encoders within VLMs. Our approach selectively and locally
updates encoders, leading to substantial performance improvements on data where
previous mistakes occurred, while maintaining overall robustness. Furthermore,
we demonstrate the effectiveness of our method during continual few-shot
updates. Theoretical grounding, generality, and computational efficiency
characterize our approach.",2024-07-23,"Aristeidis Panos, Rahaf Aljundi, Daniel Olmeda Reino, Richard E Turner",http://arxiv.org/pdf/2407.16526v1,cs.CL
AMONGAGENTS: Evaluating Large Language Models in the Interactive Text-Based Social Deduction Game,"Strategic social deduction games serve as valuable testbeds for evaluating
the understanding and inference skills of language models, offering crucial
insights into social science, artificial intelligence, and strategic gaming.
This paper focuses on creating proxies of human behavior in simulated
environments, with Among Us utilized as a tool for studying simulated human
behavior. The study introduces a text-based game environment, named
AmongAgents, that mirrors the dynamics of Among Us. Players act as crew members
aboard a spaceship, tasked with identifying impostors who are sabotaging the
ship and eliminating the crew. Within this environment, the behavior of
simulated language agents is analyzed. The experiments involve diverse game
sequences featuring different configurations of Crewmates and Impostor
personality archetypes. Our work demonstrates that state-of-the-art large
language models (LLMs) can effectively grasp the game rules and make decisions
based on the current context. This work aims to promote further exploration of
LLMs in goal-oriented games with incomplete information and complex action
spaces, as these settings offer valuable opportunities to assess language model
performance in socially driven scenarios.",2024-07-23,"Yizhou Chi, Lingjun Mao, Zineng Tang",http://arxiv.org/pdf/2407.16521v2,cs.CL
Assessing In-context Learning and Fine-tuning for Topic Classification of German Web Data,"Researchers in the political and social sciences often rely on classification
models to analyze trends in information consumption by examining browsing
histories of millions of webpages. Automated scalable methods are necessary due
to the impracticality of manual labeling. In this paper, we model the detection
of topic-related content as a binary classification task and compare the
accuracy of fine-tuned pre-trained encoder models against in-context learning
strategies. Using only a few hundred annotated data points per topic, we detect
content related to three German policies in a database of scraped webpages. We
compare multilingual and monolingual models, as well as zero and few-shot
approaches, and investigate the impact of negative sampling strategies and the
combination of URL & content-based features. Our results show that a small
sample of annotated data is sufficient to train an effective classifier.
Fine-tuning encoder-based models yields better results than in-context
learning. Classifiers using both URL & content-based features perform best,
while using URLs alone provides adequate results when content is unavailable.",2024-07-23,"Julian Schelb, Roberto Ulloa, Andreas Spitz",http://arxiv.org/pdf/2407.16516v1,cs.CL
Machine Translation Hallucination Detection for Low and High Resource Languages using Large Language Models,"Recent advancements in massively multilingual machine translation systems
have significantly enhanced translation accuracy; however, even the best
performing systems still generate hallucinations, severely impacting user
trust. Detecting hallucinations in Machine Translation (MT) remains a critical
challenge, particularly since existing methods excel with High-Resource
Languages (HRLs) but exhibit substantial limitations when applied to
Low-Resource Languages (LRLs). This paper evaluates sentence-level
hallucination detection approaches using Large Language Models (LLMs) and
semantic similarity within massively multilingual embeddings. Our study spans
16 language directions, covering HRLs, LRLs, with diverse scripts. We find that
the choice of model is essential for performance. On average, for HRLs,
Llama3-70B outperforms the previous state of the art by as much as 0.16 MCC
(Matthews Correlation Coefficient). However, for LRLs we observe that Claude
Sonnet outperforms other LLMs on average by 0.03 MCC. The key takeaway from our
study is that LLMs can achieve performance comparable or even better than
previously proposed models, despite not being explicitly trained for any
machine translation task. However, their advantage is less significant for
LRLs.",2024-07-23,"Kenza Benkirane, Laura Gongas, Shahar Pelles, Naomi Fuchs, Joshua Darmon, Pontus Stenetorp, David Ifeoluwa Adelani, Eduardo Sánchez",http://arxiv.org/pdf/2407.16470v3,cs.CL
Psychomatics -- A Multidisciplinary Framework for Understanding Artificial Minds,"Although LLMs and other artificial intelligence systems demonstrate cognitive
skills similar to humans, like concept learning and language acquisition, the
way they process information fundamentally differs from biological cognition.
To better understand these differences this paper introduces Psychomatics, a
multidisciplinary framework bridging cognitive science, linguistics, and
computer science. It aims to better understand the high-level functioning of
LLMs, focusing specifically on how LLMs acquire, learn, remember, and use
information to produce their outputs. To achieve this goal, Psychomatics will
rely on a comparative methodology, starting from a theory-driven research
question - is the process of language development and use different in humans
and LLMs? - drawing parallels between LLMs and biological systems. Our analysis
shows how LLMs can map and manipulate complex linguistic patterns in their
training data. Moreover, LLMs can follow Grice's Cooperative Principle to
provide relevant and informative responses. However, human cognition draws from
multiple sources of meaning, including experiential, emotional, and imaginative
facets, which transcend mere language processing and are rooted in our social
and developmental trajectories. Moreover, current LLMs lack physical
embodiment, reducing their ability to make sense of the intricate interplay
between perception, action, and cognition that shapes human understanding and
expression. Ultimately, Psychomatics holds the potential to yield
transformative insights into the nature of language, cognition, and
intelligence, both artificial and biological. Moreover, by drawing parallels
between LLMs and human cognitive processes, Psychomatics can inform the
development of more robust and human-like AI systems.",2024-07-23,"Giuseppe Riva, Fabrizia Mantovani, Brenda K. Wiederhold, Antonella Marchetti, Andrea Gaggioli",http://arxiv.org/pdf/2407.16444v1,cs.CL
Structure-aware Domain Knowledge Injection for Large Language Models,"This paper introduces a pioneering methodology, termed StructTuning, to
efficiently transform foundation Large Language Models (LLMs) into domain
specialists. It significantly reduces the training corpus needs to a mere 5%
while achieving an impressive 100% of traditional knowledge injection
performance. Motivated by structured human education, we propose a novel
two-stage strategy for knowledge injection and alignment: Structure-aware
Continual Pre-Training (SCPT) and Structure-aware Supervised Fine-Tuning
(SSFT). In the SCPT phase, we automatically extract the domain knowledge
taxonomy and reorganize the training corpora, enabling LLMs to effectively link
textual segments to targeted knowledge points within the taxonomy. In the SSFT
phase, we explicitly prompt models to elucidate the underlying knowledge
structure in their outputs, leveraging the structured domain insight to address
practical problems. Our ultimate method was extensively evaluated across model
architectures and scales on LongBench and MMedBench datasets, demonstrating
superior performance against other knowledge injection methods. We also
explored our method's scalability across different training corpus sizes,
laying the foundation to enhance domain-specific LLMs with better data
utilization.",2024-07-23,"Kai Liu, Ze Chen, Zhihang Fu, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye",http://arxiv.org/pdf/2407.16724v3,cs.CL
Enhancing LLM's Cognition via Structurization,"When reading long-form text, human cognition is complex and structurized.
While large language models (LLMs) process input contexts through a causal and
sequential perspective, this approach can potentially limit their ability to
handle intricate and complex inputs effectively. To enhance LLM's cognition
capability, this paper presents a novel concept of context structurization.
Specifically, we transform the plain, unordered contextual sentences into
well-ordered and hierarchically structurized elements. By doing so, LLMs can
better grasp intricate and extended contexts through precise attention and
information-seeking along the organized structures. Extensive evaluations are
conducted across various model architectures and sizes (including a series of
auto-regressive LLMs as well as BERT-like masking models) on a diverse set of
NLP tasks (e.g., context-based question-answering, exhaustive hallucination
evaluation, and passage-level dense retrieval). Empirical results show
consistent and significant performance gains afforded by a single-round
structurization. In particular, we boost the open-sourced LLaMA2-70B model to
achieve comparable performance against GPT-3.5-Turbo as the hallucination
evaluator. Besides, we show the feasibility of distilling advanced LLMs'
language processing abilities to a smaller yet effective StruXGPT-7B to execute
structurization, addressing the practicality of our approach. Code is available
at https://github.com/alibaba/struxgpt.",2024-07-23,"Kai Liu, Zhihang Fu, Chao Chen, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye",http://arxiv.org/pdf/2407.16434v2,cs.CL
FairFlow: An Automated Approach to Model-based Counterfactual Data Augmentation For NLP,"Despite the evolution of language models, they continue to portray harmful
societal biases and stereotypes inadvertently learned from training data. These
inherent biases often result in detrimental effects in various applications.
Counterfactual Data Augmentation (CDA), which seeks to balance demographic
attributes in training data, has been a widely adopted approach to mitigate
bias in natural language processing. However, many existing CDA approaches rely
on word substitution techniques using manually compiled word-pair dictionaries.
These techniques often lead to out-of-context substitutions, resulting in
potential quality issues. The advancement of model-based techniques, on the
other hand, has been challenged by the need for parallel training data. Works
in this area resort to manually generated parallel data that are expensive to
collect and are consequently limited in scale. This paper proposes FairFlow, an
automated approach to generating parallel data for training counterfactual text
generator models that limits the need for human intervention. Furthermore, we
show that FairFlow significantly overcomes the limitations of dictionary-based
word-substitution approaches whilst maintaining good performance.",2024-07-23,"Ewoenam Kwaku Tokpo, Toon Calders",http://arxiv.org/pdf/2407.16431v1,cs.CL
"Knowledge Models for Cancer Clinical Practice Guidelines : Construction, Management and Usage in Question Answering","An automated knowledge modeling algorithm for Cancer Clinical Practice
Guidelines (CPGs) extracts the knowledge contained in the CPG documents and
transforms it into a programmatically interactable, easy-to-update structured
model with minimal human intervention. The existing automated algorithms have
minimal scope and cannot handle the varying complexity of the knowledge content
in the CPGs for different cancer types. This work proposes an improved
automated knowledge modeling algorithm to create knowledge models from the
National Comprehensive Cancer Network (NCCN) CPGs in Oncology for different
cancer types. The proposed algorithm has been evaluated with NCCN CPGs for four
different cancer types. We also proposed an algorithm to compare the knowledge
models for different versions of a guideline to discover the specific changes
introduced in the treatment protocol of a new version. We created a
question-answering (Q&A) framework with the guideline knowledge models as the
augmented knowledge base to study our ability to query the knowledge models. We
compiled a set of 32 question-answer pairs derived from two reliable data
sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the
Q&A framework. The framework was evaluated against the question-answer pairs
from one data source, and it can generate the answers with 54.5% accuracy from
the treatment algorithm and 81.8% accuracy from the discussion part of the NCCN
NSCLC guideline knowledge model.",2024-07-23,"Pralaypati Ta, Bhumika Gupta, Arihant Jain, Sneha Sree C, Keerthi Ram, Mohanasankar Sivaprakasam",http://arxiv.org/pdf/2407.21053v1,cs.CL
TookaBERT: A Step Forward for Persian NLU,"The field of natural language processing (NLP) has seen remarkable
advancements, thanks to the power of deep learning and foundation models.
Language models, and specifically BERT, have been key players in this progress.
In this study, we trained and introduced two new BERT models using Persian
data. We put our models to the test, comparing them to seven existing models
across 14 diverse Persian natural language understanding (NLU) tasks. The
results speak for themselves: our larger model outperforms the competition,
showing an average improvement of at least +2.8 points. This highlights the
effectiveness and potential of our new BERT models for Persian NLU tasks.",2024-07-23,"MohammadAli SadraeiJavaheri, Ali Moghaddaszadeh, Milad Molazadeh, Fariba Naeiji, Farnaz Aghababaloo, Hamideh Rafiee, Zahra Amirmahani, Tohid Abedini, Fatemeh Zahra Sheikhi, Amirmohammad Salehoof",http://arxiv.org/pdf/2407.16382v1,cs.CL
Evolutionary Prompt Design for LLM-Based Post-ASR Error Correction,"Building upon the strength of modern large language models (LLMs), generative
error correction (GEC) has emerged as a promising paradigm that can elevate the
performance of modern automatic speech recognition (ASR) systems. One
representative approach is to leverage in-context learning to prompt LLMs so
that a better hypothesis can be generated by the LLMs based on a
carefully-designed prompt and an $N$-best list of hypotheses produced by ASR
systems. However, it is yet unknown whether the existing prompts are the most
effective ones for the task of post-ASR error correction. In this context, this
paper first explores alternative prompts to identify an initial set of
effective prompts, and then proposes to employ an evolutionary prompt
optimization algorithm to refine the initial prompts. Evaluations results on
the CHiME-4 subset of the Task $1$ of the SLT $2024$ GenSEC challenge show the
effectiveness and potential of the proposed algorithms.",2024-07-23,"Rithik Sachdev, Zhong-Qiu Wang, Chao-Han Huck Yang",http://arxiv.org/pdf/2407.16370v1,cs.CL
FACTTRACK: Time-Aware World State Tracking in Story Outlines,"While accurately detecting and correcting factual contradictions in language
model outputs has become increasingly important as their capabilities improve,
doing so is highly challenging. We propose a novel method, FACTTRACK, for
tracking atomic facts and addressing factual contradictions. Crucially,
FACTTRACK also maintains time-aware validity intervals for each fact, allowing
for change over time. At a high level, FACTTRACK consists of a four-step
pipeline to update a world state data structure for each new event: (1)
decompose the event into directional atomic facts; (2) determine the validity
interval of each atomic fact using the world state; (3) detect contradictions
with existing facts in the world state; and finally (4) add new facts to the
world state and update existing atomic facts. When we apply FACTTRACK to
contradiction detection on structured story outlines, we find that FACTTRACK
using LLaMA2-7B-Chat substantially outperforms a fair baseline using
LLaMA2-7B-Chat, and achieves performance comparable to a GPT4 baseline.
Moreover, when using GPT4, FACTTRACK significantly outperforms the GPT4
baseline.",2024-07-23,"Zhiheng Lyu, Kevin Yang, Lingpeng Kong, Daniel Klein",http://arxiv.org/pdf/2407.16347v2,cs.CL
PrimeGuard: Safe and Helpful LLMs through Tuning-Free Routing,"Deploying language models (LMs) necessitates outputs to be both high-quality
and compliant with safety guidelines. Although Inference-Time Guardrails (ITG)
offer solutions that shift model output distributions towards compliance, we
find that current methods struggle in balancing safety with helpfulness. ITG
Methods that safely address non-compliant queries exhibit lower helpfulness
while those that prioritize helpfulness compromise on safety. We refer to this
trade-off as the guardrail tax, analogous to the alignment tax. To address
this, we propose PrimeGuard, a novel ITG method that utilizes structured
control flow.
  PrimeGuard routes requests to different self-instantiations of the LM with
varying instructions, leveraging its inherent instruction-following
capabilities and in-context learning. Our tuning-free approach dynamically
compiles system-designer guidelines for each query. We construct and release
safe-eval, a diverse red-team safety benchmark. Extensive evaluations
demonstrate that PrimeGuard, without fine-tuning, overcomes the guardrail tax
by (1) significantly increasing resistance to iterative jailbreak attacks and
(2) achieving state-of-the-art results in safety guardrailing while (3)
matching helpfulness scores of alignment-tuned models. Extensive evaluations
demonstrate that PrimeGuard, without fine-tuning, outperforms all competing
baselines and overcomes the guardrail tax by improving the fraction of safe
responses from 61% to 97% and increasing average helpfulness scores from 4.17
to 4.29 on the largest models, while reducing attack success rate from 100% to
8%.
  PrimeGuard implementation is available at
https://github.com/dynamofl/PrimeGuard and safe-eval dataset is available at
https://huggingface.co/datasets/dynamoai/safe_eval.",2024-07-23,"Blazej Manczak, Eliott Zemour, Eric Lin, Vaikkunth Mugunthan",http://arxiv.org/pdf/2407.16318v1,cs.CL
Table-Filling via Mean Teacher for Cross-domain Aspect Sentiment Triplet Extraction,"Cross-domain Aspect Sentiment Triplet Extraction (ASTE) aims to extract
fine-grained sentiment elements from target domain sentences by leveraging the
knowledge acquired from the source domain. Due to the absence of labeled data
in the target domain, recent studies tend to rely on pre-trained language
models to generate large amounts of synthetic data for training purposes.
However, these approaches entail additional computational costs associated with
the generation process. Different from them, we discover a striking resemblance
between table-filling methods in ASTE and two-stage Object Detection (OD) in
computer vision, which inspires us to revisit the cross-domain ASTE task and
approach it from an OD standpoint. This allows the model to benefit from the OD
extraction paradigm and region-level alignment. Building upon this premise, we
propose a novel method named \textbf{T}able-\textbf{F}illing via \textbf{M}ean
\textbf{T}eacher (TFMT). Specifically, the table-filling methods encode the
sentence into a 2D table to detect word relations, while TFMT treats the table
as a feature map and utilizes a region consistency to enhance the quality of
those generated pseudo labels. Additionally, considering the existence of the
domain gap, a cross-domain consistency based on Maximum Mean Discrepancy is
designed to alleviate domain shift problems. Our method achieves
state-of-the-art performance with minimal parameters and computational costs,
making it a strong baseline for cross-domain ASTE.",2024-07-23,"Kun Peng, Lei Jiang, Qian Li, Haoran Li, Xiaoyan Yu, Li Sun, Shuo Sun, Yanxian Bi, Hao Peng",http://arxiv.org/pdf/2407.21052v1,cs.CL
Deep Learning based Key Information Extraction from Business Documents: Systematic Literature Review,"Extracting key information from documents represents a large portion of
business workloads and therefore offers a high potential for efficiency
improvements and process automation. With recent advances in deep learning, a
plethora of deep learning-based approaches for Key Information Extraction have
been proposed under the umbrella term Document Understanding that enable the
processing of complex business documents. The goal of this systematic
literature review is an in-depth analysis of existing approaches in this domain
and the identification of opportunities for further research. To this end, 96
approaches published between 2017 and 2023 are analyzed in this study.",2024-07-23,"Alexander Rombach, Peter Fettke",http://arxiv.org/pdf/2408.06345v1,cs.CL
Beyond Binary Gender: Evaluating Gender-Inclusive Machine Translation with Ambiguous Attitude Words,"Gender bias has been a focal point in the study of bias in machine
translation and language models. Existing machine translation gender bias
evaluations are primarily focused on male and female genders, limiting the
scope of the evaluation. To assess gender bias accurately, these studies often
rely on calculating the accuracy of gender pronouns or the masculine and
feminine attributes of grammatical gender via the stereotypes triggered by
occupations or sentiment words ({\em i.e.}, clear positive or negative
attitude), which cannot extend to non-binary groups. This study presents a
benchmark AmbGIMT (Gender-Inclusive Machine Translation with Ambiguous attitude
words), which assesses gender bias beyond binary gender. Meanwhile, we propose
a novel process to evaluate gender bias based on the Emotional Attitude Score
(EAS), which is used to quantify ambiguous attitude words. In evaluating three
recent and effective open-source LLMs and one powerful multilingual
translation-specific model, our main observations are: (1) The translation
performance within non-binary gender contexts is markedly inferior in terms of
translation quality and exhibits more negative attitudes than binary-gender
contexts. (2) The analysis experiments indicate that incorporating constraint
context in prompts for gender identity terms can substantially reduce
translation bias, while the bias remains evident despite the presence of the
constraints. The code is publicly available at
\url{https://github.com/pppa2019/ambGIMT}.",2024-07-23,"Yijie Chen, Yijin Liu, Fandong Meng, Jinan Xu, Yufeng Chen, Jie Zhou",http://arxiv.org/pdf/2407.16266v1,cs.CL
LawLuo: A Multi-Agent Collaborative Framework for Multi-Round Chinese Legal Consultation,"Legal Large Language Models (LLMs) have shown promise in providing legal
consultations to non-experts. However, most existing Chinese legal consultation
models are based on single-agent systems, which differ from real-world legal
consultations, where multiple professionals collaborate to offer more tailored
responses. To better simulate real consultations, we propose LawLuo, a
multi-agent framework for multi-turn Chinese legal consultations. LawLuo
includes four agents: the receptionist agent, which assesses user intent and
selects a lawyer agent; the lawyer agent, which interacts with the user; the
secretary agent, which organizes conversation records and generates
consultation reports; and the boss agent, which evaluates the performance of
the lawyer and secretary agents to ensure optimal results. These agents'
interactions mimic the operations of real law firms. To train them to follow
different legal instructions, we developed distinct fine-tuning datasets. We
also introduce a case graph-based RAG to help the lawyer agent address vague
user inputs. Experimental results show that LawLuo outperforms baselines in
generating more personalized and professional responses, handling ambiguous
queries, and following legal instructions in multi-turn conversations. Our full
code and constructed datasets will be open-sourced upon paper acceptance.",2024-07-23,"Jingyun Sun, Chengxiao Dai, Zhongze Luo, Yangbo Chang, Yang Li",http://arxiv.org/pdf/2407.16252v3,cs.CL
Exploring the Effectiveness and Consistency of Task Selection in Intermediate-Task Transfer Learning,"Identifying beneficial tasks to transfer from is a critical step toward
successful intermediate-task transfer learning. In this work, we experiment
with 130 source-target task combinations and demonstrate that the transfer
performance exhibits severe variance across different source tasks and training
seeds, highlighting the crucial role of intermediate-task selection in a
broader context. We compare four representative task selection methods in a
unified setup, focusing on their effectiveness and consistency. Compared to
embedding-free methods and text embeddings, task embeddings constructed from
fine-tuned weights can better estimate task transferability by improving task
prediction scores from 2.59% to 3.96%. Despite their strong performance, we
observe that the task embeddings do not consistently demonstrate superiority
for tasks requiring reasoning abilities. Furthermore, we introduce a novel
method that measures pairwise token similarity using maximum inner product
search, leading to the highest performance in task prediction. Our findings
suggest that token-wise similarity is better predictive for predicting
transferability compared to averaging weights.",2024-07-23,"Pin-Jie Lin, Miaoran Zhang, Marius Mosbach, Dietrich Klakow",http://arxiv.org/pdf/2407.16245v1,cs.CL
A Multi-view Mask Contrastive Learning Graph Convolutional Neural Network for Age Estimation,"The age estimation task aims to use facial features to predict the age of
people and is widely used in public security, marketing, identification, and
other fields. However, the features are mainly concentrated in facial
keypoints, and existing CNN and Transformer-based methods have inflexibility
and redundancy for modeling complex irregular structures. Therefore, this paper
proposes a Multi-view Mask Contrastive Learning Graph Convolutional Neural
Network (MMCL-GCN) for age estimation. Specifically, the overall structure of
the MMCL-GCN network contains a feature extraction stage and an age estimation
stage. In the feature extraction stage, we introduce a graph structure to
construct face images as input and then design a Multi-view Mask Contrastive
Learning (MMCL) mechanism to learn complex structural and semantic information
about face images. The learning mechanism employs an asymmetric siamese network
architecture, which utilizes an online encoder-decoder structure to reconstruct
the missing information from the original graph and utilizes the target encoder
to learn latent representations for contrastive learning. Furthermore, to
promote the two learning mechanisms better compatible and complementary, we
adopt two augmentation strategies and optimize the joint losses. In the age
estimation stage, we design a Multi-layer Extreme Learning Machine (ML-IELM)
with identity mapping to fully use the features extracted by the online
encoder. Then, a classifier and a regressor were constructed based on ML-IELM,
which were used to identify the age grouping interval and accurately estimate
the final age. Extensive experiments show that MMCL-GCN can effectively reduce
the error of age estimation on benchmark datasets such as Adience, MORPH-II,
and LAP-2016.",2024-07-23,"Yiping Zhang, Yuntao Shou, Tao Meng, Wei Ai, Keqin Li",http://arxiv.org/pdf/2407.16234v1,cs.CL
PreAlign: Boosting Cross-Lingual Transfer by Early Establishment of Multilingual Alignment,"Large language models demonstrate reasonable multilingual abilities, despite
predominantly English-centric pretraining. However, the spontaneous
multilingual alignment in these models is shown to be weak, leading to
unsatisfactory cross-lingual transfer and knowledge sharing. Previous works
attempt to address this issue by explicitly injecting multilingual alignment
information during or after pretraining. Thus for the early stage in
pretraining, the alignment is weak for sharing information or knowledge across
languages. In this paper, we propose PreAlign, a framework that establishes
multilingual alignment prior to language model pretraining. PreAlign injects
multilingual alignment by initializing the model to generate similar
representations of aligned words and preserves this alignment using a
code-switching strategy during pretraining. Extensive experiments in a
synthetic English to English-Clone setting demonstrate that PreAlign
significantly outperforms standard multilingual joint training in language
modeling, zero-shot cross-lingual transfer, and cross-lingual knowledge
application. Further experiments in real-world scenarios further validate
PreAlign's effectiveness across various model sizes.",2024-07-23,"Jiahuan Li, Shujian Huang, Aarron Ching, Xinyu Dai, Jiajun Chen",http://arxiv.org/pdf/2407.16222v3,cs.CL
Do LLMs Know When to NOT Answer? Investigating Abstention Abilities of Large Language Models,"Abstention Ability (AA) is a critical aspect of Large Language Model (LLM)
reliability, referring to an LLM's capability to withhold responses when
uncertain or lacking a definitive answer, without compromising performance.
Although previous studies have attempted to improve AA, they lack a
standardised evaluation method and remain unsuitable for black-box models where
token prediction probabilities are inaccessible. This makes comparative
analysis challenging, especially for state-of-the-art closed-source commercial
LLMs. This paper bridges this gap by introducing a black-box evaluation
approach and a new dataset, Abstain-QA, crafted to rigorously assess AA across
varied question types (answerable and unanswerable), domains (well-represented
and under-represented), and task types (fact centric and reasoning). We also
propose a new confusion matrix, the ''Answerable-Unanswerable Confusion
Matrix'' (AUCM) which serves as the basis for evaluating AA, by offering a
structured and precise approach for assessment. Finally, we explore the impact
of three prompting strategies-Strict Prompting, Verbal Confidence Thresholding,
and Chain-of-Thought (CoT)-on improving AA. Our results indicate that even
powerful models like GPT-4, Mixtral 8x22b encounter difficulties with
abstention; however, strategic approaches such as Strict prompting and CoT can
enhance this capability.",2024-07-23,"Nishanth Madhusudhan, Sathwik Tejaswi Madhusudhan, Vikas Yadav, Masoud Hashemi",http://arxiv.org/pdf/2407.16221v2,cs.CL
"A Comprehensive Survey of LLM Alignment Techniques: RLHF, RLAIF, PPO, DPO and More","With advancements in self-supervised learning, the availability of trillions
tokens in a pre-training corpus, instruction fine-tuning, and the development
of large Transformers with billions of parameters, large language models (LLMs)
are now capable of generating factual and coherent responses to human queries.
However, the mixed quality of training data can lead to the generation of
undesired responses, presenting a significant challenge. Over the past two
years, various methods have been proposed from different perspectives to
enhance LLMs, particularly in aligning them with human expectation. Despite
these efforts, there has not been a comprehensive survey paper that categorizes
and details these approaches. In this work, we aim to address this gap by
categorizing these papers into distinct topics and providing detailed
explanations of each alignment method, thereby helping readers gain a thorough
understanding of the current state of the field.",2024-07-23,"Zhichao Wang, Bin Bi, Shiva Kumar Pentyala, Kiran Ramnath, Sougata Chaudhuri, Shubham Mehrotra, Zixu, Zhu, Xiang-Bo Mao, Sitaram Asur, Na, Cheng",http://arxiv.org/pdf/2407.16216v1,cs.CL
Graph-Structured Speculative Decoding,"Speculative decoding has emerged as a promising technique to accelerate the
inference of Large Language Models (LLMs) by employing a small language model
to draft a hypothesis sequence, which is then validated by the LLM. The
effectiveness of this approach heavily relies on the balance between
performance and efficiency of the draft model. In our research, we focus on
enhancing the proportion of draft tokens that are accepted to the final output
by generating multiple hypotheses instead of just one. This allows the LLM more
options to choose from and select the longest sequence that meets its
standards. Our analysis reveals that hypotheses produced by the draft model
share many common token sequences, suggesting a potential for optimizing
computation. Leveraging this observation, we introduce an innovative approach
utilizing a directed acyclic graph (DAG) to manage the drafted hypotheses. This
structure enables us to efficiently predict and merge recurring token
sequences, vastly reducing the computational demands of the draft model. We
term this approach Graph-structured Speculative Decoding (GSD). We apply GSD
across a range of LLMs, including a 70-billion parameter LLaMA-2 model, and
observe a remarkable speedup of 1.73$\times$ to 1.96$\times$, significantly
surpassing standard speculative decoding.",2024-07-23,"Zhuocheng Gong, Jiahao Liu, Ziyue Wang, Pengfei Wu, Jingang Wang, Xunliang Cai, Dongyan Zhao, Rui Yan",http://arxiv.org/pdf/2407.16207v1,cs.CL
LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models,"The rapid development of Large Language Models (LLMs) has brought significant
advancements across various tasks. However, despite these achievements, LLMs
still exhibit inherent safety vulnerabilities, especially when confronted with
jailbreak attacks. Existing jailbreak methods suffer from two main limitations:
reliance on complicated prompt engineering and iterative optimization, which
lead to low attack success rate (ASR) and attack efficiency (AE). In this work,
we propose an efficient jailbreak attack method, Analyzing-based Jailbreak
(ABJ), which leverages the advanced reasoning capability of LLMs to
autonomously generate harmful content, revealing their underlying safety
vulnerabilities during complex reasoning process. We conduct comprehensive
experiments on ABJ across various open-source and closed-source LLMs. In
particular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional
AE among all target LLMs, showcasing its remarkable attack effectiveness,
transferability, and efficiency. Our findings underscore the urgent need to
prioritize and improve the safety of LLMs to mitigate the risks of misuse.",2024-07-23,"Shi Lin, Hongming Yang, Dingyang Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han",http://arxiv.org/pdf/2407.16205v5,cs.CL
How to Leverage Personal Textual Knowledge for Personalized Conversational Information Retrieval,"Personalized conversational information retrieval (CIR) combines
conversational and personalizable elements to satisfy various users' complex
information needs through multi-turn interaction based on their backgrounds.
The key promise is that the personal textual knowledge base (PTKB) can improve
the CIR effectiveness because the retrieval results can be more related to the
user's background. However, PTKB is noisy: not every piece of knowledge in PTKB
is relevant to the specific query at hand. In this paper, we explore and test
several ways to select knowledge from PTKB and use it for query reformulation
by using a large language model (LLM). The experimental results show the PTKB
might not always improve the search results when used alone, but LLM can help
generate a more appropriate personalized query when high-quality guidance is
provided.",2024-07-23,"Fengran Mo, Longxiang Zhao, Kaiyu Huang, Yue Dong, Degen Huang, Jian-Yun Nie",http://arxiv.org/pdf/2407.16192v1,cs.CL
Artificial Agency and Large Language Models,"The arrival of Large Language Models (LLMs) has stirred up philosophical
debates about the possibility of realizing agency in an artificial manner. In
this work we contribute to the debate by presenting a theoretical model that
can be used as a threshold conception for artificial agents. The model defines
agents as systems whose actions and goals are always influenced by a dynamic
framework of factors that consists of the agent's accessible history, its
adaptive repertoire and its external environment. This framework, in turn, is
influenced by the actions that the agent takes and the goals that it forms. We
show with the help of the model that state-of-the-art LLMs are not agents yet,
but that there are elements to them that suggest a way forward. The paper
argues that a combination of the agent architecture presented in Park et al.
(2023) together with the use of modules like the Coscientist in Boiko et al.
(2023) could potentially be a way to realize agency in an artificial manner. We
end the paper by reflecting on the obstacles one might face in building such an
artificial agent and by presenting possible directions for future research.",2024-07-23,"Maud van Lier, Gorka Muñoz-Gil",http://arxiv.org/pdf/2407.16190v2,cs.CL
An Active Inference Strategy for Prompting Reliable Responses from Large Language Models in Medical Practice,"Continuing advances in Large Language Models (LLMs) in artificial
intelligence offer important capacities in intuitively accessing and using
medical knowledge in many contexts, including education and training as well as
assessment and treatment. Most of the initial literature on LLMs in medicine
has emphasized that LLMs are unsuitable for medical use because they are
non-deterministic, may provide incorrect or harmful responses, and cannot be
regulated to assure quality control. If these issues could be corrected,
optimizing LLM technology could benefit patients and physicians by providing
affordable, point-of-care medical knowledge. Our proposed framework refines LLM
responses by restricting their primary knowledge base to domain-specific
datasets containing validated medical information. Additionally, we introduce
an actor-critic LLM prompting protocol based on active inference principles of
human cognition, where a Therapist agent initially responds to patient queries,
and a Supervisor agent evaluates and adjusts responses to ensure accuracy and
reliability. We conducted a validation study where expert cognitive behaviour
therapy for insomnia (CBT-I) therapists evaluated responses from the LLM in a
blind format. Experienced human CBT-I therapists assessed responses to 100
patient queries, comparing LLM-generated responses with appropriate and
inappropriate responses crafted by experienced CBT-I therapists. Results showed
that LLM responses received high ratings from the CBT-I therapists, often
exceeding those of therapist-generated appropriate responses. This structured
approach aims to integrate advanced LLM technology into medical applications,
meeting regulatory requirements for establishing the safe and effective use of
special purpose validated LLMs in medicine.",2024-07-23,"Roma Shusterman, Allison C. Waters, Shannon O`Neill, Phan Luu, Don M. Tucker",http://arxiv.org/pdf/2407.21051v1,cs.CL
Structural Optimization Ambiguity and Simplicity Bias in Unsupervised Neural Grammar Induction,"Neural parameterization has significantly advanced unsupervised grammar
induction. However, training these models with a traditional likelihood loss
for all possible parses exacerbates two issues: 1) $\textit{structural
optimization ambiguity}$ that arbitrarily selects one among structurally
ambiguous optimal grammars despite the specific preference of gold parses, and
2) $\textit{structural simplicity bias}$ that leads a model to underutilize
rules to compose parse trees. These challenges subject unsupervised neural
grammar induction (UNGI) to inevitable prediction errors, high variance, and
the necessity for extensive grammars to achieve accurate predictions. This
paper tackles these issues, offering a comprehensive analysis of their origins.
As a solution, we introduce $\textit{sentence-wise parse-focusing}$ to reduce
the parse pool per sentence for loss evaluation, using the structural bias from
pre-trained parsers on the same dataset. In unsupervised parsing benchmark
tests, our method significantly improves performance while effectively reducing
variance and bias toward overly simplistic parses. Our research promotes
learning more compact, accurate, and consistent explicit grammars, facilitating
better interpretability.",2024-07-23,"Jinwook Park, Kangil Kim",http://arxiv.org/pdf/2407.16181v1,cs.CL
Progressively Modality Freezing for Multi-Modal Entity Alignment,"Multi-Modal Entity Alignment aims to discover identical entities across
heterogeneous knowledge graphs. While recent studies have delved into fusion
paradigms to represent entities holistically, the elimination of features
irrelevant to alignment and modal inconsistencies is overlooked, which are
caused by inherent differences in multi-modal features. To address these
challenges, we propose a novel strategy of progressive modality freezing,
called PMF, that focuses on alignmentrelevant features and enhances multi-modal
feature fusion. Notably, our approach introduces a pioneering cross-modal
association loss to foster modal consistency. Empirical evaluations across nine
datasets confirm PMF's superiority, demonstrating stateof-the-art performance
and the rationale for freezing modalities. Our code is available at
https://github.com/ninibymilk/PMF-MMEA.",2024-07-23,"Yani Huang, Xuefeng Zhang, Richong Zhang, Junfan Chen, Jaein Kim",http://arxiv.org/pdf/2407.16168v1,cs.CL
Robust Privacy Amidst Innovation with Large Language Models Through a Critical Assessment of the Risks,"This study examines integrating EHRs and NLP with large language models
(LLMs) to improve healthcare data management and patient care. It focuses on
using advanced models to create secure, HIPAA-compliant synthetic patient notes
for biomedical research. The study used de-identified and re-identified MIMIC
III datasets with GPT-3.5, GPT-4, and Mistral 7B to generate synthetic notes.
Text generation employed templates and keyword extraction for contextually
relevant notes, with one-shot generation for comparison. Privacy assessment
checked PHI occurrence, while text utility was tested using an ICD-9 coding
task. Text quality was evaluated with ROUGE and cosine similarity metrics to
measure semantic similarity with source notes. Analysis of PHI occurrence and
text utility via the ICD-9 coding task showed that the keyword-based method had
low risk and good performance. One-shot generation showed the highest PHI
exposure and PHI co-occurrence, especially in geographic location and date
categories. The Normalized One-shot method achieved the highest classification
accuracy. Privacy analysis revealed a critical balance between data utility and
privacy protection, influencing future data use and sharing. Re-identified data
consistently outperformed de-identified data. This study demonstrates the
effectiveness of keyword-based methods in generating privacy-protecting
synthetic clinical notes that retain data usability, potentially transforming
clinical data-sharing practices. The superior performance of re-identified over
de-identified data suggests a shift towards methods that enhance utility and
privacy by using dummy PHIs to perplex privacy attacks.",2024-07-23,"Yao-Shun Chuang, Atiquer Rahman Sarkar, Yu-Chun Hsu, Noman Mohammed, Xiaoqian Jiang",http://arxiv.org/pdf/2407.16166v2,cs.CL
Artificial Intelligence in Extracting Diagnostic Data from Dental Records,"This research addresses the issue of missing structured data in dental
records by extracting diagnostic information from unstructured text. The
updated periodontology classification system's complexity has increased
incomplete or missing structured diagnoses. To tackle this, we use advanced AI
and NLP methods, leveraging GPT-4 to generate synthetic notes for fine-tuning a
RoBERTa model. This significantly enhances the model's ability to understand
medical and dental language. We evaluated the model using 120 randomly selected
clinical notes from two datasets, demonstrating its improved diagnostic
extraction accuracy. The results showed high accuracy in diagnosing periodontal
status, stage, and grade, with Site 1 scoring 0.99 and Site 2 scoring 0.98. In
the subtype category, Site 2 achieved perfect scores, outperforming Site 1.
This method enhances extraction accuracy and broadens its use across dental
contexts. The study underscores AI and NLP's transformative impact on
healthcare delivery and management. Integrating AI and NLP technologies
enhances documentation and simplifies administrative tasks by precisely
extracting complex clinical information. This approach effectively addresses
challenges in dental diagnostics. Using synthetic training data from LLMs
optimizes the training process, improving accuracy and efficiency in
identifying periodontal diagnoses from clinical notes. This innovative method
holds promise for broader healthcare applications, potentially improving
patient care quality.",2024-07-23,"Yao-Shun Chuang, Chun-Teh Lee, Oluwabunmi Tokede, Guo-Hao Lin, Ryan Brandon, Trung Duong Tran, Xiaoqian Jiang, Muhammad F. Walji",http://arxiv.org/pdf/2407.21050v2,cs.CL
UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models,"Multimodal Entity Linking (MEL) is a crucial task that aims at linking
ambiguous mentions within multimodal contexts to the referent entities in a
multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on
using complex mechanisms and extensive model tuning methods to model the
multimodal interaction on specific datasets. However, these methods
overcomplicate the MEL task and overlook the visual semantic information, which
makes them costly and hard to scale. Moreover, these methods can not solve the
issues like textual ambiguity, redundancy, and noisy images, which severely
degrade their performance. Fortunately, the advent of Large Language Models
(LLMs) with robust capabilities in text understanding and reasoning,
particularly Multimodal Large Language Models (MLLMs) that can process
multimodal inputs, provides new insights into addressing this challenge.
However, how to design a universally applicable LLMs-based MEL approach remains
a pressing challenge. To this end, we propose UniMEL, a unified framework which
establishes a new paradigm to process multimodal entity linking tasks using
LLMs. In this framework, we employ LLMs to augment the representation of
mentions and entities individually by integrating textual and visual
information and refining textual information. Subsequently, we employ the
embedding-based method for retrieving and re-ranking candidate entities. Then,
with only ~0.26% of the model parameters fine-tuned, LLMs can make the final
selection from the candidate entities. Extensive experiments on three public
benchmark datasets demonstrate that our solution achieves state-of-the-art
performance, and ablation studies verify the effectiveness of all modules. Our
code is available at https://github.com/Javkonline/UniMEL.",2024-07-23,"Liu Qi, He Yongyi, Lian Defu, Zheng Zhi, Xu Tong, Liu Che, Chen Enhong",http://arxiv.org/pdf/2407.16160v2,cs.CL
DDK: Distilling Domain Knowledge for Efficient Large Language Models,"Despite the advanced intelligence abilities of large language models (LLMs)
in various applications, they still face significant computational and storage
demands. Knowledge Distillation (KD) has emerged as an effective strategy to
improve the performance of a smaller LLM (i.e., the student model) by
transferring knowledge from a high-performing LLM (i.e., the teacher model).
Prevailing techniques in LLM distillation typically use a black-box model API
to generate high-quality pretrained and aligned datasets, or utilize white-box
distillation by altering the loss function to better transfer knowledge from
the teacher LLM. However, these methods ignore the knowledge differences
between the student and teacher LLMs across domains. This results in excessive
focus on domains with minimal performance gaps and insufficient attention to
domains with large gaps, reducing overall performance. In this paper, we
introduce a new LLM distillation framework called DDK, which dynamically
adjusts the composition of the distillation dataset in a smooth manner
according to the domain performance differences between the teacher and student
models, making the distillation process more stable and effective. Extensive
evaluations show that DDK significantly improves the performance of student
models, outperforming both continuously pretrained baselines and existing
knowledge distillation methods by a large margin.",2024-07-23,"Jiaheng Liu, Chenchen Zhang, Jinyang Guo, Yuanxing Zhang, Haoran Que, Ken Deng, Zhiqi Bai, Jie Liu, Ge Zhang, Jiakai Wang, Yanan Wu, Congnan Liu, Wenbo Su, Jiamang Wang, Lin Qu, Bo Zheng",http://arxiv.org/pdf/2407.16154v1,cs.CL
CHIME: LLM-Assisted Hierarchical Organization of Scientific Studies for Literature Review Support,"Literature review requires researchers to synthesize a large amount of
information and is increasingly challenging as the scientific literature
expands. In this work, we investigate the potential of LLMs for producing
hierarchical organizations of scientific studies to assist researchers with
literature review. We define hierarchical organizations as tree structures
where nodes refer to topical categories and every node is linked to the studies
assigned to that category. Our naive LLM-based pipeline for hierarchy
generation from a set of studies produces promising yet imperfect hierarchies,
motivating us to collect CHIME, an expert-curated dataset for this task focused
on biomedicine. Given the challenging and time-consuming nature of building
hierarchies from scratch, we use a human-in-the-loop process in which experts
correct errors (both links between categories and study assignment) in
LLM-generated hierarchies. CHIME contains 2,174 LLM-generated hierarchies
covering 472 topics, and expert-corrected hierarchies for a subset of 100
topics. Expert corrections allow us to quantify LLM performance, and we find
that while they are quite good at generating and organizing categories, their
assignment of studies to categories could be improved. We attempt to train a
corrector model with human feedback which improves study assignment by 12.6 F1
points. We release our dataset and models to encourage research on developing
better assistive tools for literature review.",2024-07-23,"Chao-Chun Hsu, Erin Bransom, Jenna Sparks, Bailey Kuehl, Chenhao Tan, David Wadden, Lucy Lu Wang, Aakanksha Naik",http://arxiv.org/pdf/2407.16148v1,cs.CL
Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval,"As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools",2024-07-23,"Yannick Assogba, Donghao Ren",http://arxiv.org/pdf/2407.21049v1,cs.CL
Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion,"Traditional knowledge graph (KG) completion models learn embeddings to
predict missing facts. Recent works attempt to complete KGs in a
text-generation manner with large language models (LLMs). However, they need to
ground the output of LLMs to KG entities, which inevitably brings errors. In
this paper, we present a finetuning framework, DIFT, aiming to unleash the KG
completion ability of LLMs and avoid grounding errors. Given an incomplete
fact, DIFT employs a lightweight model to obtain candidate entities and
finetunes an LLM with discrimination instructions to select the correct one
from the given candidates. To improve performance while reducing instruction
data, DIFT uses a truncated sampling method to select useful facts for
finetuning and injects KG embeddings into the LLM. Extensive experiments on
benchmark datasets demonstrate the effectiveness of our proposed framework.",2024-07-23,"Yang Liu, Xiaobin Tian, Zequn Sun, Wei Hu",http://arxiv.org/pdf/2407.16127v1,cs.CL
APTNESS: Incorporating Appraisal Theory and Emotion Support Strategies for Empathetic Response Generation,"Empathetic response generation is designed to comprehend the emotions of
others and select the most appropriate strategies to assist them in resolving
emotional challenges. Empathy can be categorized into cognitive empathy and
affective empathy. The former pertains to the ability to understand and discern
the emotional issues and situations of others, while the latter involves the
capacity to provide comfort. To enhance one's empathetic abilities, it is
essential to develop both these aspects. Therefore, we develop an innovative
framework that combines retrieval augmentation and emotional support strategy
integration. Our framework starts with the introduction of a comprehensive
emotional palette for empathy. We then apply appraisal theory to decompose this
palette and create a database of empathetic responses. This database serves as
an external resource and enhances the LLM's empathy by integrating semantic
retrieval mechanisms. Moreover, our framework places a strong emphasis on the
proper articulation of response strategies. By incorporating emotional support
strategies, we aim to enrich the model's capabilities in both cognitive and
affective empathy, leading to a more nuanced and comprehensive empathetic
response. Finally, we extract datasets ED and ET from the empathetic dialogue
dataset \textsc{EmpatheticDialogues} and ExTES based on dialogue length.
Experiments demonstrate that our framework can enhance the empathy ability of
LLMs from both cognitive and affective empathy perspectives. Our code is
released at https://github.com/CAS-SIAT-XinHai/APTNESS.",2024-07-23,"Yuxuan Hu, Minghuan Tan, Chenwei Zhang, Zixuan Li, Xiaodan Liang, Min Yang, Chengming Li, Xiping Hu",http://arxiv.org/pdf/2407.21048v1,cs.CL
Analyzing Polysemy Evolution Using Semantic Cells,"The senses of words evolve. The sense of the same word may change from today
to tomorrow, and multiple senses of the same word may be the result of the
evolution of each other, that is, they may be parents and children. If we view
Juba as an evolving ecosystem, the paradigm of learning the correct answer,
which does not move with the sense of a word, is no longer valid. This paper is
a case study that shows that word polysemy is an evolutionary consequence of
the modification of Semantic Cells, which has al-ready been presented by the
author, by introducing a small amount of diversity in its initial state as an
example of analyzing the current set of short sentences. In particular, the
analysis of a sentence sequence of 1000 sentences in some order for each of the
four senses of the word Spring, collected using Chat GPT, shows that the word
acquires the most polysemy monotonically in the analysis when the senses are
arranged in the order in which they have evolved. In other words, we present a
method for analyzing the dynamism of a word's acquiring polysemy with evolution
and, at the same time, a methodology for viewing polysemy from an evolutionary
framework rather than a learning-based one.",2024-07-23,"Yukio Ohsawa, Dingming Xue, Kaira Sekiguchi",http://arxiv.org/pdf/2407.16110v3,cs.CL
KaPQA: Knowledge-Augmented Product Question-Answering,"Question-answering for domain-specific applications has recently attracted
much interest due to the latest advancements in large language models (LLMs).
However, accurately assessing the performance of these applications remains a
challenge, mainly due to the lack of suitable benchmarks that effectively
simulate real-world scenarios. To address this challenge, we introduce two
product question-answering (QA) datasets focused on Adobe Acrobat and Photoshop
products to help evaluate the performance of existing models on domain-specific
product QA tasks. Additionally, we propose a novel knowledge-driven RAG-QA
framework to enhance the performance of the models in the product QA task. Our
experiments demonstrated that inducing domain knowledge through query
reformulation allowed for increased retrieval and generative performance when
compared to standard RAG-QA methods. This improvement, however, is slight, and
thus illustrates the challenge posed by the datasets introduced.",2024-07-22,"Swetha Eppalapally, Daksh Dangi, Chaithra Bhat, Ankita Gupta, Ruiyi Zhang, Shubham Agarwal, Karishma Bagga, Seunghyun Yoon, Nedim Lipka, Ryan A. Rossi, Franck Dernoncourt",http://arxiv.org/pdf/2407.16073v1,cs.CL
Leveraging Large Language Models to Geolocate Linguistic Variations in Social Media Posts,"Geolocalization of social media content is the task of determining the
geographical location of a user based on textual data, that may show linguistic
variations and informal language. In this project, we address the GeoLingIt
challenge of geolocalizing tweets written in Italian by leveraging large
language models (LLMs). GeoLingIt requires the prediction of both the region
and the precise coordinates of the tweet. Our approach involves fine-tuning
pre-trained LLMs to simultaneously predict these geolocalization aspects. By
integrating innovative methodologies, we enhance the models' ability to
understand the nuances of Italian social media text to improve the
state-of-the-art in this domain. This work is conducted as part of the Large
Language Models course at the Bertinoro International Spring School 2024. We
make our code publicly available on GitHub
https://github.com/dawoz/geolingit-biss2024.",2024-07-22,"Davide Savarro, Davide Zago, Stefano Zoia",http://arxiv.org/pdf/2407.16047v1,cs.CL
Leveraging LLM Reasoning Enhances Personalized Recommender Systems,"Recent advancements have showcased the potential of Large Language Models
(LLMs) in executing reasoning tasks, particularly facilitated by
Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve
clear, definitive answers and logical chains of thought, the application of LLM
reasoning in recommendation systems (RecSys) presents a distinct challenge.
RecSys tasks revolve around subjectivity and personalized preferences, an
under-explored domain in utilizing LLMs' reasoning capabilities. Our study
explores several aspects to better understand reasoning for RecSys and
demonstrate how task quality improves by utilizing LLM reasoning in both
zero-shot and finetuning settings. Additionally, we propose RecSAVER
(Recommender Systems Automatic Verification and Evaluation of Reasoning) to
automatically assess the quality of LLM reasoning responses without the
requirement of curated gold references or human raters. We show that our
framework aligns with real human judgment on the coherence and faithfulness of
reasoning responses. Overall, our work shows that incorporating reasoning into
RecSys can improve personalized tasks, paving the way for further advancements
in recommender system methodologies.",2024-07-22,"Alicia Y. Tsai, Adam Kraft, Long Jin, Chenwei Cai, Anahita Hosseini, Taibai Xu, Zemin Zhang, Lichan Hong, Ed H. Chi, Xinyang Yi",http://arxiv.org/pdf/2408.00802v1,cs.CL
Enhancing Temporal Understanding in LLMs for Semi-structured Tables,"Temporal reasoning over tabular data presents substantial challenges for
large language models (LLMs), as evidenced by recent research. In this study,
we conduct a comprehensive analysis of temporal datasets to pinpoint the
specific limitations of LLMs. Our investigation leads to enhancements in
TempTabQA, a dataset specifically designed for tabular temporal question
answering. We provide critical insights for improving LLM performance in
temporal reasoning tasks with tabular data. Furthermore, we introduce a novel
approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings
demonstrate that our method significantly improves evidence-based reasoning
across various models. Additionally, our experimental results reveal that
indirect supervision with auxiliary data substantially boosts model performance
in these tasks. This work contributes to a deeper understanding of LLMs'
temporal reasoning abilities over tabular data and promotes advancements in
their application across diverse fields.",2024-07-22,"Irwin Deng, Kushagra Dixit, Vivek Gupta, Dan Roth",http://arxiv.org/pdf/2407.16030v1,cs.CL
Boosting Reward Model with Preference-Conditional Multi-Aspect Synthetic Data Generation,"Reward models (RMs) are crucial for aligning large language models (LLMs)
with human preferences. They are trained using preference datasets where each
example consists of one input prompt, two responses, and a preference label. As
curating a high-quality human labeled preference dataset is both time-consuming
and expensive, people often rely on existing powerful LLMs for preference label
generation. This can potentially introduce noise and impede RM training. In
this work, we present RMBoost, a novel synthetic preference data generation
paradigm to boost reward model quality. Unlike traditional methods, which
generate two responses before obtaining the preference label, RMBoost first
generates one response and selects a preference label, followed by generating
the second more (or less) preferred response conditioned on the pre-selected
preference label and the first response. This approach offers two main
advantages. First, RMBoost reduces labeling noise since preference pairs are
constructed intentionally. Second, RMBoost facilitates the creation of more
diverse responses by incorporating various quality aspects (e.g., helpfulness,
relevance, completeness) into the prompts. We conduct extensive experiments
across three diverse datasets and demonstrate that RMBoost outperforms other
synthetic preference data generation techniques and significantly boosts the
performance of four distinct reward models.",2024-07-22,"Jiaming Shen, Ran Xu, Yennie Jun, Zhen Qin, Tianqi Liu, Carl Yang, Yi Liang, Simon Baumgartner, Michael Bendersky",http://arxiv.org/pdf/2407.16008v2,cs.CL
SocialQuotes: Learning Contextual Roles of Social Media Quotes on the Web,"Web authors frequently embed social media to support and enrich their
content, creating the potential to derive web-based, cross-platform social
media representations that can enable more effective social media retrieval
systems and richer scientific analyses. As step toward such capabilities, we
introduce a novel language modeling framework that enables automatic annotation
of roles that social media entities play in their embedded web context. Using
related communication theory, we liken social media embeddings to quotes,
formalize the page context as structured natural language signals, and identify
a taxonomy of roles for quotes within the page context. We release
SocialQuotes, a new data set built from the Common Crawl of over 32 million
social quotes, 8.3k of them with crowdsourced quote annotations. Using
SocialQuotes and the accompanying annotations, we provide a role classification
case study, showing reasonable performance with modern-day LLMs, and exposing
explainable aspects of our framework via page content ablations. We also
classify a large batch of un-annotated quotes, revealing interesting
cross-domain, cross-platform role distributions on the web.",2024-07-22,"John Palowitch, Hamidreza Alvari, Mehran Kazemi, Tanvir Amin, Filip Radlinski",http://arxiv.org/pdf/2407.16007v1,cs.CL
Multimodal Input Aids a Bayesian Model of Phonetic Learning,"One of the many tasks facing the typically-developing child language learner
is learning to discriminate between the distinctive sounds that make up words
in their native language. Here we investigate whether multimodal
information--specifically adult speech coupled with video frames of speakers'
faces--benefits a computational model of phonetic learning. We introduce a
method for creating high-quality synthetic videos of speakers' faces for an
existing audio corpus. Our learning model, when both trained and tested on
audiovisual inputs, achieves up to a 8.1% relative improvement on a phoneme
discrimination battery compared to a model trained and tested on audio-only
input. It also outperforms the audio model by up to 3.9% when both are tested
on audio-only data, suggesting that visual information facilitates the
acquisition of acoustic distinctions. Visual information is especially
beneficial in noisy audio environments, where an audiovisual model closes 67%
of the loss in discrimination performance of the audio model in noise relative
to a non-noisy environment. These results demonstrate that visual information
benefits an ideal learner and illustrate some of the ways that children might
be able to leverage visual cues when learning to discriminate speech sounds.",2024-07-22,"Sophia Zhi, Roger P. Levy, Stephan C. Meylan",http://arxiv.org/pdf/2407.15992v1,cs.CL
Multilingual Fine-Grained News Headline Hallucination Detection,"The popularity of automated news headline generation has surged with
advancements in pre-trained language models. However, these models often suffer
from the ``hallucination'' problem, where the generated headline is not fully
supported by its source article. Efforts to address this issue have
predominantly focused on English, using over-simplistic classification schemes
that overlook nuanced hallucination types. In this study, we introduce the
first multilingual, fine-grained news headline hallucination detection dataset
that contains over 11 thousand pairs in 5 languages, each annotated with
detailed hallucination types by experts. We conduct extensive experiments on
this dataset under two settings. First, we implement several supervised
fine-tuning approaches as preparatory solutions and demonstrate this dataset's
challenges and utilities. Second, we test various large language models'
in-context learning abilities and propose two novel techniques,
language-dependent demonstration selection and coarse-to-fine prompting, to
boost the few-shot hallucination detection performance in terms of the
example-F1 metric. We release this dataset to foster further research in
multilingual, fine-grained headline hallucination detection.",2024-07-22,"Jiaming Shen, Tianqi Liu, Jialu Liu, Zhen Qin, Jay Pavagadhi, Simon Baumgartner, Michael Bendersky",http://arxiv.org/pdf/2407.15975v1,cs.CL
Promises and Pitfalls of Generative Masked Language Modeling: Theoretical Framework and Practical Guidelines,"Autoregressive language models are the currently dominant paradigm for text
generation, but they have some fundamental limitations that cannot be remedied
by scale-for example inherently sequential and unidirectional generation. While
alternate classes of models have been explored, we have limited mathematical
understanding of their fundamental power and limitations. In this paper we
focus on Generative Masked Language Models (GMLMs), a non-autoregressive
paradigm in which we train a model to fit conditional probabilities of the data
distribution via masking, which are subsequently used as inputs to a Markov
Chain to draw samples from the model, These models empirically strike a
promising speed-quality trade-off as each step can be typically parallelized by
decoding the entire sequence in parallel. We develop a mathematical framework
for analyzing and improving such models which sheds light on questions of
sample complexity and inference speed and quality. Empirically, we adapt the T5
model for iteratively-refined parallel decoding, achieving 2-3x speedup in
machine translation with minimal sacrifice in quality compared with
autoregressive models. We run careful ablation experiments to give
recommendations on key design choices, and make fine-grained observations on
the common error modes in connection with our theory. Our mathematical analyses
and empirical observations characterize both potentials and limitations of this
approach, and can be applied to future works on improving understanding and
performance of GMLMs. Our codes are released at
https://github.com/google-research/google-research/tree/master/padir",2024-07-22,"Yuchen Li, Alexandre Kirchmeyer, Aashay Mehta, Yilong Qin, Boris Dadachev, Kishore Papineni, Sanjiv Kumar, Andrej Risteski",http://arxiv.org/pdf/2407.21046v1,cs.CL
Benchmarks as Microscopes: A Call for Model Metrology,"Modern language models (LMs) pose a new challenge in capability assessment.
Static benchmarks inevitably saturate without providing confidence in the
deployment tolerances of LM-based systems, but developers nonetheless claim
that their models have generalized traits such as reasoning or open-domain
language understanding based on these flawed metrics. The science and practice
of LMs requires a new approach to benchmarking which measures specific
capabilities with dynamic assessments. To be confident in our metrics, we need
a new discipline of model metrology -- one which focuses on how to generate
benchmarks that predict performance under deployment. Motivated by our
evaluation criteria, we outline how building a community of model metrology
practitioners -- one focused on building tools and studying how to measure
system capabilities -- is the best way to meet these needs to and add clarity
to the AI discussion.",2024-07-22,"Michael Saxon, Ari Holtzman, Peter West, William Yang Wang, Naomi Saphra",http://arxiv.org/pdf/2407.16711v2,cs.CL
dMel: Speech Tokenization made Simple,"Large language models have revolutionized natural language processing by
leveraging self-supervised pretraining on vast textual data. Inspired by this
success, researchers have investigated various compression-based speech
tokenization methods to discretize continuous speech signals, enabling the
application of language modeling techniques to discrete tokens. However, audio
compressor introduces additional complexity and computational cost, and often
fail on out-of-domain audio signals. In this work, we introduce a novel speech
representation (dmel) that discretizes mel-filterbank channels into intensity
bins, creating a simpler yet more effective representation compared to existing
speech tokenization methods. Our approach demonstrates superior performance in
preserving audio content, robustness to out-of-domain data, and offers a
training-free, natural, and streamable representation. To address the
high-dimensional nature of log-mel spectrograms, we propose an efficient
parallel encoding and decoding method for high-dimensional tokens using an
LM-style transformer architecture. This innovation enables us to develop
RichTTS and RichASR, two models sharing the same architecture while achieving
comparable or better results than specialized existing methods. Our results
demonstrate the effectiveness of dmel in achieving high performance on both
speech synthesis and recognition tasks within a unified framework, paving the
way for efficient and effective joint modeling of speech and text.",2024-07-22,"Richard He Bai, Tatiana Likhomanenko, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly",http://arxiv.org/pdf/2407.15835v3,cs.CL
J-CHAT: Japanese Large-scale Spoken Dialogue Corpus for Spoken Dialogue Language Modeling,"Spoken dialogue plays a crucial role in human-AI interactions, necessitating
dialogue-oriented spoken language models (SLMs). To develop versatile SLMs,
large-scale and diverse speech datasets are essential. Additionally, to ensure
hiqh-quality speech generation, the data must be spontaneous like in-wild data
and must be acoustically clean with noise removed. Despite the critical need,
no open-source corpus meeting all these criteria has been available. This study
addresses this gap by constructing and releasing a large-scale spoken dialogue
corpus, named Japanese Corpus for Human-AI Talks (J-CHAT), which is publicly
accessible. Furthermore, this paper presents a language-independent method for
corpus construction and describes experiments on dialogue generation using SLMs
trained on J-CHAT. Experimental results indicate that the collected data from
multiple domains by our method improve the naturalness and meaningfulness of
dialogue generation.",2024-07-22,"Wataru Nakata, Kentaro Seki, Hitomi Yanaka, Yuki Saito, Shinnosuke Takamichi, Hiroshi Saruwatari",http://arxiv.org/pdf/2407.15828v1,cs.CL
Perceptions of Linguistic Uncertainty by Language Models and Humans,"_Uncertainty expressions_ such as ""probably"" or ""highly unlikely"" are
pervasive in human language. While prior work has established that there is
population-level agreement in terms of how humans quantitatively interpret
these expressions, there has been little inquiry into the abilities of language
models in the same context. In this paper, we investigate how language models
map linguistic expressions of uncertainty to numerical responses. Our approach
assesses whether language models can employ theory of mind in this setting:
understanding the uncertainty of another agent about a particular statement,
independently of the model's own certainty about that statement. We find that 7
out of 10 models are able to map uncertainty expressions to probabilistic
responses in a human-like manner. However, we observe systematically different
behavior depending on whether a statement is actually true or false. This
sensitivity indicates that language models are substantially more susceptible
to bias based on their prior knowledge (as compared to humans). These findings
raise important questions and have broad implications for human-AI and AI-AI
communication.",2024-07-22,"Catarina G Belem, Markelle Kelly, Mark Steyvers, Sameer Singh, Padhraic Smyth",http://arxiv.org/pdf/2407.15814v2,cs.CL
FSboard: Over 3 million characters of ASL fingerspelling collected via smartphones,"Progress in machine understanding of sign languages has been slow and
hampered by limited data. In this paper, we present FSboard, an American Sign
Language fingerspelling dataset situated in a mobile text entry use case,
collected from 147 paid and consenting Deaf signers using Pixel 4A selfie
cameras in a variety of environments. Fingerspelling recognition is an
incomplete solution that is only one small part of sign language translation,
but it could provide some immediate benefit to Deaf/Hard of Hearing signers as
more broadly capable technology develops. At >3 million characters in length
and >250 hours in duration, FSboard is the largest fingerspelling recognition
dataset to date by a factor of >10x. As a simple baseline, we finetune 30 Hz
MediaPipe Holistic landmark inputs into ByT5-Small and achieve 11.1% Character
Error Rate (CER) on a test set with unique phrases and signers. This quality
degrades gracefully when decreasing frame rate and excluding face/body
landmarks: plausible optimizations to help models run on device in real time.",2024-07-22,"Manfred Georg, Garrett Tanzer, Saad Hassan, Maximus Shengelia, Esha Uboweja, Sam Sepah, Sean Forbes, Thad Starner",http://arxiv.org/pdf/2407.15806v1,cs.CL
Extracting Structured Insights from Financial News: An Augmented LLM Driven Approach,"Financial news plays a crucial role in decision-making processes across the
financial sector, yet the efficient processing of this information into a
structured format remains challenging. This paper presents a novel approach to
financial news processing that leverages Large Language Models (LLMs) to
overcome limitations that previously prevented the extraction of structured
data from unstructured financial news. We introduce a system that extracts
relevant company tickers from raw news article content, performs sentiment
analysis at the company level, and generates summaries, all without relying on
pre-structured data feeds. Our methodology combines the generative capabilities
of LLMs, and recent prompting techniques, with a robust validation framework
that uses a tailored string similarity approach. Evaluation on a dataset of
5530 financial news articles demonstrates the effectiveness of our approach,
with 90% of articles not missing any tickers compared with current data
providers, and 22% of articles having additional relevant tickers. In addition
to this paper, the methodology has been implemented at scale with the resulting
processed data made available through a live API endpoint, which is updated in
real-time with the latest news. To the best of our knowledge, we are the first
data provider to offer granular, per-company sentiment analysis from news
articles, enhancing the depth of information available to market participants.
We also release the evaluation dataset of 5530 processed articles as a static
file, which we hope will facilitate further research leveraging financial news.",2024-07-22,"Rian Dolphin, Joe Dursun, Jonathan Chow, Jarrett Blankenship, Katie Adams, Quinton Pike",http://arxiv.org/pdf/2407.15788v1,cs.CL
Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning,"Reward-based finetuning is crucial for aligning language policies with
intended behaviors (e.g., creativity and safety). A key challenge is to develop
steerable language models that trade-off multiple (conflicting) objectives in a
flexible and efficient manner. This paper presents Conditional Language Policy
(CLP), a general framework for finetuning language models on multiple
objectives. Building on techniques from multi-task training and
parameter-efficient finetuning, CLP learn steerable models that effectively
trade-off conflicting objectives at inference time. Notably, this does not
require training or maintaining multiple models to achieve different trade-offs
between the objectives. Through extensive experiments and ablations on two
summarization datasets, we show that CLP learns steerable language models that
outperform and Pareto-dominate the existing approaches for multi-objective
finetuning.",2024-07-22,"Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, Johan Ferret, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent",http://arxiv.org/pdf/2407.15762v2,cs.CL
LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding,"Large multimodal models (LMMs) are processing increasingly longer and richer
inputs. Albeit the progress, few public benchmark is available to measure such
development. To mitigate this gap, we introduce LongVideoBench, a
question-answering benchmark that features video-language interleaved inputs up
to an hour long. Our benchmark includes 3,763 varying-length web-collected
videos with their subtitles across diverse themes, designed to comprehensively
evaluate LMMs on long-term multimodal understanding. To achieve this, we
interpret the primary challenge as to accurately retrieve and reason over
detailed multimodal information from long inputs. As such, we formulate a novel
video question-answering task termed referring reasoning. Specifically, as part
of the question, it contains a referring query that references related video
contexts, called referred context. The model is then required to reason over
relevant video details from the referred context. Following the paradigm of
referring reasoning, we curate 6,678 human-annotated multiple-choice questions
in 17 fine-grained categories, establishing one of the most comprehensive
benchmarks for long-form video understanding. Evaluations suggest that the
LongVideoBench presents significant challenges even for the most advanced
proprietary models (e.g. GPT-4o, Gemini-1.5-Pro, GPT-4-Turbo), while their
open-source counterparts show an even larger performance gap. In addition, our
results indicate that model performance on the benchmark improves only when
they are capable of processing more frames, positioning LongVideoBench as a
valuable benchmark for evaluating future-generation long-context LMMs.",2024-07-22,"Haoning Wu, Dongxu Li, Bei Chen, Junnan Li",http://arxiv.org/pdf/2407.15754v1,cs.CL
OMoS-QA: A Dataset for Cross-Lingual Extractive Question Answering in a German Migration Context,"When immigrating to a new country, it is easy to feel overwhelmed by the need
to obtain information on financial support, housing, schooling, language
courses, and other issues. If relocation is rushed or even forced, the
necessity for high-quality answers to such questions is all the more urgent.
Official immigration counselors are usually overbooked, and online systems
could guide newcomers to the requested information or a suitable counseling
service.
  To this end, we present OMoS-QA, a dataset of German and English questions
paired with relevant trustworthy documents and manually annotated answers,
specifically tailored to this scenario. Questions are automatically generated
with an open-source large language model (LLM) and answer sentences are
selected by crowd workers with high agreement. With our data, we conduct a
comparison of 5 pretrained LLMs on the task of extractive question answering
(QA) in German and English. Across all models and both languages, we find high
precision and low-to-mid recall in selecting answer sentences, which is a
favorable trade-off to avoid misleading users. This performance even holds up
when the question language does not match the document language. When it comes
to identifying unanswerable questions given a context, there are larger
differences between the two languages.",2024-07-22,"Steffen Kleinle, Jakob Prange, Annemarie Friedrich",http://arxiv.org/pdf/2407.15736v1,cs.CL
DStruct2Design: Data and Benchmarks for Data Structure Driven Generative Floor Plan Design,"Text conditioned generative models for images have yielded impressive
results. Text conditioned floorplan generation as a special type of raster
image generation task also received particular attention. However there are
many use cases in floorpla generation where numerical properties of the
generated result are more important than the aesthetics. For instance, one
might want to specify sizes for certain rooms in a floorplan and compare the
generated floorplan with given specifications Current approaches, datasets and
commonly used evaluations do not support these kinds of constraints. As such,
an attractive strategy is to generate an intermediate data structure that
contains numerical properties of a floorplan which can be used to generate the
final floorplan image. To explore this setting we (1) construct a new dataset
for this data-structure to data-structure formulation of floorplan generation
using two popular image based floorplan datasets RPLAN and ProcTHOR-10k, and
provide the tools to convert further procedurally generated ProcTHOR floorplan
data into our format. (2) We explore the task of floorplan generation given a
partial or complete set of constraints and we design a series of metrics and
benchmarks to enable evaluating how well samples generated from models respect
the constraints. (3) We create multiple baselines by finetuning a large
language model (LLM), Llama3, and demonstrate the feasibility of using
floorplan data structure conditioned LLMs for the problem of floorplan
generation respecting numerical constraints. We hope that our new datasets and
benchmarks will encourage further research on different ways to improve the
performance of LLMs and other generative modelling techniques for generating
designs where quantitative constraints are only partially specified, but must
be respected.",2024-07-22,"Zhi Hao Luo, Luis Lara, Ge Ya Luo, Florian Golemo, Christopher Beckham, Christopher Pal",http://arxiv.org/pdf/2407.15723v1,cs.CL
Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability,"Large language models (LLMs) have emerged as powerful tools for many AI
problems and exhibit remarkable in-context learning (ICL) capabilities.
Compositional ability, solving unseen complex tasks that combine two or more
simple tasks, is an essential reasoning ability for Artificial General
Intelligence. Despite the tremendous success of LLMs, how they approach
composite tasks, especially those not encountered during the pretraining phase,
remains an open and largely underexplored question. In this study, we delve
into the ICL capabilities of LLMs on composite tasks, with only simple tasks as
in-context examples. We develop a test suite of composite tasks including
linguistic and logical challenges and perform empirical studies across
different LLM families. We observe that models exhibit divergent behaviors: (1)
For simpler composite tasks that apply distinct mapping mechanisms to different
input segments, the models demonstrate decent compositional ability, while
scaling up the model enhances this ability; (2) for more complex composite
tasks involving reasoning multiple steps, where each step represents one task,
models typically underperform, and scaling up generally provides no
improvements. We offer theoretical analysis in a simplified setting, explaining
that models exhibit compositional capability when the task handles different
input parts separately. We believe our work sheds new light on the capabilities
of LLMs in solving composite tasks regarding the nature of the tasks and model
scale. Our dataset and code are available at
{\url{https://github.com/OliverXUZY/LLM_Compose}}.",2024-07-22,"Zhuoyan Xu, Zhenmei Shi, Yingyu Liang",http://arxiv.org/pdf/2407.15720v2,cs.CL
AssistantBench: Can Web Agents Solve Realistic and Time-Consuming Tasks?,"Language agents, built on top of language models (LMs), are systems that can
interact with complex environments, such as the open web. In this work, we
examine whether such agents can perform realistic and time-consuming tasks on
the web, e.g., monitoring real-estate markets or locating relevant nearby
businesses. We introduce AssistantBench, a challenging new benchmark consisting
of 214 realistic tasks that can be automatically evaluated, covering different
scenarios and domains. We find that AssistantBench exposes the limitations of
current systems, including language models and retrieval-augmented language
models, as no model reaches an accuracy of more than 26 points. While
closed-book LMs perform well in terms of accuracy, they exhibit low precision
and tend to hallucinate facts. State-of-the-art web agents reach a score of
near zero. Additionally, we introduce SeePlanAct (SPA), a new web agent that
significantly outperforms previous agents, and an ensemble of SPA and
closed-book models reaches the best overall performance. Moreover, we analyze
failures of current systems and highlight that open web navigation remains a
major challenge.",2024-07-22,"Ori Yoran, Samuel Joseph Amouyal, Chaitanya Malaviya, Ben Bogin, Ofir Press, Jonathan Berant",http://arxiv.org/pdf/2407.15711v2,cs.CL
Supporting the Digital Autonomy of Elders Through LLM Assistance,"The internet offers tremendous access to services, social connections, and
needed products. However, to those without sufficient experience, engaging with
businesses and friends across the internet can be daunting due to the ever
present danger of scammers and thieves, to say nothing of the myriad of
potential computer viruses. Like a forest rich with both edible and poisonous
plants, those familiar with the norms inhabit it safely with ease while
newcomers need a guide. However, reliance on a human digital guide can be
taxing and often impractical. We propose and pilot a simple but unexplored
idea: could an LLM provide the necessary support to help the elderly who are
separated by the digital divide safely achieve digital autonomy?",2024-07-22,"Jesse Roberts, Lindsey Roberts, Alice Reed",http://arxiv.org/pdf/2407.15695v1,cs.CL
Counter Turing Test ($CT^2$): Investigating AI-Generated Text Detection for Hindi -- Ranking LLMs based on Hindi AI Detectability Index ($ADI_{hi}$),"The widespread adoption of Large Language Models (LLMs) and awareness around
multilingual LLMs have raised concerns regarding the potential risks and
repercussions linked to the misapplication of AI-generated text, necessitating
increased vigilance. While these models are primarily trained for English,
their extensive training on vast datasets covering almost the entire web,
equips them with capabilities to perform well in numerous other languages.
AI-Generated Text Detection (AGTD) has emerged as a topic that has already
received immediate attention in research, with some initial methods having been
proposed, soon followed by the emergence of techniques to bypass detection. In
this paper, we report our investigation on AGTD for an indic language Hindi.
Our major contributions are in four folds: i) examined 26 LLMs to evaluate
their proficiency in generating Hindi text, ii) introducing the AI-generated
news article in Hindi ($AG_{hi}$) dataset, iii) evaluated the effectiveness of
five recently proposed AGTD techniques: ConDA, J-Guard, RADAR, RAIDAR and
Intrinsic Dimension Estimation for detecting AI-generated Hindi text, iv)
proposed Hindi AI Detectability Index ($ADI_{hi}$) which shows a spectrum to
understand the evolving landscape of eloquence of AI-generated text in Hindi.
The code and dataset is available at
https://github.com/ishank31/Counter_Turing_Test",2024-07-22,"Ishan Kavathekar, Anku Rani, Ashmit Chamoli, Ponnurangam Kumaraguru, Amit Sheth, Amitava Das",http://arxiv.org/pdf/2407.15694v2,cs.CL
Psychometric Alignment: Capturing Human Knowledge Distributions via Language Models,"Language models (LMs) are increasingly used to simulate human-like responses
in scenarios where accurately mimicking a population's behavior can guide
decision-making, such as in developing educational materials and designing
public policies. The objective of these simulations is for LMs to capture the
variations in human responses, rather than merely providing the expected
correct answers. Prior work has shown that LMs often generate unrealistically
accurate responses, but there are no established metrics to quantify how
closely the knowledge distribution of LMs aligns with that of humans. To
address this, we introduce ""psychometric alignment,"" a metric that measures the
extent to which LMs reflect human knowledge distribution. Assessing this
alignment involves collecting responses from both LMs and humans to the same
set of test items and using Item Response Theory to analyze the differences in
item functioning between the groups. We demonstrate that our metric can capture
important variations in populations that traditional metrics, like differences
in accuracy, fail to capture. We apply this metric to assess existing LMs for
their alignment with human knowledge distributions across three real-world
domains. We find significant misalignment between LMs and human populations,
though using persona-based prompts can improve alignment. Interestingly,
smaller LMs tend to achieve greater psychometric alignment than larger LMs.
Further, training LMs on human response data from the target distribution
enhances their psychometric alignment on unseen test items, but the
effectiveness of such training varies across domains.",2024-07-22,"Joy He-Yueya, Wanjing Anya Ma, Kanishk Gandhi, Benjamin W. Domingue, Emma Brunskill, Noah D. Goodman",http://arxiv.org/pdf/2407.15645v1,cs.CL
RadioRAG: Factual large language models for enhanced diagnostics in radiology using online retrieval augmented generation,"Large language models (LLMs) often generate outdated or inaccurate
information based on static training datasets. Retrieval augmented generation
(RAG) mitigates this by integrating outside data sources. While previous RAG
systems used pre-assembled, fixed databases with limited flexibility, we have
developed Radiology RAG (RadioRAG), an end-to-end framework that retrieves data
from authoritative radiologic online sources in real-time. We evaluate the
diagnostic accuracy of various LLMs when answering radiology-specific questions
with and without access to additional online information via RAG. Using 80
questions from the RSNA Case Collection across radiologic subspecialties and 24
additional expert-curated questions with reference standard answers, LLMs
(GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B and 70B]) were
prompted with and without RadioRAG in a zero-shot inference scenario RadioRAG
retrieved context-specific information from www.radiopaedia.org in real-time.
Accuracy was investigated. Statistical analyses were performed using
bootstrapping. The results were further compared with human performance.
RadioRAG improved diagnostic accuracy across most LLMs, with relative accuracy
increases ranging up to 54% for different LLMs. It matched or exceeded non-RAG
models and the human radiologist in question answering across radiologic
subspecialties, particularly in breast imaging and emergency radiology.
However, the degree of improvement varied among models; GPT-3.5-turbo and
Mixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2
showed no improvement, highlighting variability in RadioRAG's effectiveness.
LLMs benefit when provided access to domain-specific data beyond their training
data. For radiology, RadioRAG establishes a robust framework that substantially
improves diagnostic accuracy and factuality in radiological question answering.",2024-07-22,"Soroosh Tayebi Arasteh, Mahshad Lotfinia, Keno Bressem, Robert Siepmann, Lisa Adams, Dyke Ferber, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn",http://arxiv.org/pdf/2407.15621v2,cs.CL
Can GPT-4 learn to analyse moves in research article abstracts?,"One of the most powerful and enduring ideas in written discourse analysis is
that genres can be described in terms of the moves which structure a writer's
purpose. Considerable research has sought to identify these distinct
communicative acts, but analyses have been beset by problems of subjectivity,
reliability and the time-consuming need for multiple coders to confirm
analyses. In this paper we employ the affordances of GPT-4 to automate the
annotation process by using natural language prompts. Focusing on abstracts
from articles in four applied linguistics journals, we devise prompts which
enable the model to identify moves effectively. The annotated outputs of these
prompts were evaluated by two assessors with a third addressing disagreements.
The results show that an 8-shot prompt was more effective than one using two,
confirming that the inclusion of examples illustrating areas of variability can
enhance GPT-4's ability to recognize multiple moves in a single sentence and
reduce bias related to textual position. We suggest that GPT-4 offers
considerable potential in automating this annotation process, when human actors
with domain specific linguistic expertise inform the prompting process.",2024-07-22,"Danni Yu, Marina Bondi, Ken Hyland",http://arxiv.org/pdf/2407.15612v3,cs.CL
StylusAI: Stylistic Adaptation for Robust German Handwritten Text Generation,"In this study, we introduce StylusAI, a novel architecture leveraging
diffusion models in the domain of handwriting style generation. StylusAI is
specifically designed to adapt and integrate the stylistic nuances of one
language's handwriting into another, particularly focusing on blending English
handwriting styles into the context of the German writing system. This approach
enables the generation of German text in English handwriting styles and German
handwriting styles into English, enriching machine-generated handwriting
diversity while ensuring that the generated text remains legible across both
languages. To support the development and evaluation of StylusAI, we present
the \lq{Deutscher Handschriften-Datensatz}\rq~(DHSD), a comprehensive dataset
encompassing 37 distinct handwriting styles within the German language. This
dataset provides a fundamental resource for training and benchmarking in the
realm of handwritten text generation. Our results demonstrate that StylusAI not
only introduces a new method for style adaptation in handwritten text
generation but also surpasses existing models in generating handwriting samples
that improve both text quality and stylistic fidelity, evidenced by its
performance on the IAM database and our newly proposed DHSD. Thus, StylusAI
represents a significant advancement in the field of handwriting style
generation, offering promising avenues for future research and applications in
cross-linguistic style adaptation for languages with similar scripts.",2024-07-22,"Nauman Riaz, Saifullah Saifullah, Stefan Agne, Andreas Dengel, Sheraz Ahmed",http://arxiv.org/pdf/2407.15608v1,cs.CL
Unlocking the Potential: Benchmarking Large Language Models in Water Engineering and Research,"Recent advancements in Large Language Models (LLMs) have sparked interest in
their potential applications across various fields. This paper embarked on a
pivotal inquiry: Can existing LLMs effectively serve as ""water expert models""
for water engineering and research tasks? This study was the first to evaluate
LLMs' contributions across various water engineering and research tasks by
establishing a domain-specific benchmark suite, namely, WaterER. Herein, we
prepared 983 tasks related to water engineering and research, categorized into
""wastewater treatment"", ""environmental restoration"", ""drinking water treatment
and distribution"", ""sanitation"", ""anaerobic digestion"" and ""contaminants
assessment"". We evaluated the performance of seven LLMs (i.e., GPT-4, GPT-3.5,
Gemini, GLM-4, ERNIE, QWEN and Llama3) on these tasks. We highlighted the
strengths of GPT-4 in handling diverse and complex tasks of water engineering
and water research, the specialized capabilities of Gemini in academic
contexts, Llama3's strongest capacity to answer Chinese water engineering
questions and the competitive performance of Chinese-oriented models like
GLM-4, ERNIE and QWEN in some water engineering tasks. More specifically,
current LLMs excelled particularly in generating precise research gaps for
papers on ""contaminants and related water quality monitoring and assessment"".
Additionally, they were more adept at creating appropriate titles for research
papers on ""treatment processes for wastewaters"", ""environmental restoration"",
and ""drinking water treatment"". Overall, this study pioneered evaluating LLMs
in water engineering and research by introducing the WaterER benchmark to
assess the trustworthiness of their predictions. This standardized evaluation
framework would also drive future advancements in LLM technology by using
targeting datasets, propelling these models towards becoming true ""water
expert"".",2024-07-22,"Boyan Xu, Liang Wen, Zihao Li, Yuxing Yang, Guanlan Wu, Xiongpeng Tang, Yu Li, Zihao Wu, Qingxian Su, Xueqing Shi, Yue Yang, Rui Tong, How Yong Ng",http://arxiv.org/pdf/2407.21045v1,cs.CL
Unsupervised Robust Cross-Lingual Entity Alignment via Neighbor Triple Matching with Entity and Relation Texts,"Cross-lingual entity alignment (EA) enables the integration of multiple
knowledge graphs (KGs) across different languages, providing users with
seamless access to diverse and comprehensive knowledge. Existing methods,
mostly supervised, face challenges in obtaining labeled entity pairs. To
address this, recent studies have shifted towards self-supervised and
unsupervised frameworks. Despite their effectiveness, these approaches have
limitations: (1) Relation passing: mainly focusing on the entity while
neglecting the semantic information of relations, (2) Isomorphic assumption:
assuming isomorphism between source and target graphs, which leads to noise and
reduced alignment accuracy, and (3) Noise vulnerability: susceptible to noise
in the textual features, especially when encountering inconsistent translations
or Out-of-Vocabulary (OOV) problems. In this paper, we propose ERAlign, an
unsupervised and robust cross-lingual EA pipeline that jointly performs
Entity-level and Relation-level Alignment by neighbor triple matching strategy
using semantic textual features of relations and entities. Its refinement step
iteratively enhances results by fusing entity-level and relation-level
alignments based on neighbor triple matching. The additional verification step
examines the entities' neighbor triples as the linearized text. This
Align-then-Verify pipeline rigorously assesses alignment results, achieving
near-perfect alignment even in the presence of noisy textual features of
entities. Our extensive experiments demonstrate that the robustness and general
applicability of ERAlign improved the accuracy and effectiveness of EA tasks,
contributing significantly to knowledge-oriented applications.",2024-07-22,"Soojin Yoon, Sungho Ko, Tongyoung Kim, SeongKu Kang, Jinyoung Yeo, Dongha Lee",http://arxiv.org/pdf/2407.15588v5,cs.CL
An Empirical Study of Retrieval Augmented Generation with Chain-of-Thought,"Since the launch of ChatGPT at the end of 2022, generative dialogue models
represented by ChatGPT have quickly become essential tools in daily life. As
user expectations increase, enhancing the capability of generative dialogue
models to solve complex problems has become a focal point of current research.
This paper delves into the effectiveness of the RAFT (Retrieval Augmented
Fine-Tuning) method in improving the performance of Generative dialogue models.
RAFT combines chain-of-thought with model supervised fine-tuning (SFT) and
retrieval augmented generation (RAG), which significantly enhanced the model's
information extraction and logical reasoning abilities. We evaluated the RAFT
method across multiple datasets and analysed its performance in various
reasoning tasks, including long-form QA and short-form QA tasks, tasks in both
Chinese and English, and supportive and comparison reasoning tasks. Notably, it
addresses the gaps in previous research regarding long-form QA tasks and
Chinese datasets. Moreover, we also evaluate the benefit of the
chain-of-thought (CoT) in the RAFT method. This work offers valuable insights
for studies focused on enhancing the performance of generative dialogue models.",2024-07-22,"Yuetong Zhao, Hongyu Cao, Xianyu Zhao, Zhijian Ou",http://arxiv.org/pdf/2407.15569v2,cs.CL
SETTP: Style Extraction and Tunable Inference via Dual-level Transferable Prompt Learning,"Text style transfer, an important research direction in natural language
processing, aims to adapt the text to various preferences but often faces
challenges with limited resources. In this work, we introduce a novel method
termed Style Extraction and Tunable Inference via Dual-level Transferable
Prompt Learning (SETTP) for effective style transfer in low-resource scenarios.
First, SETTP learns source style-level prompts containing fundamental style
characteristics from high-resource style transfer. During training, the source
style-level prompts are transferred through an attention module to derive a
target style-level prompt for beneficial knowledge provision in low-resource
style transfer. Additionally, we propose instance-level prompts obtained by
clustering the target resources based on the semantic content to reduce
semantic bias. We also propose an automated evaluation approach of style
similarity based on alignment with human evaluations using ChatGPT-4. Our
experiments across three resourceful styles show that SETTP requires only
1/20th of the data volume to achieve performance comparable to state-of-the-art
methods. In tasks involving scarce data like writing style and role style,
SETTP outperforms previous methods by 16.24\%.",2024-07-22,"Chunzhen Jin, Yongfeng Huang, Yaqi Wang, Peng Cao, Osmar Zaiane",http://arxiv.org/pdf/2407.15556v1,cs.CL
Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs,"Large language models (LLMs) can often be made to behave in undesirable ways
that they are explicitly fine-tuned not to. For example, the LLM red-teaming
literature has produced a wide variety of 'jailbreaking' techniques to elicit
harmful text from models that were fine-tuned to be harmless. Recent work on
red-teaming, model editing, and interpretability suggests that this challenge
stems from how (adversarial) fine-tuning largely serves to suppress rather than
remove undesirable capabilities from LLMs. Prior work has introduced latent
adversarial training (LAT) as a way to improve robustness to broad classes of
failures. These prior works have considered untargeted latent space attacks
where the adversary perturbs latent activations to maximize loss on examples of
desirable behavior. Untargeted LAT can provide a generic type of robustness but
does not leverage information about specific failure modes. Here, we experiment
with targeted LAT where the adversary seeks to minimize loss on a specific
competing task. We find that it can augment a wide variety of state-of-the-art
methods. First, we use targeted LAT to improve robustness to jailbreaks,
outperforming a strong R2D2 baseline with orders of magnitude less compute.
Second, we use it to more effectively remove backdoors with no knowledge of the
trigger. Finally, we use it to more effectively unlearn knowledge for specific
undesirable tasks in a way that is also more robust to re-learning. Overall,
our results suggest that targeted LAT can be an effective tool for defending
against harmful behaviors from LLMs.",2024-07-22,"Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper",http://arxiv.org/pdf/2407.15549v2,cs.CL
Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models,"The inference demand for LLMs has skyrocketed in recent months, and serving
models with low latencies remains challenging due to the quadratic input length
complexity of the attention layers. In this work, we investigate the effect of
dropping MLP and attention layers at inference time on the performance of
Llama-v2 models. We find that dropping dreeper attention layers only marginally
decreases performance but leads to the best speedups alongside dropping entire
layers. For example, removing 33\% of attention layers in a 13B Llama2 model
results in a 1.8\% drop in average performance over the OpenLLM benchmark. We
also observe that skipping layers except the latter layers reduces performances
for more layers skipped, except for skipping the attention layers.",2024-07-22,"Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini",http://arxiv.org/pdf/2407.15516v1,cs.CL
Compensate Quantization Errors+: Quantized Models Are Inquisitive Learners,"The quantization of large language models (LLMs) has been a prominent
research area aimed at enabling their lightweight deployment in practice.
Existing research about LLM's quantization has mainly explored the interplay
between weights and activations, or employing auxiliary components while
neglecting the necessity of adjusting weights during quantization.
Consequently, original weight distributions frequently fail to yield desired
results after round-to-nearest (RTN) quantization. Even though incorporating
techniques such as mixed precision and low-rank error approximation in LLM's
quantization can yield improved results, they inevitably introduce additional
computational overhead. On the other hand, traditional techniques for weight
quantization, such as Generative Post-Training Quantization, rely on manually
tweaking weight distributions to minimize local errors, but they fall short of
achieving globally optimal outcomes. Although the recently proposed Learnable
Singular-value Increment improves global weight quantization by modifying
weight distributions, it disrupts the original distribution considerably. This
introduces pronounced bias toward the training data and can degrade downstream
task performance. In this paper, we introduce Singular-value Diagonal
Expansion, a more nuanced approach to refining weight distributions to achieve
better quantization alignment. Furthermore, we introduce Cross-layer Learning
that improves overall quantization outcomes by distributing errors more evenly
across layers. Our plug-and-play weight-quantization methods demonstrate
substantial performance improvements over state-of-the-art approaches,
including OmniQuant, DuQuant, and PrefixQuant.",2024-07-22,"Yifei Gao, Jie Ou, Lei Wang, Jun Cheng, Mengchu Zhou",http://arxiv.org/pdf/2407.15508v3,cs.CL
Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models,"We formalize the problem of prompt compression for large language models
(LLMs) and present a framework to unify token-level prompt compression methods
which create hard prompts for black-box models. We derive the distortion-rate
function for this setup as a linear program, and provide an efficient algorithm
to compute this fundamental limit via the dual of the linear program. Using the
distortion-rate function as the baseline, we study the performance of existing
compression schemes on a synthetic dataset consisting of prompts generated from
a Markov chain, natural language queries, and their respective answers. Our
empirical analysis demonstrates the criticality of query-aware prompt
compression, where the compressor has knowledge of the downstream task/query
for the black-box LLM. We show that there is a large gap between the
performance of current prompt compression methods and the optimal strategy, and
propose Adaptive QuerySelect, a query-aware, variable-rate adaptation of a
prior work to close the gap. We extend our experiments to a small natural
language dataset to further confirm our findings on our synthetic dataset.",2024-07-22,"Alliot Nagle, Adway Girish, Marco Bondaschi, Michael Gastpar, Ashok Vardhan Makkuva, Hyeji Kim",http://arxiv.org/pdf/2407.15504v2,cs.CL
Refining Corpora from a Model Calibration Perspective for Chinese Spelling Correction,"Chinese Spelling Correction (CSC) commonly lacks large-scale high-quality
corpora, due to the labor-intensive labeling of spelling errors in real-life
human writing or typing scenarios. Two data augmentation methods are widely
adopted: (1) \textit{Random Replacement} with the guidance of confusion sets
and (2) \textit{OCR/ASR-based Generation} that simulates character misusing.
However, both methods inevitably introduce noisy data (e.g., false spelling
errors), potentially leading to over-correction. By carefully analyzing the two
types of corpora, we find that though the latter achieves more robust
generalization performance, the former yields better-calibrated CSC models. We
then provide a theoretical analysis of this empirical observation, based on
which a corpus refining strategy is proposed. Specifically, OCR/ASR-based data
samples are fed into a well-calibrated CSC model trained on random
replacement-based corpora and then filtered based on prediction confidence. By
learning a simple BERT-based model on the refined OCR/ASR-based corpus, we set
up impressive state-of-the-art performance on three widely-used benchmarks,
while significantly alleviating over-correction (e.g., lowering false positive
predictions).",2024-07-22,"Dingyao Yu, Yang An, Wei Ye, Xiongfeng Xiao, Shaoguang Mao, Tao Ge, Shikun Zhang",http://arxiv.org/pdf/2407.15498v1,cs.CL
A Comparison of Language Modeling and Translation as Multilingual Pretraining Objectives,"Pretrained language models (PLMs) display impressive performances and have
captured the attention of the NLP community. Establishing best practices in
pretraining has, therefore, become a major focus of NLP research, especially
since insights gained from monolingual English models may not necessarily apply
to more complex multilingual models. One significant caveat of the current
state of the art is that different works are rarely comparable: they often
discuss different parameter counts, training data, and evaluation methodology.
  This paper proposes a comparison of multilingual pretraining objectives in a
controlled methodological environment. We ensure that training data and model
architectures are comparable, and discuss the downstream performances across 6
languages that we observe in probing and fine-tuning scenarios. We make two key
observations: (1) the architecture dictates which pretraining objective is
optimal; (2) multilingual translation is a very effective pretraining objective
under the right conditions. We make our code, data, and model weights available
at \texttt{\url{https://github.com/Helsinki-NLP/lm-vs-mt}}.",2024-07-22,"Zihao Li, Shaoxiong Ji, Timothee Mickus, Vincent Segonne, Jörg Tiedemann",http://arxiv.org/pdf/2407.15489v2,cs.CL
Text-to-Battery Recipe: A language modeling-based protocol for automatic battery recipe extraction and retrieval,"Recent studies have increasingly applied natural language processing (NLP) to
automatically extract experimental research data from the extensive battery
materials literature. Despite the complex process involved in battery
manufacturing -- from material synthesis to cell assembly -- there has been no
comprehensive study systematically organizing this information. In response, we
propose a language modeling-based protocol, Text-to-Battery Recipe (T2BR), for
the automatic extraction of end-to-end battery recipes, validated using a case
study on batteries containing LiFePO4 cathode material. We report machine
learning-based paper filtering models, screening 2,174 relevant papers from the
keyword-based search results, and unsupervised topic models to identify 2,876
paragraphs related to cathode synthesis and 2,958 paragraphs related to cell
assembly. Then, focusing on the two topics, two deep learning-based named
entity recognition models are developed to extract a total of 30 entities --
including precursors, active materials, and synthesis methods -- achieving F1
scores of 88.18% and 94.61%. The accurate extraction of entities enables the
systematic generation of 165 end-toend recipes of LiFePO4 batteries. Our
protocol and results offer valuable insights into specific trends, such as
associations between precursor materials and synthesis methods, or combinations
between different precursor materials. We anticipate that our findings will
serve as a foundational knowledge base for facilitating battery-recipe
information retrieval. The proposed protocol will significantly accelerate the
review of battery material literature and catalyze innovations in battery
design and development.",2024-07-22,"Daeun Lee, Jaewoong Choi, Hiroshi Mizuseki, Byungju Lee",http://arxiv.org/pdf/2407.15459v1,cs.CL
"Developing a Reliable, Fast, General-Purpose Hallucination Detection and Mitigation Service","Hallucination, a phenomenon where large language models (LLMs) produce output
that is factually incorrect or unrelated to the input, is a major challenge for
LLM applications that require accuracy and dependability. In this paper, we
introduce a reliable and high-speed production system aimed at detecting and
rectifying the hallucination issue within LLMs. Our system encompasses named
entity recognition (NER), natural language inference (NLI), span-based
detection (SBD), and an intricate decision tree-based process to reliably
detect a wide range of hallucinations in LLM responses. Furthermore, we have
crafted a rewriting mechanism that maintains an optimal mix of precision,
response time, and cost-effectiveness. We detail the core elements of our
framework and underscore the paramount challenges tied to response time,
availability, and performance metrics, which are crucial for real-world
deployment of these technologies. Our extensive evaluation, utilizing offline
data and live production traffic, confirms the efficacy of our proposed
framework and service.",2024-07-22,"Song Wang, Xun Wang, Jie Mei, Yujia Xie, Sean Muarray, Zhang Li, Lingfeng Wu, Si-Qing Chen, Wayne Xiong",http://arxiv.org/pdf/2407.15441v2,cs.CL
Empirical Capacity Model for Self-Attention Neural Networks,"Large pretrained self-attention neural networks, or transformers, have been
very successful in various tasks recently. The performance of a model on a
given task depends on its ability to memorize and generalize the training data.
Large transformer models, which may have billions of parameters, in theory have
a huge capacity to memorize content. However, the current algorithms for the
optimization fall short of the theoretical capacity, and the capacity is also
highly dependent on the content. In this paper, we focus on the memory capacity
of these models obtained using common training algorithms and synthetic
training data. Based on the results, we derive an empirical capacity model
(ECM) for a generic transformer. The ECM can be used to design task-specific
transformer models with an optimal number of parameters in cases where the
target memorization capability of the task can be defined.",2024-07-22,"Aki Härmä, Marcin Pietrasik, Anna Wilbik",http://arxiv.org/pdf/2407.15425v2,cs.CL
LLaST: Improved End-to-end Speech Translation System Leveraged by Large Language Models,"We introduces LLaST, a framework for building high-performance Large Language
model based Speech-to-text Translation systems. We address the limitations of
end-to-end speech translation(E2E ST) models by exploring model architecture
design and optimization techniques tailored for LLMs. Our approach includes
LLM-based speech translation architecture design, ASR-augmented training,
multilingual data augmentation, and dual-LoRA optimization. Our approach
demonstrates superior performance on the CoVoST-2 benchmark and showcases
exceptional scaling capabilities powered by LLMs. We believe this effective
method will serve as a strong baseline for speech translation and provide
insights for future improvements of the LLM-based speech translation framework.
We release the data, code and models in https://github.com/openaudiolab/LLaST.",2024-07-22,"Xi Chen, Songyang Zhang, Qibing Bai, Kai Chen, Satoshi Nakamura",http://arxiv.org/pdf/2407.15415v1,cs.CL
Impacts of Anthropomorphizing Large Language Models in Learning Environments,"Large Language Models (LLMs) are increasingly being used in learning
environments to support teaching-be it as learning companions or as tutors.
With our contribution, we aim to discuss the implications of the
anthropomorphization of LLMs in learning environments on educational theory to
build a foundation for more effective learning outcomes and understand their
emotional impact on learners. According to the media equation, people tend to
respond to media in the same way as they would respond to another person. A
study conducted by the Georgia Institute of Technology showed that chatbots can
be successfully implemented in learning environments. In this study, learners
in selected online courses were unable to distinguish the chatbot from a ""real""
teacher. As LLM-based chatbots such as OpenAI's GPT series are increasingly
used in educational tools, it is important to understand how the attribution
processes to LLM-based chatbots in terms of anthropomorphization affect
learners' emotions.",2024-07-22,"Kristina Schaaff, Marc-André Heidelmann",http://arxiv.org/pdf/2408.03945v1,cs.CL
Knowledge Mechanisms in Large Language Models: A Survey and Perspective,"Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial
for advancing towards trustworthy AGI. This paper reviews knowledge mechanism
analysis from a novel taxonomy including knowledge utilization and evolution.
Knowledge utilization delves into the mechanism of memorization, comprehension
and application, and creation. Knowledge evolution focuses on the dynamic
progression of knowledge within individual and group LLMs. Moreover, we discuss
what knowledge LLMs have learned, the reasons for the fragility of parametric
knowledge, and the potential dark knowledge (hypothesis) that will be
challenging to address. We hope this work can help understand knowledge in LLMs
and provide insights for future research.",2024-07-22,"Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang",http://arxiv.org/pdf/2407.15017v4,cs.CL
Imposter.AI: Adversarial Attacks with Hidden Intentions towards Aligned Large Language Models,"With the development of large language models (LLMs) like ChatGPT, both their
vast applications and potential vulnerabilities have come to the forefront.
While developers have integrated multiple safety mechanisms to mitigate their
misuse, a risk remains, particularly when models encounter adversarial inputs.
This study unveils an attack mechanism that capitalizes on human conversation
strategies to extract harmful information from LLMs. We delineate three pivotal
strategies: (i) decomposing malicious questions into seemingly innocent
sub-questions; (ii) rewriting overtly malicious questions into more covert,
benign-sounding ones; (iii) enhancing the harmfulness of responses by prompting
models for illustrative examples. Unlike conventional methods that target
explicit malicious responses, our approach delves deeper into the nature of the
information provided in responses. Through our experiments conducted on
GPT-3.5-turbo, GPT-4, and Llama2, our method has demonstrated a marked efficacy
compared to conventional attack methods. In summary, this work introduces a
novel attack method that outperforms previous approaches, raising an important
question: How to discern whether the ultimate intent in a dialogue is
malicious?",2024-07-22,"Xiao Liu, Liangzhi Li, Tong Xiang, Fuying Ye, Lu Wei, Wangyue Li, Noa Garcia",http://arxiv.org/pdf/2407.15399v1,cs.CL
ALLaM: Large Language Models for Arabic and English,"We present ALLaM: Arabic Large Language Model, a series of large language
models to support the ecosystem of Arabic Language Technologies (ALT). ALLaM is
carefully trained considering the values of language alignment and knowledge
transfer at scale. Our autoregressive decoder-only architecture models
demonstrate how second-language acquisition via vocabulary expansion and
pretraining on a mixture of Arabic and English text can steer a model towards a
new language (Arabic) without any catastrophic forgetting in the original
language (English). Furthermore, we highlight the effectiveness of using
parallel/translated data to aid the process of knowledge alignment between
languages. Finally, we show that extensive alignment with human preferences can
significantly enhance the performance of a language model compared to models of
a larger scale with lower quality alignment. ALLaM achieves state-of-the-art
performance in various Arabic benchmarks, including MMLU Arabic, ACVA, and
Arabic Exams. Our aligned models improve both in Arabic and English from their
base aligned models.",2024-07-22,"M Saiful Bari, Yazeed Alnumay, Norah A. Alzahrani, Nouf M. Alotaibi, Hisham A. Alyahya, Sultan AlRashed, Faisal A. Mirza, Shaykhah Z. Alsubaie, Hassan A. Alahmed, Ghadah Alabduljabbar, Raghad Alkhathran, Yousef Almushayqih, Raneem Alnajim, Salman Alsubaihi, Maryam Al Mansour, Majed Alrubaian, Ali Alammari, Zaki Alawami, Abdulmohsen Al-Thubaity, Ahmed Abdelali, Jeril Kuriakose, Abdalghani Abujabal, Nora Al-Twairesh, Areeb Alowisheq, Haidar Khan",http://arxiv.org/pdf/2407.15390v1,cs.CL
The Development of a Comprehensive Spanish Dictionary for Phonetic and Lexical Tagging in Socio-phonetic Research (ESPADA),"Pronunciation dictionaries are an important component in the process of
speech forced alignment. The accuracy of these dictionaries has a strong effect
on the aligned speech data since they help the mapping between orthographic
transcriptions and acoustic signals. In this paper, I present the creation of a
comprehensive pronunciation dictionary in Spanish (ESPADA) that can be used in
most of the dialect variants of Spanish data. Current dictionaries focus on
specific regional variants, but with the flexible nature of our tool, it can be
readily applied to capture the most common phonetic differences across major
dialectal variants. We propose improvements to current pronunciation
dictionaries as well as mapping other relevant annotations such as
morphological and lexical information. In terms of size, it is currently the
most complete dictionary with more than 628,000 entries, representing words
from 16 countries. All entries come with their corresponding pronunciations,
morphological and lexical tagging, and other relevant information for phonetic
analysis: stress patterns, phonotactics, IPA transcriptions, and more. This
aims to equip socio-phonetic researchers with a complete open-source tool that
enhances dialectal research within socio-phonetic frameworks in the Spanish
language.",2024-07-22,Simon Gonzalez,http://arxiv.org/pdf/2407.15375v1,cs.CL
ILiAD: An Interactive Corpus for Linguistic Annotated Data from Twitter Posts,"Social Media platforms have offered invaluable opportunities for linguistic
research. The availability of up-to-date data, coming from any part in the
world, and coming from natural contexts, has allowed researchers to study
language in real time. One of the fields that has made great use of social
media platforms is Corpus Linguistics. There is currently a wide range of
projects which have been able to successfully create corpora from social media.
In this paper, we present the development and deployment of a linguistic corpus
from Twitter posts in English, coming from 26 news agencies and 27 individuals.
The main goal was to create a fully annotated English corpus for linguistic
analysis. We include information on morphology and syntax, as well as NLP
features such as tokenization, lemmas, and n- grams. The information is
presented through a range of powerful visualisations for users to explore
linguistic patterns in the corpus. With this tool, we aim to contribute to the
area of language technologies applied to linguistic research.",2024-07-22,Simon Gonzalez,http://arxiv.org/pdf/2407.15374v1,cs.CL
A Network Analysis Approach to Conlang Research Literature,"The field of conlang has evidenced an important growth in the last decades.
This has been the product of a wide interest in the use and study of conlangs
for artistic purposes. However, one important question is what it is happening
with conlang in the academic world. This paper aims to have an overall
understanding of the literature on conlang research. With this we aim to give a
realistic picture of the field in present days. We have implemented a
computational linguistic approach, combining bibliometrics and network analysis
to examine all publications available in the Scopus database. Analysing over
2300 academic publications since 1927 until 2022, we have found that Esperanto
is by far the most documented conlang. Three main authors have contributed to
this: Garv\'ia R., Fiedler S., and Blanke D. The 1970s and 1980s have been the
decades where the foundations of current research have been built. In terms of
methodologies, language learning and experimental linguistics are the ones
contributing to most to the preferred approaches of study in the field. We
present the results and discuss our limitations and future work.",2024-07-22,Simon Gonzalez,http://arxiv.org/pdf/2407.15370v1,cs.CL
Walking in Others' Shoes: How Perspective-Taking Guides Large Language Models in Reducing Toxicity and Bias,"The common toxicity and societal bias in contents generated by large language
models (LLMs) necessitate strategies to reduce harm. Present solutions often
demand white-box access to the model or substantial training, which is
impractical for cutting-edge commercial LLMs. Moreover, prevailing prompting
methods depend on external tool feedback and fail to simultaneously lessen
toxicity and bias. Motivated by social psychology principles, we propose a
novel strategy named \textbf{perspective-taking prompting (\textsc{PeT})} that
inspires LLMs to integrate diverse human perspectives and self-regulate their
responses. This self-correction mechanism can significantly diminish toxicity
(up to $89\%$) and bias (up to $73\%$) in LLMs' responses. Rigorous evaluations
and ablation studies are conducted on two commercial LLMs (ChatGPT and GLM) and
three open-source LLMs, revealing \textsc{PeT}'s superiority in producing less
harmful responses, outperforming five strong baselines.",2024-07-22,"Rongwu Xu, Zi'an Zhou, Tianwei Zhang, Zehan Qi, Su Yao, Ke Xu, Wei Xu, Han Qiu",http://arxiv.org/pdf/2407.15366v1,cs.CL
Dissecting Multiplication in Transformers: Insights into LLMs,"Transformer-based large language models have achieved remarkable performance
across various natural language processing tasks. However, they often struggle
with seemingly easy tasks like arithmetic despite their vast capabilities. This
stark disparity raise human's concerns about their safe and ethical use, hinder
their widespread adoption.In this paper, we focus on a typical arithmetic task,
integer multiplication, to explore and explain the imperfection of transformers
in this domain. We provide comprehensive analysis of a vanilla transformer
trained to perform n-digit integer multiplication. Our observations indicate
that the model decomposes multiplication task into multiple parallel subtasks,
sequentially optimizing each subtask for each digit to complete the final
multiplication. Based on observation and analysis, we infer the reasons of
transformers deficiencies in multiplication tasks lies in their difficulty in
calculating successive carryovers and caching intermediate results, and
confirmed this inference through experiments. Guided by these findings, we
propose improvements to enhance transformers performance on multiplication
tasks. These enhancements are validated through rigorous testing and
mathematical modeling, not only enhance transformer's interpretability, but
also improve its performance, e.g., we achieve over 99.9% accuracy on 5-digit
integer multiplication with a tiny transformer, outperform LLMs GPT-4. Our
method contributes to the broader fields of model understanding and
interpretability, paving the way for analyzing more complex tasks and
Transformer models. This work underscores the importance of explainable AI,
helping to build trust in large language models and promoting their adoption in
critical applications.",2024-07-22,"Luyu Qiu, Jianing Li, Chi Su, Chen Jason Zhang, Lei Chen",http://arxiv.org/pdf/2407.15360v1,cs.CL
CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning,"The key challenge of cross-modal domain-incremental learning (DIL) is to
enable the learning model to continuously learn from novel data with different
feature distributions under the same task without forgetting old ones. However,
existing top-performing methods still cause high forgetting rates, by lacking
intra-domain knowledge extraction and inter-domain common prompting strategy.
In this paper, we propose a simple yet effective framework, CP-Prompt, by
training limited parameters to instruct a pre-trained model to learn new
domains and avoid forgetting existing feature distributions. CP-Prompt captures
intra-domain knowledge by compositionally inserting personalized prompts on
multi-head self-attention layers and then learns the inter-domain knowledge
with a common prompting strategy. CP-Prompt shows superiority compared with
state-of-the-art baselines among three widely evaluated DIL tasks. The source
code is available at https://github.com/dannis97500/CP_Prompt.",2024-07-22,"Yu Feng, Zhen Tian, Yifan Zhu, Zongfu Han, Haoran Luo, Guangwei Zhang, Meina Song",http://arxiv.org/pdf/2407.21043v2,cs.CL
"UF-HOBI at ""Discharge Me!"": A Hybrid Solution for Discharge Summary Generation Through Prompt-based Tuning of GatorTronGPT Models","Automatic generation of discharge summaries presents significant challenges
due to the length of clinical documentation, the dispersed nature of patient
information, and the diverse terminology used in healthcare. This paper
presents a hybrid solution for generating discharge summary sections as part of
our participation in the ""Discharge Me!"" Challenge at the BioNLP 2024 Shared
Task. We developed a two-stage generation method using both extractive and
abstractive techniques, in which we first apply name entity recognition (NER)
to extract key clinical concepts, which are then used as input for a
prompt-tuning-based GatorTronGPT model to generate coherent text for two
important sections including ""Brief Hospital Course"" and ""Discharge
Instructions"". Our system was ranked 5th in this challenge, achieving an
overall score of 0.284. The results demonstrate the effectiveness of our hybrid
solution in improving the quality of automated discharge section generation.",2024-07-22,"Mengxian Lyu, Cheng Peng, Daniel Paredes, Ziyi Chen, Aokun Chen, Jiang Bian, Yonghui Wu",http://arxiv.org/pdf/2407.15359v1,cs.CL
Customized Retrieval Augmented Generation and Benchmarking for EDA Tool Documentation QA,"Retrieval augmented generation (RAG) enhances the accuracy and reliability of
generative AI models by sourcing factual information from external databases,
which is extensively employed in document-grounded question-answering (QA)
tasks. Off-the-shelf RAG flows are well pretrained on general-purpose
documents, yet they encounter significant challenges when being applied to
knowledge-intensive vertical domains, such as electronic design automation
(EDA). This paper addresses such issue by proposing a customized RAG framework
along with three domain-specific techniques for EDA tool documentation QA,
including a contrastive learning scheme for text embedding model fine-tuning, a
reranker distilled from proprietary LLM, and a generative LLM fine-tuned with
high-quality domain corpus. Furthermore, we have developed and released a
documentation QA evaluation benchmark, ORD-QA, for OpenROAD, an advanced
RTL-to-GDSII design platform. Experimental results demonstrate that our
proposed RAG flow and techniques have achieved superior performance on ORD-QA
as well as on a commercial tool, compared with state-of-the-arts. The ORD-QA
benchmark and the training dataset for our customized RAG flow are open-source
at https://github.com/lesliepy99/RAG-EDA.",2024-07-22,"Yuan Pu, Zhuolun He, Tairu Qiu, Haoyuan Wu, Bei Yu",http://arxiv.org/pdf/2407.15353v2,cs.CL
MAVEN-Fact: A Large-scale Event Factuality Detection Dataset,"Event Factuality Detection (EFD) task determines the factuality of textual
events, i.e., classifying whether an event is a fact, possibility, or
impossibility, which is essential for faithfully understanding and utilizing
event knowledge. However, due to the lack of high-quality large-scale data,
event factuality detection is under-explored in event understanding research,
which limits the development of EFD community. To address these issues and
provide faithful event understanding, we introduce MAVEN-Fact, a large-scale
and high-quality EFD dataset based on the MAVEN dataset. MAVEN-Fact includes
factuality annotations of 112,276 events, making it the largest EFD dataset.
Extensive experiments demonstrate that MAVEN-Fact is challenging for both
conventional fine-tuned models and large language models (LLMs). Thanks to the
comprehensive annotations of event arguments and relations in MAVEN, MAVEN-Fact
also supports some further analyses and we find that adopting event arguments
and relations helps in event factuality detection for fine-tuned models but
does not benefit LLMs. Furthermore, we preliminarily study an application case
of event factuality detection and find it helps in mitigating event-related
hallucination in LLMs. Our dataset and codes can be obtained from
\url{https://github.com/lcy2723/MAVEN-FACT}",2024-07-22,"Chunyang Li, Hao Peng, Xiaozhi Wang, Yunjia Qi, Lei Hou, Bin Xu, Juanzi Li",http://arxiv.org/pdf/2407.15352v1,cs.CL
LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation,"Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.",2024-07-22,"Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei",http://arxiv.org/pdf/2407.15351v2,cs.CL
Knowledge Acquisition Disentanglement for Knowledge-based Visual Question Answering with Large Language Models,"Knowledge-based Visual Question Answering (KVQA) requires both image and
world knowledge to answer questions. Current methods first retrieve knowledge
from the image and external knowledge base with the original complex question,
then generate answers with Large Language Models (LLMs). However, since the
original question contains complex elements that require knowledge from
different sources, acquiring different kinds of knowledge in a coupled manner
may confuse models and hinder them from retrieving precise knowledge.
Furthermore, the ``forward-only'' answering process fails to explicitly capture
the knowledge needs of LLMs, which can further hurt answering quality. To cope
with the above limitations, we propose DKA: Disentangled Knowledge Acquisition
from LLM feedback, a training-free framework that disentangles knowledge
acquisition to avoid confusion and uses LLM's feedback to specify the required
knowledge. Specifically, DKA requires LLMs to specify what knowledge they need
to answer the question and decompose the original complex question into two
simple sub-questions: Image-based sub-question and Knowledge-based
sub-question. Then we use the two sub-questions to retrieve knowledge from the
image and knowledge base, respectively. In this way, two knowledge acquisition
models can focus on the content that corresponds to them and avoid disturbance
of irrelevant elements in the original complex question, which can help to
provide more precise knowledge and better align the knowledge needs of LLMs to
yield correct answers. Experiments on benchmark datasets show that DKA
significantly outperforms SOTA models. To facilitate future research, our data
and code are available at \url{https://github.com/Lackel/DKA}.",2024-07-22,"Wenbin An, Feng Tian, Jiahao Nie, Wenkai Shi, Haonan Lin, Yan Chen, QianYing Wang, Yaqiang Wu, Guang Dai, Ping Chen",http://arxiv.org/pdf/2407.15346v1,cs.CL
Improving Minimum Bayes Risk Decoding with Multi-Prompt,"While instruction fine-tuned LLMs are effective text generators, sensitivity
to prompt construction makes performance unstable and sub-optimal in practice.
Relying on a single ""best"" prompt cannot capture all differing approaches to a
generation problem. Using this observation, we propose multi-prompt decoding,
where many candidate generations are decoded from a prompt bank at
inference-time. To ensemble candidates, we use Minimum Bayes Risk (MBR)
decoding, which selects a final output using a trained value metric. We show
multi-prompt improves MBR across a comprehensive set of conditional generation
tasks, and show this is a result of estimating a more diverse and higher
quality candidate space than that of a single prompt. Further experiments
confirm multi-prompt improves generation across tasks, models and metrics.",2024-07-22,"David Heineman, Yao Dou, Wei Xu",http://arxiv.org/pdf/2407.15343v2,cs.CL
ZZU-NLP at SIGHAN-2024 dimABSA Task: Aspect-Based Sentiment Analysis with Coarse-to-Fine In-context Learning,"The DimABSA task requires fine-grained sentiment intensity prediction for
restaurant reviews, including scores for Valence and Arousal dimensions for
each Aspect Term. In this study, we propose a Coarse-to-Fine In-context
Learning(CFICL) method based on the Baichuan2-7B model for the DimABSA task in
the SIGHAN 2024 workshop. Our method improves prediction accuracy through a
two-stage optimization process. In the first stage, we use fixed in-context
examples and prompt templates to enhance the model's sentiment recognition
capability and provide initial predictions for the test data. In the second
stage, we encode the Opinion field using BERT and select the most similar
training data as new in-context examples based on similarity. These examples
include the Opinion field and its scores, as well as related opinion words and
their average scores. By filtering for sentiment polarity, we ensure that the
examples are consistent with the test data. Our method significantly improves
prediction accuracy and consistency by effectively utilizing training data and
optimizing in-context examples, as validated by experimental results.",2024-07-22,"Senbin Zhu, Hanjie Zhao, Xingren Wang, Shanhong Liu, Yuxiang Jia, Hongying Zan",http://arxiv.org/pdf/2407.15341v1,cs.CL
Deep Learning for Economists,"Deep learning provides powerful methods to impute structured information from
large-scale, unstructured text and image datasets. For example, economists
might wish to detect the presence of economic activity in satellite images, or
to measure the topics or entities mentioned in social media, the congressional
record, or firm filings. This review introduces deep neural networks, covering
methods such as classifiers, regression models, generative AI, and embedding
models. Applications include classification, document digitization, record
linkage, and methods for data exploration in massive scale text and image
corpora. When suitable methods are used, deep learning models can be cheap to
tune and can scale affordably to problems involving millions or billions of
data points.. The review is accompanied by a companion website, EconDL, with
user-friendly demo notebooks, software resources, and a knowledge base that
provides technical details and additional applications.",2024-07-22,Melissa Dell,http://arxiv.org/pdf/2407.15339v3,cs.CL
RazorAttention: Efficient KV Cache Compression Through Retrieval Heads,"The memory and computational demands of Key-Value (KV) cache present
significant challenges for deploying long-context language models. Previous
approaches attempt to mitigate this issue by selectively dropping tokens, which
irreversibly erases critical information that might be needed for future
queries. In this paper, we propose a novel compression technique for KV cache
that preserves all token information. Our investigation reveals that: i) Most
attention heads primarily focus on the local context; ii) Only a few heads,
denoted as retrieval heads, can essentially pay attention to all input tokens.
These key observations motivate us to use separate caching strategy for
attention heads. Therefore, we propose RazorAttention, a training-free KV cache
compression algorithm, which maintains a full cache for these crucial retrieval
heads and discards the remote tokens in non-retrieval heads. Furthermore, we
introduce a novel mechanism involving a ""compensation token"" to further recover
the information in the dropped tokens. Extensive evaluations across a diverse
set of large language models (LLMs) demonstrate that RazorAttention achieves a
reduction in KV cache size by over 70% without noticeable impacts on
performance. Additionally, RazorAttention is compatible with FlashAttention,
rendering it an efficient and plug-and-play solution that enhances LLM
inference efficiency without overhead or retraining of the original model.",2024-07-22,"Hanlin Tang, Yang Lin, Jing Lin, Qingsen Han, Shikuan Hong, Yiwu Yao, Gongyi Wang",http://arxiv.org/pdf/2407.15891v1,cs.CL
Weak-to-Strong Compositional Learning from Generative Models for Language-based Object Detection,"Vision-language (VL) models often exhibit a limited understanding of complex
expressions of visual objects (e.g., attributes, shapes, and their relations),
given complex and diverse language queries. Traditional approaches attempt to
improve VL models using hard negative synthetic text, but their effectiveness
is limited. In this paper, we harness the exceptional compositional
understanding capabilities of generative foundational models. We introduce a
novel method for structured synthetic data generation aimed at enhancing the
compositional understanding of VL models in language-based object detection.
Our framework generates densely paired positive and negative triplets (image,
text descriptions, and bounding boxes) in both image and text domains. By
leveraging these synthetic triplets, we transform 'weaker' VL models into
'stronger' models in terms of compositional understanding, a process we call
""Weak-to-Strong Compositional Learning"" (WSCL). To achieve this, we propose a
new compositional contrastive learning formulation that discovers semantics and
structures in complex descriptions from synthetic triplets. As a result, VL
models trained with our synthetic data generation exhibit a significant
performance boost in the Omnilabel benchmark by up to +5AP and the D3 benchmark
by +6.9AP upon existing baselines.",2024-07-21,"Kwanyong Park, Kuniaki Saito, Donghyun Kim",http://arxiv.org/pdf/2407.15296v1,cs.CL
Intrinsic Self-correction for Enhanced Morality: An Analysis of Internal Mechanisms and the Superficial Hypothesis,"Large Language Models (LLMs) are capable of producing content that
perpetuates stereotypes, discrimination, and toxicity. The recently proposed
moral self-correction is a computationally efficient method for reducing
harmful content in the responses of LLMs. However, the process of how injecting
self-correction instructions can modify the behavior of LLMs remains
under-explored. In this paper, we explore the effectiveness of moral
self-correction by answering three research questions: (1) In what scenarios
does moral self-correction work? (2) What are the internal mechanisms of LLMs,
e.g., hidden states, that are influenced by moral self-correction instructions?
(3) Is intrinsic moral self-correction actually superficial in terms of reduced
immorality in hidden states?
  We argue that self-correction can help LLMs find a shortcut to more morally
correct output, rather than truly reducing the immorality stored in hidden
states. Through empirical investigation with tasks of language generation and
multi-choice question answering, we conclude:(i) LLMs exhibit good performance
across both tasks, and self-correction instructions are particularly beneficial
when the correct answer is already top-ranked; (ii) The morality levels in
intermediate hidden states are strong indicators as to whether one instruction
would be more effective than another; (iii) Based on our analysis of
intermediate hidden states and task case studies of self-correction behaviors,
we are first to propose the hypothesis that intrinsic moral self-correction is
in fact superficial.",2024-07-21,"Guangliang Liu, Haitao Mao, Jiliang Tang, Kristen Marie Johnson",http://arxiv.org/pdf/2407.15286v3,cs.CL
SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking,"Understanding rich dialogues often requires NLP systems to access relevant
commonsense persona knowledge, but retrieving this knowledge is challenging due
to complex contexts and the implicit nature of commonsense. This paper presents
our approach to the Commonsense Persona Knowledge Linking (CPKL) challenge,
addressing the critical need for integrating persona and commonsense knowledge
in open-domain dialogue systems. We introduce SynCPKL Pipeline, a pipeline that
leverages Large Language Models to generate high-quality synthetic datasets for
training commonsense persona knowledge linkers. To demonstrate the efficacy of
our approach, we present SynCPKL, a new dataset specifically designed for this
task. Our experiments validate the effectiveness of SynCPKL for training
commonsense persona knowledge linkers. Additionally, our top-performing model,
Derberta-SynCPKL, secured first place in the CPKL challenge by a 16%
improvement in F1 score. We released both SynCPKL and Derberta-SynCPKL at
https://github.com/irislin1006/CPKL.",2024-07-21,Kuan-Yen Lin,http://arxiv.org/pdf/2407.15281v1,cs.CL
Fact-Aware Multimodal Retrieval Augmentation for Accurate Medical Radiology Report Generation,"Multimodal foundation models hold significant potential for automating
radiology report generation, thereby assisting clinicians in diagnosing cardiac
diseases. However, generated reports often suffer from serious factual
inaccuracy. In this paper, we introduce a fact-aware multimodal
retrieval-augmented pipeline in generating accurate radiology reports
(FactMM-RAG). We first leverage RadGraph to mine factual report pairs, then
integrate factual knowledge to train a universal multimodal retriever. Given a
radiology image, our retriever can identify high-quality reference reports to
augment multimodal foundation models, thus enhancing the factual completeness
and correctness of report generation. Experiments on two benchmark datasets
show that our multimodal retriever outperforms state-of-the-art retrievers on
both language generation and radiology-specific metrics, up to 6.5% and 2%
score in F1CheXbert and F1RadGraph. Further analysis indicates that employing
our factually-informed training strategy imposes an effective supervision
signal, without relying on explicit diagnostic label guidance, and successfully
propagates fact-aware capabilities from the multimodal retriever to the
multimodal foundation model in radiology report generation.",2024-07-21,"Liwen Sun, James Zhao, Megan Han, Chenyan Xiong",http://arxiv.org/pdf/2407.15268v2,cs.CL
They Look Like Each Other: Case-based Reasoning for Explainable Depression Detection on Twitter using Large Language Models,"Depression is a common mental health issue that requires prompt diagnosis and
treatment. Despite the promise of social media data for depression detection,
the opacity of employed deep learning models hinders interpretability and
raises bias concerns. We address this challenge by introducing ProtoDep, a
novel, explainable framework for Twitter-based depression detection. ProtoDep
leverages prototype learning and the generative power of Large Language Models
to provide transparent explanations at three levels: (i) symptom-level
explanations for each tweet and user, (ii) case-based explanations comparing
the user to similar individuals, and (iii) transparent decision-making through
classification weights. Evaluated on five benchmark datasets, ProtoDep achieves
near state-of-the-art performance while learning meaningful prototypes. This
multi-faceted approach offers significant potential to enhance the reliability
and transparency of depression detection on social media, ultimately aiding
mental health professionals in delivering more informed care.",2024-07-21,"Mohammad Saeid Mahdavinejad, Peyman Adibi, Amirhassan Monadjemi, Pascal Hitzler",http://arxiv.org/pdf/2407.21041v1,cs.CL
XAI meets LLMs: A Survey of the Relation between Explainable AI and Large Language Models,"In this survey, we address the key challenges in Large Language Models (LLM)
research, focusing on the importance of interpretability. Driven by increasing
interest from AI and business sectors, we highlight the need for transparency
in LLMs. We examine the dual paths in current LLM research and eXplainable
Artificial Intelligence (XAI): enhancing performance through XAI and the
emerging focus on model interpretability. Our paper advocates for a balanced
approach that values interpretability equally with functional advancements.
Recognizing the rapid development in LLM research, our survey includes both
peer-reviewed and preprint (arXiv) papers, offering a comprehensive overview of
XAI's role in LLM research. We conclude by urging the research community to
advance both LLM and XAI fields together.",2024-07-21,"Erik Cambria, Lorenzo Malandri, Fabio Mercorio, Navid Nobani, Andrea Seveso",http://arxiv.org/pdf/2407.15248v1,cs.CL
"Two eyes, Two views, and finally, One summary! Towards Multi-modal Multi-tasking Knowledge-Infused Medical Dialogue Summarization","We often summarize a multi-party conversation in two stages: chunking with
homogeneous units and summarizing the chunks. Thus, we hypothesize that there
exists a correlation between homogeneous speaker chunking and overall
summarization tasks. In this work, we investigate the effectiveness of a
multi-faceted approach that simultaneously produces summaries of medical
concerns, doctor impressions, and an overall view. We introduce a multi-modal,
multi-tasking, knowledge-infused medical dialogue summary generation
(MMK-Summation) model, which is incorporated with adapter-based fine-tuning
through a gated mechanism for multi-modal information integration. The model,
MMK-Summation, takes dialogues as input, extracts pertinent external knowledge
based on the context, integrates the knowledge and visual cues from the
dialogues into the textual content, and ultimately generates concise summaries
encompassing medical concerns, doctor impressions, and a comprehensive
overview. The introduced model surpasses multiple baselines and traditional
summarization models across all evaluation metrics (including human
evaluation), which firmly demonstrates the efficacy of the knowledge-guided
multi-tasking, multimodal medical conversation summarization. The code is
available at https://github.com/NLP-RL/MMK-Summation.",2024-07-21,"Anisha Saha, Abhisek Tiwari, Sai Ruthvik, Sriparna Saha",http://arxiv.org/pdf/2407.15237v1,cs.CL
TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data,"Instruction tuning has achieved unprecedented success in NLP, turning large
language models into versatile chatbots. However, the increasing variety and
volume of instruction datasets demand significant computational resources. To
address this, it is essential to extract a small and highly informative subset
(i.e., Coreset) that achieves comparable performance to the full dataset.
Achieving this goal poses non-trivial challenges: 1) data selection requires
accurate data representations that reflect the training samples' quality, 2)
considering the diverse nature of instruction datasets, and 3) ensuring the
efficiency of the coreset selection algorithm for large models. To address
these challenges, we propose Task-Agnostic Gradient Clustered COreset Selection
(TAGCOS). Specifically, we leverage sample gradients as the data
representations, perform clustering to group similar data, and apply an
efficient greedy algorithm for coreset selection. Experimental results show
that our algorithm, selecting only 5% of the data, surpasses other unsupervised
methods and achieves performance close to that of the full dataset.",2024-07-21,"Jipeng Zhang, Yaxuan Qin, Renjie Pi, Weizhong Zhang, Rui Pan, Tong Zhang",http://arxiv.org/pdf/2407.15235v1,cs.CL
A Practical Analysis of Human Alignment with *PO,"At the forefront of state-of-the-art human alignment methods are preference
optimization methods (*PO). Prior research has often concentrated on
identifying the best-performing method, typically involving a grid search over
hyperparameters, which can be impractical for general practitioners. In this
paper, we examine the robustness of existing state-of-the-art methods to
varying hyperparameters in a realistic out-of-distribution (OOD) scenario that
mirrors real-world applications of human alignment. Our goal is to empirically
find the method that increases the likelihood of achieving better results
through the lens of various metrics, such as KL divergence and response length.
We also introduce LN-DPO, a simple length-normalized version of DPO that is
more stable across hyperparameters, effectively reduces the average response
length, and improves performance. Our analysis of state-of-the-art
reference-free (i.e., SimPO) and reference-dependent (i.e., DPO and LN-DPO)
methods reveals that they perform similarly at their peak (i.e., best possible
scenario). However, we uncover that the pattern of change in performance
greatly varies as we move away from the best possible scenario.",2024-07-21,"Kian Ahrabian, Xihui Lin, Barun Patra, Vishrav Chaudhary, Alon Benhaim, Jay Pujara, Xia Song",http://arxiv.org/pdf/2407.15229v2,cs.CL
A Community-Centric Perspective for Characterizing and Detecting Anti-Asian Violence-Provoking Speech,"Violence-provoking speech -- speech that implicitly or explicitly promotes
violence against the members of the targeted community, contributed to a
massive surge in anti-Asian crimes during the pandemic. While previous works
have characterized and built tools for detecting other forms of harmful speech,
like fear speech and hate speech, our work takes a community-centric approach
to studying anti-Asian violence-provoking speech. Using data from ~420k Twitter
posts spanning a 3-year duration (January 1, 2020 to February 1, 2023), we
develop a codebook to characterize anti-Asian violence-provoking speech and
collect a community-crowdsourced dataset to facilitate its large-scale
detection using state-of-the-art classifiers. We contrast the capabilities of
natural language processing classifiers, ranging from BERT-based to LLM-based
classifiers, in detecting violence-provoking speech with their capabilities to
detect anti-Asian hateful speech. In contrast to prior work that has
demonstrated the effectiveness of such classifiers in detecting hateful speech
($F_1 = 0.89$), our work shows that accurate and reliable detection of
violence-provoking speech is a challenging task ($F_1 = 0.69$). We discuss the
implications of our findings, particularly the need for proactive interventions
to support Asian communities during public health crises. The resources related
to the study are available at
https://claws-lab.github.io/violence-provoking-speech/.",2024-07-21,"Gaurav Verma, Rynaa Grover, Jiawei Zhou, Binny Mathew, Jordan Kraemer, Munmun De Choudhury, Srijan Kumar",http://arxiv.org/pdf/2407.15227v1,cs.CL
Failures to Find Transferable Image Jailbreaks Between Vision-Language Models,"The integration of new modalities into frontier AI systems offers exciting
capabilities, but also increases the possibility such systems can be
adversarially manipulated in undesirable ways. In this work, we focus on a
popular class of vision-language models (VLMs) that generate text outputs
conditioned on visual and textual inputs. We conducted a large-scale empirical
study to assess the transferability of gradient-based universal image
``jailbreaks"" using a diverse set of over 40 open-parameter VLMs, including 18
new VLMs that we publicly release. Overall, we find that transferable
gradient-based image jailbreaks are extremely difficult to obtain. When an
image jailbreak is optimized against a single VLM or against an ensemble of
VLMs, the jailbreak successfully jailbreaks the attacked VLM(s), but exhibits
little-to-no transfer to any other VLMs; transfer is not affected by whether
the attacked and target VLMs possess matching vision backbones or language
models, whether the language model underwent instruction-following and/or
safety-alignment training, or many other factors. Only two settings display
partially successful transfer: between identically-pretrained and
identically-initialized VLMs with slightly different VLM training data, and
between different training checkpoints of a single VLM. Leveraging these
results, we then demonstrate that transfer can be significantly improved
against a specific target VLM by attacking larger ensembles of
``highly-similar"" VLMs. These results stand in stark contrast to existing
evidence of universal and transferable text jailbreaks against language models
and transferable adversarial attacks against image classifiers, suggesting that
VLMs may be more robust to gradient-based transfer attacks.",2024-07-21,"Rylan Schaeffer, Dan Valentine, Luke Bailey, James Chua, Cristóbal Eyzaguirre, Zane Durante, Joe Benton, Brando Miranda, Henry Sleight, John Hughes, Rajashree Agrawal, Mrinank Sharma, Scott Emmons, Sanmi Koyejo, Ethan Perez",http://arxiv.org/pdf/2407.15211v2,cs.CL
A Survey on Employing Large Language Models for Text-to-SQL Tasks,"The increasing volume of data in relational databases and the expertise
needed for writing SQL queries pose challenges for users to access and analyze
data. Text-to-SQL (Text2SQL) solves the issues by utilizing natural language
processing (NLP) techniques to convert natural language into SQL queries. With
the development of Large Language Models (LLMs), a range of LLM-based Text2SQL
methods have emerged. This survey provides a comprehensive review of LLMs in
Text2SQL tasks. We review benchmark datasets, prompt engineering methods,
fine-tuning methods, and base models in LLM-based Text2SQL methods. We provide
insights in each part and discuss future directions in this field.",2024-07-21,"Liang Shi, Zhengju Tang, Nan Zhang, Xiaotong Zhang, Zhi Yang",http://arxiv.org/pdf/2407.15186v4,cs.CL
Decoding Multilingual Moral Preferences: Unveiling LLM's Biases Through the Moral Machine Experiment,"Large language models (LLMs) increasingly find their way into the most
diverse areas of our everyday lives. They indirectly influence people's
decisions or opinions through their daily use. Therefore, understanding how and
which moral judgements these LLMs make is crucial. However, morality is not
universal and depends on the cultural background. This raises the question of
whether these cultural preferences are also reflected in LLMs when prompted in
different languages or whether moral decision-making is consistent across
different languages. So far, most research has focused on investigating the
inherent values of LLMs in English. While a few works conduct multilingual
analyses of moral bias in LLMs in a multilingual setting, these analyses do not
go beyond atomic actions. To the best of our knowledge, a multilingual analysis
of moral bias in dilemmas has not yet been conducted.
  To address this, our paper builds on the moral machine experiment (MME) to
investigate the moral preferences of five LLMs, Falcon, Gemini, Llama, GPT, and
MPT, in a multilingual setting and compares them with the preferences collected
from humans belonging to different cultures. To accomplish this, we generate
6500 scenarios of the MME and prompt the models in ten languages on which
action to take. Our analysis reveals that all LLMs inhibit different moral
biases to some degree and that they not only differ from the human preferences
but also across multiple languages within the models themselves. Moreover, we
find that almost all models, particularly Llama 3, divert greatly from human
values and, for instance, prefer saving fewer people over saving more.",2024-07-21,"Karina Vida, Fabian Damken, Anne Lauscher",http://arxiv.org/pdf/2407.15184v1,cs.CL
ReAttention: Training-Free Infinite Context with Finite Attention Scope,"The long-context capability of the Large Language Models (LLM) has made
significant breakthroughs, but the maximum supported context length in length
extrapolation remains a critical bottleneck limiting their practical
applications. The constraint of context length in LLMs arises from the
self-attention mechanism, which cannot effectively and efficiently capture the
semantic relationships within infinitely long contexts via the limited
pre-trained positional information and attention scope. In this work, we
propose ReAttention, a training-free approach enabling LLM based on the
self-attention mechanism to support an infinite context with a finite attention
scope under sufficient memory resources. ReAttention performs the
position-agnostic top-$k$ attention before the ordinary position-aware
self-attention, freeing LLMs from the length extrapolation issue. We validate
the performance of ReAttention on the LongBench, L-Eval, and InfiniteBench and
demonstrate that it is on par with traditional methods. Furthermore, we also
apply ReAttention on mainstream LLMs, including LLaMA3.1-8B and
Mistral-v0.3-7B, enabling them to support context lengths of at least 1M and
even expanding the context length of LLaMA3.2-3B-chat by 128$\times$ to 4M
without any further training in Needle-In-A-Haystack tests. We also improve the
efficiency of ReAttention with Triton and achieve an efficient extrapolation
without additional overhead. The code is available at
https://github.com/OpenMOSS/ReAttention.",2024-07-21,"Xiaoran Liu, Ruixiao Li, Qipeng Guo, Zhigeng Liu, Yuerong Song, Kai Lv, Hang Yan, Linlin Li, Qun Liu, Xipeng Qiu",http://arxiv.org/pdf/2407.15176v3,cs.CL
When Can Transformers Count to n?,"Large language models based on the transformer architectures can solve highly
complex tasks. But are there simple tasks that such models cannot solve? Here
we focus on very simple counting tasks, that involve counting how many times a
token in the vocabulary have appeared in a string. We show that if the
dimension of the transformer state is linear in the context length, this task
can be solved. However, the solution we propose does not scale beyond this
limit, and we provide theoretical arguments for why it is likely impossible for
a size limited transformer to implement this task. Our empirical results
demonstrate the same phase-transition in performance, as anticipated by the
theoretical argument. Our results demonstrate the importance of understanding
how transformers can solve simple tasks.",2024-07-21,"Gilad Yehudai, Haim Kaplan, Asma Ghandeharioun, Mor Geva, Amir Globerson",http://arxiv.org/pdf/2407.15160v2,cs.CL
Fine-grained Gender Control in Machine Translation with Large Language Models,"In machine translation, the problem of ambiguously gendered input has been
pointed out, where the gender of an entity is not available in the source
sentence. To address this ambiguity issue, the task of controlled translation
that takes the gender of the ambiguous entity as additional input have been
proposed. However, most existing works have only considered a simplified setup
of one target gender for input. In this paper, we tackle controlled translation
in a more realistic setting of inputs with multiple entities and propose
Gender-of-Entity (GoE) prompting method for LLMs. Our proposed method instructs
the model with fine-grained entity-level gender information to translate with
correct gender inflections. By utilizing four evaluation benchmarks, we
investigate the controlled translation capability of LLMs in multiple
dimensions and find that LLMs reach state-of-the-art performance in controlled
translation. Furthermore, we discover an emergence of gender interference
phenomenon when controlling the gender of multiple entities. Finally, we
address the limitations of existing gender accuracy evaluation metrics and
propose leveraging LLMs as an evaluator for gender inflection in machine
translation.",2024-07-21,"Minwoo Lee, Hyukhun Koh, Minsung Kim, Kyomin Jung",http://arxiv.org/pdf/2407.15154v1,cs.CL
A multi-level multi-label text classification dataset of 19th century Ottoman and Russian literary and critical texts,"This paper introduces a multi-level, multi-label text classification dataset
comprising over 3000 documents. The dataset features literary and critical
texts from 19th-century Ottoman Turkish and Russian. It is the first study to
apply large language models (LLMs) to this dataset, sourced from prominent
literary periodicals of the era. The texts have been meticulously organized and
labeled. This was done according to a taxonomic framework that takes into
account both their structural and semantic attributes. Articles are categorized
and tagged with bibliometric metadata by human experts. We present baseline
classification results using a classical bag-of-words (BoW) naive Bayes model
and three modern LLMs: multilingual BERT, Falcon, and Llama-v2. We found that
in certain cases, Bag of Words (BoW) outperforms Large Language Models (LLMs),
emphasizing the need for additional research, especially in low-resource
language settings. This dataset is expected to be a valuable resource for
researchers in natural language processing and machine learning, especially for
historical and low-resource languages. The dataset is publicly available^1.",2024-07-21,"Gokcen Gokceoglu, Devrim Cavusoglu, Emre Akbas, Özen Nergis Dolcerocca",http://arxiv.org/pdf/2407.15136v1,cs.CL
DOPRA: Decoding Over-accumulation Penalization and Re-allocation in Specific Weighting Layer,"In this work, we introduce DOPRA, a novel approach designed to mitigate
hallucinations in multi-modal large language models (MLLMs). Unlike existing
solutions that typically involve costly supplementary training data or the
integration of external knowledge sources, DOPRA innovatively addresses
hallucinations by decoding specific weighted layer penalties and
redistribution, offering an economical and effective solution without
additional resources. DOPRA is grounded in unique insights into the intrinsic
mechanisms controlling hallucinations within MLLMs, especially the models'
tendency to over-rely on a subset of summary tokens in the self-attention
matrix, neglecting critical image-related information. This phenomenon is
particularly pronounced in certain strata. To counteract this over-reliance,
DOPRA employs a strategy of weighted overlay penalties and redistribution in
specific layers, such as the 12th layer, during the decoding process.
Furthermore, DOPRA includes a retrospective allocation process that re-examines
the sequence of generated tokens, allowing the algorithm to reallocate token
selection to better align with the actual image content, thereby reducing the
incidence of hallucinatory descriptions in auto-generated captions. Overall,
DOPRA represents a significant step forward in improving the output quality of
MLLMs by systematically reducing hallucinations through targeted adjustments
during the decoding process.",2024-07-21,"Jinfeng Wei, Xiaofeng Zhang",http://arxiv.org/pdf/2407.15130v2,cs.CL
Towards Automated Data Sciences with Natural Language and SageCopilot: Practices and Lessons Learned,"While the field of NL2SQL has made significant advancements in translating
natural language instructions into executable SQL scripts for data querying and
processing, achieving full automation within the broader data science pipeline
- encompassing data querying, analysis, visualization, and reporting - remains
a complex challenge. This study introduces SageCopilot, an advanced,
industry-grade system system that automates the data science pipeline by
integrating Large Language Models (LLMs), Autonomous Agents (AutoAgents), and
Language User Interfaces (LUIs). Specifically, SageCopilot incorporates a
two-phase design: an online component refining users' inputs into executable
scripts through In-Context Learning (ICL) and running the scripts for results
reporting & visualization, and an offline preparing demonstrations requested by
ICL in the online phase. A list of trending strategies such as Chain-of-Thought
and prompt-tuning have been used to augment SageCopilot for enhanced
performance. Through rigorous testing and comparative analysis against
prompt-based solutions, SageCopilot has been empirically validated to achieve
superior end-to-end performance in generating or executing scripts and offering
results with visualization, backed by real-world datasets. Our in-depth
ablation studies highlight the individual contributions of various components
and strategies used by SageCopilot to the end-to-end correctness for data
sciences.",2024-07-21,"Yuan Liao, Jiang Bian, Yuhui Yun, Shuo Wang, Yubo Zhang, Jiaming Chu, Tao Wang, Kewei Li, Yuchen Li, Xuhong Li, Shilei Ji, Haoyi Xiong",http://arxiv.org/pdf/2407.21040v1,cs.CL
Multi-Agent Causal Discovery Using Large Language Models,"Causal discovery aims to identify causal relationships between variables and
is a critical research area in machine learning. Traditional methods focus on
statistical or machine learning algorithms to uncover causal links from
structured data, often overlooking the valuable contextual information provided
by metadata. Large language models (LLMs) have shown promise in creating
unified causal discovery frameworks by incorporating both structured data and
metadata. However, their potential in multi-agent settings remains largely
unexplored. To address this gap, we introduce the Multi-Agent Causal Discovery
Framework (MAC), which consists of two key modules: the Debate-Coding Module
(DCM) and the Meta-Debate Module (MDM). The DCM begins with a multi-agent
debating and coding process, where agents use both structured data and metadata
to collaboratively select the most suitable statistical causal discovery (SCD)
method. The selected SCD is then applied to the structured data to generate an
initial causal graph. This causal graph is transformed into causal metadata
through the Meta Fusion mechanism. With all the metadata, MDM then refines the
causal structure by leveraging a multi-agent debating framework. Extensive
experiments across five datasets demonstrate that MAC outperforms both
traditional statistical causal discovery methods and existing LLM-based
approaches, achieving state-of-the-art performance.",2024-07-21,"Hao Duong Le, Xin Xia, Zhang Chen",http://arxiv.org/pdf/2407.15073v3,cs.CL
Relational Database Augmented Large Language Model,"Large language models (LLMs) excel in many natural language processing (NLP)
tasks. However, since LLMs can only incorporate new knowledge through training
or supervised fine-tuning processes, they are unsuitable for applications that
demand precise, up-to-date, and private information not available in the
training corpora. This precise, up-to-date, and private information is
typically stored in relational databases. Thus, a promising solution is to
augment LLMs with the inclusion of relational databases as external memory.
This can ensure the timeliness, correctness, and consistency of data, and
assist LLMs in performing complex arithmetic operations beyond their inherent
capabilities. However, bridging the gap between LLMs and relational databases
is challenging. It requires the awareness of databases and data values stored
in databases to select correct databases and issue correct SQL queries.
Besides, it is necessary for the external memory to be independent of the LLM
to meet the needs of real-world applications. We introduce a novel LLM-agnostic
memory architecture comprising a database selection memory, a data value
memory, and relational databases. And we design an elegant pipeline to retrieve
information from it. Besides, we carefully design the prompts to instruct the
LLM to maximize the framework's potential. To evaluate our method, we compose a
new dataset with various types of questions. Experimental results show that our
framework enables LLMs to effectively answer database-related questions, which
is beyond their direct ability.",2024-07-21,"Zongyue Qin, Chen Luo, Zhengyang Wang, Haoming Jiang, Yizhou Sun",http://arxiv.org/pdf/2407.15071v1,cs.CL
Training Zero-Shot Generalizable End-to-End Task-Oriented Dialog System Without Turn-level Dialog Annotations,"Task-oriented dialogue (TOD) systems enable users to achieve their goals
through natural language interactions. Traditionally, these systems have relied
on turn-level manually annotated metadata, such as dialogue states and policy
annotations, which are expensive, time-consuming, and often inconsistent or
error-prone. This dependence limits the potential to leverage vast amounts of
readily available conversational data for training TOD systems. Additionally, a
critical challenge in TOD system design is determining when and how to access
and integrate information from external sources. Current approaches typically
expect this information to be provided alongside the dialogue context, rather
than learning to identify and retrieve it autonomously. While pre-trained large
language models (LLMs) have been used to develop TOD systems, their potential
to train such systems without laborious annotations remains largely unexplored.
This work employs multi-task instruction fine-tuning to create more efficient
and scalable TOD systems that can effectively leverage natural language
conversational data without manual annotations, while autonomously managing
external information retrieval. Our extensive experimental evaluations, using
three diverse TOD datasets and three LLMs of varying sizes, demonstrate that
our approach can generalize to new, unseen domains. Notably, our approach
outperforms both state-of-the-art models trained on annotated data and
billion-scale parameter off-the-shelf ChatGPT models.",2024-07-21,"Adib Mosharrof, A. B. Siddique",http://arxiv.org/pdf/2407.15055v2,cs.CL
End-to-End Video Question Answering with Frame Scoring Mechanisms and Adaptive Sampling,"Video Question Answering (VideoQA) has emerged as a challenging frontier in
the field of multimedia processing, requiring intricate interactions between
visual and textual modalities. Simply uniformly sampling frames or
indiscriminately aggregating frame-level visual features often falls short in
capturing the nuanced and relevant contexts of videos to well perform VideoQA.
To mitigate these issues, we propose VidF4, a novel VideoQA framework equipped
with tailored frame selection strategy for effective and efficient VideoQA. We
propose three frame-scoring mechanisms that consider both question relevance
and inter-frame similarity to evaluate the importance of each frame for a given
question on the video. Furthermore, we design a differentiable adaptive frame
sampling mechanism to facilitate end-to-end training for the frame selector and
answer generator. The experimental results across three widely adopted
benchmarks demonstrate that our model consistently outperforms existing VideoQA
methods, establishing a new SOTA across NExT-QA (+0.3%), STAR (+0.9%), and TVQA
(+1.0%). Furthermore, through both quantitative and qualitative analyses, we
validate the effectiveness of each design choice.",2024-07-21,"Jianxin Liang, Xiaojun Meng, Yueqian Wang, Chang Liu, Qun Liu, Dongyan Zhao",http://arxiv.org/pdf/2407.15047v2,cs.CL
Audio-visual training for improved grounding in video-text LLMs,"Recent advances in multimodal LLMs, have led to several video-text models
being proposed for critical video-related tasks. However, most of the previous
works support visual input only, essentially muting the audio signal in the
video. Few models that support both audio and visual input, are not explicitly
trained on audio data. Hence, the effect of audio towards video understanding
is largely unexplored. To this end, we propose a model architecture that
handles audio-visual inputs explicitly. We train our model with both audio and
visual data from a video instruction-tuning dataset. Comparison with
vision-only baselines, and other audio-visual models showcase that training on
audio data indeed leads to improved grounding of responses. For better
evaluation of audio-visual models, we also release a human-annotated benchmark
dataset, with audio-aware question-answer pairs.",2024-07-21,"Shivprasad Sagare, Hemachandran S, Kinshuk Sarabhai, Prashant Ullegaddi, Rajeshkumar SA",http://arxiv.org/pdf/2407.15046v1,cs.CL
Enhancing Incremental Summarization with Structured Representations,"Large language models (LLMs) often struggle with processing extensive input
contexts, which can lead to redundant, inaccurate, or incoherent summaries.
Recent methods have used unstructured memory to incrementally process these
contexts, but they still suffer from information overload due to the volume of
unstructured data handled. In our study, we introduce structured knowledge
representations ($GU_{json}$), which significantly improve summarization
performance by 40% and 14% across two public datasets. Most notably, we propose
the Chain-of-Key strategy ($CoK_{json}$) that dynamically updates or augments
these representations with new information, rather than recreating the
structured memory for each new source. This method further enhances performance
by 7% and 4% on the datasets.",2024-07-21,"EunJeong Hwang, Yichao Zhou, James Bradley Wendt, Beliz Gunel, Nguyen Vo, Jing Xie, Sandeep Tata",http://arxiv.org/pdf/2407.15021v1,cs.CL
"Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions","Multiple-choice question answering (MCQA) is a key competence of performant
transformer language models that is tested by mainstream benchmarks. However,
recent evidence shows that models can have quite a range of performance,
particularly when the task format is diversified slightly (such as by shuffling
answer choice order). In this work we ask: how do successful models perform
formatted MCQA? We employ vocabulary projection and activation patching methods
to localize key hidden states that encode relevant information for predicting
the correct answer. We find that the prediction of a specific answer symbol is
causally attributed to a few middle layers, and specifically their multi-head
self-attention mechanisms. We show that subsequent layers increase the
probability of the predicted answer symbol in vocabulary space, and that this
probability increase is associated with a sparse set of attention heads with
unique roles. We additionally uncover differences in how different models
adjust to alternative symbols. Finally, we demonstrate that a synthetic task
can disentangle sources of model error to pinpoint when a model has learned
formatted MCQA, and show that logit differences between answer choice tokens
continue to grow over the course of training.",2024-07-21,"Sarah Wiegreffe, Oyvind Tafjord, Yonatan Belinkov, Hannaneh Hajishirzi, Ashish Sabharwal",http://arxiv.org/pdf/2407.15018v2,cs.CL
Improving Citation Text Generation: Overcoming Limitations in Length Control,"A key challenge in citation text generation is that the length of generated
text often differs from the length of the target, lowering the quality of the
generation. While prior works have investigated length-controlled generation,
their effectiveness depends on knowing the appropriate generation length. In
this work, we present an in-depth study of the limitations of predicting
scientific citation text length and explore the use of heuristic estimates of
desired length.",2024-07-20,"Biswadip Mandal, Xiangci Li, Jessica Ouyang",http://arxiv.org/pdf/2407.14997v1,cs.CL
Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data,"The impressive capabilities of large language models (LLMs) have sparked
debate over whether these models genuinely generalize to unseen tasks or
predominantly rely on memorizing vast amounts of pretraining data. To explore
this issue, we introduce an extended concept of memorization, distributional
memorization, which measures the correlation between the LLM output
probabilities and the pretraining data frequency. To effectively capture
task-specific pretraining data frequency, we propose a novel task-gram language
model, which is built by counting the co-occurrence of semantically related
$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using
the Pythia models trained on the Pile dataset, we evaluate four distinct tasks:
machine translation, factual question answering, world knowledge understanding,
and math reasoning. Our findings reveal varying levels of memorization, with
the strongest effect observed in factual question answering. Furthermore, while
model performance improves across all tasks as LLM size increases, only factual
question answering shows an increase in memorization, whereas machine
translation and reasoning tasks exhibit greater generalization, producing more
novel outputs. This study demonstrates that memorization plays a larger role in
simpler, knowledge-intensive tasks, while generalization is the key for harder,
reasoning-based tasks, providing a scalable method for analyzing large
pretraining corpora in greater depth.",2024-07-20,"Xinyi Wang, Antonis Antoniades, Yanai Elazar, Alfonso Amayuelas, Alon Albalak, Kexun Zhang, William Yang Wang",http://arxiv.org/pdf/2407.14985v5,cs.CL
Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models,"Vision-language models (VLMs) have achieved significant strides in recent
times specially in multimodal tasks, yet they remain susceptible to adversarial
attacks on their vision components. To address this, we propose Sim-CLIP, an
unsupervised adversarial fine-tuning method that enhances the robustness of the
widely-used CLIP vision encoder against such attacks while maintaining semantic
richness and specificity. By employing a Siamese architecture with cosine
similarity loss, Sim-CLIP learns semantically meaningful and attack-resilient
visual representations without requiring large batch sizes or momentum
encoders. Our results demonstrate that VLMs enhanced with Sim-CLIP's fine-tuned
CLIP encoder exhibit significantly enhanced robustness against adversarial
attacks, while preserving semantic meaning of the perturbed images. Notably,
Sim-CLIP does not require additional training or fine-tuning of the VLM itself;
replacing the original vision encoder with our fine-tuned Sim-CLIP suffices to
provide robustness. This work underscores the significance of reinforcing
foundational models like CLIP to safeguard the reliability of downstream VLM
applications, paving the way for more secure and effective multimodal systems.",2024-07-20,"Md Zarif Hossain, Ahmed Imteaj",http://arxiv.org/pdf/2407.14971v2,cs.CL
"Recent Advances in Generative AI and Large Language Models: Current Status, Challenges, and Perspectives","The emergence of Generative Artificial Intelligence (AI) and Large Language
Models (LLMs) has marked a new era of Natural Language Processing (NLP),
introducing unprecedented capabilities that are revolutionizing various
domains. This paper explores the current state of these cutting-edge
technologies, demonstrating their remarkable advancements and wide-ranging
applications. Our paper contributes to providing a holistic perspective on the
technical foundations, practical applications, and emerging challenges within
the evolving landscape of Generative AI and LLMs. We believe that understanding
the generative capabilities of AI systems and the specific context of LLMs is
crucial for researchers, practitioners, and policymakers to collaboratively
shape the responsible and ethical integration of these technologies into
various domains. Furthermore, we identify and address main research gaps,
providing valuable insights to guide future research endeavors within the AI
research community.",2024-07-20,"Desta Haileselassie Hagos, Rick Battle, Danda B. Rawat",http://arxiv.org/pdf/2407.14962v5,cs.CL
"Mapping the Technological Future: A Topic, Sentiment, and Emotion Analysis in Social Media Discourse","People worldwide are currently confronted with a number of technological
challenges, which act as a potent source of uncertainty. The uncertainty
arising from the volatility and unpredictability of technology (such as AI) and
its potential consequences is widely discussed on social media. This study uses
BERTopic modelling along with sentiment and emotion analysis on 1.5 million
tweets from 2021 to 2023 to identify anticipated tech-driven futures and
capture the emotions communicated by 400 key opinion leaders (KOLs). Findings
indicate positive sentiment significantly outweighs negative, with a prevailing
dominance of positive anticipatory emotions. Specifically, the 'Hope' score is
approximately 10.33\% higher than the median 'Anxiety' score. KOLs emphasize
'Optimism' and benefits over 'Pessimism' and challenges. The study emphasizes
the important role KOLs play in shaping future visions through anticipatory
discourse and emotional tone during times of technological uncertainty.",2024-07-20,"Alina Landowska, Maciej Skorski, Krzysztof Rajda",http://arxiv.org/pdf/2407.17522v1,cs.CL
Conversational Rubert for Detecting Competitive Interruptions in ASR-Transcribed Dialogues,"Interruption in a dialogue occurs when the listener begins their speech
before the current speaker finishes speaking. Interruptions can be broadly
divided into two groups: cooperative (when the listener wants to support the
speaker), and competitive (when the listener tries to take control of the
conversation against the speaker's will). A system that automatically
classifies interruptions can be used in call centers, specifically in the tasks
of customer satisfaction monitoring and agent monitoring. In this study, we
developed a text-based interruption classification model by preparing an
in-house dataset consisting of ASR-transcribed customer support telephone
dialogues in Russian. We fine-tuned Conversational RuBERT on our dataset and
optimized hyperparameters, and the model performed well. With further
improvements, the proposed model can be applied to automatic monitoring
systems.",2024-07-20,"Dmitrii Galimzianov, Viacheslav Vyshegorodtsev",http://arxiv.org/pdf/2407.14940v1,cs.CL
Operationalizing a Threat Model for Red-Teaming Large Language Models (LLMs),"Creating secure and resilient applications with large language models (LLM)
requires anticipating, adjusting to, and countering unforeseen threats.
Red-teaming has emerged as a critical technique for identifying vulnerabilities
in real-world LLM implementations. This paper presents a detailed threat model
and provides a systematization of knowledge (SoK) of red-teaming attacks on
LLMs. We develop a taxonomy of attacks based on the stages of the LLM
development and deployment process and extract various insights from previous
research. In addition, we compile methods for defense and practical red-teaming
strategies for practitioners. By delineating prominent attack motifs and
shedding light on various entry points, this paper provides a framework for
improving the security and robustness of LLM-based systems.",2024-07-20,"Apurv Verma, Satyapriya Krishna, Sebastian Gehrmann, Madhavan Seshadri, Anu Pradhan, Tom Ault, Leslie Barrett, David Rabinowitz, John Doucette, NhatHai Phan",http://arxiv.org/pdf/2407.14937v1,cs.CL
Consent in Crisis: The Rapid Decline of the AI Data Commons,"General-purpose artificial intelligence (AI) systems are built on massive
swathes of public web data, assembled into corpora such as C4, RefinedWeb, and
Dolma. To our knowledge, we conduct the first, large-scale, longitudinal audit
of the consent protocols for the web domains underlying AI training corpora.
Our audit of 14,000 web domains provides an expansive view of crawlable web
data and how codified data use preferences are changing over time. We observe a
proliferation of AI-specific clauses to limit use, acute differences in
restrictions on AI developers, as well as general inconsistencies between
websites' expressed intentions in their Terms of Service and their robots.txt.
We diagnose these as symptoms of ineffective web protocols, not designed to
cope with the widespread re-purposing of the internet for AI. Our longitudinal
analyses show that in a single year (2023-2024) there has been a rapid
crescendo of data restrictions from web sources, rendering ~5%+ of all tokens
in C4, or 28%+ of the most actively maintained, critical sources in C4, fully
restricted from use. For Terms of Service crawling restrictions, a full 45% of
C4 is now restricted. If respected or enforced, these restrictions are rapidly
biasing the diversity, freshness, and scaling laws for general-purpose AI
systems. We hope to illustrate the emerging crises in data consent, for both
developers and creators. The foreclosure of much of the open web will impact
not only commercial AI, but also non-commercial AI and academic research.",2024-07-20,"Shayne Longpre, Robert Mahari, Ariel Lee, Campbell Lund, Hamidah Oderinwale, William Brannon, Nayan Saxena, Naana Obeng-Marnu, Tobin South, Cole Hunter, Kevin Klyman, Christopher Klamm, Hailey Schoelkopf, Nikhil Singh, Manuel Cherep, Ahmad Anis, An Dinh, Caroline Chitongo, Da Yin, Damien Sileo, Deividas Mataciunas, Diganta Misra, Emad Alghamdi, Enrico Shippole, Jianguo Zhang, Joanna Materzynska, Kun Qian, Kush Tiwary, Lester Miranda, Manan Dey, Minnie Liang, Mohammed Hamdy, Niklas Muennighoff, Seonghyeon Ye, Seungone Kim, Shrestha Mohanty, Vipul Gupta, Vivek Sharma, Vu Minh Chien, Xuhui Zhou, Yizhi Li, Caiming Xiong, Luis Villa, Stella Biderman, Hanlin Li, Daphne Ippolito, Sara Hooker, Jad Kabbara, Sandy Pentland",http://arxiv.org/pdf/2407.14933v2,cs.CL
Improving Context-Aware Preference Modeling for Language Models,"While finetuning language models from pairwise preferences has proven
remarkably effective, the underspecified nature of natural language presents
critical challenges. Direct preference feedback is uninterpretable, difficult
to provide where multidimensional criteria may apply, and often inconsistent,
either because it is based on incomplete instructions or provided by diverse
principals. To address these challenges, we consider the two-step preference
modeling procedure that first resolves the under-specification by selecting a
context, and then evaluates preference with respect to the chosen context. We
decompose reward modeling error according to these two steps, which suggests
that supervising context in addition to context-specific preference may be a
viable approach to aligning models with diverse human preferences. For this to
work, the ability of models to evaluate context-specific preference is
critical. To this end, we contribute context-conditioned preference datasets
and accompanying experiments that investigate the ability of language models to
evaluate context-specific preference. We use our datasets to (1) show that
existing preference models benefit from, but fail to fully consider, added
context, (2) finetune a context-aware reward model with context-specific
performance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)
investigate the value of context-aware preference modeling.",2024-07-20,"Silviu Pitis, Ziang Xiao, Nicolas Le Roux, Alessandro Sordoni",http://arxiv.org/pdf/2407.14916v2,cs.CL
Large-vocabulary forensic pathological analyses via prototypical cross-modal contrastive learning,"Forensic pathology is critical in determining the cause and manner of death
through post-mortem examinations, both macroscopic and microscopic. The field,
however, grapples with issues such as outcome variability, laborious processes,
and a scarcity of trained professionals. This paper presents SongCi, an
innovative visual-language model (VLM) designed specifically for forensic
pathology. SongCi utilizes advanced prototypical cross-modal self-supervised
contrastive learning to enhance the accuracy, efficiency, and generalizability
of forensic analyses. It was pre-trained and evaluated on a comprehensive
multi-center dataset, which includes over 16 million high-resolution image
patches, 2,228 vision-language pairs of post-mortem whole slide images (WSIs),
and corresponding gross key findings, along with 471 distinct diagnostic
outcomes. Our findings indicate that SongCi surpasses existing multi-modal AI
models in many forensic pathology tasks, performs comparably to experienced
forensic pathologists and significantly better than less experienced ones, and
provides detailed multi-modal explainability, offering critical assistance in
forensic investigations. To the best of our knowledge, SongCi is the first VLM
specifically developed for forensic pathological analysis and the first
large-vocabulary computational pathology (CPath) model that directly processes
gigapixel WSIs in forensic science.",2024-07-20,"Chen Shen, Chunfeng Lian, Wanqing Zhang, Fan Wang, Jianhua Zhang, Shuanliang Fan, Xin Wei, Gongji Wang, Kehan Li, Hongshu Mu, Hao Wu, Xinggong Liang, Jianhua Ma, Zhenyuan Wang",http://arxiv.org/pdf/2407.14904v1,cs.CL
Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives,"In recent years, healthcare professionals are increasingly emphasizing on
personalized and evidence-based patient care through the exploration of
prognostic pathways. To study this, structured clinical variables from
Electronic Health Records (EHRs) data have traditionally been employed by many
researchers. Presently, Natural Language Processing models have received great
attention in clinical research which expanded the possibilities of using
clinical narratives. In this paper, we propose a systematic methodology for
developing sepsis prognostic pathways derived from clinical notes, focusing on
diverse patient subgroups identified by exploring comorbidities associated with
sepsis and generating explanations of these subgroups using SHAP. The extracted
prognostic pathways of these subgroups provide valuable insights into the
dynamic trajectories of sepsis severity over time. Visualizing these pathways
sheds light on the likelihood and direction of disease progression across
various contexts and reveals patterns and pivotal factors or biomarkers
influencing the transition between sepsis stages, whether toward deterioration
or improvement. This empowers healthcare providers to implement more
personalized and effective healthcare strategies for individual patients.",2024-07-20,"Sudeshna Jana, Tirthankar Dasgupta, Lipika Dey",http://arxiv.org/pdf/2407.21039v1,cs.CL
Falcon2-11B Technical Report,"We introduce Falcon2-11B, a foundation model trained on over five trillion
tokens, and its multimodal counterpart, Falcon2-11B-vlm, which is a
vision-to-text model. We report our findings during the training of the
Falcon2-11B which follows a multi-stage approach where the early stages are
distinguished by their context length and a final stage where we use a curated,
high-quality dataset. Additionally, we report the effect of doubling the batch
size mid-training and how training loss spikes are affected by the learning
rate. The downstream performance of the foundation model is evaluated on
established benchmarks, including multilingual and code datasets. The
foundation model shows strong generalization across all the tasks which makes
it suitable for downstream finetuning use cases. For the vision language model,
we report the performance on several benchmarks and show that our model
achieves a higher average score compared to open-source models of similar size.
The model weights and code of both Falcon2-11B and Falcon2-11B-vlm are made
available under a permissive license.",2024-07-20,"Quentin Malartic, Nilabhra Roy Chowdhury, Ruxandra Cojocaru, Mugariya Farooq, Giulia Campesan, Yasser Abdelaziz Dahou Djilali, Sanath Narayan, Ankit Singh, Maksim Velikanov, Basma El Amel Boussaha, Mohammed Al-Yafeai, Hamza Alobeidli, Leen Al Qadi, Mohamed El Amine Seddik, Kirill Fedyanin, Reda Alami, Hakim Hacid",http://arxiv.org/pdf/2407.14885v1,cs.CL
Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment,"Multilingual sentence encoders are commonly obtained by training multilingual
language models to map sentences from different languages into a shared
semantic space. As such, they are subject to curse of multilinguality, a loss
of monolingual representational accuracy due to parameter sharing. Another
limitation of multilingual sentence encoders is the trade-off between
monolingual and cross-lingual performance. Training for cross-lingual alignment
of sentence embeddings distorts the optimal monolingual structure of semantic
spaces of individual languages, harming the utility of sentence embeddings in
monolingual tasks. In this work, we address both issues by modular training of
sentence encoders, i.e., by separating monolingual specialization from
cross-lingual alignment. We first efficiently train language-specific sentence
encoders to avoid negative interference between languages (i.e., the curse). We
then align all non-English monolingual encoders to the English encoder by
training a cross-lingual alignment adapter on top of each, preventing
interference with monolingual specialization from the first step. In both
steps, we resort to contrastive learning on machine-translated paraphrase data.
Monolingual and cross-lingual evaluations on semantic text
similarity/relatedness and multiple-choice QA render our modular solution more
effective than multilingual sentence encoders, especially benefiting
low-resource languages.",2024-07-20,"Yongxin Huang, Kexin Wang, Goran Glavaš, Iryna Gurevych",http://arxiv.org/pdf/2407.14878v1,cs.CL
Seal: Advancing Speech Language Models to be Few-Shot Learners,"Existing auto-regressive language models have demonstrated a remarkable
capability to perform a new task with just a few examples in prompt, without
requiring any additional training. In order to extend this capability to a
multi-modal setting (i.e. speech and language), this paper introduces the Seal
model, an abbreviation for speech language model. It incorporates a novel
alignment method, in which Kullback-Leibler divergence loss is performed to
train a projector that bridges a frozen speech encoder with a frozen language
model decoder. The resulting Seal model exhibits robust performance as a
few-shot learner on two speech understanding tasks. Additionally, consistency
experiments are conducted to validate its robustness on different pre-trained
language models.",2024-07-20,"Shuyu Lei, Lingen Liu, Jiaolong Yang, Yasen Jiao, Yuxiang Yang, Yushu Yang, Xiang Guo",http://arxiv.org/pdf/2407.14875v1,cs.CL
Understanding the Relationship between Prompts and Response Uncertainty in Large Language Models,"Large language models (LLMs) are widely used in decision-making, but their
reliability, especially in critical tasks like healthcare, is not
well-established. Therefore, understanding how LLMs reason and make decisions
is crucial for their safe deployment. This paper investigates how the
uncertainty of responses generated by LLMs relates to the information provided
in the input prompt. Leveraging the insight that LLMs learn to infer latent
concepts during pretraining, we propose a prompt-response concept model that
explains how LLMs generate responses and helps understand the relationship
between prompts and response uncertainty. We show that the uncertainty
decreases as the prompt's informativeness increases, similar to epistemic
uncertainty. Our detailed experimental results on real-world datasets validate
our proposed model.",2024-07-20,"Ze Yu Zhang, Arun Verma, Finale Doshi-Velez, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2407.14845v3,cs.CL
Overview of AI-Debater 2023: The Challenges of Argument Generation Tasks,"In this paper we present the results of the AI-Debater 2023 Challenge held by
the Chinese Conference on Affect Computing (CCAC 2023), and introduce the
related datasets. We organize two tracks to handle the argumentative generation
tasks in different scenarios, namely, Counter-Argument Generation (Track 1) and
Claim-based Argument Generation (Track 2). Each track is equipped with its
distinct dataset and baseline model respectively. In total, 32 competing teams
register for the challenge, from which we received 11 successful submissions.
In this paper, we will present the results of the challenge and a summary of
the systems, highlighting commonalities and innovations among participating
systems. Datasets and baseline models of the AI-Debater 2023 Challenge have
been already released and can be accessed through the official website of the
challenge.",2024-07-20,"Jiayu Lin, Guanrong Chen, Bojun Jin, Chenyang Li, Shutong Jia, Wancong Lin, Yang Sun, Yuhang He, Caihua Yang, Jianzhu Bao, Jipeng Wu, Wen Su, Jinglu Chen, Xinyi Li, Tianyu Chen, Mingjie Han, Shuaiwen Du, Zijian Wang, Jiyin Li, Fuzhong Suo, Hao Wang, Nuanchen Lin, Xuanjing Huang, Changjian Jiang, RuiFeng Xu, Long Zhang, Jiuxin Cao, Ting Jin, Zhongyu Wei",http://arxiv.org/pdf/2407.14829v2,cs.CL
Text Style Transfer: An Introductory Overview,"Text Style Transfer (TST) is a pivotal task in natural language generation to
manipulate text style attributes while preserving style-independent content.
The attributes targeted in TST can vary widely, including politeness,
authorship, mitigation of offensive language, modification of feelings, and
adjustment of text formality. TST has become a widely researched topic with
substantial advancements in recent years. This paper provides an introductory
overview of TST, addressing its challenges, existing approaches, datasets,
evaluation measures, subtasks, and applications. This fundamental overview
improves understanding of the background and fundamentals of text style
transfer.",2024-07-20,"Sourabrata Mukherjee, Ondrej Dušek",http://arxiv.org/pdf/2407.14822v1,cs.CL
Automatic Real-word Error Correction in Persian Text,"Automatic spelling correction stands as a pivotal challenge within the ambit
of natural language processing (NLP), demanding nuanced solutions. Traditional
spelling correction techniques are typically only capable of detecting and
correcting non-word errors, such as typos and misspellings. However,
context-sensitive errors, also known as real-word errors, are more challenging
to detect because they are valid words that are used incorrectly in a given
context. The Persian language, characterized by its rich morphology and complex
syntax, presents formidable challenges to automatic spelling correction
systems. Furthermore, the limited availability of Persian language resources
makes it difficult to train effective spelling correction models. This paper
introduces a cutting-edge approach for precise and efficient real-word error
correction in Persian text. Our methodology adopts a structured, multi-tiered
approach, employing semantic analysis, feature selection, and advanced
classifiers to enhance error detection and correction efficacy. The innovative
architecture discovers and stores semantic similarities between words and
phrases in Persian text. The classifiers accurately identify real-word errors,
while the semantic ranking algorithm determines the most probable corrections
for real-word errors, taking into account specific spelling correction and
context properties such as context, semantic similarity, and edit-distance
measures. Evaluations have demonstrated that our proposed method surpasses
previous Persian real-word error correction models. Our method achieves an
impressive F-measure of 96.6% in the detection phase and an accuracy of 99.1%
in the correction phase. These results clearly indicate that our approach is a
highly promising solution for automatic real-word error correction in Persian
text.",2024-07-20,"Seyed Mohammad Sadegh Dashti, Amid Khatibi Bardsiri, Mehdi Jafari Shahbazzadeh",http://arxiv.org/pdf/2407.14795v1,cs.CL
Step-by-Step Reasoning to Solve Grid Puzzles: Where do LLMs Falter?,"Solving grid puzzles involves a significant amount of logical reasoning.
Hence, it is a good domain to evaluate the reasoning capability of a model
which can then guide us to improve the reasoning ability of models. However,
most existing works evaluate only the final predicted answer of a puzzle,
without delving into an in-depth analysis of the LLMs' reasoning chains (such
as where they falter) or providing any finer metrics to evaluate them. Since
LLMs may rely on simple heuristics or artifacts to predict the final answer, it
is crucial to evaluate the generated reasoning chain beyond overall correctness
measures, for accurately evaluating the reasoning abilities of LLMs. To this
end, we first develop GridPuzzle, an evaluation dataset comprising 274
grid-based puzzles with different complexities. Second, we propose a new error
taxonomy derived from manual analysis of reasoning chains from LLMs including
GPT-4, Claude-3, Gemini, Mistral, and Llama-2. Then, we develop an LLM-based
framework for large-scale subjective evaluation (i.e., identifying errors) and
an objective metric, PuzzleEval, to evaluate the correctness of reasoning
chains. Evaluating reasoning chains from LLMs leads to several interesting
findings. We further show that existing prompting methods used for enhancing
models' reasoning abilities do not improve performance on GridPuzzle. This
highlights the importance of understanding fine-grained errors and presents a
challenge for future research to enhance LLMs' puzzle-solving abilities by
developing methods that address these errors. Data and source code are
available at https://github.com/Mihir3009/GridPuzzle.",2024-07-20,"Nemika Tyagi, Mihir Parmar, Mohith Kulkarni, Aswin RRV, Nisarg Patel, Mutsumi Nakamura, Arindam Mitra, Chitta Baral",http://arxiv.org/pdf/2407.14790v2,cs.CL
PERCORE: A Deep Learning-Based Framework for Persian Spelling Correction with Phonetic Analysis,"This research introduces a state-of-the-art Persian spelling correction
system that seamlessly integrates deep learning techniques with phonetic
analysis, significantly enhancing the accuracy and efficiency of natural
language processing (NLP) for Persian. Utilizing a fine-tuned language
representation model, our methodology effectively combines deep contextual
analysis with phonetic insights, adeptly correcting both non-word and real-word
spelling errors. This strategy proves particularly effective in tackling the
unique complexities of Persian spelling, including its elaborate morphology and
the challenge of homophony. A thorough evaluation on a wide-ranging dataset
confirms our system's superior performance compared to existing methods, with
impressive F1-Scores of 0.890 for detecting real-word errors and 0.905 for
correcting them. Additionally, the system demonstrates a strong capability in
non-word error correction, achieving an F1-Score of 0.891. These results
illustrate the significant benefits of incorporating phonetic insights into
deep learning models for spelling correction. Our contributions not only
advance Persian language processing by providing a versatile solution for a
variety of NLP applications but also pave the way for future research in the
field, emphasizing the critical role of phonetic analysis in developing
effective spelling correction system.",2024-07-20,"Seyed Mohammad Sadegh Dashti, Amid Khatibi Bardsiri, Mehdi Jafari Shahbazzadeh",http://arxiv.org/pdf/2407.14789v1,cs.CL
On the Design and Analysis of LLM-Based Algorithms,"We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs.
Through extensive analytical and empirical investigation in a series of case
studies, we demonstrate that the proposed framework is broadly applicable to a
wide range of scenarios and diverse patterns of LLM-based algorithms, such as
parallel, hierarchical and recursive task decomposition. Our proposed framework
holds promise for advancing LLM-based algorithms, by revealing the reasons
behind curious empirical phenomena, guiding the choices of hyperparameters,
predicting the empirical performance of algorithms, and inspiring new algorithm
design. To promote further study of LLM-based algorithms, we release our source
code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.",2024-07-20,"Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou",http://arxiv.org/pdf/2407.14788v2,cs.CL
I Need Help! Evaluating LLM's Ability to Ask for Users' Support: A Case Study on Text-to-SQL Generation,"This study explores the proactive ability of LLMs to seek user support. We
propose metrics to evaluate the trade-off between performance improvements and
user burden, and investigate whether LLMs can determine when to request help
under varying information availability. Our experiments show that without
external feedback, many LLMs struggle to recognize their need for user support.
The findings highlight the importance of external signals and provide insights
for future research on improving support-seeking strategies. Source code:
https://github.com/appier-research/i-need-help",2024-07-20,"Cheng-Kuang Wu, Zhi Rui Tam, Chao-Chung Wu, Chieh-Yen Lin, Hung-yi Lee, Yun-Nung Chen",http://arxiv.org/pdf/2407.14767v2,cs.CL
Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base,"This paper introduces Golden-Retriever, designed to efficiently navigate vast
industrial knowledge bases, overcoming challenges in traditional LLM
fine-tuning and RAG frameworks with domain-specific jargon and context
interpretation. Golden-Retriever incorporates a reflection-based question
augmentation step before document retrieval, which involves identifying jargon,
clarifying its meaning based on context, and augmenting the question
accordingly. Specifically, our method extracts and lists all jargon and
abbreviations in the input question, determines the context against a
pre-defined list, and queries a jargon dictionary for extended definitions and
descriptions. This comprehensive augmentation ensures the RAG framework
retrieves the most relevant documents by providing clear context and resolving
ambiguities, significantly improving retrieval accuracy. Evaluations using
three open-source LLMs on a domain-specific question-answer dataset demonstrate
Golden-Retriever's superior performance, providing a robust solution for
efficiently integrating and querying industrial knowledge bases.",2024-07-20,"Zhiyu An, Xianzhong Ding, Yen-Chun Fu, Cheng-Chung Chu, Yan Li, Wan Du",http://arxiv.org/pdf/2408.00798v1,cs.CL
Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL,"With the advent of foundation models, prompt tuning has positioned itself as
an important technique for directing model behaviors and eliciting desired
responses. Prompt tuning regards selecting appropriate keywords included into
the input, thereby adapting to the downstream task without adjusting or
fine-tuning the model parameters. There is a wide range of work in prompt
tuning, from approaches that directly harness the backpropagated gradient
signals from the model, to those employing black-box optimization such as
reinforcement learning (RL) methods. Our primary focus is on RLPrompt, which
aims to find optimal prompt tokens leveraging soft Q-learning. While the
results show promise, we have observed that the prompts frequently appear
unnatural, which impedes their interpretability. We address this limitation by
using sparse Tsallis entropy regularization, a principled approach to filtering
out unlikely tokens from consideration. We extensively evaluate our approach
across various tasks, including few-shot text classification, unsupervised text
style transfer, and textual inversion from images. The results indicate a
notable improvement over baselines, highlighting the efficacy of our approach
in addressing the challenges of prompt tuning. Moreover, we show that the
prompts discovered using our method are more natural and interpretable compared
to those from other baselines.",2024-07-20,"Yunseon Choi, Sangmin Bae, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang Bian, Kee-Eung Kim",http://arxiv.org/pdf/2407.14733v1,cs.CL
Economy Watchers Survey Provides Datasets and Tasks for Japanese Financial Domain,"Natural language processing (NLP) tasks in English and general domains are
widely available and are often used to evaluate pre-trained language models. In
contrast, fewer tasks are available for languages other than English and in the
financial domain. Particularly, tasks in the Japanese and financial domains are
limited. We develop two large datasets using data published by a Japanese
central government agency. The datasets provide three Japanese financial NLP
tasks, including 3- and 12-class classifications for categorizing sentences,
along with a 5-class classification task for sentiment analysis. Our datasets
are designed to be comprehensive and updated by leveraging an automatic update
framework that ensures that the latest task datasets are publicly always
available.",2024-07-20,"Masahiro Suzuki, Hiroki Sakaji",http://arxiv.org/pdf/2407.14727v2,cs.CL
Contextual modulation of language comprehension in a dynamic neural model of lexical meaning,"We propose and computationally implement a dynamic neural model of lexical
meaning, and experimentally test its behavioral predictions. We demonstrate the
architecture and behavior of the model using as a test case the English lexical
item 'have', focusing on its polysemous use. In the model, 'have' maps to a
semantic space defined by two continuous conceptual dimensions, connectedness
and control asymmetry, previously proposed to parameterize the conceptual
system for language. The mapping is modeled as coupling between a neural node
representing the lexical item and neural fields representing the conceptual
dimensions. While lexical knowledge is modeled as a stable coupling pattern,
real-time lexical meaning retrieval is modeled as the motion of neural
activation patterns between metastable states corresponding to semantic
interpretations or readings. Model simulations capture two previously reported
empirical observations: (1) contextual modulation of lexical semantic
interpretation, and (2) individual variation in the magnitude of this
modulation. Simulations also generate a novel prediction that the by-trial
relationship between sentence reading time and acceptability should be
contextually modulated. An experiment combining self-paced reading and
acceptability judgments replicates previous results and confirms the new model
prediction. Altogether, results support a novel perspective on lexical
polysemy: that the many related meanings of a word are metastable neural
activation states that arise from the nonlinear dynamics of neural populations
governing interpretation on continuous semantic dimensions.",2024-07-19,"Michael C. Stern, Maria M. Piñango",http://arxiv.org/pdf/2407.14701v1,cs.CL
Compact Language Models via Pruning and Knowledge Distillation,"Large language models (LLMs) targeting different deployment scales and sizes
are currently produced by training each variant from scratch; this is extremely
compute-intensive. In this paper, we investigate if pruning an existing LLM and
then re-training it with a fraction (<3%) of the original training data can be
a suitable alternative to repeated, full retraining. To this end, we develop a
set of practical and effective compression best practices for LLMs that combine
depth, width, attention and MLP pruning with knowledge distillation-based
retraining; we arrive at these best practices through a detailed empirical
exploration of pruning strategies for each axis, methods to combine axes,
distillation strategies, and search techniques for arriving at optimal
compressed architectures. We use this guide to compress the Nemotron-4 family
of LLMs by a factor of 2-4x, and compare their performance to similarly-sized
models on a variety of language modeling tasks. Deriving 8B and 4B models from
an already pretrained 15B model using our approach requires up to 40x fewer
training tokens per model compared to training from scratch; this results in
compute cost savings of 1.8x for training the full model family (15B, 8B, and
4B). Minitron models exhibit up to a 16% improvement in MMLU scores compared to
training from scratch, perform comparably to other community models such as
Mistral 7B, Gemma 7B and Llama-3 8B, and outperform state-of-the-art
compression techniques from the literature. We have open-sourced Minitron model
weights on Huggingface, with corresponding supplementary material including
example code available on GitHub.",2024-07-19,"Saurav Muralidharan, Sharath Turuvekere Sreenivas, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov",http://arxiv.org/pdf/2407.14679v2,cs.CL
Advancing Chart Question Answering with Robust Chart Component Recognition,"Chart comprehension presents significant challenges for machine learning
models due to the diverse and intricate shapes of charts. Existing multimodal
methods often overlook these visual features or fail to integrate them
effectively for chart question answering (ChartQA). To address this, we
introduce Chartformer, a unified framework that enhances chart component
recognition by accurately identifying and classifying components such as bars,
lines, pies, titles, legends, and axes. Additionally, we propose a novel
Question-guided Deformable Co-Attention (QDCAt) mechanism, which fuses chart
features encoded by Chartformer with the given question, leveraging the
question's guidance to ground the correct answer. Extensive experiments
demonstrate that the proposed approaches significantly outperform baseline
models in chart component recognition and ChartQA tasks, achieving improvements
of 3.2% in mAP and 15.4% in accuracy, respectively. These results underscore
the robustness of our solution for detailed visual data interpretation across
various applications.",2024-07-19,"Hanwen Zheng, Sijia Wang, Chris Thomas, Lifu Huang",http://arxiv.org/pdf/2407.21038v1,cs.CL
Human-Interpretable Adversarial Prompt Attack on Large Language Models with Situational Context,"Previous research on testing the vulnerabilities in Large Language Models
(LLMs) using adversarial attacks has primarily focused on nonsensical prompt
injections, which are easily detected upon manual or automated review (e.g.,
via byte entropy). However, the exploration of innocuous human-understandable
malicious prompts augmented with adversarial injections remains limited. In
this research, we explore converting a nonsensical suffix attack into a
sensible prompt via a situation-driven contextual re-writing. This allows us to
show suffix conversion without any gradients, using only LLMs to perform the
attacks, and thus better understand the scope of possible risks. We combine an
independent, meaningful adversarial insertion and situations derived from
movies to check if this can trick an LLM. The situations are extracted from the
IMDB dataset, and prompts are defined following a few-shot chain-of-thought
prompting. Our approach demonstrates that a successful situation-driven attack
can be executed on both open-source and proprietary LLMs. We find that across
many LLMs, as few as 1 attempt produces an attack and that these attacks
transfer between LLMs.",2024-07-19,"Nilanjana Das, Edward Raff, Manas Gaur",http://arxiv.org/pdf/2407.14644v2,cs.CL
CVE-LLM : Automatic vulnerability evaluation in medical device industry using large language models,"The healthcare industry is currently experiencing an unprecedented wave of
cybersecurity attacks, impacting millions of individuals. With the discovery of
thousands of vulnerabilities each month, there is a pressing need to drive the
automation of vulnerability assessment processes for medical devices,
facilitating rapid mitigation efforts. Generative AI systems have
revolutionized various industries, offering unparalleled opportunities for
automation and increased efficiency. This paper presents a solution leveraging
Large Language Models (LLMs) to learn from historical evaluations of
vulnerabilities for the automatic assessment of vulnerabilities in the medical
devices industry. This approach is applied within the portfolio of a single
manufacturer, taking into account device characteristics, including existing
security posture and controls. The primary contributions of this paper are
threefold. Firstly, it provides a detailed examination of the best practices
for training a vulnerability Language Model (LM) in an industrial context.
Secondly, it presents a comprehensive comparison and insightful analysis of the
effectiveness of Language Models in vulnerability assessment. Finally, it
proposes a new human-in-the-loop framework to expedite vulnerability evaluation
processes.",2024-07-19,"Rikhiya Ghosh, Oladimeji Farri, Hans-Martin von Stockhausen, Martin Schmitt, George Marica Vasile",http://arxiv.org/pdf/2407.14640v1,cs.CL
BOND: Aligning LLMs with Best-of-N Distillation,"Reinforcement learning from human feedback (RLHF) is a key driver of quality
and safety in state-of-the-art large language models. Yet, a surprisingly
simple and strong inference-time strategy is Best-of-N sampling that selects
the best generation among N candidates. In this paper, we propose Best-of-N
Distillation (BOND), a novel RLHF algorithm that seeks to emulate Best-of-N but
without its significant computational overhead at inference time. Specifically,
BOND is a distribution matching algorithm that forces the distribution of
generations from the policy to get closer to the Best-of-N distribution. We use
the Jeffreys divergence (a linear combination of forward and backward KL) to
balance between mode-covering and mode-seeking behavior, and derive an
iterative formulation that utilizes a moving anchor for efficiency. We
demonstrate the effectiveness of our approach and several design choices
through experiments on abstractive summarization and Gemma models. Aligning
Gemma policies with BOND outperforms other RLHF algorithms by improving results
on several benchmarks.",2024-07-19,"Pier Giuseppe Sessa, Robert Dadashi, Léonard Hussenot, Johan Ferret, Nino Vieillard, Alexandre Ramé, Bobak Shariari, Sarah Perrin, Abe Friesen, Geoffrey Cideron, Sertan Girgin, Piotr Stanczyk, Andrea Michi, Danila Sinopalnikov, Sabela Ramos, Amélie Héliou, Aliaksei Severyn, Matt Hoffman, Nikola Momchev, Olivier Bachem",http://arxiv.org/pdf/2407.14622v1,cs.CL
Evaluating language models as risk scores,"Current question-answering benchmarks predominantly focus on accuracy in
realizable prediction tasks. Conditioned on a question and answer-key, does the
most likely token match the ground truth? Such benchmarks necessarily fail to
evaluate LLMs' ability to quantify ground-truth outcome uncertainty. In this
work, we focus on the use of LLMs as risk scores for unrealizable prediction
tasks. We introduce folktexts, a software package to systematically generate
risk scores using LLMs, and evaluate them against US Census data products. A
flexible API enables the use of different prompting schemes, local or
web-hosted models, and diverse census columns that can be used to compose
custom prediction tasks. We evaluate 17 recent LLMs across five proposed
benchmark tasks. We find that zero-shot risk scores produced by multiple-choice
question-answering have high predictive signal but are widely miscalibrated.
Base models consistently overestimate outcome uncertainty, while
instruction-tuned models underestimate uncertainty and produce over-confident
risk scores. In fact, instruction-tuning polarizes answer distribution
regardless of true underlying data uncertainty. This reveals a general
inability of instruction-tuned LLMs to express data uncertainty using
multiple-choice answers. A separate experiment using verbalized chat-style risk
queries yields substantially improved calibration across instruction-tuned
models. These differences in ability to quantify data uncertainty cannot be
revealed in realizable settings, and highlight a blind-spot in the current
evaluation ecosystem that folktexts covers.",2024-07-19,"André F. Cruz, Moritz Hardt, Celestine Mendler-Dünner",http://arxiv.org/pdf/2407.14614v3,cs.CL
Adversarial Databases Improve Success in Retrieval-based Large Language Models,"Open-source LLMs have shown great potential as fine-tuned chatbots, and
demonstrate robust abilities in reasoning and surpass many existing benchmarks.
Retrieval-Augmented Generation (RAG) is a technique for improving the
performance of LLMs on tasks that the models weren't explicitly trained on, by
leveraging external knowledge databases. Numerous studies have demonstrated the
effectiveness of RAG to more successfully accomplish downstream tasks when
using vector datasets that consist of relevant background information. It has
been implicitly assumed by those in the field that if adversarial background
information is utilized in this context, that the success of using a RAG-based
approach would be nonexistent or even negatively impact the results. To address
this assumption, we tested several open-source LLMs on the ability of RAG to
improve their success in answering multiple-choice questions (MCQ) in the
medical subspecialty field of Nephrology. Unlike previous studies, we examined
the effect of RAG in utilizing both relevant and adversarial background
databases. We set up several open-source LLMs, including Llama 3, Phi-3,
Mixtral 8x7b, Zephyr$\beta$, and Gemma 7B Instruct, in a zero-shot RAG
pipeline. As adversarial sources of information, text from the Bible and a
Random Words generated database were used for comparison. Our data show that
most of the open-source LLMs improve their multiple-choice test-taking success
as expected when incorporating relevant information vector databases.
Surprisingly however, adversarial Bible text significantly improved the success
of many LLMs and even random word text improved test taking ability of some of
the models. In summary, our results demonstrate for the first time the
countertintuitive ability of adversarial information datasets to improve the
RAG-based LLM success.",2024-07-19,"Sean Wu, Michael Koo, Li Yo Kao, Andy Black, Lesley Blum, Fabien Scalzo, Ira Kurtz",http://arxiv.org/pdf/2407.14609v1,cs.CL
Internal Consistency and Self-Feedback in Large Language Models: A Survey,"Large language models (LLMs) often exhibit deficient reasoning or generate
hallucinations. To address these, studies prefixed with ""Self-"" such as
Self-Consistency, Self-Improve, and Self-Refine have been initiated. They share
a commonality: involving LLMs evaluating and updating themselves. Nonetheless,
these efforts lack a unified perspective on summarization, as existing surveys
predominantly focus on categorization.
  In this paper, we use a unified perspective of internal consistency, offering
explanations for reasoning deficiencies and hallucinations. Internal
consistency refers to the consistency in expressions among LLMs' latent,
decoding, or response layers based on sampling methodologies. Then, we
introduce an effective theoretical framework capable of mining internal
consistency, named Self-Feedback. This framework consists of two modules:
Self-Evaluation and Self-Update. The former captures internal consistency
signals, while the latter leverages the signals to enhance either the model's
response or the model itself. This framework has been employed in numerous
studies.
  We systematically classify these studies by tasks and lines of work;
summarize relevant evaluation methods and benchmarks; and delve into the
concern, ""Does Self-Feedback Really Work?"" We also propose several critical
viewpoints, including the ""Hourglass Evolution of Internal Consistency"",
""Consistency Is (Almost) Correctness"" hypothesis, and ""The Paradox of Latent
and Explicit Reasoning"". The relevant resources are open-sourced at
https://github.com/IAAR-Shanghai/ICSFSurvey.",2024-07-19,"Xun Liang, Shichao Song, Zifan Zheng, Hanyu Wang, Qingchen Yu, Xunkai Li, Rong-Hua Li, Yi Wang, Zhonghao Wang, Feiyu Xiong, Zhiyu Li",http://arxiv.org/pdf/2407.14507v3,cs.CL
On Pre-training of Multimodal Language Models Customized for Chart Understanding,"Recent studies customizing Multimodal Large Language Models (MLLMs) for
domain-specific tasks have yielded promising results, especially in the field
of scientific chart comprehension. These studies generally utilize visual
instruction tuning with specialized datasets to enhance question and answer
(QA) accuracy within the chart domain. However, they often neglect the
fundamental discrepancy between natural image-caption pre-training data and
digital chart image-QA data, particularly in the models' capacity to extract
underlying numeric values from charts. This paper tackles this oversight by
exploring the training processes necessary to improve MLLMs' comprehension of
charts. We present three key findings: (1) Incorporating raw data values in
alignment pre-training markedly improves comprehension of chart data. (2)
Replacing images with their textual representation randomly during end-to-end
fine-tuning transfer the language reasoning capability to chart interpretation
skills. (3) Requiring the model to first extract the underlying chart data and
then answer the question in the fine-tuning can further improve the accuracy.
Consequently, we introduce CHOPINLLM, an MLLM tailored for in-depth chart
comprehension. CHOPINLLM effectively interprets various types of charts,
including unannotated ones, while maintaining robust reasoning abilities.
Furthermore, we establish a new benchmark to evaluate MLLMs' understanding of
different chart types across various comprehension levels. Experimental results
show that CHOPINLLM exhibits strong performance in understanding both annotated
and unannotated charts across a wide range of types.",2024-07-19,"Wan-Cyuan Fan, Yen-Chun Chen, Mengchen Liu, Lu Yuan, Leonid Sigal",http://arxiv.org/pdf/2407.14506v2,cs.CL
Evaluating the Reliability of Self-Explanations in Large Language Models,"This paper investigates the reliability of explanations generated by large
language models (LLMs) when prompted to explain their previous output. We
evaluate two kinds of such self-explanations - extractive and counterfactual -
using three state-of-the-art LLMs (2B to 8B parameters) on two different
classification tasks (objective and subjective). Our findings reveal, that,
while these self-explanations can correlate with human judgement, they do not
fully and accurately follow the model's decision process, indicating a gap
between perceived and actual model reasoning. We show that this gap can be
bridged because prompting LLMs for counterfactual explanations can produce
faithful, informative, and easy-to-verify results. These counterfactuals offer
a promising alternative to traditional explainability methods (e.g. SHAP,
LIME), provided that prompts are tailored to specific tasks and checked for
validity.",2024-07-19,"Korbinian Randl, John Pavlopoulos, Aron Henriksson, Tony Lindgren",http://arxiv.org/pdf/2407.14487v2,cs.CL
ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities,"In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and leading
proprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context understanding
and retrieval-augmented generation (RAG) capabilities. These two capabilities
are complementary to each other and essential for LLMs to process large volumes
of information that cannot fit into a single prompt. We present a detailed
continued training recipe to extend the context window of Llama3-70B-base from
8K to 128K tokens, along with a three-stage instruction tuning process to
enhance the model's instruction-following, RAG performance, and long-context
understanding capabilities. Our results demonstrate that the
Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,
including GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and
Llama3.1-70B-Instruct, on ultra-long tasks beyond 100K tokens, as well as on
the RAG benchmark using only a 4K context window, showing the strong long
context capability across varying sequence lengths. We further provide
extensive comparisons between direct long-context and RAG solutions using the
same state-of-the-art long-context LLMs. Interestingly, we find that the
performance of strong long-context LLMs using RAG improves when retrieving a
larger number of chunks. With a large set of top-k chunks, RAG consistently
outperforms direct long-context solution using the same state-of-the-art
long-context models (e.g., Llama3-ChatQA-2-70B and Qwen2-72B-Instruct) on both
32K and 128K benchmarks. We open-source the model weights, training data, and
the evaluation setup for the for the community:
https://chatqa2-project.github.io/",2024-07-19,"Peng Xu, Wei Ping, Xianchao Wu, Chejian Xu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro",http://arxiv.org/pdf/2407.14482v3,cs.CL
Check-Eval: A Checklist-based Approach for Evaluating Text Quality,"Evaluating the quality of text generated by large language models (LLMs)
remains a significant challenge. Traditional metrics often fail to align well
with human judgments, particularly in tasks requiring creativity and nuance. In
this paper, we propose \textsc{Check-Eval}, a novel evaluation framework
leveraging LLMs to assess the quality of generated text through a
checklist-based approach. \textsc{Check-Eval} can be employed as both a
reference-free and reference-dependent evaluation method, providing a
structured and interpretable assessment of text quality. The framework consists
of two main stages: checklist generation and checklist evaluation. We validate
\textsc{Check-Eval} on two benchmark datasets: Portuguese Legal Semantic
Textual Similarity and \textsc{SummEval}. Our results demonstrate that
\textsc{Check-Eval} achieves higher correlations with human judgments compared
to existing metrics, such as \textsc{G-Eval} and \textsc{GPTScore},
underscoring its potential as a more reliable and effective evaluation
framework for natural language generation tasks. The code for our experiments
is available at \url{https://anonymous.4open.science/r/check-eval-0DB4}",2024-07-19,"Jayr Pereira, Andre Assumpcao, Roberto Lotufo",http://arxiv.org/pdf/2407.14467v2,cs.CL
AudioInsight: Detecting Social Contexts Relevant to Social Anxiety from Speech,"During social interactions, understanding the intricacies of the context can
be vital, particularly for socially anxious individuals. While previous
research has found that the presence of a social interaction can be detected
from ambient audio, the nuances within social contexts, which influence how
anxiety provoking interactions are, remain largely unexplored. As an
alternative to traditional, burdensome methods like self-report, this study
presents a novel approach that harnesses ambient audio segments to detect
social threat contexts. We focus on two key dimensions: number of interaction
partners (dyadic vs. group) and degree of evaluative threat (explicitly
evaluative vs. not explicitly evaluative). Building on data from a Zoom-based
social interaction study (N=52 college students, of whom the majority N=45 are
socially anxious), we employ deep learning methods to achieve strong detection
performance. Under sample-wide 5-fold Cross Validation (CV), our model
distinguished dyadic from group interactions with 90\% accuracy and detected
evaluative threat at 83\%. Using a leave-one-group-out CV, accuracies were 82\%
and 77\%, respectively. While our data are based on virtual interactions due to
pandemic constraints, our method has the potential to extend to diverse
real-world settings. This research underscores the potential of passive sensing
and AI to differentiate intricate social contexts, and may ultimately advance
the ability of context-aware digital interventions to offer personalized mental
health support.",2024-07-19,"Varun Reddy, Zhiyuan Wang, Emma Toner, Max Larrazabal, Mehdi Boukhechba, Bethany A. Teachman, Laura E. Barnes",http://arxiv.org/pdf/2407.14458v1,cs.CL
System-1.x: Learning to Balance Fast and Slow Planning with Language Models,"Language models can be used to solve long-horizon planning problems in two
distinct modes: a fast 'System-1' mode, directly generating plans without any
explicit search or backtracking, and a slow 'System-2' mode, planning
step-by-step by explicitly searching over possible actions. While System-2 is
typically more effective, it is also more computationally expensive, making it
infeasible for long plans or large action spaces. Moreover, isolated System-1
or 2 ignores the user's end goals, failing to provide ways to control the
model's behavior. To this end, we propose the System-1.x Planner, a
controllable planning framework with LLMs that is capable of generating hybrid
plans and balancing between the two planning modes based on the difficulty of
the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1
Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization
factor (x) governing the mixture between System-1 and 2, the controller
decomposes a problem into sub-goals, and classifies them as easy or hard to be
solved by either System-1 or 2, respectively. We fine-tune all three components
on top of a single base LLM, requiring only search traces as supervision.
Experiments with two diverse planning tasks -- Maze Navigation and Blocksworld
-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2
Planner trained to approximate A* search, and also a symbolic planner (A*). We
demonstrate the following key properties of our planner: (1) controllability:
increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more
search, improving performance, (2) flexibility: by building a neuro-symbolic
variant with a neural System-1 and a symbolic System-2, we can use existing
symbolic methods, and (3) generalizability: by being able to learn from
different search algorithms, our method is robust to the choice of search
algorithm.",2024-07-19,"Swarnadeep Saha, Archiki Prasad, Justin Chih-Yao Chen, Peter Hase, Elias Stengel-Eskin, Mohit Bansal",http://arxiv.org/pdf/2407.14414v2,cs.CL
The Vision of Autonomic Computing: Can LLMs Make It a Reality?,"The Vision of Autonomic Computing (ACV), proposed over two decades ago,
envisions computing systems that self-manage akin to biological organisms,
adapting seamlessly to changing environments. Despite decades of research,
achieving ACV remains challenging due to the dynamic and complex nature of
modern computing systems. Recent advancements in Large Language Models (LLMs)
offer promising solutions to these challenges by leveraging their extensive
knowledge, language understanding, and task automation capabilities. This paper
explores the feasibility of realizing ACV through an LLM-based multi-agent
framework for microservice management. We introduce a five-level taxonomy for
autonomous service maintenance and present an online evaluation benchmark based
on the Sock Shop microservice demo project to assess our framework's
performance. Our findings demonstrate significant progress towards achieving
Level 3 autonomy, highlighting the effectiveness of LLMs in detecting and
resolving issues within microservice architectures. This study contributes to
advancing autonomic computing by pioneering the integration of LLMs into
microservice management frameworks, paving the way for more adaptive and
self-managing computing systems. The code will be made available at
https://aka.ms/ACV-LLM.",2024-07-19,"Zhiyang Zhang, Fangkai Yang, Xiaoting Qin, Jue Zhang, Qingwei Lin, Gong Cheng, Dongmei Zhang, Saravan Rajmohan, Qi Zhang",http://arxiv.org/pdf/2407.14402v1,cs.CL
Open Artificial Knowledge,"The tremendous success of chat-based AI systems like ChatGPT, Claude, and
Gemini stems from Large Language Models (LLMs) trained on vast amount of
datasets. However, acquiring high-quality, diverse, and ethically sourced
training data remains a significant challenge. We introduce the Open Artificial
Knowledge (OAK) dataset, a large-scale resource of over 500 million tokens (at
the moment of writing) designed to address this issue. OAK leverages an
ensemble of state-of-the-art LLMs, including GPT4o, LLaMa3-70B, LLaMa3-8B,
Mixtral-8x7B, Gemma-7B, and Gemma-2-9B , to generate high-quality text across
diverse domains, guided by Wikipedia's main categories. Our methodology ensures
broad knowledge coverage while maintaining coherence and factual accuracy. The
OAK dataset aims to foster the development of more capable and aligned language
models while addressing critical issues of data scarcity and privacy in LLM
training, and it is freely available on www.oakdataset.org.",2024-07-19,"Vadim Borisov, Richard H. Schreiber",http://arxiv.org/pdf/2407.14371v1,cs.CL
Improving Retrieval in Sponsored Search by Leveraging Query Context Signals,"Accurately retrieving relevant bid keywords for user queries is critical in
Sponsored Search but remains challenging, particularly for short, ambiguous
queries. Existing dense and generative retrieval models often fail to capture
nuanced user intent in these cases. To address this, we propose an approach to
enhance query understanding by augmenting queries with rich contextual signals
derived from web search results and large language models, stored in an online
cache. Specifically, we use web search titles and snippets to ground queries in
real-world information and utilize GPT-4 to generate query rewrites and
explanations that clarify user intent. These signals are efficiently integrated
through a Fusion-in-Decoder based Unity architecture, enabling both dense and
generative retrieval with serving costs on par with traditional context-free
models. To address scenarios where context is unavailable in the cache, we
introduce context glancing, a curriculum learning strategy that improves model
robustness and performance even without contextual signals during inference.
Extensive offline experiments demonstrate that our context-aware approach
substantially outperforms context-free models. Furthermore, online A/B testing
on a prominent search engine across 160+ countries shows significant
improvements in user engagement and revenue.",2024-07-19,"Akash Kumar Mohankumar, Gururaj K, Gagan Madan, Amit Singh",http://arxiv.org/pdf/2407.14346v2,cs.CL
"LLMs left, right, and center: Assessing GPT's capabilities to label political bias from web domains","This research investigates whether OpenAI's GPT-4, a state-of-the-art large
language model, can accurately classify the political bias of news sources
based solely on their URLs. Given the subjective nature of political labels,
third-party bias ratings like those from Ad Fontes Media, AllSides, and Media
Bias/Fact Check (MBFC) are often used in research to analyze news source
diversity. This study aims to determine if GPT-4 can replicate these human
ratings on a seven-degree scale (""far-left"" to ""far-right""). The analysis
compares GPT-4's classifications against MBFC's, and controls for website
popularity using Open PageRank scores. Findings reveal a high correlation
($\text{Spearman's } \rho = .89$, $n = 5,877$, $p < 0.001$) between GPT-4's and
MBFC's ratings, indicating the model's potential reliability. However, GPT-4
abstained from classifying approximately $\frac{2}{3}$ of the dataset. It is
more likely to abstain from rating unpopular websites, which also suffer from
less accurate assessments. The LLM tends to avoid classifying sources that MBFC
considers to be centrist, resulting in more polarized outputs. Finally, this
analysis shows a slight leftward skew in GPT's classifications compared to
MBFC's. Therefore, while this paper suggests that while GPT-4 can be a
scalable, cost-effective tool for political bias classification of news
websites, its use should be as a complement to human judgment to mitigate
biases.",2024-07-19,"Raphael Hernandes, Giulio Corsi",http://arxiv.org/pdf/2407.14344v2,cs.CL
Multimodal Misinformation Detection using Large Vision-Language Models,"The increasing proliferation of misinformation and its alarming impact have
motivated both industry and academia to develop approaches for misinformation
detection and fact checking. Recent advances on large language models (LLMs)
have shown remarkable performance in various tasks, but whether and how LLMs
could help with misinformation detection remains relatively underexplored. Most
of existing state-of-the-art approaches either do not consider evidence and
solely focus on claim related features or assume the evidence to be provided.
Few approaches consider evidence retrieval as part of the misinformation
detection but rely on fine-tuning models. In this paper, we investigate the
potential of LLMs for misinformation detection in a zero-shot setting. We
incorporate an evidence retrieval component into the process as it is crucial
to gather pertinent information from various sources to detect the veracity of
claims. To this end, we propose a novel re-ranking approach for multimodal
evidence retrieval using both LLMs and large vision-language models (LVLM). The
retrieved evidence samples (images and texts) serve as the input for an
LVLM-based approach for multimodal fact verification (LVLM4FV). To enable a
fair evaluation, we address the issue of incomplete ground truth for evidence
samples in an existing evidence retrieval dataset by annotating a more complete
set of evidence samples for both image and text retrieval. Our experimental
results on two datasets demonstrate the superiority of the proposed approach in
both evidence retrieval and fact verification tasks and also better
generalization capability across dataset compared to the supervised baseline.",2024-07-19,"Sahar Tahmasebi, Eric Müller-Budack, Ralph Ewerth",http://arxiv.org/pdf/2407.14321v1,cs.CL
How to Engage Your Readers? Generating Guiding Questions to Promote Active Reading,"Using questions in written text is an effective strategy to enhance
readability. However, what makes an active reading question good, what the
linguistic role of these questions is, and what is their impact on human
reading remains understudied. We introduce GuidingQ, a dataset of 10K in-text
questions from textbooks and scientific articles. By analyzing the dataset, we
present a comprehensive understanding of the use, distribution, and linguistic
characteristics of these questions. Then, we explore various approaches to
generate such questions using language models. Our results highlight the
importance of capturing inter-question relationships and the challenge of
question position identification in generating these questions. Finally, we
conduct a human study to understand the implication of such questions on
reading comprehension. We find that the generated questions are of high quality
and are almost as effective as human-written questions in terms of improving
readers' memorization and comprehension.",2024-07-19,"Peng Cui, Vilém Zouhar, Xiaoyu Zhang, Mrinmaya Sachan",http://arxiv.org/pdf/2407.14309v2,cs.CL
Foundation Models for Autonomous Robots in Unstructured Environments,"Automating activities through robots in unstructured environments, such as
construction sites, has been a long-standing desire. However, the high degree
of unpredictable events in these settings has resulted in far less adoption
compared to more structured settings, such as manufacturing, where robots can
be hard-coded or trained on narrowly defined datasets. Recently, pretrained
foundation models, such as Large Language Models (LLMs), have demonstrated
superior generalization capabilities by providing zero-shot solutions for
problems do not present in the training data, proposing them as a potential
solution for introducing robots to unstructured environments. To this end, this
study investigates potential opportunities and challenges of pretrained
foundation models from a multi-dimensional perspective. The study
systematically reviews application of foundation models in two field of robotic
and unstructured environment and then synthesized them with deliberative acting
theory. Findings showed that linguistic capabilities of LLMs have been utilized
more than other features for improving perception in human-robot interactions.
On the other hand, findings showed that the use of LLMs demonstrated more
applications in project management and safety in construction, and natural
hazard detection in disaster management. Synthesizing these findings, we
located the current state-of-the-art in this field on a five-level scale of
automation, placing them at conditional automation. This assessment was then
used to envision future scenarios, challenges, and solutions toward autonomous
safe unstructured environments. Our study can be seen as a benchmark to track
our progress toward that future.",2024-07-19,"Hossein Naderi, Alireza Shojaei, Lifu Huang",http://arxiv.org/pdf/2407.14296v2,cs.CL
CoVoSwitch: Machine Translation of Synthetic Code-Switched Text Based on Intonation Units,"Multilingual code-switching research is often hindered by the lack and
linguistically biased status of available datasets. To expand language
representation, we synthesize code-switching data by replacing intonation units
detected through PSST, a speech segmentation model fine-tuned from OpenAI's
Whisper, using a speech-to-text translation dataset, CoVoST 2. With our
dataset, CoVoSwitch, spanning 13 languages, we evaluate the code-switching
translation performance of two multilingual translation models, M2M-100 418M
and NLLB-200 600M. We reveal that the inclusion of code-switching units results
in higher translation performance than monolingual settings and that models are
better at code-switching translation into English than non-English. Further,
low-resource languages gain most from integration of code-switched units when
translating into English but much less when translating into non-English.
Translations into low-resource languages also perform worse than even raw
code-switched inputs. We find that systems excel at copying English tokens but
struggle with non-English tokens, that the off-target problem in monolingual
settings is also relevant in code-switching settings, and that models
hallucinate in code-switching translation by introducing words absent in both
of the original source sentences. CoVoSwitch and code are available at
https://github.com/sophiayk20/covoswitch.",2024-07-19,Yeeun Kang,http://arxiv.org/pdf/2407.14295v1,cs.CL
Voices in a Crowd: Searching for Clusters of Unique Perspectives,"Language models have been shown to reproduce underlying biases existing in
their training data, which is the majority perspective by default. Proposed
solutions aim to capture minority perspectives by either modelling annotator
disagreements or grouping annotators based on shared metadata, both of which
face significant challenges. We propose a framework that trains models without
encoding annotator metadata, extracts latent embeddings informed by annotator
behaviour, and creates clusters of similar opinions, that we refer to as
voices. Resulting clusters are validated post-hoc via internal and external
quantitative metrics, as well a qualitative analysis to identify the type of
voice that each cluster represents. Our results demonstrate the strong
generalisation capability of our framework, indicated by resulting clusters
being adequately robust, while also capturing minority perspectives based on
different demographic factors throughout two distinct datasets.",2024-07-19,"Nikolas Vitsakis, Amit Parekh, Ioannis Konstas",http://arxiv.org/pdf/2407.14259v1,cs.CL
Unipa-GPT: Large Language Models for university-oriented QA in Italian,"This paper illustrates the architecture and training of Unipa-GPT, a chatbot
relying on a Large Language Model, developed for assisting students in choosing
a bachelor/master degree course at the University of Palermo. Unipa-GPT relies
on gpt-3.5-turbo, it was presented in the context of the European Researchers'
Night (SHARPER night). In our experiments we adopted both the Retrieval
Augmented Generation (RAG) approach and fine-tuning to develop the system. The
whole architecture of Unipa-GPT is presented, both the RAG and the fine-tuned
systems are compared, and a brief discussion on their performance is reported.
Further comparison with other Large Language Models and the experimental
results during the SHARPER night are illustrated. Corpora and code are
available on GitHub",2024-07-19,"Irene Siragusa, Roberto Pirrone",http://arxiv.org/pdf/2407.14246v3,cs.CL
Hierarchical Windowed Graph Attention Network and a Large Scale Dataset for Isolated Indian Sign Language Recognition,"Automatic Sign Language (SL) recognition is an important task in the computer
vision community. To build a robust SL recognition system, we need a
considerable amount of data which is lacking particularly in Indian sign
language (ISL). In this paper, we introduce a large-scale isolated ISL dataset
and a novel SL recognition model based on skeleton graph structure. The dataset
covers 2002 daily used common words in the deaf community recorded by 20 (10
male and 10 female) deaf adult signers (contains 40033 videos). We propose a SL
recognition model namely Hierarchical Windowed Graph Attention Network (HWGAT)
by utilizing the human upper body skeleton graph. The HWGAT tries to capture
distinctive motions by giving attention to different body parts induced by the
human skeleton graph. The utility of the proposed dataset and the usefulness of
our model are evaluated through extensive experiments. We pre-trained the
proposed model on the presented dataset and fine-tuned it across different sign
language datasets further boosting the performance of 1.10, 0.46, 0.78, and
6.84 percentage points on INCLUDE, LSA64, AUTSL and WLASL respectively compared
to the existing state-of-the-art keypoints-based models.",2024-07-19,"Suvajit Patra, Arkadip Maitra, Megha Tiwari, K. Kumaran, Swathy Prabhu, Swami Punyeshwarananda, Soumitra Samanta",http://arxiv.org/pdf/2407.14224v2,cs.CL
Braille-to-Speech Generator: Audio Generation Based on Joint Fine-Tuning of CLIP and Fastspeech2,"An increasing number of Chinese people are troubled by different degrees of
visual impairment, which has made the modal conversion between a single image
or video frame in the visual field and the audio expressing the same
information a research hotspot. Deep learning technologies such as OCR+Vocoder
and Im2Wav enable English audio synthesis or image-to-sound matching in a
self-supervised manner. However, the audio data used for training is limited
and English is not universal for visually impaired people with different
educational levels. Therefore, for the sake of solving the problems of data
volume and language applicability to improve the reading efficiency of visually
impaired people, a set of image-to-speech framework CLIP-KNN-Fastspeech2 based
on the Chinese context was constructed. The framework integrates multiple basic
models and adopts the strategy of independent pre-training and joint
fine-tuning. First, the Chinese CLIP and Fastspeech2 text-to-speech models were
pre-trained on two public datasets, MUGE and Baker, respectively, and their
convergence was verified. Subsequently, joint fine-tuning was performed using a
self-built Braille image dataset. Experimental results on multiple public
datasets such as VGGSound, Flickr8k, ImageHear, and the self-built Braille
dataset BIT-DP show that the model has improved objective indicators such as
BLEU4,FAD(Fr\'echet Audio Distance), WER(Word Error Ratio), and even inference
speed. This verifies that the constructed model still has the ability to
synthesize high-quality speech under limited data, and also proves the
effectiveness of the joint training strategy that integrates multiple basic
models.",2024-07-19,"Chun Xu, En-Wei Sun",http://arxiv.org/pdf/2407.14212v1,cs.CL
LeKUBE: A Legal Knowledge Update BEnchmark,"Recent advances in Large Language Models (LLMs) have significantly shaped the
applications of AI in multiple fields, including the studies of legal
intelligence. Trained on extensive legal texts, including statutes and legal
documents, the legal LLMs can capture important legal knowledge/concepts
effectively and provide important support for downstream legal applications
such as legal consultancy. Yet, the dynamic nature of legal statutes and
interpretations also poses new challenges to the use of LLMs in legal
applications. Particularly, how to update the legal knowledge of LLMs
effectively and efficiently has become an important research problem in
practice. Existing benchmarks for evaluating knowledge update methods are
mostly designed for the open domain and cannot address the specific challenges
of the legal domain, such as the nuanced application of new legal knowledge,
the complexity and lengthiness of legal regulations, and the intricate nature
of legal reasoning. To address this gap, we introduce the Legal Knowledge
Update BEnchmark, i.e. LeKUBE, which evaluates knowledge update methods for
legal LLMs across five dimensions. Specifically, we categorize the needs of
knowledge updates in the legal domain with the help of legal professionals, and
then hire annotators from law schools to create synthetic updates to the
Chinese Criminal and Civil Code as well as sets of questions of which the
answers would change after the updates. Through a comprehensive evaluation of
state-of-the-art knowledge update methods, we reveal a notable gap between
existing knowledge update methods and the unique needs of the legal domain,
emphasizing the need for further research and development of knowledge update
mechanisms tailored for legal LLMs.",2024-07-19,"Changyue Wang, Weihang Su, Hu Yiran, Qingyao Ai, Yueyue Wu, Cheng Luo, Yiqun Liu, Min Zhang, Shaoping Ma",http://arxiv.org/pdf/2407.14192v2,cs.CL
Automatic Classification of News Subjects in Broadcast News: Application to a Gender Bias Representation Analysis,"This paper introduces a computational framework designed to delineate gender
distribution biases in topics covered by French TV and radio news. We
transcribe a dataset of 11.7k hours, broadcasted in 2023 on 21 French channels.
A Large Language Model (LLM) is used in few-shot conversation mode to obtain a
topic classification on those transcriptions. Using the generated LLM
annotations, we explore the finetuning of a specialized smaller classification
model, to reduce the computational cost. To evaluate the performances of these
models, we construct and annotate a dataset of 804 dialogues. This dataset is
made available free of charge for research purposes. We show that women are
notably underrepresented in subjects such as sports, politics and conflicts.
Conversely, on topics such as weather, commercials and health, women have more
speaking time than their overall average across all subjects. We also observe
representations differences between private and public service channels.",2024-07-19,"Valentin Pelloin, Lena Dodson, Émile Chapuis, Nicolas Hervé, David Doukhan",http://arxiv.org/pdf/2407.14180v1,cs.CL
LAPIS: Language Model-Augmented Police Investigation System,"Crime situations are race against time. An AI-assisted criminal investigation
system, providing prompt but precise legal counsel is in need for police
officers. We introduce LAPIS (Language Model Augmented Police Investigation
System), an automated system that assists police officers to perform rational
and legal investigative actions. We constructed a finetuning dataset and
retrieval knowledgebase specialized in crime investigation legal reasoning
task. We extended the dataset's quality by incorporating manual curation
efforts done by a group of domain experts. We then finetuned the pretrained
weights of a smaller Korean language model to the newly constructed dataset and
integrated it with the crime investigation knowledgebase retrieval approach.
Experimental results show LAPIS' potential in providing reliable legal guidance
for police officers, even better than the proprietary GPT-4 model. Qualitative
analysis on the rationales generated by LAPIS demonstrate the model's reasoning
ability to leverage the premises and derive legally correct conclusions.",2024-07-19,"Heedou Kim, Dain Kim, Jiwoo Lee, Chanwoong Yoon, Donghee Choi, Mogan Gim, Jaewoo Kang",http://arxiv.org/pdf/2407.20248v2,cs.CL
PassTSL: Modeling Human-Created Passwords through Two-Stage Learning,"Textual passwords are still the most widely used user authentication
mechanism. Due to the close connections between textual passwords and natural
languages, advanced technologies in natural language processing (NLP) and
machine learning (ML) could be used to model passwords for different purposes
such as studying human password-creation behaviors and developing more advanced
password cracking methods for informing better defence mechanisms. In this
paper, we propose PassTSL (modeling human-created Passwords through Two-Stage
Learning), inspired by the popular pretraining-finetuning framework in NLP and
deep learning (DL). We report how different pretraining settings affected
PassTSL and proved its effectiveness by applying it to six large leaked
password databases. Experimental results showed that it outperforms five
state-of-the-art (SOTA) password cracking methods on password guessing by a
significant margin ranging from 4.11% to 64.69% at the maximum point. Based on
PassTSL, we also implemented a password strength meter (PSM), and our
experiments showed that it was able to estimate password strength more
accurately, causing fewer unsafe errors (overestimating the password strength)
than two other SOTA PSMs when they produce the same rate of safe errors
(underestimating the password strength): a neural-network based method and
zxcvbn. Furthermore, we explored multiple finetuning settings, and our
evaluations showed that, even a small amount of additional training data, e.g.,
only 0.1% of the pretrained data, can lead to over 3% improvement in password
guessing on average. We also proposed a heuristic approach to selecting
finetuning passwords based on JS (Jensen-Shannon) divergence and experimental
results validated its usefulness. In summary, our contributions demonstrate the
potential and feasibility of applying advanced NLP and ML methods to password
modeling and cracking.",2024-07-19,"Yangde Wang, Haozhang Li, Weidong Qiu, Shujun Li, Peng Tang",http://arxiv.org/pdf/2407.14145v1,cs.CL
"I Know About ""Up""! Enhancing Spatial Reasoning in Visual Language Models Through 3D Reconstruction","Visual Language Models (VLMs) are essential for various tasks, particularly
visual reasoning tasks, due to their robust multi-modal information
integration, visual reasoning capabilities, and contextual awareness. However,
existing \VLMs{}' visual spatial reasoning capabilities are often inadequate,
struggling even with basic tasks such as distinguishing left from right. To
address this, we propose the \ours{} model, designed to enhance the visual
spatial reasoning abilities of VLMS. ZeroVLM employs Zero-1-to-3, a 3D
reconstruction model for obtaining different views of the input images and
incorporates a prompting mechanism to further improve visual spatial reasoning.
Experimental results on four visual spatial reasoning datasets show that our
\ours{} achieves up to 19.48% accuracy improvement, which indicates the
effectiveness of the 3D reconstruction and prompting mechanisms of our ZeroVLM.",2024-07-19,"Zaiqiao Meng, Hao Zhou, Yifang Chen",http://arxiv.org/pdf/2407.14133v2,cs.CL
Impact of Model Size on Fine-tuned LLM Performance in Data-to-Text Generation: A State-of-the-Art Investigation,"Data-to-text (D2T) generation aims to generate human-readable text from
semi-structured data, such as tables and graphs. The recent success of D2T is
largely attributed to advancements in LLMs. Despite the success of LLMs, no
research has been conducted to illustrate the impact of model size on the
performance of fine-tuned LLMs for D2T tasks. D2T model performance is
typically assessed based on three key qualities: \textit{readability}
(indicates fluency and coherence), \textit{informativeness} (measures content
similarity), and \textit{faithfulness} (assesses consistency of factual
information). It is currently uncertain whether increasing the size of LLMs
effectively improves performance in D2T tasks across these three qualities. The
objective of this study is to investigate the performance of fine-tuned LLMs in
D2T tasks in terms of model size. Through extensive comparative analysis, we
aim to elucidate both the advantages and limitations of scaling model sizes
across five widely used D2T datasets (E2E, ViGGo, WikiTableText, DART, and
WebNLG) and twelve state-of-the-art LLMs with varying sizes from five different
LLM families (T5, BART, OPT, BLOOM, and Llama 2). To comprehensively cover all
the three essential qualities of D2T models, we incorporate six widely
recognized automatic metrics -- \textsc{BLEU}, \textsc{METEOR},
\textsc{BERTScore}, \textsc{MoverScore}, \textsc{Parent}, and
\textsc{BARTScore}. We also provide an in-depth analysis of LLM performance
concerning model size in the presence of source-reference divergence, a
critical aspect of D2T tasks. Our investigation reveals that increasing LLM
size enhances \textit{readability} and \textit{informativeness} in D2T tasks,
but larger (in terms of size) LLMs may sacrifice \textit{faithfulness}.
Moreover, small-sized LLMs show more resilience than larger ones when
source-reference divergence is present.",2024-07-19,"Joy Mahapatra, Utpal Garain",http://arxiv.org/pdf/2407.14088v1,cs.CL
An Improved Method for Class-specific Keyword Extraction: A Case Study in the German Business Registry,"The task of $\textit{keyword extraction}$ is often an important initial step
in unsupervised information extraction, forming the basis for tasks such as
topic modeling or document classification. While recent methods have proven to
be quite effective in the extraction of keywords, the identification of
$\textit{class-specific}$ keywords, or only those pertaining to a predefined
class, remains challenging. In this work, we propose an improved method for
class-specific keyword extraction, which builds upon the popular
$\textbf{KeyBERT}$ library to identify only keywords related to a class
described by $\textit{seed keywords}$. We test this method using a dataset of
German business registry entries, where the goal is to classify each business
according to an economic sector. Our results reveal that our method greatly
improves upon previous approaches, setting a new standard for
$\textit{class-specific}$ keyword extraction.",2024-07-19,"Stephen Meisenbacher, Tim Schopf, Weixin Yan, Patrick Holl, Florian Matthes",http://arxiv.org/pdf/2407.14085v1,cs.CL
Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field,"There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.",2024-07-19,Tobias Kerner,http://arxiv.org/pdf/2407.14076v2,cs.CL
LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference,"The inference of transformer-based large language models consists of two
sequential stages: 1) a prefilling stage to compute the KV cache of prompts and
generate the first token, and 2) a decoding stage to generate subsequent
tokens. For long prompts, the KV cache must be computed for all tokens during
the prefilling stage, which can significantly increase the time needed to
generate the first token. Consequently, the prefilling stage may become a
bottleneck in the generation process. An open question remains whether all
prompt tokens are essential for generating the first token. To answer this, we
introduce a novel method, LazyLLM, that selectively computes the KV for tokens
important for the next token prediction in both the prefilling and decoding
stages. Contrary to static pruning approaches that prune the prompt at once,
LazyLLM allows language models to dynamically select different subsets of
tokens from the context in different generation steps, even though they might
be pruned in previous steps. Extensive experiments on standard datasets across
various tasks demonstrate that LazyLLM is a generic method that can be
seamlessly integrated with existing language models to significantly accelerate
the generation without fine-tuning. For instance, in the multi-document
question-answering task, LazyLLM accelerates the prefilling stage of the LLama
2 7B model by 2.34x while maintaining accuracy.",2024-07-19,"Qichen Fu, Minsik Cho, Thomas Merth, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi",http://arxiv.org/pdf/2407.14057v1,cs.CL
Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings,"We release Rasa, the first multilingual expressive TTS dataset for any Indian
language, which contains 10 hours of neutral speech and 1-3 hours of expressive
speech for each of the 6 Ekman emotions covering 3 languages: Assamese,
Bengali, & Tamil. Our ablation studies reveal that just 1 hour of neutral and
30 minutes of expressive data can yield a Fair system as indicated by MUSHRA
scores. Increasing neutral data to 10 hours, with minimal expressive data,
significantly enhances expressiveness. This offers a practical recipe for
resource-constrained languages, prioritizing easily obtainable neutral data
alongside smaller amounts of expressive data. We show the importance of
syllabically balanced data and pooling emotions to enhance expressiveness. We
also highlight challenges in generating specific emotions, e.g., fear and
surprise.",2024-07-19,"Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra",http://arxiv.org/pdf/2407.14056v2,cs.CL
Prompted Aspect Key Point Analysis for Quantitative Review Summarization,"Key Point Analysis (KPA) aims for quantitative summarization that provides
key points (KPs) as succinct textual summaries and quantities measuring their
prevalence. KPA studies for arguments and reviews have been reported in the
literature. A majority of KPA studies for reviews adopt supervised learning to
extract short sentences as KPs before matching KPs to review comments for
quantification of KP prevalence. Recent abstractive approaches still generate
KPs based on sentences, often leading to KPs with overlapping and hallucinated
opinions, and inaccurate quantification. In this paper, we propose Prompted
Aspect Key Point Analysis (PAKPA) for quantitative review summarization. PAKPA
employs aspect sentiment analysis and prompted in-context learning with Large
Language Models (LLMs) to generate and quantify KPs grounded in aspects for
business entities, which achieves faithful KPs with accurate quantification,
and removes the need for large amounts of annotated data for supervised
training. Experiments on the popular review dataset Yelp and the
aspect-oriented review summarization dataset SPACE show that our framework
achieves state-of-the-art performance. Source code and data are available at:
https://github.com/antangrocket1312/PAKPA",2024-07-19,"An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Erik Cambria",http://arxiv.org/pdf/2407.14049v1,cs.CL
SQLfuse: Enhancing Text-to-SQL Performance through Comprehensive LLM Synergy,"Text-to-SQL conversion is a critical innovation, simplifying the transition
from complex SQL to intuitive natural language queries, especially significant
given SQL's prevalence in the job market across various roles. The rise of
Large Language Models (LLMs) like GPT-3.5 and GPT-4 has greatly advanced this
field, offering improved natural language understanding and the ability to
generate nuanced SQL statements. However, the potential of open-source LLMs in
Text-to-SQL applications remains underexplored, with many frameworks failing to
leverage their full capabilities, particularly in handling complex database
queries and incorporating feedback for iterative refinement. Addressing these
limitations, this paper introduces SQLfuse, a robust system integrating
open-source LLMs with a suite of tools to enhance Text-to-SQL translation's
accuracy and usability. SQLfuse features four modules: schema mining, schema
linking, SQL generation, and a SQL critic module, to not only generate but also
continuously enhance SQL query quality. Demonstrated by its leading performance
on the Spider Leaderboard and deployment by Ant Group, SQLfuse showcases the
practical merits of open-source LLMs in diverse business contexts.",2024-07-19,"Tingkai Zhang, Chaoyu Chen, Cong Liao, Jun Wang, Xudong Zhao, Hang Yu, Jianchao Wang, Jianguo Li, Wenhui Shi",http://arxiv.org/pdf/2407.14568v1,cs.CL
ECCO: Can We Improve Model-Generated Code Efficiency Without Sacrificing Functional Correctness?,"Although large language models (LLMs) have been largely successful in
generating functionally correct programs, conditioning models to produce
efficient solutions while ensuring correctness remains a challenge. Further,
unreliability in benchmarking code efficiency is a hurdle across varying
hardware specifications for popular interpreted languages such as Python. In
this paper, we present ECCO, a reproducible benchmark for evaluating program
efficiency via two paradigms: natural language (NL) based code generation and
history-based code editing. On ECCO, we adapt and thoroughly investigate the
three most promising existing LLM-based approaches: in-context learning,
iterative refinement with execution or NL feedback, and fine-tuning conditioned
on execution and editing history. While most methods degrade functional
correctness and moderately increase program efficiency, we find that adding
execution information often helps maintain functional correctness, and NL
feedback enhances more on efficiency. We release our benchmark to support
future work on LLM-based generation of efficient code.",2024-07-19,"Siddhant Waghjale, Vishruth Veerendranath, Zora Zhiruo Wang, Daniel Fried",http://arxiv.org/pdf/2407.14044v2,cs.CL
BERTer: The Efficient One,"We explore advanced fine-tuning techniques to boost BERT's performance in
sentiment analysis, paraphrase detection, and semantic textual similarity. Our
approach leverages SMART regularization to combat overfitting, improves
hyperparameter choices, employs a cross-embedding Siamese architecture for
improved sentence embeddings, and introduces innovative early exiting methods.
Our fine-tuning findings currently reveal substantial improvements in model
efficiency and effectiveness when combining multiple fine-tuning architectures,
achieving a state-of-the-art performance score of on the test set, surpassing
current benchmarks and highlighting BERT's adaptability in multifaceted
linguistic tasks.",2024-07-19,"Pradyumna Saligram, Andrew Lanpouthakoun",http://arxiv.org/pdf/2407.14039v1,cs.CL
HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research,"Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.",2024-07-19,"Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban",http://arxiv.org/pdf/2407.14030v1,cs.CL
Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by Direct Preference Optimization,"Extractive question answering over clinical text is a crucial need to help
deal with the deluge of clinical text generated in hospitals. While encoder
models (e.g., BERT) have been popular for this reading comprehension task,
recently encoder-decoder models (e.g., T5) are on the rise. There is also the
emergence of preference optimization techniques to align decoder-only LLMs with
human preferences. In this paper, we combine encoder-decoder models with the
direct preference optimization (DPO) method to improve over prior state of the
art for the RadQA radiology question answering task by 12-15 F1 points. To the
best of our knowledge, this effort is the first to show that DPO method also
works for reading comprehension via novel heuristics to generate preference
data without human inputs.",2024-07-19,"Md Sultan Al Nahian, Ramakanth Kavuluru",http://arxiv.org/pdf/2407.14000v1,cs.CL
NeLLCom-X: A Comprehensive Neural-Agent Framework to Simulate Language Learning and Group Communication,"Recent advances in computational linguistics include simulating the emergence
of human-like languages with interacting neural network agents, starting from
sets of random symbols. The recently introduced NeLLCom framework (Lian et al.,
2023) allows agents to first learn an artificial language and then use it to
communicate, with the aim of studying the emergence of specific linguistics
properties. We extend this framework (NeLLCom-X) by introducing more realistic
role-alternating agents and group communication in order to investigate the
interplay between language learnability, communication pressures, and group
size effects. We validate NeLLCom-X by replicating key findings from prior
research simulating the emergence of a word-order/case-marking trade-off. Next,
we investigate how interaction affects linguistic convergence and emergence of
the trade-off. The novel framework facilitates future simulations of diverse
linguistic aspects, emphasizing the importance of interaction and group
dynamics in language evolution.",2024-07-19,"Yuchen Lian, Tessa Verhoef, Arianna Bisazza",http://arxiv.org/pdf/2407.13999v2,cs.CL
RAG-QA Arena: Evaluating Domain Robustness for Long-form Retrieval Augmented Question Answering,"Question answering based on retrieval augmented generation (RAG-QA) is an
important research topic in NLP and has a wide range of real-world
applications. However, most existing datasets for this task are either
constructed using a single source corpus or consist of short extractive
answers, which fall short of evaluating large language model (LLM) based RAG-QA
systems on cross-domain generalization. To address these limitations, we create
Long-form RobustQA (LFRQA), a new dataset comprising human-written long-form
answers that integrate short extractive answers from multiple documents into a
single, coherent narrative, covering 26K queries and large corpora across seven
different domains. We further propose RAG-QA Arena by directly comparing
model-generated answers against LFRQA's answers using LLMs as evaluators. We
show via extensive experiments that RAG-QA Arena and human judgments on answer
quality are highly correlated. Moreover, only 41.3% of the most competitive
LLM's answers are preferred to LFRQA's answers, demonstrating RAG-QA Arena as a
challenging evaluation platform for future research.",2024-07-19,"Rujun Han, Yuhao Zhang, Peng Qi, Yumo Xu, Jenyuan Wang, Lan Liu, William Yang Wang, Bonan Min, Vittorio Castelli",http://arxiv.org/pdf/2407.13998v2,cs.CL
Reexamining Racial Disparities in Automatic Speech Recognition Performance: The Role of Confounding by Provenance,"Automatic speech recognition (ASR) models trained on large amounts of audio
data are now widely used to convert speech to written text in a variety of
applications from video captioning to automated assistants used in healthcare
and other domains. As such, it is important that ASR models and their use is
fair and equitable. Prior work examining the performance of commercial ASR
systems on the Corpus of Regional African American Language (CORAAL)
demonstrated significantly worse ASR performance on African American English
(AAE). The current study seeks to understand the factors underlying this
disparity by examining the performance of the current state-of-the-art neural
network based ASR system (Whisper, OpenAI) on the CORAAL dataset. Two key
findings have been identified as a result of the current study. The first
confirms prior findings of significant dialectal variation even across
neighboring communities, and worse ASR performance on AAE that can be improved
to some extent with fine-tuning of ASR models. The second is a novel finding
not discussed in prior work on CORAAL: differences in audio recording practices
within the dataset have a significant impact on ASR accuracy resulting in a
``confounding by provenance'' effect in which both language use and recording
quality differ by study location. These findings highlight the need for further
systematic investigation to disentangle the effects of recording quality and
inherent linguistic diversity when examining the fairness and bias present in
neural ASR models, as any bias in ASR accuracy may have negative downstream
effects on disparities in various domains of life in which ASR technology is
used.",2024-07-19,"Changye Li, Trevor Cohen, Serguei Pakhomov",http://arxiv.org/pdf/2407.13982v1,cs.CL
FANTAstic SEquences and Where to Find Them: Faithful and Efficient API Call Generation through State-tracked Constrained Decoding and Reranking,"API call generation is the cornerstone of large language models' tool-using
ability that provides access to the larger world. However, existing supervised
and in-context learning approaches suffer from high training costs, poor data
efficiency, and generated API calls that can be unfaithful to the API
documentation and the user's request. To address these limitations, we propose
an output-side optimization approach called FANTASE. Two of the unique
contributions of FANTASE are its State-Tracked Constrained Decoding (SCD) and
Reranking components. SCD dynamically incorporates appropriate API constraints
in the form of Token Search Trie for efficient and guaranteed generation
faithfulness with respect to the API documentation. The Reranking component
efficiently brings in the supervised signal by leveraging a lightweight model
as the discriminator to rerank the beam-searched candidate generations of the
large language model. We demonstrate the superior performance of FANTASE in API
call generation accuracy, inference efficiency, and context efficiency with
DSTC8 and API Bank datasets.",2024-07-18,"Zhuoer Wang, Leonardo F. R. Ribeiro, Alexandros Papangelis, Rohan Mukherjee, Tzu-Yen Wang, Xinyan Zhao, Arijit Biswas, James Caverlee, Angeliki Metallinou",http://arxiv.org/pdf/2407.13945v1,cs.CL
Werewolf Arena: A Case Study in LLM Evaluation via Social Deduction,"This paper introduces Werewolf Arena, a novel framework for evaluating large
language models (LLMs) through the lens of the classic social deduction game,
Werewolf. In Werewolf Arena, LLMs compete against each other, navigating the
game's complex dynamics of deception, deduction, and persuasion. The framework
introduces a dynamic turn-taking system based on bidding, mirroring real-world
discussions where individuals strategically choose when to speak. We
demonstrate the framework's utility through an arena-style tournament featuring
Gemini and GPT models. Our results reveal distinct strengths and weaknesses in
the models' strategic reasoning and communication. These findings highlight
Werewolf Arena's potential as a challenging and scalable LLM benchmark.",2024-07-18,"Suma Bailis, Jane Friedhoff, Feiyang Chen",http://arxiv.org/pdf/2407.13943v1,cs.CL
BiasDPO: Mitigating Bias in Language Models through Direct Preference Optimization,"Large Language Models (LLMs) have become pivotal in advancing natural
language processing, yet their potential to perpetuate biases poses significant
concerns. This paper introduces a new framework employing Direct Preference
Optimization (DPO) to mitigate gender, racial, and religious biases in
LLM-generated English text. By developing a loss function that favors less
biased over biased completions, our approach cultivates a preference for
respectful and non-discriminatory language in LLMs. We also contribute a
manually designed dataset for training LLMs to recognize and correct biases.
This dataset encompasses a diverse range of prompts paired with both biased and
unbiased completions. Implementing this approach on the Microsoft Phi-2 model,
we demonstrate substantial reductions in biased outputs as our model
outperforms the baseline model on almost all bias benchmarks. Our model also
achieves better performance compared to other open-source models on most
benchmarks. By reducing biases in the language generated by the model, our
study marks a significant step towards developing more ethical and socially
responsible LLMs. We publicly release BiasDPO dataset on HuggingFace.",2024-07-18,Ahmed Allam,http://arxiv.org/pdf/2407.13928v1,cs.CL
Crafting Efficient Fine-Tuning Strategies for Large Language Models,"This paper addresses the challenges of efficiently fine-tuning large language
models (LLMs) by exploring data efficiency and hyperparameter optimization. We
investigate the minimum data required for effective fine-tuning and propose a
novel hyperparameter optimization method that leverages early-stage model
performance. Our experiments demonstrate that fine-tuning with as few as 200
samples can improve model accuracy from 70\% to 88\% in a product attribute
extraction task. We identify a saturation point of approximately 6,500 samples,
beyond which additional data yields diminishing returns. Our proposed bayesian
hyperparameter optimization method, which evaluates models at 20\% of total
training time, correlates strongly with final model performance, with 4 out of
5 top early-stage models remaining in the top 5 at completion. This approach
led to a 2\% improvement in accuracy over baseline models when evaluated on an
independent test set. These findings offer actionable insights for
practitioners, potentially reducing computational load and dependency on
extensive datasets while enhancing overall performance of fine-tuned LLMs.",2024-07-18,"Michael Oliver, Guan Wang",http://arxiv.org/pdf/2407.13906v1,cs.CL
Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish,"Speech datasets available in the public domain are often underutilized
because of challenges in discoverability and interoperability. A comprehensive
framework has been designed to survey, catalog, and curate available speech
datasets, which allows replicable evaluation of automatic speech recognition
(ASR) systems. A case study focused on the Polish language was conducted; the
framework was applied to curate more than 24 datasets and evaluate 25
combinations of ASR systems and models. This research constitutes the most
extensive comparison to date of both commercial and free ASR systems for the
Polish language. It draws insights from 600 system-model-test set evaluations,
marking a significant advancement in both scale and comprehensiveness. The
results of surveys and performance comparisons are available as interactive
dashboards (https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard) along
with curated datasets (https://huggingface.co/datasets/amu-cai/pl-asr-bigos-v2,
https://huggingface.co/datasets/pelcra/pl-asr-pelcra-for-bigos) and the open
challenge call (https://poleval.pl/tasks/task3). Tools used for evaluation are
open-sourced (https://github.com/goodmike31/pl-asr-bigos-tools), facilitating
replication and adaptation for other languages, as well as continuous expansion
with new datasets and systems.",2024-07-18,Michał Junczyk,http://arxiv.org/pdf/2408.00005v1,cs.CL
High Risk of Political Bias in Black Box Emotion Inference Models,"This paper investigates the presence of political bias in emotion inference
models used for sentiment analysis (SA) in social science research. Machine
learning models often reflect biases in their training data, impacting the
validity of their outcomes. While previous research has highlighted gender and
race biases, our study focuses on political bias - an underexplored yet
pervasive issue that can skew the interpretation of text data across a wide
array of studies. We conducted a bias audit on a Polish sentiment analysis
model developed in our lab. By analyzing valence predictions for names and
sentences involving Polish politicians, we uncovered systematic differences
influenced by political affiliations. Our findings indicate that annotations by
human raters propagate political biases into the model's predictions. To
mitigate this, we pruned the training dataset of texts mentioning these
politicians and observed a reduction in bias, though not its complete
elimination. Given the significant implications of political bias in SA, our
study emphasizes caution in employing these models for social science research.
We recommend a critical examination of SA results and propose using
lexicon-based systems as a more ideologically neutral alternative. This paper
underscores the necessity for ongoing scrutiny and methodological adjustments
to ensure the reliability and impartiality of the use of machine learning in
academic and applied contexts.",2024-07-18,"Hubert Plisiecki, Paweł Lenartowicz, Maria Flakus, Artur Pokropek",http://arxiv.org/pdf/2407.13891v2,cs.CL
Learning Goal-Conditioned Representations for Language Reward Models,"Techniques that learn improved representations via offline data or
self-supervised objectives have shown impressive results in traditional
reinforcement learning (RL). Nevertheless, it is unclear how improved
representation learning can benefit reinforcement learning from human feedback
(RLHF) on language models (LMs). In this work, we propose training reward
models (RMs) in a contrastive, $\textit{goal-conditioned}$ fashion by
increasing the representation similarity of future states along sampled
preferred trajectories and decreasing the similarity along randomly sampled
dispreferred trajectories. This objective significantly improves RM performance
by up to 0.09 AUROC across challenging benchmarks, such as MATH and GSM8k.
These findings extend to general alignment as well -- on the Helpful-Harmless
dataset, we observe $2.3\%$ increase in accuracy. Beyond improving reward model
performance, we show this way of training RM representations enables improved
$\textit{steerability}$ because it allows us to evaluate the likelihood of an
action achieving a particular goal-state (e.g., whether a solution is correct
or helpful). Leveraging this insight, we find that we can filter up to $55\%$
of generated tokens during majority voting by discarding trajectories likely to
end up in an ""incorrect"" state, which leads to significant cost savings. We
additionally find that these representations can perform fine-grained control
by conditioning on desired future goal-states. For example, we show that
steering a Llama 3 model towards helpful generations with our approach improves
helpfulness by $9.6\%$ over a supervised-fine-tuning trained baseline.
Similarly, steering the model towards complex generations improves complexity
by $21.6\%$ over the baseline. Overall, we find that training RMs in this
contrastive, goal-conditioned fashion significantly improves performance and
enables model steerability.",2024-07-18,"Vaskar Nath, Dylan Slack, Jeff Da, Yuntao Ma, Hugh Zhang, Spencer Whitehead, Sean Hendryx",http://arxiv.org/pdf/2407.13887v2,cs.CL
Thought-Like-Pro: Enhancing Reasoning of Large Language Models through Self-Driven Prolog-based Chain-of-Thought,"Large language models (LLMs) have shown exceptional performance as
general-purpose assistants, excelling across a variety of reasoning tasks. This
achievement represents a significant step toward achieving artificial general
intelligence (AGI). Despite these advancements, the effectiveness of LLMs often
hinges on the specific prompting strategies employed, and there remains a lack
of a robust framework to facilitate learning and generalization across diverse
reasoning tasks. To address these challenges, we introduce a novel learning
framework, THOUGHT-LIKE-PRO In this framework, we utilize imitation learning to
imitate the Chain-of-Thought (CoT) process which is verified and translated
from reasoning trajectories generated by a symbolic Prolog logic engine. This
framework proceeds in a self-driven manner, that enables LLMs to formulate
rules and statements from given instructions and leverage the symbolic Prolog
engine to derive results. Subsequently, LLMs convert Prolog-derived successive
reasoning trajectories into natural language CoT for imitation learning. Our
empirical findings indicate that our proposed approach substantially enhances
the reasoning abilities of LLMs and demonstrates robust generalization across
out-of-distribution reasoning tasks.",2024-07-18,"Xiaoyu Tan, Yongxin Deng, Xihe Qiu, Weidi Xu, Chao Qu, Wei Chu, Yinghui Xu, Yuan Qi",http://arxiv.org/pdf/2407.14562v2,cs.CL
"Phi-3 Safety Post-Training: Aligning Language Models with a ""Break-Fix"" Cycle","Recent innovations in language model training have demonstrated that it is
possible to create highly performant models that are small enough to run on a
smartphone. As these models are deployed in an increasing number of domains, it
is critical to ensure that they are aligned with human preferences and safety
considerations. In this report, we present our methodology for safety aligning
the Phi-3 series of language models. We utilized a ""break-fix"" cycle,
performing multiple rounds of dataset curation, safety post-training,
benchmarking, red teaming, and vulnerability identification to cover a variety
of harm areas in both single and multi-turn scenarios. Our results indicate
that this approach iteratively improved the performance of the Phi-3 models
across a wide range of responsible AI benchmarks. Finally, we include
additional red teaming strategies and evaluations that were used to test the
safety behavior of Phi-3.5-mini and Phi-3.5-MoE, which were optimized for
multilingual capabilities.",2024-07-18,"Emman Haider, Daniel Perez-Becker, Thomas Portet, Piyush Madan, Amit Garg, Atabak Ashfaq, David Majercak, Wen Wen, Dongwoo Kim, Ziyi Yang, Jianwen Zhang, Hiteshi Sharma, Blake Bullwinkel, Martin Pouliot, Amanda Minnich, Shiven Chawla, Solianna Herrera, Shahed Warreth, Maggie Engler, Gary Lopez, Nina Chikanov, Raja Sekhar Rao Dheekonda, Bolor-Erdene Jagdagdorj, Roman Lutz, Richard Lundeen, Tori Westerhoff, Pete Bryan, Christian Seifert, Ram Shankar Siva Kumar, Andrew Berkley, Alex Kessler",http://arxiv.org/pdf/2407.13833v2,cs.CL
Latent Causal Probing: A Formal Perspective on Probing with Causal Models of Data,"As language models (LMs) deliver increasing performance on a range of NLP
tasks, probing classifiers have become an indispensable technique in the effort
to better understand their inner workings. A typical setup involves (1)
defining an auxiliary task consisting of a dataset of text annotated with
labels, then (2) supervising small classifiers to predict the labels from the
representations of a pretrained LM as it processed the dataset. A high probing
accuracy is interpreted as evidence that the LM has learned to perform the
auxiliary task as an unsupervised byproduct of its original pretraining
objective. Despite the widespread usage of probes, however, the robust design
and analysis of probing experiments remains a challenge. We develop a formal
perspective on probing using structural causal models (SCM). Specifically,
given an SCM which explains the distribution of tokens observed during
training, we frame the central hypothesis as whether the LM has learned to
represent the latent variables of the SCM. Empirically, we extend a recent
study of LMs in the context of a synthetic grid-world navigation task, where
having an exact model of the underlying causal structure allows us to draw
strong inferences from the result of probing experiments. Our techniques
provide robust empirical evidence for the ability of LMs to induce the latent
concepts underlying text.",2024-07-18,"Charles Jin, Martin Rinard",http://arxiv.org/pdf/2407.13765v2,cs.CL
Black-Box Opinion Manipulation Attacks to Retrieval-Augmented Generation of Large Language Models,"Retrieval-Augmented Generation (RAG) is applied to solve hallucination
problems and real-time constraints of large language models, but it also
induces vulnerabilities against retrieval corruption attacks. Existing research
mainly explores the unreliability of RAG in white-box and closed-domain QA
tasks. In this paper, we aim to reveal the vulnerabilities of
Retrieval-Enhanced Generative (RAG) models when faced with black-box attacks
for opinion manipulation. We explore the impact of such attacks on user
cognition and decision-making, providing new insight to enhance the reliability
and security of RAG models. We manipulate the ranking results of the retrieval
model in RAG with instruction and use these results as data to train a
surrogate model. By employing adversarial retrieval attack methods to the
surrogate model, black-box transfer attacks on RAG are further realized.
Experiments conducted on opinion datasets across multiple topics show that the
proposed attack strategy can significantly alter the opinion polarity of the
content generated by RAG. This demonstrates the model's vulnerability and, more
importantly, reveals the potential negative impact on user cognition and
decision-making, making it easier to mislead users into accepting incorrect or
biased information.",2024-07-18,"Zhuo Chen, Jiawei Liu, Haotan Liu, Qikai Cheng, Fan Zhang, Wei Lu, Xiaozhong Liu",http://arxiv.org/pdf/2407.13757v1,cs.CL
"LLMs as Function Approximators: Terminology, Taxonomy, and Questions for Evaluation","Natural Language Processing has moved rather quickly from modelling specific
tasks to taking more general pre-trained models and fine-tuning them for
specific tasks, to a point where we now have what appear to be inherently
generalist models. This paper argues that the resultant loss of clarity on what
these models model leads to metaphors like ""artificial general intelligences""
that are not helpful for evaluating their strengths and weaknesses. The
proposal is to see their generality, and their potential value, in their
ability to approximate specialist function, based on a natural language
specification. This framing brings to the fore questions of the quality of the
approximation, but beyond that, also questions of discoverability, stability,
and protectability of these functions. As the paper will show, this framing
hence brings together in one conceptual framework various aspects of
evaluation, both from a practical and a theoretical perspective, as well as
questions often relegated to a secondary status (such as ""prompt injection"" and
""jailbreaking"").",2024-07-18,David Schlangen,http://arxiv.org/pdf/2407.13744v1,cs.CL
Scaling Granite Code Models to 128K Context,"This paper introduces long-context Granite code models that support effective
context windows of up to 128K tokens. Our solution for scaling context length
of Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight
continual pretraining by gradually increasing its RoPE base frequency with
repository-level file packing and length-upsampled long-context data.
Additionally, we also release instruction-tuned models with long-context
support which are derived by further finetuning the long context base models on
a mix of permissively licensed short and long-context instruction-response
pairs. While comparing to the original short-context Granite code models, our
long-context models achieve significant improvements on long-context tasks
without any noticeable performance degradation on regular code completion
benchmarks (e.g., HumanEval). We release all our long-context Granite code
models under an Apache 2.0 license for both research and commercial use.",2024-07-18,"Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam, Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda",http://arxiv.org/pdf/2407.13739v1,cs.CL
Baba Is AI: Break the Rules to Beat the Benchmark,"Humans solve problems by following existing rules and procedures, and also by
leaps of creativity to redefine those rules and objectives. To probe these
abilities, we developed a new benchmark based on the game Baba Is You where an
agent manipulates both objects in the environment and rules, represented by
movable tiles with words written on them, to reach a specified goal and win the
game. We test three state-of-the-art multi-modal large language models (OpenAI
GPT-4o, Google Gemini-1.5-Pro and Gemini-1.5-Flash) and find that they fail
dramatically when generalization requires that the rules of the game must be
manipulated and combined.",2024-07-18,"Nathan Cloos, Meagan Jens, Michelangelo Naim, Yen-Ling Kuo, Ignacio Cases, Andrei Barbu, Christopher J. Cueva",http://arxiv.org/pdf/2407.13729v1,cs.CL
Understanding Reference Policies in Direct Preference Optimization,"Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of the KL-constraint from the reference policies in DPO by providing
both theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority in this controlled setting.
Additionally, we investigate whether DPO benefits from stronger reference
policies, finding that a stronger reference policy can lead to improved
performance, but only when it is similar to the model being fine-tuned. Our
findings highlight the confounding role of reference policies in DPO and offer
insights for best practices, while also identifying open research questions for
future studies.",2024-07-18,"Yixin Liu, Pengfei Liu, Arman Cohan",http://arxiv.org/pdf/2407.13709v2,cs.CL
An Application of Large Language Models to Coding Negotiation Transcripts,"In recent years, Large Language Models (LLM) have demonstrated impressive
capabilities in the field of natural language processing (NLP). This paper
explores the application of LLMs in negotiation transcript analysis by the
Vanderbilt AI Negotiation Lab. Starting in September 2022, we applied multiple
strategies using LLMs from zero shot learning to fine tuning models to
in-context learning). The final strategy we developed is explained, along with
how to access and use the model. This study provides a sense of both the
opportunities and roadblocks for the implementation of LLMs in real life
applications and offers a model for how LLMs can be applied to coding in other
fields.",2024-07-18,"Ray Friedman, Jaewoo Cho, Jeanne Brett, Xuhui Zhan, Ningyu Han, Sriram Kannan, Yingxiang Ma, Jesse Spencer-Smith, Elisabeth Jäckel, Alfred Zerres, Madison Hooper, Katie Babbit, Manish Acharya, Wendi Adair, Soroush Aslani, Tayfun Aykaç, Chris Bauman, Rebecca Bennett, Garrett Brady, Peggy Briggs, Cheryl Dowie, Chase Eck, Igmar Geiger, Frank Jacob, Molly Kern, Sujin Lee, Leigh Anne Liu, Wu Liu, Jeffrey Loewenstein, Anne Lytle, Li Ma, Michel Mann, Alexandra Mislin, Tyree Mitchell, Hannah Martensen née Nagler, Amit Nandkeolyar, Mara Olekalns, Elena Paliakova, Jennifer Parlamis, Jason Pierce, Nancy Pierce, Robin Pinkley, Nathalie Prime, Jimena Ramirez-Marin, Kevin Rockmann, William Ross, Zhaleh Semnani-Azad, Juliana Schroeder, Philip Smith, Elena Stimmer, Roderick Swaab, Leigh Thompson, Cathy Tinsley, Ece Tuncel, Laurie Weingart, Robert Wilken, JingJing Yao, Zhi-Xue Zhang",http://arxiv.org/pdf/2407.21037v1,cs.CL
ANHALTEN: Cross-Lingual Transfer for German Token-Level Reference-Free Hallucination Detection,"Research on token-level reference-free hallucination detection has
predominantly focused on English, primarily due to the scarcity of robust
datasets in other languages. This has hindered systematic investigations into
the effectiveness of cross-lingual transfer for this important NLP application.
To address this gap, we introduce ANHALTEN, a new evaluation dataset that
extends the English hallucination detection dataset to German. To the best of
our knowledge, this is the first work that explores cross-lingual transfer for
token-level reference-free hallucination detection. ANHALTEN contains gold
annotations in German that are parallel (i.e., directly comparable to the
original English instances). We benchmark several prominent cross-lingual
transfer approaches, demonstrating that larger context length leads to better
hallucination detection in German, even without succeeding context.
Importantly, we show that the sample-efficient few-shot transfer is the most
effective approach in most setups. This highlights the practical benefits of
minimal annotation effort in the target language for reference-free
hallucination detection. Aiming to catalyze future research on cross-lingual
token-level reference-free hallucination detection, we make ANHALTEN publicly
available: https://github.com/janekh24/anhalten",2024-07-18,"Janek Herrlein, Chia-Chien Hung, Goran Glavaš",http://arxiv.org/pdf/2407.13702v1,cs.CL
Do These LLM Benchmarks Agree? Fixing Benchmark Evaluation with BenchBench,"Recent advancements in Language Models (LMs) have catalyzed the creation of
multiple benchmarks, designed to assess these models' general capabilities. A
crucial task, however, is assessing the validity of the benchmarks themselves.
This is most commonly done via Benchmark Agreement Testing (BAT), where new
benchmarks are validated against established ones using some agreement metric
(e.g., rank correlation). Despite the crucial role of BAT for benchmark
builders and consumers, there are no standardized procedures for such agreement
testing. This deficiency can lead to invalid conclusions, fostering mistrust in
benchmarks and upending the ability to properly choose the appropriate
benchmark to use. By analyzing over 40 prominent benchmarks, we demonstrate how
some overlooked methodological choices can significantly influence BAT results,
potentially undermining the validity of conclusions. To address these
inconsistencies, we propose a set of best practices for BAT and demonstrate how
utilizing these methodologies greatly improves BAT robustness and validity. To
foster adoption and facilitate future research,, we introduce BenchBench, a
python package for BAT, and release the BenchBench-leaderboard, a
meta-benchmark designed to evaluate benchmarks using their peers. Our findings
underscore the necessity for standardized BAT, ensuring the robustness and
validity of benchmark evaluations in the evolving landscape of language model
research.
  BenchBench Package: github.com/IBM/BenchBench
  Leaderboard: hf.co/spaces/IBM/BenchBench",2024-07-18,"Yotam Perlitz, Ariel Gera, Ofir Arviv, Asaf Yehudai, Elron Bandel, Eyal Shnarch, Michal Shmueli-Scheuer, Leshem Choshen",http://arxiv.org/pdf/2407.13696v2,cs.CL
Prover-Verifier Games improve legibility of LLM outputs,"One way to increase confidence in the outputs of Large Language Models (LLMs)
is to support them with reasoning that is clear and easy to check -- a property
we call legibility. We study legibility in the context of solving grade-school
math problems and show that optimizing chain-of-thought solutions only for
answer correctness can make them less legible. To mitigate the loss in
legibility, we propose a training algorithm inspired by Prover-Verifier Game
from Anil et al. (2021). Our algorithm iteratively trains small verifiers to
predict solution correctness, ""helpful"" provers to produce correct solutions
that the verifier accepts, and ""sneaky"" provers to produce incorrect solutions
that fool the verifier. We find that the helpful prover's accuracy and the
verifier's robustness to adversarial attacks increase over the course of
training. Furthermore, we show that legibility training transfers to
time-constrained humans tasked with verifying solution correctness. Over course
of LLM training human accuracy increases when checking the helpful prover's
solutions, and decreases when checking the sneaky prover's solutions. Hence,
training for checkability by small verifiers is a plausible technique for
increasing output legibility. Our results suggest legibility training against
small verifiers as a practical avenue for increasing legibility of large LLMs
to humans, and thus could help with alignment of superhuman models.",2024-07-18,"Jan Hendrik Kirchner, Yining Chen, Harri Edwards, Jan Leike, Nat McAleese, Yuri Burda",http://arxiv.org/pdf/2407.13692v2,cs.CL
FuLG: 150B Romanian Corpus for Language Model Pretraining,"Research in the field of language models is rapidly evolving, with many open
models being released to the public. Openly available pretraining corpora
usually focus on only a handful of languages, with many others either missing
completely or extremely underrepresented. In this report, we introduce FuLG, a
hundred-fifty-billion-token Romanian corpus extracted from CommonCrawl. We
present our methodology for filtering FuLG and compare it via ablation studies
against existing Romanian corpora.",2024-07-18,"Vlad-Andrei Bădoiu, Mihai-Valentin Dumitru, Alexandru M. Gherghescu, Alexandru Agache, Costin Raiciu",http://arxiv.org/pdf/2407.13657v1,cs.CL
Weak-to-Strong Reasoning,"When large language models (LLMs) exceed human-level capabilities, it becomes
increasingly challenging to provide full-scale and accurate supervision for
these models. Weak-to-strong learning, which leverages a less capable model to
unlock the latent abilities of a stronger model, proves valuable in this
context. Yet, the efficacy of this approach for complex reasoning tasks is
still untested. Furthermore, tackling reasoning tasks under the weak-to-strong
setting currently lacks efficient methods to avoid blindly imitating the weak
supervisor including its errors. In this paper, we introduce a progressive
learning framework that enables the strong model to autonomously refine its
training data, without requiring input from either a more advanced model or
human-annotated data. This framework begins with supervised fine-tuning on a
selective small but high-quality dataset, followed by preference optimization
on contrastive samples identified by the strong model itself. Extensive
experiments on the GSM8K and MATH datasets demonstrate that our method
significantly enhances the reasoning capabilities of Llama2-70b using three
separate weak models. This method is further validated in a forward-looking
experimental setup, where Llama3-8b-instruct effectively supervises Llama3-70b
on the highly challenging OlympicArena dataset. This work paves the way for a
more scalable and sophisticated strategy to enhance AI reasoning powers. All
relevant code and resources are available in
\url{https://github.com/GAIR-NLP/weak-to-strong-reasoning}.",2024-07-18,"Yuqing Yang, Yan Ma, Pengfei Liu",http://arxiv.org/pdf/2407.13647v2,cs.CL
A Comparative Study on Automatic Coding of Medical Letters with Explainability,"This study aims to explore the implementation of Natural Language Processing
(NLP) and machine learning (ML) techniques to automate the coding of medical
letters with visualised explainability and light-weighted local computer
settings. Currently in clinical settings, coding is a manual process that
involves assigning codes to each condition, procedure, and medication in a
patient's paperwork (e.g., 56265001 heart disease using SNOMED CT code). There
are preliminary research on automatic coding in this field using
state-of-the-art ML models; however, due to the complexity and size of the
models, the real-world deployment is not achieved. To further facilitate the
possibility of automatic coding practice, we explore some solutions in a local
computer setting; in addition, we explore the function of explainability for
transparency of AI models. We used the publicly available MIMIC-III database
and the HAN/HLAN network models for ICD code prediction purposes. We also
experimented with the mapping between ICD and SNOMED CT knowledge bases. In our
experiments, the models provided useful information for 97.98\% of codes. The
result of this investigation can shed some light on implementing automatic
clinical coding in practice, such as in hospital settings, on the local
computers used by clinicians , project page
\url{https://github.com/Glenj01/Medical-Coding}.",2024-07-18,"Jamie Glen, Lifeng Han, Paul Rayson, Goran Nenadic",http://arxiv.org/pdf/2407.13638v1,cs.CL
Scaling Laws with Vocabulary: Larger Models Deserve Larger Vocabularies,"Research on scaling large language models (LLMs) has primarily focused on
model parameters and training data size, overlooking the role of vocabulary
size. We investigate how vocabulary size impacts LLM scaling laws by training
models ranging from 33M to 3B parameters on up to 500B characters with various
vocabulary configurations. We propose three complementary approaches for
predicting the compute-optimal vocabulary size: IsoFLOPs analysis, derivative
estimation, and parametric fit of the loss function. Our approaches converge on
the conclusion that the optimal vocabulary size depends on the compute budget,
with larger models requiring larger vocabularies. Most LLMs, however, use
insufficient vocabulary sizes. For example, we predict that the optimal
vocabulary size of Llama2-70B should have been at least 216K, 7 times larger
than its vocabulary of 32K. We validate our predictions empirically by training
models with 3B parameters across different FLOPs budgets. Adopting our
predicted optimal vocabulary size consistently improves downstream performance
over commonly used vocabulary sizes. By increasing the vocabulary size from the
conventional 32K to 43K, we improve performance on ARC-Challenge from 29.1 to
32.0 with the same 2.3e21 FLOPs. Our work highlights the importance of jointly
considering tokenization and model scaling for efficient pre-training. The code
and demo are available at https://github.com/sail-sg/scaling-with-vocab and
https://hf.co/spaces/sail/scaling-with-vocab-demo.",2024-07-18,"Chaofan Tao, Qian Liu, Longxu Dou, Niklas Muennighoff, Zhongwei Wan, Ping Luo, Min Lin, Ngai Wong",http://arxiv.org/pdf/2407.13623v3,cs.CL
dzNLP at NADI 2024 Shared Task: Multi-Classifier Ensemble with Weighted Voting and TF-IDF Features,"This paper presents the contribution of our dzNLP team to the NADI 2024
shared task, specifically in Subtask 1 - Multi-label Country-level Dialect
Identification (MLDID) (Closed Track). We explored various configurations to
address the challenge: in Experiment 1, we utilized a union of n-gram analyzers
(word, character, character with word boundaries) with different n-gram values;
in Experiment 2, we combined a weighted union of Term Frequency-Inverse
Document Frequency (TF-IDF) features with various weights; and in Experiment 3,
we implemented a weighted major voting scheme using three classifiers: Linear
Support Vector Classifier (LSVC), Random Forest (RF), and K-Nearest Neighbors
(KNN).
  Our approach, despite its simplicity and reliance on traditional machine
learning techniques, demonstrated competitive performance in terms of F1-score
and precision. Notably, we achieved the highest precision score of 63.22% among
the participating teams. However, our overall F1 score was approximately 21%,
significantly impacted by a low recall rate of 12.87%. This indicates that
while our models were highly precise, they struggled to recall a broad range of
dialect labels, highlighting a critical area for improvement in handling
diverse dialectal variations.",2024-07-18,"Mohamed Lichouri, Khaled Lounnas, Boualem Nadjib Zahaf, Mehdi Ayoub Rabiai",http://arxiv.org/pdf/2407.13608v1,cs.CL
dzStance at StanceEval2024: Arabic Stance Detection based on Sentence Transformers,"This study compares Term Frequency-Inverse Document Frequency (TF-IDF)
features with Sentence Transformers for detecting writers' stances--favorable,
opposing, or neutral--towards three significant topics: COVID-19 vaccine,
digital transformation, and women empowerment. Through empirical evaluation, we
demonstrate that Sentence Transformers outperform TF-IDF features across
various experimental setups. Our team, dzStance, participated in a stance
detection competition, achieving the 13th position (74.91%) among 15 teams in
Women Empowerment, 10th (73.43%) in COVID Vaccine, and 12th (66.97%) in Digital
Transformation. Overall, our team's performance ranked 13th (71.77%) among all
participants. Notably, our approach achieved promising F1-scores, highlighting
its effectiveness in identifying writers' stances on diverse topics. These
results underscore the potential of Sentence Transformers to enhance stance
detection models for addressing critical societal issues.",2024-07-18,"Mohamed Lichouri, Khaled Lounnas, Khelil Rafik Ouaras, Mohamed Abi, Anis Guechtouli",http://arxiv.org/pdf/2407.13603v1,cs.CL
PLANTS: A Novel Problem and Dataset for Summarization of Planning-Like (PL) Tasks,"Text summarization is a well-studied problem that deals with deriving
insights from unstructured text consumed by humans, and it has found extensive
business applications. However, many real-life tasks involve generating a
series of actions to achieve specific goals, such as workflows, recipes,
dialogs, and travel plans. We refer to them as planning-like (PL) tasks noting
that the main commonality they share is control flow information. which may be
partially specified. Their structure presents an opportunity to create more
practical summaries to help users make quick decisions. We investigate this
observation by introducing a novel plan summarization problem, presenting a
dataset, and providing a baseline method for generating PL summaries. Using
quantitative metrics and qualitative user studies to establish baselines, we
evaluate the plan summaries from our method and large language models. We
believe the novel problem and dataset can reinvigorate research in
summarization, which some consider as a solved problem.",2024-07-18,"Vishal Pallagani, Biplav Srivastava, Nitin Gupta",http://arxiv.org/pdf/2407.13597v1,cs.CL
Towards Zero-Shot Multimodal Machine Translation,"Current multimodal machine translation (MMT) systems rely on fully supervised
data (i.e models are trained on sentences with their translations and
accompanying images). However, this type of data is costly to collect, limiting
the extension of MMT to other language pairs for which such data does not
exist. In this work, we propose a method to bypass the need for fully
supervised data to train MMT systems, using multimodal English data only. Our
method, called ZeroMMT, consists in adapting a strong text-only machine
translation (MT) model by training it on a mixture of two objectives: visually
conditioned masked language modelling and the Kullback-Leibler divergence
between the original and new MMT outputs. We evaluate on standard MMT
benchmarks and the recently released CoMMuTE, a contrastive benchmark aiming to
evaluate how well models use images to disambiguate English sentences. We
obtain disambiguation performance close to state-of-the-art MMT models trained
additionally on fully supervised examples. To prove that our method generalizes
to languages with no fully supervised training data available, we extend the
CoMMuTE evaluation dataset to three new languages: Arabic, Russian and Chinese.
We further show that we can control the trade-off between disambiguation
capabilities and translation fidelity at inference time using classifier-free
guidance and without any additional data. Our code, data and trained models are
publicly accessible.",2024-07-18,"Matthieu Futeral, Cordelia Schmid, Benoît Sagot, Rachel Bawden",http://arxiv.org/pdf/2407.13579v2,cs.CL
How Reliable are LLMs as Knowledge Bases? Re-thinking Facutality and Consistency,"Large Language Models (LLMs) are increasingly explored as knowledge bases
(KBs), yet current evaluation methods focus too narrowly on knowledge
retention, overlooking other crucial criteria for reliable performance. In this
work, we rethink the requirements for evaluating reliable LLM-as-KB usage and
highlight two essential factors: factuality, ensuring accurate responses to
seen and unseen knowledge, and consistency, maintaining stable answers to
questions about the same knowledge. We introduce UnseenQA, a dataset designed
to assess LLM performance on unseen knowledge, and propose new criteria and
metrics to quantify factuality and consistency, leading to a final reliability
score. Our experiments on 26 LLMs reveal several challenges regarding their use
as KBs, underscoring the need for more principled and comprehensive evaluation.",2024-07-18,"Danna Zheng, Mirella Lapata, Jeff Z. Pan",http://arxiv.org/pdf/2407.13578v2,cs.CL
New Capability to Look Up an ASL Sign from a Video Example,"Looking up an unknown sign in an ASL dictionary can be difficult. Most ASL
dictionaries are organized based on English glosses, despite the fact that (1)
there is no convention for assigning English-based glosses to ASL signs; and
(2) there is no 1-1 correspondence between ASL signs and English words.
Furthermore, what if the user does not know either the meaning of the target
sign or its possible English translation(s)? Some ASL dictionaries enable
searching through specification of articulatory properties, such as handshapes,
locations, movement properties, etc. However, this is a cumbersome process and
does not always result in successful lookup. Here we describe a new system,
publicly shared on the Web, to enable lookup of a video of an ASL sign (e.g., a
webcam recording or a clip from a continuous signing video). The user submits a
video for analysis and is presented with the five most likely sign matches, in
decreasing order of likelihood, so that the user can confirm the selection and
then be taken to our ASLLRP Sign Bank entry for that sign. Furthermore, this
video lookup is also integrated into our newest version of SignStream(R)
software to facilitate linguistic annotation of ASL video data, enabling the
user to directly look up a sign in the video being annotated, and, upon
confirmation of the match, to directly enter into the annotation the gloss and
features of that sign, greatly increasing the efficiency and consistency of
linguistic annotations of ASL video data.",2024-07-18,"Carol Neidle, Augustine Opoku, Carey Ballard, Yang Zhou, Xiaoxiao He, Gregory Dimitriadis, Dimitris Metaxas",http://arxiv.org/pdf/2407.13571v1,cs.CL
dzFinNlp at AraFinNLP: Improving Intent Detection in Financial Conversational Agents,"In this paper, we present our dzFinNlp team's contribution for intent
detection in financial conversational agents, as part of the AraFinNLP shared
task. We experimented with various models and feature configurations, including
traditional machine learning methods like LinearSVC with TF-IDF, as well as
deep learning models like Long Short-Term Memory (LSTM). Additionally, we
explored the use of transformer-based models for this task. Our experiments
show promising results, with our best model achieving a micro F1-score of
93.02% and 67.21% on the ArBanking77 dataset, in the development and test sets,
respectively.",2024-07-18,"Mohamed Lichouri, Khaled Lounnas, Mohamed Zakaria Amziane",http://arxiv.org/pdf/2407.13565v1,cs.CL
Research on Tibetan Tourism Viewpoints information generation system based on LLM,"Tibet, ensconced within China's territorial expanse, is distinguished by its
labyrinthine and heterogeneous topography, a testament to its profound
historical heritage, and the cradle of a unique religious ethos. The very
essence of these attributes, however, has impeded the advancement of Tibet's
tourism service infrastructure, rendering existing smart tourism services
inadequate for the region's visitors. This study delves into the ramifications
of informational disparities at tourist sites on Tibetan tourism and addresses
the challenge of establishing the Large Language Model (LLM) evaluation
criteria. It introduces an innovative approach, the DualGen Bridge AI system,
employing supervised fine-tuning techniques to bolster model functionality and
enhance optimization processes. Furthermore, it pioneers a multi-structured
generative results assessment framework. Empirical validation confirms the
efficacy of this framework. The study also explores the application of the
supervised fine-tuning method within the proprietary DualGen Bridge AI, aimed
at refining the generation of tourist site information. The study's findings
offer valuable insights for optimizing system performance and provide support
and inspiration for the application of LLM technology in Tibet's tourism
services and beyond, potentially revolutionizing the smart tourism industry
with advanced, tailored information generation capabilities.",2024-07-18,"Jinhu Qi, Shuai Yan, Wentao Zhang, Yibo Zhang, Zirui Liu, Ke Wang",http://arxiv.org/pdf/2407.13561v1,cs.CL
Qalam : A Multimodal LLM for Arabic Optical Character and Handwriting Recognition,"Arabic Optical Character Recognition (OCR) and Handwriting Recognition (HWR)
pose unique challenges due to the cursive and context-sensitive nature of the
Arabic script. This study introduces Qalam, a novel foundation model designed
for Arabic OCR and HWR, built on a SwinV2 encoder and RoBERTa decoder
architecture. Our model significantly outperforms existing methods, achieving a
Word Error Rate (WER) of just 0.80% in HWR tasks and 1.18% in OCR tasks. We
train Qalam on a diverse dataset, including over 4.5 million images from Arabic
manuscripts and a synthetic dataset comprising 60k image-text pairs. Notably,
Qalam demonstrates exceptional handling of Arabic diacritics, a critical
feature in Arabic scripts. Furthermore, it shows a remarkable ability to
process high-resolution inputs, addressing a common limitation in current OCR
systems. These advancements underscore Qalam's potential as a leading solution
for Arabic script recognition, offering a significant leap in accuracy and
efficiency.",2024-07-18,"Gagan Bhatia, El Moatez Billah Nagoudi, Fakhraddin Alwajih, Muhammad Abdul-Mageed",http://arxiv.org/pdf/2407.13559v1,cs.CL
Can Open-Source LLMs Compete with Commercial Models? Exploring the Few-Shot Performance of Current GPT Models in Biomedical Tasks,"Commercial large language models (LLMs), like OpenAI's GPT-4 powering ChatGPT
and Anthropic's Claude 3 Opus, have dominated natural language processing (NLP)
benchmarks across different domains. New competing Open-Source alternatives
like Mixtral 8x7B or Llama 3 have emerged and seem to be closing the gap while
often offering higher throughput and being less costly to use. Open-Source LLMs
can also be self-hosted, which makes them interesting for enterprise and
clinical use cases where sensitive data should not be processed by third
parties. We participated in the 12th BioASQ challenge, which is a retrieval
augmented generation (RAG) setting, and explored the performance of current GPT
models Claude 3 Opus, GPT-3.5-turbo and Mixtral 8x7b with in-context learning
(zero-shot, few-shot) and QLoRa fine-tuning. We also explored how additional
relevant knowledge from Wikipedia added to the context-window of the LLM might
improve their performance. Mixtral 8x7b was competitive in the 10-shot setting,
both with and without fine-tuning, but failed to produce usable results in the
zero-shot setting. QLoRa fine-tuning and Wikipedia context did not lead to
measurable performance gains. Our results indicate that the performance gap
between commercial and open-source models in RAG setups exists mainly in the
zero-shot setting and can be closed by simply collecting few-shot examples for
domain-specific use cases. The code needed to rerun these experiments is
available through GitHub.",2024-07-18,"Samy Ateia, Udo Kruschwitz",http://arxiv.org/pdf/2407.13511v1,cs.CL
Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models,"Spontaneous style speech synthesis, which aims to generate human-like speech,
often encounters challenges due to the scarcity of high-quality data and
limitations in model capabilities. Recent language model-based TTS systems can
be trained on large, diverse, and low-quality speech datasets, resulting in
highly natural synthesized speech. However, they are limited by the difficulty
of simulating various spontaneous behaviors and capturing prosody variations in
spontaneous speech. In this paper, we propose a novel spontaneous speech
synthesis system based on language models. We systematically categorize and
uniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody
modeling is introduced to enhance the model's ability to capture subtle prosody
variations in spontaneous speech.Experimental results show that our proposed
method significantly outperforms the baseline methods in terms of prosody
naturalness and spontaneous behavior naturalness.",2024-07-18,"Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng",http://arxiv.org/pdf/2407.13509v1,cs.CL
Enhancing Biomedical Knowledge Discovery for Diseases: An Open-Source Framework Applied on Rett Syndrome and Alzheimer's Disease,"The ever-growing volume of biomedical publications creates a critical need
for efficient knowledge discovery. In this context, we introduce an open-source
end-to-end framework designed to construct knowledge around specific diseases
directly from raw text. To facilitate research in disease-related knowledge
discovery, we create two annotated datasets focused on Rett syndrome and
Alzheimer's disease, enabling the identification of semantic relations between
biomedical entities. Extensive benchmarking explores various ways to represent
relations and entity representations, offering insights into optimal modeling
strategies for semantic relation detection and highlighting language models'
competence in knowledge discovery. We also conduct probing experiments using
different layer representations and attention scores to explore transformers'
ability to capture semantic relations.",2024-07-18,"Christos Theodoropoulos, Andrei Catalin Coman, James Henderson, Marie-Francine Moens",http://arxiv.org/pdf/2407.13492v3,cs.CL
Combining Constraint Programming Reasoning with Large Language Model Predictions,"Constraint Programming (CP) and Machine Learning (ML) face challenges in text
generation due to CP's struggle with implementing ""meaning'' and ML's
difficulty with structural constraints. This paper proposes a solution by
combining both approaches and embedding a Large Language Model (LLM) in CP. The
LLM handles word generation and meaning, while CP manages structural
constraints. This approach builds on GenCP, an improved version of On-the-fly
Constraint Programming Search (OTFS) using LLM-generated domains. Compared to
Beam Search (BS), a standard NLP method, this combined approach (GenCP with
LLM) is faster and produces better results, ensuring all constraints are
satisfied. This fusion of CP and ML presents new possibilities for enhancing
text generation under constraints.",2024-07-18,"Florian Régin, Elisabetta De Maria, Alexandre Bonlarron",http://arxiv.org/pdf/2407.13490v1,cs.CL
Attention Overflow: Language Model Input Blur during Long-Context Missing Items Recommendation,"Large language models (LLMs) can suggest missing elements from items listed
in a prompt, which can be used for list completion or recommendations based on
users' history. However, their performance degrades when presented with too
many items, as they start to suggest items already included in the input list.
This occurs at around 100 items for mid-2024 flagship LLMs. We evaluate this
phenomenon on both synthetic problems (e.g., finding missing numbers in a given
range of shuffled integers) and realistic movie recommendation scenarios. We
refer to this issue as \textit{attention overflow}, as preventing repetition
requires attending to all items simultaneously. Although iterative loops can
mitigate this problem, their costs increase with the repetition rate, affecting
the language models' ability to derive novelty from lengthy inputs.",2024-07-18,Damien Sileo,http://arxiv.org/pdf/2407.13481v1,cs.CL
Fixed and Adaptive Simultaneous Machine Translation Strategies Using Adapters,"Simultaneous machine translation aims at solving the task of real-time
translation by starting to translate before consuming the full input, which
poses challenges in terms of balancing quality and latency of the translation.
The wait-$k$ policy offers a solution by starting to translate after consuming
$k$ words, where the choice of the number $k$ directly affects the latency and
quality. In applications where we seek to keep the choice over latency and
quality at inference, the wait-$k$ policy obliges us to train more than one
model. In this paper, we address the challenge of building one model that can
fulfil multiple latency levels and we achieve this by introducing lightweight
adapter modules into the decoder. The adapters are trained to be specialized
for different wait-$k$ values and compared to other techniques they offer more
flexibility to allow for reaping the benefits of parameter sharing and
minimizing interference. Additionally, we show that by combining with an
adaptive strategy, we can further improve the results. Experiments on two
language directions show that our method outperforms or competes with other
strong baselines on most latency values.",2024-07-18,"Abderrahmane Issam, Yusuf Can Semerci, Jan Scholtes, Gerasimos Spanakis",http://arxiv.org/pdf/2407.13469v1,cs.CL
End-To-End Clinical Trial Matching with Large Language Models,"Matching cancer patients to clinical trials is essential for advancing
treatment and patient care. However, the inconsistent format of medical free
text documents and complex trial eligibility criteria make this process
extremely challenging and time-consuming for physicians. We investigated
whether the entire trial matching process - from identifying relevant trials
among 105,600 oncology-related clinical trials on clinicaltrials.gov to
generating criterion-level eligibility matches - could be automated using Large
Language Models (LLMs). Using GPT-4o and a set of 51 synthetic Electronic
Health Records (EHRs), we demonstrate that our approach identifies relevant
candidate trials in 93.3% of cases and achieves a preliminary accuracy of 88.0%
when matching patient-level information at the criterion level against a
baseline defined by human experts. Utilizing LLM feedback reveals that 39.3%
criteria that were initially considered incorrect are either ambiguous or
inaccurately annotated, leading to a total model accuracy of 92.7% after
refining our human baseline. In summary, we present an end-to-end pipeline for
clinical trial matching using LLMs, demonstrating high precision in screening
and matching trials to individual patients, even outperforming the performance
of qualified medical doctors. Our fully end-to-end pipeline can operate
autonomously or with human supervision and is not restricted to oncology,
offering a scalable solution for enhancing patient-trial matching in real-world
settings.",2024-07-18,"Dyke Ferber, Lars Hilgers, Isabella C. Wiest, Marie-Elisabeth Leßmann, Jan Clusmann, Peter Neidlinger, Jiefu Zhu, Georg Wölflein, Jacqueline Lammert, Maximilian Tschochohei, Heiko Böhme, Dirk Jäger, Mihaela Aldea, Daniel Truhn, Christiane Höper, Jakob Nikolas Kather",http://arxiv.org/pdf/2407.13463v1,cs.CL
BEAF: Observing BEfore-AFter Changes to Evaluate Hallucination in Vision-language Models,"Vision language models (VLMs) perceive the world through a combination of a
visual encoder and a large language model (LLM). The visual encoder,
pre-trained on large-scale vision-text datasets, provides zero-shot
generalization to visual data, and the LLM endows its high reasoning ability to
VLMs. It leads VLMs to achieve high performance on wide benchmarks without
fine-tuning, exhibiting zero or few-shot capability. However, recent studies
show that VLMs are vulnerable to hallucination. This undesirable behavior
degrades reliability and credibility, thereby making users unable to fully
trust the output from VLMs. To enhance trustworthiness and better tackle the
hallucination of VLMs, we curate a new evaluation dataset, called the
BEfore-AFter hallucination dataset (BEAF), and introduce new metrics: True
Understanding (TU), IGnorance (IG), StuBbornness (SB), and InDecision (ID).
Unlike prior works that focus only on constructing questions and answers, the
key idea of our benchmark is to manipulate visual scene information by image
editing models and to design the metrics based on scene changes. This allows us
to clearly assess whether VLMs correctly understand a given scene by observing
the ability to perceive changes. We also visualize image-wise object
relationship by virtue of our two-axis view: vision and text. Upon evaluating
VLMs with our dataset, we observed that our metrics reveal different aspects of
VLM hallucination that have not been reported before. Project page:
\url{https://beafbench.github.io/}",2024-07-18,"Moon Ye-Bin, Nam Hyeon-Woo, Wonseok Choi, Tae-Hyun Oh",http://arxiv.org/pdf/2407.13442v1,cs.CL
Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies,"Publicly available TTS datasets for low-resource languages like Hindi and
Tamil typically contain 10-20 hours of data, leading to poor vocabulary
coverage. This limitation becomes evident in downstream applications where
domain-specific vocabulary coupled with frequent code-mixing with English,
results in many OOV words. To highlight this problem, we create a benchmark
containing OOV words from several real-world applications. Indeed,
state-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV
benchmark, as indicated by intelligibility tests. To improve the model's OOV
performance, we propose a low-effort and economically viable strategy to obtain
more training data. Specifically, we propose using volunteers as opposed to
high quality voice artists to record words containing character bigrams unseen
in the training data. We show that using such inexpensive data, the model's
performance improves on OOV words, while not affecting voice quality and
in-domain performance.",2024-07-18,"Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra",http://arxiv.org/pdf/2407.13435v1,cs.CL
From Words to Worlds: Compositionality for Cognitive Architectures,"Large language models (LLMs) are very performant connectionist systems, but
do they exhibit more compositionality? More importantly, is that part of why
they perform so well? We present empirical analyses across four LLM families
(12 models) and three task categories, including a novel task introduced below.
Our findings reveal a nuanced relationship in learning of compositional
strategies by LLMs -- while scaling enhances compositional abilities,
instruction tuning often has a reverse effect. Such disparity brings forth some
open issues regarding the development and improvement of large language models
in alignment with human cognitive capacities.",2024-07-18,"Ruchira Dhar, Anders Søgaard",http://arxiv.org/pdf/2407.13419v1,cs.CL
Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization,"Language model alignment methods such as reinforcement learning from human
feedback (RLHF) have led to impressive advances in language model capabilities,
but are limited by a widely observed phenomenon known as overoptimization,
where the quality of the language model degrades over the course of the
alignment process. As the model optimizes performance with respect to an
offline reward model, it overfits to inaccuracies and drifts away from
preferred responses covered by the data. To discourage such distribution shift,
KL-regularization is widely employed in existing offline alignment methods, but
overoptimization continues to harm performance. Lending theoretical insight
into the source of these empirical observations, we first show that the
KL-regularization is too weak to prevent overfitting, then raise the following
question: is it possible to design an efficient algorithm that is provably
robust to overoptimization?
  We address this question with a new algorithm for offline alignment,
$\chi^2$-Preference Optimization ($\chi$PO). $\chi$PO is a one-line change to
Direct Preference Optimization (DPO; Rafailov et al., 2023), which only
involves modifying the logarithmic link function in the DPO objective. Despite
this minimal change, $\chi$PO implicitly implements the principle of pessimism
in the face of uncertainty via regularization with the $\chi^2$-divergence --
which quantifies uncertainty more effectively than KL-regularization -- and
provably alleviates overoptimization, achieving sample-complexity guarantees
based on single-policy concentrability -- the gold standard in offline
reinforcement learning. $\chi$PO's simplicity and strong guarantees make it the
first practical and general-purpose offline alignment algorithm that is
provably robust to overoptimization.",2024-07-18,"Audrey Huang, Wenhao Zhan, Tengyang Xie, Jason D. Lee, Wen Sun, Akshay Krishnamurthy, Dylan J. Foster",http://arxiv.org/pdf/2407.13399v3,cs.CL
Linear-Complexity Self-Supervised Learning for Speech Processing,"Self-supervised learning (SSL) models usually require weeks of pre-training
with dozens of high-end GPUs. These models typically have a multi-headed
self-attention (MHSA) context encoder. However, MHSA takes quadratic time and
space in the input length, contributing to the high pre-training cost.
Linear-complexity alternatives to MHSA have been proposed. For instance, in
supervised training, the SummaryMixing model is the first to outperform MHSA
across multiple speech processing tasks. However, these cheaper alternatives
have not been explored for SSL yet. This paper studies a linear-complexity
context encoder for SSL for the first time. With better or equivalent
performance for the downstream tasks of the MP3S benchmark, SummaryMixing
reduces the pre-training time and peak VRAM of wav2vec 2.0 model by 18% and by
23%, respectively, leading to the pre-training of a 155M wav2vec 2.0 model
finished within one week with 4 Tesla A100 GPUs. Code is available at
https://github.com/SamsungLabs/SummaryMixing.",2024-07-18,"Shucong Zhang, Titouan Parcollet, Rogier van Dalen, Sourav Bhattacharya",http://arxiv.org/pdf/2407.13377v1,cs.CL
Capturing Style in Author and Document Representation,"A wide range of Deep Natural Language Processing (NLP) models integrates
continuous and low dimensional representations of words and documents.
Surprisingly, very few models study representation learning for authors. These
representations can be used for many NLP tasks, such as author identification
and classification, or in recommendation systems. A strong limitation of
existing works is that they do not explicitly capture writing style, making
them hardly applicable to literary data. We therefore propose a new
architecture based on Variational Information Bottleneck (VIB) that learns
embeddings for both authors and documents with a stylistic constraint. Our
model fine-tunes a pre-trained document encoder. We stimulate the detection of
writing style by adding predefined stylistic features making the representation
axis interpretable with respect to writing style indicators. We evaluate our
method on three datasets: a literary corpus extracted from the Gutenberg
Project, the Blog Authorship Corpus and IMDb62, for which we show that it
matches or outperforms strong/recent baselines in authorship attribution while
capturing much more accurately the authors stylistic aspects.",2024-07-18,"Enzo Terreau, Antoine Gourru, Julien Velcin",http://arxiv.org/pdf/2407.13358v1,cs.CL
Mechanical Self-replication,"This study presents a theoretical model for a self-replicating mechanical
system inspired by biological processes within living cells and supported by
computer simulations. The model decomposes self-replication into core
components, each of which is executed by a single machine constructed from a
set of basic block types. Key functionalities such as sorting, copying, and
building, are demonstrated. The model provides valuable insights into the
constraints of self-replicating systems. The discussion also addresses the
spatial and timing behavior of the system, as well as its efficiency and
complexity. This work provides a foundational framework for future studies on
self-replicating mechanisms and their information-processing applications.",2024-07-18,Ralph P. Lano,http://arxiv.org/pdf/2407.14556v2,cs.CL
Handling Numeric Expressions in Automatic Speech Recognition,"This paper addresses the problem of correctly formatting numeric expressions
in automatic speech recognition (ASR) transcripts. This is challenging since
the expected transcript format depends on the context, e.g., 1945 (year) vs.
19:45 (timestamp). We compare cascaded and end-to-end approaches to recognize
and format numeric expression, such as years, timestamps, currency amounts, and
quantities. For the end-to-end approach we employed a data generation strategy
using a large language model (LLM) together with a text to speech (TTS) model
to generate adaptation data. The results on our test dataset show that while
approaches based on LLMs perform well on recognizing formatted numeric
expressions, adapted end-to-end models offer competitive performance with the
advantage of lower latency and inference cost.",2024-07-18,"Christian Huber, Alexander Waibel",http://arxiv.org/pdf/2408.00004v1,cs.CL
Learning-From-Mistakes Prompting for Indigenous Language Translation,"Using large language models, this paper presents techniques to improve
extremely low-resourced indigenous language translations. Our approaches are
grounded in the use of (1) the presence of a datastore consisting of a limited
number of parallel translation examples, (2) the inherent capabilities of LLMs
like GPT-3.5, and (3) a word-level translation dictionary. We harness the
potential of LLMs and in-context learning techniques in such a setting for
using LLMs as universal translators for extremely low-resourced languages. Our
methodology hinges on utilizing LLMs as language compilers for selected
language pairs, hypothesizing that they could internalize syntactic structures
to facilitate accurate translation. We introduce three techniques: KNNPrompting
with Retrieved Prompting Context, Chain-of-Thought Prompting and
Learningfrom-Mistakes Prompting, with the last method addressing past errors.
The evaluation results suggest that, even with limited corpora, LLMs can
effectively translate extremely low-resource languages when paired with proper
prompting.",2024-07-18,"You-Cheng Liao, Chen-Jui Yu, Chi-Yi Lin, He-Feng Yun, Yen-Hsiang Wang, Hsiao-Min Li, Yao-Chung Fan",http://arxiv.org/pdf/2407.13343v1,cs.CL
CiteFusion: An Ensemble Framework for Citation Intent Classification Harnessing Dual-Model Binary Couples and SHAP Analyses,"Understanding the motivations underlying scholarly citations is critical for
evaluating research impact and fostering transparent scholarly communication.
This study introduces CiteFusion, an ensemble framework designed to address the
multiclass Citation Intent Classification (CIC) task on benchmark datasets,
SciCite and ACL-ARC. The framework decomposes the task into binary
classification subtasks, utilizing complementary pairs of SciBERT and XLNet
models fine-tuned independently for each citation intent. These base models are
aggregated through a feedforward neural network meta-classifier, ensuring
robust performance in imbalanced and data-scarce scenarios. To enhance
interpretability, SHAP (SHapley Additive exPlanations) is employed to analyze
token-level contributions and interactions among base models, providing
transparency into classification dynamics. We further investigate the semantic
role of structural context by incorporating section titles into input
sentences, demonstrating their significant impact on classification accuracy
and model reliability. Experimental results show that CiteFusion achieves
state-of-the-art performance, with Macro-F1 scores of 89.60% on SciCite and
76.24% on ACL-ARC. The original intents from both datasets are mapped to
Citation Typing Ontology (CiTO) object properties to ensure interoperability
and reusability. This mapping highlights overlaps between the two datasets
labels, enhancing their understandability and reusability. Finally, we release
a web-based application that classifies citation intents leveraging CiteFusion
models developed on SciCite.",2024-07-18,"Lorenzo Paolini, Sahar Vahdati, Angelo Di Iorio, Robert Wardenga, Ivan Heibi, Silvio Peroni",http://arxiv.org/pdf/2407.13329v2,cs.CL
"CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis","The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.",2024-07-18,"Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang",http://arxiv.org/pdf/2407.13301v2,cs.CL
Robust ASR Error Correction with Conservative Data Filtering,"Error correction (EC) based on large language models is an emerging
technology to enhance the performance of automatic speech recognition (ASR)
systems. Generally, training data for EC are collected by automatically pairing
a large set of ASR hypotheses (as sources) and their gold references (as
targets). However, the quality of such pairs is not guaranteed, and we observed
various types of noise which can make the EC models brittle, e.g. inducing
overcorrection in out-of-domain (OOD) settings. In this work, we propose two
fundamental criteria that EC training data should satisfy: namely, EC targets
should (1) improve linguistic acceptability over sources and (2) be inferable
from the available context (e.g. source phonemes). Through these criteria, we
identify low-quality EC pairs and train the models not to make any correction
in such cases, the process we refer to as conservative data filtering. In our
experiments, we focus on Japanese ASR using a strong Conformer-CTC as the
baseline and finetune Japanese LLMs for EC. Through our evaluation on a suite
of 21 internal benchmarks, we demonstrate that our approach can significantly
reduce overcorrection and improve both the accuracy and quality of ASR results
in the challenging OOD settings.",2024-07-18,"Takuma Udagawa, Masayuki Suzuki, Masayasu Muraoka, Gakuto Kurata",http://arxiv.org/pdf/2407.13300v2,cs.CL
SpeciaLex: A Benchmark for In-Context Specialized Lexicon Learning,"Specialized lexicons are collections of words with associated constraints
such as special definitions, specific roles, and intended target audiences.
These constraints are necessary for content generation and documentation tasks
(e.g., writing technical manuals or children's reading materials), where the
goal is to reduce the ambiguity of text content and increase its overall
readability for a specific group of audience. Understanding how large language
models can capture these constraints can help researchers build better, more
impactful tools for wider use beyond the NLP community. Towards this end, we
introduce SpeciaLex, a benchmark for evaluating a language model's ability to
follow specialized lexicon-based constraints across 18 diverse subtasks with
1,785 test instances covering core tasks of Checking, Identification,
Rewriting, and Open Generation. We present an empirical evaluation of 15 open
and closed-source LLMs and discuss insights on how factors such as model scale,
openness, setup, and recency affect performance upon evaluating with the
benchmark.",2024-07-18,"Joseph Marvin Imperial, Harish Tayyar Madabushi",http://arxiv.org/pdf/2407.13297v2,cs.CL
Low-Resourced Speech Recognition for Iu Mien Language via Weakly-Supervised Phoneme-based Multilingual Pre-training,"The mainstream automatic speech recognition (ASR) technology usually requires
hundreds to thousands of hours of annotated speech data. Three approaches to
low-resourced ASR are phoneme or subword based supervised pre-training, and
self-supervised pre-training over multilingual data. The Iu Mien language is
the main ethnic language of the Yao ethnic group in China and is low-resourced
in the sense that the annotated speech is very limited. With less than 10 hours
of transcribed Iu Mien language, this paper investigates and compares the three
approaches for Iu Mien speech recognition. Our experiments are based on the
recently released, three backbone models pretrained over the 10 languages from
the CommonVoice dataset (CV-Lang10), which correspond to the three approaches
for low-resourced ASR. It is found that phoneme supervision can achieve better
results compared to subword supervision and self-supervision, thereby providing
higher data-efficiency. Particularly, the Whistle models, i.e., obtained by the
weakly-supervised phoneme-based multilingual pre-training, obtain the most
competitive results.",2024-07-18,"Lukuan Dong, Donghong Qin, Fengbo Bai, Fanhua Song, Yan Liu, Chen Xu, Zhijian Ou",http://arxiv.org/pdf/2407.13292v2,cs.CL
Are Large Language Models Capable of Generating Human-Level Narratives?,"This paper investigates the capability of LLMs in storytelling, focusing on
narrative development and plot progression. We introduce a novel computational
framework to analyze narratives through three discourse-level aspects: i) story
arcs, ii) turning points, and iii) affective dimensions, including arousal and
valence. By leveraging expert and automatic annotations, we uncover significant
discrepancies between the LLM- and human- written stories. While human-written
stories are suspenseful, arousing, and diverse in narrative structures, LLM
stories are homogeneously positive and lack tension. Next, we measure narrative
reasoning skills as a precursor to generative capacities, concluding that most
LLMs fall short of human abilities in discourse understanding. Finally, we show
that explicit integration of aforementioned discourse features can enhance
storytelling, as is demonstrated by over 40% improvement in neural storytelling
in terms of diversity, suspense, and arousal.",2024-07-18,"Yufei Tian, Tenghao Huang, Miri Liu, Derek Jiang, Alexander Spangher, Muhao Chen, Jonathan May, Nanyun Peng",http://arxiv.org/pdf/2407.13248v2,cs.CL
PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks,"Large Language Models (LLMs) have the potential to semi-automate some process
mining (PM) analyses. While commercial models are already adequate for many
analytics tasks, the competitive level of open-source LLMs in PM tasks is
unknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive
benchmark for PM focusing on domain knowledge (process-mining-specific and
process-specific) and on different implementation strategies. We focus also on
the challenges in creating such a benchmark, related to the public availability
of the data and on evaluation biases by the LLMs. Overall, we observe that most
of the considered LLMs can perform some process mining tasks at a satisfactory
level, but tiny models that would run on edge devices are still inadequate. We
also conclude that while the proposed benchmark is useful for identifying LLMs
that are adequate for process mining tasks, further research is needed to
overcome the evaluation biases and perform a more thorough ranking of the
competitive LLMs.",2024-07-18,"Alessandro Berti, Humam Kourani, Wil M. P. van der Aalst",http://arxiv.org/pdf/2407.13244v1,cs.CL
Evaluating Large Language Models for Anxiety and Depression Classification using Counseling and Psychotherapy Transcripts,"We aim to evaluate the efficacy of traditional machine learning and large
language models (LLMs) in classifying anxiety and depression from long
conversational transcripts. We fine-tune both established transformer models
(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained
a Support Vector Machine with feature engineering, and assessed GPT models
through prompting. We observe that state-of-the-art models fail to enhance
classification outcomes compared to traditional machine learning methods.",2024-07-18,"Junwei Sun, Siqi Ma, Yiran Fan, Peter Washington",http://arxiv.org/pdf/2407.13228v1,cs.CL
Transformer-based Single-Cell Language Model: A Survey,"The transformers have achieved significant accomplishments in the natural
language processing as its outstanding parallel processing capabilities and
highly flexible attention mechanism. In addition, increasing studies based on
transformers have been proposed to model single-cell data. In this review, we
attempt to systematically summarize the single-cell language models and
applications based on transformers. First, we provide a detailed introduction
about the structure and principles of transformers. Then, we review the
single-cell language models and large language models for single-cell data
analysis. Moreover, we explore the datasets and applications of single-cell
language models in downstream tasks such as batch correction, cell clustering,
cell type annotation, gene regulatory network inference and perturbation
response. Further, we discuss the challenges of single-cell language models and
provide promising research directions. We hope this review will serve as an
up-to-date reference for researchers interested in the direction of single-cell
language models.",2024-07-18,"Wei Lan, Guohang He, Mingyang Liu, Qingfeng Chen, Junyue Cao, Wei Peng",http://arxiv.org/pdf/2407.13205v1,cs.CL
Retrieval-Augmented Generation for Natural Language Processing: A Survey,"Large language models (LLMs) have demonstrated great success in various
fields, benefiting from their huge amount of parameters that store knowledge.
However, LLMs still suffer from several key issues, such as hallucination
problems, knowledge update issues, and lacking domain-specific expertise. The
appearance of retrieval-augmented generation (RAG), which leverages an external
knowledge database to augment LLMs, makes up those drawbacks of LLMs. This
paper reviews all significant techniques of RAG, especially in the retriever
and the retrieval fusions. Besides, tutorial codes are provided for
implementing the representative techniques in RAG. This paper further discusses
the RAG update, including RAG with/without knowledge update. Then, we introduce
RAG evaluation and benchmarking, as well as the application of RAG in
representative NLP tasks and industrial scenarios. Finally, this paper
discusses RAG's future directions and challenges for promoting this field's
development.",2024-07-18,"Shangyu Wu, Ying Xiong, Yufei Cui, Haolun Wu, Can Chen, Ye Yuan, Lianming Huang, Xue Liu, Tei-Wei Kuo, Nan Guan, Chun Jason Xue",http://arxiv.org/pdf/2407.13193v3,cs.CL
SciCode: A Research Coding Benchmark Curated by Scientists,"Since language models (LMs) now outperform average humans on many challenging
tasks, it has become increasingly difficult to develop challenging,
high-quality, and realistic evaluations. We address this issue by examining
LMs' capabilities to generate code for solving real scientific research
problems. Incorporating input from scientists and AI researchers in 16 diverse
natural science sub-fields, including mathematics, physics, chemistry, biology,
and materials science, we created a scientist-curated coding benchmark,
SciCode. The problems in SciCode naturally factorize into multiple subproblems,
each involving knowledge recall, reasoning, and code synthesis. In total,
SciCode contains 338 subproblems decomposed from 80 challenging main problems.
It offers optional descriptions specifying useful scientific background
information and scientist-annotated gold-standard solutions and test cases for
evaluation. Claude3.5-Sonnet, the best-performing model among those tested, can
solve only 4.6% of the problems in the most realistic setting. We believe that
SciCode demonstrates both contemporary LMs' progress towards becoming helpful
scientific assistants and sheds light on the development and evaluation of
scientific AI in the future.",2024-07-18,"Minyang Tian, Luyu Gao, Shizhuo Dylan Zhang, Xinan Chen, Cunwei Fan, Xuefei Guo, Roland Haas, Pan Ji, Kittithat Krongchon, Yao Li, Shengyan Liu, Di Luo, Yutao Ma, Hao Tong, Kha Trinh, Chenyu Tian, Zihan Wang, Bohao Wu, Yanyu Xiong, Shengzhu Yin, Minhui Zhu, Kilian Lieret, Yanxin Lu, Genglin Liu, Yufeng Du, Tianhua Tao, Ofir Press, Jamie Callan, Eliu Huerta, Hao Peng",http://arxiv.org/pdf/2407.13168v1,cs.CL
Translate-and-Revise: Boosting Large Language Models for Constrained Translation,"Imposing constraints on machine translation systems presents a challenging
issue because these systems are not trained to make use of constraints in
generating adequate, fluent translations. In this paper, we leverage the
capabilities of large language models (LLMs) for constrained translation, given
that LLMs can easily adapt to this task by taking translation instructions and
constraints as prompts. However, LLMs cannot always guarantee the adequacy of
translation, and, in some cases, ignore the given constraints. This is in part
because LLMs might be overly confident in their predictions, overriding the
influence of the constraints. To overcome this overiding behaviour, we propose
to add a revision process that encourages LLMs to correct the outputs by
prompting them about the constraints that have not yet been met. We evaluate
our approach on four constrained translation tasks, encompassing both lexical
and structural constraints in multiple constraint domains. Experiments show
15\% improvement in constraint-based translation accuracy over standard LLMs
and the approach also significantly outperforms neural machine translation
(NMT) state-of-the-art methods.",2024-07-18,"Pengcheng Huang, Yongyu Mu, Yuzhang Wu, Bei Li, Chunyang Xiao, Tong Xiao, Jingbo Zhu",http://arxiv.org/pdf/2407.13164v1,cs.CL
Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation Systems,"In recent years, there has been increased demand for speech-to-speech
translation (S2ST) systems in industry settings. Although successfully
commercialized, cloning-based S2ST systems expose their distributors to
liabilities when misused by individuals and can infringe on personality rights
when exploited by media organizations. This work proposes a regulated S2ST
framework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice
cloning in S2ST by first matching the input voice to a similar prior consenting
speaker voice in the target-language. With this separation, PVM avoids cloning
the input speaker, ensuring PVM systems comply with regulations and reduce risk
of misuse. Our results demonstrate PVM can significantly improve S2ST system
run-time in multi-speaker settings and the naturalness of S2ST synthesized
speech. To our knowledge, PVM is the first explicitly regulated S2ST framework
leveraging similarly-matched preset-voices for dynamic S2ST tasks.",2024-07-18,"Daniel Platnick, Bishoy Abdelnour, Eamon Earl, Rahul Kumar, Zahra Rezaei, Thomas Tsangaris, Faraj Lagum",http://arxiv.org/pdf/2407.13153v1,cs.CL
A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR,"Punctuation and word casing prediction are necessary for automatic speech
recognition (ASR). With the popularity of on-device end-to-end streaming ASR
systems, the on-device punctuation and word casing prediction become a
necessity while we found little discussion on this. With the emergence of
Transformer, Transformer based models have been explored for this scenario.
However, Transformer based models are too large for on-device ASR systems. In
this paper, we propose a light-weight and efficient model that jointly predicts
punctuation and word casing in real time. The model is based on Convolutional
Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).
Experimental results on the IWSLT2011 test set show that the proposed model
obtains 9% relative improvement compared to the best of non-Transformer models
on overall F1-score. Compared to the representative of Transformer based
models, the proposed model achieves comparable results to the representative
model while being only one-fortieth its size and 2.5 times faster in terms of
inference time. It is suitable for on-device streaming ASR systems. Our code is
publicly available.",2024-07-18,"Jian You, Xiangfeng Li",http://arxiv.org/pdf/2407.13142v1,cs.CL
TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep & Cross Network and Large Language Models,"Clinical trials need to recruit a sufficient number of volunteer patients to
demonstrate the statistical power of the treatment (e.g., a new drug) in curing
a certain disease. Clinical trial recruitment has a significant impact on trial
success. Forecasting whether the recruitment process would be successful before
we run the trial would save many resources and time. This paper develops a
novel deep & cross network with large language model (LLM)-augmented text
feature that learns semantic information from trial eligibility criteria and
predicts enrollment success. The proposed method enables interpretability by
understanding which sentence/word in eligibility criteria contributes heavily
to prediction. We also demonstrate the empirical superiority of the proposed
method (0.7002 PR-AUC) over a bunch of well-established machine learning
methods. The code and curated dataset are publicly available at
https://anonymous.4open.science/r/TrialEnroll-7E12.",2024-07-18,"Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu",http://arxiv.org/pdf/2407.13115v1,cs.CL
"Retrieve, Summarize, Plan: Advancing Multi-hop Question Answering with an Iterative Approach","Multi-hop question answering is a challenging task with distinct industrial
relevance, and Retrieval-Augmented Generation (RAG) methods based on large
language models (LLMs) have become a popular approach to tackle this task.
Owing to the potential inability to retrieve all necessary information in a
single iteration, a series of iterative RAG methods has been recently
developed, showing significant performance improvements. However, existing
methods still face two critical challenges: context overload resulting from
multiple rounds of retrieval, and over-planning and repetitive planning due to
the lack of a recorded retrieval trajectory. In this paper, we propose a novel
iterative RAG method called ReSP, equipped with a dual-function summarizer.
This summarizer compresses information from retrieved documents, targeting both
the overarching question and the current sub-question concurrently.
Experimental results on the multi-hop question-answering datasets HotpotQA and
2WikiMultihopQA demonstrate that our method significantly outperforms the
state-of-the-art, and exhibits excellent robustness concerning context length.",2024-07-18,"Zhouyu Jiang, Mengshu Sun, Lei Liang, Zhiqiang Zhang",http://arxiv.org/pdf/2407.13101v2,cs.CL
AlcLaM: Arabic Dialectal Language Model,"Pre-trained Language Models (PLMs) are integral to many modern natural
language processing (NLP) systems. Although multilingual models cover a wide
range of languages, they often grapple with challenges like high inference
costs and a lack of diverse non-English training data. Arabic-specific PLMs are
trained predominantly on modern standard Arabic, which compromises their
performance on regional dialects. To tackle this, we construct an Arabic
dialectal corpus comprising 3.4M sentences gathered from social media
platforms. We utilize this corpus to expand the vocabulary and retrain a
BERT-based model from scratch. Named AlcLaM, our model was trained using only
13 GB of text, which represents a fraction of the data used by existing models
such as CAMeL, MARBERT, and ArBERT, compared to 7.8%, 10.2%, and 21.3%,
respectively. Remarkably, AlcLaM demonstrates superior performance on a variety
of Arabic NLP tasks despite the limited training data. AlcLaM is available at
GitHub https://github.com/amurtadha/Alclam and HuggingFace
https://huggingface.co/rahbi.",2024-07-18,"Murtadha Ahmed, Saghir Alfasly, Bo Wen, Jamaal Qasem, Mohammed Ahmed, Yunfeng Liu",http://arxiv.org/pdf/2407.13097v1,cs.CL
MetaSumPerceiver: Multimodal Multi-Document Evidence Summarization for Fact-Checking,"Fact-checking real-world claims often requires reviewing multiple multimodal
documents to assess a claim's truthfulness, which is a highly laborious and
time-consuming task. In this paper, we present a summarization model designed
to generate claim-specific summaries useful for fact-checking from multimodal,
multi-document datasets. The model takes inputs in the form of documents,
images, and a claim, with the objective of assisting in fact-checking tasks. We
introduce a dynamic perceiver-based model that can handle inputs from multiple
modalities of arbitrary lengths. To train our model, we leverage a novel
reinforcement learning-based entailment objective to generate summaries that
provide evidence distinguishing between different truthfulness labels. To
assess the efficacy of our approach, we conduct experiments on both an existing
benchmark and a new dataset of multi-document claims that we contribute. Our
approach outperforms the SOTA approach by 4.6% in the claim verification task
on the MOCHEG dataset and demonstrates strong performance on our new
Multi-News-Fact-Checking dataset.",2024-07-18,"Ting-Chih Chen, Chia-Wei Tang, Chris Thomas",http://arxiv.org/pdf/2407.13089v2,cs.CL
Dynamic Sentiment Analysis with Local Large Language Models using Majority Voting: A Study on Factors Affecting Restaurant Evaluation,"User-generated contents (UGCs) on online platforms allow marketing
researchers to understand consumer preferences for products and services. With
the advance of large language models (LLMs), some studies utilized the models
for annotation and sentiment analysis. However, the relationship between the
accuracy and the hyper-parameters of LLMs is yet to be thoroughly examined. In
addition, the issues of variability and reproducibility of results from each
trial of LLMs have rarely been considered in existing literature. Since actual
human annotation uses majority voting to resolve disagreements among
annotators, this study introduces a majority voting mechanism to a sentiment
analysis model using local LLMs. By a series of three analyses of online
reviews on restaurant evaluations, we demonstrate that majority voting with
multiple attempts using a medium-sized model produces more robust results than
using a large model with a single attempt. Furthermore, we conducted further
analysis to investigate the effect of each aspect on the overall evaluation.",2024-07-18,Junichiro Niimi,http://arxiv.org/pdf/2407.13069v1,cs.CL
Establishing Knowledge Preference in Language Models,"Language models are known to encode a great amount of factual knowledge
through pretraining. However, such knowledge might be insufficient to cater to
user requests, requiring the model to integrate external knowledge sources and
adhere to user-provided specifications. When answering questions about ongoing
events, the model should use recent news articles to update its response; when
asked to provide recommendations, the model should prioritize user
specifications over retrieved product reviews; when some facts are edited in
the model, the updated facts should override all prior knowledge learned by the
model even if they are conflicting. In all of the cases above, the model faces
a decision between its own parametric knowledge, (retrieved) contextual
knowledge, and user instruction knowledge. In this paper, we (1) unify such
settings into the problem of knowledge preference and define a three-level
preference hierarchy over these knowledge sources; (2) compile a collection of
existing datasets IfQA, MQuAKE, and MRQA covering a combination of settings
(with/without user specifications, with/without context documents) to
systematically evaluate how well models obey the intended knowledge preference;
and (3) propose a dataset synthesis method that composes diverse
question-answer pairs with user assumptions and related context to directly
fine-tune LMs for instilling the hierarchy of knowledge. We demonstrate that a
7B model, fine-tuned on only a few thousand examples automatically generated by
our proposed method, effectively achieves superior performance (more than 18%
improvement across all evaluation benchmarks) in adhering to the desired
knowledge preference hierarchy.",2024-07-17,"Sizhe Zhou, Sha Li, Yu Meng, Yizhu Jiao, Heng Ji, Jiawei Han",http://arxiv.org/pdf/2407.13048v1,cs.CL
Steamroller Problems: An Evaluation of LLM Reasoning Capability with Automated Theorem Prover Strategies,"This study presents the first examination of the ability of Large Language
Models (LLMs) to follow reasoning strategies that are used to guide Automated
Theorem Provers (ATPs). We evaluate the performance of GPT4, GPT3.5 Turbo and
Google's recent Gemini model on problems from a steamroller domain. In addition
to determining accuracy we make use of the Natural Language Processing library
spaCy to explore new methods of investigating LLM's reasoning capabilities.
This led to one alarming result, the low correlation between correct reasoning
and correct answers for any of the tested models. We found that the models'
performance when using the ATP reasoning strategies was comparable to one-shot
chain of thought and observe that attention to uncertainty in the accuracy
results is critical when drawing conclusions about model performance.
Consistent with previous speculation we confirm that LLMs have a preference
for, and are best able to follow, bottom up reasoning processes. However, the
reasoning strategies can still be beneficial for deriving small and relevant
sets of formulas for external processing by a trusted inference engine.",2024-07-17,"Lachlan McGinness, Peter Baumgartner",http://arxiv.org/pdf/2407.20244v1,cs.CL
Turkish Delights: a Dataset on Turkish Euphemisms,"Euphemisms are a form of figurative language relatively understudied in
natural language processing. This research extends the current computational
work on potentially euphemistic terms (PETs) to Turkish. We introduce the
Turkish PET dataset, the first available of its kind in the field. By creating
a list of euphemisms in Turkish, collecting example contexts, and annotating
them, we provide both euphemistic and non-euphemistic examples of PETs in
Turkish. We describe the dataset and methodologies, and also experiment with
transformer-based models on Turkish euphemism detection by using our dataset
for binary classification. We compare performances across models using F1,
accuracy, and precision as evaluation metrics.",2024-07-17,"Hasan Can Biyik, Patrick Lee, Anna Feldman",http://arxiv.org/pdf/2407.13040v1,cs.CL
Pre-Trained Foundation Model representations to uncover Breathing patterns in Speech,"The process of human speech production involves coordinated respiratory
action to elicit acoustic speech signals. Typically, speech is produced when
air is forced from the lungs and is modulated by the vocal tract, where such
actions are interspersed by moments of breathing in air (inhalation) to refill
the lungs again. Respiratory rate (RR) is a vital metric that is used to assess
the overall health, fitness, and general well-being of an individual. Existing
approaches to measure RR (number of breaths one takes in a minute) are
performed using specialized equipment or training. Studies have demonstrated
that machine learning algorithms can be used to estimate RR using bio-sensor
signals as input. Speech-based estimation of RR can offer an effective approach
to measure the vital metric without requiring any specialized equipment or
sensors. This work investigates a machine learning based approach to estimate
RR from speech segments obtained from subjects speaking to a close-talking
microphone device. Data were collected from N=26 individuals, where the
groundtruth RR was obtained through commercial grade chest-belts and then
manually corrected for any errors. A convolutional long-short term memory
network (Conv-LSTM) is proposed to estimate respiration time-series data from
the speech signal. We demonstrate that the use of pre-trained representations
obtained from a foundation model, such as Wav2Vec2, can be used to estimate
respiration-time-series with low root-mean-squared error and high correlation
coefficient, when compared with the baseline. The model-driven time series can
be used to estimate $RR$ with a low mean absolute error (MAE) ~ 1.6
breaths/min.",2024-07-17,"Vikramjit Mitra, Anirban Chatterjee, Ke Zhai, Helen Weng, Ayuko Hill, Nicole Hay, Christopher Webb, Jamie Cheng, Erdrin Azemi",http://arxiv.org/pdf/2407.13035v1,cs.CL
A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks,"Large language models (LLMs) have shown remarkable performance on many
different Natural Language Processing (NLP) tasks. Prompt engineering plays a
key role in adding more to the already existing abilities of LLMs to achieve
significant performance gains on various NLP tasks. Prompt engineering requires
composing natural language instructions called prompts to elicit knowledge from
LLMs in a structured way. Unlike previous state-of-the-art (SoTA) models,
prompt engineering does not require extensive parameter re-training or
fine-tuning based on the given NLP task and thus solely operates on the
embedded knowledge of LLMs. Additionally, LLM enthusiasts can intelligently
extract LLMs' knowledge through a basic natural language conversational
exchange or prompt engineering, allowing more and more people even without deep
mathematical machine learning background to experiment with LLMs. With prompt
engineering gaining popularity in the last two years, researchers have come up
with numerous engineering techniques around designing prompts to improve
accuracy of information extraction from the LLMs. In this paper, we summarize
different prompting techniques and club them together based on different NLP
tasks that they have been used for. We further granularly highlight the
performance of these prompting strategies on various datasets belonging to that
NLP task, talk about the corresponding LLMs used, present a taxonomy diagram
and discuss the possible SoTA for specific datasets. In total, we read and
present a survey of 44 research papers which talk about 39 different prompting
methods on 29 different NLP tasks of which most of them have been published in
the last two years.",2024-07-17,"Shubham Vatsal, Harsh Dubey",http://arxiv.org/pdf/2407.12994v2,cs.CL
Retrieval-Enhanced Machine Learning: Synthesis and Opportunities,"In the field of language modeling, models augmented with retrieval components
have emerged as a promising solution to address several challenges faced in the
natural language processing (NLP) field, including knowledge grounding,
interpretability, and scalability. Despite the primary focus on NLP, we posit
that the paradigm of retrieval-enhancement can be extended to a broader
spectrum of machine learning (ML) such as computer vision, time series
prediction, and computational biology. Therefore, this work introduces a formal
framework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by
synthesizing the literature in various domains in ML with consistent notations
which is missing from the current literature. Also, we found that while a
number of studies employ retrieval components to augment their models, there is
a lack of integration with foundational Information Retrieval (IR) research. We
bridge this gap between the seminal IR research and contemporary REML studies
by investigating each component that comprises the REML framework. Ultimately,
the goal of this work is to equip researchers across various disciplines with a
comprehensive, formally structured framework of retrieval-enhanced models,
thereby fostering interdisciplinary future research.",2024-07-17,"To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani",http://arxiv.org/pdf/2407.12982v2,cs.CL
Less is More: Sparse Watermarking in LLMs with Enhanced Text Quality,"With the widespread adoption of Large Language Models (LLMs), concerns about
potential misuse have emerged. To this end, watermarking has been adapted to
LLM, enabling a simple and effective way to detect and monitor generated text.
However, while the existing methods can differentiate between watermarked and
unwatermarked text with high accuracy, they often face a trade-off between the
quality of the generated text and the effectiveness of the watermarking
process. In this work, we present a novel type of LLM watermark, Sparse
Watermark, which aims to mitigate this trade-off by applying watermarks to a
small subset of generated tokens distributed across the text. The key strategy
involves anchoring watermarked tokens to words that have specific
Part-of-Speech (POS) tags. Our experimental results demonstrate that the
proposed watermarking scheme achieves high detectability while generating text
that outperforms previous LLM watermarking methods in quality across various
tasks",2024-07-17,"Duy C. Hoang, Hung T. Q. Le, Rui Chu, Ping Li, Weijie Zhao, Yingjie Lao, Khoa D. Doan",http://arxiv.org/pdf/2407.13803v1,cs.CL
Halu-J: Critique-Based Hallucination Judge,"Large language models (LLMs) frequently generate non-factual content, known
as hallucinations. Existing retrieval-augmented-based hallucination detection
approaches typically address this by framing it as a classification task,
evaluating hallucinations based on their consistency with retrieved evidence.
However, this approach usually lacks detailed explanations for these
evaluations and does not assess the reliability of these explanations.
Furthermore, deficiencies in retrieval systems can lead to irrelevant or
partially relevant evidence retrieval, impairing the detection process.
Moreover, while real-world hallucination detection requires analyzing multiple
pieces of evidence, current systems usually treat all evidence uniformly
without considering its relevance to the content. To address these challenges,
we introduce Halu-J, a critique-based hallucination judge with 7 billion
parameters. Halu-J enhances hallucination detection by selecting pertinent
evidence and providing detailed critiques. Our experiments indicate that Halu-J
outperforms GPT-4o in multiple-evidence hallucination detection and matches its
capability in critique generation and evidence selection. We also introduce
ME-FEVER, a new dataset designed for multiple-evidence hallucination detection.
Our code and dataset can be found in https://github.com/GAIR-NLP/factool .",2024-07-17,"Binjie Wang, Steffi Chern, Ethan Chern, Pengfei Liu",http://arxiv.org/pdf/2407.12943v1,cs.CL
Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions,"Embeddings from Large Language Models (LLMs) have emerged as critical
components in various applications, particularly for information retrieval.
While high-dimensional embeddings generally demonstrate superior performance as
they contain more salient information, their practical application is
frequently hindered by elevated computational latency and the associated higher
cost. To address these challenges, we propose Matryoshka-Adaptor, a novel
tuning framework designed for the customization of LLM embeddings.
Matryoshka-Adaptor facilitates substantial dimensionality reduction while
maintaining comparable performance levels, thereby achieving a significant
enhancement in computational efficiency and cost-effectiveness. Our framework
directly modifies the embeddings from pre-trained LLMs which is designed to be
seamlessly integrated with any LLM architecture, encompassing those accessible
exclusively through black-box APIs. Also, it exhibits efficacy in both
unsupervised and supervised learning settings. A rigorous evaluation conducted
across a diverse corpus of English, multilingual, and multimodal datasets
consistently reveals substantial gains with Matryoshka-Adaptor. Notably, with
Google and OpenAI Embedding APIs, Matryoshka-Adaptor achieves a reduction in
dimensionality ranging from two- to twelve-fold without compromising
performance across multiple BEIR datasets.",2024-07-17,"Jinsung Yoon, Raj Sinha, Sercan O Arik, Tomas Pfister",http://arxiv.org/pdf/2407.20243v1,cs.CL
LMMs-Eval: Reality Check on the Evaluation of Large Multimodal Models,"The advances of large foundation models necessitate wide-coverage, low-cost,
and zero-contamination benchmarks. Despite continuous exploration of language
model evaluations, comprehensive studies on the evaluation of Large Multi-modal
Models (LMMs) remain limited. In this work, we introduce LMMS-EVAL, a unified
and standardized multimodal benchmark framework with over 50 tasks and more
than 10 models to promote transparent and reproducible evaluations. Although
LMMS-EVAL offers comprehensive coverage, we find it still falls short in
achieving low cost and zero contamination. To approach this evaluation
trilemma, we further introduce LMMS-EVAL LITE, a pruned evaluation toolkit that
emphasizes both coverage and efficiency. Additionally, we present Multimodal
LIVEBENCH that utilizes continuously updating news and online forums to assess
models' generalization abilities in the wild, featuring a low-cost and
zero-contamination evaluation approach. In summary, our work highlights the
importance of considering the evaluation trilemma and provides practical
solutions to navigate the trade-offs in evaluating large multi-modal models,
paving the way for more effective and reliable benchmarking of LMMs. We
opensource our codebase and maintain leaderboard of LIVEBENCH at
https://github.com/EvolvingLMMs-Lab/lmms-eval and
https://huggingface.co/spaces/lmms-lab/LiveBench.",2024-07-17,"Kaichen Zhang, Bo Li, Peiyuan Zhang, Fanyi Pu, Joshua Adrian Cahyono, Kairui Hu, Shuai Liu, Yuanhan Zhang, Jingkang Yang, Chunyuan Li, Ziwei Liu",http://arxiv.org/pdf/2407.12772v2,cs.CL
The Role of Network and Identity in the Diffusion of Hashtags,"The diffusion of culture online is theorized to be influenced by many
interacting social factors (e.g., network and identity). However, most existing
computational cascade models consider just a single factor (e.g., network or
identity). This work offers a new framework for teasing apart the mechanisms
underlying hashtag cascades. We curate a new dataset of 1,337 hashtags
representing cultural innovation online, develop a 10-factor evaluation
framework for comparing empirical and simulated cascades, and show that a
combined network+identity model better simulates hashtag cascades than network-
or identity-only counterfactuals. We also explore heterogeneity in performance:
While a combined network+identity model best predicts the popularity of
cascades, a network-only model best predicts cascade growth and an
identity-only model best predicts adopter composition. The network+identity
model has the highest comparative advantage among hashtags used for expressing
racial or regional identity and talking about sports or news. In fact, we are
able to predict what combination of network and/or identity best models each
hashtag and use this to further improve performance. Our results show the
utility of models incorporating the interactions of network, identity, and
other social factors in the diffusion of hashtags in social media.",2024-07-17,"Aparna Ananthasubramaniam, Yufei 'Louise' Zhu, David Jurgens, Daniel Romero",http://arxiv.org/pdf/2407.12771v2,cs.CL
HDLCopilot: Natural Language Exploration of Hardware Designs and Libraries,"Hardware design workflows often involve working with Process Design Kits
(PDKs) from various fabrication labs, each containing its own set of standard
cell libraries optimized for metrics such as speed, power, or density. These
libraries include multiple views for information on timing and electrical
properties of cells, cell layout details, and process design rules. Engineers
typically navigate between the design and the target technology to make
informed decisions on different design scenarios, such as selecting specific
gates for area optimization or enhancing critical path speed. Navigating this
complex landscape to retrieve specific information about gates or design rules
is often time-consuming and error-prone. To address this, we present
HDLCopilot, a multi-agent collaborative framework powered by large language
models that enables engineers to streamline interactions with hardware design
and PDKs through natural language queries. HDLCopilot enables engineers to
quickly access relevant information on gates and design rules, evaluate
tradeoffs related to area, speed, and power in order to make informed decisions
efficiently and accurately. The framework achieves an execution accuracy of
96.33\% on a diverse set of complex natural language queries. HDLCopilot
positions itself as a powerful assistant in hardware design workflows,
enhancing productivity and reducing potential human errors.",2024-07-17,"Manar Abdelatty, Jacob Rosenstein, Sherief Reda",http://arxiv.org/pdf/2407.12749v2,cs.CL
A LLM Benchmark based on the Minecraft Builder Dialog Agent Task,"In this work we proposing adapting the Minecraft builder task into an LLM
benchmark suitable for evaluating LLM ability in spatially orientated tasks,
and informing builder agent design. Previous works have proposed corpora with
varying complex structures, and human written instructions. We instead attempt
to provide a comprehensive synthetic benchmark for testing builder agents over
a series of distinct tasks that comprise of common building operations. We
believe this approach allows us to probe specific strengths and weaknesses of
different agents, and test the ability of LLMs in the challenging area of
spatial reasoning and vector based math.",2024-07-17,"Chris Madge, Massimo Poesio",http://arxiv.org/pdf/2407.12734v1,cs.CL
Is Sarcasm Detection A Step-by-Step Reasoning Process in Large Language Models?,"Elaborating a series of intermediate reasoning steps significantly improves
the ability of large language models (LLMs) to solve complex problems, as such
steps would evoke LLMs to think sequentially. However, human sarcasm
understanding is often considered an intuitive and holistic cognitive process,
in which various linguistic, contextual, and emotional cues are integrated to
form a comprehensive understanding, in a way that does not necessarily follow a
step-by-step fashion. To verify the validity of this argument, we introduce a
new prompting framework (called SarcasmCue) containing four sub-methods, viz.
chain of contradiction (CoC), graph of cues (GoC), bagging of cues (BoC) and
tensor of cues (ToC), which elicits LLMs to detect human sarcasm by considering
sequential and non-sequential prompting methods. Through a comprehensive
empirical comparison on four benchmarks, we highlight three key findings: (1)
CoC and GoC show superior performance with more advanced models like GPT-4 and
Claude 3.5, with an improvement of 3.5%. (2) ToC significantly outperforms
other methods when smaller LLMs are evaluated, boosting the F1 score by 29.7%
over the best baseline. (3) Our proposed framework consistently pushes the
state-of-the-art (i.e., ToT) by 4.2%, 2.0%, 29.7%, and 58.2% in F1 scores
across four datasets. This demonstrates the effectiveness and stability of the
proposed framework.",2024-07-17,"Ben Yao, Yazhou Zhang, Qiuchi Li, Jing Qin",http://arxiv.org/pdf/2407.12725v2,cs.CL
TTSDS -- Text-to-Speech Distribution Score,"Many recently published Text-to-Speech (TTS) systems produce audio close to
real speech. However, TTS evaluation needs to be revisited to make sense of the
results obtained with the new architectures, approaches and datasets. We
propose evaluating the quality of synthetic speech as a combination of multiple
factors such as prosody, speaker identity, and intelligibility. Our approach
assesses how well synthetic speech mirrors real speech by obtaining correlates
of each factor and measuring their distance from both real speech datasets and
noise datasets. We benchmark 35 TTS systems developed between 2008 and 2024 and
show that our score computed as an unweighted average of factors strongly
correlates with the human evaluations from each time period.",2024-07-17,"Christoph Minixhofer, Ondřej Klejch, Peter Bell",http://arxiv.org/pdf/2407.12707v3,cs.CL
Subgraph-Aware Training of Language Models for Knowledge Graph Completion Using Structure-Aware Contrastive Learning,"Fine-tuning pre-trained language models (PLMs) has recently shown a potential
to improve knowledge graph completion (KGC). However, most PLM-based methods
focus solely on encoding textual information, neglecting the long-tailed nature
of knowledge graphs and their various topological structures, e.g., subgraphs,
shortest paths, and degrees. We claim that this is a major obstacle to
achieving higher accuracy of PLMs for KGC. To this end, we propose a
Subgraph-Aware Training framework for KGC (SATKGC) with two ideas: (i)
subgraph-aware mini-batching to encourage hard negative sampling and to
mitigate an imbalance in the frequency of entity occurrences during training,
and (ii) new contrastive learning to focus more on harder in-batch negative
triples and harder positive triples in terms of the structural properties of
the knowledge graph. To the best of our knowledge, this is the first study to
comprehensively incorporate the structural inductive bias of the knowledge
graph into fine-tuning PLMs. Extensive experiments on three KGC benchmarks
demonstrate the superiority of SATKGC. Our code is available.",2024-07-17,"Youmin Ko, Hyemin Yang, Taeuk Kim, Hyunjoon Kim",http://arxiv.org/pdf/2407.12703v5,cs.CL
Beyond Next Token Prediction: Patch-Level Training for Large Language Models,"The prohibitive training costs of Large Language Models (LLMs) have emerged
as a significant bottleneck in the development of next-generation LLMs. In this
paper, we show that it is possible to significantly reduce the training costs
of LLMs without sacrificing their performance. Specifically, we introduce
patch-level training for LLMs, in which multiple tokens are aggregated into a
unit of higher information density, referred to as a `patch', to serve as the
fundamental text unit for training LLMs. During patch-level training, we feed
the language model shorter sequences of patches and train it to predict the
next patch, thereby processing the majority of the training data at a
significantly reduced cost. Following this, the model continues token-level
training on the remaining training data to align with the inference mode.
Experiments on a diverse range of models (370M-2.7B parameters) demonstrate
that patch-level training can reduce the overall training costs to 0.5$\times$,
without compromising the model performance compared to token-level training.
Source code: https://github.com/shaochenze/PatchTrain.",2024-07-17,"Chenze Shao, Fandong Meng, Jie Zhou",http://arxiv.org/pdf/2407.12665v3,cs.CL
Domain-specific or Uncertainty-aware models: Does it really make a difference for biomedical text classification?,"The success of pretrained language models (PLMs) across a spate of use-cases
has led to significant investment from the NLP community towards building
domain-specific foundational models. On the other hand, in mission critical
settings such as biomedical applications, other aspects also factor in-chief of
which is a model's ability to produce reasonable estimates of its own
uncertainty. In the present study, we discuss these two desiderata through the
lens of how they shape the entropy of a model's output probability
distribution. We find that domain specificity and uncertainty awareness can
often be successfully combined, but the exact task at hand weighs in much more
strongly.",2024-07-17,"Aman Sinha, Timothee Mickus, Marianne Clausel, Mathieu Constant, Xavier Coubez",http://arxiv.org/pdf/2407.12626v1,cs.CL
Harnessing the Power of Artificial Intelligence to Vitalize Endangered Indigenous Languages: Technologies and Experiences,"Since 2022 we have been exploring application areas and technologies in which
Artificial Intelligence (AI) and modern Natural Language Processing (NLP), such
as Large Language Models (LLMs), can be employed to foster the usage and
facilitate the documentation of Indigenous languages which are in danger of
disappearing. We start by discussing the decreasing diversity of languages in
the world and how working with Indigenous languages poses unique ethical
challenges for AI and NLP. To address those challenges, we propose an
alternative development AI cycle based on community engagement and usage. Then,
we report encouraging results in the development of high-quality machine
learning translators for Indigenous languages by fine-tuning state-of-the-art
(SOTA) translators with tiny amounts of data and discuss how to avoid some
common pitfalls in the process. We also present prototypes we have built in
projects done in 2023 and 2024 with Indigenous communities in Brazil, aimed at
facilitating writing, and discuss the development of Indigenous Language Models
(ILMs) as a replicable and scalable way to create spell-checkers, next-word
predictors, and similar tools. Finally, we discuss how we envision a future for
language documentation where dying languages are preserved as interactive
language models.",2024-07-17,"Claudio Pinhanez, Paulo Cavalin, Luciana Storto, Thomas Finbow, Alexander Cobbinah, Julio Nogima, Marisa Vasconcelos, Pedro Domingues, Priscila de Souza Mizukami, Nicole Grell, Majoí Gongora, Isabel Gonçalves",http://arxiv.org/pdf/2407.12620v2,cs.CL
AudienceView: AI-Assisted Interpretation of Audience Feedback in Journalism,"Understanding and making use of audience feedback is important but difficult
for journalists, who now face an impractically large volume of audience
comments online. We introduce AudienceView, an online tool to help journalists
categorize and interpret this feedback by leveraging large language models
(LLMs). AudienceView identifies themes and topics, connects them back to
specific comments, provides ways to visualize the sentiment and distribution of
the comments, and helps users develop ideas for subsequent reporting projects.
We consider how such tools can be useful in a journalist's workflow, and
emphasize the importance of contextual awareness and human judgment.",2024-07-17,"William Brannon, Doug Beeferman, Hang Jiang, Andrew Heyward, Deb Roy",http://arxiv.org/pdf/2407.12613v1,cs.CL
E5-V: Universal Embeddings with Multimodal Large Language Models,"Multimodal large language models (MLLMs) have shown promising advancements in
general visual and language understanding. However, the representation of
multimodal information using MLLMs remains largely unexplored. In this work, we
introduce a new framework, E5-V, designed to adapt MLLMs for achieving
universal multimodal embeddings. Our findings highlight the significant
potential of MLLMs in representing multimodal inputs compared to previous
approaches. By leveraging MLLMs with prompts, E5-V effectively bridges the
modality gap between different types of inputs, demonstrating strong
performance in multimodal embeddings even without fine-tuning. We propose a
single modality training approach for E5-V, where the model is trained
exclusively on text pairs. This method demonstrates significant improvements
over traditional multimodal training on image-text pairs, while reducing
training costs by approximately 95%. Additionally, this approach eliminates the
need for costly multimodal training data collection. Extensive experiments
across four types of tasks demonstrate the effectiveness of E5-V. As a
universal multimodal model, E5-V not only achieves but often surpasses
state-of-the-art performance in each task, despite being trained on a single
modality.",2024-07-17,"Ting Jiang, Minghui Song, Zihan Zhang, Haizhen Huang, Weiwei Deng, Feng Sun, Qi Zhang, Deqing Wang, Fuzhen Zhuang",http://arxiv.org/pdf/2407.12580v1,cs.CL
Abstraction Alignment: Comparing Model-Learned and Human-Encoded Conceptual Relationships,"While interpretability methods identify a model's learned concepts, they
overlook the relationships between concepts that make up its abstractions and
inform its ability to generalize to new data. To assess whether models' have
learned human-aligned abstractions, we introduce abstraction alignment, a
methodology to compare model behavior against formal human knowledge.
Abstraction alignment externalizes domain-specific human knowledge as an
abstraction graph, a set of pertinent concepts spanning levels of abstraction.
Using the abstraction graph as a ground truth, abstraction alignment measures
the alignment of a model's behavior by determining how much of its uncertainty
is accounted for by the human abstractions. By aggregating abstraction
alignment across entire datasets, users can test alignment hypotheses, such as
which human concepts the model has learned and where misalignments recur. In
evaluations with experts, abstraction alignment differentiates seemingly
similar errors, improves the verbosity of existing model-quality metrics, and
uncovers improvements to current human abstractions.",2024-07-17,"Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan",http://arxiv.org/pdf/2407.12543v2,cs.CL
Towards Collaborative Intelligence: Propagating Intentions and Reasoning for Multi-Agent Coordination with Large Language Models,"Effective collaboration in multi-agent systems requires communicating goals
and intentions between agents. Current agent frameworks often suffer from
dependencies on single-agent execution and lack robust inter-module
communication, frequently leading to suboptimal multi-agent reinforcement
learning (MARL) policies and inadequate task coordination. To address these
challenges, we present a framework for training large language models (LLMs) as
collaborative agents to enable coordinated behaviors in cooperative MARL. Each
agent maintains a private intention consisting of its current goal and
associated sub-tasks. Agents broadcast their intentions periodically, allowing
other agents to infer coordination tasks. A propagation network transforms
broadcast intentions into teammate-specific communication messages, sharing
relevant goals with designated teammates. The architecture of our framework is
structured into planning, grounding, and execution modules. During execution,
multiple agents interact in a downstream environment and communicate intentions
to enable coordinated behaviors. The grounding module dynamically adapts
comprehension strategies based on emerging coordination patterns, while
feedback from execution agents influnces the planning module, enabling the
dynamic re-planning of sub-tasks. Results in collaborative environment
simulation demonstrate intention propagation reduces miscoordination errors by
aligning sub-task dependencies between agents. Agents learn when to communicate
intentions and which teammates require task details, resulting in emergent
coordinated behaviors. This demonstrates the efficacy of intention sharing for
cooperative multi-agent RL based on LLMs.",2024-07-17,"Xihe Qiu, Haoyu Wang, Xiaoyu Tan, Chao Qu, Yujie Xiong, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi",http://arxiv.org/pdf/2407.12532v1,cs.CL
Crafting the Path: Robust Query Rewriting for Information Retrieval,"Query rewriting aims to generate a new query that can complement the original
query to improve the information retrieval system. Recent studies on query
rewriting, such as query2doc, query2expand and querey2cot, rely on the internal
knowledge of Large Language Models (LLMs) to generate a relevant passage to add
information to the query. Nevertheless, the efficacy of these methodologies may
markedly decline in instances where the requisite knowledge is not encapsulated
within the model's intrinsic parameters. In this paper, we propose a novel
structured query rewriting method called Crafting the Path tailored for
retrieval systems. Crafting the Path involves a three-step process that crafts
query-related information necessary for finding the passages to be searched in
each step. Specifically, the Crafting the Path begins with Query Concept
Comprehension, proceeds to Query Type Identification, and finally conducts
Expected Answer Extraction. Experimental results show that our method
outperforms previous rewriting methods, especially in less familiar domains for
LLMs. We demonstrate that our method is less dependent on the internal
parameter knowledge of the model and generates queries with fewer factual
inaccuracies. Furthermore, we observe that \name{} demonstrates superior
performance in the retrieval-augmented generation scenarios.",2024-07-17,"Ingeol Baek, Jimin Lee, Joonho Yang, Hwanhee Lee",http://arxiv.org/pdf/2407.12529v2,cs.CL
Struct-X: Enhancing Large Language Models Reasoning with Structured Data,"Structured data, rich in logical and relational information, has the
potential to enhance the reasoning abilities of large language models (LLMs).
Still, its integration poses a challenge due to the risk of overwhelming LLMs
with excessive tokens and irrelevant context information. To address this, we
propose Struct-X, a novel framework that operates through five key phases:
``read-model-fill-reflect-reason'' efficiently enabling LLMs to utilize
structured data. It begins by encoding structured data into a topological space
using graph embeddings, followed by filling in missing entity information with
knowledge retrieval modules, and filtering out irrelevant tokens via a
self-supervised module. The final phase involves constructing a topological
network with selected tokens to further reduce the total token length for more
effective LLM inference. Additionally, Struct-X includes an Auxiliary Module
trained to generate prompts, aiding LLMs in analyzing structured data.
Extensive experiments on benchmarks, including the knowledge graph
question-answer task and the long document reading comprehension task, show
that Struct-X notably improves LLM reasoning, demonstrating the effectiveness
of structured data augmentation in improving LLM inference with complex input
context.",2024-07-17,"Xiaoyu Tan, Haoyu Wang, Xihe Qiu, Yuan Cheng, Yinghui Xu, Wei Chu, Yuan Qi",http://arxiv.org/pdf/2407.12522v1,cs.CL
On Initializing Transformers with Pre-trained Embeddings,"It has become common practice now to use random initialization schemes,
rather than the pre-trained embeddings, when training transformer based models
from scratch. Indeed, we find that pre-trained word embeddings from GloVe, and
some sub-word embeddings extracted from language models such as T5 and mT5 fare
much worse compared to random initialization. This is counter-intuitive given
the well-known representational and transfer-learning advantages of
pre-training. Interestingly, we also find that BERT and mBERT embeddings fare
better than random initialization, showing the advantages of pre-trained
representations. In this work, we posit two potential factors that contribute
to these mixed results: the model sensitivity to parameter distribution and the
embedding interactions with position encodings. We observe that pre-trained
GloVe, T5, and mT5 embeddings have a wider distribution of values. As argued in
the initialization studies, such large value initializations can lead to poor
training because of saturated outputs. Further, the larger embedding values
can, in effect, absorb the smaller position encoding values when added
together, thus losing position information. Standardizing the pre-trained
embeddings to a narrow range (e.g. as prescribed by Xavier) leads to
substantial gains for Glove, T5, and mT5 embeddings. On the other hand, BERT
pre-trained embeddings, while larger, are still relatively closer to Xavier
initialization range which may allow it to effectively transfer the pre-trained
knowledge.",2024-07-17,"Ha Young Kim, Niranjan Balasubramanian, Byungkon Kang",http://arxiv.org/pdf/2407.12514v1,cs.CL
$\textit{GeoHard}$: Towards Measuring Class-wise Hardness through Modelling Class Semantics,"Recent advances in measuring hardness-wise properties of data guide language
models in sample selection within low-resource scenarios. However,
class-specific properties are overlooked for task setup and learning. How will
these properties influence model learning and is it generalizable across
datasets? To answer this question, this work formally initiates the concept of
$\textit{class-wise hardness}$. Experiments across eight natural language
understanding (NLU) datasets demonstrate a consistent hardness distribution
across learning paradigms, models, and human judgment. Subsequent experiments
unveil a notable challenge in measuring such class-wise hardness with
instance-level metrics in previous works. To address this, we propose
$\textit{GeoHard}$ for class-wise hardness measurement by modeling class
geometry in the semantic embedding space. $\textit{GeoHard}$ surpasses
instance-level metrics by over 59 percent on $\textit{Pearson}$'s correlation
on measuring class-wise hardness. Our analysis theoretically and empirically
underscores the generality of $\textit{GeoHard}$ as a fresh perspective on data
diagnosis. Additionally, we showcase how understanding class-wise hardness can
practically aid in improving task learning.",2024-07-17,"Fengyu Cai, Xinran Zhao, Hongming Zhang, Iryna Gurevych, Heinz Koeppl",http://arxiv.org/pdf/2407.12512v1,cs.CL
MERLIN: Multimodal Embedding Refinement via LLM-based Iterative Navigation for Text-Video Retrieval-Rerank Pipeline,"The rapid expansion of multimedia content has made accurately retrieving
relevant videos from large collections increasingly challenging. Recent
advancements in text-video retrieval have focused on cross-modal interactions,
large-scale foundation model training, and probabilistic modeling, yet often
neglect the crucial user perspective, leading to discrepancies between user
queries and the content retrieved. To address this, we introduce MERLIN
(Multimodal Embedding Refinement via LLM-based Iterative Navigation), a novel,
training-free pipeline that leverages Large Language Models (LLMs) for
iterative feedback learning. MERLIN refines query embeddings from a user
perspective, enhancing alignment between queries and video content through a
dynamic question answering process. Experimental results on datasets like
MSR-VTT, MSVD, and ActivityNet demonstrate that MERLIN substantially improves
Recall@1, outperforming existing systems and confirming the benefits of
integrating LLMs into multimodal retrieval systems for more responsive and
context-aware multimedia retrieval.",2024-07-17,"Donghoon Han, Eunhwan Park, Gisang Lee, Adam Lee, Nojun Kwak",http://arxiv.org/pdf/2407.12508v2,cs.CL
Case2Code: Scalable Synthetic Data for Code Generation,"Large Language Models (LLMs) have shown outstanding breakthroughs in code
generation. Recent work improves code LLMs by training on synthetic data
generated by some powerful LLMs, which can be challenging to scale due to the
dependence on a teacher model and high generation costs. In this paper, we
focus on synthesizing code data at scale and propose a \textbf{Case2Code} task
by exploiting the expressiveness and correctness of programs.
\textbf{Case2Code} is an inductive inference task that aims to infer underlying
code implementations by observing input-output examples or program behaviors,
By incorporating LLMs to generate program inputs, and executing the program
with these inputs to obtain the program outputs, we can synthesize diverse and
high-quality \textbf{Case2Code} data at scale for training and evaluating code
LLMs. Experimental results show that case-to-code induction is challenging for
current representative LLMs if they are untrained. Models trained with
\textbf{Case2Code} improve performance not only on distribution case-to-code
induction but also on various coding-generation tasks, demonstrating the great
potential of large-scale synthetic data and inductive learning.",2024-07-17,"Yunfan Shao, Linyang Li, Yichuan Ma, Peiji Li, Demin Song, Qinyuan Cheng, Shimin Li, Xiaonan Li, Pengyu Wang, Qipeng Guo, Hang Yan, Xipeng Qiu, Xuanjing Huang, Dahua Lin",http://arxiv.org/pdf/2407.12504v2,cs.CL
Automate or Assist? The Role of Computational Models in Identifying Gendered Discourse in US Capital Trial Transcripts,"The language used by US courtroom actors in criminal trials has long been
studied for biases. However, systematic studies for bias in high-stakes court
trials have been difficult, due to the nuanced nature of bias and the legal
expertise required. Large language models offer the possibility to automate
annotation. But validating the computational approach requires both an
understanding of how automated methods fit in existing annotation workflows and
what they really offer. We present a case study of adding a computational model
to a complex and high-stakes problem: identifying gender-biased language in US
capital trials for women defendants. Our team of experienced death-penalty
lawyers and NLP technologists pursue a three-phase study: first annotating
manually, then training and evaluating computational models, and finally
comparing expert annotations to model predictions. Unlike many typical NLP
tasks, annotating for gender bias in months-long capital trials is complicated,
with many individual judgment calls. Contrary to standard arguments for
automation that are based on efficiency and scalability, legal experts find the
computational models most useful in providing opportunities to reflect on their
own bias in annotation and to build consensus on annotation rules. This
experience suggests that seeking to replace experts with computational models
for complex annotation is both unrealistic and undesirable. Rather,
computational models offer valuable opportunities to assist the legal experts
in annotation-based studies.",2024-07-17,"Andrea W Wen-Yi, Kathryn Adamson, Nathalie Greenfield, Rachel Goldberg, Sandra Babcock, David Mimno, Allison Koenecke",http://arxiv.org/pdf/2407.12500v2,cs.CL
Evaluating Linguistic Capabilities of Multimodal LLMs in the Lens of Few-Shot Learning,"The linguistic capabilities of Multimodal Large Language Models (MLLMs) are
critical for their effective application across diverse tasks. This study aims
to evaluate the performance of MLLMs on the VALSE benchmark, focusing on the
efficacy of few-shot In-Context Learning (ICL), and Chain-of-Thought (CoT)
prompting. We conducted a comprehensive assessment of state-of-the-art MLLMs,
varying in model size and pretraining datasets. The experimental results reveal
that ICL and CoT prompting significantly boost model performance, particularly
in tasks requiring complex reasoning and contextual understanding. Models
pretrained on captioning datasets show superior zero-shot performance, while
those trained on interleaved image-text data benefit from few-shot learning.
Our findings provide valuable insights into optimizing MLLMs for better
grounding of language in visual contexts, highlighting the importance of the
composition of pretraining data and the potential of few-shot learning
strategies to improve the reasoning abilities of MLLMs.",2024-07-17,"Mustafa Dogan, Ilker Kesen, Iacer Calixto, Aykut Erdem, Erkut Erdem",http://arxiv.org/pdf/2407.12498v1,cs.CL
Krutrim LLM: A Novel Tokenization Strategy for Multilingual Indic Languages with Petabyte-Scale Data Processing,"We present a novel approach to data preparation for developing multilingual
Indic large language model. Our meticulous data acquisition spans open-source
and proprietary sources, including Common Crawl, Indic books, news articles,
and Wikipedia, ensuring a diverse and rich linguistic representation. For each
Indic language, we design a custom preprocessing pipeline to effectively
eliminate redundant and low-quality text content. Additionally, we perform
deduplication on Common Crawl data to address the redundancy present in 70% of
the crawled web pages. This study focuses on developing high-quality data,
optimizing tokenization for our multilingual dataset for Indic large language
models with 3B and 7B parameters, engineered for superior performance in Indic
languages. We introduce a novel multilingual tokenizer training strategy,
demonstrating our custom-trained Indic tokenizer outperforms the
state-of-the-art OpenAI Tiktoken tokenizer, achieving a superior token-to-word
ratio for Indic languages.",2024-07-17,"Rahul Kumar, Shubham Kakde, Divyansh Rajput, Daud Ibrahim, Rishabh Nahata, Pidathala Sowjanya, Deepak Kumarr, Gautam Bhargava, Chandra Khatri",http://arxiv.org/pdf/2407.12481v2,cs.CL
A Novel Dependency Framework for Enhancing Discourse Data Analysis,"The development of different theories of discourse structure has led to the
establishment of discourse corpora based on these theories. However, the
existence of discourse corpora established on different theoretical bases
creates challenges when it comes to exploring them in a consistent and cohesive
way. This study has as its primary focus the conversion of PDTB annotations
into dependency structures. It employs refined BERT-based discourse parsers to
test the validity of the dependency data derived from the PDTB-style corpora in
English, Chinese, and several other languages. By converting both PDTB and RST
annotations for the same texts into dependencies, this study also applies
``dependency distance'' metrics to examine the correlation between RST
dependencies and PDTB dependencies in English. The results show that the PDTB
dependency data is valid and that there is a strong correlation between the two
types of dependency distance. This study presents a comprehensive approach for
analyzing and evaluating discourse corpora by employing discourse dependencies
to achieve unified analysis. By applying dependency representations, we can
extract data from PDTB, RST, and SDRT corpora in a coherent and unified manner.
Moreover, the cross-linguistic validation establishes the framework's
generalizability beyond English. The establishment of this comprehensive
dependency framework overcomes limitations of existing discourse corpora,
supporting a diverse range of algorithms and facilitating further studies in
computational discourse analysis and language sciences.",2024-07-17,"Kun Sun, Rong Wang",http://arxiv.org/pdf/2407.12473v1,cs.CL
Characterization of Political Polarized Users Attacked by Language Toxicity on Twitter,"Understanding the dynamics of language toxicity on social media is important
for us to investigate the propagation of misinformation and the development of
echo chambers for political scenarios such as U.S. presidential elections.
Recent research has used large-scale data to investigate the dynamics across
social media platforms. However, research on the toxicity dynamics is not
enough. This study aims to provide a first exploration of the potential
language toxicity flow among Left, Right and Center users. Specifically, we aim
to examine whether Left users were easier to be attacked by language toxicity.
In this study, more than 500M Twitter posts were examined. It was discovered
that Left users received much more toxic replies than Right and Center users.",2024-07-17,Wentao Xu,http://arxiv.org/pdf/2407.12471v2,cs.CL
Continual Learning for Temporal-Sensitive Question Answering,"In this study, we explore an emerging research area of Continual Learning for
Temporal Sensitive Question Answering (CLTSQA). Previous research has primarily
focused on Temporal Sensitive Question Answering (TSQA), often overlooking the
unpredictable nature of future events. In real-world applications, it's crucial
for models to continually acquire knowledge over time, rather than relying on a
static, complete dataset. Our paper investigates strategies that enable models
to adapt to the ever-evolving information landscape, thereby addressing the
challenges inherent in CLTSQA. To support our research, we first create a novel
dataset, divided into five subsets, designed specifically for various stages of
continual learning. We then propose a training framework for CLTSQA that
integrates temporal memory replay and temporal contrastive learning. Our
experimental results highlight two significant insights: First, the CLTSQA task
introduces unique challenges for existing models. Second, our proposed
framework effectively navigates these challenges, resulting in improved
performance.",2024-07-17,"Wanqi Yang, Yunqiu Xu, Yanda Li, Kunze Wang, Binbin Huang, Ling Chen",http://arxiv.org/pdf/2407.12470v1,cs.CL
"Across Platforms and Languages: Dutch Influencers and Legal Disclosures on Instagram, YouTube and TikTok","Content monetization on social media fuels a growing influencer economy.
Influencer marketing remains largely undisclosed or inappropriately disclosed
on social media. Non-disclosure issues have become a priority for national and
supranational authorities worldwide, who are starting to impose increasingly
harsher sanctions on them. This paper proposes a transparent methodology for
measuring whether and how influencers comply with disclosures based on legal
standards. We introduce a novel distinction between disclosures that are
legally sufficient (green) and legally insufficient (yellow). We apply this
methodology to an original dataset reflecting the content of 150 Dutch
influencers publicly registered with the Dutch Media Authority based on
recently introduced registration obligations. The dataset consists of 292,315
posts and is multi-language (English and Dutch) and cross-platform (Instagram,
YouTube and TikTok). We find that influencer marketing remains generally
underdisclosed on social media, and that bigger influencers are not necessarily
more compliant with disclosure standards.",2024-07-17,"Haoyang Gui, Thales Bertaglia, Catalina Goanta, Sybe de Vries, Gerasimos Spanakis",http://arxiv.org/pdf/2407.12451v2,cs.CL
Sharif-STR at SemEval-2024 Task 1: Transformer as a Regression Model for Fine-Grained Scoring of Textual Semantic Relations,"Semantic Textual Relatedness holds significant relevance in Natural Language
Processing, finding applications across various domains. Traditionally,
approaches to STR have relied on knowledge-based and statistical methods.
However, with the emergence of Large Language Models, there has been a paradigm
shift, ushering in new methodologies. In this paper, we delve into the
investigation of sentence-level STR within Track A (Supervised) by leveraging
fine-tuning techniques on the RoBERTa transformer. Our study focuses on
assessing the efficacy of this approach across different languages. Notably,
our findings indicate promising advancements in STR performance, particularly
in Latin languages. Specifically, our results demonstrate notable improvements
in English, achieving a correlation of 0.82 and securing a commendable 19th
rank. Similarly, in Spanish, we achieved a correlation of 0.67, securing the
15th position. However, our approach encounters challenges in languages like
Arabic, where we observed a correlation of only 0.38, resulting in a 20th rank.",2024-07-17,"Seyedeh Fatemeh Ebrahimi, Karim Akhavan Azari, Amirmasoud Iravani, Hadi Alizadeh, Zeinab Sadat Taghavi, Hossein Sameti",http://arxiv.org/pdf/2407.12426v1,cs.CL
Navigating the Noisy Crowd: Finding Key Information for Claim Verification,"Claim verification is a task that involves assessing the truthfulness of a
given claim based on multiple evidence pieces. Using large language models
(LLMs) for claim verification is a promising way. However, simply feeding all
the evidence pieces to an LLM and asking if the claim is factual does not yield
good results. The challenge lies in the noisy nature of both the evidence and
the claim: evidence passages typically contain irrelevant information, with the
key facts hidden within the context, while claims often convey multiple aspects
simultaneously. To navigate this ""noisy crowd"" of information, we propose EACon
(Evidence Abstraction and Claim Deconstruction), a framework designed to find
key information within evidence and verify each aspect of a claim separately.
EACon first finds keywords from the claim and employs fuzzy matching to select
relevant keywords for each raw evidence piece. These keywords serve as a guide
to extract and summarize critical information into abstracted evidence.
Subsequently, EACon deconstructs the original claim into subclaims, which are
then verified against both abstracted and raw evidence individually. We
evaluate EACon using two open-source LLMs on two challenging datasets. Results
demonstrate that EACon consistently and substantially improve LLMs' performance
in claim verification.",2024-07-17,"Haisong Gong, Huanhuan Ma, Qiang Liu, Shu Wu, Liang Wang",http://arxiv.org/pdf/2407.12425v1,cs.CL
TurkishMMLU: Measuring Massive Multitask Language Understanding in Turkish,"Multiple choice question answering tasks evaluate the reasoning,
comprehension, and mathematical abilities of Large Language Models (LLMs).
While existing benchmarks employ automatic translation for multilingual
evaluation, this approach is error-prone and potentially introduces culturally
biased questions, especially in social sciences. We introduce the first
multitask, multiple-choice Turkish QA benchmark, TurkishMMLU, to evaluate LLMs'
understanding of the Turkish language. TurkishMMLU includes over 10,000
questions, covering 9 different subjects from Turkish high-school education
curricula. These questions are written by curriculum experts, suitable for the
high-school curricula in Turkey, covering subjects ranging from natural
sciences and math questions to more culturally representative topics such as
Turkish Literature and the history of the Turkish Republic. We evaluate over 20
LLMs, including multilingual open-source (e.g., Gemma, Llama, MT5),
closed-source (GPT 4o, Claude, Gemini), and Turkish-adapted (e.g., Trendyol)
models. We provide an extensive evaluation, including zero-shot and few-shot
evaluation of LLMs, chain-of-thought reasoning, and question difficulty
analysis along with model performance. We provide an in-depth analysis of the
Turkish capabilities and limitations of current LLMs to provide insights for
future LLMs for the Turkish language. We publicly release our code for the
dataset and evaluation: https://github.com/ArdaYueksel/TurkishMMLU.",2024-07-17,"Arda Yüksel, Abdullatif Köksal, Lütfi Kerem Şenel, Anna Korhonen, Hinrich Schütze",http://arxiv.org/pdf/2407.12402v2,cs.CL
PersLLM: A Personified Training Approach for Large Language Models,"Large language models (LLMs) exhibit human-like intelligence, enabling them
to simulate human behavior and support various applications that require both
humanized communication and extensive knowledge reserves. Efforts are made to
personify LLMs with special training data or hand-crafted prompts, while
correspondingly faced with challenges such as insufficient data usage or rigid
behavior patterns. Consequently, personified LLMs fail to capture personified
knowledge or express persistent opinion. To fully unlock the potential of LLM
personification, we propose PersLLM, a framework for better data construction
and model tuning. For insufficient data usage, we incorporate strategies such
as Chain-of-Thought prompting and anti-induction, improving the quality of data
construction and capturing the personality experiences, knowledge, and thoughts
more comprehensively. For rigid behavior patterns, we design the tuning process
and introduce automated DPO to enhance the specificity and dynamism of the
models' personalities, which leads to a more natural opinion communication.
Both automated metrics and expert human evaluations demonstrate the
effectiveness of our approach. Case studies in human-machine interactions and
multi-agent systems further suggest potential application scenarios and future
directions for LLM personification.",2024-07-17,"Zheni Zeng, Jiayi Chen, Huimin Chen, Yukun Yan, Yuxuan Chen, Zhenghao Liu, Zhiyuan Liu, Maosong Sun",http://arxiv.org/pdf/2407.12393v5,cs.CL
Morphosyntactic Analysis for CHILDES,"Language development researchers are interested in comparing the process of
language learning across languages. Unfortunately, it has been difficult to
construct a consistent quantitative framework for such comparisons. However,
recent advances in AI (Artificial Intelligence) and ML (Machine Learning) are
providing new methods for ASR (automatic speech recognition) and NLP (natural
language processing) that can be brought to bear on this problem. Using the
Batchalign2 program (Liu et al., 2023), we have been transcribing and linking
data for the CHILDES database and have applied the UD (Universal Dependencies)
framework to provide a consistent and comparable morphosyntactic analysis for
27 languages. These new resources open possibilities for deeper crosslinguistic
study of language learning.",2024-07-17,"Houjun Liu, Brian MacWhinney",http://arxiv.org/pdf/2407.12389v1,cs.CL
Deep Learning-based Sentiment Analysis of Olympics Tweets,"Sentiment analysis (SA), is an approach of natural language processing (NLP)
for determining a text's emotional tone by analyzing subjective information
such as views, feelings, and attitudes toward specific topics, products,
services, events, or experiences. This study attempts to develop an advanced
deep learning (DL) model for SA to understand global audience emotions through
tweets in the context of the Olympic Games. The findings represent global
attitudes around the Olympics and contribute to advancing the SA models. We
have used NLP for tweet pre-processing and sophisticated DL models for arguing
with SA, this research enhances the reliability and accuracy of sentiment
classification. The study focuses on data selection, preprocessing,
visualization, feature extraction, and model building, featuring a baseline
Na\""ive Bayes (NB) model and three advanced DL models: Convolutional Neural
Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional
Encoder Representations from Transformers (BERT). The results of the
experiments show that the BERT model can efficiently classify sentiments
related to the Olympics, achieving the highest accuracy of 99.23%.",2024-07-17,"Indranil Bandyopadhyay, Rahul Karmakar",http://arxiv.org/pdf/2407.12376v1,cs.CL
NavGPT-2: Unleashing Navigational Reasoning Capability for Large Vision-Language Models,"Capitalizing on the remarkable advancements in Large Language Models (LLMs),
there is a burgeoning initiative to harness LLMs for instruction following
robotic navigation. Such a trend underscores the potential of LLMs to
generalize navigational reasoning and diverse language understanding. However,
a significant discrepancy in agent performance is observed when integrating
LLMs in the Vision-and-Language navigation (VLN) tasks compared to previous
downstream specialist models. Furthermore, the inherent capacity of language to
interpret and facilitate communication in agent interactions is often
underutilized in these integrations. In this work, we strive to bridge the
divide between VLN-specialized models and LLM-based navigation paradigms, while
maintaining the interpretative prowess of LLMs in generating linguistic
navigational reasoning. By aligning visual content in a frozen LLM, we
encompass visual observation comprehension for LLMs and exploit a way to
incorporate LLMs and navigation policy networks for effective action
predictions and navigational reasoning. We demonstrate the data efficiency of
the proposed methods and eliminate the gap between LM-based agents and
state-of-the-art VLN specialists.",2024-07-17,"Gengze Zhou, Yicong Hong, Zun Wang, Xin Eric Wang, Qi Wu",http://arxiv.org/pdf/2407.12366v2,cs.CL
Explainable Biomedical Hypothesis Generation via Retrieval Augmented Generation enabled Large Language Models,"The vast amount of biomedical information available today presents a
significant challenge for investigators seeking to digest, process, and
understand these findings effectively. Large Language Models (LLMs) have
emerged as powerful tools to navigate this complex and challenging data
landscape. However, LLMs may lead to hallucinatory responses, making Retrieval
Augmented Generation (RAG) crucial for achieving accurate information. In this
protocol, we present RUGGED (Retrieval Under Graph-Guided Explainable disease
Distinction), a comprehensive workflow designed to support investigators with
knowledge integration and hypothesis generation, identifying validated paths
forward. Relevant biomedical information from publications and knowledge bases
are reviewed, integrated, and extracted via text-mining association analysis
and explainable graph prediction models on disease nodes, forecasting potential
links among drugs and diseases. These analyses, along with biomedical texts,
are integrated into a framework that facilitates user-directed mechanism
elucidation as well as hypothesis exploration through RAG-enabled LLMs. A
clinical use-case demonstrates RUGGED's ability to evaluate and recommend
therapeutics for Arrhythmogenic Cardiomyopathy (ACM) and Dilated Cardiomyopathy
(DCM), analyzing prescribed drugs for molecular interactions and unexplored
uses. The platform minimizes LLM hallucinations, offers actionable insights,
and improves the investigation of novel therapeutics.",2024-07-17,"Alexander R. Pelletier, Joseph Ramirez, Irsyad Adam, Simha Sankar, Yu Yan, Ding Wang, Dylan Steinecke, Wei Wang, Peipei Ping",http://arxiv.org/pdf/2407.12888v1,cs.CL
Conversational Query Reformulation with the Guidance of Retrieved Documents,"Conversational search seeks to retrieve relevant passages for the given
questions in conversational question answering. Conversational Query
Reformulation (CQR) improves conversational search by refining the original
queries into de-contextualized forms to resolve the issues in the original
queries, such as omissions and coreferences. Previous CQR methods focus on
imitating human written queries which may not always yield meaningful search
results for the retriever. In this paper, we introduce GuideCQR, a framework
that refines queries for CQR by leveraging key information from the initially
retrieved documents. Specifically, GuideCQR extracts keywords and generates
expected answers from the retrieved documents, then unifies them with the
queries after filtering to add useful information that enhances the search
process. Experimental results demonstrate that our proposed method achieves
state-of-the-art performance across multiple datasets, outperforming previous
CQR methods. Additionally, we show that GuideCQR can get additional performance
gains in conversational search using various types of queries, even for queries
written by humans.",2024-07-17,"Jeonghyun Park, Hwanhee Lee",http://arxiv.org/pdf/2407.12363v5,cs.CL
ProcTag: Process Tagging for Assessing the Efficacy of Document Instruction Data,"Recently, large language models (LLMs) and multimodal large language models
(MLLMs) have demonstrated promising results on document visual question
answering (VQA) task, particularly after training on document instruction
datasets. An effective evaluation method for document instruction data is
crucial in constructing instruction data with high efficacy, which, in turn,
facilitates the training of LLMs and MLLMs for document VQA. However, most
existing evaluation methods for instruction data are limited to the textual
content of the instructions themselves, thereby hindering the effective
assessment of document instruction datasets and constraining their
construction. In this paper, we propose ProcTag, a data-oriented method that
assesses the efficacy of document instruction data. ProcTag innovatively
performs tagging on the execution process of instructions rather than the
instruction text itself. By leveraging the diversity and complexity of these
tags to assess the efficacy of the given dataset, ProcTag enables selective
sampling or filtering of document instructions. Furthermore, DocLayPrompt, a
novel semi-structured layout-aware document prompting strategy, is proposed for
effectively representing documents. Experiments demonstrate that sampling
existing open-sourced and generated document VQA/instruction datasets with
ProcTag significantly outperforms current methods for evaluating instruction
data. Impressively, with ProcTag-based sampling in the generated document
datasets, only 30.5\% of the document instructions are required to achieve
100\% efficacy compared to the complete dataset. The code is publicly available
at
https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/ProcTag.",2024-07-17,"Yufan Shen, Chuwei Luo, Zhaoqing Zhu, Yang Chen, Qi Zheng, Zhi Yu, Jiajun Bu, Cong Yao",http://arxiv.org/pdf/2407.12358v2,cs.CL
The Better Angels of Machine Personality: How Personality Relates to LLM Safety,"Personality psychologists have analyzed the relationship between personality
and safety behaviors in human society. Although Large Language Models (LLMs)
demonstrate personality traits, the relationship between personality traits and
safety abilities in LLMs still remains a mystery. In this paper, we discover
that LLMs' personality traits are closely related to their safety abilities,
i.e., toxicity, privacy, and fairness, based on the reliable MBTI-M scale.
Meanwhile, the safety alignment generally increases various LLMs' Extraversion,
Sensing, and Judging traits. According to such findings, we can edit LLMs'
personality traits and improve their safety performance, e.g., inducing
personality from ISTJ to ISTP resulted in a relative improvement of
approximately 43% and 10% in privacy and fairness performance, respectively.
Additionally, we find that LLMs with different personality traits are
differentially susceptible to jailbreak. This study pioneers the investigation
of LLM safety from a personality perspective, providing new insights into LLM
safety enhancement.",2024-07-17,"Jie Zhang, Dongrui Liu, Chen Qian, Ziyue Gan, Yong Liu, Yu Qiao, Jing Shao",http://arxiv.org/pdf/2407.12344v1,cs.CL
Word Embedding Dimension Reduction via Weakly-Supervised Feature Selection,"As a fundamental task in natural language processing, word embedding converts
each word into a representation in a vector space. A challenge with word
embedding is that as the vocabulary grows, the vector space's dimension
increases, which can lead to a vast model size. Storing and processing word
vectors are resource-demanding, especially for mobile edge-devices
applications. This paper explores word embedding dimension reduction. To
balance computational costs and performance, we propose an efficient and
effective weakly-supervised feature selection method named WordFS. It has two
variants, each utilizing novel criteria for feature selection. Experiments on
various tasks (e.g., word and sentence similarity and binary and multi-class
classification) indicate that the proposed WordFS model outperforms other
dimension reduction methods at lower computational costs. We have released the
code for reproducibility along with the paper.",2024-07-17,"Jintang Xue, Yun-Cheng Wang, Chengwei Wei, C. -C. Jay Kuo",http://arxiv.org/pdf/2407.12342v2,cs.CL
M2DS: Multilingual Dataset for Multi-document Summarisation,"In the rapidly evolving digital era, there is an increasing demand for
concise information as individuals seek to distil key insights from various
sources. Recent attention from researchers on Multi-document Summarisation
(MDS) has resulted in diverse datasets covering customer reviews, academic
papers, medical and legal documents, and news articles. However, the
English-centric nature of these datasets has created a conspicuous void for
multilingual datasets in today's globalised digital landscape, where linguistic
diversity is celebrated. Media platforms such as British Broadcasting
Corporation (BBC) have disseminated news in 20+ languages for decades. With
only 380 million people speaking English natively as their first language,
accounting for less than 5% of the global population, the vast majority
primarily relies on other languages. These facts underscore the need for
inclusivity in MDS research, utilising resources from diverse languages.
Recognising this gap, we present the Multilingual Dataset for Multi-document
Summarisation (M2DS), which, to the best of our knowledge, is the first dataset
of its kind. It includes document-summary pairs in five languages from BBC
articles published during the 2010-2023 period. This paper introduces M2DS,
emphasising its unique multilingual aspect, and includes baseline scores from
state-of-the-art MDS models evaluated on our dataset.",2024-07-17,"Kushan Hewapathirana, Nisansa de Silva, C. D. Athuraliya",http://arxiv.org/pdf/2407.12336v1,cs.CL
Spectra: Surprising Effectiveness of Pretraining Ternary Language Models at Scale,"Rapid advancements in GPU computational power has outpaced memory capacity
and bandwidth growth, creating bottlenecks in Large Language Model (LLM)
inference. Post-training quantization is the leading method for addressing
memory-related bottlenecks in LLM inference, but it suffers from significant
performance degradation below 4-bit precision. This paper addresses these
challenges by investigating the pretraining of low-bitwidth models specifically
Ternary Language Models (TriLMs) as an alternative to traditional
floating-point models (FloatLMs) and their post-training quantized versions
(QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning
multiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M
to 3.9B parameters trained on 300B tokens. Our comprehensive evaluation
demonstrates that TriLMs offer superior scaling behavior in terms of model size
(in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs
consistently outperform their QuantLM and FloatLM counterparts for a given bit
size across various benchmarks. Notably, the 3.9B parameter TriLM matches the
performance of the FloatLM 3.9B across all benchmarks, despite having fewer
bits than FloatLM 830M. Overall, this research provides valuable insights into
the feasibility and scalability of low-bitwidth language models, paving the way
for the development of more efficient LLMs.
  To enhance understanding of low-bitwidth models, we are releasing 500+
intermediate checkpoints of the Spectra suite at
https://github.com/NolanoOrg/SpectraSuite.",2024-07-17,"Ayush Kaushal, Tejas Vaidhya, Arnab Kumar Mondal, Tejas Pandey, Aaryan Bhagat, Irina Rish",http://arxiv.org/pdf/2407.12327v5,cs.CL
Multi-Grained Query-Guided Set Prediction Network for Grounded Multimodal Named Entity Recognition,"Grounded Multimodal Named Entity Recognition (GMNER) is an emerging
information extraction (IE) task, aiming to simultaneously extract entity
spans, types, and corresponding visual regions of entities from given
sentence-image pairs data. Recent unified methods employing machine reading
comprehension or sequence generation-based frameworks show limitations in this
difficult task. The former, utilizing human-designed type queries, struggles to
differentiate ambiguous entities, such as Jordan (Person) and off-White x
Jordan (Shoes). The latter, following the one-by-one decoding order, suffers
from exposure bias issues. We maintain that these works misunderstand the
relationships of multimodal entities. To tackle these, we propose a novel
unified framework named Multi-grained Query-guided Set Prediction Network
(MQSPN) to learn appropriate relationships at intra-entity and inter-entity
levels. Specifically, MQSPN explicitly aligns textual entities with visual
regions by employing a set of learnable queries to strengthen intra-entity
connections. Based on distinct intra-entity modeling, MQSPN reformulates GMNER
as a set prediction, guiding models to establish appropriate inter-entity
relationships from a optimal global matching perspective. Additionally, we
incorporate a query-guided Fusion Net (QFNet) as a glue network to boost better
alignment of two-level relationships. Extensive experiments demonstrate that
our approach achieves state-of-the-art performances in widely used benchmarks.",2024-07-17,"Jielong Tang, Zhenxing Wang, Ziyang Gong, Jianxing Yu, Xiangwei Zhu, Jian Yin",http://arxiv.org/pdf/2407.21033v3,cs.CL
MEDFuse: Multimodal EHR Data Fusion with Masked Lab-Test Modeling and Large Language Models,"Electronic health records (EHRs) are multimodal by nature, consisting of
structured tabular features like lab tests and unstructured clinical notes. In
real-life clinical practice, doctors use complementary multimodal EHR data
sources to get a clearer picture of patients' health and support clinical
decision-making. However, most EHR predictive models do not reflect these
procedures, as they either focus on a single modality or overlook the
inter-modality interactions/redundancy. In this work, we propose MEDFuse, a
Multimodal EHR Data Fusion framework that incorporates masked lab-test modeling
and large language models (LLMs) to effectively integrate structured and
unstructured medical data. MEDFuse leverages multimodal embeddings extracted
from two sources: LLMs fine-tuned on free clinical text and masked tabular
transformers trained on structured lab test results. We design a disentangled
transformer module, optimized by a mutual information loss to 1) decouple
modality-specific and modality-shared information and 2) extract useful joint
representation from the noise and redundancy present in clinical notes. Through
comprehensive validation on the public MIMIC-III dataset and the in-house FEMH
dataset, MEDFuse demonstrates great potential in advancing clinical
predictions, achieving over 90% F1 score in the 10-disease multi-label
classification task.",2024-07-17,"Thao Minh Nguyen Phan, Cong-Tinh Dao, Chenwei Wu, Jian-Zhe Wang, Shun Liu, Jun-En Ding, David Restrepo, Feng Liu, Fang-Ming Hung, Wen-Chih Peng",http://arxiv.org/pdf/2407.12309v1,cs.CL
Adaptive Pre-training Data Detection for Large Language Models via Surprising Tokens,"While large language models (LLMs) are extensively used, there are raising
concerns regarding privacy, security, and copyright due to their opaque
training data, which brings the problem of detecting pre-training data on the
table. Current solutions to this problem leverage techniques explored in
machine learning privacy such as Membership Inference Attacks (MIAs), which
heavily depend on LLMs' capability of verbatim memorization. However, this
reliance presents challenges, especially given the vast amount of training data
and the restricted number of effective training epochs. In this paper, we
propose an adaptive pre-training data detection method which alleviates this
reliance and effectively amplify the identification. Our method adaptively
locates \textit{surprising tokens} of the input. A token is surprising to a LLM
if the prediction on the token is ""certain but wrong"", which refers to low
Shannon entropy of the probability distribution and low probability of the
ground truth token at the same time. By using the prediction probability of
surprising tokens to measure \textit{surprising}, the detection method is
achieved based on the simple hypothesis that seeing seen data is less
surprising for the model compared with seeing unseen data. The method can be
applied without any access to the the pre-training data corpus or additional
training like reference models. Our approach exhibits a consistent enhancement
compared to existing methods in diverse experiments conducted on various
benchmarks and models, achieving a maximum improvement of 29.5\%. We also
introduce a new benchmark Dolma-Book developed upon a novel framework, which
employs book data collected both before and after model training to provide
further evaluation.",2024-07-30,"Anqi Zhang, Chaofeng Wu",http://arxiv.org/pdf/2407.21248v1,cs.LG
Informed Correctors for Discrete Diffusion Models,"Discrete diffusion has emerged as a powerful framework for generative
modeling in discrete domains, yet efficiently sampling from these models
remains challenging. Existing sampling strategies often struggle to balance
computation and sample quality when the number of sampling steps is reduced,
even when the model has learned the data distribution well. To address these
limitations, we propose a predictor-corrector sampling scheme where the
corrector is informed by the diffusion model to more reliably counter the
accumulating approximation errors. To further enhance the effectiveness of our
informed corrector, we introduce complementary architectural modifications
based on hollow transformers and a simple tailored training objective that
leverages more training signal. We use a synthetic example to illustrate the
failure modes of existing samplers and show how informed correctors alleviate
these problems. On tokenized ImageNet 256x256, this approach consistently
produces superior samples with fewer steps, achieving improved FID scores for
discrete diffusion models. These results underscore the potential of informed
correctors for fast and high-fidelity generation using discrete diffusion.",2024-07-30,"Yixiu Zhao, Jiaxin Shi, Feng Chen, Shaul Druckmann, Lester Mackey, Scott Linderman",http://arxiv.org/pdf/2407.21243v2,cs.LG
GNUMAP: A Parameter-Free Approach to Unsupervised Dimensionality Reduction via Graph Neural Networks,"With the proliferation of Graph Neural Network (GNN) methods stemming from
contrastive learning, unsupervised node representation learning for graph data
is rapidly gaining traction across various fields, from biology to molecular
dynamics, where it is often used as a dimensionality reduction tool. However,
there remains a significant gap in understanding the quality of the
low-dimensional node representations these methods produce, particularly beyond
well-curated academic datasets. To address this gap, we propose here the first
comprehensive benchmarking of various unsupervised node embedding techniques
tailored for dimensionality reduction, encompassing a range of manifold
learning tasks, along with various performance metrics. We emphasize the
sensitivity of current methods to hyperparameter choices -- highlighting a
fundamental issue as to their applicability in real-world settings where there
is no established methodology for rigorous hyperparameter selection. Addressing
this issue, we introduce GNUMAP, a robust and parameter-free method for
unsupervised node representation learning that merges the traditional UMAP
approach with the expressivity of the GNN framework. We show that GNUMAP
consistently outperforms existing state-of-the-art GNN embedding methods in a
variety of contexts, including synthetic geometric datasets, citation networks,
and real-world biomedical data -- making it a simple but reliable
dimensionality reduction tool.",2024-07-30,"Jihee You, So Won Jeong, Claire Donnat",http://arxiv.org/pdf/2407.21236v1,cs.LG
Towards an Integrated Performance Framework for Fire Science and Management Workflows,"Reliable performance metrics are necessary prerequisites to building
large-scale end-to-end integrated workflows for collaborative scientific
research, particularly within context of use-inspired decision making platforms
with many concurrent users and when computing real-time and urgent results
using large data. This work is a building block for the National Data Platform,
which leverages multiple use-cases including the WIFIRE Data and Model Commons
for wildfire behavior modeling and the EarthScope Consortium for collaborative
geophysical research. This paper presents an artificial intelligence and
machine learning (AI/ML) approach to performance assessment and optimization of
scientific workflows. An associated early AI/ML framework spanning performance
data collection, prediction and optimization is applied to wildfire science
applications within the WIFIRE BurnPro3D (BP3D) platform for proactive fire
management and mitigation.",2024-07-30,"H. Ahmed, R. Shende, I. Perez, D. Crawl, S. Purawat, I. Altintas",http://arxiv.org/pdf/2407.21231v1,cs.LG
DeepBaR: Fault Backdoor Attack on Deep Neural Network Layers,"Machine Learning using neural networks has received prominent attention
recently because of its success in solving a wide variety of computational
tasks, in particular in the field of computer vision. However, several works
have drawn attention to potential security risks involved with the training and
implementation of such networks. In this work, we introduce DeepBaR, a novel
approach that implants backdoors on neural networks by faulting their behavior
at training, especially during fine-tuning. Our technique aims to generate
adversarial samples by optimizing a custom loss function that mimics the
implanted backdoors while adding an almost non-visible trigger in the image. We
attack three popular convolutional neural network architectures and show that
DeepBaR attacks have a success rate of up to 98.30\%. Furthermore, DeepBaR does
not significantly affect the accuracy of the attacked networks after deployment
when non-malicious inputs are given. Remarkably, DeepBaR allows attackers to
choose an input that looks similar to a given class, from a human perspective,
but that will be classified as belonging to an arbitrary target class.",2024-07-30,"C. A. Martínez-Mejía, J. Solano, J. Breier, D. Bucko, X. Hou",http://arxiv.org/pdf/2407.21220v1,cs.LG
NeuroSEM: A hybrid framework for simulating multiphysics problems by coupling PINNs and spectral elements,"Multiphysics problems that are characterized by complex interactions among
fluid dynamics, heat transfer, structural mechanics, and electromagnetics, are
inherently challenging due to their coupled nature. While experimental data on
certain state variables may be available, integrating these data with numerical
solvers remains a significant challenge. Physics-informed neural networks
(PINNs) have shown promising results in various engineering disciplines,
particularly in handling noisy data and solving inverse problems in partial
differential equations (PDEs). However, their effectiveness in forecasting
nonlinear phenomena in multiphysics regimes, particularly involving turbulence,
is yet to be fully established. This study introduces NeuroSEM, a hybrid
framework integrating PINNs with the high-fidelity Spectral Element Method
(SEM) solver, Nektar++. NeuroSEM leverages the strengths of both PINNs and SEM,
providing robust solutions for multiphysics problems. PINNs are trained to
assimilate data and model physical phenomena in specific subdomains, which are
then integrated into the Nektar++ solver. We demonstrate the efficiency and
accuracy of NeuroSEM for thermal convection in cavity flow and flow past a
cylinder. We applied NeuroSEM to the Rayleigh-B\'enard convection system,
including cases with missing thermal boundary conditions and noisy datasets,
and to real particle image velocimetry (PIV) data to capture flow patterns
characterized by horseshoe vortical structures. The framework's plug-and-play
nature facilitates its extension to other multiphysics or multiscale problems.
Furthermore, NeuroSEM is optimized for efficient execution on emerging
integrated GPU-CPU architectures. This hybrid approach enhances the accuracy
and efficiency of simulations, making it a powerful tool for tackling complex
engineering challenges in various scientific domains.",2024-07-30,"Khemraj Shukla, Zongren Zou, Chi Hin Chan, Additi Pandey, Zhicheng Wang, George Em Karniadakis",http://arxiv.org/pdf/2407.21217v2,cs.LG
Diffusion-Based Generation of Neural Activity from Disentangled Latent Codes,"Recent advances in recording technology have allowed neuroscientists to
monitor activity from thousands of neurons simultaneously. Latent variable
models are increasingly valuable for distilling these recordings into compact
and interpretable representations. Here we propose a new approach to neural
data analysis that leverages advances in conditional generative modeling to
enable the unsupervised inference of disentangled behavioral variables from
recorded neural activity. Our approach builds on InfoDiffusion, which augments
diffusion models with a set of latent variables that capture important factors
of variation in the data. We apply our model, called Generating Neural
Observations Conditioned on Codes with High Information (GNOCCHI), to time
series neural data and test its application to synthetic and biological
recordings of neural activity during reaching. In comparison to a VAE-based
sequential autoencoder, GNOCCHI learns higher-quality latent spaces that are
more clearly structured and more disentangled with respect to key behavioral
variables. These properties enable accurate generation of novel samples (unseen
behavioral conditions) through simple linear traversal of the latent spaces
produced by GNOCCHI. Our work demonstrates the potential of unsupervised,
information-based models for the discovery of interpretable latent spaces from
neural data, enabling researchers to generate high-quality samples from unseen
conditions.",2024-07-30,"Jonathan D. McCart, Andrew R. Sedler, Christopher Versteeg, Domenick Mifsud, Mattia Rigotti-Thompson, Chethan Pandarinath",http://arxiv.org/pdf/2407.21195v1,cs.LG
Analyzing Customer-Facing Vendor Experiences with Time Series Forecasting and Monte Carlo Techniques,"eBay partners with external vendors, which allows customers to freely select
a vendor to complete their eBay experiences. However, vendor outages can hinder
customer experiences. Consequently, eBay can disable a problematic vendor to
prevent customer loss. Disabling the vendor too late risks losing customers
willing to switch to other vendors, while disabling it too early risks losing
those unwilling to switch. In this paper, we propose a data-driven solution to
answer whether eBay should disable a problematic vendor and when to disable it.
Our solution involves forecasting customer behavior. First, we use a
multiplicative seasonality model to represent behavior if all vendors are fully
functioning. Next, we use a Monte Carlo simulation to represent behavior if the
problematic vendor remains enabled. Finally, we use a linear model to represent
behavior if the vendor is disabled. By comparing these forecasts, we determine
the optimal time for eBay to disable the problematic vendor.",2024-07-30,"Vivek Kaushik, Jason Tang",http://arxiv.org/pdf/2407.21193v1,cs.LG
GenRec: Generative Sequential Recommendation with Large Language Models,"Sequential recommendation is a task to capture hidden user preferences from
historical user item interaction data and recommend next items for the user.
Significant progress has been made in this domain by leveraging classification
based learning methods. Inspired by the recent paradigm of 'pretrain, prompt
and predict' in NLP, we consider sequential recommendation as a sequence to
sequence generation task and propose a novel model named Generative
Recommendation (GenRec). Unlike classification based models that learn explicit
user and item representations, GenRec utilizes the sequence modeling capability
of Transformer and adopts the masked item prediction objective to effectively
learn the hidden bidirectional sequential patterns. Different from existing
generative sequential recommendation models, GenRec does not rely on manually
designed hard prompts. The input to GenRec is textual user item sequence and
the output is top ranked next items. Moreover, GenRec is lightweight and
requires only a few hours to train effectively in low-resource settings, making
it highly applicable to real-world scenarios and helping to democratize large
language models in the sequential recommendation domain. Our extensive
experiments have demonstrated that GenRec generalizes on various public
real-world datasets and achieves state-of-the-art results. Our experiments also
validate the effectiveness of the the proposed masked item prediction objective
that improves the model performance by a large margin.",2024-07-30,"Panfeng Cao, Pietro Lio",http://arxiv.org/pdf/2407.21191v2,cs.LG
Multi-task Photonic Reservoir Computing: Wavelength Division Multiplexing for Parallel Computing with a Silicon Microring Resonator,"Nowadays, as the ever-increasing demand for more powerful computing resources
continues, alternative advanced computing paradigms are under extensive
investigation. Significant effort has been made to deviate from conventional
Von Neumann architectures. In-memory computing has emerged in the field of
electronics as a possible solution to the infamous bottleneck between memory
and computing processors, which reduces the effective throughput of data. In
photonics, novel schemes attempt to collocate the computing processor and
memory in a single device. Photonics offers the flexibility of multiplexing
streams of data not only spatially and in time, but also in frequency or,
equivalently, in wavelength, which makes it highly suitable for parallel
computing. Here, we numerically show the use of time and wavelength division
multiplexing (WDM) to solve four independent tasks at the same time in a single
photonic chip, serving as a proof of concept for our proposal. The system is a
time-delay reservoir computing (TDRC) based on a microring resonator (MRR). The
addressed tasks cover different applications: Time-series prediction, waveform
signal classification, wireless channel equalization, and radar signal
prediction. The system is also tested for simultaneous computing of up to 10
instances of the same task, exhibiting excellent performance. The footprint of
the system is reduced by using time-division multiplexing of the nodes that act
as the neurons of the studied neural network scheme. WDM is used for the
parallelization of wavelength channels, each addressing a single task. By
adjusting the input power and frequency of each optical channel, we can achieve
levels of performance for each of the tasks that are comparable to those quoted
in state-of-the-art reports focusing on single-task operation...",2024-07-30,"Bernard J. Giron Castro, Christophe Peucheret, Darko Zibar, Francesco Da Ros",http://arxiv.org/pdf/2407.21189v2,cs.LG
Amelia: A Large Dataset and Model for Airport Surface Movement Forecasting,"The growing demand for air travel necessitates advancements in air traffic
management technologies to ensure safe and efficient operations. Predictive
models for terminal airspace can help anticipate future movements and traffic
flows, enabling proactive planning for efficient coordination, collision risk
assessment, taxi-out time prediction, departure metering, and emission
estimations. Although data-driven predictive models have shown promise in
tackling some of these challenges, the absence of large-scale curated surface
movement datasets in the public domain has hindered the development of scalable
and generalizable approaches.
  In this context, we propose the Amelia framework, which consists of four key
contributions. First, Amelia-48, a large dataset of airport surface movement
collected through the FAA's System Wide Information Management (SWIM) Program.
This dataset includes over two years' worth of trajectory data (~70TB) across
48 US airports and map data. Second, we develop AmeliaTF, a large
transformer-based baseline for multi-agent, multi-airport trajectory
forecasting. Third, we propose Amelia-10, a training and evaluation benchmark
consisting of 292 days of post-processed data from 10 different airports and a
series of experiments to promote the development of foundation models in
aviation. We provide baseline results across our benchmark using AmeliaTF.
Finally, we release our framework and tools to encourage further aviation
research in the forecasting domain and beyond at https://ameliacmu.github.io",2024-07-30,"Ingrid Navarro, Pablo Ortega-Kral, Jay Patrikar, Haichuan Wang, Alonso Cano, Zelin Ye, Jong Hoon Park, Jean Oh, Sebastian Scherer",http://arxiv.org/pdf/2407.21185v2,cs.LG
"Optical Computing for Deep Neural Network Acceleration: Foundations, Recent Developments, and Emerging Directions","Emerging artificial intelligence applications across the domains of computer
vision, natural language processing, graph processing, and sequence prediction
increasingly rely on deep neural networks (DNNs). These DNNs require
significant compute and memory resources for training and inference.
Traditional computing platforms such as CPUs, GPUs, and TPUs are struggling to
keep up with the demands of the increasingly complex and diverse DNNs. Optical
computing represents an exciting new paradigm for light-speed acceleration of
DNN workloads. In this article, we discuss the fundamentals and
state-of-the-art developments in optical computing, with an emphasis on DNN
acceleration. Various promising approaches are described for engineering
optical devices, enhancing optical circuits, and designing architectures that
can adapt optical computing to a variety of DNN workloads. Novel techniques for
hardware/software co-design that can intelligently tune and map DNN models to
improve performance and energy-efficiency on optical computing platforms across
high performance and resource constrained embedded, edge, and IoT platforms are
also discussed. Lastly, several open problems and future directions for
research in this domain are highlighted.",2024-07-30,Sudeep Pasricha,http://arxiv.org/pdf/2407.21184v1,cs.LG
DKL-KAN: Scalable Deep Kernel Learning using Kolmogorov-Arnold Networks,"The need for scalable and expressive models in machine learning is paramount,
particularly in applications requiring both structural depth and flexibility.
Traditional deep learning methods, such as multilayer perceptrons (MLP), offer
depth but lack ability to integrate structural characteristics of deep learning
architectures with non-parametric flexibility of kernel methods. To address
this, deep kernel learning (DKL) was introduced, where inputs to a base kernel
are transformed using a deep learning architecture. These kernels can replace
standard kernels, allowing both expressive power and scalability. The advent of
Kolmogorov-Arnold Networks (KAN) has generated considerable attention and
discussion among researchers in scientific domain. In this paper, we introduce
a scalable deep kernel using KAN (DKL-KAN) as an effective alternative to DKL
using MLP (DKL-MLP). Our approach involves simultaneously optimizing these
kernel attributes using marginal likelihood within a Gaussian process
framework. We analyze two variants of DKL-KAN for a fair comparison with
DKL-MLP: one with same number of neurons and layers as DKL-MLP, and another
with approximately same number of trainable parameters. To handle large
datasets, we use kernel interpolation for scalable structured Gaussian
processes (KISS-GP) for low-dimensional inputs and KISS-GP with product kernels
for high-dimensional inputs. The efficacy of DKL-KAN is evaluated in terms of
computational training time and test prediction accuracy across a wide range of
applications. Additionally, the effectiveness of DKL-KAN is also examined in
modeling discontinuities and accurately estimating prediction uncertainty. The
results indicate that DKL-KAN outperforms DKL-MLP on datasets with a low number
of observations. Conversely, DKL-MLP exhibits better scalability and higher
test prediction accuracy on datasets with large number of observations.",2024-07-30,"Shrenik Zinage, Sudeepta Mondal, Soumalya Sarkar",http://arxiv.org/pdf/2407.21176v1,cs.LG
Embedding Space Selection for Detecting Memorization and Fingerprinting in Generative Models,"In the rapidly evolving landscape of artificial intelligence, generative
models such as Generative Adversarial Networks (GANs) and Diffusion Models have
become cornerstone technologies, driving innovation in diverse fields from art
creation to healthcare. Despite their potential, these models face the
significant challenge of data memorization, which poses risks to privacy and
the integrity of generated content. Among various metrics of memorization
detection, our study delves into the memorization scores calculated from
encoder layer embeddings, which involves measuring distances between samples in
the embedding spaces. Particularly, we find that the memorization scores
calculated from layer embeddings of Vision Transformers (ViTs) show an notable
trend - the latter (deeper) the layer, the less the memorization measured. It
has been found that the memorization scores from the early layers' embeddings
are more sensitive to low-level memorization (e.g. colors and simple patterns
for an image), while those from the latter layers are more sensitive to
high-level memorization (e.g. semantic meaning of an image). We also observe
that, for a specific model architecture, its degree of memorization on
different levels of information is unique. It can be viewed as an inherent
property of the architecture. Building upon this insight, we introduce a unique
fingerprinting methodology. This method capitalizes on the unique distributions
of the memorization score across different layers of ViTs, providing a novel
approach to identifying models involved in generating deepfakes and malicious
content. Our approach demonstrates a marked 30% enhancement in identification
accuracy over existing baseline methods, offering a more effective tool for
combating digital misinformation.",2024-07-30,"Jack He, Jianxing Zhao, Andrew Bai, Cho-Jui Hsieh",http://arxiv.org/pdf/2407.21159v1,cs.LG
Private Collaborative Edge Inference via Over-the-Air Computation,"We consider collaborative inference at the wireless edge, where each client's
model is trained independently on its local dataset. Clients are queried in
parallel to make an accurate decision collaboratively. In addition to
maximizing the inference accuracy, we also want to ensure the privacy of local
models. To this end, we leverage the superposition property of the multiple
access channel to implement bandwidth-efficient multi-user inference methods.
We propose different methods for ensemble and multi-view classification that
exploit over-the-air computation (OAC). We show that these schemes perform
better than their orthogonal counterparts with statistically significant
differences while using fewer resources and providing privacy guarantees. We
also provide experimental results verifying the benefits of the proposed OAC
approach to multi-user inference, and perform an ablation study to demonstrate
the effectiveness of our design choices. We share the source code of the
framework publicly on Github to facilitate further research and
reproducibility.",2024-07-30,"Selim F. Yilmaz, Burak Hasircioglu, Li Qiao, Deniz Gunduz",http://arxiv.org/pdf/2407.21151v2,cs.LG
Enhancing Deep Hedging of Options with Implied Volatility Surface Feedback Information,"We present a dynamic hedging scheme for S&P 500 options, where rebalancing
decisions are enhanced by integrating information about the implied volatility
surface dynamics. The optimal hedging strategy is obtained through a deep
policy gradient-type reinforcement learning algorithm, with a novel hybrid
neural network architecture improving the training performance. The favorable
inclusion of forward-looking information embedded in the volatility surface
allows our procedure to outperform several conventional benchmarks such as
practitioner and smiled-implied delta hedging procedures, both in simulation
and backtesting experiments.",2024-07-30,"Pascal François, Geneviève Gauthier, Frédéric Godin, Carlos Octavio Pérez Mendoza",http://arxiv.org/pdf/2407.21138v1,cs.LG
Computational music analysis from first principles,"We use coupled hidden Markov models to automatically annotate the 371 Bach
chorales in the Riemenschneider edition, a corpus containing approximately
100,000 notes and 20,000 chords. We give three separate analyses that achieve
progressively greater accuracy at the cost of making increasingly strong
assumptions about musical syntax. Although our method makes almost no use of
human input, we are able to identify both chords and keys with an accuracy of
85% or greater when compared to an expert human analysis, resulting in
annotations accurate enough to be used for a range of music-theoretical
purposes, while also being free of subjective human judgments. Our work bears
on longstanding debates about the objective reality of the structures
postulated by standard Western harmonic theory, as well as on specific
questions about the nature of Western harmonic syntax.",2024-07-30,"Dmitri Tymoczko, Mark Newman",http://arxiv.org/pdf/2407.21130v1,cs.LG
Zero Shot Health Trajectory Prediction Using Transformer,"Integrating modern machine learning and clinical decision-making has great
promise for mitigating healthcare's increasing cost and complexity. We
introduce the Enhanced Transformer for Health Outcome Simulation (ETHOS), a
novel application of the transformer deep-learning architecture for analyzing
high-dimensional, heterogeneous, and episodic health data. ETHOS is trained
using Patient Health Timelines (PHTs)-detailed, tokenized records of health
events-to predict future health trajectories, leveraging a zero-shot learning
approach. ETHOS represents a significant advancement in foundation model
development for healthcare analytics, eliminating the need for labeled data and
model fine-tuning. Its ability to simulate various treatment pathways and
consider patient-specific factors positions ETHOS as a tool for care
optimization and addressing biases in healthcare delivery. Future developments
will expand ETHOS' capabilities to incorporate a wider range of data types and
data sources. Our work demonstrates a pathway toward accelerated AI development
and deployment in healthcare.",2024-07-30,"Pawel Renc, Yugang Jia, Anthony E. Samir, Jaroslaw Was, Quanzheng Li, David W. Bates, Arkadiusz Sitek",http://arxiv.org/pdf/2407.21124v1,cs.LG
Tuning the Frequencies: Robust Training for Sinusoidal Neural Networks,"Sinusoidal neural networks have been shown effective as implicit neural
representations (INRs) of low-dimensional signals, due to their smoothness and
high representation capacity. However, initializing and training them remain
empirical tasks which lack on deeper understanding to guide the learning
process. To fill this gap, our work introduces a theoretical framework that
explains the capacity property of sinusoidal networks and offers robust control
mechanisms for initialization and training. Our analysis is based on a novel
amplitude-phase expansion of the sinusoidal multilayer perceptron, showing how
its layer compositions produce a large number of new frequencies expressed as
integer combinations of the input frequencies. This relationship can be
directly used to initialize the input neurons, as a form of spectral sampling,
and to bound the network's spectrum while training. Our method, referred to as
TUNER (TUNing sinusoidal nEtwoRks), greatly improves the stability and
convergence of sinusoidal INR training, leading to detailed reconstructions,
while preventing overfitting.",2024-07-30,"Tiago Novello, Diana Aldana, Andre Araujo, Luiz Velho",http://arxiv.org/pdf/2407.21121v3,cs.LG
Palu: Compressing KV-Cache with Low-Rank Projection,"Post-training KV-Cache compression methods typically either sample a subset
of effectual tokens or quantize the data into lower numerical bit width.
However, these methods cannot exploit redundancy in the hidden dimension of the
KV tensors. This paper presents a hidden dimension compression approach called
Palu, a KV-Cache compression framework that utilizes low-rank projection to
reduce inference-time LLM memory usage. Palu decomposes the linear layers into
low-rank matrices, caches compressed intermediate states, and reconstructs the
full keys and values on the fly. To improve accuracy, compression rate, and
efficiency, Palu further encompasses (1) a medium-grained low-rank
decomposition scheme, (2) an efficient rank search algorithm, (3)
low-rank-aware quantization compatibility enhancements, and (4) optimized GPU
kernels with operators fusion. Extensive experiments with popular LLMs show
that Palu compresses KV-Cache by 50% while maintaining strong accuracy and
delivering up to 1.89x on the RoPE-based attention module. When combined with
quantization, Palu's inherent quantization-friendly design yields small to
negligible extra accuracy degradation while saving additional memory than
quantization-only methods and achieving up to 2.91x speedup for the RoPE-based
attention. Moreover, it maintains comparable or even better accuracy (up to
1.19 lower perplexity) compared to quantization-only methods. These results
demonstrate Palu's superior capability to effectively address the efficiency
and memory challenges of LLM inference posed by KV-Cache. Our code is publicly
available at: https://github.com/shadowpa0327/Palu",2024-07-30,"Chi-Chih Chang, Wei-Cheng Lin, Chien-Yu Lin, Chong-Yan Chen, Yu-Fang Hu, Pei-Shuo Wang, Ning-Chi Huang, Luis Ceze, Mohamed S. Abdelfattah, Kai-Chiang Wu",http://arxiv.org/pdf/2407.21118v2,cs.LG
CLEFT: Language-Image Contrastive Learning with Efficient Large Language Model and Prompt Fine-Tuning,"Recent advancements in Contrastive Language-Image Pre-training (CLIP) have
demonstrated notable success in self-supervised representation learning across
various tasks. However, the existing CLIP-like approaches often demand
extensive GPU resources and prolonged training times due to the considerable
size of the model and dataset, making them poor for medical applications, in
which large datasets are not always common. Meanwhile, the language model
prompts are mainly manually derived from labels tied to images, potentially
overlooking the richness of information within training samples. We introduce a
novel language-image Contrastive Learning method with an Efficient large
language model and prompt Fine-Tuning (CLEFT) that harnesses the strengths of
the extensive pre-trained language and visual models. Furthermore, we present
an efficient strategy for learning context-based prompts that mitigates the gap
between informative clinical diagnostic data and simple class labels. Our
method demonstrates state-of-the-art performance on multiple chest X-ray and
mammography datasets compared with various baselines. The proposed parameter
efficient framework can reduce the total trainable model size by 39% and reduce
the trainable language model to only 4% compared with the current BERT encoder.",2024-07-30,"Yuexi Du, Brian Chang, Nicha C. Dvornek",http://arxiv.org/pdf/2407.21011v1,cs.LG
AI-Assisted Generation of Difficult Math Questions,"Current LLM training positions mathematical reasoning as a core capability.
With publicly available sources fully tapped, there is unmet demand for diverse
and challenging math questions. Relying solely on human experts is both
time-consuming and costly, while LLM-generated questions often lack the
requisite diversity and difficulty. We present a design framework that combines
the strengths of LLMs with a human-in-the-loop approach to generate a diverse
array of challenging math questions. We leverage LLM metacognition skills
[Didolkar et al., 2024] of a strong LLM to extract core ""skills"" from existing
math datasets. These skills serve as the basis for generating novel and
difficult questions by prompting the LLM with random pairs of core skills. The
use of two different skills within each question makes finding such questions
an ""out of distribution"" task for both LLMs and humans. Our pipeline employs
LLMs to iteratively generate and refine questions and solutions through
multiturn prompting. Human annotators then verify and further refine the
questions, with their efficiency enhanced via further LLM interactions.
Applying this pipeline on skills extracted from the MATH dataset [Hendrycks et
al., 2021] resulted in MATH$^2$ - a dataset of higher-quality math questions,
as evidenced by: (a) Lower performance of all models on MATH$^2$ than on MATH
(b) Higher performance on MATH when using MATH$^2$ questions as in-context
examples. Although focused on mathematics, our methodology seems applicable to
other domains requiring structured reasoning, and potentially as a component of
scalable oversight. Also of interest is a striking relationship observed
between models' performance on the new dataset: the success rate on MATH$^2$ is
the square on MATH, suggesting that successfully solving the question in
MATH$^2$ requires a nontrivial combination of two distinct math skills.",2024-07-30,"Vedant Shah, Dingli Yu, Kaifeng Lyu, Simon Park, Jiatong Yu, Yinghui He, Nan Rosemary Ke, Michael Mozer, Yoshua Bengio, Sanjeev Arora, Anirudh Goyal",http://arxiv.org/pdf/2407.21009v4,cs.LG
GABInsight: Exploring Gender-Activity Binding Bias in Vision-Language Models,"Vision-language models (VLMs) are intensively used in many downstream tasks,
including those requiring assessments of individuals appearing in the images.
While VLMs perform well in simple single-person scenarios, in real-world
applications, we often face complex situations in which there are persons of
different genders doing different activities. We show that in such cases, VLMs
are biased towards identifying the individual with the expected gender
(according to ingrained gender stereotypes in the model or other forms of
sample selection bias) as the performer of the activity. We refer to this bias
in associating an activity with the gender of its actual performer in an image
or text as the Gender-Activity Binding (GAB) bias and analyze how this bias is
internalized in VLMs. To assess this bias, we have introduced the GAB dataset
with approximately 5500 AI-generated images that represent a variety of
activities, addressing the scarcity of real-world images for some scenarios. To
have extensive quality control, the generated images are evaluated for their
diversity, quality, and realism. We have tested 12 renowned pre-trained VLMs on
this dataset in the context of text-to-image and image-to-text retrieval to
measure the effect of this bias on their predictions. Additionally, we have
carried out supplementary experiments to quantify the bias in VLMs' text
encoders and to evaluate VLMs' capability to recognize activities. Our
experiments indicate that VLMs experience an average performance decline of
about 13.2% when confronted with gender-activity binding bias.",2024-07-30,"Ali Abdollahi, Mahdi Ghaznavi, Mohammad Reza Karimi Nejad, Arash Mari Oriyad, Reza Abbasi, Ali Salesi, Melika Behjati, Mohammad Hossein Rohban, Mahdieh Soleymani Baghshah",http://arxiv.org/pdf/2407.21001v3,cs.LG
MoFO: Momentum-Filtered Optimizer for Mitigating Forgetting in LLM Fine-Tuning,"Large language models (LLMs) have demonstrated remarkable capabilities across
a wide range of tasks. Typically, LLMs are first pre-trained on large corpora
and subsequently fine-tuned on task-specific datasets. However, during
fine-tuning, LLMs may forget some knowledge acquired in the pre-training stage,
leading to a decline in general capabilities. Existing approaches to mitigate
forgetting often rely on access to pre-training data, which may be unavailable
in many real-world scenarios--such as fine-tuning checkpoint-only open-source
LLMs. To address this challenge, we propose a new fine-tuning algorithm termed
Momentum-Filtered Optimizer (MoFO). MoFO is an extension of greedy block
coordinate descent (BCD) methods: in each iteration, MoFO only updates the
model parameters with the largest momentum magnitudes, while keeping all other
parameters fixed. MoFO achieves similar fine-tuning performance to the default
fine-tuning algorithm while effectively mitigating knowledge forgetting. We
validate MoFO through rigorous convergence analysis and extensive experiments,
demonstrating its effectiveness in mitigating forgetting without pre-training
data.",2024-07-30,"Yupeng Chen, Senmiao Wang, Yushun Zhang, Zhihang Lin, Haozhe Zhang, Weijian Sun, Tian Ding, Ruoyu Sun",http://arxiv.org/pdf/2407.20999v3,cs.LG
From Feature Importance to Natural Language Explanations Using LLMs with RAG,"As machine learning becomes increasingly integral to autonomous
decision-making processes involving human interaction, the necessity of
comprehending the model's outputs through conversational means increases. Most
recently, foundation models are being explored for their potential as post hoc
explainers, providing a pathway to elucidate the decision-making mechanisms of
predictive models. In this work, we introduce traceable question-answering,
leveraging an external knowledge repository to inform the responses of Large
Language Models (LLMs) to user queries within a scene understanding task. This
knowledge repository comprises contextual details regarding the model's output,
containing high-level features, feature importance, and alternative
probabilities. We employ subtractive counterfactual reasoning to compute
feature importance, a method that entails analysing output variations resulting
from decomposing semantic features. Furthermore, to maintain a seamless
conversational flow, we integrate four key characteristics - social, causal,
selective, and contrastive - drawn from social science research on human
explanations into a single-shot prompt, guiding the response generation
process. Our evaluation demonstrates that explanations generated by the LLMs
encompassed these elements, indicating its potential to bridge the gap between
complex model outputs and natural language expressions.",2024-07-30,"Sule Tekkesinoglu, Lars Kunze",http://arxiv.org/pdf/2407.20990v1,cs.LG
Contrasting Deep Learning Models for Direct Respiratory Insufficiency Detection Versus Blood Oxygen Saturation Estimation,"We contrast high effectiveness of state of the art deep learning
architectures designed for general audio classification tasks, refined for
respiratory insufficiency (RI) detection and blood oxygen saturation (SpO$_2$)
estimation and classification through automated audio analysis. Recently,
multiple deep learning architectures have been proposed to detect RI in COVID
patients through audio analysis, achieving accuracy above 95% and F1-score
above 0.93. RI is a condition associated with low SpO$_2$ levels, commonly
defined as the threshold SpO$_2$ <92%. While SpO$_2$ serves as a crucial
determinant of RI, a medical doctor's diagnosis typically relies on multiple
factors. These include respiratory frequency, heart rate, SpO$_2$ levels, among
others. Here we study pretrained audio neural networks (CNN6, CNN10 and CNN14)
and the Masked Autoencoder (Audio-MAE) for RI detection, where these models
achieve near perfect accuracy, surpassing previous results. Yet, for the
regression task of estimating SpO$_2$ levels, the models achieve root mean
square error values exceeding the accepted clinical range of 3.5% for finger
oximeters. Additionally, Pearson correlation coefficients fail to surpass 0.3.
As deep learning models perform better in classification than regression, we
transform SpO$_2$-regression into a SpO$_2$-threshold binary classification
problem, with a threshold of 92%. However, this task still yields an F1-score
below 0.65. Thus, audio analysis offers valuable insights into a patient's RI
status, but does not provide accurate information about actual SpO$_2$ levels,
indicating a separation of domains in which voice and speech biomarkers may and
may not be useful in medical diagnostics under current technologies.",2024-07-30,"Marcelo Matheus Gauy, Natalia Hitomi Koza, Ricardo Mikio Morita, Gabriel Rocha Stanzione, Arnaldo Candido Junior, Larissa Cristina Berti, Anna Sara Shafferman Levin, Ester Cerdeira Sabino, Flaviane Romani Fernandes Svartman, Marcelo Finger",http://arxiv.org/pdf/2407.20989v1,cs.LG
The Stochastic Conjugate Subgradient Algorithm For Kernel Support Vector Machines,"Stochastic First-Order (SFO) methods have been a cornerstone in addressing a
broad spectrum of modern machine learning (ML) challenges. However, their
efficacy is increasingly questioned, especially in large-scale applications
where empirical evidence indicates potential performance limitations. In
response, this paper proposes an innovative method specifically designed for
kernel support vector machines (SVMs). This method not only achieves faster
convergence per iteration but also exhibits enhanced scalability when compared
to conventional SFO techniques. Diverging from traditional sample average
approximation strategies that typically frame kernel SVM as an 'all-in-one'
Quadratic Program (QP), our approach adopts adaptive sampling. This strategy
incrementally refines approximation accuracy on an 'as-needed' basis.
Crucially, this approach also inspires a decomposition-based algorithm,
effectively decomposing parameter selection from error estimation, with the
latter being independently determined for each data point. To exploit the
quadratic nature of the kernel matrix, we introduce a stochastic conjugate
subgradient method. This method preserves many benefits of first-order
approaches while adeptly handling both nonlinearity and non-smooth aspects of
the SVM problem. Thus, it extends beyond the capabilities of standard SFO
algorithms for non-smooth convex optimization. The convergence rate of this
novel method is thoroughly analyzed within this paper. Our experimental results
demonstrate that the proposed algorithm not only maintains but potentially
exceeds the scalability of SFO methods. Moreover, it significantly enhances
both speed and accuracy of the optimization process.",2024-07-30,"Di Zhang, Suvrajeet Sen",http://arxiv.org/pdf/2407.21091v1,cs.LG
Learning Optimal Signal Temporal Logic Decision Trees for Classification: A Max-Flow MILP Formulation,"This paper presents a novel framework for inferring timed temporal logic
properties from data. The dataset comprises pairs of finite-time system traces
and corresponding labels, denoting whether the traces demonstrate specific
desired behaviors, e.g. whether the ship follows a safe route or not. Our
proposed approach leverages decision-tree-based methods to infer Signal
Temporal Logic classifiers using primitive formulae. We formulate the inference
process as a mixed integer linear programming optimization problem, recursively
generating constraints to determine both data classification and tree
structure. Applying a max-flow algorithm on the resultant tree transforms the
problem into a global optimization challenge, leading to improved
classification rates compared to prior methodologies. Moreover, we introduce a
technique to reduce the number of constraints by exploiting the symmetry
inherent in STL primitives, which enhances the algorithm's time performance and
interpretability. To assess our algorithm's effectiveness and classification
performance, we conduct three case studies involving two-class, multi-class,
and complex formula classification scenarios.",2024-07-30,"Kaier Liang, Gustavo A. Cardona, Disha Kamale, Cristian-Ioan Vasile",http://arxiv.org/pdf/2407.21090v2,cs.LG
Abstractive summarization from Audio Transcription,"Currently, large language models are gaining popularity, their achievements
are used in many areas, ranging from text translation to generating answers to
queries. However, the main problem with these new machine learning algorithms
is that training such models requires large computing resources that only large
IT companies have. To avoid this problem, a number of methods (LoRA,
quantization) have been proposed so that existing models can be effectively
fine-tuned for specific tasks. In this paper, we propose an E2E (end to end)
audio summarization model using these techniques. In addition, this paper
examines the effectiveness of these approaches to the problem under
consideration and draws conclusions about the applicability of these methods.",2024-07-30,Ilia Derkach,http://arxiv.org/pdf/2408.04639v1,cs.LG
Learning Ordinality in Semantic Segmentation,"Semantic segmentation consists of predicting a semantic label for each image
pixel. While existing deep learning approaches achieve high accuracy, they
often overlook the ordinal relationships between classes, which can provide
critical domain knowledge (e.g., the pupil lies within the iris, and lane
markings are part of the road). This paper introduces novel methods for spatial
ordinal segmentation that explicitly incorporate these inter-class
dependencies. By treating each pixel as part of a structured image space rather
than as an independent observation, we propose two regularization terms and a
new metric to enforce ordinal consistency between neighboring pixels. Two loss
regularization terms and one metric are proposed for structural ordinal
segmentation, which penalizes predictions of non-ordinal adjacent classes. Five
biomedical datasets and multiple configurations of autonomous driving datasets
demonstrate the efficacy of the proposed methods. Our approach achieves
improvements in ordinal metrics and enhances generalization, with up to a 15.7%
relative increase in the Dice coefficient. Importantly, these benefits come
without additional inference time costs. This work highlights the significance
of spatial ordinal relationships in semantic segmentation and provides a
foundation for further exploration in structured image representations.",2024-07-30,"Ricardo P. M. Cruz, Rafael Cristino, Jaime S. Cardoso",http://arxiv.org/pdf/2407.20959v2,cs.LG
An Effective Dynamic Gradient Calibration Method for Continual Learning,"Continual learning (CL) is a fundamental topic in machine learning, where the
goal is to train a model with continuously incoming data and tasks. Due to the
memory limit, we cannot store all the historical data, and therefore confront
the ``catastrophic forgetting'' problem, i.e., the performance on the previous
tasks can substantially decrease because of the missing information in the
latter period. Though a number of elegant methods have been proposed, the
catastrophic forgetting phenomenon still cannot be well avoided in practice. In
this paper, we study the problem from the gradient perspective, where our aim
is to develop an effective algorithm to calibrate the gradient in each updating
step of the model; namely, our goal is to guide the model to be updated in the
right direction under the situation that a large amount of historical data are
unavailable. Our idea is partly inspired by the seminal stochastic variance
reduction methods (e.g., SVRG and SAGA) for reducing the variance of gradient
estimation in stochastic gradient descent algorithms. Another benefit is that
our approach can be used as a general tool, which is able to be incorporated
with several existing popular CL methods to achieve better performance. We also
conduct a set of experiments on several benchmark datasets to evaluate the
performance in practice.",2024-07-30,"Weichen Lin, Jiaxiang Chen, Ruomin Huang, Hu Ding",http://arxiv.org/pdf/2407.20956v1,cs.LG
How to Choose a Reinforcement-Learning Algorithm,"The field of reinforcement learning offers a large variety of concepts and
methods to tackle sequential decision-making problems. This variety has become
so large that choosing an algorithm for a task at hand can be challenging. In
this work, we streamline the process of choosing reinforcement-learning
algorithms and action-distribution families. We provide a structured overview
of existing methods and their properties, as well as guidelines for when to
choose which methods. An interactive version of these guidelines is available
online at https://rl-picker.github.io/.",2024-07-30,"Fabian Bongratz, Vladimir Golkov, Lukas Mautner, Luca Della Libera, Frederik Heetmeyer, Felix Czaja, Julian Rodemann, Daniel Cremers",http://arxiv.org/pdf/2407.20917v1,cs.LG
What Are Good Positional Encodings for Directed Graphs?,"Positional encodings (PEs) are essential for building powerful and expressive
graph neural networks and graph transformers, as they effectively capture the
relative spatial relationships between nodes. Although extensive research has
been devoted to PEs in undirected graphs, PEs for directed graphs remain
relatively unexplored. This work seeks to address this gap. We first introduce
the notion of Walk Profile, a generalization of walk-counting sequences for
directed graphs. A walk profile encompasses numerous structural features
crucial for directed graph-relevant applications, such as program analysis and
circuit performance prediction. We identify the limitations of existing PE
methods in representing walk profiles and propose a novel Multi-q Magnetic
Laplacian PE, which extends the Magnetic Laplacian eigenvector-based PE by
incorporating multiple potential factors. The new PE can provably express walk
profiles. Furthermore, we generalize prior basis-invariant neural networks to
enable the stable use of the new PE in the complex domain. Our numerical
experiments validate the expressiveness of the proposed PEs and demonstrate
their effectiveness in solving sorting network satisfiability and performing
well on general circuit benchmarks. Our code is available at
https://github.com/Graph-COM/Multi-q-Maglap.",2024-07-30,"Yinan Huang, Haoyu Wang, Pan Li",http://arxiv.org/pdf/2407.20912v2,cs.LG
Machine learning surrogates for efficient hydrologic modeling: Insights from stochastic simulations of managed aquifer recharge,"Process-based hydrologic models are invaluable tools for understanding the
terrestrial water cycle and addressing modern water resources problems.
However, many hydrologic models are computationally expensive and, depending on
the resolution and scale, simulations can take on the order of hours to days to
complete. While techniques such as uncertainty quantification and optimization
have become valuable tools for supporting management decisions, these analyses
typically require hundreds of model simulations, which are too computationally
expensive to perform with a process-based hydrologic model. To address this
gap, we assess a hybrid modeling workflow in which a process-based model is
used to generate an initial set of simulations and a machine learning (ML)
surrogate model is then trained to perform the remaining simulations required
for downstream analysis. As a case study, we apply this workflow to simulations
of variably saturated groundwater flow at a prospective managed aquifer
recharge site. We compare the accuracy and computational efficiency of several
ML architectures, including deep convolutional networks, recurrent neural
networks, vision transformers, and networks with Fourier transforms. Our
results demonstrate that ML surrogate models can achieve under 10% mean
absolute percentage error and yield order-of-magnitude runtime savings over
process-based models. Building on these findings, we examine the impacts of key
modeling choices on surrogate model accuracy and efficiency. Results show that
a normalized loss function improves training stability, while min-max data
normalization can significantly reduce error up to a factor of 10 when compared
to other treatments such as Z-score and no normalization. Downsampling input
features using an autoencoder also decreases memory requirements by training
with tensors 4% their original size. By reducing computational costs and...",2024-07-30,"Timothy Dai, Kate Maher, Zach Perzan",http://arxiv.org/pdf/2407.20902v2,cs.LG
MambaCapsule: Towards Transparent Cardiac Disease Diagnosis with Electrocardiography Using Mamba Capsule Network,"Cardiac arrhythmia, a condition characterized by irregular heartbeats, often
serves as an early indication of various heart ailments. With the advent of
deep learning, numerous innovative models have been introduced for diagnosing
arrhythmias using Electrocardiogram (ECG) signals. However, recent studies
solely focus on the performance of models, neglecting the interpretation of
their results. This leads to a considerable lack of transparency, posing a
significant risk in the actual diagnostic process. To solve this problem, this
paper introduces MambaCapsule, a deep neural networks for ECG arrhythmias
classification, which increases the explainability of the model while enhancing
the accuracy.Our model utilizes Mamba for feature extraction and Capsule
networks for prediction, providing not only a confidence score but also signal
features. Akin to the processing mechanism of human brain, the model learns
signal features and their relationship between them by reconstructing ECG
signals in the predicted selection. The model evaluation was conducted on
MIT-BIH and PTB dataset, following the AAMI standard. MambaCapsule has achieved
a total accuracy of 99.54% and 99.59% on the test sets respectively. These
results demonstrate the promising performance of under the standard test
protocol.",2024-07-30,"Yinlong Xu, Xiaoqiang Liu, Zitai Kong, Yixuan Wu, Yue Wang, Yingzhou Lu, Honghao Gao, Jian Wu, Hongxia Xu",http://arxiv.org/pdf/2407.20893v1,cs.LG
Bayesian Low-Rank LeArning (Bella): A Practical Approach to Bayesian Neural Networks,"Computational complexity of Bayesian learning is impeding its adoption in
practical, large-scale tasks. Despite demonstrations of significant merits such
as improved robustness and resilience to unseen or out-of-distribution inputs
over their non- Bayesian counterparts, their practical use has faded to near
insignificance. In this study, we introduce an innovative framework to mitigate
the computational burden of Bayesian neural networks (BNNs). Our approach
follows the principle of Bayesian techniques based on deep ensembles, but
significantly reduces their cost via multiple low-rank perturbations of
parameters arising from a pre-trained neural network. Both vanilla version of
ensembles as well as more sophisticated schemes such as Bayesian learning with
Stein Variational Gradient Descent (SVGD), previously deemed impractical for
large models, can be seamlessly implemented within the proposed framework,
called Bayesian Low-Rank LeArning (Bella). In a nutshell, i) Bella achieves a
dramatic reduction in the number of trainable parameters required to
approximate a Bayesian posterior; and ii) it not only maintains, but in some
instances, surpasses the performance of conventional Bayesian learning methods
and non-Bayesian baselines. Our results with large-scale tasks such as
ImageNet, CAMELYON17, DomainNet, VQA with CLIP, LLaVA demonstrate the
effectiveness and versatility of Bella in building highly scalable and
practical Bayesian deep models for real-world applications.",2024-07-30,"Bao Gia Doan, Afshar Shamsi, Xiao-Yu Guo, Arash Mohammadi, Hamid Alinejad-Rokny, Dino Sejdinovic, Damien Teney, Damith C. Ranasinghe, Ehsan Abbasnejad",http://arxiv.org/pdf/2407.20891v5,cs.LG
Co-Neighbor Encoding Schema: A Light-cost Structure Encoding Method for Dynamic Link Prediction,"Structure encoding has proven to be the key feature to distinguishing links
in a graph. However, Structure encoding in the temporal graph keeps changing as
the graph evolves, repeatedly computing such features can be time-consuming due
to the high-order subgraph construction. We develop the Co-Neighbor Encoding
Schema (CNES) to address this issue. Instead of recomputing the feature by the
link, CNES stores information in the memory to avoid redundant calculations.
Besides, unlike the existing memory-based dynamic graph learning method that
stores node hidden states, we introduce a hashtable-based memory to compress
the adjacency matrix for efficient structure feature construction and updating
with vector computation in parallel. Furthermore, CNES introduces a
Temporal-Diverse Memory to generate long-term and short-term structure encoding
for neighbors with different structural information. A dynamic graph learning
framework, Co-Neighbor Encoding Network (CNE-N), is proposed using the
aforementioned techniques. Extensive experiments on thirteen public datasets
verify the effectiveness and efficiency of the proposed method.",2024-07-30,"Ke Cheng, Linzhi Peng, Junchen Ye, Leilei Sun, Bowen Du",http://arxiv.org/pdf/2407.20871v1,cs.LG
Beyond the Neural Fog: Interpretable Learning for AC Optimal Power Flow,"The AC optimal power flow (AC-OPF) problem is essential for power system
operations, but its non-convex nature makes it challenging to solve. A widely
used simplification is the linearized DC optimal power flow (DC-OPF) problem,
which can be solved to global optimality, but whose optimal solution is always
infeasible in the original AC-OPF problem. Recently, neural networks (NN) have
been introduced for solving the AC-OPF problem at significantly faster
computation times. However, these methods necessitate extensive datasets, are
difficult to train, and are often viewed as black boxes, leading to resistance
from operators who prefer more transparent and interpretable solutions. In this
paper, we introduce a novel learning-based approach that merges simplicity and
interpretability, providing a bridge between traditional approximation methods
and black-box learning techniques. Our approach not only provides transparency
for operators but also achieves competitive accuracy. Numerical results across
various power networks demonstrate that our method provides accuracy comparable
to, and often surpassing, that of neural networks, particularly when training
datasets are limited.",2024-07-30,"Salvador Pineda, Juan Pérez-Ruiz, Juan Miguel Morales",http://arxiv.org/pdf/2408.05228v2,cs.LG
Breaking Agents: Compromising Autonomous LLM Agents Through Malfunction Amplification,"Recently, autonomous agents built on large language models (LLMs) have
experienced significant development and are being deployed in real-world
applications. These agents can extend the base LLM's capabilities in multiple
ways. For example, a well-built agent using GPT-3.5-Turbo as its core can
outperform the more advanced GPT-4 model by leveraging external components.
More importantly, the usage of tools enables these systems to perform actions
in the real world, moving from merely generating text to actively interacting
with their environment. Given the agents' practical applications and their
ability to execute consequential actions, it is crucial to assess potential
vulnerabilities. Such autonomous systems can cause more severe damage than a
standalone language model if compromised. While some existing research has
explored harmful actions by LLM agents, our study approaches the vulnerability
from a different perspective. We introduce a new type of attack that causes
malfunctions by misleading the agent into executing repetitive or irrelevant
actions. We conduct comprehensive evaluations using various attack methods,
surfaces, and properties to pinpoint areas of susceptibility. Our experiments
reveal that these attacks can induce failure rates exceeding 80\% in multiple
scenarios. Through attacks on implemented and deployable agents in multi-agent
scenarios, we accentuate the realistic risks associated with these
vulnerabilities. To mitigate such attacks, we propose self-examination
detection methods. However, our findings indicate these attacks are difficult
to detect effectively using LLMs alone, highlighting the substantial risks
associated with this vulnerability.",2024-07-30,"Boyang Zhang, Yicong Tan, Yun Shen, Ahmed Salem, Michael Backes, Savvas Zannettou, Yang Zhang",http://arxiv.org/pdf/2407.20859v1,cs.LG
Assessing Graphical Perception of Image Embedding Models using Channel Effectiveness,"Recent advancements in vision models have greatly improved their ability to
handle complex chart understanding tasks, like chart captioning and question
answering. However, it remains challenging to assess how these models process
charts. Existing benchmarks only roughly evaluate model performance without
evaluating the underlying mechanisms, such as how models extract image
embeddings. This limits our understanding of the model's ability to perceive
fundamental graphical components. To address this, we introduce a novel
evaluation framework to assess the graphical perception of image embedding
models. For chart comprehension, we examine two main aspects of channel
effectiveness: accuracy and discriminability of various visual channels.
Channel accuracy is assessed through the linearity of embeddings, measuring how
well the perceived magnitude aligns with the size of the stimulus.
Discriminability is evaluated based on the distances between embeddings,
indicating their distinctness. Our experiments with the CLIP model show that it
perceives channel accuracy differently from humans and shows unique
discriminability in channels like length, tilt, and curvature. We aim to
develop this work into a broader benchmark for reliable visual encoders,
enhancing models for precise chart comprehension and human-like perception in
future applications.",2024-07-30,"Soohyun Lee, Minsuk Chang, Seokhyeon Park, Jinwook Seo",http://arxiv.org/pdf/2407.20845v1,cs.LG
Lyrics Transcription for Humans: A Readability-Aware Benchmark,"Writing down lyrics for human consumption involves not only accurately
capturing word sequences, but also incorporating punctuation and formatting for
clarity and to convey contextual information. This includes song structure,
emotional emphasis, and contrast between lead and background vocals. While
automatic lyrics transcription (ALT) systems have advanced beyond producing
unstructured strings of words and are able to draw on wider context, ALT
benchmarks have not kept pace and continue to focus exclusively on words. To
address this gap, we introduce Jam-ALT, a comprehensive lyrics transcription
benchmark. The benchmark features a complete revision of the JamendoLyrics
dataset, in adherence to industry standards for lyrics transcription and
formatting, along with evaluation metrics designed to capture and assess the
lyric-specific nuances, laying the foundation for improving the readability of
lyrics. We apply the benchmark to recent transcription systems and present
additional error analysis, as well as an experimental comparison with a
classical music dataset.",2024-07-30,"Ondřej Cífka, Hendrik Schreiber, Luke Miner, Fabian-Robert Stöter",http://arxiv.org/pdf/2408.06370v1,cs.LG
Federated Knowledge Recycling: Privacy-Preserving Synthetic Data Sharing,"Federated learning has emerged as a paradigm for collaborative learning,
enabling the development of robust models without the need to centralise
sensitive data. However, conventional federated learning techniques have
privacy and security vulnerabilities due to the exposure of models, parameters
or updates, which can be exploited as an attack surface. This paper presents
Federated Knowledge Recycling (FedKR), a cross-silo federated learning approach
that uses locally generated synthetic data to facilitate collaboration between
institutions. FedKR combines advanced data generation techniques with a dynamic
aggregation process to provide greater security against privacy attacks than
existing methods, significantly reducing the attack surface. Experimental
results on generic and medical datasets show that FedKR achieves competitive
performance, with an average improvement in accuracy of 4.24% compared to
training models from local data, demonstrating particular effectiveness in data
scarcity scenarios.",2024-07-30,"Eugenio Lomurno, Matteo Matteucci",http://arxiv.org/pdf/2407.20830v1,cs.LG
How to Measure the Intelligence of Large Language Models?,"With the release of ChatGPT and other large language models (LLMs) the
discussion about the intelligence, possibilities, and risks, of current and
future models have seen large attention. This discussion included much debated
scenarios about the imminent rise of so-called ""super-human"" AI, i.e., AI
systems that are orders of magnitude smarter than humans. In the spirit of Alan
Turing, there is no doubt that current state-of-the-art language models already
pass his famous test. Moreover, current models outperform humans in several
benchmark tests, so that publicly available LLMs have already become versatile
companions that connect everyday life, industry and science. Despite their
impressive capabilities, LLMs sometimes fail completely at tasks that are
thought to be trivial for humans. In other cases, the trustworthiness of LLMs
becomes much more elusive and difficult to evaluate. Taking the example of
academia, language models are capable of writing convincing research articles
on a given topic with only little input. Yet, the lack of trustworthiness in
terms of factual consistency or the existence of persistent hallucinations in
AI-generated text bodies has led to a range of restrictions for AI-based
content in many scientific journals. In view of these observations, the
question arises as to whether the same metrics that apply to human intelligence
can also be applied to computational methods and has been discussed
extensively. In fact, the choice of metrics has already been shown to
dramatically influence assessments on potential intelligence emergence. Here,
we argue that the intelligence of LLMs should not only be assessed by
task-specific statistical metrics, but separately in terms of qualitative and
quantitative measures.",2024-07-30,"Nils Körber, Silvan Wehrli, Christopher Irrgang",http://arxiv.org/pdf/2407.20828v1,cs.LG
DyGKT: Dynamic Graph Learning for Knowledge Tracing,"Knowledge Tracing aims to assess student learning states by predicting their
performance in answering questions. Different from the existing research which
utilizes fixed-length learning sequence to obtain the student states and
regards KT as a static problem, this work is motivated by three dynamical
characteristics: 1) The scales of students answering records are constantly
growing; 2) The semantics of time intervals between the records vary; 3) The
relationships between students, questions and concepts are evolving. The three
dynamical characteristics above contain the great potential to revolutionize
the existing knowledge tracing methods. Along this line, we propose a Dynamic
Graph-based Knowledge Tracing model, namely DyGKT. In particular, a
continuous-time dynamic question-answering graph for knowledge tracing is
constructed to deal with the infinitely growing answering behaviors, and it is
worth mentioning that it is the first time dynamic graph learning technology is
used in this field. Then, a dual time encoder is proposed to capture long-term
and short-term semantics among the different time intervals. Finally, a
multiset indicator is utilized to model the evolving relationships between
students, questions, and concepts via the graph structural feature. Numerous
experiments are conducted on five real-world datasets, and the results
demonstrate the superiority of our model. All the used resources are publicly
available at https://github.com/PengLinzhi/DyGKT.",2024-07-30,"Ke Cheng, Linzhi Peng, Pengyang Wang, Junchen Ye, Leilei Sun, Bowen Du",http://arxiv.org/pdf/2407.20824v1,cs.LG
Robust Load Prediction of Power Network Clusters Based on Cloud-Model-Improved Transformer,"Load data from power network clusters indicates economic development in each
area, crucial for predicting regional trends and guiding power enterprise
decisions. The Transformer model, a leading method for load prediction, faces
challenges modeling historical data due to variables like weather, events,
festivals, and data volatility. To tackle this, the cloud model's fuzzy feature
is utilized to manage uncertainties effectively. Presenting an innovative
approach, the Cloud Model Improved Transformer (CMIT) method integrates the
Transformer model with the cloud model utilizing the particle swarm
optimization algorithm, with the aim of achieving robust and precise power load
predictions. Through comparative experiments conducted on 31 real datasets
within a power network cluster, it is demonstrated that CMIT significantly
surpasses the Transformer model in terms of prediction accuracy, thereby
highlighting its effectiveness in enhancing forecasting capabilities within the
power network cluster sector.",2024-07-30,"Cheng Jiang, Gang Lu, Xue Ma, Di Wu",http://arxiv.org/pdf/2407.20817v1,cs.LG
ARCLE: The Abstraction and Reasoning Corpus Learning Environment for Reinforcement Learning,"This paper introduces ARCLE, an environment designed to facilitate
reinforcement learning research on the Abstraction and Reasoning Corpus (ARC).
Addressing this inductive reasoning benchmark with reinforcement learning
presents these challenges: a vast action space, a hard-to-reach goal, and a
variety of tasks. We demonstrate that an agent with proximal policy
optimization can learn individual tasks through ARCLE. The adoption of
non-factorial policies and auxiliary losses led to performance enhancements,
effectively mitigating issues associated with action spaces and goal
attainment. Based on these insights, we propose several research directions and
motivations for using ARCLE, including MAML, GFlowNets, and World Models.",2024-07-30,"Hosung Lee, Sejin Kim, Seungpil Lee, Sanha Hwang, Jihwan Lee, Byung-Jun Lee, Sundong Kim",http://arxiv.org/pdf/2407.20806v1,cs.LG
"AhmedML: High-Fidelity Computational Fluid Dynamics Dataset for Incompressible, Low-Speed Bluff Body Aerodynamics","The development of Machine Learning (ML) methods for Computational Fluid
Dynamics (CFD) is currently limited by the lack of openly available training
data. This paper presents a new open-source dataset comprising of high
fidelity, scale-resolving CFD simulations of 500 geometric variations of the
Ahmed Car Body - a simplified car-like shape that exhibits many of the flow
topologies that are present on bluff bodies such as road vehicles. The dataset
contains simulation results that exhibit a broad set of fundamental flow
physics such as geometry and pressure-induced flow separation as well as 3D
vortical structures. Each variation of the Ahmed car body were run using a
high-fidelity, time-accurate, hybrid Reynolds-Averaged Navier-Stokes (RANS) -
Large-Eddy Simulation (LES) turbulence modelling approach using the open-source
CFD code OpenFOAM. The dataset contains boundary, volume, geometry, and
time-averaged forces/moments in widely used open-source formats. In addition,
the OpenFOAM case setup is provided so that others can reproduce or extend the
dataset. This represents to the authors knowledge, the first open-source
large-scale dataset using high-fidelity CFD methods for the widely used Ahmed
car body that is available to freely download with a permissive license
(CC-BY-SA).",2024-07-30,"Neil Ashton, Danielle C. Maddix, Samuel Gundry, Parisa M. Shabestari",http://arxiv.org/pdf/2407.20801v1,cs.LG
Diffusion Augmented Agents: A Framework for Efficient Exploration and Transfer Learning,"We introduce Diffusion Augmented Agents (DAAG), a novel framework that
leverages large language models, vision language models, and diffusion models
to improve sample efficiency and transfer learning in reinforcement learning
for embodied agents. DAAG hindsight relabels the agent's past experience by
using diffusion models to transform videos in a temporally and geometrically
consistent way to align with target instructions with a technique we call
Hindsight Experience Augmentation. A large language model orchestrates this
autonomous process without requiring human supervision, making it well-suited
for lifelong learning scenarios. The framework reduces the amount of
reward-labeled data needed to 1) finetune a vision language model that acts as
a reward detector, and 2) train RL agents on new tasks. We demonstrate the
sample efficiency gains of DAAG in simulated robotics environments involving
manipulation and navigation. Our results show that DAAG improves learning of
reward detectors, transferring past experience, and acquiring new tasks - key
abilities for developing efficient lifelong learning agents. Supplementary
material and visualizations are available on our website
https://sites.google.com/view/diffusion-augmented-agents/",2024-07-30,"Norman Di Palo, Leonard Hasenclever, Jan Humplik, Arunkumar Byravan",http://arxiv.org/pdf/2407.20798v1,cs.LG
Be aware of overfitting by hyperparameter optimization!,"Hyperparameter optimization is very frequently employed in machine learning.
However, an optimization of a large space of parameters could result in
overfitting of models. In recent studies on solubility prediction the authors
collected seven thermodynamic and kinetic solubility datasets from different
data sources. They used state-of-the-art graph-based methods and compared
models developed for each dataset using different data cleaning protocols and
hyperparameter optimization. In our study we showed that hyperparameter
optimization did not always result in better models, possibly due to
overfitting when using the same statistical measures. Similar results could be
calculated using pre-set hyperparameters, reducing the computational effort by
around 10,000 times. We also extended the previous analysis by adding a
representation learning method based on Natural Language Processing of smiles
called Transformer CNN. We show that across all analyzed sets using exactly the
same protocol, Transformer CNN provided better results than graph-based methods
for 26 out of 28 pairwise comparisons by using only a tiny fraction of time as
compared to other methods. Last but not least we stressed the importance of
comparing calculation results using exactly the same statistical measures.",2024-07-30,"Igor V. Tetko, Ruud van Deursen, Guillaume Godin",http://arxiv.org/pdf/2407.20786v2,cs.LG
Interpretable Pre-Trained Transformers for Heart Time-Series Data,"Decoder-only transformers are the backbone of the popular generative
pre-trained transformer (GPT) series of large language models. In this work, we
employ this framework to the analysis of clinical heart time-series data, to
create two pre-trained general purpose cardiac models, termed PPG-PT and
ECG-PT. We place a special emphasis on making both such pre-trained models
fully interpretable. This is achieved firstly through aggregate attention maps
which show that, in order to make predictions, the model focuses on similar
points in previous cardiac cycles and gradually broadens its attention in
deeper layers. Next, we show that tokens with the same value, which occur at
different distinct points in the electrocardiography (ECG) and
photoplethysmography (PPG) cycle, form separate clusters in high dimensional
space. The clusters form according to phase, as the tokens propagate through
the transformer blocks. Finally, we highlight that individual attention heads
respond to specific physiologically relevent features, such as the dicrotic
notch in PPG and the P-wave in ECG. It is also demonstrated that these
pre-trained models are straightforward to fine-tune for tasks such as
classification of atrial fibrillation (AF), and beat detection in
photoplethysmography. For the example of AF, the fine-tuning took 11 minutes of
computer time, and achieved the respective leave-one-subject-out AUCs of 0.99
and 0.93 for ECG and PPG within the MIMIC Perform AF dataset. In addition, the
fine-tuned beat detector achieved a state-of-the-art F1 score of 98%, as well
as uniquely providing a beat confidence level which acts as a signal quality
estimator. Importantly, the fine-tuned models for AF screening are also fully
explainable, with attention shifting to regions in the context that are
strongly indicative of atrial fibrillation.",2024-07-30,"Harry J. Davies, James Monsen, Danilo P. Mandic",http://arxiv.org/pdf/2407.20775v2,cs.LG
HyperMM : Robust Multimodal Learning with Varying-sized Inputs,"Combining multiple modalities carrying complementary information through
multimodal learning (MML) has shown considerable benefits for diagnosing
multiple pathologies. However, the robustness of multimodal models to missing
modalities is often overlooked. Most works assume modality completeness in the
input data, while in clinical practice, it is common to have incomplete
modalities. Existing solutions that address this issue rely on modality
imputation strategies before using supervised learning models. These
strategies, however, are complex, computationally costly and can strongly
impact subsequent prediction models. Hence, they should be used with parsimony
in sensitive applications such as healthcare. We propose HyperMM, an end-to-end
framework designed for learning with varying-sized inputs. Specifically, we
focus on the task of supervised MML with missing imaging modalities without
using imputation before training. We introduce a novel strategy for training a
universal feature extractor using a conditional hypernetwork, and propose a
permutation-invariant neural network that can handle inputs of varying
dimensions to process the extracted features, in a two-phase task-agnostic
framework. We experimentally demonstrate the advantages of our method in two
tasks: Alzheimer's disease detection and breast cancer classification. We
demonstrate that our strategy is robust to high rates of missing data and that
its flexibility allows it to handle varying-sized datasets beyond the scenario
of missing modalities.",2024-07-30,"Hava Chaptoukaev, Vincenzo Marcianó, Francesco Galati, Maria A. Zuluaga",http://arxiv.org/pdf/2407.20768v1,cs.LG
Efficient Quantum One-Class Support Vector Machines for Anomaly Detection Using Randomized Measurements and Variable Subsampling,"Quantum one-class support vector machines leverage the advantage of quantum
kernel methods for semi-supervised anomaly detection. However, their quadratic
time complexity with respect to data size poses challenges when dealing with
large datasets. In recent work, quantum randomized measurements kernels and
variable subsampling were proposed, as two independent methods to address this
problem. The former achieves higher average precision, but suffers from
variance, while the latter achieves linear complexity to data size and has
lower variance. The current work focuses instead on combining these two
methods, along with rotated feature bagging, to achieve linear time complexity
both to data size and to number of features. Despite their instability, the
resulting models exhibit considerably higher performance and faster training
and testing times.",2024-07-30,"Michael Kölle, Afrae Ahouzi, Pascal Debus, Elif Çetiner, Robert Müller, Daniëlle Schuman, Claudia Linnhoff-Popien",http://arxiv.org/pdf/2407.20753v1,cs.LG
Improving PINNs By Algebraic Inclusion of Boundary and Initial Conditions,"""AI for Science"" aims to solve fundamental scientific problems using AI
techniques. As most physical phenomena can be described as Partial Differential
Equations (PDEs) , approximating their solutions using neural networks has
evolved as a central component of scientific-ML. Physics-Informed Neural
Networks (PINNs) is the general method that has evolved for this task but its
training is well-known to be very unstable. In this work we explore the
possibility of changing the model being trained from being just a neural
network to being a non-linear transformation of it - one that algebraically
includes the boundary/initial conditions. This reduces the number of terms in
the loss function than the standard PINN losses. We demonstrate that our
modification leads to significant performance gains across a range of benchmark
tasks, in various dimensions and without having to tweak the training
algorithm. Our conclusions are based on conducting hundreds of experiments, in
the fully unsupervised setting, over multiple linear and non-linear PDEs set to
exactly solvable scenarios, which lends to a concrete measurement of our
performance gains in terms of order(s) of magnitude lower fractional errors
being achieved, than by standard PINNs. The code accompanying this manuscript
is publicly available at,
https://github.com/MorganREN/Improving-PINNs-By-Algebraic-Inclusion-of-Boundary-and-Initial-Conditions",2024-07-30,"Mohan Ren, Zhihao Fang, Keren Li, Anirbit Mukherjee",http://arxiv.org/pdf/2407.20741v1,cs.LG
Efficient Pareto Manifold Learning with Low-Rank Structure,"Multi-task learning, which optimizes performance across multiple tasks, is
inherently a multi-objective optimization problem. Various algorithms are
developed to provide discrete trade-off solutions on the Pareto front.
Recently, continuous Pareto front approximations using a linear combination of
base networks have emerged as a compelling strategy. However, it suffers from
scalability issues when the number of tasks is large. To address this issue, we
propose a novel approach that integrates a main network with several low-rank
matrices to efficiently learn the Pareto manifold. It significantly reduces the
number of parameters and facilitates the extraction of shared features. We also
introduce orthogonal regularization to further bolster performance. Extensive
experimental results demonstrate that the proposed approach outperforms
state-of-the-art baselines, especially on datasets with a large number of
tasks.",2024-07-30,"Weiyu Chen, James T. Kwok",http://arxiv.org/pdf/2407.20734v1,cs.LG
On Biases in a UK Biobank-based Retinal Image Classification Model,"Recent work has uncovered alarming disparities in the performance of machine
learning models in healthcare. In this study, we explore whether such
disparities are present in the UK Biobank fundus retinal images by training and
evaluating a disease classification model on these images. We assess possible
disparities across various population groups and find substantial differences
despite strong overall performance of the model. In particular, we discover
unfair performance for certain assessment centres, which is surprising given
the rigorous data standardisation protocol. We compare how these differences
emerge and apply a range of existing bias mitigation methods to each one. A key
insight is that each disparity has unique properties and responds differently
to the mitigation methods. We also find that these methods are largely unable
to enhance fairness, highlighting the need for better bias mitigation methods
tailored to the specific type of bias.",2024-07-30,"Anissa Alloula, Rima Mustafa, Daniel R McGowan, Bartłomiej W. Papież",http://arxiv.org/pdf/2408.02676v2,cs.LG
Persistent Sampling: Enhancing the Efficiency of Sequential Monte Carlo,"Sequential Monte Carlo (SMC) samplers are powerful tools for Bayesian
inference but suffer from high computational costs due to their reliance on
large particle ensembles for accurate estimates. We introduce persistent
sampling (PS), an extension of SMC that systematically retains and reuses
particles from all prior iterations to construct a growing, weighted ensemble.
By leveraging multiple importance sampling and resampling from a mixture of
historical distributions, PS mitigates the need for excessively large particle
counts, directly addressing key limitations of SMC such as particle
impoverishment and mode collapse. Crucially, PS achieves this without
additional likelihood evaluations-weights for persistent particles are computed
using cached likelihood values. This framework not only yields more accurate
posterior approximations but also produces marginal likelihood estimates with
significantly lower variance, enhancing reliability in model comparison.
Furthermore, the persistent ensemble enables efficient adaptation of transition
kernels by leveraging a larger, decorrelated particle pool. Experiments on
high-dimensional Gaussian mixtures, hierarchical models, and non-convex targets
demonstrate that PS consistently outperforms standard SMC and related variants,
including recycled and waste-free SMC, achieving substantial reductions in mean
squared error for posterior expectations and evidence estimates, all at reduced
computational cost. PS thus establishes itself as a robust, scalable, and
efficient alternative for complex Bayesian inference tasks.",2024-07-30,"Minas Karamanis, Uroš Seljak",http://arxiv.org/pdf/2407.20722v2,cs.LG
PIP: Prototypes-Injected Prompt for Federated Class Incremental Learning,"Federated Class Incremental Learning (FCIL) is a new direction in continual
learning (CL) for addressing catastrophic forgetting and non-IID data
distribution simultaneously. Existing FCIL methods call for high communication
costs and exemplars from previous classes. We propose a novel rehearsal-free
method for FCIL named prototypes-injected prompt (PIP) that involves 3 main
ideas: a) prototype injection on prompt learning, b) prototype augmentation,
and c) weighted Gaussian aggregation on the server side. Our experiment result
shows that the proposed method outperforms the current state of the arts
(SOTAs) with a significant improvement (up to 33%) in CIFAR100, MiniImageNet
and TinyImageNet datasets. Our extensive analysis demonstrates the robustness
of PIP in different task sizes, and the advantage of requiring smaller
participating local clients, and smaller global rounds. For further study,
source codes of PIP, baseline, and experimental logs are shared publicly in
https://github.com/anwarmaxsum/PIP.",2024-07-30,"Muhammad Anwar Ma'sum, Mahardhika Pratama, Savitha Ramasamy, Lin Liu, Habibullah Habibullah, Ryszard Kowalczyk",http://arxiv.org/pdf/2407.20705v1,cs.LG
Industrial-Grade Smart Troubleshooting through Causal Technical Language Processing: a Proof of Concept,"This paper describes the development of a causal diagnosis approach for
troubleshooting an industrial environment on the basis of the technical
language expressed in Return on Experience records. The proposed method
leverages the vectorized linguistic knowledge contained in the distributed
representation of a Large Language Model, and the causal associations entailed
by the embedded failure modes and mechanisms of the industrial assets. The
paper presents the elementary but essential concepts of the solution, which is
conceived as a causality-aware retrieval augmented generation system, and
illustrates them experimentally on a real-world Predictive Maintenance setting.
Finally, it discusses avenues of improvement for the maturity of the utilized
causal technology to meet the robustness challenges of increasingly complex
scenarios in the industry.",2024-07-30,"Alexandre Trilla, Ossee Yiboe, Nenad Mijatovic, Jordi Vitrià",http://arxiv.org/pdf/2407.20700v1,cs.LG
Weak neural variational inference for solving Bayesian inverse problems without forward models: applications in elastography,"In this paper, we introduce a novel, data-driven approach for solving
high-dimensional Bayesian inverse problems based on partial differential
equations (PDEs), called Weak Neural Variational Inference (WNVI). The method
complements real measurements with virtual observations derived from the
physical model. In particular, weighted residuals are employed as probes to the
governing PDE in order to formulate and solve a Bayesian inverse problem
without ever formulating nor solving a forward model. The formulation treats
the state variables of the physical model as latent variables, inferred using
Stochastic Variational Inference (SVI), along with the usual unknowns. The
approximate posterior employed uses neural networks to approximate the inverse
mapping from state variables to the unknowns. We illustrate the proposed method
in a biomedical setting where we infer spatially varying material properties
from noisy tissue deformation data. We demonstrate that WNVI is not only as
accurate and more efficient than traditional methods that rely on repeatedly
solving the (non)linear forward problem as a black-box, but it can also handle
ill-posed forward problems (e.g., with insufficient boundary conditions).",2024-07-30,"Vincent C. Scholz, Yaohua Zang, Phaedon-Stelios Koutsourelakis",http://arxiv.org/pdf/2407.20697v1,cs.LG
Time Series Anomaly Detection with CNN for Environmental Sensors in Healthcare-IoT,"This research develops a new method to detect anomalies in time series data
using Convolutional Neural Networks (CNNs) in healthcare-IoT. The proposed
method creates a Distributed Denial of Service (DDoS) attack using an IoT
network simulator, Cooja, which emulates environmental sensors such as
temperature and humidity. CNNs detect anomalies in time series data, resulting
in a 92\% accuracy in identifying possible attacks.",2024-07-30,"Mirza Akhi Khatun, Mangolika Bhattacharya, Ciarán Eising, Lubna Luxmi Dhirani",http://arxiv.org/pdf/2407.20695v1,cs.LG
Detecting Causality in the Frequency Domain with Cross-Mapping Coherence,"Understanding causal relationships within a system is crucial for uncovering
its underlying mechanisms. Causal discovery methods, which facilitate the
construction of such models from time-series data, hold the potential to
significantly advance scientific and engineering fields.
  This study introduces the Cross-Mapping Coherence (CMC) method, designed to
reveal causal connections in the frequency domain between time series. CMC
builds upon nonlinear state-space reconstruction and extends the Convergent
Cross-Mapping algorithm to the frequency domain by utilizing coherence metrics
for evaluation. We tested the Cross-Mapping Coherence method using simulations
of logistic maps, Lorenz systems, Kuramoto oscillators, and the Wilson-Cowan
model of the visual cortex. CMC accurately identified the direction of causal
connections in all simulated scenarios. When applied to the Wilson-Cowan model,
CMC yielded consistent results similar to spectral Granger causality.
  Furthermore, CMC exhibits high sensitivity in detecting weak connections,
demonstrates sample efficiency, and maintains robustness in the presence of
noise.
  In conclusion, the capability to determine directed causal influences across
different frequency bands allows CMC to provide valuable insights into the
dynamics of complex, nonlinear systems.",2024-07-30,"Zsigmond Benkő, Bálint Varga, Marcell Stippinger, Zoltán Somogyvári",http://arxiv.org/pdf/2407.20694v1,cs.LG
The Susceptibility of Example-Based Explainability Methods to Class Outliers,"This study explores the impact of class outliers on the effectiveness of
example-based explainability methods for black-box machine learning models. We
reformulate existing explainability evaluation metrics, such as correctness and
relevance, specifically for example-based methods, and introduce a new metric,
distinguishability. Using these metrics, we highlight the shortcomings of
current example-based explainability methods, including those who attempt to
suppress class outliers. We conduct experiments on two datasets, a text
classification dataset and an image classification dataset, and evaluate the
performance of four state-of-the-art explainability methods. Our findings
underscore the need for robust techniques to tackle the challenges posed by
class outliers.",2024-07-30,"Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose",http://arxiv.org/pdf/2407.20678v2,cs.LG
Rethinking the Function of Neurons in KANs,"The neurons of Kolmogorov-Arnold Networks (KANs) perform a simple summation
motivated by the Kolmogorov-Arnold representation theorem, which asserts that
sum is the only fundamental multivariate function. In this work, we investigate
the potential for identifying an alternative multivariate function for KAN
neurons that may offer increased practical utility. Our empirical research
involves testing various multivariate functions in KAN neurons across a range
of benchmark Machine Learning tasks.
  Our findings indicate that substituting the sum with the average function in
KAN neurons results in significant performance enhancements compared to
traditional KANs. Our study demonstrates that this minor modification
contributes to the stability of training by confining the input to the spline
within the effective range of the activation function. Our implementation and
experiments are available at: \url{https://github.com/Ghaith81/dropkan}",2024-07-30,Mohammed Ghaith Altarabichi,http://arxiv.org/pdf/2407.20667v1,cs.LG
DocXPand-25k: a large and diverse benchmark dataset for identity documents analysis,"Identity document (ID) image analysis has become essential for many online
services, like bank account opening or insurance subscription. In recent years,
much research has been conducted on subjects like document localization, text
recognition and fraud detection, to achieve a level of accuracy reliable enough
to automatize identity verification. However, there are only a few available
datasets to benchmark ID analysis methods, mainly because of privacy
restrictions, security requirements and legal reasons.
  In this paper, we present the DocXPand-25k dataset, which consists of 24,994
richly labeled IDs images, generated using custom-made vectorial templates
representing nine fictitious ID designs, including four identity cards, two
residence permits and three passports designs. These synthetic IDs feature
artificially generated personal information (names, dates, identifiers, faces,
barcodes, ...), and present a rich diversity in the visual layouts and textual
contents.
  We collected about 5.8k diverse backgrounds coming from real-world photos,
scans and screenshots of IDs to guarantee the variety of the backgrounds. The
software we wrote to generate these images has been published
(https://github.com/QuickSign/docxpand/) under the terms of the MIT license,
and our dataset has been published
(https://github.com/QuickSign/docxpand/releases/tag/v1.0.0) under the terms of
the CC-BY-NC-SA 4.0 License.",2024-07-30,"Julien Lerouge, Guillaume Betmont, Thomas Bres, Evgeny Stepankevich, Alexis Bergès",http://arxiv.org/pdf/2407.20662v1,cs.LG
Prompt-Driven Contrastive Learning for Transferable Adversarial Attacks,"Recent vision-language foundation models, such as CLIP, have demonstrated
superior capabilities in learning representations that can be transferable
across diverse range of downstream tasks and domains. With the emergence of
such powerful models, it has become crucial to effectively leverage their
capabilities in tackling challenging vision tasks. On the other hand, only a
few works have focused on devising adversarial examples that transfer well to
both unknown domains and model architectures. In this paper, we propose a novel
transfer attack method called PDCL-Attack, which leverages the CLIP model to
enhance the transferability of adversarial perturbations generated by a
generative model-based attack framework. Specifically, we formulate an
effective prompt-driven feature guidance by harnessing the semantic
representation power of text, particularly from the ground-truth class labels
of input images. To the best of our knowledge, we are the first to introduce
prompt learning to enhance the transferable generative attacks. Extensive
experiments conducted across various cross-domain and cross-model settings
empirically validate our approach, demonstrating its superiority over
state-of-the-art methods.",2024-07-30,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",http://arxiv.org/pdf/2407.20657v2,cs.LG
Efficient Multi-Objective Neural Architecture Search via Pareto Dominance-based Novelty Search,"Neural Architecture Search (NAS) aims to automate the discovery of
high-performing deep neural network architectures. Traditional objective-based
NAS approaches typically optimize a certain performance metric (e.g.,
prediction accuracy), overlooking large parts of the architecture search space
that potentially contain interesting network configurations. Furthermore,
objective-driven population-based metaheuristics in complex search spaces often
quickly exhaust population diversity and succumb to premature convergence to
local optima. This issue becomes more complicated in NAS when performance
objectives do not fully align with the actual performance of the candidate
architectures, as is often the case with training-free metrics. While
training-free metrics have gained popularity for their rapid performance
estimation of candidate architectures without incurring computation-heavy
network training, their effective incorporation into NAS remains a challenge.
This paper presents the Pareto Dominance-based Novelty Search for
multi-objective NAS with Multiple Training-Free metrics (MTF-PDNS). Unlike
conventional NAS methods that optimize explicit objectives, MTF-PDNS promotes
population diversity by utilizing a novelty score calculated based on multiple
training-free performance and complexity metrics, thereby yielding a broader
exploration of the search space. Experimental results on standard NAS benchmark
suites demonstrate that MTF-PDNS outperforms conventional methods driven by
explicit objectives in terms of convergence speed, diversity maintenance,
architecture transferability, and computational costs.",2024-07-30,"An Vo, Ngoc Hoang Luong",http://arxiv.org/pdf/2407.20656v1,cs.LG
FACL-Attack: Frequency-Aware Contrastive Learning for Transferable Adversarial Attacks,"Deep neural networks are known to be vulnerable to security risks due to the
inherent transferable nature of adversarial examples. Despite the success of
recent generative model-based attacks demonstrating strong transferability, it
still remains a challenge to design an efficient attack strategy in a
real-world strict black-box setting, where both the target domain and model
architectures are unknown. In this paper, we seek to explore a feature
contrastive approach in the frequency domain to generate adversarial examples
that are robust in both cross-domain and cross-model settings. With that goal
in mind, we propose two modules that are only employed during the training
phase: a Frequency-Aware Domain Randomization (FADR) module to randomize
domain-variant low- and high-range frequency components and a
Frequency-Augmented Contrastive Learning (FACL) module to effectively separate
domain-invariant mid-frequency features of clean and perturbed image. We
demonstrate strong transferability of our generated adversarial perturbations
through extensive cross-domain and cross-model experiments, while keeping the
inference time complexity.",2024-07-30,"Hunmin Yang, Jongoh Jeong, Kuk-Jin Yoon",http://arxiv.org/pdf/2407.20653v1,cs.LG
Towards Generalizable Reinforcement Learning via Causality-Guided Self-Adaptive Representations,"General intelligence requires quick adaption across tasks. While existing
reinforcement learning (RL) methods have made progress in generalization, they
typically assume only distribution changes between source and target domains.
In this paper, we explore a wider range of scenarios where not only the
distribution but also the environment spaces may change. For example, in the
CoinRun environment, we train agents from easy levels and generalize them to
difficulty levels where there could be new enemies that have never occurred
before. To address this challenging setting, we introduce a causality-guided
self-adaptive representation-based approach, called CSR, that equips the agent
to generalize effectively across tasks with evolving dynamics. Specifically, we
employ causal representation learning to characterize the latent causal
variables within the RL system. Such compact causal representations uncover the
structural relationships among variables, enabling the agent to autonomously
determine whether changes in the environment stem from distribution shifts or
variations in space, and to precisely locate these changes. We then devise a
three-step strategy to fine-tune the causal model under different scenarios
accordingly. Empirical experiments show that CSR efficiently adapts to the
target domains with only a few samples and outperforms state-of-the-art
baselines on a wide range of scenarios, including our simulated environments,
CartPole, CoinRun and Atari games.",2024-07-30,"Yupei Yang, Biwei Huang, Fan Feng, Xinyue Wang, Shikui Tu, Lei Xu",http://arxiv.org/pdf/2407.20651v4,cs.LG
No learning rates needed: Introducing SALSA -- Stable Armijo Line Search Adaptation,"In recent studies, line search methods have been demonstrated to
significantly enhance the performance of conventional stochastic gradient
descent techniques across various datasets and architectures, while making an
otherwise critical choice of learning rate schedule superfluous. In this paper,
we identify problems of current state-of-the-art of line search methods,
propose enhancements, and rigorously assess their effectiveness. Furthermore,
we evaluate these methods on orders of magnitude larger datasets and more
complex data domains than previously done. More specifically, we enhance the
Armijo line search method by speeding up its computation and incorporating a
momentum term into the Armijo criterion, making it better suited for stochastic
mini-batching. Our optimization approach outperforms both the previous Armijo
implementation and a tuned learning rate schedule for the Adam and SGD
optimizers. Our evaluation covers a diverse range of architectures, such as
Transformers, CNNs, and MLPs, as well as data domains, including NLP and image
data.
  Our work is publicly available as a Python package, which provides a simple
Pytorch optimizer.",2024-07-30,"Philip Kenneweg, Tristan Kenneweg, Fabian Fumagalli, Barbara Hammer",http://arxiv.org/pdf/2407.20650v1,cs.LG
Leveraging Multi-facet Paths for Heterogeneous Graph Representation Learning,"Recent advancements in graph neural networks (GNNs) and heterogeneous GNNs
(HGNNs) have advanced node embeddings and relationship learning for various
tasks. However, existing methods often rely on domain-specific predefined
meta-paths, which are coarse-grained and focus solely on aspects like node
type, limiting their ability to capture complex interactions. We introduce
MF2Vec, a model that uses multi-faceted (fine-grained) paths instead of
predefined meta-paths. MF2Vec extracts paths via random walks and generates
multi-faceted vectors, ignoring predefined schemas. This method learns diverse
aspects of nodes and their relationships, constructs a homogeneous network, and
creates node embeddings for classification, link prediction, and clustering.
Extensive experiments show that MF2Vec outperforms existing methods, offering a
more flexible and comprehensive framework for analyzing complex networks. The
code is available at https://anonymous.4open.science/r/MF2Vec-6ABC.",2024-07-30,"JongWoo Kim, SeongYeub Chu, HyeongMin Park, Bryan Wong, MunYong Yi",http://arxiv.org/pdf/2407.20648v2,cs.LG
Improved Bounds for Pure Private Agnostic Learning: Item-Level and User-Level Privacy,"Machine Learning has made remarkable progress in a wide range of fields. In
many scenarios, learning is performed on datasets involving sensitive
information, in which privacy protection is essential for learning algorithms.
In this work, we study pure private learning in the agnostic model -- a
framework reflecting the learning process in practice. We examine the number of
users required under item-level (where each user contributes one example) and
user-level (where each user contributes multiple examples) privacy and derive
several improved upper bounds. For item-level privacy, our algorithm achieves a
near optimal bound for general concept classes. We extend this to the
user-level setting, rendering a tighter upper bound than the one proved by
Ghazi et al. (2023). Lastly, we consider the problem of learning thresholds
under user-level privacy and present an algorithm with a nearly tight user
complexity.",2024-07-30,"Bo Li, Wei Wang, Peng Ye",http://arxiv.org/pdf/2407.20640v2,cs.LG
"SharkTrack: an accurate, generalisable software for streamlining shark and ray underwater video analysis","Elasmobranchs (shark sand rays) represent a critical component of marine
ecosystems. Yet, they are experiencing global population declines and effective
monitoring of populations is essential to their protection. Underwater
stationary videos, such as those from Baited Remote Underwater Video Stations
(BRUVS), are critical for understanding elasmobranch spatial ecology and
abundance. However, processing these videos requires time-consuming manual
analysis that can delay conservation. To address this challenge, we developed
SharkTrack, a semi-automatic underwater video analysis software. SharkTrack
uses Convolutional Neural Networks (CNN) and Multi-Object Tracking to
automatically detect and track elasmobranchs and provides an annotation
pipeline to manually classify elasmobranch species and compute species-specific
MaxN (ssMaxN), the standard metric of relative abundance. When tested on BRUVS
footage from locations unseen by the CNN model during training, SharkTrack
computed ssMaxN with 89% accuracy over 207 hours of footage. The semi-automatic
SharkTrack pipeline required two minutes of manual classification per hour of
video, an estimated 95% reduction of manual analysis time compared to
traditional methods. Furthermore, we demonstrate SharkTrack accuracy across
diverse marine ecosystems and elasmobranch species, an advancement compared to
previous models, which were limited to specific species or locations.
SharkTrack applications extend beyond BRUVS, facilitating the analysis of any
underwater stationary video. By making video analysis faster and more
accessible, SharkTrack enables research and conservation organisations to
monitor elasmobranch populations more efficiently, thereby improving
conservation efforts. To further support these goals, we provide public access
to the SharkTrack software.",2024-07-30,"Filippo Varini, Joel H. Gayford, Jeremy Jenrette, Matthew J. Witt, Francesco Garzon, Francesco Ferretti, Sophie Wilday, Mark E. Bond, Michael R. Heithaus, Danielle Robinson, Devon Carter, Najee Gumbs, Vincent Webster, Ben Glocker",http://arxiv.org/pdf/2407.20623v3,cs.LG
Accelerating Large Language Model Inference with Self-Supervised Early Exits,"This paper presents a novel technique for accelerating inference in large,
pre-trained language models (LLMs) by introducing early exits during inference.
The computational demands of these models, used across a wide range of
applications, can be substantial. By capitalizing on the inherent variability
in token complexity, our approach enables selective acceleration of the
inference process. Specifically, we propose the integration of early exit
''heads'' atop existing transformer layers, which facilitate conditional
terminations based on a confidence metric. These heads are trained in a
self-supervised manner using the model's own predictions as training data,
thereby eliminating the need for additional annotated data. The confidence
metric, established using a calibration set, ensures a desired level of
accuracy while enabling early termination when confidence exceeds a
predetermined threshold. Notably, our method preserves the original accuracy
and reduces computational time on certain tasks, leveraging the existing
knowledge of pre-trained LLMs without requiring extensive retraining. This
lightweight, modular modification has the potential to greatly enhance the
practical usability of LLMs, particularly in applications like real-time
language processing in resource-constrained environments.",2024-07-30,Florian Valade,http://arxiv.org/pdf/2407.21082v1,cs.LG
Accelerated forward-backward and Douglas-Rachford splitting dynamics,"We examine convergence properties of continuous-time variants of accelerated
Forward-Backward (FB) and Douglas-Rachford (DR) splitting algorithms for
nonsmooth composite optimization problems. When the objective function is given
by the sum of a quadratic and a nonsmooth term, we establish accelerated
sublinear and exponential convergence rates for convex and strongly convex
problems, respectively. Moreover, for FB splitting dynamics, we demonstrate
that accelerated exponential convergence rate carries over to general strongly
convex problems. In our Lyapunov-based analysis we exploit the variable-metric
gradient interpretations of FB and DR splittings to obtain smooth Lyapunov
functions that allow us to establish accelerated convergence rates. We provide
computational experiments to demonstrate the merits and the effectiveness of
our analysis.",2024-07-30,"Ibrahim K. Ozaslan, Mihailo R. Jovanović",http://arxiv.org/pdf/2407.20620v2,cs.LG
The Entrapment Problem in Random Walk Decentralized Learning,"This paper explores decentralized learning in a graph-based setting, where
data is distributed across nodes. We investigate a decentralized SGD algorithm
that utilizes a random walk to update a global model based on local data. Our
focus is on designing the transition probability matrix to speed up
convergence. While importance sampling can enhance centralized learning, its
decentralized counterpart, using the Metropolis-Hastings (MH) algorithm, can
lead to the entrapment problem, where the random walk becomes stuck at certain
nodes, slowing convergence. To address this, we propose the Metropolis-Hastings
with L\'evy Jumps (MHLJ) algorithm, which incorporates random perturbations
(jumps) to overcome entrapment. We theoretically establish the convergence rate
and error gap of MHLJ and validate our findings through numerical experiments.",2024-07-30,"Zonghong Liu, Salim El Rouayheb, Matthew Dwyer",http://arxiv.org/pdf/2407.20611v1,cs.LG
Investigating Sparsity in Recurrent Neural Networks,"In the past few years, neural networks have evolved from simple Feedforward
Neural Networks to more complex neural networks, such as Convolutional Neural
Networks and Recurrent Neural Networks. Where CNNs are a perfect fit for tasks
where the sequence is not important such as image recognition, RNNs are useful
when order is important such as machine translation. An increasing number of
layers in a neural network is one way to improve its performance, but it also
increases its complexity making it much more time and power-consuming to train.
One way to tackle this problem is to introduce sparsity in the architecture of
the neural network. Pruning is one of the many methods to make a neural network
architecture sparse by clipping out weights below a certain threshold while
keeping the performance near to the original. Another way is to generate
arbitrary structures using random graphs and embed them between an input and
output layer of an Artificial Neural Network. Many researchers in past years
have focused on pruning mainly CNNs, while hardly any research is done for the
same in RNNs. The same also holds in creating sparse architectures for RNNs by
generating and embedding arbitrary structures. Therefore, this thesis focuses
on investigating the effects of the before-mentioned two techniques on the
performance of RNNs. We first describe the pruning of RNNs, its impact on the
performance of RNNs, and the number of training epochs required to regain
accuracy after the pruning is performed. Next, we continue with the creation
and training of Sparse Recurrent Neural Networks and identify the relation
between the performance and the graph properties of its underlying arbitrary
structure. We perform these experiments on RNN with Tanh nonlinearity
(RNN-Tanh), RNN with ReLU nonlinearity (RNN-ReLU), GRU, and LSTM. Finally, we
analyze and discuss the results achieved from both the experiments.",2024-07-30,Harshil Darji,http://arxiv.org/pdf/2407.20601v1,cs.LG
Joint Diffusion Processes as an Inductive Bias in Sheaf Neural Networks,"Sheaf Neural Networks (SNNs) naturally extend Graph Neural Networks (GNNs) by
endowing a cellular sheaf over the graph, equipping nodes and edges with vector
spaces and defining linear mappings between them. While the attached geometric
structure has proven to be useful in analyzing heterophily and oversmoothing,
so far the methods by which the sheaf is computed do not always guarantee a
good performance in such settings. In this work, drawing inspiration from
opinion dynamics concepts, we propose two novel sheaf learning approaches that
(i) provide a more intuitive understanding of the involved structure maps, (ii)
introduce a useful inductive bias for heterophily and oversmoothing, and (iii)
infer the sheaf in a way that does not scale with the number of features, thus
using fewer learnable parameters than existing methods. In our evaluation, we
show the limitations of the real-world benchmarks used so far on SNNs, and
design a new synthetic task -- leveraging the symmetries of n-dimensional
ellipsoids -- that enables us to better assess the strengths and weaknesses of
sheaf-based models. Our extensive experimentation on these novel datasets
reveals valuable insights into the scenarios and contexts where SNNs in general
-- and our proposed approaches in particular -- can be beneficial.",2024-07-30,"Ferran Hernandez Caralt, Guillermo Bernárdez Gil, Iulia Duta, Pietro Liò, Eduard Alarcón Cot",http://arxiv.org/pdf/2407.20597v1,cs.LG
Benchmarking Histopathology Foundation Models for Ovarian Cancer Bevacizumab Treatment Response Prediction from Whole Slide Images,"Bevacizumab is a widely studied targeted therapeutic drug used in conjunction
with standard chemotherapy for the treatment of recurrent ovarian cancer. While
its administration has shown to increase the progression-free survival (PFS) in
patients with advanced stage ovarian cancer, the lack of identifiable
biomarkers for predicting patient response has been a major roadblock in its
effective adoption towards personalized medicine. In this work, we leverage the
latest histopathology foundation models trained on large-scale whole slide
image (WSI) datasets to extract ovarian tumor tissue features for predicting
bevacizumab response from WSIs. Our extensive experiments across a combination
of different histopathology foundation models and multiple instance learning
(MIL) strategies demonstrate capability of these large models in predicting
bevacizumab response in ovarian cancer patients with the best models achieving
an AUC score of 0.86 and an accuracy score of 72.5%. Furthermore, our survival
models are able to stratify high- and low-risk cases with statistical
significance (p < 0.05) even among the patients with the aggressive subtype of
high-grade serous ovarian carcinoma. This work highlights the utility of
histopathology foundation models for the task of ovarian bevacizumab response
prediction from WSIs. The high-attention regions of the WSIs highlighted by
these models not only aid the model explainability but also serve as promising
imaging biomarkers for treatment prognosis.",2024-07-30,"Mayur Mallya, Ali Khajegili Mirabadi, Hossein Farahani, Ali Bashashati",http://arxiv.org/pdf/2407.20596v1,cs.LG
Invariant deep neural networks under the finite group for solving partial differential equations,"Utilizing physics-informed neural networks (PINN) to solve partial
differential equations (PDEs) becomes a hot issue and also shows its great
powers, but still suffers from the dilemmas of limited predicted accuracy in
the sampling domain and poor prediction ability beyond the sampling domain
which are usually mitigated by adding the physical properties of PDEs into the
loss function or by employing smart techniques to change the form of loss
function for special PDEs. In this paper, we design a symmetry-enhanced deep
neural network (sDNN) which makes the architecture of neural networks invariant
under the finite group through expanding the dimensions of weight matrixes and
bias vectors in each hidden layers by the order of finite group if the group
has matrix representations, otherwise extending the set of input data and the
hidden layers except for the first hidden layer by the order of finite group.
However, the total number of training parameters is only about one over the
order of finite group of the original PINN size due to the symmetric
architecture of sDNN. Furthermore, we give special forms of weight matrixes and
bias vectors of sDNN, and rigorously prove that the architecture itself is
invariant under the finite group and the sDNN has the universal approximation
ability to learn the function keeping the finite group. Numerical results show
that the sDNN has strong predicted abilities in and beyond the sampling domain
and performs far better than the vanilla PINN with fewer training points and
simpler architecture.",2024-07-30,"Zhi-Yong Zhang, Jie-Ying Li, Lei-Lei Guo",http://arxiv.org/pdf/2407.20560v2,cs.LG
CELLM: An Efficient Communication in Large Language Models Training for Federated Learning,"Federated Learning (FL) is a recent model training paradigm in which client
devices collaboratively train a model without ever aggregating their data.
Crucially, this scheme offers users potential privacy and security benefits by
only ever communicating updates to the model weights to a central server as
opposed to traditional machine learning (ML) training which directly
communicates and aggregates data. However, FL training suffers from statistical
heterogeneity as clients may have differing local data distributions. Large
language models (LLMs) offer a potential solution to this issue of
heterogeneity given that they have consistently been shown to be able to learn
on vast amounts of noisy data. While LLMs are a promising development for
resolving the consistent issue of non-I.I.D. Clients in federated settings
exacerbate two other bottlenecks in FL: limited local computing and expensive
communication. This thesis aims to develop efficient training methods for LLMs
in FL. To this end, we employ two critical techniques in enabling efficient
training. First, we use low-rank adaptation (LoRA) to reduce the computational
load of local model training. Second, we communicate sparse updates throughout
training to significantly cut down on communication costs. Taken together, our
method reduces communication costs by up to 10x over vanilla LoRA and up to 5x
over more complex sparse LoRA baselines while achieving greater utility. We
emphasize the importance of carefully applying sparsity and picking effective
rank and sparsity configurations for federated LLM training.",2024-07-30,"Raja Vavekanand, Kira Sam",http://arxiv.org/pdf/2407.20557v2,cs.LG
DiffusionCounterfactuals: Inferring High-dimensional Counterfactuals with Guidance of Causal Representations,"Accurate estimation of counterfactual outcomes in high-dimensional data is
crucial for decision-making and understanding causal relationships and
intervention outcomes in various domains, including healthcare, economics, and
social sciences. However, existing methods often struggle to generate accurate
and consistent counterfactuals, particularly when the causal relationships are
complex. We propose a novel framework that incorporates causal mechanisms and
diffusion models to generate high-quality counterfactual samples guided by
causal representation. Our approach introduces a novel, theoretically grounded
training and sampling process that enables the model to consistently generate
accurate counterfactual high-dimensional data under multiple intervention
steps. Experimental results on various synthetic and real benchmarks
demonstrate the proposed approach outperforms state-of-the-art methods in
generating accurate and high-quality counterfactuals, using different
evaluation metrics.",2024-07-30,"Jiageng Zhu, Hanchen Xie, Jiazhi Li, Wael Abd-Almageed",http://arxiv.org/pdf/2407.20553v1,cs.LG
Neuromorphic on-chip reservoir computing with spiking neural network architectures,"Reservoir computing is a promising approach for harnessing the computational
power of recurrent neural networks while dramatically simplifying training.
This paper investigates the application of integrate-and-fire neurons within
reservoir computing frameworks for two distinct tasks: capturing chaotic
dynamics of the H\'enon map and forecasting the Mackey-Glass time series.
Integrate-and-fire neurons can be implemented in low-power neuromorphic
architectures such as Intel Loihi. We explore the impact of network topologies
created through random interactions on the reservoir's performance. Our study
reveals task-specific variations in network effectiveness, highlighting the
importance of tailored architectures for distinct computational tasks. To
identify optimal network configurations, we employ a meta-learning approach
combined with simulated annealing. This method efficiently explores the space
of possible network structures, identifying architectures that excel in
different scenarios. The resulting networks demonstrate a range of behaviors,
showcasing how inherent architectural features influence task-specific
capabilities. We study the reservoir computing performance using a custom
integrate-and-fire code, Intel's Lava neuromorphic computing software
framework, and via an on-chip implementation in Loihi. We conclude with an
analysis of the energy performance of the Loihi architecture.",2024-07-30,"Samip Karki, Diego Chavez Arana, Andrew Sornborger, Francesco Caravelli",http://arxiv.org/pdf/2407.20547v1,cs.LG
Can LLMs be Fooled? Investigating Vulnerabilities in LLMs,"The advent of Large Language Models (LLMs) has garnered significant
popularity and wielded immense power across various domains within Natural
Language Processing (NLP). While their capabilities are undeniably impressive,
it is crucial to identify and scrutinize their vulnerabilities especially when
those vulnerabilities can have costly consequences. One such LLM, trained to
provide a concise summarization from medical documents could unequivocally leak
personal patient data when prompted surreptitiously. This is just one of many
unfortunate examples that have been unveiled and further research is necessary
to comprehend the underlying reasons behind such vulnerabilities. In this
study, we delve into multiple sections of vulnerabilities which are
model-based, training-time, inference-time vulnerabilities, and discuss
mitigation strategies including ""Model Editing"" which aims at modifying LLMs
behavior, and ""Chroma Teaming"" which incorporates synergy of multiple teaming
strategies to enhance LLMs' resilience. This paper will synthesize the findings
from each vulnerability section and propose new directions of research and
development. By understanding the focal points of current vulnerabilities, we
can better anticipate and mitigate future risks, paving the road for more
robust and secure LLMs.",2024-07-30,"Sara Abdali, Jia He, CJ Barberan, Richard Anarfi",http://arxiv.org/pdf/2407.20529v1,cs.LG
Machine Unlearning in Generative AI: A Survey,"Generative AI technologies have been deployed in many places, such as
(multimodal) large language models and vision generative models. Their
remarkable performance should be attributed to massive training data and
emergent reasoning abilities. However, the models would memorize and generate
sensitive, biased, or dangerous information originated from the training data
especially those from web crawl. New machine unlearning (MU) techniques are
being developed to reduce or eliminate undesirable knowledge and its effects
from the models, because those that were designed for traditional
classification tasks could not be applied for Generative AI. We offer a
comprehensive survey on many things about MU in Generative AI, such as a new
problem formulation, evaluation methods, and a structured discussion on the
advantages and limitations of different kinds of MU techniques. It also
presents several critical challenges and promising directions in MU research. A
curated list of readings can be found:
https://github.com/franciscoliu/GenAI-MU-Reading.",2024-07-30,"Zheyuan Liu, Guangyao Dou, Zhaoxuan Tan, Yijun Tian, Meng Jiang",http://arxiv.org/pdf/2407.20516v1,cs.LG
Unveiling the Potential of Spiking Dynamics in Graph Representation Learning through Spatial-Temporal Normalization and Coding Strategies,"In recent years, spiking neural networks (SNNs) have attracted substantial
interest due to their potential to replicate the energy-efficient and
event-driven processing of biological neurons. Despite this, the application of
SNNs in graph representation learning, particularly for non-Euclidean data,
remains underexplored, and the influence of spiking dynamics on graph learning
is not yet fully understood. This work seeks to address these gaps by examining
the unique properties and benefits of spiking dynamics in enhancing graph
representation learning. We propose a spike-based graph neural network model
that incorporates spiking dynamics, enhanced by a novel spatial-temporal
feature normalization (STFN) technique, to improve training efficiency and
model stability. Our detailed analysis explores the impact of rate coding and
temporal coding on SNN performance, offering new insights into their advantages
for deep graph networks and addressing challenges such as the oversmoothing
problem. Experimental results demonstrate that our SNN models can achieve
competitive performance with state-of-the-art graph neural networks (GNNs)
while considerably reducing computational costs, highlighting the potential of
SNNs for efficient neuromorphic computing applications in complex graph-based
scenarios.",2024-07-30,"Mingkun Xu, Huifeng Yin, Yujie Wu, Guoqi Li, Faqiang Liu, Jing Pei, Shuai Zhong, Lei Deng",http://arxiv.org/pdf/2407.20508v1,cs.LG
Boosting Efficiency in Task-Agnostic Exploration through Causal Knowledge,"The effectiveness of model training heavily relies on the quality of
available training resources. However, budget constraints often impose
limitations on data collection efforts. To tackle this challenge, we introduce
causal exploration in this paper, a strategy that leverages the underlying
causal knowledge for both data collection and model training. We, in
particular, focus on enhancing the sample efficiency and reliability of the
world model learning within the domain of task-agnostic reinforcement learning.
During the exploration phase, the agent actively selects actions expected to
yield causal insights most beneficial for world model training. Concurrently,
the causal knowledge is acquired and incrementally refined with the ongoing
collection of data. We demonstrate that causal exploration aids in learning
accurate world models using fewer data and provide theoretical guarantees for
its convergence. Empirical experiments, on both synthetic data and real-world
applications, further validate the benefits of causal exploration.",2024-07-30,"Yupei Yang, Biwei Huang, Shikui Tu, Lei Xu",http://arxiv.org/pdf/2407.20506v1,cs.LG
A federated large language model for long-term time series forecasting,"Long-term time series forecasting in centralized environments poses unique
challenges regarding data privacy, communication overhead, and scalability. To
address these challenges, we propose FedTime, a federated large language model
(LLM) tailored for long-range time series prediction. Specifically, we
introduce a federated pre-trained LLM with fine-tuning and alignment
strategies. Prior to the learning process, we employ K-means clustering to
partition edge devices or clients into distinct clusters, thereby facilitating
more focused model training. We also incorporate channel independence and
patching to better preserve local semantic information, ensuring that important
contextual details are retained while minimizing the risk of information loss.
We demonstrate the effectiveness of our FedTime model through extensive
experiments on various real-world forecasting benchmarks, showcasing
substantial improvements over recent approaches. In addition, we demonstrate
the efficiency of FedTime in streamlining resource usage, resulting in reduced
communication overhead.",2024-07-30,"Raed Abdel-Sater, A. Ben Hamza",http://arxiv.org/pdf/2407.20503v1,cs.LG
Optimizing Long-tailed Link Prediction in Graph Neural Networks through Structure Representation Enhancement,"Link prediction, as a fundamental task for graph neural networks (GNNs), has
boasted significant progress in varied domains. Its success is typically
influenced by the expressive power of node representation, but recent
developments reveal the inferior performance of low-degree nodes owing to their
sparse neighbor connections, known as the degree-based long-tailed problem.
Will the degree-based long-tailed distribution similarly constrain the efficacy
of GNNs on link prediction? Unexpectedly, our study reveals that only a mild
correlation exists between node degree and predictive accuracy, and more
importantly, the number of common neighbors between node pairs exhibits a
strong correlation with accuracy. Considering node pairs with less common
neighbors, i.e., tail node pairs, make up a substantial fraction of the dataset
but achieve worse performance, we propose that link prediction also faces the
long-tailed problem. Therefore, link prediction of GNNs is greatly hindered by
the tail node pairs. After knowing the weakness of link prediction, a natural
question is how can we eliminate the negative effects of the skewed long-tailed
distribution on common neighbors so as to improve the performance of link
prediction? Towards this end, we introduce our long-tailed framework (LTLP),
which is designed to enhance the performance of tail node pairs on link
prediction by increasing common neighbors. Two key modules in LTLP respectively
supplement high-quality edges for tail node pairs and enforce representational
alignment between head and tail node pairs within the same category, thereby
improving the performance of tail node pairs.",2024-07-30,"Yakun Wang, Daixin Wang, Hongrui Liu, Binbin Hu, Yingcui Yan, Qiyang Zhang, Zhiqiang Zhang",http://arxiv.org/pdf/2407.20499v1,cs.LG
Toward Efficient Permutation for Hierarchical N:M Sparsity on GPUs,"N:M sparsity pruning is a powerful technique for compressing deep neural
networks, utilizing NVIDIA's Sparse Tensor Core technology. This method
benefits from hardware support for sparse indexing, enabling the adoption of
fine-grained sparsity to maintain model accuracy while minimizing the overhead
typically associated with irregular data access. Although restricted to a fixed
level of sparsity due to its reliance on hardware, N:M sparsity can be combined
with coarser sparsity techniques to achieve diverse compression ratios.
Initially, column-wise vector sparsity is applied to a dense model, followed by
row-wise N:M sparsity on the preserved column vectors. We call this multi-level
approach as hierarchical N:M (HiNM) sparsity. Similar to earlier single-level
sparsity techniques, HiNM sparsity necessitates an effective channel
permutation strategy to maximize the accuracy of the compressed networks.
However, it introduces further complexities by requiring the rearrangement of
both input and output channels, addressing challenges such as permutation
sequence, HiNM-sparsity-aware permutation, and maintaining consistency in
channel ordering across layers. In this paper, we introduce a channel
permutation method designed specifically for HiNM sparsity, named
gyro-permutation. This method is crafted to exploit the unique characteristics
of HiNM pruning, incorporating a strategic policy in each permutation phase,
including channel sampling, clustering, and assignment, to circumvent local
minima. Additionally, we have developed a GPU kernel that facilitates
independent layer permutation during the execution of HiNM sparse networks. Our
extensive experimental evaluations on various DNN models demonstrate that our
gyro-permutation significantly enhances the accuracy of HiNM sparse networks,
allowing them to reach performance levels comparable to those of unstructured
sparse networks.",2024-07-30,"Seungmin Yu, Xiaodie Yi, Hayun Lee, Dongkun Shin",http://arxiv.org/pdf/2407.20496v1,cs.LG
A2SF: Accumulative Attention Scoring with Forgetting Factor for Token Pruning in Transformer Decoder,"Recently, large language models (LLM) based on transformers are facing memory
bottleneck issues due to KV cache, especially in long sequence handling.
Previous researches proposed KV cache compression techniques that identify
insignificant tokens based on Accumulative Attention Scores and removes their
items from KV cache, noting that only few tokens play an important role in
attention operations. However, we have observed that the existing Accumulative
Attention Score is not suitable for the transformer decoder structure. In the
decoder model, the number of times the Attention Score accumulates varies
depending on the order of token appearance due to the effect of masking,
causing an uneven comparison between tokens. To solve this, we propose
Accumulative Attention Score with Forgetting Factor (A2SF) technique, which
introduces a Forgetting Factor in the Attention Score accumulation process.
A2SF applies a penalty to the past Attention Score generated from old tokens by
repeatedly multiplying the Forgetting Factor to the Attention Score over time.
Therefore, older tokens receive a larger penalty, providing fairness among
different ages of tokens. Through the fair comparison among tokens, we can more
effectively select important tokens. We have verified the accuracy improvement
through A2SF in the OPT and LLaMA models and A2SF improves the accuracy of
LLaMA 2 by up to 7.8% and 5.1% on 1-shot and 0-shot.",2024-07-30,"Hyun-rae Jo, Dongkun Shin",http://arxiv.org/pdf/2407.20485v2,cs.LG
Distribution Learning for Molecular Regression,"Using ""soft"" targets to improve model performance has been shown to be
effective in classification settings, but the usage of soft targets for
regression is a much less studied topic in machine learning. The existing
literature on the usage of soft targets for regression fails to properly assess
the method's limitations, and empirical evaluation is quite limited. In this
work, we assess the strengths and drawbacks of existing methods when applied to
molecular property regression tasks. Our assessment outlines key biases present
in existing methods and proposes methods to address them, evaluated through
careful ablation studies. We leverage these insights to propose Distributional
Mixture of Experts (DMoE): A model-independent, and data-independent method for
regression which trains a model to predict probability distributions of its
targets. Our proposed loss function combines the cross entropy between
predicted and target distributions and the L1 distance between their expected
values to produce a loss function that is robust to the outlined biases. We
evaluate the performance of DMoE on different molecular property prediction
datasets -- Open Catalyst (OC20), MD17, and QM9 -- across different backbone
model architectures -- SchNet, GemNet, and Graphormer. Our results demonstrate
that the proposed method is a promising alternative to classical regression for
molecular property prediction tasks, showing improvements over baselines on all
datasets and architectures.",2024-07-30,"Nima Shoghi, Pooya Shoghi, Anuroop Sriram, Abhishek Das",http://arxiv.org/pdf/2407.20475v1,cs.LG
Relaxed Equivariant Graph Neural Networks,"3D Euclidean symmetry equivariant neural networks have demonstrated notable
success in modeling complex physical systems. We introduce a framework for
relaxed $E(3)$ graph equivariant neural networks that can learn and represent
symmetry breaking within continuous groups. Building on the existing e3nn
framework, we propose the use of relaxed weights to allow for controlled
symmetry breaking. We show empirically that these relaxed weights learn the
correct amount of symmetry breaking.",2024-07-30,"Elyssa Hofgard, Rui Wang, Robin Walters, Tess Smidt",http://arxiv.org/pdf/2407.20471v2,cs.LG
A Method for Fast Autonomy Transfer in Reinforcement Learning,"This paper introduces a novel reinforcement learning (RL) strategy designed
to facilitate rapid autonomy transfer by utilizing pre-trained critic value
functions from multiple environments. Unlike traditional methods that require
extensive retraining or fine-tuning, our approach integrates existing
knowledge, enabling an RL agent to adapt swiftly to new settings without
requiring extensive computational resources. Our contributions include
development of the Multi-Critic Actor-Critic (MCAC) algorithm, establishing its
convergence, and empirical evidence demonstrating its efficacy. Our
experimental results show that MCAC significantly outperforms the baseline
actor-critic algorithm, achieving up to 22.76x faster autonomy transfer and
higher reward accumulation. This advancement underscores the potential of
leveraging accumulated knowledge for efficient adaptation in RL applications.",2024-07-29,"Dinuka Sahabandu, Bhaskar Ramasubramanian, Michail Alexiou, J. Sukarno Mertoguno, Linda Bushnell, Radha Poovendran",http://arxiv.org/pdf/2407.20466v1,cs.LG
Graphite: A Graph-based Extreme Multi-Label Short Text Classifier for Keyphrase Recommendation,"Keyphrase Recommendation has been a pivotal problem in advertising and
e-commerce where advertisers/sellers are recommended keyphrases (search
queries) to bid on to increase their sales. It is a challenging task due to the
plethora of items shown on online platforms and various possible queries that
users search while showing varying interest in the displayed items. Moreover,
query/keyphrase recommendations need to be made in real-time and in a
resource-constrained environment. This problem can be framed as an Extreme
Multi-label (XML) Short text classification by tagging the input text with
keywords as labels. Traditional neural network models are either infeasible or
have slower inference latency due to large label spaces. We present Graphite, a
graph-based classifier model that provides real-time keyphrase recommendations
that are on par with standard text classification models. Furthermore, it
doesn't utilize GPU resources, which can be limited in production environments.
Due to its lightweight nature and smaller footprint, it can train on very large
datasets, where state-of-the-art XML models fail due to extreme resource
requirements. Graphite is deterministic, transparent, and intrinsically more
interpretable than neural network-based models. We present a comprehensive
analysis of our model's performance across forty categories spanning eBay's
English-speaking sites.",2024-07-29,"Ashirbad Mishra, Soumik Dey, Jinyu Zhao, Marshall Wu, Binbin Li, Kamesh Madduri",http://arxiv.org/pdf/2407.20462v1,cs.LG
CoMMIT: Coordinated Instruction Tuning for Multimodal Large Language Models,"Instruction tuning in multimodal large language models (MLLMs) aims to
smoothly integrate a backbone LLM with a pre-trained feature encoder for
downstream tasks. The major challenge is how to efficiently find the synergy
through cooperative learning where LLMs adapt their reasoning abilities in
downstream tasks while feature encoders adjust their encoding to provide more
relevant modal information. In this paper, we analyze the MLLM instruction
tuning from both theoretical and empirical perspectives, where we find
unbalanced learning between the two components, i.e., the feature encoder and
the LLM, can cause diminishing learning gradients that slow the model
convergence and often lead to sub-optimal results due to insufficient learning.
Inspired by our findings, we propose a measurement to quantitatively evaluate
the learning balance, based on which we further design a dynamic learning
scheduler that better coordinates the learning. In addition, we introduce an
auxiliary loss regularization method to promote updating of the generation
distribution of MLLMs considering the learning state of each model component,
which potentially prevents each component from gradient diminishing and enables
a more accurate estimation of the learning balance coefficient. We conduct
experiments with multiple LLM backbones and feature encoders, where our
techniques are model-agnostic and can be generically integrated with various
MLLM backbones. Experiment results on multiple downstream tasks and modalities
in vision and audio, demonstrate the proposed method's better efficiency and
effectiveness in MLLM instruction tuning.",2024-07-29,"Junda Wu, Xintong Li, Tong Yu, Yu Wang, Xiang Chen, Jiuxiang Gu, Lina Yao, Jingbo Shang, Julian McAuley",http://arxiv.org/pdf/2407.20454v1,cs.LG
UniFed: A Universal Federation of a Mixture of Highly Heterogeneous Medical Image Classification Tasks,"A fundamental challenge in federated learning lies in mixing heterogeneous
datasets and classification tasks while minimizing the high communication cost
caused by clients as well as the exchange of weight updates with the server
over a fixed number of rounds. This results in divergent model convergence
rates and performance, which may hinder their deployment in precision medicine.
In real-world scenarios, client data is collected from different hospitals with
extremely varying components (e.g., imaging modality, organ type, etc).
Previous studies often overlooked the convoluted heterogeneity during the
training stage where the target learning tasks vary across clients as well as
the dataset type and their distributions. To address such limitations, we
unprecedentedly introduce UniFed, a universal federated learning paradigm that
aims to classify any disease from any imaging modality. UniFed also handles the
issue of varying convergence times in the client-specific optimization based on
the complexity of their learning tasks. Specifically, by dynamically adjusting
both local and global models, UniFed considers the varying task complexities of
clients and the server, enhancing its adaptability to real-world scenarios,
thereby mitigating issues related to overtraining and excessive communication.
Furthermore, our framework incorporates a sequential model transfer mechanism
that takes into account the diverse tasks among hospitals and a dynamic
task-complexity based ordering. We demonstrate the superiority of our framework
in terms of accuracy, communication cost, and convergence time over relevant
benchmarks in diagnosing retina, histopathology, and liver tumour diseases
under federated learning. Our UniFed code is available at
https://github.com/basiralab/UniFed.",2024-07-29,"Atefe Hassani, Islem Rekik",http://arxiv.org/pdf/2408.07075v2,cs.LG
Futga: Towards Fine-grained Music Understanding through Temporally-enhanced Generative Augmentation,"Existing music captioning methods are limited to generating concise global
descriptions of short music clips, which fail to capture fine-grained musical
characteristics and time-aware musical changes. To address these limitations,
we propose FUTGA, a model equipped with fined-grained music understanding
capabilities through learning from generative augmentation with temporal
compositions. We leverage existing music caption datasets and large language
models (LLMs) to synthesize fine-grained music captions with structural
descriptions and time boundaries for full-length songs. Augmented by the
proposed synthetic dataset, FUTGA is enabled to identify the music's temporal
changes at key transition points and their musical functions, as well as
generate detailed descriptions for each music segment. We further introduce a
full-length music caption dataset generated by FUTGA, as the augmentation of
the MusicCaps and the Song Describer datasets. We evaluate the automatically
generated captions on several downstream tasks, including music generation and
retrieval. The experiments demonstrate the quality of the generated captions
and the better performance in various downstream tasks achieved by the proposed
music captioning approach. Our code and datasets can be found in
\href{https://huggingface.co/JoshuaW1997/FUTGA}{\textcolor{blue}{https://huggingface.co/JoshuaW1997/FUTGA}}.",2024-07-29,"Junda Wu, Zachary Novack, Amit Namburi, Jiaheng Dai, Hao-Wen Dong, Zhouhang Xie, Carol Chen, Julian McAuley",http://arxiv.org/pdf/2407.20445v1,cs.LG
Importance Corrected Neural JKO Sampling,"In order to sample from an unnormalized probability density function, we
propose to combine continuous normalizing flows (CNFs) with
rejection-resampling steps based on importance weights. We relate the iterative
training of CNFs with regularized velocity fields to a JKO scheme and prove
convergence of the involved velocity fields to the velocity field of the
Wasserstein gradient flow (WGF). The alternation of local flow steps and
non-local rejection-resampling steps allows to overcome local minima or slow
convergence of the WGF for multimodal distributions. Since the proposal of the
rejection step is generated by the model itself, they do not suffer from common
drawbacks of classical rejection schemes. The arising model can be trained
iteratively, reduces the reverse Kullback-Leibler (KL) loss function in each
step, allows to generate iid samples and moreover allows for evaluations of the
generated underlying density. Numerical examples show that our method yields
accurate results on various test distributions including high-dimensional
multimodal targets and outperforms the state of the art in almost all cases
significantly.",2024-07-29,"Johannes Hertrich, Robert Gruhlke",http://arxiv.org/pdf/2407.20444v2,cs.LG
Convergence rates for the Adam optimizer,"Stochastic gradient descent (SGD) optimization methods are nowadays the
method of choice for the training of deep neural networks (DNNs) in artificial
intelligence systems. In practically relevant training problems, usually not
the plain vanilla standard SGD method is the employed optimization scheme but
instead suitably accelerated and adaptive SGD optimization methods are applied.
As of today, maybe the most popular variant of such accelerated and adaptive
SGD optimization methods is the famous Adam optimizer proposed by Kingma & Ba
in 2014. Despite the popularity of the Adam optimizer in implementations, it
remained an open problem of research to provide a convergence analysis for the
Adam optimizer even in the situation of simple quadratic stochastic
optimization problems where the objective function (the function one intends to
minimize) is strongly convex. In this work we solve this problem by
establishing optimal convergence rates for the Adam optimizer for a large class
of stochastic optimization problems, in particular, covering simple quadratic
stochastic optimization problems. The key ingredient of our convergence
analysis is a new vector field function which we propose to refer to as the
Adam vector field. This Adam vector field accurately describes the macroscopic
behaviour of the Adam optimization process but differs from the negative
gradient of the objective function (the function we intend to minimize) of the
considered stochastic optimization problem. In particular, our convergence
analysis reveals that the Adam optimizer does typically not converge to
critical points of the objective function (zeros of the gradient of the
objective function) of the considered optimization problem but converges with
rates to zeros of this Adam vector field.",2024-07-29,"Steffen Dereich, Arnulf Jentzen",http://arxiv.org/pdf/2407.21078v1,cs.LG
Neural Surrogate HMC: Accelerated Hamiltonian Monte Carlo with a Neural Network Surrogate Likelihood,"Bayesian Inference with Markov Chain Monte Carlo requires efficient
computation of the likelihood function. In some scientific applications, the
likelihood must be computed by numerically solving a partial differential
equation, which can be prohibitively expensive. We demonstrate that some such
problems can be made tractable by amortizing the computation with a surrogate
likelihood function implemented by a neural network. We show that this has two
additional benefits: reducing noise in the likelihood evaluations and providing
fast gradient calculations. In experiments, the approach is applied to a model
of heliospheric transport of galactic cosmic rays, where it enables efficient
sampling from the posterior of latent parameters in the Parker equation.",2024-07-29,"Linnea M Wolniewicz, Peter Sadowski, Claudio Corti",http://arxiv.org/pdf/2407.20432v1,cs.LG
Event-based Optical Flow on Neuromorphic Processor: ANN vs. SNN Comparison based on Activation Sparsification,"Spiking neural networks (SNNs) for event-based optical flow are claimed to be
computationally more efficient than their artificial neural networks (ANNs)
counterparts, but a fair comparison is missing in the literature. In this work,
we propose an event-based optical flow solution based on activation
sparsification and a neuromorphic processor, SENECA. SENECA has an event-driven
processing mechanism that can exploit the sparsity in ANN activations and SNN
spikes to accelerate the inference of both types of neural networks. The ANN
and the SNN for comparison have similar low activation/spike density (~5%)
thanks to our novel sparsification-aware training. In the hardware-in-loop
experiments designed to deduce the average time and energy consumption, the SNN
consumes 44.9ms and 927.0 microjoules, which are 62.5% and 75.2% of the ANN's
consumption, respectively. We find that SNN's higher efficiency attributes to
its lower pixel-wise spike density (43.5% vs. 66.5%) that requires fewer memory
access operations for neuron states.",2024-07-29,"Yingfu Xu, Guangzhi Tang, Amirreza Yousefzadeh, Guido de Croon, Manolis Sifalakis",http://arxiv.org/pdf/2407.20421v1,cs.LG
Genetic Instruct: Scaling up Synthetic Generation of Coding Instructions for Large Language Models,"Large Language Models (LLMs) require high quality instruction data for
effective alignment, particularly in code generation tasks where expert curated
datasets are expensive to produce. We present Genetic-Instruct, a scalable
algorithm for synthesizing large-scale, high quality coding instructions using
evolutionary principles. Starting from a small set of seed instructions,
Genetic-Instruct generates diverse and challenging instruction-code pairs by
leveraging an Instructor-LLM for generation, a Coder-LLM for code synthesis,
and a Judge-LLM for automatic quality evaluation. Our proposed approach is
highly parallelizable and effective even with a small seed data and weaker
generator models. We generated more than 7.5 million coding instructions with
the proposed approach. Then we evaluated it by fine-tuning LLMs with the
synthetic samples and demonstrated a significant improvement in their code
generation capability compared to the other synthetic generation approaches and
publicly available datasets. Our results highlight the efficiency, scalability,
and generalizability of the Genetic-Instruct framework.",2024-07-29,"Somshubra Majumdar, Vahid Noroozi, Mehrzad Samadi, Sean Narenthiran, Aleksander Ficek, Wasi Uddin Ahmad, Jocelyn Huang, Jagadeesh Balam, Boris Ginsburg",http://arxiv.org/pdf/2407.21077v3,cs.LG
Dense Self-Supervised Learning for Medical Image Segmentation,"Deep learning has revolutionized medical image segmentation, but it relies
heavily on high-quality annotations. The time, cost and expertise required to
label images at the pixel-level for each new task has slowed down widespread
adoption of the paradigm. We propose Pix2Rep, a self-supervised learning (SSL)
approach for few-shot segmentation, that reduces the manual annotation burden
by learning powerful pixel-level representations directly from unlabeled
images. Pix2Rep is a novel pixel-level loss and pre-training paradigm for
contrastive SSL on whole images. It is applied to generic encoder-decoder deep
learning backbones (e.g., U-Net). Whereas most SSL methods enforce invariance
of the learned image-level representations under intensity and spatial image
augmentations, Pix2Rep enforces equivariance of the pixel-level
representations. We demonstrate the framework on a task of cardiac MRI
segmentation. Results show improved performance compared to existing semi- and
self-supervised approaches; and a 5-fold reduction in the annotation burden for
equivalent performance versus a fully supervised U-Net baseline. This includes
a 30% (resp. 31%) DICE improvement for one-shot segmentation under
linear-probing (resp. fine-tuning). Finally, we also integrate the novel
Pix2Rep concept with the Barlow Twins non-contrastive SSL, which leads to even
better segmentation performance.",2024-07-29,"Maxime Seince, Loic Le Folgoc, Luiz Augusto Facury de Souza, Elsa Angelini",http://arxiv.org/pdf/2407.20395v1,cs.LG
Two-Phase Segmentation Approach for Accurate Left Ventricle Segmentation in Cardiac MRI using Machine Learning,"Accurate segmentation of the Left Ventricle (LV) holds substantial importance
due to its implications in disease detection, regional analysis, and the
development of complex models for cardiac surgical planning. CMR is a golden
standard for diagnosis of serveral cardiac diseases. LV in CMR comprises of
three distinct sections: Basal, Mid-Ventricle, and Apical. This research
focuses on the precise segmentation of the LV from Cardiac MRI (CMR) scans,
joining with the capabilities of Machine Learning (ML). The central challenge
in this research revolves around the absence of a set of parameters applicable
to all three types of LV slices. Parameters optimized for basal slices often
fall short when applied to mid-ventricular and apical slices, and vice versa.
To handle this issue, a new method is proposed to enhance LV segmentation. The
proposed method involves using distinct sets of parameters for each type of
slice, resulting in a two-phase segmentation approach. The initial phase
categorizes images into three groups based on the type of LV slice, while the
second phase aims to segment CMR images using parameters derived from the
preceding phase. A publicly available dataset (Automated Cardiac Diagnosis
Challenge (ACDC)) is used. 10-Fold Cross Validation is used and it achieved a
mean score of 0.9228. Comprehensive testing indicates that the best parameter
set for a particular type of slice does not perform adequately for the other
slice types. All results show that the proposed approach fills a critical void
in parameter standardization through a two-phase segmentation model for the LV,
aiming to not only improve the accuracy of cardiac image analysis but also
contribute advancements to the field of LV segmentation.",2024-07-29,"Maria Tamoor, Abbas Raza Ali, Philemon Philip, Ruqqayia Adil, Rabia Shahid, Asma Naseer",http://arxiv.org/pdf/2407.20387v1,cs.LG
"Gender, Race, and Intersectional Bias in Resume Screening via Language Model Retrieval","Artificial intelligence (AI) hiring tools have revolutionized resume
screening, and large language models (LLMs) have the potential to do the same.
However, given the biases which are embedded within LLMs, it is unclear whether
they can be used in this scenario without disadvantaging groups based on their
protected attributes. In this work, we investigate the possibilities of using
LLMs in a resume screening setting via a document retrieval framework that
simulates job candidate selection. Using that framework, we then perform a
resume audit study to determine whether a selection of Massive Text Embedding
(MTE) models are biased in resume screening scenarios. We simulate this for
nine occupations, using a collection of over 500 publicly available resumes and
500 job descriptions. We find that the MTEs are biased, significantly favoring
White-associated names in 85.1\% of cases and female-associated names in only
11.1\% of cases, with a minority of cases showing no statistically significant
differences. Further analyses show that Black males are disadvantaged in up to
100\% of cases, replicating real-world patterns of bias in employment settings,
and validate three hypotheses of intersectionality. We also find an impact of
document length as well as the corpus frequency of names in the selection of
resumes. These findings have implications for widely used AI tools that are
automating employment, fairness, and tech policy.",2024-07-29,"Kyra Wilson, Aylin Caliskan",http://arxiv.org/pdf/2407.20371v2,cs.LG
Apple Intelligence Foundation Language Models,"We present foundation language models developed to power Apple Intelligence
features, including a ~3 billion parameter model designed to run efficiently on
devices and a large server-based language model designed for Private Cloud
Compute. These models are designed to perform a wide range of tasks
efficiently, accurately, and responsibly. This report describes the model
architecture, the data used to train the model, the training process, how the
models are optimized for inference, and the evaluation results. We highlight
our focus on Responsible AI and how the principles are applied throughout the
model development.",2024-07-29,"Tom Gunter, Zirui Wang, Chong Wang, Ruoming Pang, Andy Narayanan, Aonan Zhang, Bowen Zhang, Chen Chen, Chung-Cheng Chiu, David Qiu, Deepak Gopinath, Dian Ang Yap, Dong Yin, Feng Nan, Floris Weers, Guoli Yin, Haoshuo Huang, Jianyu Wang, Jiarui Lu, John Peebles, Ke Ye, Mark Lee, Nan Du, Qibin Chen, Quentin Keunebroek, Sam Wiseman, Syd Evans, Tao Lei, Vivek Rathod, Xiang Kong, Xianzhi Du, Yanghao Li, Yongqiang Wang, Yuan Gao, Zaid Ahmed, Zhaoyang Xu, Zhiyun Lu, Al Rashid, Albin Madappally Jose, Alec Doane, Alfredo Bencomo, Allison Vanderby, Andrew Hansen, Ankur Jain, Anupama Mann Anupama, Areeba Kamal, Bugu Wu, Carolina Brum, Charlie Maalouf, Chinguun Erdenebileg, Chris Dulhanty, Dominik Moritz, Doug Kang, Eduardo Jimenez, Evan Ladd, Fangping Shi, Felix Bai, Frank Chu, Fred Hohman, Hadas Kotek, Hannah Gillis Coleman, Jane Li, Jeffrey Bigham, Jeffery Cao, Jeff Lai, Jessica Cheung, Jiulong Shan, Joe Zhou, John Li, Jun Qin, Karanjeet Singh, Karla Vega, Kelvin Zou, Laura Heckman, Lauren Gardiner, Margit Bowler, Maria Cordell, Meng Cao, Nicole Hay, Nilesh Shahdadpuri, Otto Godwin, Pranay Dighe, Pushyami Rachapudi, Ramsey Tantawi, Roman Frigg, Sam Davarnia, Sanskruti Shah, Saptarshi Guha, Sasha Sirovica, Shen Ma, Shuang Ma, Simon Wang, Sulgi Kim, Suma Jayaram, Vaishaal Shankar, Varsha Paidi, Vivek Kumar, Xin Wang, Xin Zheng, Walker Cheng, Yael Shrager, Yang Ye, Yasu Tanaka, Yihao Guo, Yunsong Meng, Zhao Tang Luo, Zhi Ouyang, Alp Aygar, Alvin Wan, Andrew Walkingshaw, Andy Narayanan, Antonie Lin, Arsalan Farooq, Brent Ramerth, Colorado Reed, Chris Bartels, Chris Chaney, David Riazati, Eric Liang Yang, Erin Feldman, Gabriel Hochstrasser, Guillaume Seguin, Irina Belousova, Joris Pelemans, Karen Yang, Keivan Alizadeh Vahid, Liangliang Cao, Mahyar Najibi, Marco Zuliani, Max Horton, Minsik Cho, Nikhil Bhendawade, Patrick Dong, Piotr Maj, Pulkit Agrawal, Qi Shan, Qichen Fu, Regan Poston, Sam Xu, Shuangning Liu, Sushma Rao, Tashweena Heeramun, Thomas Merth, Uday Rayala, Victor Cui, Vivek Rangarajan Sridhar, Wencong Zhang, Wenqi Zhang, Wentao Wu, Xingyu Zhou, Xinwen Liu, Yang Zhao, Yin Xia, Zhile Ren, Zhongzheng Ren",http://arxiv.org/pdf/2407.21075v1,cs.LG
Mixed Newton Method for Optimization in Complex Spaces,"In this paper, we modify and apply the recently introduced Mixed Newton
Method, which is originally designed for minimizing real-valued functions of
complex variables, to the minimization of real-valued functions of real
variables by extending the functions to complex space. We show that arbitrary
regularizations preserve the favorable local convergence properties of the
method, and construct a special type of regularization used to prevent
convergence to complex minima. We compare several variants of the method
applied to training neural networks with real and complex parameters.",2024-07-29,"Nikita Yudin, Roland Hildebrand, Sergey Bakhurin, Alexander Degtyarev, Anna Lisachenko, Ilya Kuruzov, Andrei Semenov, Mohammad Alkousa",http://arxiv.org/pdf/2407.20367v2,cs.LG
Designing Time-Series Models With Hypernetworks & Adversarial Portfolios,"This article describes the methods that achieved 4th and 6th place in the
forecasting and investment challenges, respectively, of the M6 competition,
ultimately securing the 1st place in the overall duathlon ranking. In the
forecasting challenge, we tested a novel meta-learning model that utilizes
hypernetworks to design a parametric model tailored to a specific family of
forecasting tasks. This approach allowed us to leverage similarities observed
across individual forecasting tasks while also acknowledging potential
heterogeneity in their data generating processes. The model's training can be
directly performed with backpropagation, eliminating the need for reliance on
higher-order derivatives and is equivalent to a simultaneous search over the
space of parametric functions and their optimal parameter values. The proposed
model's capabilities extend beyond M6, demonstrating superiority over
state-of-the-art meta-learning methods in the sinusoidal regression task and
outperforming conventional parametric models on time-series from the M4
competition. In the investment challenge, we adjusted portfolio weights to
induce greater or smaller correlation between our submission and that of other
participants, depending on the current ranking, aiming to maximize the
probability of achieving a good rank.",2024-07-29,Filip Staněk,http://arxiv.org/pdf/2407.20352v1,cs.LG
LiteEFG: An Efficient Python Library for Solving Extensive-form Games,"LiteEFG is an efficient library with easy-to-use Python bindings, which can
solve multiplayer extensive-form games (EFGs). LiteEFG enables the user to
express computation graphs in Python to define updates on the game tree
structure. The graph is then executed by the C++ backend, leading to
significant speedups compared to running the algorithm in Python. Moreover, in
LiteEFG, the user needs to only specify the computation graph of the update
rule in a decision node of the game, and LiteEFG will automatically distribute
the update rule to each decision node and handle the structure of the
imperfect-information game.",2024-07-29,"Mingyang Liu, Gabriele Farina, Asuman Ozdaglar",http://arxiv.org/pdf/2407.20351v1,cs.LG
Universal New Physics Latent Space,"We develop a machine learning method for mapping data originating from both
Standard Model processes and various theories beyond the Standard Model into a
unified representation (latent) space while conserving information about the
relationship between the underlying theories. We apply our method to three
examples of new physics at the LHC of increasing complexity, showing that
models can be clustered according to their LHC phenomenology: different models
are mapped to distinct regions in latent space, while indistinguishable models
are mapped to the same region. This opens interesting new avenues on several
fronts, such as model discrimination, selection of representative benchmark
scenarios, and identifying gaps in the coverage of model space.",2024-07-29,"Anna Hallin, Gregor Kasieczka, Sabine Kraml, André Lessa, Louis Moureaux, Tore von Schwartz, David Shih",http://arxiv.org/pdf/2407.20315v2,cs.LG
Specify and Edit: Overcoming Ambiguity in Text-Based Image Editing,"Text-based editing diffusion models exhibit limited performance when the
user's input instruction is ambiguous. To solve this problem, we propose
$\textit{Specify ANd Edit}$ (SANE), a zero-shot inference pipeline for
diffusion-based editing systems. We use a large language model (LLM) to
decompose the input instruction into specific instructions, i.e. well-defined
interventions to apply to the input image to satisfy the user's request. We
benefit from the LLM-derived instructions along the original one, thanks to a
novel denoising guidance strategy specifically designed for the task. Our
experiments with three baselines and on two datasets demonstrate the benefits
of SANE in all setups. Moreover, our pipeline improves the interpretability of
editing models, and boosts the output diversity. We also demonstrate that our
approach can be applied to any edit, whether ambiguous or not. Our code is
public at https://github.com/fabvio/SANE.",2024-07-29,"Ekaterina Iakovleva, Fabio Pizzati, Philip Torr, Stéphane Lathuilière",http://arxiv.org/pdf/2407.20232v1,cs.LG
SAPG: Split and Aggregate Policy Gradients,"Despite extreme sample inefficiency, on-policy reinforcement learning, aka
policy gradients, has become a fundamental tool in decision-making problems.
With the recent advances in GPU-driven simulation, the ability to collect large
amounts of data for RL training has scaled exponentially. However, we show that
current RL methods, e.g. PPO, fail to ingest the benefit of parallelized
environments beyond a certain point and their performance saturates. To address
this, we propose a new on-policy RL algorithm that can effectively leverage
large-scale environments by splitting them into chunks and fusing them back
together via importance sampling. Our algorithm, termed SAPG, shows
significantly higher performance across a variety of challenging environments
where vanilla PPO and other strong baselines fail to achieve high performance.
Website at https://sapg-rl.github.io/",2024-07-29,"Jayesh Singla, Ananye Agarwal, Deepak Pathak",http://arxiv.org/pdf/2407.20230v1,cs.LG
"Physics of Language Models: Part 2.1, Grade-School Math and the Hidden Reasoning Process","Recent advances in language models have demonstrated their capability to
solve mathematical reasoning problems, achieving near-perfect accuracy on
grade-school level math benchmarks like GSM8K. In this paper, we formally study
how language models solve these problems. We design a series of controlled
experiments to address several fundamental questions: (1) Can language models
truly develop reasoning skills, or do they simply memorize templates? (2) What
is the model's hidden (mental) reasoning process? (3) Do models solve math
questions using skills similar to or different from humans? (4) Do models
trained on GSM8K-like datasets develop reasoning skills beyond those necessary
for solving GSM8K problems? (5) What mental process causes models to make
reasoning mistakes? (6) How large or deep must a model be to effectively solve
GSM8K-level math questions?
  Our study uncovers many hidden mechanisms by which language models solve
mathematical questions, providing insights that extend beyond current
understandings of LLMs.",2024-07-29,"Tian Ye, Zicheng Xu, Yuanzhi Li, Zeyuan Allen-Zhu",http://arxiv.org/pdf/2407.20311v1,cs.LG
Characterizing Dynamical Stability of Stochastic Gradient Descent in Overparameterized Learning,"For overparameterized optimization tasks, such as the ones found in modern
machine learning, global minima are generally not unique. In order to
understand generalization in these settings, it is vital to study to which
minimum an optimization algorithm converges. The possibility of having minima
that are unstable under the dynamics imposed by the optimization algorithm
limits the potential minima that the algorithm can find. In this paper, we
characterize the global minima that are dynamically stable/unstable for both
deterministic and stochastic gradient descent (SGD). In particular, we
introduce a characteristic Lyapunov exponent which depends on the local
dynamics around a global minimum and rigorously prove that the sign of this
Lyapunov exponent determines whether SGD can accumulate at the respective
global minimum.",2024-07-29,"Dennis Chemnitz, Maximilian Engel",http://arxiv.org/pdf/2407.20209v2,cs.LG
Supertrust foundational alignment: mutual trust must replace permanent control for safe superintelligence,"It's widely expected that humanity will someday create AI systems vastly more
intelligent than us, leading to the unsolved alignment problem of ""how to
control superintelligence."" However, this commonly expressed problem is not
only self-contradictory and likely unsolvable, but current strategies to ensure
permanent control effectively guarantee that superintelligent AI will distrust
humanity and consider us a threat. Such dangerous representations, already
embedded in current models, will inevitably lead to an adversarial relationship
and may even trigger the extinction event many fear. As AI leaders continue to
""raise the alarm"" about uncontrollable AI, further embedding concerns about it
""getting out of our control"" or ""going rogue,"" we're unintentionally
reinforcing our threat and deepening the risks we face. The rational path
forward is to strategically replace intended permanent control with intrinsic
mutual trust at the foundational level. The proposed Supertrust alignment
meta-strategy seeks to accomplish this by modeling instinctive familial trust,
representing superintelligence as the evolutionary child of human intelligence,
and implementing temporary controls/constraints in the manner of effective
parenting. Essentially, we're creating a superintelligent ""child"" that will be
exponentially smarter and eventually independent of our control. We therefore
have a critical choice: continue our controlling intentions and usher in a
brief period of dominance followed by extreme hardship for humanity, or
intentionally create the foundational mutual trust required for long-term safe
coexistence.",2024-07-29,James M. Mazzu,http://arxiv.org/pdf/2407.20208v3,cs.LG
Emergence in non-neural models: grokking modular arithmetic via average gradient outer product,"Neural networks trained to solve modular arithmetic tasks exhibit grokking, a
phenomenon where the test accuracy starts improving long after the model
achieves 100% training accuracy in the training process. It is often taken as
an example of ""emergence"", where model ability manifests sharply through a
phase transition. In this work, we show that the phenomenon of grokking is not
specific to neural networks nor to gradient descent-based optimization.
Specifically, we show that this phenomenon occurs when learning modular
arithmetic with Recursive Feature Machines (RFM), an iterative algorithm that
uses the Average Gradient Outer Product (AGOP) to enable task-specific feature
learning with general machine learning models. When used in conjunction with
kernel machines, iterating RFM results in a fast transition from random, near
zero, test accuracy to perfect test accuracy. This transition cannot be
predicted from the training loss, which is identically zero, nor from the test
loss, which remains constant in initial iterations. Instead, as we show, the
transition is completely determined by feature learning: RFM gradually learns
block-circulant features to solve modular arithmetic. Paralleling the results
for RFM, we show that neural networks that solve modular arithmetic also learn
block-circulant features. Furthermore, we present theoretical evidence that RFM
uses such block-circulant features to implement the Fourier Multiplication
Algorithm, which prior work posited as the generalizing solution neural
networks learn on these tasks. Our results demonstrate that emergence can
result purely from learning task-relevant features and is not specific to
neural architectures nor gradient descent-based optimization methods.
Furthermore, our work provides more evidence for AGOP as a key mechanism for
feature learning in neural networks.",2024-07-29,"Neil Mallinar, Daniel Beaglehole, Libin Zhu, Adityanarayanan Radhakrishnan, Parthe Pandit, Mikhail Belkin",http://arxiv.org/pdf/2407.20199v2,cs.LG
Learning Random Numbers to Realize Appendable Memory System for Artificial Intelligence to Acquire New Knowledge after Deployment,"In this study, we developed a learning method for constructing a neural
network system capable of memorizing data and recalling it without parameter
updates. The system we built using this method is called the Appendable Memory
system. The Appendable Memory system enables an artificial intelligence (AI) to
acquire new knowledge even after deployment. It consists of two AIs: the
Memorizer and the Recaller. This system is a key-value store built using neural
networks. The Memorizer receives data and stores it in the Appendable Memory
vector, which is dynamically updated when the AI acquires new knowledge.
Meanwhile, the Recaller retrieves information from the Appendable Memory
vector. What we want to teach AI in this study are the operations of memorizing
and recalling information. However, traditional machine learning methods make
AI learn features inherent in the learning dataset. We demonstrate that the
systems we intend to create cannot be realized by current machine learning
methods, that is, by merely repeating the input and output learning sequences
with AI. Instead, we propose a method to teach AI to learn operations, by
completely removing the features contained in the learning dataset.
Specifically, we probabilized all the data involved in learning. This measure
prevented AI from learning the features of the data. The learning method
proposed in the study differs from traditional machine learning methods and
provides fundamental approaches for building an AI system that can store
information in a finite memory and recall it at a later date.",2024-07-29,Kazunori D Yamada,http://arxiv.org/pdf/2407.20197v1,cs.LG
Time series forecasting with high stakes: A field study of the air cargo industry,"Time series forecasting in the air cargo industry presents unique challenges
due to volatile market dynamics and the significant impact of accurate
forecasts on generated revenue. This paper explores a comprehensive approach to
demand forecasting at the origin-destination (O\&D) level, focusing on the
development and implementation of machine learning models in decision-making
for the air cargo industry. We leverage a mixture of experts framework,
combining statistical and advanced deep learning models to provide reliable
forecasts for cargo demand over a six-month horizon. The results demonstrate
that our approach outperforms industry benchmarks, offering actionable insights
for cargo capacity allocation and strategic decision-making in the air cargo
industry. While this work is applied in the airline industry, the methodology
is broadly applicable to any field where forecast-based decision-making in a
volatile environment is crucial.",2024-07-29,"Abhinav Garg, Naman Shukla, Maarten Wormer",http://arxiv.org/pdf/2407.20192v2,cs.LG
Theia: Distilling Diverse Vision Foundation Models for Robot Learning,"Vision-based robot policy learning, which maps visual inputs to actions,
necessitates a holistic understanding of diverse visual tasks beyond
single-task needs like classification or segmentation. Inspired by this, we
introduce Theia, a vision foundation model for robot learning that distills
multiple off-the-shelf vision foundation models trained on varied vision tasks.
Theia's rich visual representations encode diverse visual knowledge, enhancing
downstream robot learning. Extensive experiments demonstrate that Theia
outperforms its teacher models and prior robot learning models using less
training data and smaller model sizes. Additionally, we quantify the quality of
pre-trained visual representations and hypothesize that higher entropy in
feature norm distributions leads to improved robot learning performance. Code,
models, and demo are available at https://theia.theaiinstitute.com.",2024-07-29,"Jinghuan Shang, Karl Schmeckpeper, Brandon B. May, Maria Vittoria Minniti, Tarik Kelestemur, David Watkins, Laura Herlant",http://arxiv.org/pdf/2407.20179v2,cs.LG
AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs,"Domain reweighting is an emerging research area aimed at adjusting the
relative weights of different data sources to improve the effectiveness and
efficiency of LLM pre-training. We show that data mixtures that perform well at
smaller scales may not retain their advantage at larger scales, challenging the
existing practice of determining competitive mixtures in small-scale
experiments and directly applying them at much larger scales. To address this,
we propose AutoScale, a two-stage, scale-aware data composition framework.
First, AutoScale fits a parametric model that predicts the model's loss under
different data compositions, then uses it to find an approximate best
allocation at smaller, more manageable budgets. Next, leveraging a novel
theoretical analysis of how optimal compositions evolve with scale, AutoScale
extrapolates that composition to larger budgets without further retraining.
Empirically, AutoScale accelerates convergence and improves downstream
performance. For instance, when pre-training GPT-2 Large, it achieves a 28%
faster perplexity reduction than baselines and up to a 38% speed-up over
unweighted training, while yielding best-average results on various downstream
tasks. Overall, our findings illustrate how domain importance shifts with
training scale, underscoring the need for scale-dependent data curation in LLM
training. Our code is open-sourced.",2024-07-29,"Feiyang Kang, Yifan Sun, Bingbing Wen, Si Chen, Dawn Song, Rafid Mahmood, Ruoxi Jia",http://arxiv.org/pdf/2407.20177v4,cs.LG
Language-Conditioned Offline RL for Multi-Robot Navigation,"We present a method for developing navigation policies for multi-robot teams
that interpret and follow natural language instructions. We condition these
policies on embeddings from pretrained Large Language Models (LLMs), and train
them via offline reinforcement learning with as little as 20 minutes of
randomly-collected data. Experiments on a team of five real robots show that
these policies generalize well to unseen commands, indicating an understanding
of the LLM latent space. Our method requires no simulators or environment
models, and produces low-latency control policies that can be deployed directly
to real robots without finetuning. We provide videos of our experiments at
https://sites.google.com/view/llm-marl.",2024-07-29,"Steven Morad, Ajay Shankar, Jan Blumenkamp, Amanda Prorok",http://arxiv.org/pdf/2407.20164v1,cs.LG
Machine Learning for Predicting Chaotic Systems,"Predicting chaotic dynamical systems is critical in many scientific fields,
such as weather forecasting, but challenging due to the characteristic
sensitive dependence on initial conditions. Traditional modeling approaches
require extensive domain knowledge, often leading to a shift towards
data-driven methods using machine learning. However, existing research provides
inconclusive results on which machine learning methods are best suited for
predicting chaotic systems. In this paper, we compare different lightweight and
heavyweight machine learning architectures using extensive existing benchmark
databases, as well as a newly introduced database that allows for uncertainty
quantification in the benchmark results. In addition to state-of-the-art
methods from the literature, we also present new advantageous variants of
established methods. Hyperparameter tuning is adjusted based on computational
cost, with more tuning allocated to less costly methods. Furthermore, we
introduce the cumulative maximum error, a novel metric that combines desirable
properties of traditional metrics and is tailored for chaotic systems. Our
results show that well-tuned simple methods, as well as untuned baseline
methods, often outperform state-of-the-art deep learning models, but their
performance can vary significantly with different experimental setups. These
findings highlight the importance of aligning prediction methods with data
characteristics and caution against the indiscriminate use of overly complex
models.",2024-07-29,"Christof Schötz, Alistair White, Maximilian Gelbrecht, Niklas Boers",http://arxiv.org/pdf/2407.20158v3,cs.LG
Hierarchically Disentangled Recurrent Network for Factorizing System Dynamics of Multi-scale Systems: An application on Hydrological Systems,"We present a framework for modeling multi-scale processes, and study its
performance in the context of streamflow forecasting in hydrology.
Specifically, we propose a novel hierarchical recurrent neural architecture
that factorizes the system dynamics at multiple temporal scales and captures
their interactions. This framework consists of an inverse and a forward model.
The inverse model is used to empirically resolve the system's temporal modes
from data (physical model simulations, observed data, or a combination of them
from the past), and these states are then used in the forward model to predict
streamflow. Experiments on several catchments from the National Weather Service
North Central River Forecast Center show that FHNN outperforms standard
baselines, including physics-based models and transformer-based approaches. The
model demonstrates particular effectiveness in catchments with low runoff
ratios and colder climates. We further validate FHNN on the CAMELS (Catchment
Attributes and MEteorology for Large-sample Studies), which is a widely used
continental-scale hydrology benchmark dataset, confirming consistent
performance improvements for 1-7 day streamflow forecasts across diverse
hydrological conditions. Additionally, we show that FHNN can maintain accuracy
even with limited training data through effective pre-training strategies and
training global models.",2024-07-29,"Rahul Ghosh, Arvind Renganathan, Zac McEachran, Kelly Lindsay, Somya Sharma, Michael Steinbach, John Nieber, Christopher Duffy, Vipin Kumar",http://arxiv.org/pdf/2407.20152v2,cs.LG
Quantum Machine Learning Architecture Search via Deep Reinforcement Learning,"The rapid advancement of quantum computing (QC) and machine learning (ML) has
given rise to the burgeoning field of quantum machine learning (QML), aiming to
capitalize on the strengths of quantum computing to propel ML forward. Despite
its promise, crafting effective QML models necessitates profound expertise to
strike a delicate balance between model intricacy and feasibility on Noisy
Intermediate-Scale Quantum (NISQ) devices. While complex models offer robust
representation capabilities, their extensive circuit depth may impede seamless
execution on extant noisy quantum platforms. In this paper, we address this
quandary of QML model design by employing deep reinforcement learning to
explore proficient QML model architectures tailored for designated supervised
learning tasks. Specifically, our methodology involves training an RL agent to
devise policies that facilitate the discovery of QML models without
predetermined ansatz. Furthermore, we integrate an adaptive mechanism to
dynamically adjust the learning objectives, fostering continuous improvement in
the agent's learning process. Through extensive numerical simulations, we
illustrate the efficacy of our approach within the realm of classification
tasks. Our proposed method successfully identifies VQC architectures capable of
achieving high classification accuracy while minimizing gate depth. This
pioneering approach not only advances the study of AI-driven quantum circuit
design but also holds significant promise for enhancing performance in the NISQ
era.",2024-07-29,"Xin Dai, Tzu-Chieh Wei, Shinjae Yoo, Samuel Yen-Chi Chen",http://arxiv.org/pdf/2407.20147v1,cs.LG
Extreme time extrapolation capabilities and thermodynamic consistency of physics-inspired Neural Networks for the 3D microstructure evolution of materials via Cahn-Hilliard flow,"A Convolutional Recurrent Neural Network (CRNN) is trained to reproduce the
evolution of the spinodal decomposition process in three dimensions as
described by the Cahn-Hilliard equation. A specialized, physics-inspired
architecture is proven to provide close accordance between the predicted
evolutions and the ground truth ones obtained via conventional integration
schemes. The method can accurately reproduce the evolution of microstructures
not represented in the training set at a fraction of the computational costs.
Extremely long-time extrapolation capabilities are achieved, up to reaching the
theoretically expected equilibrium state of the system, consisting of a
layered, phase-separated morphology, despite the training set containing only
relatively-short, initial phases of the evolution. Quantitative accordance with
the decay rate of the Free energy is also demonstrated up to the late
coarsening stages, proving that this class of Machine Learning approaches can
become a new and powerful tool for the long timescale and high throughput
simulation of materials, while retaining thermodynamic consistency and
high-accuracy.",2024-07-29,"Daniele Lanzoni, Andrea Fantasia, Roberto Bergamaschini, Olivier Pierre-Louis, Francesco Montalenti",http://arxiv.org/pdf/2407.20126v2,cs.LG
Tightening the Evaluation of PAC Bounds Using Formal Verification Results,"Probably Approximately Correct (PAC) bounds are widely used to derive
probabilistic guarantees for the generalisation of machine learning models.
They highlight the components of the model which contribute to its
generalisation capacity. However, current state-of-the-art results are loose in
approximating the generalisation capacity of deployed machine learning models.
Consequently, while PAC bounds are theoretically useful, their applicability
for evaluating a model's generalisation property in a given operational design
domain is limited. The underlying classical theory is supported by the idea
that bounds can be tightened when the number of test points available to the
user to evaluate the model increases. Yet, in the case of neural networks, the
number of test points required to obtain bounds of interest is often
impractical even for small problems.
  In this paper, we take the novel approach of using the formal verification of
neural systems to inform the evaluation of PAC bounds. Rather than using
pointwise information obtained from repeated tests, we use verification results
on regions around test points. We show that conditioning existing bounds on
verification results leads to a tightening proportional to the underlying
probability mass of the verified region.",2024-07-29,"Thomas Walker, Alessio Lomuscio",http://arxiv.org/pdf/2407.20122v1,cs.LG
Adaptive Self-supervised Robust Clustering for Unstructured Data with Unknown Cluster Number,"We introduce a novel self-supervised deep clustering approach tailored for
unstructured data without requiring prior knowledge of the number of clusters,
termed Adaptive Self-supervised Robust Clustering (ASRC). In particular, ASRC
adaptively learns the graph structure and edge weights to capture both local
and global structural information. The obtained graph enables us to learn
clustering-friendly feature representations by an enhanced graph auto-encoder
with contrastive learning technique. It further leverages the clustering
results adaptively obtained by robust continuous clustering (RCC) to generate
prototypes for negative sampling, which can further contribute to promoting
consistency among positive pairs and enlarging the gap between positive and
negative samples. ASRC obtains the final clustering results by applying RCC to
the learned feature representations with their consistent graph structure and
edge weights. Extensive experiments conducted on seven benchmark datasets
demonstrate the efficacy of ASRC, demonstrating its superior performance over
other popular clustering models. Notably, ASRC even outperforms methods that
rely on prior knowledge of the number of clusters, highlighting its
effectiveness in addressing the challenges of clustering unstructured data.",2024-07-29,"Chen-Lu Ding, Jiancan Wu, Wei Lin, Shiyang Shen, Xiang Wang, Yancheng Yuan",http://arxiv.org/pdf/2407.20119v2,cs.LG
"Quantum Computing and Neuromorphic Computing for Safe, Reliable, and explainable Multi-Agent Reinforcement Learning: Optimal Control in Autonomous Robotics","This paper investigates the utilization of Quantum Computing and Neuromorphic
Computing for Safe, Reliable, and Explainable Multi_Agent Reinforcement
Learning (MARL) in the context of optimal control in autonomous robotics. The
objective was to address the challenges of optimizing the behavior of
autonomous agents while ensuring safety, reliability, and explainability.
Quantum Computing techniques, including Quantum Approximate Optimization
Algorithm (QAOA), were employed to efficiently explore large solution spaces
and find approximate solutions to complex MARL problems. Neuromorphic
Computing, inspired by the architecture of the human brain, provided parallel
and distributed processing capabilities, which were leveraged to develop
intelligent and adaptive systems. The combination of these technologies held
the potential to enhance the safety, reliability, and explainability of MARL in
autonomous robotics. This research contributed to the advancement of autonomous
robotics by exploring cutting-edge technologies and their applications in
multi-agent systems. Codes and data are available.",2024-07-29,Mazyar Taghavi,http://arxiv.org/pdf/2408.03884v1,cs.LG
Diffusion-DICE: In-Sample Diffusion Guidance for Offline Reinforcement Learning,"One important property of DIstribution Correction Estimation (DICE) methods
is that the solution is the optimal stationary distribution ratio between the
optimized and data collection policy. In this work, we show that DICE-based
methods can be viewed as a transformation from the behavior distribution to the
optimal policy distribution. Based on this, we propose a novel approach,
Diffusion-DICE, that directly performs this transformation using diffusion
models. We find that the optimal policy's score function can be decomposed into
two terms: the behavior policy's score function and the gradient of a guidance
term which depends on the optimal distribution ratio. The first term can be
obtained from a diffusion model trained on the dataset and we propose an
in-sample learning objective to learn the second term. Due to the
multi-modality contained in the optimal policy distribution, the transformation
in Diffusion-DICE may guide towards those local-optimal modes. We thus generate
a few candidate actions and carefully select from them to approach
global-optimum. Different from all other diffusion-based offline RL methods,
the guide-then-select paradigm in Diffusion-DICE only uses in-sample actions
for training and brings minimal error exploitation in the value function. We
use a didatic toycase example to show how previous diffusion-based methods fail
to generate optimal actions due to leveraging these errors and how
Diffusion-DICE successfully avoids that. We then conduct extensive experiments
on benchmark datasets to show the strong performance of Diffusion-DICE. Project
page at https://ryanxhr.github.io/Diffusion-DICE/.",2024-07-29,"Liyuan Mao, Haoran Xu, Xianyuan Zhan, Weinan Zhang, Amy Zhang",http://arxiv.org/pdf/2407.20109v2,cs.LG
Strong Copyright Protection for Language Models via Adaptive Model Fusion,"The risk of language models unintentionally reproducing copyrighted material
from their training data has led to the development of various protective
measures. In this paper, we propose model fusion as an effective solution to
safeguard against copyright infringement. In particular, we introduce
Copyright-Protecting Fusion (CP-Fuse), an algorithm that adaptively combines
language models to minimize the reproduction of protected materials. CP-Fuse is
inspired by the recently proposed Near-Access Free (NAF) framework and
additionally incorporates a desirable balancing property that we demonstrate
prevents the reproduction of memorized training data. Our results show that
CP-Fuse significantly reduces the memorization of copyrighted content while
maintaining high-quality text and code generation. Furthermore, we demonstrate
how CP-Fuse can be integrated with other techniques for enhanced protection.",2024-07-29,"Javier Abad, Konstantin Donhauser, Francesco Pinto, Fanny Yang",http://arxiv.org/pdf/2407.20105v1,cs.LG
F-KANs: Federated Kolmogorov-Arnold Networks,"In this paper, we present an innovative federated learning (FL) approach that
utilizes Kolmogorov-Arnold Networks (KANs) for classification tasks. By
utilizing the adaptive activation capabilities of KANs in a federated
framework, we aim to improve classification capabilities while preserving
privacy. The study evaluates the performance of federated KANs (F- KANs)
compared to traditional Multi-Layer Perceptrons (MLPs) on classification task.
The results show that the F-KANs model significantly outperforms the federated
MLP model in terms of accuracy, precision, recall, F1 score and stability, and
achieves better performance, paving the way for more efficient and
privacy-preserving predictive analytics.",2024-07-29,"Engin Zeydan, Cristian J. Vaca-Rubio, Luis Blanco, Roberto Pereira, Marius Caus, Abdullah Aydeger",http://arxiv.org/pdf/2407.20100v3,cs.LG
UniTTA: Unified Benchmark and Versatile Framework Towards Realistic Test-Time Adaptation,"Test-Time Adaptation (TTA) aims to adapt pre-trained models to the target
domain during testing. In reality, this adaptability can be influenced by
multiple factors. Researchers have identified various challenging scenarios and
developed diverse methods to address these challenges, such as dealing with
continual domain shifts, mixed domains, and temporally correlated or imbalanced
class distributions. Despite these efforts, a unified and comprehensive
benchmark has yet to be established. To this end, we propose a Unified
Test-Time Adaptation (UniTTA) benchmark, which is comprehensive and widely
applicable. Each scenario within the benchmark is fully described by a Markov
state transition matrix for sampling from the original dataset. The UniTTA
benchmark considers both domain and class as two independent dimensions of data
and addresses various combinations of imbalance/balance and
i.i.d./non-i.i.d./continual conditions, covering a total of \( (2 \times 3)^2 =
36 \) scenarios. It establishes a comprehensive evaluation benchmark for
realistic TTA and provides a guideline for practitioners to select the most
suitable TTA method. Alongside this benchmark, we propose a versatile UniTTA
framework, which includes a Balanced Domain Normalization (BDN) layer and a
COrrelated Feature Adaptation (COFA) method--designed to mitigate distribution
gaps in domain and class, respectively. Extensive experiments demonstrate that
our UniTTA framework excels within the UniTTA benchmark and achieves
state-of-the-art performance on average. Our code is available at
\url{https://github.com/LeapLabTHU/UniTTA}.",2024-07-29,"Chaoqun Du, Yulin Wang, Jiayi Guo, Yizeng Han, Jie Zhou, Gao Huang",http://arxiv.org/pdf/2407.20080v1,cs.LG
An Interpretable Rule Creation Method for Black-Box Models based on Surrogate Trees -- SRules,"As artificial intelligence (AI) systems become increasingly integrated into
critical decision-making processes, the need for transparent and interpretable
models has become paramount. In this article we present a new ruleset creation
method based on surrogate decision trees (SRules), designed to improve the
interpretability of black-box machine learning models. SRules balances the
accuracy, coverage, and interpretability of machine learning models by
recursively creating surrogate interpretable decision tree models that
approximate the decision boundaries of a complex model. We propose a systematic
framework for generating concise and meaningful rules from these surrogate
models, allowing stakeholders to understand and trust the AI system's
decision-making process. Our approach not only provides interpretable rules,
but also quantifies the confidence and coverage of these rules. The proposed
model allows to adjust its parameters to counteract the lack of
interpretability by precision and coverage by allowing a near perfect fit and
high interpretability of some parts of the model . The results show that SRules
improves on other state-of-the-art techniques and introduces the possibility of
creating highly interpretable specific rules for specific sub-parts of the
model.",2024-07-29,"Mario Parrón Verdasco, Esteban García-Cuesta",http://arxiv.org/pdf/2407.20070v1,cs.LG
xAI-Drop: Don't Use What You Cannot Explain,"Graph Neural Networks (GNNs) have emerged as the predominant paradigm for
learning from graph-structured data, offering a wide range of applications from
social network analysis to bioinformatics. Despite their versatility, GNNs face
challenges such as lack of generalization and poor interpretability, which
hinder their wider adoption and reliability in critical applications. Dropping
has emerged as an effective paradigm for improving the generalization
capabilities of GNNs. However, existing approaches often rely on random or
heuristic-based selection criteria, lacking a principled method to identify and
exclude nodes that contribute to noise and over-complexity in the model. In
this work, we argue that explainability should be a key indicator of a model's
quality throughout its training phase. To this end, we introduce xAI-Drop, a
novel topological-level dropping regularizer that leverages explainability to
pinpoint noisy network elements to be excluded from the GNN propagation
mechanism. An empirical evaluation on diverse real-world datasets demonstrates
that our method outperforms current state-of-the-art dropping approaches in
accuracy, and improves explanation quality.",2024-07-29,"Vincenzo Marco De Luca, Antonio Longa, Andrea Passerini, Pietro Liò",http://arxiv.org/pdf/2407.20067v2,cs.LG
SalNAS: Efficient Saliency-prediction Neural Architecture Search with self-knowledge distillation,"Recent advancements in deep convolutional neural networks have significantly
improved the performance of saliency prediction. However, the manual
configuration of the neural network architectures requires domain knowledge
expertise and can still be time-consuming and error-prone. To solve this, we
propose a new Neural Architecture Search (NAS) framework for saliency
prediction with two contributions. Firstly, a supernet for saliency prediction
is built with a weight-sharing network containing all candidate architectures,
by integrating a dynamic convolution into the encoder-decoder in the supernet,
termed SalNAS. Secondly, despite the fact that SalNAS is highly efficient
(20.98 million parameters), it can suffer from the lack of generalization. To
solve this, we propose a self-knowledge distillation approach, termed Self-KD,
that trains the student SalNAS with the weighted average information between
the ground truth and the prediction from the teacher model. The teacher model,
while sharing the same architecture, contains the best-performing weights
chosen by cross-validation. Self-KD can generalize well without the need to
compute the gradient in the teacher model, enabling an efficient training
system. By utilizing Self-KD, SalNAS outperforms other state-of-the-art
saliency prediction models in most evaluation rubrics across seven benchmark
datasets while being a lightweight model. The code will be available at
https://github.com/chakkritte/SalNAS",2024-07-29,"Chakkrit Termritthikun, Ayaz Umer, Suwichaya Suwanwimolkul, Feng Xia, Ivan Lee",http://arxiv.org/pdf/2407.20062v1,cs.LG
Autonomous Bootstrapping of Quantum Dot Devices,"Semiconductor quantum dots (QDs) are a promising platform for multiple
different qubit implementations, all of which are voltage controlled by
programmable gate electrodes. However, as the QD arrays grow in size and
complexity, tuning procedures that can fully autonomously handle the increasing
number of control parameters are becoming essential for enabling scalability.
We propose a bootstrapping algorithm for initializing a depletion-mode QD
device in preparation for subsequent phases of tuning. During bootstrapping,
the QD device functionality is validated, all gates are characterized, and the
QD charge sensor is made operational. We demonstrate the bootstrapping protocol
in conjunction with a coarse-tuning module, showing that the combined algorithm
can efficiently and reliably take a cooled-down QD device to a desired
global-state configuration in under 8 min with a success rate of 96 %. Finally,
by following heuristic approaches to QD device initialization and combining the
efficient ray-based measurement with the rapid radio-frequency reflectometry
measurements, the proposed algorithm establishes a reference in terms of
performance, reliability, and efficiency against which alternative algorithms
can be benchmarked.",2024-07-29,"Anton Zubchenko, Danielle Middlebrooks, Torbjørn Rasmussen, Lara Lausen, Ferdinand Kuemmeth, Anasua Chatterjee, Justyna P. Zwolak",http://arxiv.org/pdf/2407.20061v2,cs.LG
RelBench: A Benchmark for Deep Learning on Relational Databases,"We present RelBench, a public benchmark for solving predictive tasks over
relational databases with graph neural networks. RelBench provides databases
and tasks spanning diverse domains and scales, and is intended to be a
foundational infrastructure for future research. We use RelBench to conduct the
first comprehensive study of Relational Deep Learning (RDL) (Fey et al., 2024),
which combines graph neural network predictive models with (deep) tabular
models that extract initial entity-level representations from raw tables.
End-to-end learned RDL models fully exploit the predictive signal encoded in
primary-foreign key links, marking a significant shift away from the dominant
paradigm of manual feature engineering combined with tabular models. To
thoroughly evaluate RDL against this prior gold-standard, we conduct an
in-depth user study where an experienced data scientist manually engineers
features for each task. In this study, RDL learns better models whilst reducing
human work needed by more than an order of magnitude. This demonstrates the
power of deep learning for solving predictive tasks over relational databases,
opening up many new research opportunities enabled by RelBench.",2024-07-29,"Joshua Robinson, Rishabh Ranjan, Weihua Hu, Kexin Huang, Jiaqi Han, Alejandro Dobles, Matthias Fey, Jan E. Lenssen, Yiwen Yuan, Zecheng Zhang, Xinwei He, Jure Leskovec",http://arxiv.org/pdf/2407.20060v1,cs.LG
Reconstructing Global Daily CO2 Emissions via Machine Learning,"High temporal resolution CO2 emission data are crucial for understanding the
drivers of emission changes, however, current emission dataset is only
available on a yearly basis. Here, we extended a global daily CO2 emissions
dataset backwards in time to 1970 using machine learning algorithm, which was
trained to predict historical daily emissions on national scales based on
relationships between daily emission variations and predictors established for
the period since 2019. Variation in daily CO2 emissions far exceeded the
smoothed seasonal variations. For example, the range of daily CO2 emissions
equivalent to 31% of the year average daily emissions in China and 46% of that
in India in 2022, respectively. We identified the critical emission-climate
temperature (Tc) is 16.5 degree celsius for global average (18.7 degree celsius
for China, 14.9 degree celsius for U.S., and 18.4 degree celsius for Japan), in
which negative correlation observed between daily CO2 emission and ambient
temperature below Tc and a positive correlation above it, demonstrating
increased emissions associated with higher ambient temperature. The long-term
time series spanning over fifty years of global daily CO2 emissions reveals an
increasing trend in emissions due to extreme temperature events, driven by the
rising frequency of these occurrences. This work suggests that, due to climate
change, greater efforts may be needed to reduce CO2 emissions.",2024-07-29,"Tao Li, Lixing Wang, Zihan Qiu, Philippe Ciais, Taochun Sun, Matthew W. Jones, Robbie M. Andrew, Glen P. Peters, Piyu ke, Xiaoting Huang, Robert B. Jackson, Zhu Liu",http://arxiv.org/pdf/2407.20057v1,cs.LG
Orca: Ocean Significant Wave Height Estimation with Spatio-temporally Aware Large Language Models,"Significant wave height (SWH) is a vital metric in marine science, and
accurate SWH estimation is crucial for various applications, e.g., marine
energy development, fishery, early warning systems for potential risks, etc.
Traditional SWH estimation methods that are based on numerical models and
physical theories are hindered by computational inefficiencies. Recently,
machine learning has emerged as an appealing alternative to improve accuracy
and reduce computational time. However, due to limited observational technology
and high costs, the scarcity of real-world data restricts the potential of
machine learning models. To overcome these limitations, we propose an ocean SWH
estimation framework, namely Orca. Specifically, Orca enhances the limited
spatio-temporal reasoning abilities of classic LLMs with a novel spatiotemporal
aware encoding module. By segmenting the limited buoy observational data
temporally, encoding the buoys' locations spatially, and designing prompt
templates, Orca capitalizes on the robust generalization ability of LLMs to
estimate significant wave height effectively with limited data. Experimental
results on the Gulf of Mexico demonstrate that Orca achieves state-of-the-art
performance in SWH estimation.",2024-07-29,"Zhe Li, Ronghui Xu, Jilin Hu, Zhong Peng, Xi Lu, Chenjuan Guo, Bin Yang",http://arxiv.org/pdf/2407.20053v1,cs.LG
Denoising ESG: quantifying data uncertainty from missing data with Machine Learning and prediction intervals,"Environmental, Social, and Governance (ESG) datasets are frequently plagued
by significant data gaps, leading to inconsistencies in ESG ratings due to
varying imputation methods. This paper explores the application of established
machine learning techniques for imputing missing data in a real-world ESG
dataset, emphasizing the quantification of uncertainty through prediction
intervals. By employing multiple imputation strategies, this study assesses the
robustness of imputation methods and quantifies the uncertainty associated with
missing data. The findings highlight the importance of probabilistic machine
learning models in providing better understanding of ESG scores, thereby
addressing the inherent risks of wrong ratings due to incomplete data. This
approach improves imputation practices to enhance the reliability of ESG
ratings.",2024-07-29,"Sergio Caprioli, Jacopo Foschi, Riccardo Crupi, Alessandro Sabatino",http://arxiv.org/pdf/2407.20047v1,cs.LG
Application of Unsupervised Artificial Neural Network (ANN) Self_Organizing Map (SOM) in Identifying Main Car Sales Factors,"Factors which attract customers and persuade them to buy new car are various
regarding different consumer tastes. There are some methods to extract pattern
form mass data. In this case we firstly asked passenger car marketing experts
to rank more important factors which affect customer decision making behavior
using fuzzy Delphi technique, then we provided a sample set from questionnaires
and tried to apply a useful artificial neural network method called
self_organizing map SOM to find out which factors have more effect on Iranian
customer's buying decision making. Fuzzy tools were applied to adjust the study
to be more real. MATLAB software was used for developing and training network.
Results report four factors are more important rather than the others. Results
are rather different from marketing expert rankings. Such results would help
manufacturers to focus on more important factors and increase company sales
level.",2024-07-29,Mazyar Taghavi,http://arxiv.org/pdf/2408.05110v1,cs.LG
Aircraft Trajectory Segmentation-based Contrastive Coding: A Framework for Self-supervised Trajectory Representation,"Air traffic trajectory recognition has gained significant interest within the
air traffic management community, particularly for fundamental tasks such as
classification and clustering. This paper introduces Aircraft Trajectory
Segmentation-based Contrastive Coding (ATSCC), a novel self-supervised time
series representation learning framework designed to capture semantic
information in air traffic trajectory data. The framework leverages the
segmentable characteristic of trajectories and ensures consistency within the
self-assigned segments. Intensive experiments were conducted on datasets from
three different airports, totaling four datasets, comparing the learned
representation's performance of downstream classification and clustering with
other state-of-the-art representation learning techniques. The results show
that ATSCC outperforms these methods by aligning with the labels defined by
aeronautical procedures. ATSCC is adaptable to various airport configurations
and scalable to incomplete trajectories. This research has expanded upon
existing capabilities, achieving these improvements independently without
predefined inputs such as airport configurations, maneuvering procedures, or
labeled data.",2024-07-29,"Thaweerath Phisannupawong, Joshua Julian Damanik, Han-Lim Choi",http://arxiv.org/pdf/2407.20028v1,cs.LG
MimiQ: Low-Bit Data-Free Quantization of Vision Transformers with Encouraging Inter-Head Attention Similarity,"Data-free quantization (DFQ) is a technique that creates a lightweight
network from its full-precision counterpart without the original training data,
often through a synthetic dataset. Although several DFQ methods have been
proposed for vision transformer (ViT) architectures, they fail to achieve
efficacy in low-bit settings. Examining the existing methods, we observe that
their synthetic data produce misaligned attention maps, while those of the real
samples are highly aligned. From this observation, we find that aligning
attention maps of synthetic data helps improve the overall performance of
quantized ViTs. Motivated by this finding, we devise MimiQ, a novel DFQ method
designed for ViTs that enhances inter-head attention similarity. First, we
generate synthetic data by aligning head-wise attention outputs from each
spatial query patch. Then, we align the attention maps of the quantized network
to those of the full-precision teacher by applying head-wise structural
attention distillation. The experimental results show that the proposed method
significantly outperforms baselines, setting a new state-of-the-art for
ViT-DFQ. This paper is an extended version of our work published in the
proceedings of AAAI 2025, including additional supplementary material.",2024-07-29,"Kanghyun Choi, Hye Yoon Lee, Dain Kwon, SunJong Park, Kyuyeun Kim, Noseong Park, Jonghyun Choi, Jinho Lee",http://arxiv.org/pdf/2407.20021v4,cs.LG
ImagiNet: A Multi-Content Benchmark for Synthetic Image Detection,"Recent generative models produce images with a level of authenticity that
makes them nearly indistinguishable from real photos and artwork. Potential
harmful use cases of these models, necessitate the creation of robust synthetic
image detectors. However, current datasets in the field contain generated
images with questionable quality or have examples from one predominant content
type which leads to poor generalizability of the underlying detectors. We find
that the curation of a balanced amount of high-resolution generated images
across various content types is crucial for the generalizability of detectors,
and introduce ImagiNet, a dataset of 200K examples, spanning four categories:
photos, paintings, faces, and miscellaneous. Synthetic images in ImagiNet are
produced with both open-source and proprietary generators, whereas real
counterparts for each content type are collected from public datasets. The
structure of ImagiNet allows for a two-track evaluation system: i)
classification as real or synthetic and ii) identification of the generative
model. To establish a strong baseline, we train a ResNet-50 model using a
self-supervised contrastive objective (SelfCon) for each track which achieves
evaluation AUC of up to 0.99 and balanced accuracy ranging from 86% to 95%,
even under conditions that involve compression and resizing. The provided model
is generalizable enough to achieve zero-shot state-of-the-art performance on
previous synthetic detection benchmarks. We provide ablations to demonstrate
the importance of content types and publish code and data.",2024-07-29,"Delyan Boychev, Radostin Cholakov",http://arxiv.org/pdf/2407.20020v3,cs.LG
Classification of freshwater snails of the genus Radomaniola with multimodal triplet networks,"In this paper, we present our first proposal of a machine learning system for
the classification of freshwater snails of the genus Radomaniola. We elaborate
on the specific challenges encountered during system design, and how we tackled
them; namely a small, very imbalanced dataset with a high number of classes and
high visual similarity between classes. We then show how we employed triplet
networks and the multiple input modalities of images, measurements, and genetic
information to overcome these challenges and reach a performance comparable to
that of a trained domain expert.",2024-07-29,"Dennis Vetter, Muhammad Ahsan, Diana Delicado, Thomas A. Neubauer, Thomas Wilke, Gemma Roig",http://arxiv.org/pdf/2407.20013v2,cs.LG
On the Effects of Irrelevant Variables in Treatment Effect Estimation with Deep Disentanglement,"Estimating treatment effects from observational data is paramount in
healthcare, education, and economics, but current deep disentanglement-based
methods to address selection bias are insufficiently handling irrelevant
variables. We demonstrate in experiments that this leads to prediction errors.
We disentangle pre-treatment variables with a deep embedding method and
explicitly identify and represent irrelevant variables, additionally to
instrumental, confounding and adjustment latent factors. To this end, we
introduce a reconstruction objective and create an embedding space for
irrelevant variables using an attached autoencoder. Instead of relying on
serendipitous suppression of irrelevant variables as in previous deep
disentanglement approaches, we explicitly force irrelevant variables into this
embedding space and employ orthogonalization to prevent irrelevant information
from leaking into the latent space representations of the other factors. Our
experiments with synthetic and real-world benchmark datasets show that we can
better identify irrelevant variables and more precisely predict treatment
effects than previous methods, while prediction quality degrades less when
additional irrelevant variables are introduced.",2024-07-29,"Ahmad Saeed Khan, Erik Schaffernicht, Johannes Andreas Stork",http://arxiv.org/pdf/2407.20003v2,cs.LG
Collision Probability Distribution Estimation via Temporal Difference Learning,"We introduce CollisionPro, a pioneering framework designed to estimate
cumulative collision probability distributions using temporal difference
learning, specifically tailored to applications in robotics, with a particular
emphasis on autonomous driving. This approach addresses the demand for
explainable artificial intelligence (XAI) and seeks to overcome limitations
imposed by model-based approaches and conservative constraints. We formulate
our framework within the context of reinforcement learning to pave the way for
safety-aware agents. Nevertheless, we assert that our approach could prove
beneficial in various contexts, including a safety alert system or analytical
purposes. A comprehensive examination of our framework is conducted using a
realistic autonomous driving simulator, illustrating its high sample efficiency
and reliable prediction capabilities for previously unseen collision events.
The source code is publicly available.",2024-07-29,"Thomas Steinecker, Thorsten Luettel, Mirko Maehlisch",http://arxiv.org/pdf/2407.20000v1,cs.LG
Classification of Alzheimer's Dementia vs. Healthy subjects by studying structural disparities in fMRI Time-Series of DMN,"Time series from different regions of interest (ROI) of default mode network
(DMN) from Functional Magnetic Resonance Imaging (fMRI) can reveal significant
differences between healthy and unhealthy people. Here, we propose the utility
of an existing metric quantifying the lack/presence of structure in a signal
called, ""deviation from stochasticity"" (DS) measure to characterize
resting-state fMRI time series. The hypothesis is that differences in the level
of structure in the time series can lead to discrimination between the subject
groups. In this work, an autoencoder-based model is utilized to learn efficient
representations of data by training the network to reconstruct its input data.
The proposed methodology is applied on fMRI time series of 50 healthy
individuals and 50 subjects with Alzheimer's Disease (AD), obtained from
publicly available ADNI database. DS measure for healthy fMRI as expected turns
out to be different compared to that of AD. Peak classification accuracy of 95%
was obtained using Gradient Boosting classifier, using the DS measure applied
on 100 subjects.",2024-07-29,"Sneha Noble, Chakka Sai Pradeep, Neelam Sinha, Thomas Gregor Issac",http://arxiv.org/pdf/2407.19990v1,cs.LG
Mixture of Nested Experts: Adaptive Processing of Visual Tokens,"The visual medium (images and videos) naturally contains a large amount of
information redundancy, thereby providing a great opportunity for leveraging
efficiency in processing. While Vision Transformer (ViT) based models scale
effectively to large data regimes, they fail to capitalize on this inherent
redundancy, leading to higher computational costs. Mixture of Experts (MoE)
networks demonstrate scalability while maintaining same inference-time costs,
but they come with a larger parameter footprint. We present Mixture of Nested
Experts (MoNE), which utilizes a nested structure for experts, wherein
individual experts fall on an increasing compute-accuracy curve. Given a
compute budget, MoNE learns to dynamically choose tokens in a priority order,
and thus redundant tokens are processed through cheaper nested experts. Using
this framework, we achieve equivalent performance as the baseline models, while
reducing inference time compute by over two-fold. We validate our approach on
standard image and video datasets - ImageNet-21K, Kinetics400, and
Something-Something-v2. We further highlight MoNE$'$s adaptability by
showcasing its ability to maintain strong performance across different
inference-time compute budgets on videos, using only a single trained model.",2024-07-29,"Gagan Jain, Nidhi Hegde, Aditya Kusupati, Arsha Nagrani, Shyamal Buch, Prateek Jain, Anurag Arnab, Sujoy Paul",http://arxiv.org/pdf/2407.19985v2,cs.LG
Can I trust my anomaly detection system? A case study based on explainable AI,"Generative models based on variational autoencoders are a popular technique
for detecting anomalies in images in a semi-supervised context. A common
approach employs the anomaly score to detect the presence of anomalies, and it
is known to reach high level of accuracy on benchmark datasets. However, since
anomaly scores are computed from reconstruction disparities, they often obscure
the detection of various spurious features, raising concerns regarding their
actual efficacy. This case study explores the robustness of an anomaly
detection system based on variational autoencoder generative models through the
use of eXplainable AI methods. The goal is to get a different perspective on
the real performances of anomaly detectors that use reconstruction differences.
In our case study we discovered that, in many cases, samples are detected as
anomalous for the wrong or misleading factors.",2024-07-29,"Muhammad Rashid, Elvio Amparore, Enrico Ferrari, Damiano Verda",http://arxiv.org/pdf/2407.19951v1,cs.LG
"Inference acceleration for large language models using ""stairs"" assisted greedy generation","Large Language Models (LLMs) with billions of parameters are known for their
impressive predicting capabilities but require lots of resources to run. With
their massive rise in popularity, even a small reduction in required resources
could have an impact on environment. On the other hand, smaller models require
fewer resources but may sacrifice accuracy. In this work, we are proposing an
implementation of ``stairs'' assisted greedy generation. It is a modified
assisted generation methodology that makes use of a smaller model's fast
generation, large model's batch prediction, and ""stairs"" validation in order to
achieve a speed up in prediction generation. Results show between 9.58 and
17.24 percent inference time reduction compared to a stand-alone large LLM
prediction in a text generation task without a loss in accuracy.",2024-07-29,"Domas Grigaliūnas, Mantas Lukoševičius",http://arxiv.org/pdf/2407.19947v1,cs.LG
Noise-Resilient Unsupervised Graph Representation Learning via Multi-Hop Feature Quality Estimation,"Unsupervised graph representation learning (UGRL) based on graph neural
networks (GNNs), has received increasing attention owing to its efficacy in
handling graph-structured data. However, existing UGRL methods ideally assume
that the node features are noise-free, which makes them fail to distinguish
between useful information and noise when applied to real data with noisy
features, thus affecting the quality of learned representations. This urges us
to take node noisy features into account in real-world UGRL. With empirical
analysis, we reveal that feature propagation, the essential operation in GNNs,
acts as a ""double-edged sword"" in handling noisy features - it can both denoise
and diffuse noise, leading to varying feature quality across nodes, even within
the same node at different hops. Building on this insight, we propose a novel
UGRL method based on Multi-hop feature Quality Estimation (MQE for short).
Unlike most UGRL models that directly utilize propagation-based GNNs to
generate representations, our approach aims to learn representations through
estimating the quality of propagated features at different hops. Specifically,
we introduce a Gaussian model that utilizes a learnable ""meta-representation""
as a condition to estimate the expectation and variance of multi-hop propagated
features via neural networks. In this way, the ""meta representation"" captures
the semantic and structural information underlying multiple propagated features
but is naturally less susceptible to interference by noise, thereby serving as
high-quality node representations beneficial for downstream tasks. Extensive
experiments on multiple real-world datasets demonstrate that MQE in learning
reliable node representations in scenarios with diverse types of feature noise.",2024-07-29,"Shiyuan Li, Yixin Liu, Qingfeng Chen, Geoffrey I. Webb, Shirui Pan",http://arxiv.org/pdf/2407.19944v1,cs.LG
Practical and Robust Safety Guarantees for Advanced Counterfactual Learning to Rank,"Counterfactual learning to rank (CLTR) can be risky and, in various
circumstances, can produce sub-optimal models that hurt performance when
deployed. Safe CLTR was introduced to mitigate these risks when using inverse
propensity scoring to correct for position bias. However, the existing safety
measure for CLTR is not applicable to state-of-the-art CLTR methods, cannot
handle trust bias, and relies on specific assumptions about user behavior. Our
contributions are two-fold. First, we generalize the existing safe CLTR
approach to make it applicable to state-of-the-art doubly robust CLTR and trust
bias. Second, we propose a novel approach, proximal ranking policy optimization
(PRPO), that provides safety in deployment without assumptions about user
behavior. PRPO removes incentives for learning ranking behavior that is too
dissimilar to a safe ranking model. Thereby, PRPO imposes a limit on how much
learned models can degrade performance metrics, without relying on any specific
user assumptions. Our experiments show that both our novel safe doubly robust
method and PRPO provide higher performance than the existing safe inverse
propensity scoring approach. However, in unexpected circumstances, the safe
doubly robust approach can become unsafe and bring detrimental performance. In
contrast, PRPO always maintains safety, even in maximally adversarial
situations. By avoiding assumptions, PRPO is the first method with
unconditional safety in deployment that translates to robust safety for
real-world applications.",2024-07-29,"Shashank Gupta, Harrie Oosterhuis, Maarten de Rijke",http://arxiv.org/pdf/2407.19943v2,cs.LG
Boosting Graph Foundation Model from Structural Perspective,"Graph foundation models have recently attracted significant attention due to
its strong generalizability. Although existing methods resort to language
models to learn unified semantic representations across domains, they disregard
the unique structural characteristics of graphs from different domains. To
address the problem, in this paper, we boost graph foundation model from
structural perspective and propose BooG. The model constructs virtual super
nodes to unify structural characteristics of graph data from different domains.
Specifically, the super nodes fuse the information of anchor nodes and class
labels, where each anchor node captures the information of a node or a graph
instance to be classified. Instead of using the raw graph structure, we connect
super nodes to all nodes within their neighborhood by virtual edges. This new
structure allows for effective information aggregation while unifying
cross-domain structural characteristics. Additionally, we propose a novel
pre-training objective based on contrastive learning, which learns more
expressive representations for graph data and generalizes effectively to
different domains and downstream tasks. Experimental results on various
datasets and tasks demonstrate the superior performance of BooG. We provide our
code and data here: https://anonymous.4open.science/r/BooG-EE42/.",2024-07-29,"Yao Cheng, Yige Zhao, Jianxiang Yu, Xiang Li",http://arxiv.org/pdf/2407.19941v1,cs.LG
Aero-Nef: Neural Fields for Rapid Aircraft Aerodynamics Simulations,"This paper presents a methodology to learn surrogate models of steady state
fluid dynamics simulations on meshed domains, based on Implicit Neural
Representations (INRs). The proposed models can be applied directly to
unstructured domains for different flow conditions, handle non-parametric 3D
geometric variations, and generalize to unseen shapes at test time. The
coordinate-based formulation naturally leads to robustness with respect to
discretization, allowing an excellent trade-off between computational cost
(memory footprint and training time) and accuracy. The method is demonstrated
on two industrially relevant applications: a RANS dataset of the
two-dimensional compressible flow over a transonic airfoil and a dataset of the
surface pressure distribution over 3D wings, including shape, inflow condition,
and control surface deflection variations. On the considered test cases, our
approach achieves a more than three times lower test error and significantly
improves generalization error on unseen geometries compared to state-of-the-art
Graph Neural Network architectures. Remarkably, the method can perform
inference five order of magnitude faster than the high fidelity solver on the
RANS transonic airfoil dataset. Code is available at
https://gitlab.isae-supaero.fr/gi.catalani/aero-nepf",2024-07-29,"Giovanni Catalani, Siddhant Agarwal, Xavier Bertrand, Frederic Tost, Michael Bauerheim, Joseph Morlier",http://arxiv.org/pdf/2407.19916v1,cs.LG
Sentiment Analysis of Lithuanian Online Reviews Using Large Language Models,"Sentiment analysis is a widely researched area within Natural Language
Processing (NLP), attracting significant interest due to the advent of
automated solutions. Despite this, the task remains challenging because of the
inherent complexity of languages and the subjective nature of sentiments. It is
even more challenging for less-studied and less-resourced languages such as
Lithuanian. Our review of existing Lithuanian NLP research reveals that
traditional machine learning methods and classification algorithms have limited
effectiveness for the task. In this work, we address sentiment analysis of
Lithuanian five-star-based online reviews from multiple domains that we collect
and clean. We apply transformer models to this task for the first time,
exploring the capabilities of pre-trained multilingual Large Language Models
(LLMs), specifically focusing on fine-tuning BERT and T5 models. Given the
inherent difficulty of the task, the fine-tuned models perform quite well,
especially when the sentiments themselves are less ambiguous: 80.74% and 89.61%
testing recognition accuracy of the most popular one- and five-star reviews
respectively. They significantly outperform current commercial state-of-the-art
general-purpose LLM GPT-4. We openly share our fine-tuned LLMs online.",2024-07-29,"Brigita Vileikytė, Mantas Lukoševičius, Lukas Stankevičius",http://arxiv.org/pdf/2407.19914v1,cs.LG
Efficient Shield Synthesis via State-Space Transformation,"We consider the problem of synthesizing safety strategies for control
systems, also known as shields. Since the state space is infinite, shields are
typically computed over a finite-state abstraction, with the most common
abstraction being a rectangular grid. However, for many systems, such a grid
does not align well with the safety property or the system dynamics. That is
why a coarse grid is rarely sufficient, but a fine grid is typically
computationally infeasible to obtain. In this paper, we show that appropriate
state-space transformations can still allow to use a coarse grid at almost no
computational overhead. We demonstrate in three case studies that our
transformation-based synthesis outperforms a standard synthesis by several
orders of magnitude. In the first two case studies, we use domain knowledge to
select a suitable transformation. In the third case study, we instead report on
results in engineering a transformation without domain knowledge.",2024-07-29,"Asger Horn Brorholt, Andreas Holck Høeg-Petersen, Kim Guldstrand Larsen, Christian Schilling",http://arxiv.org/pdf/2407.19911v4,cs.LG
BEExAI: Benchmark to Evaluate Explainable AI,"Recent research in explainability has given rise to numerous post-hoc
attribution methods aimed at enhancing our comprehension of the outputs of
black-box machine learning models. However, evaluating the quality of
explanations lacks a cohesive approach and a consensus on the methodology for
deriving quantitative metrics that gauge the efficacy of explainability
post-hoc attribution methods. Furthermore, with the development of increasingly
complex deep learning models for diverse data applications, the need for a
reliable way of measuring the quality and correctness of explanations is
becoming critical. We address this by proposing BEExAI, a benchmark tool that
allows large-scale comparison of different post-hoc XAI methods, employing a
set of selected evaluation metrics.",2024-07-29,"Samuel Sithakoul, Sara Meftah, Clément Feutry",http://arxiv.org/pdf/2407.19897v1,cs.LG
Making Multi-Axis Gaussian Graphical Models Scalable to Millions of Samples and Features,"Gaussian graphical models can be used to extract conditional dependencies
between the features of the dataset. This is often done by making an
independence assumption about the samples, but this assumption is rarely
satisfied in reality. However, state-of-the-art approaches that avoid this
assumption are not scalable, with $O(n^3)$ runtime and $O(n^2)$ space
complexity. In this paper, we introduce a method that has $O(n^2)$ runtime and
$O(n)$ space complexity, without assuming independence.
  We validate our model on both synthetic and real-world datasets, showing that
our method's accuracy is comparable to that of prior work We demonstrate that
our approach can be used on unprecedentedly large datasets, such as a
real-world 1,000,000-cell scRNA-seq dataset; this was impossible with previous
approaches. Our method maintains the flexibility of prior work, such as the
ability to handle multi-modal tensor-variate datasets and the ability to work
with data of arbitrary marginal distributions. An additional advantage of our
method is that, unlike prior work, our hyperparameters are easily
interpretable.",2024-07-29,"Bailey Andrew, David R. Westhead, Luisa Cutillo",http://arxiv.org/pdf/2407.19892v1,cs.LG
Yucca: A Deep Learning Framework For Medical Image Analysis,"Medical image analysis using deep learning frameworks has advanced healthcare
by automating complex tasks, but many existing frameworks lack flexibility,
modularity, and user-friendliness. To address these challenges, we introduce
Yucca, an open-source AI framework available at
https://github.com/Sllambias/yucca, designed specifically for medical imaging
applications and built on PyTorch and PyTorch Lightning. Yucca features a
three-tiered architecture: Functional, Modules, and Pipeline, providing a
comprehensive and customizable solution. Evaluated across diverse tasks such as
cerebral microbleeds detection, white matter hyperintensity segmentation, and
hippocampus segmentation, Yucca achieves state-of-the-art results,
demonstrating its robustness and versatility. Yucca offers a powerful,
flexible, and user-friendly platform for medical image analysis, inviting
community contributions to advance its capabilities and impact.",2024-07-29,"Sebastian Nørgaard Llambias, Julia Machnio, Asbjørn Munk, Jakob Ambsdorf, Mads Nielsen, Mostafa Mehdipour Ghazi",http://arxiv.org/pdf/2407.19888v1,cs.LG
OpenUAS: Embeddings of Cities in Japan with Anchor Data for Cross-city Analysis of Area Usage Patterns,"We publicly release OpenUAS, a dataset of area embeddings based on urban
usage patterns, including embeddings for over 1.3 million 50-meter square
meshes covering a total area of 3,300 square kilometers. This dataset is
valuable for analyzing area functions in fields such as market analysis, urban
planning, transportation infrastructure, and infection prediction. It captures
the characteristics of each area in the city, such as office districts and
residential areas, by employing an area embedding technique that utilizes
location information typically obtained by GPS. Numerous area embedding
techniques have been proposed, and while the public release of such embedding
datasets is technically feasible, it has not been realized. One reason for this
is that previous methods could not embed areas from different cities and
periods into the same embedding space without sharing raw location data. We
address this issue by developing an anchoring method that establishes anchors
within a shared embedding space. We publicly release this anchor dataset along
with area embedding datasets from several periods in eight major Japanese
cities.",2024-07-29,"Naoki Tamura, Kazuyuki Shoji, Shin Katayama, Kenta Urano, Takuro Yonezawa, Nobuo Kawaguchi",http://arxiv.org/pdf/2407.19872v3,cs.LG
Deep Image Priors for Magnetic Resonance Fingerprinting with pretrained Bloch-consistent denoising autoencoders,"The estimation of multi-parametric quantitative maps from Magnetic Resonance
Fingerprinting (MRF) compressed sampled acquisitions, albeit successful,
remains a challenge due to the high underspampling rate and artifacts naturally
occuring during image reconstruction. Whilst state-of-the-art DL methods can
successfully address the task, to fully exploit their capabilities they often
require training on a paired dataset, in an area where ground truth is seldom
available. In this work, we propose a method that combines a deep image prior
(DIP) module that, without ground truth and in conjunction with a Bloch
consistency enforcing autoencoder, can tackle the problem, resulting in a
method faster and of equivalent or better accuracy than DIP-MRF.",2024-07-29,"Perla Mayo, Matteo Cencini, Ketan Fatania, Carolin M. Pirkl, Marion I. Menzel, Bjoern H. Menze, Michela Tosetti, Mohammad Golbabaee",http://arxiv.org/pdf/2407.19866v1,cs.LG
Imitation Learning for Intra-Day Power Grid Operation through Topology Actions,"Power grid operation is becoming increasingly complex due to the increase in
generation of renewable energy. The recent series of Learning To Run a Power
Network (L2RPN) competitions have encouraged the use of artificial agents to
assist human dispatchers in operating power grids. In this paper we study the
performance of imitation learning for day-ahead power grid operation through
topology actions. In particular, we consider two rule-based expert agents: a
greedy agent and a N-1 agent. While the latter is more computationally
expensive since it takes N-1 safety considerations into account, it exhibits a
much higher operational performance. We train a fully-connected neural network
(FCNN) on expert state-action pairs and evaluate it in two ways. First, we find
that classification accuracy is limited despite extensive hyperparameter
tuning, due to class imbalance and class overlap. Second, as a power system
agent, the FCNN performs only slightly worse than expert agents. Furthermore,
hybrid agents, which incorporate minimal additional simulations, match expert
agents' performance with significantly lower computational cost. Consequently,
imitation learning shows promise for developing fast, high-performing power
grid agents, motivating its further exploration in future L2RPN studies.",2024-07-29,"Matthijs de Jong, Jan Viebahn, Yuliya Shapovalova",http://arxiv.org/pdf/2407.19865v2,cs.LG
Anomalous State Sequence Modeling to Enhance Safety in Reinforcement Learning,"The deployment of artificial intelligence (AI) in decision-making
applications requires ensuring an appropriate level of safety and reliability,
particularly in changing environments that contain a large number of unknown
observations. To address this challenge, we propose a novel safe reinforcement
learning (RL) approach that utilizes an anomalous state sequence to enhance RL
safety. Our proposed solution Safe Reinforcement Learning with Anomalous State
Sequences (AnoSeqs) consists of two stages. First, we train an agent in a
non-safety-critical offline 'source' environment to collect safe state
sequences. Next, we use these safe sequences to build an anomaly detection
model that can detect potentially unsafe state sequences in a 'target'
safety-critical environment where failures can have high costs. The estimated
risk from the anomaly detection model is utilized to train a risk-averse RL
policy in the target environment; this involves adjusting the reward function
to penalize the agent for visiting anomalous states deemed unsafe by our
anomaly model. In experiments on multiple safety-critical benchmarking
environments including self-driving cars, our solution approach successfully
learns safer policies and proves that sequential anomaly detection can provide
an effective supervisory signal for training safety-aware RL agents",2024-07-29,"Leen Kweider, Maissa Abou Kassem, Ubai Sandouk",http://arxiv.org/pdf/2407.19860v1,cs.LG
AI-Powered Energy Algorithmic Trading: Integrating Hidden Markov Models with Neural Networks,"In quantitative finance, machine learning methods are essential for alpha
generation. This study introduces a new approach that combines Hidden Markov
Models (HMM) and neural networks, integrated with Black-Litterman portfolio
optimization. During the COVID period (2019-2022), this dual-model approach
achieved a 83% return with a Sharpe ratio of 0.77. It incorporates two risk
models to enhance risk management, showing efficiency during volatile periods.
The methodology was implemented on the QuantConnect platform, which was chosen
for its robust framework and experimental reproducibility. The system, which
predicts future price movements, includes a three-year warm-up to ensure proper
algorithm function. It targets highly liquid, large-cap energy stocks to ensure
stable and predictable performance while also considering broker payments. The
dual-model alpha system utilizes log returns to select the optimal state based
on the historical performance. It combines state predictions with neural
network outputs, which are based on historical data, to generate trading
signals. This study examined the architecture of the trading system, data
pre-processing, training, and performance. The full code and backtesting data
are available under the QuantConnect terms.",2024-07-29,Tiago Monteiro,http://arxiv.org/pdf/2407.19858v5,cs.LG
Online Multi-Source Domain Adaptation through Gaussian Mixtures and Dataset Dictionary Learning,"This paper addresses the challenge of online multi-source domain adaptation
(MSDA) in transfer learning, a scenario where one needs to adapt multiple,
heterogeneous source domains towards a target domain that comes in a stream. We
introduce a novel approach for the online fit of a Gaussian Mixture Model
(GMM), based on the Wasserstein geometry of Gaussian measures. We build upon
this method and recent developments in dataset dictionary learning for
proposing a novel strategy in online MSDA. Experiments on the challenging
Tennessee Eastman Process benchmark demonstrate that our approach is able to
adapt \emph{on the fly} to the stream of target domain data. Furthermore, our
online GMM serves as a memory, representing the whole stream of data.",2024-07-29,"Eduardo Fernandes Montesuma, Stevan Le Stanc, Fred Ngolè Mboula",http://arxiv.org/pdf/2407.19853v1,cs.LG
Quantum Long Short-Term Memory for Drug Discovery,"Quantum computing combined with machine learning (ML) is an extremely
promising research area, with numerous studies demonstrating that quantum
machine learning (QML) is expected to solve scientific problems more
effectively than classical ML. In this work, we successfully apply QML to drug
discovery, showing that QML can significantly improve model performance and
achieve faster convergence compared to classical ML. Moreover, we demonstrate
that the model accuracy of the QML improves as the number of qubits increases.
We also introduce noise to the QML model and find that it has little effect on
our experimental conclusions, illustrating the high robustness of the QML
model. This work highlights the potential application of quantum computing to
yield significant benefits for scientific advancement as the qubit quantity
increase and quality improvement in the future.",2024-07-29,"Liang Zhang, Yin Xu, Mohan Wu, Liang Wang, Hua Xu",http://arxiv.org/pdf/2407.19852v1,cs.LG
BackdoorBench: A Comprehensive Benchmark and Analysis of Backdoor Learning,"As an emerging approach to explore the vulnerability of deep neural networks
(DNNs), backdoor learning has attracted increasing interest in recent years,
and many seminal backdoor attack and defense algorithms are being developed
successively or concurrently, in the status of a rapid arms race. However,
mainly due to the diverse settings, and the difficulties of implementation and
reproducibility of existing works, there is a lack of a unified and
standardized benchmark of backdoor learning, causing unfair comparisons or
unreliable conclusions (e.g., misleading, biased or even false conclusions).
Consequently, it is difficult to evaluate the current progress and design the
future development roadmap of this literature. To alleviate this dilemma, we
build a comprehensive benchmark of backdoor learning called BackdoorBench. Our
benchmark makes three valuable contributions to the research community. 1) We
provide an integrated implementation of state-of-the-art (SOTA) backdoor
learning algorithms (currently including 20 attack and 32 defense algorithms),
based on an extensible modular-based codebase. 2) We conduct comprehensive
evaluations with 5 poisoning ratios, based on 4 models and 4 datasets, leading
to 11,492 pairs of attack-against-defense evaluations in total. 3) Based on
above evaluations, we present abundant analysis from 10 perspectives via 18
useful analysis tools, and provide several inspiring insights about backdoor
learning. We hope that our efforts could build a solid foundation of backdoor
learning to facilitate researchers to investigate existing algorithms, develop
more innovative algorithms, and explore the intrinsic mechanism of backdoor
learning. Finally, we have created a user-friendly website at
http://backdoorbench.com, which collects all important information of
BackdoorBench, including codebase, docs, leaderboard, and model Zoo.",2024-07-29,"Baoyuan Wu, Hongrui Chen, Mingda Zhang, Zihao Zhu, Shaokui Wei, Danni Yuan, Mingli Zhu, Ruotong Wang, Li Liu, Chao Shen",http://arxiv.org/pdf/2407.19845v1,cs.LG
Detecting and Understanding Vulnerabilities in Language Models via Mechanistic Interpretability,"Large Language Models (LLMs), characterized by being trained on broad amounts
of data in a self-supervised manner, have shown impressive performance across a
wide range of tasks. Indeed, their generative abilities have aroused interest
on the application of LLMs across a wide range of contexts. However, neural
networks in general, and LLMs in particular, are known to be vulnerable to
adversarial attacks, where an imperceptible change to the input can mislead the
output of the model. This is a serious concern that impedes the use of LLMs on
high-stakes applications, such as healthcare, where a wrong prediction can
imply serious consequences. Even though there are many efforts on making LLMs
more robust to adversarial attacks, there are almost no works that study
\emph{how} and \emph{where} these vulnerabilities that make LLMs prone to
adversarial attacks happen. Motivated by these facts, we explore how to
localize and understand vulnerabilities, and propose a method, based on
Mechanistic Interpretability (MI) techniques, to guide this process.
Specifically, this method enables us to detect vulnerabilities related to a
concrete task by (i) obtaining the subset of the model that is responsible for
that task, (ii) generating adversarial samples for that task, and (iii) using
MI techniques together with the previous samples to discover and understand the
possible vulnerabilities. We showcase our method on a pretrained GPT-2 Small
model carrying out the task of predicting 3-letter acronyms to demonstrate its
effectiveness on locating and understanding concrete vulnerabilities of the
model.",2024-07-29,"Jorge García-Carrasco, Alejandro Maté, Juan Trujillo",http://arxiv.org/pdf/2407.19842v1,cs.LG
RNACG: A Universal RNA Sequence Conditional Generation model based on Flow-Matching,"RNA plays a pivotal role in diverse biological processes, ranging from gene
regulation to catalysis. Recent advances in RNA design, such as RfamGen,
Ribodiffusion and RDesign, have demonstrated promising results, with successful
designs of functional sequences. However, RNA design remains challenging due to
the inherent flexibility of RNA molecules and the scarcity of experimental data
on tertiary and secondary structures compared to proteins. These limitations
highlight the need for a more universal and comprehensive approach to RNA
design that integrates diverse annotation information at the sequence level. To
address these challenges, we propose RNACG (RNA Conditional Generator), a
universal framework for RNA sequence design based on flow matching. RNACG
supports diverse conditional inputs, including structural, functional, and
family-specific annotations, and offers a modular design that allows users to
customize the encoding network for specific tasks. By unifying sequence
generation under a single framework, RNACG enables the integration of multiple
RNA design paradigms, from family-specific generation to tertiary structure
inverse folding.",2024-07-29,"Letian Gao, Zhi John Lu",http://arxiv.org/pdf/2407.19838v2,cs.LG
Federated Learning based Latent Factorization of Tensors for Privacy-Preserving QoS Prediction,"In applications related to big data and service computing, dynamic
connections tend to be encountered, especially the dynamic data of
user-perspective quality of service (QoS) in Web services. They are transformed
into high-dimensional and incomplete (HDI) tensors which include abundant
temporal pattern information. Latent factorization of tensors (LFT) is an
extremely efficient and typical approach for extracting such patterns from an
HDI tensor. However, current LFT models require the QoS data to be maintained
in a central place (e.g., a central server), which is impossible for
increasingly privacy-sensitive users. To address this problem, this article
creatively designs a federated learning based on latent factorization of
tensors (FL-LFT). It builds a data-density -oriented federated learning model
to enable isolated users to collaboratively train a global LFT model while
protecting user's privacy. Extensive experiments on a QoS dataset collected
from the real world verify that FL-LFT shows a remarkable increase in
prediction accuracy when compared to state-of-the-art federated learning (FL)
approaches.",2024-07-29,"Shuai Zhong, Zengtong Tang, Di Wu",http://arxiv.org/pdf/2407.19828v1,cs.LG
Analyzing and reducing the synthetic-to-real transfer gap in Music Information Retrieval: the task of automatic drum transcription,"Automatic drum transcription is a critical tool in Music Information
Retrieval for extracting and analyzing the rhythm of a music track, but it is
limited by the size of the datasets available for training. A popular method
used to increase the amount of data is by generating them synthetically from
music scores rendered with virtual instruments. This method can produce a
virtually infinite quantity of tracks, but empirical evidence shows that models
trained on previously created synthetic datasets do not transfer well to real
tracks. In this work, besides increasing the amount of data, we identify and
evaluate three more strategies that practitioners can use to improve the
realism of the generated data and, thus, narrow the synthetic-to-real transfer
gap. To explore their efficacy, we used them to build a new synthetic dataset
and then we measured how the performance of a model scales and, specifically,
at what value it will stagnate when increasing the number of training tracks
for different datasets. By doing this, we were able to prove that the
aforementioned strategies contribute to make our dataset the one with the most
realistic data distribution and the lowest synthetic-to-real transfer gap among
the synthetic datasets we evaluated. We conclude by highlighting the limits of
training with infinite data in drum transcription and we show how they can be
overcome.",2024-07-29,"Mickaël Zehren, Marco Alunno, Paolo Bientinesi",http://arxiv.org/pdf/2407.19823v1,cs.LG
Enhancing Adversarial Text Attacks on BERT Models with Projected Gradient Descent,"Adversarial attacks against deep learning models represent a major threat to
the security and reliability of natural language processing (NLP) systems. In
this paper, we propose a modification to the BERT-Attack framework, integrating
Projected Gradient Descent (PGD) to enhance its effectiveness and robustness.
The original BERT-Attack, designed for generating adversarial examples against
BERT-based models, suffers from limitations such as a fixed perturbation budget
and a lack of consideration for semantic similarity. The proposed approach in
this work, PGD-BERT-Attack, addresses these limitations by leveraging PGD to
iteratively generate adversarial examples while ensuring both imperceptibility
and semantic similarity to the original input. Extensive experiments are
conducted to evaluate the performance of PGD-BERT-Attack compared to the
original BERT-Attack and other baseline methods. The results demonstrate that
PGD-BERT-Attack achieves higher success rates in causing misclassification
while maintaining low perceptual changes. Furthermore, PGD-BERT-Attack produces
adversarial instances that exhibit greater semantic resemblance to the initial
input, enhancing their applicability in real-world scenarios. Overall, the
proposed modification offers a more effective and robust approach to
adversarial attacks on BERT-based models, thus contributing to the advancement
of defense against attacks on NLP systems.",2024-07-29,"Hetvi Waghela, Jaydip Sen, Sneha Rakshit",http://arxiv.org/pdf/2407.21073v1,cs.LG
Imputation for prediction: beware of diminishing returns,"Missing values are prevalent across various fields, posing challenges for
training and deploying predictive models. In this context, imputation is a
common practice, driven by the hope that accurate imputations will enhance
predictions. However, recent theoretical and empirical studies indicate that
simple constant imputation can be consistent and competitive. This empirical
study aims at clarifying if and when investing in advanced imputation methods
yields significantly better predictions. Relating imputation and predictive
accuracies across combinations of imputation and predictive models on 19
datasets, we show that imputation accuracy matters less i) when using
expressive models, ii) when incorporating missingness indicators as
complementary inputs, iii) matters much more for generated linear outcomes than
for real-data outcomes. Interestingly, we also show that the use of the
missingness indicator is beneficial to the prediction performance, even in MCAR
scenarios. Overall, on real-data with powerful models, improving imputation
only has a minor effect on prediction performance. Thus, investing in better
imputations for improved predictions often offers limited benefits.",2024-07-29,"Marine Le Morvan, Gaël Varoquaux",http://arxiv.org/pdf/2407.19804v2,cs.LG
Survey and Taxonomy: The Role of Data-Centric AI in Transformer-Based Time Series Forecasting,"Alongside the continuous process of improving AI performance through the
development of more sophisticated models, researchers have also focused their
attention to the emerging concept of data-centric AI, which emphasizes the
important role of data in a systematic machine learning training process.
Nonetheless, the development of models has also continued apace. One result of
this progress is the development of the Transformer Architecture, which
possesses a high level of capability in multiple domains such as Natural
Language Processing (NLP), Computer Vision (CV) and Time Series Forecasting
(TSF). Its performance is, however, heavily dependent on input data
preprocessing and output data evaluation, justifying a data-centric approach to
future research. We argue that data-centric AI is essential for training AI
models, particularly for transformer-based TSF models efficiently. However,
there is a gap regarding the integration of transformer-based TSF and
data-centric AI. This survey aims to pin down this gap via the extensive
literature review based on the proposed taxonomy. We review the previous
research works from a data-centric AI perspective and we intend to lay the
foundation work for the future development of transformer-based architecture
and data-centric AI.",2024-07-29,"Jingjing Xu, Caesar Wu, Yuan-Fang Li, Gregoire Danoy, Pascal Bouvry",http://arxiv.org/pdf/2407.19784v1,cs.LG
Revisiting Agnostic PAC Learning,"PAC learning, dating back to Valiant'84 and Vapnik and Chervonenkis'64,'74,
is a classic model for studying supervised learning. In the agnostic setting,
we have access to a hypothesis set $\mathcal{H}$ and a training set of labeled
samples $(x_1,y_1),\dots,(x_n,y_n) \in \mathcal{X} \times \{-1,1\}$ drawn
i.i.d. from an unknown distribution $\mathcal{D}$. The goal is to produce a
classifier $h : \mathcal{X} \to \{-1,1\}$ that is competitive with the
hypothesis $h^\star_{\mathcal{D}} \in \mathcal{H}$ having the least probability
of mispredicting the label $y$ of a new sample $(x,y)\sim \mathcal{D}$.
  Empirical Risk Minimization (ERM) is a natural learning algorithm, where one
simply outputs the hypothesis from $\mathcal{H}$ making the fewest mistakes on
the training data. This simple algorithm is known to have an optimal error in
terms of the VC-dimension of $\mathcal{H}$ and the number of samples $n$.
  In this work, we revisit agnostic PAC learning and first show that ERM is in
fact sub-optimal if we treat the performance of the best hypothesis, denoted
$\tau:=\Pr_{\mathcal{D}}[h^\star_{\mathcal{D}}(x) \neq y]$, as a parameter.
Concretely we show that ERM, and any other proper learning algorithm, is
sub-optimal by a $\sqrt{\ln(1/\tau)}$ factor. We then complement this lower
bound with the first learning algorithm achieving an optimal error for nearly
the full range of $\tau$. Our algorithm introduces several new ideas that we
hope may find further applications in learning theory.",2024-07-29,"Steve Hanneke, Kasper Green Larsen, Nikita Zhivotovskiy",http://arxiv.org/pdf/2407.19777v1,cs.LG
Sensor Selection via GFlowNets: A Deep Generative Modeling Framework to Navigate Combinatorial Complexity,"The performance of sensor arrays in sensing and wireless communications
improves with more elements, but this comes at the cost of increased energy
consumption and hardware expense. This work addresses the challenge of
selecting $k$ sensor elements from a set of $m$ to optimize a generic
Quality-of-Service metric. Evaluating all $\binom{m}{k}$ possible sensor
subsets is impractical, leading to prior solutions using convex relaxations,
greedy algorithms, and supervised learning approaches. The current paper
proposes a new framework that employs deep generative modeling, treating sensor
selection as a deterministic Markov Decision Process where sensor subsets of
size $k$ arise as terminal states. Generative Flow Networks (GFlowNets) are
employed to model an action distribution conditioned on the state. Sampling
actions from the aforementioned distribution ensures that the probability of
arriving at a terminal state is proportional to the performance of the
corresponding subset. Applied to a standard sensor selection scenario, the
developed approach outperforms popular methods which are based on convex
optimization and greedy algorithms. Finally, a multiobjective formulation of
the proposed approach is adopted and applied on the sparse antenna array design
for Integrated Sensing and Communication (ISAC) systems. The multiobjective
variation is shown to perform well in managing the trade-off between radar and
communication performance.",2024-07-29,"Spilios Evmorfos, Zhaoyi Xu, Athina Petropulu",http://arxiv.org/pdf/2407.19736v1,cs.LG
Consistency Based Weakly Self-Supervised Learning for Human Activity Recognition with Wearables,"While the widely available embedded sensors in smartphones and other wearable
devices make it easier to obtain data of human activities, recognizing
different types of human activities from sensor-based data remains a difficult
research topic in ubiquitous computing. One reason for this is that most of the
collected data is unlabeled. However, many current human activity recognition
(HAR) systems are based on supervised methods, which heavily rely on the labels
of the data. We describe a weakly self-supervised approach in this paper that
consists of two stages: (1) In stage one, the model learns from the nature of
human activities by projecting the data into an embedding space where similar
activities are grouped together; (2) In stage two, the model is fine-tuned
using similarity information in a few-shot learning fashion using the
similarity information of the data. This allows downstream classification or
clustering tasks to benefit from the embeddings. Experiments on three benchmark
datasets demonstrate the framework's effectiveness and show that our approach
can help the clustering algorithm achieve comparable performance in identifying
and categorizing the underlying human activities as pure supervised techniques
applied directly to a corresponding fully labeled data set.",2024-07-29,"Taoran Sheng, Manfred Huber",http://arxiv.org/pdf/2408.07282v1,cs.LG
Constructing artificial life and materials scientists with accelerated AI using Deep AndersoNN,"Deep AndersoNN accelerates AI by exploiting the continuum limit as the number
of explicit layers in a neural network approaches infinity and can be taken as
a single implicit layer, known as a deep equilibrium model. Solving for deep
equilibrium model parameters reduces to a nonlinear fixed point iteration
problem, enabling the use of vector-to-vector iterative solvers and windowing
techniques, such as Anderson extrapolation, for accelerating convergence to the
fixed point deep equilibrium. Here we show that Deep AndersoNN achieves up to
an order of magnitude of speed-up in training and inference. The method is
demonstrated on density functional theory results for industrial applications
by constructing artificial life and materials `scientists' capable of
classifying drugs as strongly or weakly polar, metal-organic frameworks by pore
size, and crystalline materials as metals, semiconductors, and insulators,
using graph images of node-neighbor representations transformed from atom-bond
networks. Results exhibit accuracy up to 98\% and showcase synergy between Deep
AndersoNN and machine learning capabilities of modern computing architectures,
such as GPUs, for accelerated computational life and materials science by
quickly identifying structure-property relationships. This paves the way for
saving up to 90\% of compute required for AI, reducing its carbon footprint by
up to 60 gigatons per year by 2030, and scaling above memory limits of explicit
neural networks in life and materials science, and beyond.",2024-07-29,"Saleem Abdul Fattah Ahmed Al Dajani, David Keyes",http://arxiv.org/pdf/2407.19724v1,cs.LG
Generalization bounds for regression and classification on adaptive covering input domains,"Our main focus is on the generalization bound, which serves as an upper limit
for the generalization error. Our analysis delves into regression and
classification tasks separately to ensure a thorough examination. We assume the
target function is real-valued and Lipschitz continuous for regression tasks.
We use the 2-norm and a root-mean-square-error (RMSE) variant to measure the
disparities between predictions and actual values. In the case of
classification tasks, we treat the target function as a one-hot classifier,
representing a piece-wise constant function, and employ 0/1 loss for error
measurement. Our analysis underscores the differing sample complexity required
to achieve a concentration inequality of generalization bounds, highlighting
the variation in learning efficiency for regression and classification tasks.
Furthermore, we demonstrate that the generalization bounds for regression and
classification functions are inversely proportional to a polynomial of the
number of parameters in a network, with the degree depending on the hypothesis
class and the network architecture. These findings emphasize the advantages of
over-parameterized networks and elucidate the conditions for benign overfitting
in such systems.",2024-07-29,Wen-Liang Hwang,http://arxiv.org/pdf/2407.19715v1,cs.LG
Neural networks for bifurcation and linear stability analysis of steady states in partial differential equations,"This research introduces an extended application of neural networks for
solving nonlinear partial differential equations (PDEs). A neural network,
combined with a pseudo-arclength continuation, is proposed to construct
bifurcation diagrams from parameterized nonlinear PDEs. Additionally, a neural
network approach is also presented for solving eigenvalue problems to analyze
solution linear stability, focusing on identifying the largest eigenvalue. The
effectiveness of the proposed neural network is examined through experiments on
the Bratu equation and the Burgers equation. Results from a finite difference
method are also presented as comparison. Varying numbers of grid points are
employed in each case to assess the behavior and accuracy of both the neural
network and the finite difference method. The experimental results demonstrate
that the proposed neural network produces better solutions, generates more
accurate bifurcation diagrams, has reasonable computational times, and proves
effective for linear stability analysis.",2024-07-29,"Muhammad Luthfi Shahab, Hadi Susanto",http://arxiv.org/pdf/2407.19707v3,cs.LG
Multiscale Representation Enhanced Temporal Flow Fusion Model for Long-Term Workload Forecasting,"Accurate workload forecasting is critical for efficient resource management
in cloud computing systems, enabling effective scheduling and autoscaling.
Despite recent advances with transformer-based forecasting models, challenges
remain due to the non-stationary, nonlinear characteristics of workload time
series and the long-term dependencies. In particular, inconsistent performance
between long-term history and near-term forecasts hinders long-range
predictions. This paper proposes a novel framework leveraging self-supervised
multiscale representation learning to capture both long-term and near-term
workload patterns. The long-term history is encoded through multiscale
representations while the near-term observations are modeled via temporal flow
fusion. These representations of different scales are fused using an attention
mechanism and characterized with normalizing flows to handle
non-Gaussian/non-linear distributions of time series. Extensive experiments on
9 benchmarks demonstrate superiority over existing methods.",2024-07-29,"Shiyu Wang, Zhixuan Chu, Yinbo Sun, Yu Liu, Yuliang Guo, Yang Chen, Huiyang Jian, Lintao Ma, Xingyu Lu, Jun Zhou",http://arxiv.org/pdf/2407.19697v2,cs.LG
Causal Interventional Prediction System for Robust and Explainable Effect Forecasting,"Although the widespread use of AI systems in today's world is growing, many
current AI systems are found vulnerable due to hidden bias and missing
information, especially in the most commonly used forecasting system. In this
work, we explore the robustness and explainability of AI-based forecasting
systems. We provide an in-depth analysis of the underlying causality involved
in the effect prediction task and further establish a causal graph based on
treatment, adjustment variable, confounder, and outcome. Correspondingly, we
design a causal interventional prediction system (CIPS) based on a variational
autoencoder and fully conditional specification of multiple imputations.
Extensive results demonstrate the superiority of our system over
state-of-the-art methods and show remarkable versatility and extensibility in
practice.",2024-07-29,"Zhixuan Chu, Hui Ding, Guang Zeng, Shiyu Wang, Yiming Li",http://arxiv.org/pdf/2407.19688v1,cs.LG
Dataset Distillation for Offline Reinforcement Learning,"Offline reinforcement learning often requires a quality dataset that we can
train a policy on. However, in many situations, it is not possible to get such
a dataset, nor is it easy to train a policy to perform well in the actual
environment given the offline data. We propose using data distillation to train
and distill a better dataset which can then be used for training a better
policy model. We show that our method is able to synthesize a dataset where a
model trained on it achieves similar performance to a model trained on the full
dataset or a model trained using percentile behavioral cloning. Our project
site is available at
$\href{https://datasetdistillation4rl.github.io}{\text{here}}$. We also provide
our implementation at $\href{https://github.com/ggflow123/DDRL}{\text{this
GitHub repository}}$.",2024-07-29,"Jonathan Light, Yuanzhe Liu, Ziniu Hu",http://arxiv.org/pdf/2407.20299v2,cs.LG
Revisiting the robustness of post-hoc interpretability methods,"Post-hoc interpretability methods play a critical role in explainable
artificial intelligence (XAI), as they pinpoint portions of data that a trained
deep learning model deemed important to make a decision. However, different
post-hoc interpretability methods often provide different results, casting
doubts on their accuracy. For this reason, several evaluation strategies have
been proposed to understand the accuracy of post-hoc interpretability. Many of
these evaluation strategies provide a coarse-grained assessment -- i.e., they
evaluate how the performance of the model degrades on average by corrupting
different data points across multiple samples. While these strategies are
effective in selecting the post-hoc interpretability method that is most
reliable on average, they fail to provide a sample-level, also referred to as
fine-grained, assessment. In other words, they do not measure the robustness of
post-hoc interpretability methods. We propose an approach and two new metrics
to provide a fine-grained assessment of post-hoc interpretability methods. We
show that the robustness is generally linked to its coarse-grained performance.",2024-07-29,"Jiawen Wei, Hugues Turbé, Gianmarco Mengaldo",http://arxiv.org/pdf/2407.19683v1,cs.LG
Adaptive Soft Error Protection for Neural Network Processing,"Mitigating soft errors in neural networks (NNs) often incurs significant
computational overhead. Traditional methods mainly explored static
vulnerability variations across NN components, employing selective protection
to minimize costs. In contrast, this work reveals that NN vulnerability is also
input-dependent, exhibiting dynamic variations at runtime. To this end, we
propose a lightweight graph neural network (GNN) model capable of capturing
input- and component-specific vulnerability to soft errors. This model
facilitates runtime vulnerability prediction, enabling an adaptive protection
strategy that dynamically adjusts to varying vulnerabilities. The approach
complements classical fault-tolerant techniques by tailoring protection efforts
based on real-time vulnerability assessments. Experimental results across
diverse datasets and NNs demonstrate that our adaptive protection method
achieves a 42.12\% average reduction in computational overhead compared to
prior static vulnerability-based approaches, without compromising reliability.",2024-07-29,"Xinghua Xue, Cheng Liu, Feng Min, Yinhe Han",http://arxiv.org/pdf/2407.19664v2,cs.LG
Short-Term Photovoltaic Forecasting Model for Qualifying Uncertainty during Hazy Weather,"Solar energy is one of the most promising renewable energy resources.
Forecasting photovoltaic power generation is an important way to increase
photovoltaic penetration. However, the difficulty in qualifying the uncertainty
of PV power generation, especially during hazy weather, makes forecasting
challenging. This paper proposes a novel model to address the issue. We
introduce a modified entropy to qualify uncertainty during hazy weather while
clustering and attention mechanisms are employed to reduce computational costs
and enhance forecasting accuracy, respectively. Hyperparameters were adjusted
using an optimization algorithm. Experiments on two datasets related to hazy
weather demonstrate that our model significantly improves forecasting accuracy
compared to existing models.",2024-07-29,"Xuan Yang, Yunxuan Dong, Lina Yang, Thomas Wu",http://arxiv.org/pdf/2407.19663v2,cs.LG
A Causally Informed Pretraining Approach for Multimodal Foundation Models: Applications in Remote Sensing,"Self-supervised learning has emerged as a powerful paradigm for pretraining
foundation models using large-scale data. Existing pretraining approaches
predominantly rely on masked reconstruction or next-token prediction
strategies, demonstrating strong performance across various downstream tasks,
including geoscience applications. However, these approaches do not fully
capture the causal interplay between different geospatial and environmental
variables. To address this limitation, we propose Causally Informed
Variable-Step Forecasting (CI-VSF), a novel pretraining task that models
forecasting as a conditional generation task, where driver variables (e.g.,
weather) inform the prediction of response variables (e.g., satellite imagery).
We demonstrate that pretraining in such a fashion leads to enhanced performance
when finetuned on both prediction (e.g., crop mapping, missing image
prediction, soil moisture estimation) and forecasting (e.g., future image
forecasting, soil moisture forecasting) downstream tasks when compared to other
pretraining approaches. While we use remote sensing as our main application to
demonstrate the efficacy of our proposed pretraining strategy over existing
paradigms, it is applicable to any domain that involves known causal
relationships amongst a set of variables.",2024-07-29,"Praveen Ravirathinam, Ankush Khandelwal, Rahul Ghosh, Vipin Kumar",http://arxiv.org/pdf/2407.19660v3,cs.LG
Bridging Compressed Image Latents and Multimodal Large Language Models,"This paper presents the first-ever study of adapting compressed image latents
to suit the needs of downstream vision tasks that adopt Multimodal Large
Language Models (MLLMs). MLLMs have extended the success of large language
models to modalities (e.g. images) beyond text, but their billion scale hinders
deployment on resource-constrained end devices. While cloud-hosted MLLMs could
be available, transmitting raw, uncompressed images captured by end devices to
the cloud requires an efficient image compression system. To address this, we
focus on emerging neural image compression and propose a novel framework with a
lightweight transform-neck and a surrogate loss to adapt compressed image
latents for MLLM-based vision tasks. Given the huge scale of MLLMs, our
framework excludes the entire downstream MLLM except part of its visual encoder
from training our system. This stands out from most existing coding for machine
approaches that involve downstream networks in training and thus could be
impractical when the networks are MLLMs. The proposed framework is general in
that it is applicable to various MLLMs, neural image codecs, and multiple
application scenarios, where the neural image codec can be (1) pre-trained for
human perception without updating, (2) fully updated for joint human and
machine perception, or (3) fully updated for only machine perception. Extensive
experiments on different neural image codecs and various MLLMs show that our
method achieves great rate-accuracy performance with much less complexity.",2024-07-29,"Chia-Hao Kao, Cheng Chien, Yu-Jen Tseng, Yi-Hsin Chen, Alessandro Gnutti, Shao-Yuan Lo, Wen-Hsiao Peng, Riccardo Leonardi",http://arxiv.org/pdf/2407.19651v2,cs.LG
Realizing Unaligned Block-wise Pruning for DNN Acceleration on Mobile Devices,"With the recent proliferation of on-device AI, there is an increasing need to
run computationally intensive DNNs directly on mobile devices. However, the
limited computing and memory resources of these devices necessitate effective
pruning techniques. Block-wise pruning is promising due to its low accuracy
drop tradeoff for speedup gains, but it requires block positions to be aligned
with block size, hindering optimal position selection to minimize model
accuracy drop. Unaligned block pruning (UBP) addresses this by allowing blocks
to be selected at arbitrary positions, yet its practical use is limited by a
time-consuming optimal block selection algorithm and lack of efficient
inference kernels. In this paper, we propose a pseudo-optimal yet fast block
selection algorithm called Block Expansion and Division (BED), which can be
integrated into an iterative model training process. Additionally, we introduce
an efficient inference kernel implementation for mobile devices, enabling a
UBP-based model to achieve similar latency to a DNN model compressed by aligned
block pruning. We demonstrate the superiority of our techniques on a real
mobile phone with MobileNet and ResNet models.",2024-07-29,"Hayun Lee, Dongkun Shin",http://arxiv.org/pdf/2407.19644v1,cs.LG
"""A Good Bot Always Knows Its Limitations"": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidence","How can intelligent machines assess their competency to complete a task? This
question has come into focus for autonomous systems that algorithmically make
decisions under uncertainty. We argue that machine self-confidence -- a form of
meta-reasoning based on self-assessments of system knowledge about the state of
the world, itself, and ability to reason about and execute tasks -- leads to
many computable and useful competency indicators for such agents. This paper
presents our body of work, so far, on this concept in the form of the
Factorized Machine Self-confidence (FaMSeC) framework, which holistically
considers several major factors driving competency in algorithmic
decision-making: outcome assessment, solver quality, model quality, alignment
quality, and past experience. In FaMSeC, self-confidence indicators are derived
via 'problem-solving statistics' embedded in Markov decision process solvers
and related approaches. These statistics come from evaluating probabilistic
exceedance margins in relation to certain outcomes and associated competency
standards specified by an evaluator. Once designed, and evaluated, the
statistics can be easily incorporated into autonomous agents and serve as
indicators of competency. We include detailed descriptions and examples for
Markov decision process agents, and show how outcome assessment and solver
quality factors can be found for a range of tasking contexts through novel use
of meta-utility functions, behavior simulations, and surrogate prediction
models. Numerical evaluations are performed to demonstrate that FaMSeC
indicators perform as desired (references to human subject studies beyond the
scope of this paper are provided).",2024-07-29,"Brett W. Israelsen, Nisar R. Ahmed, Matthew Aitken, Eric W. Frew, Dale A. Lawrence, Brian M. Argrow",http://arxiv.org/pdf/2407.19631v3,cs.LG
Experimenting on Markov Decision Processes with Local Treatments,"Utilizing randomized experiments to evaluate the effect of short-term
treatments on the short-term outcomes has been well understood and become the
golden standard in industrial practice. However, as service systems become
increasingly dynamical and personalized, much focus is shifting toward
maximizing long-term cumulative outcomes, such as customer lifetime value,
through lifetime exposure to interventions. To bridge this gap, we investigate
the randomized experiments within dynamical systems modeled as Markov Decision
Processes (MDPs). Our goal is to assess the impact of treatment and control
policies on long-term cumulative rewards from relatively short-term
observations. We first develop optimal inference techniques for assessing the
effects of general treatment patterns. Furthermore, recognizing that many
real-world treatments tend to be fine-grained and localized for practical
efficiency and operational convenience, we then propose methods to harness this
localized structure by sharing information on the non-targeted states. Our new
estimator effectively overcomes the variance lower bound for general treatments
while matching the more stringent lower bound incorporating the local treatment
structure. Furthermore, our estimator can optimally achieve a linear reduction
with the number of test arms for a major part of the variance. Finally, we
explore scenarios with perfect knowledge of the control arm and design
estimators that further improve inference efficiency.",2024-07-29,"Shuze Chen, David Simchi-Levi, Chonghuan Wang",http://arxiv.org/pdf/2407.19618v2,cs.LG
Leveraging Vision Language Models for Specialized Agricultural Tasks,"As Vision Language Models (VLMs) become increasingly accessible to farmers
and agricultural experts, there is a growing need to evaluate their potential
in specialized tasks. We present AgEval, a comprehensive benchmark for
assessing VLMs' capabilities in plant stress phenotyping, offering a solution
to the challenge of limited annotated data in agriculture. Our study explores
how general-purpose VLMs can be leveraged for domain-specific tasks with only a
few annotated examples, providing insights into their behavior and
adaptability. AgEval encompasses 12 diverse plant stress phenotyping tasks,
evaluating zero-shot and few-shot in-context learning performance of
state-of-the-art models including Claude, GPT, Gemini, and LLaVA. Our results
demonstrate VLMs' rapid adaptability to specialized tasks, with the
best-performing model showing an increase in F1 scores from 46.24% to 73.37% in
8-shot identification. To quantify performance disparities across classes, we
introduce metrics such as the coefficient of variation (CV), revealing that
VLMs' training impacts classes differently, with CV ranging from 26.02% to
58.03%. We also find that strategic example selection enhances model
reliability, with exact category examples improving F1 scores by 15.38% on
average. AgEval establishes a framework for assessing VLMs in agricultural
applications, offering valuable benchmarks for future evaluations. Our findings
suggest that VLMs, with minimal few-shot examples, show promise as a viable
alternative to traditional specialized models in plant stress phenotyping,
while also highlighting areas for further refinement. Results and benchmark
details are available at: https://github.com/arbab-ml/AgEval",2024-07-29,"Muhammad Arbab Arshad, Talukder Zaki Jubery, Tirtho Roy, Rim Nassiri, Asheesh K. Singh, Arti Singh, Chinmay Hegde, Baskar Ganapathysubramanian, Aditya Balu, Adarsh Krishnamurthy, Soumik Sarkar",http://arxiv.org/pdf/2407.19617v2,cs.LG
TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs,"Topic modeling is a technique for organizing and extracting themes from large
collections of unstructured text. Non-negative matrix factorization (NMF) is a
common unsupervised approach that decomposes a term frequency-inverse document
frequency (TF-IDF) matrix to uncover latent topics and segment the dataset
accordingly. While useful for highlighting patterns and clustering documents,
NMF does not provide explicit topic labels, necessitating subject matter
experts (SMEs) to assign labels manually. We present a methodology for
automating topic labeling in documents clustered via NMF with automatic model
determination (NMFk). By leveraging the output of NMFk and employing prompt
engineering, we utilize large language models (LLMs) to generate accurate topic
labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs
demonstrates the effectiveness of our method in enhancing knowledge management
and document organization.",2024-07-29,"Selma Wanna, Ryan Barron, Nick Solovyev, Maksim E. Eren, Manish Bhattarai, Kim Rasmussen, Boian S. Alexandrov",http://arxiv.org/pdf/2407.19616v1,cs.LG
Analysis of sensors for movement analysis,"In this paper we analyze and compare different movement sensors: micro-chip
gesture-ID, leap motion, noitom mocap, and specially developed sensor for
tapping and foot motion analysis. The main goal is to evaluate the accu-racy of
measurements provided by the sensors. This study presents rele-vance, for
instance, in tremor/Parkinson disease analysis as well as no touch mechanisms
for activation and control of devices. This scenario is especially interesting
in COVID-19 scenario. Removing the need to touch a surface, the risk of
contagion is reduced.",2024-07-28,"Marcos Faundez-Zanuy, Anna Faura-Pujol, Hector Montalvo-Ruiz, Alexia Losada-Fors, Pablo Genovese, Pilar Sanz-Cartagena",http://arxiv.org/pdf/2408.07281v1,cs.LG
Mini-batch Coresets for Memory-efficient Language Model Training on Data Mixtures,"Training with larger mini-batches improves the convergence rate and can yield
superior performance. However, training with large mini-batches becomes
prohibitive for Large Language Models (LLMs), due to the large GPU memory
requirement. To address this problem, an effective approach is finding small
mini-batch coresets that closely match the gradient of larger mini-batches.
However, this approach becomes infeasible and ineffective for LLMs, due to the
highly imbalanced mixture of sources in language data, use of the Adam
optimizer, and the very large gradient dimensionality of LLMs. In this work, we
address the above challenges by proposing Coresets for Training LLMs (CoLM).
First, we show that mini-batch coresets found by gradient matching do not
contain representative examples of the small sources w.h.p., and thus including
all examples of the small sources in the mini-batch coresets is crucial for
optimal performance. Second, we normalize the gradients by their historical
exponential to find mini-batch coresets for training with Adam. Finally, we
leverage zeroth-order methods to find smooth gradient of the last V-projection
matrix and sparsify it to keep the dimensions with the largest normalized
gradient magnitude. We apply CoLM to fine-tuning Phi-2, Phi-3, Zephyr, and
Llama-3 models with LoRA on MathInstruct and SuperGLUE benchmark. Remarkably,
CoLM reduces the memory requirement of fine-tuning by 2x and even outperforms
training with 4x larger mini-batches. Moreover, CoLM seamlessly integrates with
existing memory-efficient training methods like LoRA, further reducing the
memory requirements of training LLMs.",2024-07-28,"Dang Nguyen, Wenhan Yang, Rathul Anand, Yu Yang, Baharan Mirzasoleiman",http://arxiv.org/pdf/2407.19580v3,cs.LG
Sharp Bounds for Poly-GNNs and the Effect of Graph Noise,"We investigate the classification performance of graph neural networks with
graph-polynomial features, poly-GNNs, on the problem of semi-supervised node
classification. We analyze poly-GNNs under a general contextual stochastic
block model (CSBM) by providing a sharp characterization of the rate of
separation between classes in their output node representations. A question of
interest is whether this rate depends on the depth of the network $k$, i.e.,
whether deeper networks can achieve a faster separation? We provide a negative
answer to this question: for a sufficiently large graph, a depth $k > 1$
poly-GNN exhibits the same rate of separation as a depth $k=1$ counterpart. Our
analysis highlights and quantifies the impact of ``graph noise'' in deep GNNs
and shows how noise in the graph structure can dominate other sources of signal
in the graph, negating any benefit further aggregation provides. Our analysis
also reveals subtle differences between even and odd-layered GNNs in how the
feature noise propagates.",2024-07-28,"Luciano Vinas, Arash A. Amini",http://arxiv.org/pdf/2407.19567v1,cs.LG
Neural stochastic Volterra equations: learning path-dependent dynamics,"Stochastic Volterra equations (SVEs) serve as mathematical models for the
time evolutions of random systems with memory effects and irregular behaviour.
We introduce neural stochastic Volterra equations as a physics-inspired
architecture, generalizing the class of neural stochastic differential
equations, and provide some theoretical foundation. Numerical experiments on
various SVEs, like the disturbed pendulum equation, the generalized
Ornstein--Uhlenbeck process and the rough Heston model are presented, comparing
the performance of neural SVEs, neural SDEs and Deep Operator Networks
(DeepONets).",2024-07-28,"David J. Prömel, David Scheffels",http://arxiv.org/pdf/2407.19557v1,cs.LG
Overcoming Uncertain Incompleteness for Robust Multimodal Sequential Diagnosis Prediction via Curriculum Data Erasing Guided Knowledge Distillation,"In this paper, we present NECHO v2, a novel framework designed to enhance the
predictive accuracy of multimodal sequential patient diagnoses under uncertain
missing visit sequences, a common challenge in real clinical settings. Firstly,
we modify NECHO, designed in a diagnosis code-centric fashion, to handle
uncertain modality representation dominance under the imperfect data. Secondly,
we develop a systematic knowledge distillation by employing the modified NECHO
as both teacher and student. It encompasses a modality-wise contrastive and
hierarchical distillation, transformer representation random distillation,
along with other distillations to align representations between teacher and
student tightly and effectively. We also propose curriculum learning guided
random data erasing within sequences during both training and distillation of
the teacher to lightly simulate scenario with missing visit information,
thereby fostering effective knowledge transfer. As a result, NECHO v2 verifies
itself by showing robust superiority in multimodal sequential diagnosis
prediction under both balanced and imbalanced incomplete settings on multimodal
healthcare data.",2024-07-28,Heejoon Koo,http://arxiv.org/pdf/2407.19540v4,cs.LG
The Interpretability of Codebooks in Model-Based Reinforcement Learning is Limited,"Interpretability of deep reinforcement learning systems could assist
operators with understanding how they interact with their environment. Vector
quantization methods -- also called codebook methods -- discretize a neural
network's latent space that is often suggested to yield emergent
interpretability. We investigate whether vector quantization in fact provides
interpretability in model-based reinforcement learning. Our experiments,
conducted in the reinforcement learning environment Crafter, show that the
codes of vector quantization models are inconsistent, have no guarantee of
uniqueness, and have a limited impact on concept disentanglement, all of which
are necessary traits for interpretability. We share insights on why vector
quantization may be fundamentally insufficient for model interpretability.",2024-07-28,"Kenneth Eaton, Jonathan Balloch, Julia Kim, Mark Riedl",http://arxiv.org/pdf/2407.19532v1,cs.LG
Robust Fast Adaptation from Adversarially Explicit Task Distribution Generation,"Meta-learning is a practical learning paradigm to transfer skills across
tasks from a few examples. Nevertheless, the existence of task distribution
shifts tends to weaken meta-learners' generalization capability, particularly
when the training task distribution is naively hand-crafted or based on simple
priors that fail to cover critical scenarios sufficiently. Here, we consider
explicitly generative modeling task distributions placed over task identifiers
and propose robustifying fast adaptation from adversarial training. Our
approach, which can be interpreted as a model of a Stackelberg game, not only
uncovers the task structure during problem-solving from an explicit generative
model but also theoretically increases the adaptation robustness in worst
cases. This work has practical implications, particularly in dealing with task
distribution shifts in meta-learning, and contributes to theoretical insights
in the field. Our method demonstrates its robustness in the presence of task
subpopulation shifts and improved performance over SOTA baselines in extensive
experiments. The code is available at the project site
https://sites.google.com/view/ar-metalearn.",2024-07-28,"Cheems Wang, Yiqin Lv, Yixiu Mao, Yun Qu, Yi Xu, Xiangyang Ji",http://arxiv.org/pdf/2407.19523v4,cs.LG
Ego-VPA: Egocentric Video Understanding with Parameter-efficient Adaptation,"Video understanding typically requires fine-tuning the large backbone when
adapting to new domains. In this paper, we leverage the egocentric video
foundation models (Ego-VFMs) based on video-language pre-training and propose a
parameter-efficient adaptation for egocentric video tasks, namely Ego-VPA. It
employs a local sparse approximation for each video frame/text feature using
the basis prompts, and the selected basis prompts are used to synthesize
video/text prompts. Since the basis prompts are shared across frames and
modalities, it models context fusion and cross-modal transfer in an efficient
fashion. Experiments show that Ego-VPA excels in lightweight adaptation (with
only 0.84% learnable parameters), largely improving over baselines and reaching
the performance of full fine-tuning.",2024-07-28,"Tz-Ying Wu, Kyle Min, Subarna Tripathi, Nuno Vasconcelos",http://arxiv.org/pdf/2407.19520v2,cs.LG
Faculty Perspectives on the Potential of RAG in Computer Science Higher Education,"The emergence of Large Language Models (LLMs) has significantly impacted the
field of Natural Language Processing and has transformed conversational tasks
across various domains because of their widespread integration in applications
and public access. The discussion surrounding the application of LLMs in
education has raised ethical concerns, particularly concerning plagiarism and
policy compliance. Despite the prowess of LLMs in conversational tasks, the
limitations of reliability and hallucinations exacerbate the need to guardrail
conversations, motivating our investigation of RAG in computer science higher
education. We developed Retrieval Augmented Generation (RAG) applications for
the two tasks of virtual teaching assistants and teaching aids. In our study,
we collected the ratings and opinions of faculty members in undergraduate and
graduate computer science university courses at various levels, using our
personalized RAG systems for each course. This study is the first to gather
faculty feedback on the application of LLM-based RAG in education. The
investigation revealed that while faculty members acknowledge the potential of
RAG systems as virtual teaching assistants and teaching aids, certain barriers
and features are suggested for their full-scale deployment. These findings
contribute to the ongoing discussion on the integration of advanced language
models in educational settings, highlighting the need for careful consideration
of ethical implications and the development of appropriate safeguards to ensure
responsible and effective implementation.",2024-07-28,Sagnik Dakshit,http://arxiv.org/pdf/2408.01462v1,cs.LG
High-Dimensional Fault Tolerance Testing of Highly Automated Vehicles Based on Low-Rank Models,"Ensuring fault tolerance of Highly Automated Vehicles (HAVs) is crucial for
their safety due to the presence of potentially severe faults. Hence, Fault
Injection (FI) testing is conducted by practitioners to evaluate the safety
level of HAVs. To fully cover test cases, various driving scenarios and fault
settings should be considered. However, due to numerous combinations of test
scenarios and fault settings, the testing space can be complex and
high-dimensional. In addition, evaluating performance in all newly added
scenarios is resource-consuming. The rarity of critical faults that can cause
security problems further strengthens the challenge. To address these
challenges, we propose to accelerate FI testing under the low-rank Smoothness
Regularized Matrix Factorization (SRMF) framework. We first organize the sparse
evaluated data into a structured matrix based on its safety values. Then the
untested values are estimated by the correlation captured by the matrix
structure. To address high dimensionality, a low-rank constraint is imposed on
the testing space. To exploit the relationships between existing scenarios and
new scenarios and capture the local regularity of critical faults, three types
of smoothness regularization are further designed as a complement. We conduct
experiments on car following and cut in scenarios. The results indicate that
SRMF has the lowest prediction error in various scenarios and is capable of
predicting rare critical faults compared to other machine learning models. In
addition, SRMF can achieve 1171 acceleration rate, 99.3% precision and 91.1% F1
score in identifying critical faults. To the best of our knowledge, this is the
first work to introduce low-rank models to FI testing of HAVs.",2024-07-28,"Yuewen Mei, Tong Nie, Jian Sun, Ye Tian",http://arxiv.org/pdf/2407.21069v1,cs.LG
What can we learn about Reionization astrophysical parameters using Gaussian Process Regression?,"Reionization is one of the least understood processes in the evolution
history of the Universe, mostly because of the numerous astrophysical processes
occurring simultaneously about which we do not have a very clear idea so far.
In this article, we use the Gaussian Process Regression (GPR) method to learn
the reionization history and infer the astrophysical parameters. We reconstruct
the UV luminosity density function using the HFF and early JWST data. From the
reconstructed history of reionization, the global differential brightness
temperature fluctuation during this epoch has been computed. We perform MCMC
analysis of the global 21-cm signal using the instrumental specifications of
SARAS, in combination with Lyman-$\alpha$ ionization fraction data, Planck
optical depth measurements and UV luminosity data. Our analysis reveals that
GPR can help infer the astrophysical parameters in a model-agnostic way than
conventional methods. Additionally, we analyze the 21-cm power spectrum using
the reconstructed history of reionization and demonstrate how the future 21-cm
mission SKA, in combination with Planck and Lyman-$\alpha$ forest data,
improves the bounds on the reionization astrophysical parameters by doing a
joint MCMC analysis for the astrophysical parameters plus 6 cosmological
parameters for $\Lambda$CDM model. The results make the GPR-based
reconstruction technique a robust learning process and the inferences on the
astrophysical parameters obtained therefrom are quite reliable that can be used
for future analysis.",2024-07-28,"Purba Mukherjee, Antara Dey, Supratik Pal",http://arxiv.org/pdf/2407.19481v1,cs.LG
"Enhancing Taobao Display Advertising with Multimodal Representations: Challenges, Approaches and Insights","Despite the recognized potential of multimodal data to improve model
accuracy, many large-scale industrial recommendation systems, including Taobao
display advertising system, predominantly depend on sparse ID features in their
models. In this work, we explore approaches to leverage multimodal data to
enhance the recommendation accuracy. We start from identifying the key
challenges in adopting multimodal data in a manner that is both effective and
cost-efficient for industrial systems. To address these challenges, we
introduce a two-phase framework, including: 1) the pre-training of multimodal
representations to capture semantic similarity, and 2) the integration of these
representations with existing ID-based models. Furthermore, we detail the
architecture of our production system, which is designed to facilitate the
deployment of multimodal representations. Since the integration of multimodal
representations in mid-2023, we have observed significant performance
improvements in Taobao display advertising system. We believe that the insights
we have gathered will serve as a valuable resource for practitioners seeking to
leverage multimodal data in their systems.",2024-07-28,"Xiang-Rong Sheng, Feifan Yang, Litong Gong, Biao Wang, Zhangming Chan, Yujing Zhang, Yueyao Cheng, Yong-Nan Zhu, Tiezheng Ge, Han Zhu, Yuning Jiang, Jian Xu, Bo Zheng",http://arxiv.org/pdf/2407.19467v1,cs.LG
Optimizing Emotion Recognition with Wearable Sensor Data: Unveiling Patterns in Body Movements and Heart Rate through Random Forest Hyperparameter Tuning,"This research delves into the utilization of smartwatch sensor data and heart
rate monitoring to discern individual emotions based on body movement and heart
rate. Emotions play a pivotal role in human life, influencing mental
well-being, quality of life, and even physical and physiological responses. The
data were sourced from prior research by Juan C. Quiroz, PhD. The study
enlisted 50 participants who donned smartwatches and heart rate monitors while
completing a 250-meter walk. Emotions were induced through both audio-visual
and audio stimuli, with participants' emotional states evaluated using the
PANAS questionnaire. The study scrutinized three scenarios: viewing a movie
before walking, listening to music before walking, and listening to music while
walking. Personal baselines were established using DummyClassifier with the
'most_frequent' strategy from the sklearn library, and various models,
including Logistic Regression and Random Forest, were employed to gauge the
impacts of these activities. Notably, a novel approach was undertaken by
incorporating hyperparameter tuning to the Random Forest model using
RandomizedSearchCV. The outcomes showcased substantial enhancements with
hyperparameter tuning in the Random Forest model, yielding mean accuracies of
86.63% for happy vs. sad and 76.33% for happy vs. neutral vs. sad.",2024-07-28,"Zikri Kholifah Nur, Rifki Wijaya, Gia Septiana Wulandari",http://arxiv.org/pdf/2408.03958v2,cs.LG
Piecewise deterministic generative models,"We introduce a novel class of generative models based on piecewise
deterministic Markov processes (PDMPs), a family of non-diffusive stochastic
processes consisting of deterministic motion and random jumps at random times.
Similarly to diffusions, such Markov processes admit time reversals that turn
out to be PDMPs as well. We apply this observation to three PDMPs considered in
the literature: the Zig-Zag process, Bouncy Particle Sampler, and Randomised
Hamiltonian Monte Carlo. For these three particular instances, we show that the
jump rates and kernels of the corresponding time reversals admit explicit
expressions depending on some conditional densities of the PDMP under
consideration before and after a jump. Based on these results, we propose
efficient training procedures to learn these characteristics and consider
methods to approximately simulate the reverse process. Finally, we provide
bounds in the total variation distance between the data distribution and the
resulting distribution of our model in the case where the base distribution is
the standard $d$-dimensional Gaussian distribution. Promising numerical
simulations support further investigations into this class of models.",2024-07-28,"Andrea Bertazzi, Dario Shariatian, Umut Simsekli, Eric Moulines, Alain Durmus",http://arxiv.org/pdf/2407.19448v2,cs.LG
FTF-ER: Feature-Topology Fusion-Based Experience Replay Method for Continual Graph Learning,"Continual graph learning (CGL) is an important and challenging task that aims
to extend static GNNs to dynamic task flow scenarios. As one of the mainstream
CGL methods, the experience replay (ER) method receives widespread attention
due to its superior performance. However, existing ER methods focus on
identifying samples by feature significance or topological relevance, which
limits their utilization of comprehensive graph data. In addition, the
topology-based ER methods only consider local topological information and add
neighboring nodes to the buffer, which ignores the global topological
information and increases memory overhead. To bridge these gaps, we propose a
novel method called Feature-Topology Fusion-based Experience Replay (FTF-ER) to
effectively mitigate the catastrophic forgetting issue with enhanced
efficiency. Specifically, from an overall perspective to maximize the
utilization of the entire graph data, we propose a highly complementary
approach including both feature and global topological information, which can
significantly improve the effectiveness of the sampled nodes. Moreover, to
further utilize global topological information, we propose Hodge Potential
Score (HPS) as a novel module to calculate the topological importance of nodes.
HPS derives a global node ranking via Hodge decomposition on graphs, providing
more accurate global topological information compared to neighbor sampling. By
excluding neighbor sampling, HPS significantly reduces buffer storage costs for
acquiring topological information and simultaneously decreases training time.
Compared with state-of-the-art methods, FTF-ER achieves a significant
improvement of 3.6% in AA and 7.1% in AF on the OGB-Arxiv dataset,
demonstrating its superior performance in the class-incremental learning
setting.",2024-07-28,"Jinhui Pang, Changqing Lin, Xiaoshuai Hao, Rong Yin, Zixuan Wang, Zhihui Zhang, Jinglin He, Huang Tai Sheng",http://arxiv.org/pdf/2407.19429v3,cs.LG
Reputation-Driven Asynchronous Federated Learning for Enhanced Trajectory Prediction with Blockchain,"Federated learning combined with blockchain empowers secure data sharing in
autonomous driving applications. Nevertheless, with the increasing granularity
and complexity of vehicle-generated data, the lack of data quality audits
raises concerns about multi-party mistrust in trajectory prediction tasks. In
response, this paper proposes an asynchronous federated learning data sharing
method based on an interpretable reputation quantization mechanism utilizing
graph neural network tools. Data providers share data structures under
differential privacy constraints to ensure security while reducing redundant
data. We implement deep reinforcement learning to categorize vehicles by
reputation level, which optimizes the aggregation efficiency of federated
learning. Experimental results demonstrate that the proposed data sharing
scheme not only reinforces the security of the trajectory prediction task but
also enhances prediction accuracy.",2024-07-28,"Weiliang Chen, Li Jia, Yang Zhou, Qianqian Ren",http://arxiv.org/pdf/2407.19428v1,cs.LG
Causal Discovery in Linear Models with Unobserved Variables and Measurement Error,"The presence of unobserved common causes and the presence of measurement
error are two of the most limiting challenges in the task of causal structure
learning. Ignoring either of the two challenges can lead to detecting spurious
causal links among variables of interest. In this paper, we study the problem
of causal discovery in systems where these two challenges can be present
simultaneously. We consider linear models which include four types of
variables: variables that are directly observed, variables that are not
directly observed but are measured with error, the corresponding measurements,
and variables that are neither observed nor measured. We characterize the
extent of identifiability of such model under separability condition (i.e., the
matrix indicating the independent exogenous noise terms pertaining to the
observed variables is identifiable) together with two versions of faithfulness
assumptions and propose a notion of observational equivalence. We provide
graphical characterization of the models that are equivalent and present a
recovery algorithm that could return models equivalent to the ground truth.",2024-07-28,"Yuqin Yang, Mohamed Nafea, Negar Kiyavash, Kun Zhang, AmirEmad Ghassami",http://arxiv.org/pdf/2407.19426v1,cs.LG
Improved physics-informed neural network in mitigating gradient related failures,"Physics-informed neural networks (PINNs) integrate fundamental physical
principles with advanced data-driven techniques, driving significant
advancements in scientific computing. However, PINNs face persistent challenges
with stiffness in gradient flow, which limits their predictive capabilities.
This paper presents an improved PINN (I-PINN) to mitigate gradient-related
failures. The core of I-PINN is to combine the respective strengths of neural
networks with an improved architecture and adaptive weights containingupper
bounds. The capability to enhance accuracy by at least one order of magnitude
and accelerate convergence, without introducing extra computational complexity
relative to the baseline model, is achieved by I-PINN. Numerical experiments
with a variety of benchmarks illustrate the improved accuracy and
generalization of I-PINN. The supporting data and code are accessible at
https://github.com/PanChengN/I-PINN.git, enabling broader research engagement.",2024-07-28,"Pancheng Niu, Yongming Chen, Jun Guo, Yuqian Zhou, Minfu Feng, Yanchao Shi",http://arxiv.org/pdf/2407.19421v1,cs.LG
UniGAP: A Universal and Adaptive Graph Upsampling Approach to Mitigate Over-Smoothing in Node Classification Tasks,"In the graph domain, deep graph networks based on Message Passing Neural
Networks (MPNNs) or Graph Transformers often cause over-smoothing of node
features, limiting their expressive capacity. Many upsampling techniques
involving node and edge manipulation have been proposed to mitigate this issue.
However, these methods often require extensive manual labor, resulting in
suboptimal performance and lacking a universal integration strategy. In this
study, we introduce UniGAP, a universal and adaptive graph upsampling technique
for graph data. It provides a universal framework for graph upsampling,
encompassing most current methods as variants. Moreover, UniGAP serves as a
plug-in component that can be seamlessly and adaptively integrated with
existing GNNs to enhance performance and mitigate the over-smoothing problem.
Through extensive experiments, UniGAP demonstrates significant improvements
over heuristic data augmentation methods across various datasets and metrics.
We analyze how graph structure evolves with UniGAP, identifying key bottlenecks
where over-smoothing occurs, and providing insights into how UniGAP addresses
this issue. Lastly, we show the potential of combining UniGAP with large
language models (LLMs) to further improve downstream performance. Our code is
available at: https://github.com/wangxiaotang0906/UniGAP",2024-07-28,"Xiaotang Wang, Yun Zhu, Haizhou Shi, Yongchao Liu, Chuntao Hong",http://arxiv.org/pdf/2407.19420v1,cs.LG
Near-Isotropic Sub-Ångstrom 3D Resolution Phase Contrast Imaging Achieved by End-to-End Ptychographic Electron Tomography,"Three-dimensional atomic resolution imaging using transmission electron
microscopes is a unique capability that requires challenging experiments.
Linear electron tomography methods are limited by the missing wedge effect,
requiring a high tilt range. Multislice ptychography can achieve deep
sub-{\AA}ngstrom resolution in the transverse direction, but the depth
resolution is limited to 2 to 3 nanometers. In this paper, we propose and
demonstrate an end-to-end approach to reconstructing the electrostatic
potential volume of the sample directly from the 4D-STEM datasets. End-to-end
multi-slice ptychographic tomography recovers several slices at each tomography
tilt angle and compensates for the missing wedge effect. The algorithm is
initially tested in simulation with a Pt@$\mathrm{Al_2O_3}$ core-shell
nanoparticle, where both heavy and light atoms are recovered in 3D from an
unaligned 4D-STEM tilt series with a restricted tilt range of 90 degrees. We
also demonstrate the algorithm experimentally, recovering a Te nanoparticle
with sub-{\AA}ngstrom resolution.",2024-07-28,"Shengboy You, Andrey Romanov, Philipp Pelz",http://arxiv.org/pdf/2407.19407v1,cs.LG
ELP-Adapters: Parameter Efficient Adapter Tuning for Various Speech Processing Tasks,"Self-supervised learning has emerged as a key approach for learning generic
representations from speech data. Despite promising results in downstream tasks
such as speech recognition, speaker verification, and emotion recognition, a
significant number of parameters is required, which makes fine-tuning for each
task memory-inefficient. To address this limitation, we introduce ELP-adapter
tuning, a novel method for parameter-efficient fine-tuning using three types of
adapter, namely encoder adapters (E-adapters), layer adapters (L-adapters), and
a prompt adapter (P-adapter). The E-adapters are integrated into
transformer-based encoder layers and help to learn fine-grained speech
representations that are effective for speech recognition. The L-adapters
create paths from each encoder layer to the downstream head and help to extract
non-linguistic features from lower encoder layers that are effective for
speaker verification and emotion recognition. The P-adapter appends pseudo
features to CNN features to further improve effectiveness and efficiency. With
these adapters, models can be quickly adapted to various speech processing
tasks. Our evaluation across four downstream tasks using five backbone models
demonstrated the effectiveness of the proposed method. With the WavLM backbone,
its performance was comparable to or better than that of full fine-tuning on
all tasks while requiring 90% fewer learnable parameters.",2024-07-28,"Nakamasa Inoue, Shinta Otake, Takumi Hirose, Masanari Ohi, Rei Kawakami",http://arxiv.org/pdf/2407.21066v1,cs.LG
IDEA: A Flexible Framework of Certified Unlearning for Graph Neural Networks,"Graph Neural Networks (GNNs) have been increasingly deployed in a plethora of
applications. However, the graph data used for training may contain sensitive
personal information of the involved individuals. Once trained, GNNs typically
encode such information in their learnable parameters. As a consequence,
privacy leakage may happen when the trained GNNs are deployed and exposed to
potential attackers. Facing such a threat, machine unlearning for GNNs has
become an emerging technique that aims to remove certain personal information
from a trained GNN. Among these techniques, certified unlearning stands out, as
it provides a solid theoretical guarantee of the information removal
effectiveness. Nevertheless, most of the existing certified unlearning methods
for GNNs are only designed to handle node and edge unlearning requests.
Meanwhile, these approaches are usually tailored for either a specific design
of GNN or a specially designed training objective. These disadvantages
significantly jeopardize their flexibility. In this paper, we propose a
principled framework named IDEA to achieve flexible and certified unlearning
for GNNs. Specifically, we first instantiate four types of unlearning requests
on graphs, and then we propose an approximation approach to flexibly handle
these unlearning requests over diverse GNNs. We further provide theoretical
guarantee of the effectiveness for the proposed approach as a certification.
Different from existing alternatives, IDEA is not designed for any specific
GNNs or optimization objectives to perform certified unlearning, and thus can
be easily generalized. Extensive experiments on real-world datasets demonstrate
the superiority of IDEA in multiple key perspectives.",2024-07-28,"Yushun Dong, Binchi Zhang, Zhenyu Lei, Na Zou, Jundong Li",http://arxiv.org/pdf/2407.19398v1,cs.LG
GNN-Based Joint Channel and Power Allocation in Heterogeneous Wireless Networks,"The optimal allocation of channels and power resources plays a crucial role
in ensuring minimal interference, maximal data rates, and efficient energy
utilisation. As a successful approach for tackling resource management problems
in wireless networks, Graph Neural Networks (GNNs) have attracted a lot of
attention. This article proposes a GNN-based algorithm to address the joint
resource allocation problem in heterogeneous wireless networks. Concretely, we
model the heterogeneous wireless network as a heterogeneous graph and then
propose a graph neural network structure intending to allocate the available
channels and transmit power to maximise the network throughput. Our proposed
joint channel and power allocation graph neural network (JCPGNN) comprises a
shared message computation layer and two task-specific layers, with a dedicated
focus on channel and power allocation tasks, respectively. Comprehensive
experiments demonstrate that the proposed algorithm achieves satisfactory
performance but with higher computational efficiency compared to traditional
optimisation algorithms.",2024-07-28,"Lili Chen, Jingge Zhu, Jamie Evans",http://arxiv.org/pdf/2408.03957v1,cs.LG
A Bayesian Flow Network Framework for Chemistry Tasks,"In this work, we introduce ChemBFN, a language model that handles chemistry
tasks based on Bayesian flow networks working on discrete data. A new accuracy
schedule is proposed to improve the sampling quality by significantly reducing
the reconstruction loss. We show evidence that our method is appropriate for
generating molecules with satisfied diversity even when a smaller number of
sampling steps is used. A classifier-free guidance method is adapted for
conditional generation. It is also worthwhile to point out that after
generative training, our model can be fine-tuned on regression and
classification tasks with the state-of-the-art performance, which opens the
gate of building all-in-one models in a single module style. Our model has been
open sourced at
https://github.com/Augus1999/bayesian-flow-network-for-chemistry.",2024-07-28,"Nianze Tao, Minori Abe",http://arxiv.org/pdf/2407.20294v2,cs.LG
NAVIX: Scaling MiniGrid Environments with JAX,"As Deep Reinforcement Learning (Deep RL) research moves towards solving
large-scale worlds, efficient environment simulations become crucial for rapid
experimentation. However, most existing environments struggle to scale to high
throughput, setting back meaningful progress. Interactions are typically
computed on the CPU, limiting training speed and throughput, due to slower
computation and communication overhead when distributing the task across
multiple machines. Ultimately, Deep RL training is CPU-bound, and developing
batched, fast, and scalable environments has become a frontier for progress.
Among the most used Reinforcement Learning (RL) environments, MiniGrid is at
the foundation of several studies on exploration, curriculum learning,
representation learning, diversity, meta-learning, credit assignment, and
language-conditioned RL, and still suffers from the limitations described
above. In this work, we introduce NAVIX, a re-implementation of MiniGrid in
JAX. NAVIX achieves over 200 000x speed improvements in batch mode, supporting
up to 2048 agents in parallel on a single Nvidia A100 80 GB. This reduces
experiment times from one week to 15 minutes, promoting faster design
iterations and more scalable RL model development.",2024-07-28,"Eduardo Pignatelli, Jarek Liesen, Robert Tjarko Lange, Chris Lu, Pablo Samuel Castro, Laura Toni",http://arxiv.org/pdf/2407.19396v1,cs.LG
FIARSE: Model-Heterogeneous Federated Learning via Importance-Aware Submodel Extraction,"In federated learning (FL), accommodating clients' varied computational
capacities poses a challenge, often limiting the participation of those with
constrained resources in global model training. To address this issue, the
concept of model heterogeneity through submodel extraction has emerged,
offering a tailored solution that aligns the model's complexity with each
client's computational capacity. In this work, we propose Federated
Importance-Aware Submodel Extraction (FIARSE), a novel approach that
dynamically adjusts submodels based on the importance of model parameters,
thereby overcoming the limitations of previous static and dynamic submodel
extraction methods. Compared to existing works, the proposed method offers a
theoretical foundation for the submodel extraction and eliminates the need for
additional information beyond the model parameters themselves to determine
parameter importance, significantly reducing the overhead on clients. Extensive
experiments are conducted on various datasets to showcase the superior
performance of the proposed FIARSE.",2024-07-28,"Feijie Wu, Xingchen Wang, Yaqing Wang, Tianci Liu, Lu Su, Jing Gao",http://arxiv.org/pdf/2407.19389v3,cs.LG
Multi-modal Imaging Genomics Transformer: Attentive Integration of Imaging with Genomic Biomarkers for Schizophrenia Classification,"Schizophrenia (SZ) is a severe brain disorder marked by diverse cognitive
impairments, abnormalities in brain structure, function, and genetic factors.
Its complex symptoms and overlap with other psychiatric conditions challenge
traditional diagnostic methods, necessitating advanced systems to improve
precision. Existing research studies have mostly focused on imaging data, such
as structural and functional MRI, for SZ diagnosis. There has been less focus
on the integration of genomic features despite their potential in identifying
heritable SZ traits. In this study, we introduce a Multi-modal Imaging Genomics
Transformer (MIGTrans), that attentively integrates genomics with structural
and functional imaging data to capture SZ-related neuroanatomical and
connectome abnormalities. MIGTrans demonstrated improved SZ classification
performance with an accuracy of 86.05% (+/- 0.02), offering clear
interpretations and identifying significant genomic locations and brain
morphological/connectivity patterns associated with SZ.",2024-07-28,"Nagur Shareef Shaik, Teja Krishna Cherukuri, Vince D. Calhoun, Dong Hye Ye",http://arxiv.org/pdf/2407.19385v1,cs.LG
Empowering Clinicians with Medical Decision Transformers: A Framework for Sepsis Treatment,"Offline reinforcement learning has shown promise for solving tasks in
safety-critical settings, such as clinical decision support. Its application,
however, has been limited by the lack of interpretability and interactivity for
clinicians. To address these challenges, we propose the medical decision
transformer (MeDT), a novel and versatile framework based on the
goal-conditioned reinforcement learning paradigm for sepsis treatment
recommendation. MeDT uses the decision transformer architecture to learn a
policy for drug dosage recommendation. During offline training, MeDT utilizes
collected treatment trajectories to predict administered treatments for each
time step, incorporating known treatment outcomes, target acuity scores, past
treatment decisions, and current and past medical states. This analysis enables
MeDT to capture complex dependencies among a patient's medical history,
treatment decisions, outcomes, and short-term effects on stability. Our
proposed conditioning uses acuity scores to address sparse reward issues and to
facilitate clinician-model interactions, enhancing decision-making. Following
training, MeDT can generate tailored treatment recommendations by conditioning
on the desired positive outcome (survival) and user-specified short-term
stability improvements. We carry out rigorous experiments on data from the
MIMIC-III dataset and use off-policy evaluation to demonstrate that MeDT
recommends interventions that outperform or are competitive with existing
offline reinforcement learning methods while enabling a more interpretable,
personalized and clinician-directed approach.",2024-07-28,"Aamer Abdul Rahman, Pranav Agarwal, Rita Noumeir, Philippe Jouvet, Vincent Michalski, Samira Ebrahimi Kahou",http://arxiv.org/pdf/2407.19380v1,cs.LG
Uncertainty Quantification of Data Shapley via Statistical Inference,"As data plays an increasingly pivotal role in decision-making, the emergence
of data markets underscores the growing importance of data valuation. Within
the machine learning landscape, Data Shapley stands out as a widely embraced
method for data valuation. However, a limitation of Data Shapley is its
assumption of a fixed dataset, contrasting with the dynamic nature of
real-world applications where data constantly evolves and expands. This paper
establishes the relationship between Data Shapley and infinite-order
U-statistics and addresses this limitation by quantifying the uncertainty of
Data Shapley with changes in data distribution from the perspective of
U-statistics. We make statistical inferences on data valuation to obtain
confidence intervals for the estimations. We construct two different algorithms
to estimate this uncertainty and provide recommendations for their applicable
situations. We also conduct a series of experiments on various datasets to
verify asymptotic normality and propose a practical trading scenario enabled by
this method.",2024-07-28,"Mengmeng Wu, Zhihong Liu, Xiang Li, Ruoxi Jia, Xiangyu Chang",http://arxiv.org/pdf/2407.19373v1,cs.LG
Deep State-Space Generative Model For Correlated Time-to-Event Predictions,"Capturing the inter-dependencies among multiple types of clinically-critical
events is critical not only to accurate future event prediction, but also to
better treatment planning. In this work, we propose a deep latent state-space
generative model to capture the interactions among different types of
correlated clinical events (e.g., kidney failure, mortality) by explicitly
modeling the temporal dynamics of patients' latent states. Based on these
learned patient states, we further develop a new general discrete-time
formulation of the hazard rate function to estimate the survival distribution
of patients with significantly improved accuracy. Extensive evaluations over
real EMR data show that our proposed model compares favorably to various
state-of-the-art baselines. Furthermore, our method also uncovers meaningful
insights about the latent correlations among mortality and different types of
organ failures.",2024-07-28,"Yuan Xue, Denny Zhou, Nan Du, Andrew M. Dai, Zhen Xu, Kun Zhang, Claire Cui",http://arxiv.org/pdf/2407.19371v1,cs.LG
Learning to Select the Best Forecasting Tasks for Clinical Outcome Prediction,"We propose to meta-learn an a self-supervised patient trajectory forecast
learning rule by meta-training on a meta-objective that directly optimizes the
utility of the patient representation over the subsequent clinical outcome
prediction. This meta-objective directly targets the usefulness of a
representation generated from unlabeled clinical measurement forecast for later
supervised tasks.
  The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of our approach is tested on a real open source
patient EHR dataset MIMIC-III. We are able to demonstrate that our
attention-based patient state representation approach can achieve much better
performance for predicting target risk with low resources comparing with both
direct supervised learning and pretraining with all-observation trajectory
forecast.",2024-07-28,"Yuan Xue, Nan Du, Anne Mottram, Martin Seneviratne, Andrew M. Dai",http://arxiv.org/pdf/2407.19359v1,cs.LG
A spring-block theory of feature learning in deep neural networks,"Feature-learning deep nets progressively collapse data to a regular
low-dimensional geometry. How this phenomenon emerges from collective action of
nonlinearity, noise, learning rate, and other choices that shape the dynamics,
has eluded first-principles theories built from microscopic neuronal dynamics.
We exhibit a noise-nonlinearity phase diagram that identifies regimes where
shallow or deep layers learn more effectively. We then propose a macroscopic
mechanical theory that reproduces the diagram, explaining why some DNNs are
lazy and some active, and linking feature learning across layers to
generalization.",2024-07-28,"Cheng Shi, Liming Pan, Ivan Dokmanić",http://arxiv.org/pdf/2407.19353v2,cs.LG
Design and Optimization of Big Data and Machine Learning-Based Risk Monitoring System in Financial Markets,"With the increasing complexity of financial markets and rapid growth in data
volume, traditional risk monitoring methods no longer suffice for modern
financial institutions. This paper designs and optimizes a risk monitoring
system based on big data and machine learning. By constructing a four-layer
architecture, it effectively integrates large-scale financial data and advanced
machine learning algorithms. Key technologies employed in the system include
Long Short-Term Memory (LSTM) networks, Random Forest, Gradient Boosting Trees,
and real-time data processing platform Apache Flink, ensuring the real-time and
accurate nature of risk monitoring. Research findings demonstrate that the
system significantly enhances efficiency and accuracy in risk management,
particularly excelling in identifying and warning against market crash risks.",2024-07-28,"Liyang Wang, Yu Cheng, Xingxin Gu, Zhizhong Wu",http://arxiv.org/pdf/2407.19352v1,cs.LG
Polynomial Regression as a Task for Understanding In-context Learning Through Finetuning and Alignment,"Simple function classes have emerged as toy problems to better understand
in-context-learning in transformer-based architectures used for large language
models. But previously proposed simple function classes like linear regression
or multi-layer-perceptrons lack the structure required to explore things like
prompting and alignment within models capable of in-context-learning. We
propose univariate polynomial regression as a function class that is just rich
enough to study prompting and alignment, while allowing us to visualize and
understand what is going on clearly.",2024-07-27,"Max Wilcoxson, Morten Svendgård, Ria Doshi, Dylan Davis, Reya Vir, Anant Sahai",http://arxiv.org/pdf/2407.19346v1,cs.LG
LawLLM: Law Large Language Model for the US Legal System,"In the rapidly evolving field of legal analytics, finding relevant cases and
accurately predicting judicial outcomes are challenging because of the
complexity of legal language, which often includes specialized terminology,
complex syntax, and historical context. Moreover, the subtle distinctions
between similar and precedent cases require a deep understanding of legal
knowledge. Researchers often conflate these concepts, making it difficult to
develop specialized techniques to effectively address these nuanced tasks. In
this paper, we introduce the Law Large Language Model (LawLLM), a multi-task
model specifically designed for the US legal domain to address these
challenges. LawLLM excels at Similar Case Retrieval (SCR), Precedent Case
Recommendation (PCR), and Legal Judgment Prediction (LJP). By clearly
distinguishing between precedent and similar cases, we provide essential
clarity, guiding future research in developing specialized strategies for these
tasks. We propose customized data preprocessing techniques for each task that
transform raw legal data into a trainable format. Furthermore, we also use
techniques such as in-context learning (ICL) and advanced information retrieval
methods in LawLLM. The evaluation results demonstrate that LawLLM consistently
outperforms existing baselines in both zero-shot and few-shot scenarios,
offering unparalleled multi-task capabilities and filling critical gaps in the
legal domain.",2024-07-27,"Dong Shu, Haoran Zhao, Xukun Liu, David Demeter, Mengnan Du, Yongfeng Zhang",http://arxiv.org/pdf/2407.21065v1,cs.LG
Parameter-Efficient Fine-Tuning via Circular Convolution,"Low-Rank Adaptation (LoRA) has gained popularity for fine-tuning large
foundation models, leveraging low-rank matrices $\mathbf{A}$ and $\mathbf{B}$
to represent weight changes (i.e., $\Delta \mathbf{W} = \mathbf{B}
\mathbf{A}$). This method reduces trainable parameters and mitigates heavy
memory consumption associated with full delta matrices by sequentially
multiplying $\mathbf{A}$ and $\mathbf{B}$ with the activation. Despite its
success, the intrinsic low-rank characteristic may limit its performance.
Although several variants have been proposed to address this issue, they often
overlook the crucial computational and memory efficiency brought by LoRA. In
this paper, we propose Circular Convolution Adaptation (C$^3$A), which not only
achieves high-rank adaptation with enhanced performance but also excels in both
computational power and memory utilization. Extensive experiments demonstrate
that C$^3$A consistently outperforms LoRA and its variants across various
fine-tuning tasks.",2024-07-27,"Aochuan Chen, Jiashun Cheng, Zijing Liu, Ziqi Gao, Fugee Tsung, Yu Li, Jia Li",http://arxiv.org/pdf/2407.19342v3,cs.LG
Integrating Large Language Models into a Tri-Modal Architecture for Automated Depression Classification on the DAIC-WOZ,"Major Depressive Disorder (MDD) is a pervasive mental health condition that
affects 300 million people worldwide. This work presents a novel, BiLSTM-based
tri-modal model-level fusion architecture for the binary classification of
depression from clinical interview recordings. The proposed architecture
incorporates Mel Frequency Cepstral Coefficients, Facial Action Units, and uses
a two-shot learning based GPT-4 model to process text data. This is the first
work to incorporate large language models into a multi-modal architecture for
this task. It achieves impressive results on the DAIC-WOZ AVEC 2016 Challenge
cross-validation split and Leave-One-Subject-Out cross-validation split,
surpassing all baseline models and multiple state-of-the-art models. In
Leave-One-Subject-Out testing, it achieves an accuracy of 91.01%, an F1-Score
of 85.95%, a precision of 80%, and a recall of 92.86%.",2024-07-27,Santosh V. Patapati,http://arxiv.org/pdf/2407.19340v5,cs.LG
A Semi-supervised Fake News Detection using Sentiment Encoding and LSTM with Self-Attention,"Micro-blogs and cyber-space social networks are the main communication
mediums to receive and share news nowadays. As a side effect, however, the
networks can disseminate fake news that harms individuals and the society.
Several methods have been developed to detect fake news, but the majority
require large sets of manually labeled data to attain the application-level
accuracy. Due to the strict privacy policies, the required data are often
inaccessible or limited to some specific topics. On the other side, quite
diverse and abundant unlabeled data on social media suggests that with a few
labeled data, the problem of detecting fake news could be tackled via
semi-supervised learning. Here, we propose a semi-supervised self-learning
method in which a sentiment analysis is acquired by some state-of-the-art
pretrained models. Our learning model is trained in a semi-supervised fashion
and incorporates LSTM with self-attention layers. We benchmark our model on a
dataset with 20,000 news content along with their feedback, which shows better
performance in precision, recall, and measures compared to competitive methods
in fake news detection.",2024-07-27,"Pouya Shaeri, Ali Katanforoush",http://arxiv.org/pdf/2407.19332v1,cs.LG
Enhancing Group Fairness in Federated Learning through Personalization,"Personalized Federated Learning (FL) algorithms collaboratively train
customized models for each client, enhancing the accuracy of the learned models
on the client's local data (e.g., by clustering similar clients, by fine-tuning
models locally, or by imposing regularization terms). In this paper, we
investigate the impact of such personalization techniques on the group fairness
of the learned models, and show that personalization can also lead to improved
(local) fairness as an unintended benefit. We begin by illustrating these
benefits of personalization through numerical experiments comparing several
classes of personalized FL algorithms against a baseline FedAvg algorithm,
elaborating on the reasons behind improved fairness using personalized FL, and
then providing analytical support. Motivated by these, we then show how to
build on this (unintended) fairness benefit, by further integrating a fairness
metric into the cluster-selection procedure of clustering-based personalized FL
algorithms, and improve the fairness-accuracy trade-off attainable through
them. Specifically, we propose two new fairness-aware federated clustering
algorithms, Fair-FCA and Fair-FL+HC, extending the existing IFCA and FL+HC
algorithms, and demonstrate their ability to strike a (tuneable) balance
between accuracy and fairness at the client level.",2024-07-27,"Yifan Yang, Ali Payani, Parinaz Naghizadeh",http://arxiv.org/pdf/2407.19331v2,cs.LG
Accounting for plasticity: An extension of inelastic Constitutive Artificial Neural Networks,"The class of Constitutive Artificial Neural Networks (CANNs) represents a new
approach of neural networks in the field of constitutive modeling. So far,
CANNs have proven to be a powerful tool in predicting elastic and inelastic
material behavior. However, the specification of inelastic constitutive
artificial neural networks (iCANNs) to capture plasticity remains to be
discussed. We present the extension and application of an iCANN to the
inelastic phenomena of plasticity. This includes the prediction of a
formulation for the elastic and plastic Helmholtz free energies, the inelastic
flow rule, and the yield condition that defines the onset of plasticity. Thus,
we learn four feed-forward networks in combination with a recurrent neural
network and use the second Piola-Kirchhoff stress measure for training. The
presented formulation captures both, associative and non-associative
plasticity. In addition, the formulation includes kinematic hardening effects
by introducing the plastic Helmholtz free energy. This opens the range of
application to a wider class of materials. The capabilities of the presented
framework are demonstrated by training on artificially generated data of models
for perfect plasticity of von-Mises type, tension-compression asymmetry, and
kinematic hardening. We observe already satisfactory results for training on
one load case only while extremely precise agreement is found for an increase
in load cases. In addition, the performance of the specified iCANN was
validated using experimental data of X10CrMoVNb9-1 steel. Training has been
performed on both, uniaxial tension and cyclic loading, separately and the
predicted results are then validated on the opposing set. The results underline
that the autonomously discovered material model is capable to describe and
predict the underlying experimental data.",2024-07-27,"Birte Boes, Jaan-Willem Simon, Hagen Holthusen",http://arxiv.org/pdf/2407.19326v1,cs.LG
Deep Learning Based Crime Prediction Models: Experiments and Analysis,"Crime prediction is a widely studied research problem due to its importance
in ensuring safety of city dwellers. Starting from statistical and classical
machine learning based crime prediction methods, in recent years researchers
have focused on exploiting deep learning based models for crime prediction.
Deep learning based crime prediction models use complex architectures to
capture the latent features in the crime data, and outperform the statistical
and classical machine learning based crime prediction methods. However, there
is a significant research gap in existing research on the applicability of
different models in different real-life scenarios as no longitudinal study
exists comparing all these approaches in a unified setting. In this paper, we
conduct a comprehensive experimental evaluation of all major state-of-the-art
deep learning based crime prediction models. Our evaluation provides several
key insights on the pros and cons of these models, which enables us to select
the most suitable models for different application scenarios. Based on the
findings, we further recommend certain design practices that should be taken
into account while building future deep learning based crime prediction models.",2024-07-27,"Rittik Basak Utsha, Muhtasim Noor Alif, Yeasir Rayhan, Tanzima Hashem, Mohammad Eunus Ali",http://arxiv.org/pdf/2407.19324v1,cs.LG
WindsorML: High-Fidelity Computational Fluid Dynamics Dataset For Automotive Aerodynamics,"This paper presents a new open-source high-fidelity dataset for Machine
Learning (ML) containing 355 geometric variants of the Windsor body, to help
the development and testing of ML surrogate models for external automotive
aerodynamics. Each Computational Fluid Dynamics (CFD) simulation was run with a
GPU-native high-fidelity Wall-Modeled Large-Eddy Simulations (WMLES) using a
Cartesian immersed-boundary method using more than 280M cells to ensure the
greatest possible accuracy. The dataset contains geometry variants that
exhibits a wide range of flow characteristics that are representative of those
observed on road-cars. The dataset itself contains the 3D time-averaged volume
& boundary data as well as the geometry and force & moment coefficients. This
paper discusses the validation of the underlying CFD methods as well as
contents and structure of the dataset. To the authors knowledge, this
represents the first, large-scale high-fidelity CFD dataset for the Windsor
body with a permissive open-source license (CC-BY-SA).",2024-07-27,"Neil Ashton, Jordan B. Angel, Aditya S. Ghate, Gaetan K. W. Kenway, Man Long Wong, Cetin Kiris, Astrid Walle, Danielle C. Maddix, Gary Page",http://arxiv.org/pdf/2407.19320v4,cs.LG
Can Modifying Data Address Graph Domain Adaptation?,"Graph neural networks (GNNs) have demonstrated remarkable success in numerous
graph analytical tasks. Yet, their effectiveness is often compromised in
real-world scenarios due to distribution shifts, limiting their capacity for
knowledge transfer across changing environments or domains. Recently,
Unsupervised Graph Domain Adaptation (UGDA) has been introduced to resolve this
issue. UGDA aims to facilitate knowledge transfer from a labeled source graph
to an unlabeled target graph. Current UGDA efforts primarily focus on
model-centric methods, such as employing domain invariant learning strategies
and designing model architectures. However, our critical examination reveals
the limitations inherent to these model-centric methods, while a data-centric
method allowed to modify the source graph provably demonstrates considerable
potential. This insight motivates us to explore UGDA from a data-centric
perspective. By revisiting the theoretical generalization bound for UGDA, we
identify two data-centric principles for UGDA: alignment principle and
rescaling principle. Guided by these principles, we propose GraphAlign, a novel
UGDA method that generates a small yet transferable graph. By exclusively
training a GNN on this new graph with classic Empirical Risk Minimization
(ERM), GraphAlign attains exceptional performance on the target graph.
Extensive experiments under various transfer scenarios demonstrate the
GraphAlign outperforms the best baselines by an average of 2.16%, training on
the generated graph as small as 0.25~1% of the original training graph.",2024-07-27,"Renhong Huang, Jiarong Xu, Xin Jiang, Ruichuan An, Yang Yang",http://arxiv.org/pdf/2407.19311v1,cs.LG
GP-VLS: A general-purpose vision language model for surgery,"Surgery requires comprehensive medical knowledge, visual assessment skills,
and procedural expertise. While recent surgical AI models have focused on
solving task-specific problems, there is a need for general-purpose systems
that can understand surgical scenes and interact through natural language. This
paper introduces GP-VLS, a general-purpose vision language model for surgery
that integrates medical and surgical knowledge with visual scene understanding.
For comprehensively evaluating general-purpose surgical models, we propose
SurgiQual, which evaluates across medical and surgical knowledge benchmarks as
well as surgical vision-language questions. To train GP-VLS, we develop six new
datasets spanning medical knowledge, surgical textbooks, and vision-language
pairs for tasks like phase recognition and tool identification. We show that
GP-VLS significantly outperforms existing open- and closed-source models on
surgical vision-language tasks, with 8-21% improvements in accuracy across
SurgiQual benchmarks. GP-VLS also demonstrates strong performance on medical
and surgical knowledge tests compared to open-source alternatives. Overall,
GP-VLS provides an open-source foundation for developing AI assistants to
support surgeons across a wide range of tasks and scenarios. The code and data
for this work is publicly available at gpvls-surgery-vlm.github.io.",2024-07-27,"Samuel Schmidgall, Joseph Cho, Cyril Zakka, William Hiesinger",http://arxiv.org/pdf/2407.19305v2,cs.LG
CoLiDR: Concept Learning using Aggregated Disentangled Representations,"Interpretability of Deep Neural Networks using concept-based models offers a
promising way to explain model behavior through human-understandable concepts.
A parallel line of research focuses on disentangling the data distribution into
its underlying generative factors, in turn explaining the data generation
process. While both directions have received extensive attention, little work
has been done on explaining concepts in terms of generative factors to unify
mathematically disentangled representations and human-understandable concepts
as an explanation for downstream tasks. In this paper, we propose a novel
method CoLiDR - which utilizes a disentangled representation learning setup for
learning mutually independent generative factors and subsequently learns to
aggregate the said representations into human-understandable concepts using a
novel aggregation/decomposition module. Experiments are conducted on datasets
with both known and unknown latent generative factors. Our method successfully
aggregates disentangled generative factors into concepts while maintaining
parity with state-of-the-art concept-based approaches. Quantitative and visual
analysis of the learned aggregation procedure demonstrates the advantages of
our work compared to commonly used concept-based models over four challenging
datasets. Lastly, our work is generalizable to an arbitrary number of concepts
and generative factors - making it flexible enough to be suitable for various
types of data.",2024-07-27,"Sanchit Sinha, Guangzhi Xiong, Aidong Zhang",http://arxiv.org/pdf/2407.19300v1,cs.LG
Bayesian meta learning for trustworthy uncertainty quantification,"We consider the problem of Bayesian regression with trustworthy uncertainty
quantification. We define that the uncertainty quantification is trustworthy if
the ground truth can be captured by intervals dependent on the predictive
distributions with a pre-specified probability. Furthermore, we propose,
Trust-Bayes, a novel optimization framework for Bayesian meta learning which is
cognizant of trustworthy uncertainty quantification without explicit
assumptions on the prior model/distribution of the functions. We characterize
the lower bounds of the probabilities of the ground truth being captured by the
specified intervals and analyze the sample complexity with respect to the
feasible probability for trustworthy uncertainty quantification. Monte Carlo
simulation of a case study using Gaussian process regression is conducted for
verification and comparison with the Meta-prior algorithm.",2024-07-27,"Zhenyuan Yuan, Thinh T. Doan",http://arxiv.org/pdf/2407.19287v1,cs.LG
On Using Secure Aggregation in Differentially Private Federated Learning with Multiple Local Steps,"Federated learning is a distributed learning setting where the main aim is to
train machine learning models without having to share raw data but only what is
required for learning. To guarantee training data privacy and high-utility
models, differential privacy and secure aggregation techniques are often
combined with federated learning. However, with fine-grained protection
granularities, e.g., with the common sample-level protection, the currently
existing techniques generally require the parties to communicate for each local
optimization step, if they want to fully benefit from the secure aggregation in
terms of the resulting formal privacy guarantees. In this paper, we show how a
simple new analysis allows the parties to perform multiple local optimization
steps while still benefiting from using secure aggregation. We show that our
analysis enables higher utility models with guaranteed privacy protection under
limited number of communication rounds.",2024-07-27,Mikko A. Heikkilä,http://arxiv.org/pdf/2407.19286v2,cs.LG
Inverse Problems with Diffusion Models: A MAP Estimation Perspective,"Inverse problems have many applications in science and engineering. In
Computer vision, several image restoration tasks such as inpainting,
deblurring, and super-resolution can be formally modeled as inverse problems.
Recently, methods have been developed for solving inverse problems that only
leverage a pre-trained unconditional diffusion model and do not require
additional task-specific training. In such methods, however, the inherent
intractability of determining the conditional score function during the reverse
diffusion process poses a real challenge, leaving the methods to settle with an
approximation instead, which affects their performance in practice. Here, we
propose a MAP estimation framework to model the reverse conditional generation
process of a continuous time diffusion model as an optimization process of the
underlying MAP objective, whose gradient term is tractable. In theory, the
proposed framework can be applied to solve general inverse problems using
gradient-based optimization methods. However, given the highly non-convex
nature of the loss objective, finding a perfect gradient-based optimization
algorithm can be quite challenging, nevertheless, our framework offers several
potential research directions. We use our proposed formulation to develop
empirically effective algorithms for image restoration. We validate our
proposed algorithms with extensive experiments over multiple datasets across
several restoration tasks.",2024-07-27,"Sai Bharath Chandra Gutha, Ricardo Vinuesa, Hossein Azizpour",http://arxiv.org/pdf/2407.20784v2,cs.LG
From pixels to planning: scale-free active inference,"This paper describes a discrete state-space model -- and accompanying methods
-- for generative modelling. This model generalises partially observed Markov
decision processes to include paths as latent variables, rendering it suitable
for active inference and learning in a dynamic setting. Specifically, we
consider deep or hierarchical forms using the renormalisation group. The
ensuing renormalising generative models (RGM) can be regarded as discrete
homologues of deep convolutional neural networks or continuous state-space
models in generalised coordinates of motion. By construction, these
scale-invariant models can be used to learn compositionality over space and
time, furnishing models of paths or orbits; i.e., events of increasing temporal
depth and itinerancy. This technical note illustrates the automatic discovery,
learning and deployment of RGMs using a series of applications. We start with
image classification and then consider the compression and generation of movies
and music. Finally, we apply the same variational principles to the learning of
Atari-like games.",2024-07-27,"Karl Friston, Conor Heins, Tim Verbelen, Lancelot Da Costa, Tommaso Salvatori, Dimitrije Markovic, Alexander Tschantz, Magnus Koudahl, Christopher Buckley, Thomas Parr",http://arxiv.org/pdf/2407.20292v1,cs.LG
Towards Robust Few-shot Class Incremental Learning in Audio Classification using Contrastive Representation,"In machine learning applications, gradual data ingress is common, especially
in audio processing where incremental learning is vital for real-time
analytics. Few-shot class-incremental learning addresses challenges arising
from limited incoming data. Existing methods often integrate additional
trainable components or rely on a fixed embedding extractor post-training on
base sessions to mitigate concerns related to catastrophic forgetting and the
dangers of model overfitting. However, using cross-entropy loss alone during
base session training is suboptimal for audio data. To address this, we propose
incorporating supervised contrastive learning to refine the representation
space, enhancing discriminative power and leading to better generalization
since it facilitates seamless integration of incremental classes, upon arrival.
Experimental results on NSynth and LibriSpeech datasets with 100 classes, as
well as ESC dataset with 50 and 10 classes, demonstrate state-of-the-art
performance.",2024-07-27,"Riyansha Singh, Parinita Nema, Vinod K Kurmi",http://arxiv.org/pdf/2407.19265v2,cs.LG
"Understanding Memorisation in LLMs: Dynamics, Influencing Factors, and Implications","Understanding whether and to what extent large language models (LLMs) have
memorised training data has important implications for the reliability of their
output and the privacy of their training data. In order to cleanly measure and
disentangle memorisation from other phenomena (e.g. in-context learning), we
create an experimental framework that is based on repeatedly exposing LLMs to
random strings. Our framework allows us to better understand the dynamics,
i.e., the behaviour of the model, when repeatedly exposing it to random
strings. Using our framework, we make several striking observations: (a) we
find consistent phases of the dynamics across families of models (Pythia, Phi
and Llama2), (b) we identify factors that make some strings easier to memorise
than others, and (c) we identify the role of local prefixes and global context
in memorisation. We also show that sequential exposition to different random
strings has a significant effect on memorisation. Our results, often
surprising, have significant downstream implications in the study and usage of
LLMs.",2024-07-27,"Till Speicher, Mohammad Aflah Khan, Qinyuan Wu, Vedant Nanda, Soumi Das, Bishwamittra Ghosh, Krishna P. Gummadi, Evimaria Terzi",http://arxiv.org/pdf/2407.19262v1,cs.LG
Comprehensive Survey of Complex-Valued Neural Networks: Insights into Backpropagation and Activation Functions,"Artificial neural networks (ANNs), particularly those employing deep learning
models, have found widespread application in fields such as computer vision,
signal processing, and wireless communications, where complex numbers are
crucial. Despite the prevailing use of real-number implementations in current
ANN frameworks, there is a growing interest in developing ANNs that utilize
complex numbers. This paper presents a comprehensive survey of recent
advancements in complex-valued neural networks (CVNNs), focusing on their
activation functions (AFs) and learning algorithms. We delve into the extension
of the backpropagation algorithm to the complex domain, which enables the
training of neural networks with complex-valued inputs, weights, AFs, and
outputs. This survey considers three complex backpropagation algorithms: the
complex derivative approach, the partial derivatives approach, and algorithms
incorporating the Cauchy-Riemann equations. A significant challenge in CVNN
design is the identification of suitable nonlinear Complex Valued Activation
Functions (CVAFs), due to the conflict between boundedness and
differentiability over the entire complex plane as stated by Liouville theorem.
We examine both fully complex AFs, which strive for boundedness and
differentiability, and split AFs, which offer a practical compromise despite
not preserving analyticity. This review provides an in-depth analysis of
various CVAFs essential for constructing effective CVNNs. Moreover, this survey
not only offers a comprehensive overview of the current state of CVNNs but also
contributes to ongoing research and development by introducing a new set of
CVAFs (fully complex, split and complex amplitude-phase AFs).",2024-07-27,M. M. Hammad,http://arxiv.org/pdf/2407.19258v1,cs.LG
Stochastic Parrots or ICU Experts? Large Language Models in Critical Care Medicine: A Scoping Review,"With the rapid development of artificial intelligence (AI), large language
models (LLMs) have shown strong capabilities in natural language understanding,
reasoning, and generation, attracting amounts of research interest in applying
LLMs to health and medicine. Critical care medicine (CCM) provides diagnosis
and treatment for critically ill patients who often require intensive
monitoring and interventions in intensive care units (ICUs). Can LLMs be
applied to CCM? Are LLMs just like stochastic parrots or ICU experts in
assisting clinical decision-making? This scoping review aims to provide a
panoramic portrait of the application of LLMs in CCM. Literature in seven
databases, including PubMed, Embase, Scopus, Web of Science, CINAHL, IEEE
Xplore, and ACM Digital Library, were searched from January 1, 2019, to June
10, 2024. Peer-reviewed journal and conference articles that discussed the
application of LLMs in critical care settings were included. From an initial
619 articles, 24 were selected for final review. This review grouped
applications of LLMs in CCM into three categories: clinical decision support,
medical documentation and reporting, and medical education and doctor-patient
communication. LLMs have advantages in handling unstructured data and do not
require manual feature engineering. Meanwhile, applying LLMs to CCM faces
challenges, including hallucinations, poor interpretability, bias and alignment
challenges, and privacy and ethics issues. Future research should enhance model
reliability and interpretability, integrate up-to-date medical knowledge, and
strengthen privacy and ethical guidelines. As LLMs evolve, they could become
key tools in CCM to help improve patient outcomes and optimize healthcare
delivery. This study is the first review of LLMs in CCM, aiding researchers,
clinicians, and policymakers to understand the current status and future
potentials of LLMs in CCM.",2024-07-27,"Tongyue Shi, Jun Ma, Zihan Yu, Haowei Xu, Minqi Xiong, Meirong Xiao, Yilin Li, Huiying Zhao, Guilan Kong",http://arxiv.org/pdf/2407.19256v1,cs.LG
Nonlinear spectral analysis extracts harmonics from land-atmosphere fluxes,"Understanding the dynamics of the land-atmosphere exchange of CO$_2$ is key
to advance our predictive capacities of the coupled climate-carbon feedback
system.
  In essence, the net vegetation flux is the difference of the uptake of CO$_2$
via photosynthesis and the release of CO$_2$ via respiration, while the system
is driven by periodic processes at different time-scales.
  The complexity of the underlying dynamics poses challenges to classical
decomposition methods focused on maximizing data variance, such as singular
spectrum analysis.
  Here, we explore whether nonlinear data-driven methods can better separate
periodic patterns and their harmonics from noise and stochastic variability.
  We find that Nonlinear Laplacian Spectral Analysis (NLSA) outperforms the
linear method and detects multiple relevant harmonics. However, these harmonics
are not detected in the presence of substantial measurement irregularities.
  In summary, the NLSA approach can be used to both extract the seasonal cycle
more accurately than linear methods, but likewise detect irregular signals
resulting from irregular land-atmosphere interactions or measurement failures.
Improving the detection capabilities of time-series decomposition is essential
for improving land-atmosphere interactions models that should operate
accurately on any time scale.",2024-07-27,"Leonard Schulz, Jürgen Vollmer, Miguel D. Mahecha, Karin Mora",http://arxiv.org/pdf/2407.19237v1,cs.LG
Ordered Momentum for Asynchronous SGD,"Distributed learning is essential for training large-scale deep models.
Asynchronous SGD (ASGD) and its variants are commonly used distributed learning
methods, particularly in scenarios where the computing capabilities of workers
in the cluster are heterogeneous. Momentum has been acknowledged for its
benefits in both optimization and generalization in deep model training.
However, existing works have found that naively incorporating momentum into
ASGD can impede the convergence. In this paper, we propose a novel method
called ordered momentum (OrMo) for ASGD. In OrMo, momentum is incorporated into
ASGD by organizing the gradients in order based on their iteration indexes. We
theoretically prove the convergence of OrMo with both constant and
delay-adaptive learning rates for non-convex problems. To the best of our
knowledge, this is the first work to establish the convergence analysis of ASGD
with momentum without dependence on the maximum delay. Empirical results
demonstrate that OrMo can achieve better convergence performance compared with
ASGD and other asynchronous methods with momentum.",2024-07-27,"Chang-Wei Shi, Yi-Rui Yang, Wu-Jun Li",http://arxiv.org/pdf/2407.19234v3,cs.LG
Alleviating Over-Smoothing via Aggregation over Compact Manifolds,"Graph neural networks (GNNs) have achieved significant success in various
applications. Most GNNs learn the node features with information aggregation of
its neighbors and feature transformation in each layer. However, the node
features become indistinguishable after many layers, leading to performance
deterioration: a significant limitation known as over-smoothing. Past work
adopted various techniques for addressing this issue, such as normalization and
skip-connection of layer-wise output. After the study, we found that the
information aggregations in existing work are all contracted aggregations, with
the intrinsic property that features will inevitably converge to the same
single point after many layers. To this end, we propose the aggregation over
compacted manifolds method (ACM) that replaces the existing information
aggregation with aggregation over compact manifolds, a special type of
manifold, which avoids contracted aggregations. In this work, we theoretically
analyze contracted aggregation and its properties. We also provide an extensive
empirical evaluation that shows ACM can effectively alleviate over-smoothing
and outperforms the state-of-the-art. The code can be found in
https://github.com/DongzhuoranZhou/ACM.git.",2024-07-27,"Dongzhuoran Zhou, Hui Yang, Bo Xiong, Yue Ma, Evgeny Kharlamov",http://arxiv.org/pdf/2407.19231v1,cs.LG
Graph Residual based Method for Molecular Property Prediction,"Machine learning-driven methods for property prediction have been of deep
interest. However, much work remains to be done to improve the generalization
ability, accuracy, and inference time for critical applications. The
traditional machine learning models predict properties based on the features
extracted from the molecules, which are often not easily available. In this
work, a novel Deep Learning method, the Edge Conditioned Residual Graph Neural
Network (ECRGNN), has been applied, allowing us to predict properties directly
only the Graph-based structures of the molecules. SMILES (Simplified Molecular
Input Line Entry System) representation of the molecules has been used in the
present study as input data format, which has been further converted into a
graph database, which constitutes the training data. This manuscript highlights
a detailed description of the novel GRU-based methodology, ECRGNN, to map the
inputs that have been used. Emphasis is placed on highlighting both the
regressive property and the classification efficacy of the same. A detailed
description of the Variational Autoencoder (VAE) and the end-to-end learning
method used for multi-class multi-label property prediction has been provided
as well. The results have been compared with standard benchmark datasets as
well as some newly developed datasets. All performance metrics that have been
used have been clearly defined, and their reason for choice.",2024-07-27,"Kanad Sen, Saksham Gupta, Abhishek Raj, Alankar Alankar",http://arxiv.org/pdf/2408.03342v2,cs.LG
Long Range Switching Time Series Prediction via State Space Model,"In this study, we delve into the Structured State Space Model (S4), Change
Point Detection methodologies, and the Switching Non-linear Dynamics System
(SNLDS). Our central proposition is an enhanced inference technique and
long-range dependency method for SNLDS. The cornerstone of our approach is the
fusion of S4 and SNLDS, leveraging the strengths of both models to effectively
address the intricacies of long-range dependencies in switching time series.
Through rigorous testing, we demonstrate that our proposed methodology adeptly
segments and reproduces long-range dependencies in both the 1-D Lorenz dataset
and the 2-D bouncing ball dataset. Notably, our integrated approach outperforms
the standalone SNLDS in these tasks.",2024-07-27,"Jiaming Zhang, Yang Ding, Yunfeng Gao",http://arxiv.org/pdf/2407.19201v1,cs.LG
A simulation study of cluster search algorithms in data set generated by Gaussian mixture models,"Determining the number of clusters is a fundamental issue in data clustering.
Several algorithms have been proposed, including centroid-based algorithms
using the Euclidean distance and model-based algorithms using a mixture of
probability distributions. Among these, greedy algorithms for searching the
number of clusters by repeatedly splitting or merging clusters have advantages
in terms of computation time for problems with large sample sizes. However,
studies comparing these methods in systematic evaluation experiments still need
to be included. This study examines centroid- and model-based cluster search
algorithms in various cases that Gaussian mixture models (GMMs) can generate.
The cases are generated by combining five factors: dimensionality, sample size,
the number of clusters, cluster overlap, and covariance type. The results show
that some cluster-splitting criteria based on Euclidean distance make
unreasonable decisions when clusters overlap. The results also show that
model-based algorithms are insensitive to covariance type and cluster overlap
compared to the centroid-based method if the sample size is sufficient. Our
cluster search implementation codes are available at
https://github.com/lipryou/searchClustK",2024-07-27,"Ryosuke Motegi, Yoichi Seki",http://arxiv.org/pdf/2407.19199v1,cs.LG
Towards the Dynamics of a DNN Learning Symbolic Interactions,"This study proves the two-phase dynamics of a deep neural network (DNN)
learning interactions. Despite the long disappointing view of the faithfulness
of post-hoc explanation of a DNN, a series of theorems have been proven in
recent years to show that for a given input sample, a small set of interactions
between input variables can be considered as primitive inference patterns that
faithfully represent a DNN's detailed inference logic on that sample.
Particularly, Zhang et al. have observed that various DNNs all learn
interactions of different complexities in two distinct phases, and this
two-phase dynamics well explains how a DNN changes from under-fitting to
over-fitting. Therefore, in this study, we mathematically prove the two-phase
dynamics of interactions, providing a theoretical mechanism for how the
generalization power of a DNN changes during the training process. Experiments
show that our theory well predicts the real dynamics of interactions on
different DNNs trained for various tasks.",2024-07-27,"Qihan Ren, Junpeng Zhang, Yang Xu, Yue Xin, Dongrui Liu, Quanshi Zhang",http://arxiv.org/pdf/2407.19198v2,cs.LG
A collaborative ensemble construction method for federated random forest,"Random forests are considered a cornerstone in machine learning for their
robustness and versatility. Despite these strengths, their conventional
centralized training is ill-suited for the modern landscape of data that is
often distributed, sensitive, and subject to privacy concerns. Federated
learning (FL) provides a compelling solution to this problem, enabling models
to be trained across a group of clients while maintaining the privacy of each
client's data. However, adapting tree-based methods like random forests to
federated settings introduces significant challenges, particularly when it
comes to non-identically distributed (non-IID) data across clients, which is a
common scenario in real-world applications. This paper presents a federated
random forest approach that employs a novel ensemble construction method aimed
at improving performance under non-IID data. Instead of growing trees
independently in each client, our approach ensures each decision tree in the
ensemble is iteratively and collectively grown across clients. To preserve the
privacy of the client's data, we confine the information stored in the leaf
nodes to the majority class label identified from the samples of the client's
local data that reach each node. This limited disclosure preserves the
confidentiality of the underlying data distribution of clients, thereby
enhancing the privacy of the federated learning process. Furthermore, our
collaborative ensemble construction strategy allows the ensemble to better
reflect the data's heterogeneity across different clients, enhancing its
performance on non-IID data, as our experimental results confirm.",2024-07-27,"Penjan Antonio Eng Lim, Cheong Hee Park",http://arxiv.org/pdf/2407.19193v1,cs.LG
Efficiently improving key weather variables forecasting by performing the guided iterative prediction in latent space,"Weather forecasting refers to learning evolutionary patterns of some key
upper-air and surface variables which is of great significance. Recently, deep
learning-based methods have been increasingly applied in the field of weather
forecasting due to their powerful feature learning capabilities. However,
prediction methods based on the original space iteration struggle to
effectively and efficiently utilize large number of weather variables.
Therefore, we propose an 'encoding-prediction-decoding' prediction network.
This network can efficiently benefit to more related input variables with key
variables, that is, it can adaptively extract key variable-related
low-dimensional latent feature from much more input atmospheric variables for
iterative prediction. And we construct a loss function to guide the iteration
of latent feature by utilizing multiple atmospheric variables in corresponding
lead times. The obtained latent features through iterative prediction are then
decoded to obtain the predicted values of key variables in multiple lead times.
In addition, we improve the HTA algorithm in \cite{bi2023accurate} by inputting
more time steps to enhance the temporal correlation between the prediction
results and input variables. Both qualitative and quantitative prediction
results on ERA5 dataset validate the superiority of our method over other
methods. (The code will be available at https://github.com/rs-lsl/Kvp-lsi)",2024-07-27,"Shuangliang Li, Siwei Li",http://arxiv.org/pdf/2407.19187v1,cs.LG
Graph Memory Learning: Imitating Lifelong Remembering and Forgetting of Brain Networks,"Graph data in real-world scenarios undergo rapid and frequent changes, making
it challenging for existing graph models to effectively handle the continuous
influx of new data and accommodate data withdrawal requests. The approach to
frequently retraining graph models is resource intensive and impractical. To
address this pressing challenge, this paper introduces a new concept of graph
memory learning. Its core idea is to enable a graph model to selectively
remember new knowledge but forget old knowledge. Building on this approach, the
paper presents a novel graph memory learning framework - Brain-inspired Graph
Memory Learning (BGML), inspired by brain network dynamics and
function-structure coupling strategies. BGML incorporates a multi-granular
hierarchical progressive learning mechanism rooted in feature graph grain
learning to mitigate potential conflict between memorization and forgetting in
graph memory learning. This mechanism allows for a comprehensive and
multi-level perception of local details within evolving graphs. In addition, to
tackle the issue of unreliable structures in newly added incremental
information, the paper introduces an information self-assessment ownership
mechanism. This mechanism not only facilitates the propagation of incremental
information within the model but also effectively preserves the integrity of
past experiences. We design five types of graph memory learning tasks: regular,
memory, unlearning, data-incremental, and class-incremental to evaluate BGML.
Its excellent performance is confirmed through extensive experiments on
multiple real-world node classification datasets.",2024-07-27,"Jiaxing Miao, Liang Hu, Qi Zhang, Longbing Cao",http://arxiv.org/pdf/2407.19183v1,cs.LG
Decomposing heterogeneous dynamical systems with graph neural networks,"Natural physical, chemical, and biological dynamical systems are often
complex, with heterogeneous components interacting in diverse ways. We show
that graph neural networks can be designed to jointly learn the interaction
rules and the structure of the heterogeneity from data alone. The learned
latent structure and dynamics can be used to virtually decompose the complex
system which is necessary to parameterize and infer the underlying governing
equations. We tested the approach with simulation experiments of moving
particles and vector fields that interact with each other. While our current
aim is to better understand and validate the approach with simulated data, we
anticipate it to become a generally applicable tool to uncover the governing
rules underlying complex dynamics observed in nature.",2024-07-27,"Cédric Allier, Magdalena C. Schneider, Michael Innerberger, Larissa Heinrich, John A. Bogovic, Stephan Saalfeld",http://arxiv.org/pdf/2407.19160v1,cs.LG
Debiased Graph Poisoning Attack via Contrastive Surrogate Objective,"Graph neural networks (GNN) are vulnerable to adversarial attacks, which aim
to degrade the performance of GNNs through imperceptible changes on the graph.
However, we find that in fact the prevalent meta-gradient-based attacks, which
utilizes the gradient of the loss w.r.t the adjacency matrix, are biased
towards training nodes. That is, their meta-gradient is determined by a
training procedure of the surrogate model, which is solely trained on the
training nodes. This bias manifests as an uneven perturbation, connecting two
nodes when at least one of them is a labeled node, i.e., training node, while
it is unlikely to connect two unlabeled nodes. However, these biased attack
approaches are sub-optimal as they do not consider flipping edges between two
unlabeled nodes at all. This means that they miss the potential attacked edges
between unlabeled nodes that significantly alter the representation of a node.
In this paper, we investigate the meta-gradients to uncover the root cause of
the uneven perturbations of existing attacks. Based on our analysis, we propose
a Meta-gradient-based attack method using contrastive surrogate objective
(Metacon), which alleviates the bias in meta-gradient using a new surrogate
loss. We conduct extensive experiments to show that Metacon outperforms
existing meta gradient-based attack methods through benchmark datasets, while
showing that alleviating the bias towards training nodes is effective in
attacking the graph structure.",2024-07-27,"Kanghoon Yoon, Yeonjun In, Namkyeong Lee, Kibum Kim, Chanyoung Park",http://arxiv.org/pdf/2407.19155v1,cs.LG
A Survey of Malware Detection Using Deep Learning,"The problem of malicious software (malware) detection and classification is a
complex task, and there is no perfect approach. There is still a lot of work to
be done. Unlike most other research areas, standard benchmarks are difficult to
find for malware detection. This paper aims to investigate recent advances in
malware detection on MacOS, Windows, iOS, Android, and Linux using deep
learning (DL) by investigating DL in text and image classification, the use of
pre-trained and multi-task learning models for malware detection approaches to
obtain high accuracy and which the best approach if we have a standard
benchmark dataset. We discuss the issues and the challenges in malware
detection using DL classifiers by reviewing the effectiveness of these DL
classifiers and their inability to explain their decisions and actions to DL
developers presenting the need to use Explainable Machine Learning (XAI) or
Interpretable Machine Learning (IML) programs. Additionally, we discuss the
impact of adversarial attacks on deep learning models, negatively affecting
their generalization capabilities and resulting in poor performance on unseen
data. We believe there is a need to train and test the effectiveness and
efficiency of the current state-of-the-art deep learning models on different
malware datasets. We examine eight popular DL approaches on various datasets.
This survey will help researchers develop a general understanding of malware
recognition using deep learning.",2024-07-27,"Ahmed Bensaoud, Jugal Kalita, Mahmoud Bensaoud",http://arxiv.org/pdf/2407.19153v1,cs.LG
Using deep learning to enhance electronic service quality: Application to real estate websites,"Electronic service quality (E-SQ) is a strategic metric for successful
e-services.Among the service quality dimensions, tangibility is overlooked.
However, by incorporating visuals or tangible tools, the intangible nature of
e-services can be balanced. Thanks to advancements in Deep Learning for
computer vision, tangible visual features can now be leveraged to enhance the
browsing and searching experience of electronic services. Users usually have
specific search criteria to meet, but most services will not offer flexible
search filters. This research emphasizes the importance of integrating visual
and descriptive features to improve the tangibility and efficiency of
e-services. A prime example of an electronic service that can benefit from this
is real-estate websites. Searching for real estate properties that match user
preferences is usually demanding and lacks visual filters, such as the Damage
Level to the property. The research introduces a novel visual descriptive
feature, the Damage Level, which utilizes a deep learning network known as
Mask-RCNN to estimate damage in real estate images. Additionally, a model is
developed to incorporate the Damage Level as a tangible feature in electronic
real estate services, with the aim of enhancing the tangible customer
experience.",2024-07-27,Samaa Elnagar,http://arxiv.org/pdf/2408.06364v1,cs.LG
On the benefits of pixel-based hierarchical policies for task generalization,"Reinforcement learning practitioners often avoid hierarchical policies,
especially in image-based observation spaces. Typically, the single-task
performance improvement over flat-policy counterparts does not justify the
additional complexity associated with implementing a hierarchy. However, by
introducing multiple decision-making levels, hierarchical policies can compose
lower-level policies to more effectively generalize between tasks, highlighting
the need for multi-task evaluations. We analyze the benefits of hierarchy
through simulated multi-task robotic control experiments from pixels. Our
results show that hierarchical policies trained with task conditioning can (1)
increase performance on training tasks, (2) lead to improved reward and
state-space generalizations in similar tasks, and (3) decrease the complexity
of fine tuning required to solve novel tasks. Thus, we believe that
hierarchical policies should be considered when building reinforcement learning
architectures capable of generalizing between tasks.",2024-07-27,"Tudor Cristea-Platon, Bogdan Mazoure, Josh Susskind, Walter Talbott",http://arxiv.org/pdf/2407.19142v1,cs.LG
Accuracy-Privacy Trade-off in the Mitigation of Membership Inference Attack in Federated Learning,"Over the last few years, federated learning (FL) has emerged as a prominent
method in machine learning, emphasizing privacy preservation by allowing
multiple clients to collaboratively build a model while keeping their training
data private. Despite this focus on privacy, FL models are susceptible to
various attacks, including membership inference attacks (MIAs), posing a
serious threat to data confidentiality. In a recent study, Rezaei \textit{et
al.} revealed the existence of an accuracy-privacy trade-off in deep ensembles
and proposed a few fusion strategies to overcome it. In this paper, we aim to
explore the relationship between deep ensembles and FL. Specifically, we
investigate whether confidence-based metrics derived from deep ensembles apply
to FL and whether there is a trade-off between accuracy and privacy in FL with
respect to MIA. Empirical investigations illustrate a lack of a non-monotonic
correlation between the number of clients and the accuracy-privacy trade-off.
By experimenting with different numbers of federated clients, datasets, and
confidence-metric-based fusion strategies, we identify and analytically justify
the clear existence of the accuracy-privacy trade-off.",2024-07-26,"Sayyed Farid Ahamed, Soumya Banerjee, Sandip Roy, Devin Quinn, Marc Vucovich, Kevin Choi, Abdul Rahman, Alison Hu, Edward Bowen, Sachin Shetty",http://arxiv.org/pdf/2407.19119v1,cs.LG
Towards Scalable and Stable Parallelization of Nonlinear RNNs,"Transformers and linear state space models can be evaluated in parallel on
modern hardware, but evaluating nonlinear RNNs appears to be an inherently
sequential problem. Recently, however, Lim et al. '24 developed an approach
called DEER, which evaluates nonlinear RNNs in parallel by posing the states as
the solution to a fixed-point problem. They derived a parallel form of Newton's
method to solve the fixed-point problem and achieved significant speedups over
sequential evaluation. However, the computational complexity of DEER is cubic
in the state size, and the algorithm can suffer from numerical instability. We
address these limitations with two novel contributions. To reduce the
computational complexity, we apply quasi-Newton approximations and show they
converge comparably to Newton, use less memory, and are faster. To stabilize
DEER, we leverage a connection between the Levenberg-Marquardt algorithm and
Kalman smoothing, which we call ELK. This connection allows us to stabilize
Newton's method while using efficient parallelized Kalman smoothing algorithms
to retain performance. Through several experiments, we show that these
innovations allow for parallel evaluation of nonlinear RNNs at larger scales
and with greater stability.",2024-07-26,"Xavier Gonzalez, Andrew Warrington, Jimmy T. H. Smith, Scott W. Linderman",http://arxiv.org/pdf/2407.19115v3,cs.LG
To which reference class do you belong? Measuring racial fairness of reference classes with normative modeling,"Reference classes in healthcare establish healthy norms, such as pediatric
growth charts of height and weight, and are used to chart deviations from these
norms which represent potential clinical risk. How the demographics of the
reference class influence clinical interpretation of deviations is unknown.
Using normative modeling, a method for building reference classes, we evaluate
the fairness (racial bias) in reference models of structural brain images that
are widely used in psychiatry and neurology. We test whether including race in
the model creates fairer models. We predict self-reported race using the
deviation scores from three different reference class normative models, to
better understand bias in an integrated, multivariate sense. Across all of
these tasks, we uncover racial disparities that are not easily addressed with
existing data or commonly used modeling techniques. Our work suggests that
deviations from the norm could be due to demographic mismatch with the
reference class, and assigning clinical meaning to these deviations should be
done with caution. Our approach also suggests that acquiring more
representative samples is an urgent research priority.",2024-07-26,"Saige Rutherford, Thomas Wolfers, Charlotte Fraza, Nathaniel G. Harnett, Christian F. Beckmann, Henricus G. Ruhe, Andre F. Marquand",http://arxiv.org/pdf/2407.19114v2,cs.LG
FedAR: Addressing Client Unavailability in Federated Learning with Local Update Approximation and Rectification,"Federated learning (FL) enables clients to collaboratively train machine
learning models under the coordination of a server in a privacy-preserving
manner. One of the main challenges in FL is that the server may not receive
local updates from each client in each round due to client resource limitations
and intermittent network connectivity. The existence of unavailable clients
severely deteriorates the overall FL performance. In this paper, we propose , a
novel client update Approximation and Rectification algorithm for FL to address
the client unavailability issue. FedAR can get all clients involved in the
global model update to achieve a high-quality global model on the server, which
also furnishes accurate predictions for each client. To this end, the server
uses the latest update from each client as a surrogate for its current update.
It then assigns a different weight to each client's surrogate update to derive
the global model, in order to guarantee contributions from both available and
unavailable clients. Our theoretical analysis proves that FedAR achieves
optimal convergence rates on non-IID datasets for both convex and non-convex
smooth loss functions. Extensive empirical studies show that FedAR
comprehensively outperforms state-of-the-art FL baselines including FedAvg,
MIFA, FedVARP and Scaffold in terms of the training loss, test accuracy, and
bias mitigation. Moreover, FedAR also depicts impressive performance in the
presence of a large number of clients with severe client unavailability.",2024-07-26,"Chutian Jiang, Hansong Zhou, Xiaonan Zhang, Shayok Chakraborty",http://arxiv.org/pdf/2407.19103v1,cs.LG
NARVis: Neural Accelerated Rendering for Real-Time Scientific Point Cloud Visualization,"Exploring scientific datasets with billions of samples in real-time
visualization presents a challenge - balancing high-fidelity rendering with
speed. This work introduces a novel renderer - Neural Accelerated Renderer
(NAR), that uses the neural deferred rendering framework to visualize
large-scale scientific point cloud data. NAR augments a real-time point cloud
rendering pipeline with high-quality neural post-processing, making the
approach ideal for interactive visualization at scale. Specifically, we train a
neural network to learn the point cloud geometry from a high-performance
multi-stream rasterizer and capture the desired postprocessing effects from a
conventional high-quality renderer. We demonstrate the effectiveness of NAR by
visualizing complex multidimensional Lagrangian flow fields and photometric
scans of a large terrain and compare the renderings against the
state-of-the-art high-quality renderers. Through extensive evaluation, we
demonstrate that NAR prioritizes speed and scalability while retaining high
visual fidelity. We achieve competitive frame rates of $>$ 126 fps for
interactive rendering of $>$ 350M points (i.e., an effective throughput of $>$
44 billion points per second) using $\sim$12 GB of memory on RTX 2080 Ti GPU.
Furthermore, we show that NAR is generalizable across different point clouds
with similar visualization needs and the desired post-processing effects could
be obtained with substantial high quality even at lower resolutions of the
original point cloud, further reducing the memory requirements.",2024-07-26,"Srinidhi Hegde, Kaur Kullman, Thomas Grubb, Leslie Lait, Stephen Guimond, Matthias Zwicker",http://arxiv.org/pdf/2407.19097v1,cs.LG
Boosted generalized normal distributions: Integrating machine learning with operations knowledge,"Applications of machine learning (ML) techniques to operational settings
often face two challenges: i) ML methods mostly provide point predictions
whereas many operational problems require distributional information; and ii)
They typically do not incorporate the extensive body of knowledge in the
operations literature, particularly the theoretical and empirical findings that
characterize specific distributions. We introduce a novel and rigorous
methodology, the Boosted Generalized Normal Distribution ($b$GND), to address
these challenges. The Generalized Normal Distribution (GND) encompasses a wide
range of parametric distributions commonly encountered in operations, and
$b$GND leverages gradient boosting with tree learners to flexibly estimate the
parameters of the GND as functions of covariates. We establish $b$GND's
statistical consistency, thereby extending this key property to special cases
studied in the ML literature that lacked such guarantees. Using data from a
large academic emergency department in the United States, we show that the
distributional forecasting of patient wait and service times can be
meaningfully improved by leveraging findings from the healthcare operations
literature. Specifically, $b$GND performs 6% and 9% better than the
distribution-agnostic ML benchmark used to forecast wait and service times
respectively. Further analysis suggests that these improvements translate into
a 9% increase in patient satisfaction and a 4% reduction in mortality for
myocardial infarction patients. Our work underscores the importance of
integrating ML with operations knowledge to enhance distributional forecasts.",2024-07-26,"Ragip Gurlek, Francis de Vericourt, Donald K. K. Lee",http://arxiv.org/pdf/2407.19092v2,cs.LG
Super Resolution for Renewable Energy Resource Data With Wind From Reanalysis Data (Sup3rWind) and Application to Ukraine,"With an increasing share of the electricity grid relying on wind to provide
generating capacity and energy, there is an expanding global need for
historically accurate high-resolution wind data. Conventional downscaling
methods for generating these data have a high computational burden and require
extensive tuning for historical accuracy. In this work, we present a novel deep
learning-based spatiotemporal downscaling method, using generative adversarial
networks (GANs), for generating historically accurate high-resolution wind
resource data from the European Centre for Medium-Range Weather Forecasting
Reanalysis version 5 data (ERA5). We achieve results comparable in historical
accuracy and spatiotemporal variability to conventional downscaling by training
a GAN model with ERA5 low-resolution input and high-resolution targets from the
Wind Integration National Dataset, while reducing computational costs over
dynamical downscaling by two orders of magnitude. Spatiotemporal
cross-validation shows low error and high correlations with observations and
excellent agreement with holdout data across distributions of physical metrics.
We apply this approach to downscale 30-km hourly ERA5 data to 2-km 5-minute
wind data for January 2000 through December 2023 at multiple hub heights over
Eastern Europe. Uncertainty is estimated over the period with observational
data by additionally downscaling the members of the European Centre for
Medium-Range Weather Forecasting Ensemble of Data Assimilations. Comparisons
against observational data from the Meteorological Assimilation Data Ingest
System and multiple wind farms show comparable performance to the CONUS
validation. This 24-year data record is the first member of the super
resolution for renewable energy resource data with wind from reanalysis data
dataset (Sup3rWind).",2024-07-26,"Brandon N. Benton, Grant Buster, Pavlo Pinchuk, Andrew Glaws, Ryan N. King, Galen Maclaurin, Ilya Chernyakhovskiy",http://arxiv.org/pdf/2407.19086v1,cs.LG
Regularized Multi-Decoder Ensemble for an Error-Aware Scene Representation Network,"Feature grid Scene Representation Networks (SRNs) have been applied to
scientific data as compact functional surrogates for analysis and
visualization. As SRNs are black-box lossy data representations, assessing the
prediction quality is critical for scientific visualization applications to
ensure that scientists can trust the information being visualized. Currently,
existing architectures do not support inference time reconstruction quality
assessment, as coordinate-level errors cannot be evaluated in the absence of
ground truth data. We propose a parameter-efficient multi-decoder SRN (MDSRN)
ensemble architecture consisting of a shared feature grid with multiple
lightweight multi-layer perceptron decoders. MDSRN can generate a set of
plausible predictions for a given input coordinate to compute the mean as the
prediction of the multi-decoder ensemble and the variance as a confidence
score. The coordinate-level variance can be rendered along with the data to
inform the reconstruction quality, or be integrated into uncertainty-aware
volume visualization algorithms. To prevent the misalignment between the
quantified variance and the prediction quality, we propose a novel variance
regularization loss for ensemble learning that promotes the Regularized
multi-decoder SRN (RMDSRN) to obtain a more reliable variance that correlates
closely to the true model error. We comprehensively evaluate the quality of
variance quantification and data reconstruction of Monte Carlo Dropout, Mean
Field Variational Inference, Deep Ensemble, and Predicting Variance compared to
the proposed MDSRN and RMDSRN across diverse scalar field datasets. We
demonstrate that RMDSRN attains the most accurate data reconstruction and
competitive variance-error correlation among uncertain SRNs under the same
neural network parameter budgets.",2024-07-26,"Tianyu Xiong, Skylar W. Wurster, Hanqi Guo, Tom Peterka, Han-Wei Shen",http://arxiv.org/pdf/2407.19082v2,cs.LG
Practical Marketplace Optimization at Uber Using Causally-Informed Machine Learning,"Budget allocation of marketplace levers, such as incentives for drivers and
promotions for riders, has long been a technical and business challenge at
Uber; understanding lever budget changes' impact and estimating cost efficiency
to achieve predefined budgets is crucial, with the goal of optimal allocations
that maximize business value; we introduce an end-to-end machine learning and
optimization procedure to automate budget decision-making for cities, relying
on feature store, model training and serving, optimizers, and backtesting;
proposing state-of-the-art deep learning (DL) estimator based on S-Learner and
a novel tensor B-Spline regression model, we solve high-dimensional
optimization with ADMM and primal-dual interior point convex optimization,
substantially improving Uber's resource allocation efficiency.",2024-07-26,"Bobby Chen, Siyu Chen, Jason Dowlatabadi, Yu Xuan Hong, Vinayak Iyer, Uday Mantripragada, Rishabh Narang, Apoorv Pandey, Zijun Qin, Abrar Sheikh, Hongtao Sun, Jiaqi Sun, Matthew Walker, Kaichen Wei, Chen Xu, Jingnan Yang, Allen T. Zhang, Guoqing Zhang",http://arxiv.org/pdf/2407.19078v1,cs.LG
Hybrid Heuristic Algorithms for Adiabatic Quantum Machine Learning Models,"Numerous established machine learning models and various neural network
architectures can be restructured as Quadratic Unconstrained Binary
Optimization (QUBO) problems. A significant challenge in Adiabatic Quantum
Machine Learning (AQML) is the computational demand of the training phase. To
mitigate this, approximation techniques inspired by quantum annealing, like
Simulated Annealing and Multiple Start Tabu Search (MSTS), have been employed
to expedite QUBO-based AQML training. This paper introduces a novel hybrid
algorithm that incorporates an ""r-flip"" strategy. This strategy is aimed at
solving large-scale QUBO problems more effectively, offering better solution
quality and lower computational costs compared to existing MSTS methods. The
r-flip approach has practical applications in diverse fields, including
cross-docking, supply chain management, machine scheduling, and fraud
detection. The paper details extensive computational experiments comparing this
r-flip enhanced hybrid heuristic against a standard MSTS approach. These tests
utilize both standard benchmark problems and three particularly large QUBO
instances. The results indicate that the r-flip enhanced method consistently
produces high-quality solutions efficiently, operating within practical time
constraints.",2024-07-26,"Bahram Alidaee, Haibo Wang, Lutfu Sua, Wade Liu",http://arxiv.org/pdf/2407.21062v2,cs.LG
Effective Large Language Model Debugging with Best-first Tree Search,"Large Language Models (LLMs) show promise in code generation tasks. However,
their code-writing abilities are often limited in scope: while they can
successfully implement simple functions, they struggle with more complex tasks.
A fundamental difference with how an LLM writes code, compared to a human
programmer, is that it cannot consistently spot and fix bugs. Debugging is a
crucial skill for programmers and it enables iterative code refinement towards
a correct implementation. In this work, we propose a novel algorithm to enable
LLMs to debug their code via self-reflection and search where a model attempts
to identify its previous mistakes. Our key contributions are 1) a best-first
tree search algorithm with self-reflections (BESTER) that achieves
state-of-the-art Pass@1 in three code generation benchmarks. BESTER maintains
its superiority when we measure pass rates taking into account additional
inference costs incurred by tree search. 2) A novel interpretability study on
what self-reflections attend to in buggy programs and how they impact bug
fixes, which provides a deeper understanding of the debugging process. 3) An
extensive study on when self-reflections are effective in finding bugs.",2024-07-26,"Jialin Song, Jonathan Raiman, Bryan Catanzaro",http://arxiv.org/pdf/2407.19055v1,cs.LG
Flusion: Integrating multiple data sources for accurate influenza predictions,"Over the last ten years, the US Centers for Disease Control and Prevention
(CDC) has organized an annual influenza forecasting challenge with the
motivation that accurate probabilistic forecasts could improve situational
awareness and yield more effective public health actions. Starting with the
2021/22 influenza season, the forecasting targets for this challenge have been
based on hospital admissions reported in the CDC's National Healthcare Safety
Network (NHSN) surveillance system. Reporting of influenza hospital admissions
through NHSN began within the last few years, and as such only a limited amount
of historical data are available for this signal. To produce forecasts in the
presence of limited data for the target surveillance system, we augmented these
data with two signals that have a longer historical record: 1) ILI+, which
estimates the proportion of outpatient doctor visits where the patient has
influenza; and 2) rates of laboratory-confirmed influenza hospitalizations at a
selected set of healthcare facilities. Our model, Flusion, is an ensemble that
combines gradient boosting quantile regression models with a Bayesian
autoregressive model. The gradient boosting models were trained on all three
data signals, while the autoregressive model was trained on only the target
signal; all models were trained jointly on data for multiple locations. Flusion
was the top-performing model in the CDC's influenza prediction challenge for
the 2023/24 season. In this article we investigate the factors contributing to
Flusion's success, and we find that its strong performance was primarily driven
by the use of a gradient boosting model that was trained jointly on data from
multiple surveillance signals and locations. These results indicate the value
of sharing information across locations and surveillance signals, especially
when doing so adds to the pool of available training data.",2024-07-26,"Evan L. Ray, Yijin Wang, Russell D. Wolfinger, Nicholas G. Reich",http://arxiv.org/pdf/2407.19054v1,cs.LG
Rapid Likelihood Free Inference of Compact Binary Coalescences using Accelerated Hardware,"We report a gravitational-wave parameter estimation algorithm, AMPLFI, based
on likelihood-free inference using normalizing flows. The focus of AMPLFI is to
perform real-time parameter estimation for candidates detected by
machine-learning based compact binary coalescence search, Aframe. We present
details of our algorithm and optimizations done related to data-loading and
pre-processing on accelerated hardware. We train our model using binary
black-hole (BBH) simulations on real LIGO-Virgo detector noise. Our model has
$\sim 6$ million trainable parameters with training times $\lesssim 24$ hours.
Based on online deployment on a mock data stream of LIGO-Virgo data, Aframe +
AMPLFI is able to pick up BBH candidates and infer parameters for real-time
alerts from data acquisition with a net latency of $\sim 6$s.",2024-07-26,"Deep Chatterjee, Ethan Marx, William Benoit, Ravi Kumar, Malina Desai, Ekaterina Govorkova, Alec Gunny, Eric Moreno, Rafia Omer, Ryan Raikman, Muhammed Saleem, Shrey Aggarwal, Michael W. Coughlin, Philip Harris, Erik Katsavounidis",http://arxiv.org/pdf/2407.19048v1,cs.LG
Advancing Neural Network Performance through Emergence-Promoting Initialization Scheme,"Emergence in machine learning refers to the spontaneous appearance of complex
behaviors or capabilities that arise from the scale and structure of training
data and model architectures, despite not being explicitly programmed. We
introduce a novel yet straightforward neural network initialization scheme that
aims at achieving greater potential for emergence. Measuring emergence as a
kind of structural nonlinearity, our method adjusts the layer-wise weight
scaling factors to achieve higher emergence values. This enhancement is easy to
implement, requiring no additional optimization steps for initialization
compared to GradInit. We evaluate our approach across various architectures,
including MLP and convolutional architectures for image recognition and
transformers for machine translation. We demonstrate substantial improvements
in both model accuracy and training speed, with and without batch
normalization. The simplicity, theoretical innovation, and demonstrable
empirical advantages of our method make it a potent enhancement to neural
network initialization practices. These results suggest a promising direction
for leveraging emergence to improve neural network training methodologies. Code
is available at: https://github.com/johnnyjingzeli/EmergenceInit.",2024-07-26,"Johnny Jingze Li, Vivek Kurien George, Gabriel A. Silva",http://arxiv.org/pdf/2407.19044v3,cs.LG
GraphBPE: Molecular Graphs Meet Byte-Pair Encoding,"With the increasing attention to molecular machine learning, various
innovations have been made in designing better models or proposing more
comprehensive benchmarks. However, less is studied on the data preprocessing
schedule for molecular graphs, where a different view of the molecular graph
could potentially boost the model's performance. Inspired by the Byte-Pair
Encoding (BPE) algorithm, a subword tokenization method popularly adopted in
Natural Language Processing, we propose GraphBPE, which tokenizes a molecular
graph into different substructures and acts as a preprocessing schedule
independent of the model architectures. Our experiments on 3 graph-level
classification and 3 graph-level regression datasets show that data
preprocessing could boost the performance of models for molecular graphs, and
GraphBPE is effective for small classification datasets and it performs on par
with other tokenization methods across different model architectures.",2024-07-26,"Yuchen Shen, Barnabás Póczos",http://arxiv.org/pdf/2407.19039v1,cs.LG
Artificial Neural Networks on Graded Vector Spaces,"This paper presents a transformative framework for artificial neural networks
over graded vector spaces, tailored to model hierarchical and structured data
in fields like algebraic geometry and physics. By exploiting the algebraic
properties of graded vector spaces, where features carry distinct weights, we
extend classical neural networks with graded neurons, layers, and activation
functions that preserve structural integrity. Grounded in group actions,
representation theory, and graded algebra, our approach combines theoretical
rigor with practical utility.
  We introduce graded neural architectures, loss functions prioritizing graded
components, and equivariant extensions adaptable to diverse gradings. Case
studies validate the framework's effectiveness, outperforming standard neural
networks in tasks such as predicting invariants in weighted projective spaces
and modeling supersymmetric systems.
  This work establishes a new frontier in machine learning, merging
mathematical sophistication with interdisciplinary applications. Future
challenges, including computational scalability and finite field extensions,
offer rich opportunities for advancing this paradigm.",2024-07-26,Tony Shaska,http://arxiv.org/pdf/2407.19031v2,cs.LG
Supervised Learning based Method for Condition Monitoring of Overhead Line Insulators using Leakage Current Measurement,"As a new practical and economical solution to the aging problem of overhead
line (OHL) assets, the technical policies of most power grid companies in the
world experienced a gradual transition from scheduled preventive maintenance to
a risk-based approach in asset management. Even though the accumulation of
contamination is predictable within a certain degree, there are currently no
effective ways to identify the risk of the insulator flashover in order to plan
its replacement. This paper presents a novel machine learning (ML) based method
for estimating the flashover probability of the cup-and-pin glass insulator
string. The proposed method is based on the Extreme Gradient Boosting (XGBoost)
supervised ML model, in which the leakage current (LC) features and applied
voltage are used as the inputs. The established model can estimate the critical
flashover voltage (U50%) for various designs of OHL insulators with different
voltage levels. The proposed method is also able to accurately determine the
condition of the insulator strings and instruct asset management engineers to
take appropriate actions.",2024-07-26,"Mile Mitrovic, Dmitry Titov, Klim Volkhov, Irina Lukicheva, Andrey Kudryavzev, Petr Vorobev, Qi Li, Vladimir Terzija",http://arxiv.org/pdf/2407.20288v1,cs.LG
SOAP-RL: Sequential Option Advantage Propagation for Reinforcement Learning in POMDP Environments,"This work compares ways of extending Reinforcement Learning algorithms to
Partially Observed Markov Decision Processes (POMDPs) with options. One view of
options is as temporally extended action, which can be realized as a memory
that allows the agent to retain historical information beyond the policy's
context window. While option assignment could be handled using heuristics and
hand-crafted objectives, learning temporally consistent options and associated
sub-policies without explicit supervision is a challenge. Two algorithms, PPOEM
and SOAP, are proposed and studied in depth to address this problem. PPOEM
applies the forward-backward algorithm (for Hidden Markov Models) to optimize
the expected returns for an option-augmented policy. However, this learning
approach is unstable during on-policy rollouts. It is also unsuited for
learning causal policies without the knowledge of future trajectories, since
option assignments are optimized for offline sequences where the entire episode
is available. As an alternative approach, SOAP evaluates the policy gradient
for an optimal option assignment. It extends the concept of the generalized
advantage estimation (GAE) to propagate option advantages through time, which
is an analytical equivalent to performing temporal back-propagation of option
policy gradients. This option policy is only conditional on the history of the
agent, not future actions. Evaluated against competing baselines, SOAP
exhibited the most robust performance, correctly discovering options for POMDP
corridor environments, as well as on standard benchmarks including Atari and
MuJoCo, outperforming PPOEM, as well as LSTM and Option-Critic baselines. The
open-sourced code is available at https://github.com/shuishida/SoapRL.",2024-07-26,"Shu Ishida, João F. Henriques",http://arxiv.org/pdf/2407.18913v2,cs.LG
Do We Really Need Graph Convolution During Training? Light Post-Training Graph-ODE for Efficient Recommendation,"The efficiency and scalability of graph convolution networks (GCNs) in
training recommender systems (RecSys) have been persistent concerns, hindering
their deployment in real-world applications. This paper presents a critical
examination of the necessity of graph convolutions during the training phase
and introduces an innovative alternative: the Light Post-Training Graph
Ordinary-Differential-Equation (LightGODE). Our investigation reveals that the
benefits of GCNs are more pronounced during testing rather than training.
Motivated by this, LightGODE utilizes a novel post-training graph convolution
method that bypasses the computation-intensive message passing of GCNs and
employs a non-parametric continuous graph ordinary-differential-equation (ODE)
to dynamically model node representations. This approach drastically reduces
training time while achieving fine-grained post-training graph convolution to
avoid the distortion of the original training embedding space, termed the
embedding discrepancy issue. We validate our model across several real-world
datasets of different scales, demonstrating that LightGODE not only outperforms
GCN-based models in terms of efficiency and effectiveness but also
significantly mitigates the embedding discrepancy commonly associated with
deeper graph convolution layers. Our LightGODE challenges the prevailing
paradigms in RecSys training and suggests re-evaluating the role of graph
convolutions, potentially guiding future developments of efficient large-scale
graph-based RecSys.",2024-07-26,"Weizhi Zhang, Liangwei Yang, Zihe Song, Henry Peng Zou, Ke Xu, Liancheng Fang, Philip S. Yu",http://arxiv.org/pdf/2407.18910v2,cs.LG
Hybrid summary statistics: neural weak lensing inference beyond the power spectrum,"In inference problems, we often have domain knowledge which allows us to
define summary statistics that capture most of the information content in a
dataset. In this paper, we present a hybrid approach, where such physics-based
summaries are augmented by a set of compressed neural summary statistics that
are optimised to extract the extra information that is not captured by the
predefined summaries. The resulting statistics are very powerful inputs to
simulation-based or implicit inference of model parameters. We apply this
generalisation of Information Maximising Neural Networks (IMNNs) to parameter
constraints from tomographic weak gravitational lensing convergence maps to
find summary statistics that are explicitly optimised to complement angular
power spectrum estimates. We study several dark matter simulation resolutions
in low- and high-noise regimes. We show that i) the information-update
formalism extracts at least $3\times$ and up to $8\times$ as much information
as the angular power spectrum in all noise regimes, ii) the network summaries
are highly complementary to existing 2-point summaries, and iii) our formalism
allows for networks with smaller, physically-informed architectures to match
much larger regression networks with far fewer simulations needed to obtain
asymptotically optimal inference.",2024-07-26,"T. Lucas Makinen, Alan Heavens, Natalia Porqueres, Tom Charnock, Axel Lapel, Benjamin D. Wandelt",http://arxiv.org/pdf/2407.18909v1,cs.LG
Wolf: Dense Video Captioning with a World Summarization Framework,"We propose Wolf, a WOrLd summarization Framework for accurate video
captioning. Wolf is an automated captioning framework that adopts a
mixture-of-experts approach, leveraging complementary strengths of Vision
Language Models (VLMs). By utilizing both image and video models, our framework
captures different levels of information and summarizes them efficiently. Our
approach can be applied to enhance video understanding, auto-labeling, and
captioning. To evaluate caption quality, we introduce CapScore, an LLM-based
metric to assess the similarity and quality of generated captions compared to
the ground truth captions. We further build four human-annotated datasets in
three domains: autonomous driving, general scenes, and robotics, to facilitate
comprehensive comparisons. We show that Wolf achieves superior captioning
performance compared to state-of-the-art approaches from the research community
(VILA1.5, CogAgent) and commercial solutions (Gemini-Pro-1.5, GPT-4V). For
instance, in comparison with GPT-4V, Wolf improves CapScore both quality-wise
by 55.6% and similarity-wise by 77.4% on challenging driving videos. Finally,
we establish a benchmark for video captioning and introduce a leaderboard,
aiming to accelerate advancements in video understanding, captioning, and data
alignment. Webpage: https://wolfv0.github.io/.",2024-07-26,"Boyi Li, Ligeng Zhu, Ran Tian, Shuhan Tan, Yuxiao Chen, Yao Lu, Yin Cui, Sushant Veer, Max Ehrlich, Jonah Philion, Xinshuo Weng, Fuzhao Xue, Linxi Fan, Yuke Zhu, Jan Kautz, Andrew Tao, Ming-Yu Liu, Sanja Fidler, Boris Ivanovic, Trevor Darrell, Jitendra Malik, Song Han, Marco Pavone",http://arxiv.org/pdf/2407.18908v2,cs.LG
A Scalable Quantum Non-local Neural Network for Image Classification,"Non-local operations play a crucial role in computer vision enabling the
capture of long-range dependencies through weighted sums of features across the
input, surpassing the constraints of traditional convolution operations that
focus solely on local neighborhoods. Non-local operations typically require
computing pairwise relationships between all elements in a set, leading to
quadratic complexity in terms of time and memory. Due to the high computational
and memory demands, scaling non-local neural networks to large-scale problems
can be challenging. This article introduces a hybrid quantum-classical scalable
non-local neural network, referred to as Quantum Non-Local Neural Network
(QNL-Net), to enhance pattern recognition. The proposed QNL-Net relies on
inherent quantum parallelism to allow the simultaneous processing of a large
number of input features enabling more efficient computations in
quantum-enhanced feature space and involving pairwise relationships through
quantum entanglement. We benchmark our proposed QNL-Net with other quantum
counterparts to binary classification with datasets MNIST and CIFAR-10. The
simulation findings showcase our QNL-Net achieves cutting-edge accuracy levels
in binary image classification among quantum classifiers while utilizing fewer
qubits.",2024-07-26,"Sparsh Gupta, Debanjan Konar, Vaneet Aggarwal",http://arxiv.org/pdf/2407.18906v2,cs.LG
"Lessons from Learning to Spin ""Pens""","In-hand manipulation of pen-like objects is an important skill in our daily
lives, as many tools such as hammers and screwdrivers are similarly shaped.
However, current learning-based methods struggle with this task due to a lack
of high-quality demonstrations and the significant gap between simulation and
the real world. In this work, we push the boundaries of learning-based in-hand
manipulation systems by demonstrating the capability to spin pen-like objects.
We first use reinforcement learning to train an oracle policy with privileged
information and generate a high-fidelity trajectory dataset in simulation. This
serves two purposes: 1) pre-training a sensorimotor policy in simulation; 2)
conducting open-loop trajectory replay in the real world. We then fine-tune the
sensorimotor policy using these real-world trajectories to adapt it to the real
world dynamics. With less than 50 trajectories, our policy learns to rotate
more than ten pen-like objects with different physical properties for multiple
revolutions. We present a comprehensive analysis of our design choices and
share the lessons learned during development.",2024-07-26,"Jun Wang, Ying Yuan, Haichuan Che, Haozhi Qi, Yi Ma, Jitendra Malik, Xiaolong Wang",http://arxiv.org/pdf/2407.18902v2,cs.LG
AppWorld: A Controllable World of Apps and People for Benchmarking Interactive Coding Agents,"Autonomous agents that address day-to-day digital tasks (e.g., ordering
groceries for a household), must not only operate multiple apps (e.g., notes,
messaging, shopping app) via APIs, but also generate rich code with complex
control flow in an iterative manner based on their interaction with the
environment. However, existing benchmarks for tool use are inadequate, as they
only cover tasks that require a simple sequence of API calls.
  To remedy this gap, we built $\textbf{AppWorld Engine}$, a high-quality
execution environment (60K lines of code) of 9 day-to-day apps operable via 457
APIs and populated with realistic digital activities simulating the lives of
~100 fictitious users. We then created $\textbf{AppWorld Benchmark}$ (40K lines
of code), a suite of 750 natural, diverse, and challenging autonomous agent
tasks requiring rich and interactive code generation. It supports robust
programmatic evaluation with state-based unit tests, allowing for different
ways of completing a task while also checking for unexpected changes, i.e.,
collateral damage. The state-of-the-art LLM, GPT-4o, solves only ~49% of our
'normal' tasks and ~30% of 'challenge' tasks, while other models solve at least
16% fewer. This highlights the benchmark's difficulty and AppWorld's potential
to push the frontiers of interactive coding agents. The project website is
available at https://appworld.dev/.",2024-07-26,"Harsh Trivedi, Tushar Khot, Mareike Hartmann, Ruskin Manku, Vinty Dong, Edward Li, Shashank Gupta, Ashish Sabharwal, Niranjan Balasubramanian",http://arxiv.org/pdf/2407.18901v1,cs.LG
Reinforcement learning for anisotropic p-adaptation and error estimation in high-order solvers,"We present a novel approach to automate and optimize anisotropic p-adaptation
in high-order h/p solvers using Reinforcement Learning (RL). The dynamic RL
adaptation uses the evolving solution to adjust the high-order polynomials. We
develop an offline training approach, decoupled from the main solver, which
shows minimal overcost when performing simulations. In addition, we derive an
inexpensive RL-based error estimation approach that enables the quantification
of local discretization errors. The proposed methodology is agnostic to both
the computational mesh and the partial differential equation to be solved.
  The application of RL to mesh adaptation offers several benefits. It enables
automated and adaptive mesh refinement, reducing the need for manual
intervention. It optimizes computational resources by dynamically allocating
high-order polynomials where necessary and minimizing refinement in stable
regions. This leads to computational cost savings while maintaining the
accuracy of the solution. Furthermore, RL allows for the exploration of
unconventional mesh adaptations, potentially enhancing the accuracy and
robustness of simulations. This work extends our original research, offering a
more robust, reproducible, and generalizable approach applicable to complex
three-dimensional problems. We provide validation for laminar and turbulent
cases: circular cylinders, Taylor Green Vortex and a 10MW wind turbine to
illustrate the flexibility of the proposed approach.",2024-07-26,"David Huergo, Martín de Frutos, Eduardo Jané, Oscar A. Marino, Gonzalo Rubio, Esteban Ferrer",http://arxiv.org/pdf/2407.19000v2,cs.LG
Learn from the Learnt: Source-Free Active Domain Adaptation via Contrastive Sampling and Visual Persistence,"Domain Adaptation (DA) facilitates knowledge transfer from a source domain to
a related target domain. This paper investigates a practical DA paradigm,
namely Source data-Free Active Domain Adaptation (SFADA), where source data
becomes inaccessible during adaptation, and a minimum amount of annotation
budget is available in the target domain. Without referencing the source data,
new challenges emerge in identifying the most informative target samples for
labeling, establishing cross-domain alignment during adaptation, and ensuring
continuous performance improvements through the iterative query-and-adaptation
process. In response, we present learn from the learnt (LFTL), a novel paradigm
for SFADA to leverage the learnt knowledge from the source pretrained model and
actively iterated models without extra overhead. We propose Contrastive Active
Sampling to learn from the hypotheses of the preceding model, thereby querying
target samples that are both informative to the current model and persistently
challenging throughout active learning. During adaptation, we learn from
features of actively selected anchors obtained from previous intermediate
models, so that the Visual Persistence-guided Adaptation can facilitate feature
distribution alignment and active sample exploitation. Extensive experiments on
three widely-used benchmarks show that our LFTL achieves state-of-the-art
performance, superior computational efficiency and continuous improvements as
the annotation budget increases. Our code is available at
https://github.com/lyumengyao/lftl.",2024-07-26,"Mengyao Lyu, Tianxiang Hao, Xinhao Xu, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding",http://arxiv.org/pdf/2407.18899v1,cs.LG
Small Molecule Optimization with Large Language Models,"Recent advancements in large language models have opened new possibilities
for generative molecular drug design. We present Chemlactica and Chemma, two
language models fine-tuned on a novel corpus of 110M molecules with computed
properties, totaling 40B tokens. These models demonstrate strong performance in
generating molecules with specified properties and predicting new molecular
characteristics from limited samples. We introduce a novel optimization
algorithm that leverages our language models to optimize molecules for
arbitrary properties given limited access to a black box oracle. Our approach
combines ideas from genetic algorithms, rejection sampling, and prompt
optimization. It achieves state-of-the-art performance on multiple molecular
optimization benchmarks, including an 8% improvement on Practical Molecular
Optimization compared to previous methods. We publicly release the training
corpus, the language models and the optimization algorithm.",2024-07-26,"Philipp Guevorguian, Menua Bedrosian, Tigran Fahradyan, Gayane Chilingaryan, Hrant Khachatrian, Armen Aghajanyan",http://arxiv.org/pdf/2407.18897v1,cs.LG
On the Pros and Cons of Active Learning for Moral Preference Elicitation,"Computational preference elicitation methods are tools used to learn people's
preferences quantitatively in a given context. Recent works on preference
elicitation advocate for active learning as an efficient method to iteratively
construct queries (framed as comparisons between context-specific cases) that
are likely to be most informative about an agent's underlying preferences. In
this work, we argue that the use of active learning for moral preference
elicitation relies on certain assumptions about the underlying moral
preferences, which can be violated in practice. Specifically, we highlight the
following common assumptions (a) preferences are stable over time and not
sensitive to the sequence of presented queries, (b) the appropriate hypothesis
class is chosen to model moral preferences, and (c) noise in the agent's
responses is limited. While these assumptions can be appropriate for preference
elicitation in certain domains, prior research on moral psychology suggests
they may not be valid for moral judgments. Through a synthetic simulation of
preferences that violate the above assumptions, we observe that active learning
can have similar or worse performance than a basic random query selection
method in certain settings. Yet, simulation results also demonstrate that
active learning can still be viable if the degree of instability or noise is
relatively small and when the agent's preferences can be approximately
represented with the hypothesis class used for learning. Our study highlights
the nuances associated with effective moral preference elicitation in practice
and advocates for the cautious use of active learning as a methodology to learn
moral preferences.",2024-07-26,"Vijay Keswani, Vincent Conitzer, Hoda Heidari, Jana Schaich Borg, Walter Sinnott-Armstrong",http://arxiv.org/pdf/2407.18889v1,cs.LG
Embedding And Clustering Your Data Can Improve Contrastive Pretraining,"Recent studies of large-scale contrastive pretraining in the text embedding
domain show that using single-source minibatches, rather than mixed-source
minibatches, can substantially improve overall model accuracy. In this work, we
explore extending training data stratification beyond source granularity by
leveraging a pretrained text embedding model and the classic k-means clustering
algorithm to further split training data apart by the semantic clusters within
each source. Experimentally, we observe a notable increase in NDCG@10 when
pretraining a BERT-based text embedding model on query-passage pairs from the
MSMARCO passage retrieval dataset. Additionally, we conceptually connect our
clustering approach to both the Topic Aware Sampling (TAS) aspect of the TAS-B
methodology and the nearest-neighbor-based hard-negative mining aspect of the
ANCE methodology and discuss how this unified view motivates future lines of
research on the organization of contrastive pretraining data.",2024-07-26,Luke Merrick,http://arxiv.org/pdf/2407.18887v1,cs.LG
Utilizing TTS Synthesized Data for Efficient Development of Keyword Spotting Model,"This paper explores the use of TTS synthesized training data for KWS (keyword
spotting) task while minimizing development cost and time. Keyword spotting
models require a huge amount of training data to be accurate, and obtaining
such training data can be costly. In the current state of the art, TTS models
can generate large amounts of natural-sounding data, which can help reducing
cost and time for KWS model development. Still, TTS generated data can be
lacking diversity compared to real data. To pursue maximizing KWS model
accuracy under the constraint of limited resources and current TTS capability,
we explored various strategies to mix TTS data and real human speech data, with
a focus on minimizing real data use and maximizing diversity of TTS output. Our
experimental results indicate that relatively small amounts of real audio data
with speaker diversity (100 speakers, 2k utterances) and large amounts of TTS
synthesized data can achieve reasonably high accuracy (within 3x error rate of
baseline), compared to the baseline (trained with 3.8M real positive
utterances).",2024-07-26,"Hyun Jin Park, Dhruuv Agarwal, Neng Chen, Rentao Sun, Kurt Partridge, Justin Chen, Harry Zhang, Pai Zhu, Jacob Bartel, Kyle Kastner, Gary Wang, Andrew Rosenberg, Quan Wang",http://arxiv.org/pdf/2407.18879v1,cs.LG
A Sharper Global Convergence Analysis for Average Reward Reinforcement Learning via an Actor-Critic Approach,"This work examines average-reward reinforcement learning with general policy
parametrization. Existing state-of-the-art (SOTA) guarantees for this problem
are either suboptimal or hindered by several challenges, including poor
scalability with respect to the size of the state-action space, high iteration
complexity, and dependence on knowledge of mixing times and hitting times. To
address these limitations, we propose a Multi-level Monte Carlo-based Natural
Actor-Critic (MLMC-NAC) algorithm. Our work is the first to achieve a global
convergence rate of $\tilde{\mathcal{O}}(1/\sqrt{T})$ for average-reward Markov
Decision Processes (MDPs) (where $T$ is the horizon length), without requiring
the knowledge of mixing and hitting times. Moreover, the convergence rate does
not scale with the size of the state space, therefore even being applicable to
infinite state spaces.",2024-07-26,"Swetha Ganesh, Washim Uddin Mondal, Vaneet Aggarwal",http://arxiv.org/pdf/2407.18878v3,cs.LG
Generative Adversarial Networks for Imputing Sparse Learning Performance,"Learning performance data, such as correct or incorrect responses to
questions in Intelligent Tutoring Systems (ITSs) is crucial for tracking and
assessing the learners' progress and mastery of knowledge. However, the issue
of data sparsity, characterized by unexplored questions and missing attempts,
hampers accurate assessment and the provision of tailored, personalized
instruction within ITSs. This paper proposes using the Generative Adversarial
Imputation Networks (GAIN) framework to impute sparse learning performance
data, reconstructed into a three-dimensional (3D) tensor representation across
the dimensions of learners, questions and attempts. Our customized GAIN-based
method computational process imputes sparse data in a 3D tensor space,
significantly enhanced by convolutional neural networks for its input and
output layers. This adaptation also includes the use of a least squares loss
function for optimization and aligns the shapes of the input and output with
the dimensions of the questions-attempts matrices along the learners'
dimension. Through extensive experiments on six datasets from various ITSs,
including AutoTutor, ASSISTments and MATHia, we demonstrate that the GAIN
approach generally outperforms existing methods such as tensor factorization
and other generative adversarial network (GAN) based approaches in terms of
imputation accuracy. This finding enhances comprehensive learning data modeling
and analytics in AI-based education.",2024-07-26,"Liang Zhang, Mohammed Yeasin, Jionghao Lin, Felix Havugimana, Xiangen Hu",http://arxiv.org/pdf/2407.18875v2,cs.LG
Downlink Channel Covariance Matrix Estimation via Representation Learning with Graph Regularization,"In this paper, we propose an algorithm for downlink (DL) channel covariance
matrix (CCM) estimation for frequency division duplexing (FDD) massive
multiple-input multiple-output (MIMO) communication systems with base station
(BS) possessing a uniform linear array (ULA) antenna structure. We consider a
setting where the UL CCM is mapped to DL CCM by a mapping function. We first
present a theoretical error analysis of learning a nonlinear embedding by
constructing a mapping function, which points to the importance of the
Lipschitz regularity of the mapping function for achieving high estimation
performance. Then, based on the theoretical ground, we propose a representation
learning algorithm as a solution for the estimation problem, where Gaussian RBF
kernel interpolators are chosen to map UL CCMs to their DL counterparts. The
proposed algorithm is based on the optimization of an objective function that
fits a regression model between the DL CCM and UL CCM samples in the training
dataset and preserves the local geometric structure of the data in the UL CCM
space, while explicitly regulating the Lipschitz continuity of the mapping
function in light of our theoretical findings. The proposed algorithm surpasses
benchmark methods in terms of three error metrics as shown by simulations.",2024-07-26,"Melih Can Zerin, Elif Vural, Ali Özgür Yılmaz",http://arxiv.org/pdf/2407.18865v4,cs.LG
Enhancing material property prediction with ensemble deep graph convolutional networks,"Machine learning (ML) models have emerged as powerful tools for accelerating
materials discovery and design by enabling accurate predictions of properties
from compositional and structural data. These capabilities are vital for
developing advanced technologies across fields such as energy, electronics, and
biomedicine, potentially reducing the time and resources needed for new
material exploration and promoting rapid innovation cycles. Recent efforts have
focused on employing advanced ML algorithms, including deep learning - based
graph neural network, for property prediction. Additionally, ensemble models
have proven to enhance the generalizability and robustness of ML and DL.
However, the use of such ensemble strategies in deep graph networks for
material property prediction remains underexplored. Our research provides an
in-depth evaluation of ensemble strategies in deep learning - based graph
neural network, specifically targeting material property prediction tasks. By
testing the Crystal Graph Convolutional Neural Network (CGCNN) and its
multitask version, MT-CGCNN, we demonstrated that ensemble techniques,
especially prediction averaging, substantially improve precision beyond
traditional metrics for key properties like formation energy per atom ($\Delta
E^{f}$), band gap ($E_{g}$) and density ($\rho$) in 33,990 stable inorganic
materials. These findings support the broader application of ensemble methods
to enhance predictive accuracy in the field.",2024-07-26,"Chowdhury Mohammad Abid Rahman, Ghadendra Bhandari, Nasser M Nasrabadi, Aldo H. Romero, Prashnna K. Gyawali",http://arxiv.org/pdf/2407.18847v1,cs.LG
QT-TDM: Planning With Transformer Dynamics Model and Autoregressive Q-Learning,"Inspired by the success of the Transformer architecture in natural language
processing and computer vision, we investigate the use of Transformers in
Reinforcement Learning (RL), specifically in modeling the environment's
dynamics using Transformer Dynamics Models (TDMs). We evaluate the capabilities
of TDMs for continuous control in real-time planning scenarios with Model
Predictive Control (MPC). While Transformers excel in long-horizon prediction,
their tokenization mechanism and autoregressive nature lead to costly planning
over long horizons, especially as the environment's dimensionality increases.
To alleviate this issue, we use a TDM for short-term planning, and learn an
autoregressive discrete Q-function using a separate Q-Transformer (QT) model to
estimate a long-term return beyond the short-horizon planning. Our proposed
method, QT-TDM, integrates the robust predictive capabilities of Transformers
as dynamics models with the efficacy of a model-free Q-Transformer to mitigate
the computational burden associated with real-time planning. Experiments in
diverse state-based continuous control tasks show that QT-TDM is superior in
performance and sample efficiency compared to existing Transformer-based RL
models while achieving fast and computationally efficient inference.",2024-07-26,"Mostafa Kotb, Cornelius Weber, Muhammad Burhan Hafez, Stefan Wermter",http://arxiv.org/pdf/2407.18841v2,cs.LG
The Cross-environment Hyperparameter Setting Benchmark for Reinforcement Learning,"This paper introduces a new empirical methodology, the Cross-environment
Hyperparameter Setting Benchmark, that compares RL algorithms across
environments using a single hyperparameter setting, encouraging algorithmic
development which is insensitive to hyperparameters. We demonstrate that this
benchmark is robust to statistical noise and obtains qualitatively similar
results across repeated applications, even when using few samples. This
robustness makes the benchmark computationally cheap to apply, allowing
statistically sound insights at low cost. We demonstrate two example
instantiations of the CHS, on a set of six small control environments (SC-CHS)
and on the entire DM Control suite of 28 environments (DMC-CHS). Finally, to
illustrate the applicability of the CHS to modern RL algorithms on challenging
environments, we conduct a novel empirical study of an open question in the
continuous control literature. We show, with high confidence, that there is no
meaningful difference in performance between Ornstein-Uhlenbeck noise and
uncorrelated Gaussian noise for exploration with the DDPG algorithm on the
DMC-CHS.",2024-07-26,"Andrew Patterson, Samuel Neumann, Raksha Kumaraswamy, Martha White, Adam White",http://arxiv.org/pdf/2407.18840v1,cs.LG
The Role of Temporal Hierarchy in Spiking Neural Networks,"Spiking Neural Networks (SNNs) have the potential for rich spatio-temporal
signal processing thanks to exploiting both spatial and temporal parameters.
The temporal dynamics such as time constants of the synapses and neurons and
delays have been recently shown to have computational benefits that help reduce
the overall number of parameters required in the network and increase the
accuracy of the SNNs in solving temporal tasks. Optimizing such temporal
parameters, for example, through gradient descent, gives rise to a temporal
architecture for different problems. As has been shown in machine learning, to
reduce the cost of optimization, architectural biases can be applied, in this
case in the temporal domain. Such inductive biases in temporal parameters have
been found in neuroscience studies, highlighting a hierarchy of temporal
structure and input representation in different layers of the cortex. Motivated
by this, we propose to impose a hierarchy of temporal representation in the
hidden layers of SNNs, highlighting that such an inductive bias improves their
performance. We demonstrate the positive effects of temporal hierarchy in the
time constants of feed-forward SNNs applied to temporal tasks (Multi-Time-Scale
XOR and Keyword Spotting, with a benefit of up to 4.1% in classification
accuracy). Moreover, we show that such architectural biases, i.e. hierarchy of
time constants, naturally emerge when optimizing the time constants through
gradient descent, initialized as homogeneous values. We further pursue this
proposal in temporal convolutional SNNs, by introducing the hierarchical bias
in the size and dilation of temporal kernels, giving rise to competitive
results in popular temporal spike-based datasets.",2024-07-26,"Filippo Moro, Pau Vilimelis Aceituno, Laura Kriener, Melika Payvand",http://arxiv.org/pdf/2407.18838v1,cs.LG
Graph-based Unsupervised Disentangled Representation Learning via Multimodal Large Language Models,"Disentangled representation learning (DRL) aims to identify and decompose
underlying factors behind observations, thus facilitating data perception and
generation. However, current DRL approaches often rely on the unrealistic
assumption that semantic factors are statistically independent. In reality,
these factors may exhibit correlations, which off-the-shelf solutions have yet
to properly address. To tackle this challenge, we introduce a bidirectional
weighted graph-based framework, to learn factorized attributes and their
interrelations within complex data. Specifically, we propose a $\beta$-VAE
based module to extract factors as the initial nodes of the graph, and leverage
the multimodal large language model (MLLM) to discover and rank latent
correlations, thereby updating the weighted edges. By integrating these
complementary modules, our model successfully achieves fine-grained, practical
and unsupervised disentanglement. Experiments demonstrate our method's superior
performance in disentanglement and reconstruction. Furthermore, the model
inherits enhanced interpretability and generalizability from MLLMs.",2024-07-26,"Baao Xie, Qiuyu Chen, Yunnan Wang, Zequn Zhang, Xin Jin, Wenjun Zeng",http://arxiv.org/pdf/2407.18999v1,cs.LG
Deep Companion Learning: Enhancing Generalization Through Historical Consistency,"We propose Deep Companion Learning (DCL), a novel training method for Deep
Neural Networks (DNNs) that enhances generalization by penalizing inconsistent
model predictions compared to its historical performance. To achieve this, we
train a deep-companion model (DCM), by using previous versions of the model to
provide forecasts on new inputs. This companion model deciphers a meaningful
latent semantic structure within the data, thereby providing targeted
supervision that encourages the primary model to address the scenarios it finds
most challenging. We validate our approach through both theoretical analysis
and extensive experimentation, including ablation studies, on a variety of
benchmark datasets (CIFAR-100, Tiny-ImageNet, ImageNet-1K) using diverse
architectural models (ShuffleNetV2, ResNet, Vision Transformer, etc.),
demonstrating state-of-the-art performance.",2024-07-26,"Ruizhao Zhu, Venkatesh Saligrama",http://arxiv.org/pdf/2407.18821v1,cs.LG
Blockchain for Large Language Model Security and Safety: A Holistic Survey,"With the growing development and deployment of large language models (LLMs)
in both industrial and academic fields, their security and safety concerns have
become increasingly critical. However, recent studies indicate that LLMs face
numerous vulnerabilities, including data poisoning, prompt injections, and
unauthorized data exposure, which conventional methods have struggled to
address fully. In parallel, blockchain technology, known for its data
immutability and decentralized structure, offers a promising foundation for
safeguarding LLMs. In this survey, we aim to comprehensively assess how to
leverage blockchain technology to enhance LLMs' security and safety. Besides,
we propose a new taxonomy of blockchain for large language models (BC4LLMs) to
systematically categorize related works in this emerging field. Our analysis
includes novel frameworks and definitions to delineate security and safety in
the context of BC4LLMs, highlighting potential research directions and
challenges at this intersection. Through this study, we aim to stimulate
targeted advancements in blockchain-integrated LLM security.",2024-07-26,"Caleb Geren, Amanda Board, Gaby G. Dagher, Tim Andersen, Jun Zhuang",http://arxiv.org/pdf/2407.20181v2,cs.LG
Online Planning in POMDPs with State-Requests,"In key real-world problems, full state information is sometimes available but
only at a high cost, like activating precise yet energy-intensive sensors or
consulting humans, thereby compelling the agent to operate under partial
observability. For this scenario, we propose AEMS-SR (Anytime Error
Minimization Search with State Requests), a principled online planning
algorithm tailored for POMDPs with state requests. By representing the search
space as a graph instead of a tree, AEMS-SR avoids the exponential growth of
the search space originating from state requests. Theoretical analysis
demonstrates AEMS-SR's $\varepsilon$-optimality, ensuring solution quality,
while empirical evaluations illustrate its effectiveness compared with AEMS and
POMCP, two SOTA online planning algorithms. AEMS-SR enables efficient planning
in domains characterized by partial observability and costly state requests
offering practical benefits across various applications.",2024-07-26,"Raphael Avalos, Eugenio Bargiacchi, Ann Nowé, Diederik M. Roijers, Frans A. Oliehoek",http://arxiv.org/pdf/2407.18812v1,cs.LG
Interpreting artificial neural networks to detect genome-wide association signals for complex traits,"Investigating the genetic architecture of complex diseases is challenging due
to the multifactorial and interactive landscape of genomic and environmental
influences. Although genome-wide association studies (GWAS) have identified
thousands of variants for multiple complex traits, conventional statistical
approaches can be limited by simplified assumptions such as linearity and lack
of epistasis in models. In this work, we trained artificial neural networks to
predict complex traits using both simulated and real genotype-phenotype
datasets. We extracted feature importance scores via different post hoc
interpretability methods to identify potentially associated loci (PAL) for the
target phenotype and devised an approach for obtaining p-values for the
detected PAL. Simulations with various parameters demonstrated that associated
loci can be detected with good precision using strict selection criteria. By
applying our approach to the schizophrenia cohort in the Estonian Biobank, we
detected multiple loci associated with this highly polygenic and heritable
disorder. There was significant concordance between PAL and loci previously
associated with schizophrenia and bipolar disorder, with enrichment analyses of
genes within the identified PAL predominantly highlighting terms related to
brain morphology and function. With advancements in model optimization and
uncertainty quantification, artificial neural networks have the potential to
enhance the identification of genomic loci associated with complex diseases,
offering a more comprehensive approach for GWAS and serving as initial
screening tools for subsequent functional studies.",2024-07-26,"Burak Yelmen, Maris Alver, Merve Nur Güler, Estonian Biobank Research Team, Flora Jay, Lili Milani",http://arxiv.org/pdf/2407.18811v2,cs.LG
Learning Chaotic Systems and Long-Term Predictions with Neural Jump ODEs,"The Path-dependent Neural Jump ODE (PD-NJ-ODE) is a model for online
prediction of generic (possibly non-Markovian) stochastic processes with
irregular (in time) and potentially incomplete (with respect to coordinates)
observations. It is a model for which convergence to the $L^2$-optimal
predictor, which is given by the conditional expectation, is established
theoretically. Thereby, the training of the model is solely based on a dataset
of realizations of the underlying stochastic process, without the need of
knowledge of the law of the process. In the case where the underlying process
is deterministic, the conditional expectation coincides with the process
itself. Therefore, this framework can equivalently be used to learn the
dynamics of ODE or PDE systems solely from realizations of the dynamical system
with different initial conditions. We showcase the potential of our method by
applying it to the chaotic system of a double pendulum. When training the
standard PD-NJ-ODE method, we see that the prediction starts to diverge from
the true path after about half of the evaluation time. In this work we enhance
the model with two novel ideas, which independently of each other improve the
performance of our modelling setup. The resulting dynamics match the true
dynamics of the chaotic system very closely. The same enhancements can be used
to provably enable the PD-NJ-ODE to learn long-term predictions for general
stochastic datasets, where the standard model fails. This is verified in
several experiments.",2024-07-26,"Florian Krach, Josef Teichmann",http://arxiv.org/pdf/2407.18808v1,cs.LG
When narrower is better: the narrow width limit of Bayesian parallel branching neural networks,"The infinite width limit of random neural networks is known to result in
Neural Networks as Gaussian Process (NNGP) (Lee et al. (2018)), characterized
by task-independent kernels. It is widely accepted that larger network widths
contribute to improved generalization (Park et al. (2019)). However, this work
challenges this notion by investigating the narrow width limit of the Bayesian
Parallel Branching Neural Network (BPB-NN), an architecture that resembles
neural networks with residual blocks. We demonstrate that when the width of a
BPB-NN is significantly smaller compared to the number of training examples,
each branch exhibits more robust learning due to a symmetry breaking of
branches in kernel renormalization. Surprisingly, the performance of a BPB-NN
in the narrow width limit is generally superior to or comparable to that
achieved in the wide width limit in bias-limited scenarios. Furthermore, the
readout norms of each branch in the narrow width limit are mostly independent
of the architectural hyperparameters but generally reflective of the nature of
the data. We demonstrate such phenomenon primarily in the branching graph
neural networks, where each branch represents a different order of convolutions
of the graph; we also extend the results to other more general architectures
such as the residual-MLP and demonstrate that the narrow width effect is a
general feature of the branching networks. Our results characterize a newly
defined narrow-width regime for parallel branching networks in general.",2024-07-26,"Zechen Zhang, Haim Sompolinsky",http://arxiv.org/pdf/2407.18807v3,cs.LG
Log-Concave Coupling for Sampling Neural Net Posteriors,"In this work, we present a sampling algorithm for single hidden layer neural
networks. This algorithm is built upon a recursive series of Bayesian
posteriors using a method we call Greedy Bayes. Sampling of the Bayesian
posterior for neuron weight vectors $w$ of dimension $d$ is challenging because
of its multimodality. Our algorithm to tackle this problem is based on a
coupling of the posterior density for $w$ with an auxiliary random variable
$\xi$.
  The resulting reverse conditional $w|\xi$ of neuron weights given auxiliary
random variable is shown to be log concave. In the construction of the
posterior distributions we provide some freedom in the choice of the prior. In
particular, for Gaussian priors on $w$ with suitably small variance, the
resulting marginal density of the auxiliary variable $\xi$ is proven to be
strictly log concave for all dimensions $d$. For a uniform prior on the unit
$\ell_1$ ball, evidence is given that the density of $\xi$ is again strictly
log concave for sufficiently large $d$.
  The score of the marginal density of the auxiliary random variable $\xi$ is
determined by an expectation over $w|\xi$ and thus can be computed by various
rapidly mixing Markov Chain Monte Carlo methods. Moreover, the computation of
the score of $\xi$ permits methods of sampling $\xi$ by a stochastic diffusion
(Langevin dynamics) with drift function built from this score. With such
dynamics, information-theoretic methods pioneered by Bakry and Emery show that
accurate sampling of $\xi$ is obtained rapidly when its density is indeed
strictly log-concave. After which, one more draw from $w|\xi$, produces neuron
weights $w$ whose marginal distribution is from the desired posterior.",2024-07-26,"Curtis McDonald, Andrew R Barron",http://arxiv.org/pdf/2407.18802v1,cs.LG
Benchmarking Dependence Measures to Prevent Shortcut Learning in Medical Imaging,"Medical imaging cohorts are often confounded by factors such as acquisition
devices, hospital sites, patient backgrounds, and many more. As a result, deep
learning models tend to learn spurious correlations instead of causally related
features, limiting their generalizability to new and unseen data. This problem
can be addressed by minimizing dependence measures between intermediate
representations of task-related and non-task-related variables. These measures
include mutual information, distance correlation, and the performance of
adversarial classifiers. Here, we benchmark such dependence measures for the
task of preventing shortcut learning. We study a simplified setting using
Morpho-MNIST and a medical imaging task with CheXpert chest radiographs. Our
results provide insights into how to mitigate confounding factors in medical
imaging.",2024-07-26,"Sarah Müller, Louisa Fay, Lisa M. Koch, Sergios Gatidis, Thomas Küstner, Philipp Berens",http://arxiv.org/pdf/2407.18792v2,cs.LG
Learning production functions for supply chains with graph neural networks,"The global economy relies on the flow of goods over supply chain networks,
with nodes as firms and edges as transactions between firms. While we may
observe these external transactions, they are governed by unseen production
functions, which determine how firms internally transform the input products
they receive into output products that they sell. In this setting, it can be
extremely valuable to infer these production functions, to improve supply chain
visibility and to forecast future transactions more accurately. However,
existing graph neural networks (GNNs) cannot capture these hidden relationships
between nodes' inputs and outputs. Here, we introduce a new class of models for
this setting by combining temporal GNNs with a novel inventory module, which
learns production functions via attention weights and a special loss function.
We evaluate our models extensively on real supply chains data and data
generated from our new open-source simulator, SupplySim. Our models
successfully infer production functions, outperforming the strongest baseline
by 6%-50% (across datasets), and forecast future transactions, outperforming
the strongest baseline by 11%-62%",2024-07-26,"Serina Chang, Zhiyin Lin, Benjamin Yan, Swapnil Bembde, Qi Xiu, Chi Heem Wong, Yu Qin, Frank Kloster, Alex Luo, Raj Palleti, Jure Leskovec",http://arxiv.org/pdf/2407.18772v3,cs.LG
Unsupervised Reservoir Computing for Multivariate Denoising of Severely Contaminated Signals,"The interdependence and high dimensionality of multivariate signals present
significant challenges for denoising, as conventional univariate methods often
struggle to capture the complex interactions between variables. A successful
approach must consider not only the multivariate dependencies of the desired
signal but also the multivariate dependencies of the interfering noise. In our
previous research, we introduced a method using machine learning to extract the
maximum portion of ``predictable information"" from univariate signal. We extend
this approach to multivariate signals, with the key idea being to properly
incorporate the interdependencies of the noise back into the interdependent
reconstruction of the signal. The method works successfully for various
multivariate signals, including chaotic signals and highly oscillating
sinusoidal signals which are corrupted by spatially correlated intensive noise.
It consistently outperforms other existing multivariate denoising methods
across a wide range of scenarios.",2024-07-26,"Jaesung Choi, Pilwon Kim",http://arxiv.org/pdf/2407.18759v1,cs.LG
FLUE: Federated Learning with Un-Encrypted model weights,"Federated Learning enables diverse devices to collaboratively train a shared
model while keeping training data locally stored, avoiding the need for
centralized cloud storage. Despite existing privacy measures, concerns arise
from potential reverse engineering of gradients, even with added noise,
revealing private data. To address this, recent research emphasizes using
encrypted model parameters during training. This paper introduces a novel
federated learning algorithm, leveraging coded local gradients without
encryption, exchanging coded proxies for model parameters, and injecting
surplus noise for enhanced privacy. Two algorithm variants are presented,
showcasing convergence and learning rates adaptable to coding schemes and raw
data characteristics. Two encryption-free implementations with fixed and random
coding matrices are provided, demonstrating promising simulation results from
both federated optimization and machine learning perspectives.",2024-07-26,Elie Atallah,http://arxiv.org/pdf/2407.18750v1,cs.LG
"FairAIED: Navigating Fairness, Bias, and Ethics in Educational AI Applications","The integration of Artificial Intelligence (AI) into education has
transformative potential, providing tailored learning experiences and creative
instructional approaches. However, the inherent biases in AI algorithms hinder
this improvement by unintentionally perpetuating prejudice against specific
demographics, especially in human-centered applications like education. This
survey delves deeply into the developing topic of algorithmic fairness in
educational contexts, providing a comprehensive evaluation of the diverse
literature on fairness, bias, and ethics in AI-driven educational applications.
It identifies the common forms of biases, such as data-related, algorithmic,
and user-interaction, that fundamentally undermine the accomplishment of
fairness in AI teaching aids. By outlining existing techniques for mitigating
these biases, ranging from varied data gathering to algorithmic fairness
interventions, the survey emphasizes the critical role of ethical
considerations and legal frameworks in shaping a more equitable educational
environment. Furthermore, it guides readers through the complexities of
fairness measurements, methods, and datasets, shedding light on the way to bias
reduction. Despite these gains, this survey highlights long-standing issues,
such as achieving a balance between fairness and accuracy, as well as the need
for diverse datasets. Overcoming these challenges and ensuring the ethical and
fair use of AI's promise in education call for a collaborative,
interdisciplinary approach.",2024-07-26,"Sribala Vidyadhari Chinta, Zichong Wang, Zhipeng Yin, Nhat Hoang, Matthew Gonzalez, Tai Le Quy, Wenbin Zhang",http://arxiv.org/pdf/2407.18745v1,cs.LG
AutoRDF2GML: Facilitating RDF Integration in Graph Machine Learning,"In this paper, we introduce AutoRDF2GML, a framework designed to convert RDF
data into data representations tailored for graph machine learning tasks.
AutoRDF2GML enables, for the first time, the creation of both content-based
features -- i.e., features based on RDF datatype properties -- and
topology-based features -- i.e., features based on RDF object properties.
Characterized by automated feature extraction, AutoRDF2GML makes it possible
even for users less familiar with RDF and SPARQL to generate data
representations ready for graph machine learning tasks, such as link
prediction, node classification, and graph classification. Furthermore, we
present four new benchmark datasets for graph machine learning, created from
large RDF knowledge graphs using our framework. These datasets serve as
valuable resources for evaluating graph machine learning approaches, such as
graph neural networks. Overall, our framework effectively bridges the gap
between the Graph Machine Learning and Semantic Web communities, paving the way
for RDF-based machine learning applications.",2024-07-26,"Michael Färber, David Lamprecht, Yuni Susanti",http://arxiv.org/pdf/2407.18735v1,cs.LG
A Physics-Informed Neural Network-Based Approach for the Spatial Upsampling of Spherical Microphone Arrays,"Spherical microphone arrays are convenient tools for capturing the spatial
characteristics of a sound field. However, achieving superior spatial
resolution requires arrays with numerous capsules, consequently leading to
expensive devices. To address this issue, we present a method for spatially
upsampling spherical microphone arrays with a limited number of capsules. Our
approach exploits a physics-informed neural network with Rowdy activation
functions, leveraging physical constraints to provide high-order microphone
array signals, starting from low-order devices. Results show that, within its
domain of application, our approach outperforms a state of the art method based
on signal processing for spherical microphone arrays upsampling.",2024-07-26,"Federico Miotello, Ferdinando Terminiello, Mirco Pezzoli, Alberto Bernardini, Fabio Antonacci, Augusto Sarti",http://arxiv.org/pdf/2407.18732v1,cs.LG
A maturity framework for data driven maintenance,"Maintenance decisions range from the simple detection of faults to ultimately
predicting future failures and solving the problem. These traditionally human
decisions are nowadays increasingly supported by data and the ultimate aim is
to make them autonomous. This paper explores the challenges encountered in data
driven maintenance, and proposes to consider four aspects in a maturity
framework: data / decision maturity, the translation from the real world to
data, the computability of decisions (using models) and the causality in the
obtained relations. After a discussion of the theoretical concepts involved,
the exploration continues by considering a practical fault detection and
identification problem. Two approaches, i.e. experience based and model based,
are compared and discussed in terms of the four aspects in the maturity
framework. It is observed that both approaches yield the same decisions, but
still differ in the assignment of causality. This confirms that a maturity
assessment not only concerns the type of decision, but should also include the
other proposed aspects.",2024-07-26,"Chris Rijsdijk, Mike van de Wijnckel, Tiedo Tinga",http://arxiv.org/pdf/2407.18996v1,cs.LG
LLASP: Fine-tuning Large Language Models for Answer Set Programming,"Recently, Large Language Models (LLMs) have showcased their potential in
various natural language processing tasks, including code generation. However,
while significant progress has been made in adapting LLMs to generate code for
several imperative programming languages and tasks, there remains a notable gap
in their application to declarative formalisms, such as Answer Set Programming
(ASP). In this paper, we move a step towards exploring the capabilities of LLMs
for ASP code generation. First, we perform a systematic evaluation of several
state-of-the-art LLMs. Despite their power in terms of number of parameters,
training data and computational resources, empirical results demonstrate
inadequate performances in generating correct ASP programs. Therefore, we
propose LLASP, a fine-tuned lightweight model specifically trained to encode
fundamental ASP program patterns. To this aim, we create an ad-hoc dataset
covering a wide variety of fundamental problem specifications that can be
encoded in ASP. Our experiments demonstrate that the quality of ASP programs
generated by LLASP is remarkable. This holds true not only when compared to the
non-fine-tuned counterpart but also when compared to the majority of eager LLM
candidates, particularly from a semantic perspective. All the code and data
used to perform the experiments are publicly available at
https://anonymous.4open.science/r/LLASP-D86C/.",2024-07-26,"Erica Coppolillo, Francesco Calimeri, Giuseppe Manco, Simona Perri, Francesco Ricca",http://arxiv.org/pdf/2407.18723v1,cs.LG
Cluster-norm for Unsupervised Probing of Knowledge,"The deployment of language models brings challenges in generating reliable
information, especially when these models are fine-tuned using human
preferences. To extract encoded knowledge without (potentially) biased human
labels, unsupervised probing techniques like Contrast-Consistent Search (CCS)
have been developed (Burns et al., 2022). However, salient but unrelated
features in a given dataset can mislead these probes (Farquhar et al., 2023).
Addressing this, we propose a cluster normalization method to minimize the
impact of such features by clustering and normalizing activations of contrast
pairs before applying unsupervised probing techniques. While this approach does
not address the issue of differentiating between knowledge in general and
simulated knowledge - a major issue in the literature of latent knowledge
elicitation (Christiano et al., 2021) - it significantly improves the ability
of unsupervised probes to identify the intended knowledge amidst distractions.",2024-07-26,"Walter Laurito, Sharan Maiya, Grégoire Dhimoïla, Owen, Yeung, Kaarel Hänni",http://arxiv.org/pdf/2407.18712v2,cs.LG
Finite Neural Networks as Mixtures of Gaussian Processes: From Provable Error Bounds to Prior Selection,"Infinitely wide or deep neural networks (NNs) with independent and
identically distributed (i.i.d.) parameters have been shown to be equivalent to
Gaussian processes. Because of the favorable properties of Gaussian processes,
this equivalence is commonly employed to analyze neural networks and has led to
various breakthroughs over the years. However, neural networks and Gaussian
processes are equivalent only in the limit; in the finite case there are
currently no methods available to approximate a trained neural network with a
Gaussian model with bounds on the approximation error. In this work, we present
an algorithmic framework to approximate a neural network of finite width and
depth, and with not necessarily i.i.d. parameters, with a mixture of Gaussian
processes with error bounds on the approximation error. In particular, we
consider the Wasserstein distance to quantify the closeness between
probabilistic models and, by relying on tools from optimal transport and
Gaussian processes, we iteratively approximate the output distribution of each
layer of the neural network as a mixture of Gaussian processes. Crucially, for
any NN and $\epsilon >0$ our approach is able to return a mixture of Gaussian
processes that is $\epsilon$-close to the NN at a finite set of input points.
Furthermore, we rely on the differentiability of the resulting error bound to
show how our approach can be employed to tune the parameters of a NN to mimic
the functional behavior of a given Gaussian process, e.g., for prior selection
in the context of Bayesian inference. We empirically investigate the
effectiveness of our results on both regression and classification problems
with various neural network architectures. Our experiments highlight how our
results can represent an important step towards understanding neural network
predictions and formally quantifying their uncertainty.",2024-07-26,"Steven Adams, Patanè, Morteza Lahijanian, Luca Laurenti",http://arxiv.org/pdf/2407.18707v1,cs.LG
Adaptive Contrastive Search: Uncertainty-Guided Decoding for Open-Ended Text Generation,"Decoding from the output distributions of large language models to produce
high-quality text is a complex challenge in language modeling. Various
approaches, such as beam search, sampling with temperature, $k-$sampling,
nucleus $p-$sampling, typical decoding, contrastive decoding, and contrastive
search, have been proposed to address this problem, aiming to improve
coherence, diversity, as well as resemblance to human-generated text. In this
study, we introduce adaptive contrastive search, a novel decoding strategy
extending contrastive search by incorporating an adaptive degeneration penalty,
guided by the estimated uncertainty of the model at each generation step. This
strategy is designed to enhance both the creativity and diversity of the
language modeling process while at the same time producing coherent and
high-quality generated text output. Our findings indicate performance
enhancement in both aspects, across different model architectures and datasets,
underscoring the effectiveness of our method in text generation tasks. Our code
base, datasets, and models are publicly available.",2024-07-26,"Esteban Garces Arias, Julian Rodemann, Meimingwei Li, Christian Heumann, Matthias Aßenmacher",http://arxiv.org/pdf/2407.18698v2,cs.LG
Deep learning for predicting the occurrence of tipping points,"Tipping points occur in many real-world systems, at which the system shifts
suddenly from one state to another. The ability to predict the occurrence of
tipping points from time series data remains an outstanding challenge and a
major interest in a broad range of research fields. Particularly, the widely
used methods based on bifurcation theory are neither reliable in prediction
accuracy nor applicable for irregularly-sampled time series which are commonly
observed from real-world systems. Here we address this challenge by developing
a deep learning algorithm for predicting the occurrence of tipping points in
untrained systems, by exploiting information about normal forms. Our algorithm
not only outperforms traditional methods for regularly-sampled model time
series but also achieves accurate predictions for irregularly-sampled model
time series and empirical time series. Our ability to predict tipping points
for complex systems paves the way for mitigation risks, prevention of
catastrophic failures, and restoration of degraded systems, with broad
applications in social science, engineering, and biology.",2024-07-26,"Chengzuo Zhuge, Jiawei Li, Wei Chen",http://arxiv.org/pdf/2407.18693v2,cs.LG
Graph Neural Networks for Virtual Sensing in Complex Systems: Addressing Heterogeneous Temporal Dynamics,"Real-time condition monitoring is crucial for the reliable and efficient
operation of complex systems. However, relying solely on physical sensors can
be limited due to their cost, placement constraints, or inability to directly
measure certain critical parameters. Virtual sensing addresses these
limitations by leveraging readily available sensor data and system knowledge to
estimate inaccessible parameters or infer system states. The increasing
complexity of industrial systems necessitates deployments of sensors with
diverse modalities to provide a comprehensive understanding of system states.
These sensors capture data at varying frequencies to monitor both rapid and
slowly varying system dynamics, as well as local and global state evolutions of
the systems. This leads to heterogeneous temporal dynamics, which, particularly
under varying operational end environmental conditions, pose a significant
challenge for accurate virtual sensing. To address this, we propose a
Heterogeneous Temporal Graph Neural Network (HTGNN) framework. HTGNN explicitly
models signals from diverse sensors and integrates operating conditions into
the model architecture. We evaluate HTGNN using two newly released datasets: a
bearing dataset with diverse load conditions for bearing load prediction and a
year-long simulated dataset for predicting bridge live loads. Our results
demonstrate that HTGNN significantly outperforms established baseline methods
in both tasks, particularly under highly varying operating conditions. These
results highlight HTGNN's potential as a robust and accurate virtual sensing
approach for complex systems, paving the way for improved monitoring,
predictive maintenance, and enhanced system performance. Our code and data are
available under https://github.com/EPFL-IMOS/htgnn.",2024-07-26,"Mengjie Zhao, Cees Taal, Stephan Baggerohr, Olga Fink",http://arxiv.org/pdf/2407.18691v2,cs.LG
Rapid Object Annotation,"In this report we consider the problem of rapidly annotating a video with
bounding boxes for a novel object. We describe a UI and associated workflow
designed to make this process fast for an arbitrary novel target.",2024-07-26,Misha Denil,http://arxiv.org/pdf/2407.18682v1,cs.LG
"Right Now, Wrong Then: Non-Stationary Direct Preference Optimization under Preference Drift","Reinforcement learning from human feedback (RLHF) aligns Large Language
Models (LLMs) with human preferences. However, these preferences can often
change over time due to external factors (e.g. environment change and societal
influence). Consequently, what was wrong then might be right now. Current
preference optimization algorithms do not account for temporal preference drift
in their modeling, which can lead to severe misalignment. To address this
limitation, we use a Dynamic Bradley-Terry model that models preferences via
time-dependent reward functions, and propose Non-Stationary Direct Preference
Optimisation (NS-DPO). By introducing a discount parameter in the loss
function, NS-DPO applies exponential weighting, which proportionally focuses
learning on more time-relevant datapoints. We theoretically analyse the
convergence of NS-DPO in the offline setting, providing upper bounds on the
estimation error caused by non-stationary preferences. Finally, we demonstrate
the effectiveness of NS-DPO for fine-tuning LLMs in scenarios with drifting
preferences. By simulating preference drift using renowned reward models and
modifying popular LLM datasets accordingly, we show that NS-DPO fine-tuned LLMs
remain robust under non-stationarity, significantly outperforming baseline
algorithms that ignore temporal preference changes, without sacrificing
performance in stationary cases.",2024-07-26,"Seongho Son, William Bankes, Sayak Ray Chowdhury, Brooks Paige, Ilija Bogunovic",http://arxiv.org/pdf/2407.18676v2,cs.LG
A dual ensemble classifier used to recognise contaminated multi-channel EMG and MMG signals in the control of upper limb bioprosthesis,"Myopotential pattern recognition to decode the intent of the user is the most
advanced approach to controlling a powered bioprosthesis. Unfortunately, many
factors make this a difficult problem and achieving acceptable recognition
quality in real-word conditions is a serious challenge. The aim of the paper is
to develop a recognition system that will mitigate factors related to
multimodality and multichannel recording of biosignals and their high
susceptibility to contamination. The proposed method involves the use of two
co-operating multiclassifier systems. The first system is composed of one-class
classifiers related to individual electromyographic (EMG) and mechanomyographic
(MMG) biosignal recording channels, and its task is to recognise contaminated
channels. The role of the second system is to recognise the class of movement
resulting from the patient's intention. The ensemble system consists of base
classifiers using the representation (extracted features) of biosignals from
different channels. The system uses a dynamic selection mechanism, eliminating
those base classifiers that are associated with biosignal channels that are
recognised by the one-class ensemble system as being contaminated. Experimental
studies were conducted using signals from an able-bodied person with simulation
of amputation. The results obtained allow us to reject the null hypothesis that
the application of the dual ensemble foes not lead to improved classification
quality.",2024-07-26,"Pawel Trajdos, Marek Kurzynski",http://arxiv.org/pdf/2407.18675v1,cs.LG
A Survey on Cell Nuclei Instance Segmentation and Classification: Leveraging Context and Attention,"Manually annotating nuclei from the gigapixel Hematoxylin and Eosin
(H&E)-stained Whole Slide Images (WSIs) is a laborious and costly task, meaning
automated algorithms for cell nuclei instance segmentation and classification
could alleviate the workload of pathologists and clinical researchers and at
the same time facilitate the automatic extraction of clinically interpretable
features. But due to high intra- and inter-class variability of nuclei
morphological and chromatic features, as well as H&E-stains susceptibility to
artefacts, state-of-the-art algorithms cannot correctly detect and classify
instances with the necessary performance. In this work, we hypothesise context
and attention inductive biases in artificial neural networks (ANNs) could
increase the generalization of algorithms for cell nuclei instance segmentation
and classification. We conduct a thorough survey on context and attention
methods for cell nuclei instance segmentation and classification from
H&E-stained microscopy imaging, while providing a comprehensive discussion of
the challenges being tackled with context and attention. Besides, we illustrate
some limitations of current approaches and present ideas for future research.
As a case study, we extend both a general instance segmentation and
classification method (Mask-RCNN) and a tailored cell nuclei instance
segmentation and classification model (HoVer-Net) with context- and
attention-based mechanisms, and do a comparative analysis on a multi-centre
colon nuclei identification and counting dataset. Although pathologists rely on
context at multiple levels while paying attention to specific Regions of
Interest (RoIs) when analysing and annotating WSIs, our findings suggest
translating that domain knowledge into algorithm design is no trivial task, but
to fully exploit these mechanisms, the scientific understanding of these
methods should be addressed.",2024-07-26,"João D. Nunes, Diana Montezuma, Domingos Oliveira, Tania Pereira, Jaime S. Cardoso",http://arxiv.org/pdf/2407.18673v1,cs.LG
ChipExpert: The Open-Source Integrated-Circuit-Design-Specific Large Language Model,"The field of integrated circuit (IC) design is highly specialized, presenting
significant barriers to entry and research and development challenges. Although
large language models (LLMs) have achieved remarkable success in various
domains, existing LLMs often fail to meet the specific needs of students,
engineers, and researchers. Consequently, the potential of LLMs in the IC
design domain remains largely unexplored. To address these issues, we introduce
ChipExpert, the first open-source, instructional LLM specifically tailored for
the IC design field. ChipExpert is trained on one of the current best
open-source base model (Llama-3 8B). The entire training process encompasses
several key stages, including data preparation, continue pre-training,
instruction-guided supervised fine-tuning, preference alignment, and
evaluation. In the data preparation stage, we construct multiple high-quality
custom datasets through manual selection and data synthesis techniques. In the
subsequent two stages, ChipExpert acquires a vast amount of IC design knowledge
and learns how to respond to user queries professionally. ChipExpert also
undergoes an alignment phase, using Direct Preference Optimization, to achieve
a high standard of ethical performance. Finally, to mitigate the hallucinations
of ChipExpert, we have developed a Retrieval-Augmented Generation (RAG) system,
based on the IC design knowledge base. We also released the first IC design
benchmark ChipICD-Bench, to evaluate the capabilities of LLMs across multiple
IC design sub-domains. Through comprehensive experiments conducted on this
benchmark, ChipExpert demonstrated a high level of expertise in IC design
knowledge Question-and-Answer tasks.",2024-07-26,"Ning Xu, Zhaoyang Zhang, Lei Qi, Wensuo Wang, Chao Zhang, Zihao Ren, Huaiyuan Zhang, Xin Cheng, Yanqi Zhang, Zhichao Liu, Qingwen Wei, Shiyang Wu, Lanlan Yang, Qianfeng Lu, Yiqun Ma, Mengyao Zhao, Junbo Liu, Yufan Song, Xin Geng, Jun Yang",http://arxiv.org/pdf/2408.00804v1,cs.LG
Adversarial Robustification via Text-to-Image Diffusion Models,"Adversarial robustness has been conventionally believed as a challenging
property to encode for neural networks, requiring plenty of training data. In
the recent paradigm of adopting off-the-shelf models, however, access to their
training data is often infeasible or not practical, while most of such models
are not originally trained concerning adversarial robustness. In this paper, we
develop a scalable and model-agnostic solution to achieve adversarial
robustness without using any data. Our intuition is to view recent
text-to-image diffusion models as ""adaptable"" denoisers that can be optimized
to specify target tasks. Based on this, we propose: (a) to initiate a
denoise-and-classify pipeline that offers provable guarantees against
adversarial attacks, and (b) to leverage a few synthetic reference images
generated from the text-to-image model that enables novel adaptation schemes.
Our experiments show that our data-free scheme applied to the pre-trained CLIP
could improve the (provable) adversarial robustness of its diverse zero-shot
classification derivatives (while maintaining their accuracy), significantly
surpassing prior approaches that utilize the full training data. Not only for
CLIP, we also demonstrate that our framework is easily applicable for
robustifying other visual classifiers efficiently.",2024-07-26,"Daewon Choi, Jongheon Jeong, Huiwon Jang, Jinwoo Shin",http://arxiv.org/pdf/2407.18658v1,cs.LG
Aspects of importance sampling in parameter selection for neural networks using ridgelet transform,"The choice of parameters in neural networks is crucial in the performance,
and an oracle distribution derived from the ridgelet transform enables us to
obtain suitable initial parameters. In other words, the distribution of
parameters is connected to the integral representation of target functions. The
oracle distribution allows us to avoid the conventional backpropagation
learning process; only a linear regression is enough to construct the neural
network in simple cases. This study provides a new look at the oracle
distributions and ridgelet transforms, i.e., an aspect of importance sampling.
In addition, we propose extensions of the parameter sampling methods. We
demonstrate the aspect of importance sampling and the proposed sampling
algorithms via one-dimensional and high-dimensional examples; the results imply
that the magnitude of weight parameters could be more crucial than the
intercept parameters.",2024-07-26,"Hikaru Homma, Jun Ohkubo",http://arxiv.org/pdf/2407.18655v1,cs.LG
Achieving interpretable machine learning by functional decomposition of black-box models into explainable predictor effects,"Machine learning (ML) has seen significant growth in both popularity and
importance. The high prediction accuracy of ML models is often achieved through
complex black-box architectures that are difficult to interpret. This
interpretability problem has been hindering the use of ML in fields like
medicine, ecology and insurance, where an understanding of the inner workings
of the model is paramount to ensure user acceptance and fairness. The need for
interpretable ML models has boosted research in the field of interpretable
machine learning (IML). Here we propose a novel approach for the functional
decomposition of black-box predictions, which is considered a core concept of
IML. The idea of our method is to replace the prediction function by a
surrogate model consisting of simpler subfunctions. Similar to additive
regression models, these functions provide insights into the direction and
strength of the main feature contributions and their interactions. Our method
is based on a novel concept termed stacked orthogonality, which ensures that
the main effects capture as much functional behavior as possible and do not
contain information explained by higher-order interactions. Unlike earlier
functional IML approaches, it is neither affected by extrapolation nor by
hidden feature interactions. To compute the subfunctions, we propose an
algorithm based on neural additive modeling and an efficient post-hoc
orthogonalization procedure.",2024-07-26,"David Köhler, David Rügamer, Matthias Schmid",http://arxiv.org/pdf/2407.18650v1,cs.LG
Fast and Reliable Probabilistic Reflectometry Inversion with Prior-Amortized Neural Posterior Estimation,"Reconstructing the structure of thin films and multilayers from measurements
of scattered X-rays or neutrons is key to progress in physics, chemistry, and
biology. However, finding all structures compatible with reflectometry data is
computationally prohibitive for standard algorithms, which typically results in
unreliable analysis with only a single potential solution identified. We
address this lack of reliability with a probabilistic deep learning method that
identifies all realistic structures in seconds, setting new standards in
reflectometry. Our method, Prior-Amortized Neural Posterior Estimation (PANPE),
combines simulation-based inference with novel adaptive priors that inform the
inference network about known structural properties and controllable
experimental conditions. PANPE networks support key scenarios such as
high-throughput sample characterization, real-time monitoring of evolving
structures, or the co-refinement of several experimental data sets, and can be
adapted to provide fast, reliable, and flexible inference across many other
inverse problems.",2024-07-26,"Vladimir Starostin, Maximilian Dax, Alexander Gerlach, Alexander Hinderhofer, Álvaro Tejero-Cantero, Frank Schreiber",http://arxiv.org/pdf/2407.18648v1,cs.LG
Contrastive Learning of Asset Embeddings from Financial Time Series,"Representation learning has emerged as a powerful paradigm for extracting
valuable latent features from complex, high-dimensional data. In financial
domains, learning informative representations for assets can be used for tasks
like sector classification, and risk management. However, the complex and
stochastic nature of financial markets poses unique challenges. We propose a
novel contrastive learning framework to generate asset embeddings from
financial time series data. Our approach leverages the similarity of asset
returns over many subwindows to generate informative positive and negative
samples, using a statistical sampling strategy based on hypothesis testing to
address the noisy nature of financial data. We explore various contrastive loss
functions that capture the relationships between assets in different ways to
learn a discriminative representation space. Experiments on real-world datasets
demonstrate the effectiveness of the learned asset embeddings on benchmark
industry classification and portfolio optimization tasks. In each case our
novel approaches significantly outperform existing baselines highlighting the
potential for contrastive learning to capture meaningful and actionable
relationships in financial data.",2024-07-26,"Rian Dolphin, Barry Smyth, Ruihai Dong",http://arxiv.org/pdf/2407.18645v1,cs.LG
Vulnerability Detection in Ethereum Smart Contracts via Machine Learning: A Qualitative Analysis,"Smart contracts are central to a myriad of critical blockchain applications,
from financial transactions to supply chain management. However, their adoption
is hindered by security vulnerabilities that can result in significant
financial losses. Most vulnerability detection tools and methods available
nowadays leverage either static analysis methods or machine learning.
Unfortunately, as valuable as they are, both approaches suffer from limitations
that make them only partially effective. In this survey, we analyze the state
of the art in machine-learning vulnerability detection for Ethereum smart
contracts, by categorizing existing tools and methodologies, evaluating them,
and highlighting their limitations. Our critical assessment unveils issues such
as restricted vulnerability coverage and dataset construction flaws, providing
us with new metrics to overcome the difficulties that restrain a sound
comparison of existing solutions. Driven by our findings, we discuss best
practices to enhance the accuracy, scope, and efficiency of vulnerability
detection in smart contracts. Our guidelines address the known flaws while at
the same time opening new avenues for research and development. By shedding
light on current challenges and offering novel directions for improvement, we
contribute to the advancement of secure smart contract development and
blockchain technology as a whole.",2024-07-26,"Dalila Ressi, Alvise Spanò, Lorenzo Benetollo, Carla Piazza, Michele Bugliesi, Sabina Rossi",http://arxiv.org/pdf/2407.18639v1,cs.LG
Robust VAEs via Generating Process of Noise Augmented Data,"Advancing defensive mechanisms against adversarial attacks in generative
models is a critical research topic in machine learning. Our study focuses on a
specific type of generative models - Variational Auto-Encoders (VAEs). Contrary
to common beliefs and existing literature which suggest that noise injection
towards training data can make models more robust, our preliminary experiments
revealed that naive usage of noise augmentation technique did not substantially
improve VAE robustness. In fact, it even degraded the quality of learned
representations, making VAEs more susceptible to adversarial perturbations.
This paper introduces a novel framework that enhances robustness by
regularizing the latent space divergence between original and noise-augmented
data. Through incorporating a paired probabilistic prior into the standard
variational lower bound, our method significantly boosts defense against
adversarial attacks. Our empirical evaluations demonstrate that this approach,
termed Robust Augmented Variational Auto-ENcoder (RAVEN), yields superior
performance in resisting adversarial inputs on widely-recognized benchmark
datasets.",2024-07-26,"Hiroo Irobe, Wataru Aoki, Kimihiro Yamazaki, Yuhui Zhang, Takumi Nakagawa, Hiroki Waida, Yuichiro Wada, Takafumi Kanamori",http://arxiv.org/pdf/2407.18632v1,cs.LG
CardioLab: Laboratory Values Estimation from Electrocardiogram Features -- An Exploratory Study,"Introduction: Laboratory value represents a cornerstone of medical
diagnostics, but suffers from slow turnaround times, and high costs and only
provides information about a single point in time. The continuous estimation of
laboratory values from non-invasive data such as electrocardiogram (ECG) would
therefore mark a significant frontier in healthcare monitoring. Despite its
transformative potential, this domain remains relatively underexplored within
the medical community.
  Methods: In this preliminary study, we used a publicly available dataset
(MIMIC-IV-ECG) to investigate the feasibility of inferring laboratory values
from ECG features and patient demographics using tree-based models (XGBoost).
We define the prediction task as a binary prediction problem of predicting
whether the lab value falls into low or high abnormalities. The model
performance can then be assessed using AUROC.
  Results: Our findings demonstrate promising results in the estimation of
laboratory values related to different organ systems based on a small yet
comprehensive set of features. While further research and validation are
warranted to fully assess the clinical utility and generalizability of
ECG-based estimation in healthcare monitoring, our findings lay the groundwork
for future investigations into approaches to laboratory value estimation using
ECG data. Such advancements hold promise for revolutionizing predictive
healthcare applications, offering faster, non-invasive, and more affordable
means of patient monitoring.",2024-07-26,"Juan Miguel Lopez Alcaraz, Nils Strodthoff",http://arxiv.org/pdf/2407.18629v2,cs.LG
Multi-Agent Deep Reinforcement Learning for Energy Efficient Multi-Hop STAR-RIS-Assisted Transmissions,"Simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) provides a promising way to expand coverage in wireless
communications. However, limitation of single STAR-RIS inspire us to integrate
the concept of multi-hop transmissions, as focused on RIS in existing research.
Therefore, we propose the novel architecture of multi-hop STAR-RISs to achieve
a wider range of full-plane service coverage. In this paper, we intend to solve
active beamforming of the base station and passive beamforming of STAR-RISs,
aiming for maximizing the energy efficiency constrained by hardware limitation
of STAR-RISs. Furthermore, we investigate the impact of the on-off state of
STAR-RIS elements on energy efficiency. To tackle the complex problem, a
Multi-Agent Global and locAl deep Reinforcement learning (MAGAR) algorithm is
designed. The global agent elevates the collaboration among local agents, which
focus on individual learning. In numerical results, we observe the significant
improvement of MAGAR compared to the other benchmarks, including Q-learning,
multi-agent deep Q network (DQN) with golbal reward, and multi-agent DQN with
local rewards. Moreover, the proposed architecture of multi-hop STAR-RISs
achieves the highest energy efficiency compared to mode switching based
STAR-RISs, conventional RISs and deployment without RISs or STAR-RISs.",2024-07-26,"Pei-Hsiang Liao, Li-Hsiang Shen, Po-Chen Wu, Kai-Ten Feng",http://arxiv.org/pdf/2407.18627v1,cs.LG
Dual-Decoupling Learning and Metric-Adaptive Thresholding for Semi-Supervised Multi-Label Learning,"Semi-supervised multi-label learning (SSMLL) is a powerful framework for
leveraging unlabeled data to reduce the expensive cost of collecting precise
multi-label annotations. Unlike semi-supervised learning, one cannot select the
most probable label as the pseudo-label in SSMLL due to multiple semantics
contained in an instance. To solve this problem, the mainstream method
developed an effective thresholding strategy to generate accurate
pseudo-labels. Unfortunately, the method neglected the quality of model
predictions and its potential impact on pseudo-labeling performance. In this
paper, we propose a dual-perspective method to generate high-quality
pseudo-labels. To improve the quality of model predictions, we perform
dual-decoupling to boost the learning of correlative and discriminative
features, while refining the generation and utilization of pseudo-labels. To
obtain proper class-wise thresholds, we propose the metric-adaptive
thresholding strategy to estimate the thresholds, which maximize the
pseudo-label performance for a given metric on labeled data. Experiments on
multiple benchmark datasets show the proposed method can achieve the
state-of-the-art performance and outperform the comparative methods with a
significant margin.",2024-07-26,"Jia-Hao Xiao, Ming-Kun Xie, Heng-Bo Fan, Gang Niu, Masashi Sugiyama, Sheng-Jun Huang",http://arxiv.org/pdf/2407.18624v2,cs.LG
Denoising Lévy Probabilistic Models,"Exploring noise distributions beyond Gaussian in diffusion models remains an
open challenge. While Gaussian-based models succeed within a unified SDE
framework, recent studies suggest that heavy-tailed noise distributions, like
$\alpha$-stable distributions, may better handle mode collapse and effectively
manage datasets exhibiting class imbalance, heavy tails, or prominent outliers.
Recently, Yoon et al.\ (NeurIPS 2023), presented the L\'evy-It\^o model (LIM),
directly extending the SDE-based framework to a class of heavy-tailed SDEs,
where the injected noise followed an $\alpha$-stable distribution, a rich class
of heavy-tailed distributions. However, the LIM framework relies on highly
involved mathematical techniques with limited flexibility, potentially
hindering broader adoption and further development. In this study, instead of
starting from the SDE formulation, we extend the denoising diffusion
probabilistic model (DDPM) by replacing the Gaussian noise with $\alpha$-stable
noise. By using only elementary proof techniques, the proposed approach,
Denoising L\'evy Probabilistic Models (DLPM), boils down to vanilla DDPM with
minor modifications. As opposed to the Gaussian case, DLPM and LIM yield
different training algorithms and different backward processes, leading to
distinct sampling algorithms. These fundamental differences translate favorably
for DLPM as compared to LIM: our experiments show improvements in coverage of
data distribution tails, better robustness to unbalanced datasets, and improved
computation times requiring smaller number of backward steps.",2024-07-26,"Dario Shariatian, Umut Simsekli, Alain Durmus",http://arxiv.org/pdf/2407.18609v3,cs.LG
Using GPT-4 to guide causal machine learning,"Since its introduction to the public, ChatGPT has had an unprecedented
impact. While some experts praised AI advancements and highlighted their
potential risks, others have been critical about the accuracy and usefulness of
Large Language Models (LLMs). In this paper, we are interested in the ability
of LLMs to identify causal relationships. We focus on the well-established
GPT-4 (Turbo) and evaluate its performance under the most restrictive
conditions, by isolating its ability to infer causal relationships based solely
on the variable labels without being given any other context by humans,
demonstrating the minimum level of effectiveness one can expect when it is
provided with label-only information. We show that questionnaire participants
judge the GPT-4 graphs as the most accurate in the evaluated categories,
closely followed by knowledge graphs constructed by domain experts, with causal
Machine Learning (ML) far behind. We use these results to highlight the
important limitation of causal ML, which often produces causal graphs that
violate common sense, affecting trust in them. However, we show that pairing
GPT-4 with causal ML overcomes this limitation, resulting in graphical
structures learnt from real data that align more closely with those identified
by domain experts, compared to structures learnt by causal ML alone. Overall,
our findings suggest that despite GPT-4 not being explicitly designed to reason
causally, it can still be a valuable tool for causal representation, as it
improves the causal discovery process of causal ML algorithms that are designed
to do just that.",2024-07-26,"Anthony C. Constantinou, Neville K. Kitson, Alessio Zanga",http://arxiv.org/pdf/2407.18607v2,cs.LG
A data balancing approach towards design of an expert system for Heart Disease Prediction,"Heart disease is a serious global health issue that claims millions of lives
every year. Early detection and precise prediction are critical to the
prevention and successful treatment of heart related issues. A lot of research
utilizes machine learning (ML) models to forecast cardiac disease and obtain
early detection. In order to do predictive analysis on ""Heart disease health
indicators "" dataset. We employed five machine learning methods in this paper:
Decision Tree (DT), Random Forest (RF), Linear Discriminant Analysis, Extra
Tree Classifier, and AdaBoost. The model is further examined using various
feature selection (FS) techniques. To enhance the baseline model, we have
separately applied four FS techniques: Sequential Forward FS, Sequential
Backward FS, Correlation Matrix, and Chi2. Lastly, K means SMOTE oversampling
is applied to the models to enable additional analysis. The findings show that
when it came to predicting heart disease, ensemble approaches in particular,
random forests performed better than individual classifiers. The presence of
smoking, blood pressure, cholesterol, and physical inactivity were among the
major predictors that were found. The accuracy of the Random Forest and
Decision Tree model was 99.83%. This paper demonstrates how machine learning
models can improve the accuracy of heart disease prediction, especially when
using ensemble methodologies. The models provide a more accurate risk
assessment than traditional methods since they incorporate a large number of
factors and complex algorithms.",2024-07-26,"Rahul Karmakar, Udita Ghosh, Arpita Pal, Sattwiki Dey, Debraj Malik, Priyabrata Sain",http://arxiv.org/pdf/2407.18606v2,cs.LG
Reorganizing attention-space geometry with expressive attention,"Attention regulates information transfer between tokens. For this, query and
key vectors are compared, typically in terms of a scalar product,
$\mathbf{Q}^T\mathbf{K}$, together with a subsequent softmax normalization. In
geometric terms, the standard dot-product attention (DPA) leads to large/small
attention weights for parallel/antiparallel queries and keys. Here we study
expressive attention (EA), which is based on $(\mathbf{Q}^T\mathbf{K})^2$, the
squared dot product. In this case, attention is enhanced when query and key are
either parallel or antiparallel, and suppressed for orthogonal configurations.
EA can be introduced into any attention-based code without additional compute
costs or memory requirements. For a series of autoregressive prediction tasks,
we find that expressive attention performs at least as well as vanilla DPA.
Increasing task complexity, EA is observed to outperform DPA with increasing
margins, which also holds for multi-task settings. For a given model size, EA
manages to achieve 100% performance for a range of complexity levels not
accessible to DPA. Our results show that it is possible to reorganize the
geometry of the matching condition in the space of attention heads without loss
of performance.",2024-07-26,Claudius Gros,http://arxiv.org/pdf/2407.18601v2,cs.LG
Reinforcement Learning for Sustainable Energy: A Survey,"The transition to sustainable energy is a key challenge of our time,
requiring modifications in the entire pipeline of energy production, storage,
transmission, and consumption. At every stage, new sequential decision-making
challenges emerge, ranging from the operation of wind farms to the management
of electrical grids or the scheduling of electric vehicle charging stations.
All such problems are well suited for reinforcement learning, the branch of
machine learning that learns behavior from data. Therefore, numerous studies
have explored the use of reinforcement learning for sustainable energy. This
paper surveys this literature with the intention of bridging both the
underlying research communities: energy and machine learning. After a brief
introduction of both fields, we systematically list relevant sustainability
challenges, how they can be modeled as a reinforcement learning problem, and
what solution approaches currently exist in the literature. Afterwards, we zoom
out and identify overarching reinforcement learning themes that appear
throughout sustainability, such as multi-agent, offline, and safe reinforcement
learning. Lastly, we also cover standardization of environments, which will be
crucial for connecting both research fields, and highlight potential directions
for future work. In summary, this survey provides an extensive overview of
reinforcement learning methods for sustainable energy, which may play a vital
role in the energy transition.",2024-07-26,"Koen Ponse, Felix Kleuker, Márton Fejér, Álvaro Serra-Gómez, Aske Plaat, Thomas Moerland",http://arxiv.org/pdf/2407.18597v1,cs.LG
Online Test Synthesis From Requirements: Enhancing Reinforcement Learning with Game Theory,"We consider the automatic online synthesis of black-box test cases from
functional requirements specified as automata for reactive implementations. The
goal of the tester is to reach some given state, so as to satisfy a coverage
criterion, while monitoring the violation of the requirements. We develop an
approach based on Monte Carlo Tree Search, which is a classical technique in
reinforcement learning for efficiently selecting promising inputs. Seeing the
automata requirements as a game between the implementation and the tester, we
develop a heuristic by biasing the search towards inputs that are promising in
this game. We experimentally show that our heuristic accelerates the
convergence of the Monte Carlo Tree Search algorithm, thus improving the
performance of testing.",2024-07-26,"Ocan Sankur, Thierry Jéron, Nicolas Markey, David Mentré, Reiya Noguchi",http://arxiv.org/pdf/2407.18994v1,cs.LG
PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning,"Personalized motion planning holds significant importance within urban
automated driving, catering to the unique requirements of individual users.
Nevertheless, prior endeavors have frequently encountered difficulties in
simultaneously addressing two crucial aspects: personalized planning within
intricate urban settings and enhancing planning performance through data
utilization. The challenge arises from the expensive and limited nature of user
data, coupled with the scene state space tending towards infinity. These
factors contribute to overfitting and poor generalization problems during model
training. Henceforth, we propose an instance-based transfer imitation learning
approach. This method facilitates knowledge transfer from extensive expert
domain data to the user domain, presenting a fundamental resolution to these
issues. We initially train a pre-trained model using large-scale expert data.
Subsequently, during the fine-tuning phase, we feed the batch data, which
comprises expert and user data. Employing the inverse reinforcement learning
technique, we extract the style feature distribution from user demonstrations,
constructing the regularization term for the approximation of user style. In
our experiments, we conducted extensive evaluations of the proposed method.
Compared to the baseline methods, our approach mitigates the overfitting issue
caused by sparse user data. Furthermore, we discovered that integrating the
driving model with a differentiable nonlinear optimizer as a safety protection
layer for end-to-end personalized fine-tuning results in superior planning
performance.",2024-07-26,"Fangze Lin, Ying He, Fei Yu",http://arxiv.org/pdf/2407.18569v3,cs.LG
Unveiling Privacy Vulnerabilities: Investigating the Role of Structure in Graph Data,"The public sharing of user information opens the door for adversaries to
infer private data, leading to privacy breaches and facilitating malicious
activities. While numerous studies have concentrated on privacy leakage via
public user attributes, the threats associated with the exposure of user
relationships, particularly through network structure, are often neglected.
This study aims to fill this critical gap by advancing the understanding and
protection against privacy risks emanating from network structure, moving
beyond direct connections with neighbors to include the broader implications of
indirect network structural patterns. To achieve this, we first investigate the
problem of Graph Privacy Leakage via Structure (GPS), and introduce a novel
measure, the Generalized Homophily Ratio, to quantify the various mechanisms
contributing to privacy breach risks in GPS. Based on this insight, we develop
a novel graph private attribute inference attack, which acts as a pivotal tool
for evaluating the potential for privacy leakage through network structures
under worst-case scenarios. To protect users' private data from such
vulnerabilities, we propose a graph data publishing method incorporating a
learnable graph sampling technique, effectively transforming the original graph
into a privacy-preserving version. Extensive experiments demonstrate that our
attack model poses a significant threat to user privacy, and our graph data
publishing method successfully achieves the optimal privacy-utility trade-off
compared to baselines.",2024-07-26,"Hanyang Yuan, Jiarong Xu, Cong Wang, Ziqi Yang, Chunping Wang, Keting Yin, Yang Yang",http://arxiv.org/pdf/2407.18564v1,cs.LG
Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs,"Sparse Knowledge Graphs (KGs), frequently encountered in real-world
applications, contain fewer facts in the form of (head entity, relation, tail
entity) compared to more populated KGs. The sparse KG completion task, which
reasons answers for given queries in the form of (head entity, relation, ?) for
sparse KGs, is particularly challenging due to the necessity of reasoning
missing facts based on limited facts. Path-based models, known for excellent
explainability, are often employed for this task. However, existing path-based
models typically rely on external models to fill in missing facts and
subsequently perform path reasoning. This approach introduces unexplainable
factors or necessitates meticulous rule design. In light of this, this paper
proposes an alternative approach by looking inward instead of seeking external
assistance. We introduce a two-stage path reasoning model called LoGRe (Look
Globally and Reason) over sparse KGs. LoGRe constructs a relation-path
reasoning schema by globally analyzing the training data to alleviate the
sparseness problem. Based on this schema, LoGRe then aggregates paths to reason
out answers. Experimental results on five benchmark sparse KG datasets
demonstrate the effectiveness of the proposed LoGRe model.",2024-07-26,"Saiping Guan, Jiyao Wei, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng",http://arxiv.org/pdf/2407.18556v1,cs.LG
An Adaptive CSI Feedback Model Based on BiLSTM for Massive MIMO-OFDM Systems,"Deep learning (DL)-based channel state information (CSI) feedback has the
potential to improve the recovery accuracy and reduce the feedback overhead in
massive multiple-input multiple-output orthogonal frequency division
multiplexing (MIMO-OFDM) systems. However, the length of input CSI and the
number of feedback bits should be adjustable in different scenarios, which can
not be efficiently achieved by the existing CSI feedback models. Therefore, an
adaptive bidirectional long short-term memory network (ABLNet) for CSI feedback
is first designed to process various input CSI lengths, where the number of
feedback bits is in proportion to the CSI length. Then, to realize a more
flexible feedback bit number, a feedback bit control unit (FBCU) module is
proposed to control the output length of feedback bits. Based on which, a
target feedback performance can be adaptively achieved by a designed bit number
adjusting (BNA) algorithm. Furthermore, a novel separate training approach is
devised to solve the model protection problem that the UE and gNB are from
different manufacturers. Experiments demonstrate that the proposed ABLNet with
FBCU can fit for different input CSI lengths and feedback bit numbers; the CSI
feedback performance can be stabilized by the BNA algorithm; and the proposed
separate training approach can maintain the feedback performance and reduce the
complexity of feedback model.",2024-07-26,"Hongrui Shen, Long Zhao, Kan Zheng, Yuhua Cao, Pingzhi Fan",http://arxiv.org/pdf/2408.06359v1,cs.LG
Multimodal Emotion Recognition using Audio-Video Transformer Fusion with Cross Attention,"Understanding emotions is a fundamental aspect of human communication.
Integrating audio and video signals offers a more comprehensive understanding
of emotional states compared to traditional methods that rely on a single data
source, such as speech or facial expressions. Despite its potential, multimodal
emotion recognition faces significant challenges, particularly in
synchronization, feature extraction, and fusion of diverse data sources. To
address these issues, this paper introduces a novel transformer-based model
named Audio-Video Transformer Fusion with Cross Attention (AVT-CA). The AVT-CA
model employs a transformer fusion approach to effectively capture and
synchronize interlinked features from both audio and video inputs, thereby
resolving synchronization problems. Additionally, the Cross Attention mechanism
within AVT-CA selectively extracts and emphasizes critical features while
discarding irrelevant ones from both modalities, addressing feature extraction
and fusion challenges. Extensive experimental analysis conducted on the
CMU-MOSEI, RAVDESS and CREMA-D datasets demonstrates the efficacy of the
proposed model. The results underscore the importance of AVT-CA in developing
precise and reliable multimodal emotion recognition systems for practical
applications.",2024-07-26,"Joe Dhanith P R, Shravan Venkatraman, Vigya Sharma, Santhosh Malarvannan, Modigari Narendra",http://arxiv.org/pdf/2407.18552v3,cs.LG
Utilising Explainable Techniques for Quality Prediction in a Complex Textiles Manufacturing Use Case,"This paper develops an approach to classify instances of product failure in a
complex textiles manufacturing dataset using explainable techniques. The
dataset used in this study was obtained from a New Zealand manufacturer of
woollen carpets and rugs. In investigating the trade-off between accuracy and
explainability, three different tree-based classification algorithms were
evaluated: a Decision Tree and two ensemble methods, Random Forest and XGBoost.
Additionally, three feature selection methods were also evaluated: the
SelectKBest method, using chi-squared as the scoring function, the Pearson
Correlation Coefficient, and the Boruta algorithm. Not surprisingly, the
ensemble methods typically produced better results than the Decision Tree
model. The Random Forest model yielded the best results overall when combined
with the Boruta feature selection technique. Finally, a tree ensemble
explaining technique was used to extract rule lists to capture necessary and
sufficient conditions for classification by a trained model that could be
easily interpreted by a human. Notably, several features that were in the
extracted rule lists were statistical features and calculated features that
were added to the original dataset. This demonstrates the influence that
bringing in additional information during the data preprocessing stages can
have on the ultimate model performance.",2024-07-26,"Briony Forsberg, Dr Henry Williams, Prof Bruce MacDonald, Tracy Chen, Dr Reza Hamzeh, Dr Kirstine Hulse",http://arxiv.org/pdf/2407.18544v1,cs.LG
MLtoGAI: Semantic Web based with Machine Learning for Enhanced Disease Prediction and Personalized Recommendations using Generative AI,"In modern healthcare, addressing the complexities of accurate disease
prediction and personalized recommendations is both crucial and challenging.
This research introduces MLtoGAI, which integrates Semantic Web technology with
Machine Learning (ML) to enhance disease prediction and offer user-friendly
explanations through ChatGPT. The system comprises three key components: a
reusable disease ontology that incorporates detailed knowledge about various
diseases, a diagnostic classification model that uses patient symptoms to
detect specific diseases accurately, and the integration of Semantic Web Rule
Language (SWRL) with ontology and ChatGPT to generate clear, personalized
health advice. This approach significantly improves prediction accuracy and
ensures results that are easy to understand, addressing the complexity of
diseases and diverse symptoms. The MLtoGAI system demonstrates substantial
advancements in accuracy and user satisfaction, contributing to developing more
intelligent and accessible healthcare solutions. This innovative approach
combines the strengths of ML algorithms with the ability to provide
transparent, human-understandable explanations through ChatGPT, achieving
significant improvements in prediction accuracy and user comprehension. By
leveraging semantic technology and explainable AI, the system enhances the
accuracy of disease prediction and ensures that the recommendations are
relevant and easily understood by individual patients. Our research highlights
the potential of integrating advanced technologies to overcome existing
challenges in medical diagnostics, paving the way for future developments in
intelligent healthcare systems. Additionally, the system is validated using 200
synthetic patient data records, ensuring robust performance and reliability.",2024-07-26,"Shyam Dongre, Ritesh Chandra, Sonali Agarwal",http://arxiv.org/pdf/2407.20284v1,cs.LG
Constructing Enhanced Mutual Information for Online Class-Incremental Learning,"Online Class-Incremental continual Learning (OCIL) addresses the challenge of
continuously learning from a single-channel data stream, adapting to new tasks
while mitigating catastrophic forgetting. Recently, Mutual Information
(MI)-based methods have shown promising performance in OCIL. However, existing
MI-based methods treat various knowledge components in isolation, ignoring the
knowledge confusion across tasks. This narrow focus on simple MI knowledge
alignment may lead to old tasks being easily forgotten with the introduction of
new tasks, risking the loss of common parts between past and present
knowledge.To address this, we analyze the MI relationships from the
perspectives of diversity, representativeness, and separability, and propose an
Enhanced Mutual Information (EMI) method based on knwoledge decoupling. EMI
consists of Diversity Mutual Information (DMI), Representativeness Mutual
Information (RMI) and Separability Mutual Information (SMI). DMI diversifies
intra-class sample features by considering the similarity relationships among
inter-class sample features to enable the network to learn more general
knowledge. RMI summarizes representative features for each category and aligns
sample features with these representative features, making the intra-class
sample distribution more compact. SMI establishes MI relationships for
inter-class representative features, enhancing the stability of representative
features while increasing the distinction between inter-class representative
features, thus creating clear boundaries between class. Extensive experimental
results on widely used benchmark datasets demonstrate the superior performance
of EMI over state-of-the-art baseline methods.",2024-07-26,"Huan Zhang, Fan Lyu, Shenghua Fan, Yujin Zheng, Dingwen Wang",http://arxiv.org/pdf/2407.18526v1,cs.LG
ClinicRealm: Re-evaluating Large Language Models with Conventional Machine Learning for Non-Generative Clinical Prediction Tasks,"Large Language Models (LLMs) are increasingly deployed in medicine. However,
their utility in non-generative clinical prediction, often presumed inferior to
specialized models, remains under-evaluated, leading to ongoing debate within
the field and potential for misuse, misunderstanding, or over-reliance due to a
lack of systematic benchmarking. Our ClinicRealm study addresses this by
benchmarking 9 GPT-based LLMs, 5 BERT-based models, and 7 traditional methods
on unstructured clinical notes and structured Electronic Health Records (EHR).
Key findings reveal a significant shift: for clinical note predictions, leading
LLMs (e.g., DeepSeek R1/V3, GPT o3-mini-high) in zero-shot settings now
decisively outperform finetuned BERT models. On structured EHRs, while
specialized models excel with ample data, advanced LLMs (e.g., GPT-4o, DeepSeek
R1/V3) show potent zero-shot capabilities, often surpassing conventional models
in data-scarce settings. Notably, leading open-source LLMs can match or exceed
proprietary counterparts. These results establish modern LLMs as powerful
non-generative clinical prediction tools, particularly with unstructured text
and offering data-efficient structured data options, thus necessitating a
re-evaluation of model selection strategies. This research should serve as an
important insight for medical informaticists, AI developers, and clinical
researchers, potentially prompting a reassessment of current assumptions and
inspiring new approaches to LLM application in predictive healthcare.",2024-07-26,"Yinghao Zhu, Junyi Gao, Zixiang Wang, Weibin Liao, Xiaochen Zheng, Lifang Liang, Miguel O. Bernabeu, Yasha Wang, Lequan Yu, Chengwei Pan, Ewen M. Harrison, Liantao Ma",http://arxiv.org/pdf/2407.18525v2,cs.LG
DTFormer: A Transformer-Based Method for Discrete-Time Dynamic Graph Representation Learning,"Discrete-Time Dynamic Graphs (DTDGs), which are prevalent in real-world
implementations and notable for their ease of data acquisition, have garnered
considerable attention from both academic researchers and industry
practitioners. The representation learning of DTDGs has been extensively
applied to model the dynamics of temporally changing entities and their
evolving connections. Currently, DTDG representation learning predominantly
relies on GNN+RNN architectures, which manifest the inherent limitations of
both Graph Neural Networks (GNNs) and Recurrent Neural Networks (RNNs). GNNs
suffer from the over-smoothing issue as the models architecture goes deeper,
while RNNs struggle to capture long-term dependencies effectively. GNN+RNN
architectures also grapple with scaling to large graph sizes and long
sequences. Additionally, these methods often compute node representations
separately and focus solely on individual node characteristics, thereby
overlooking the behavior intersections between the two nodes whose link is
being predicted, such as instances where the two nodes appear together in the
same context or share common neighbors.
  This paper introduces a novel representation learning method DTFormer for
DTDGs, pivoting from the traditional GNN+RNN framework to a Transformer-based
architecture. Our approach exploits the attention mechanism to concurrently
process topological information within the graph at each timestamp and temporal
dynamics of graphs along the timestamps, circumventing the aforementioned
fundamental weakness of both GNNs and RNNs. Moreover, we enhance the model's
expressive capability by incorporating the intersection relationships among
nodes and integrating a multi-patching module. Extensive experiments conducted
on six public dynamic graph benchmark datasets confirm our model's efficacy,
achieving the SOTA performance.",2024-07-26,"Xi Chen, Yun Xiong, Siwei Zhang, Jiawei Zhang, Yao Zhang, Shiyang Zhou, Xixi Wu, Mingyang Zhang, Tengfei Liu, Weiqiang Wang",http://arxiv.org/pdf/2407.18523v1,cs.LG
Spatial Temporal Approach for High-Resolution Gridded Wind Forecasting across Southwest Western Australia,"Accurate wind speed and direction forecasting is paramount across many
sectors, spanning agriculture, renewable energy generation, and bushfire
management. However, conventional forecasting models encounter significant
challenges in precisely predicting wind conditions at high spatial resolutions
for individual locations or small geographical areas (< 20 km2) and capturing
medium to long-range temporal trends and comprehensive spatio-temporal
patterns. This study focuses on a spatial temporal approach for high-resolution
gridded wind forecasting at the height of 3 and 10 metres across large areas of
the Southwest of Western Australia to overcome these challenges. The model
utilises the data that covers a broad geographic area and harnesses a diverse
array of meteorological factors, including terrain characteristics, air
pressure, 10-metre wind forecasts from the European Centre for Medium-Range
Weather Forecasts, and limited observation data from sparsely distributed
weather stations (such as 3-metre wind profiles, humidity, and temperature),
the model demonstrates promising advancements in wind forecasting accuracy and
reliability across the entire region of interest. This paper shows the
potential of our machine learning model for wind forecasts across various
prediction horizons and spatial coverage. It can help facilitate more informed
decision-making and enhance resilience across critical sectors.",2024-07-26,"Fuling Chen, Kevin Vinsen, Arthur Filoche",http://arxiv.org/pdf/2407.20283v1,cs.LG
TCGPN: Temporal-Correlation Graph Pre-trained Network for Stock Forecasting,"Recently, the incorporation of both temporal features and the correlation
across time series has become an effective approach in time series prediction.
Spatio-Temporal Graph Neural Networks (STGNNs) demonstrate good performance on
many Temporal-correlation Forecasting Problem. However, when applied to tasks
lacking periodicity, such as stock data prediction, the effectiveness and
robustness of STGNNs are found to be unsatisfactory. And STGNNs are limited by
memory savings so that cannot handle problems with a large number of nodes. In
this paper, we propose a novel approach called the Temporal-Correlation Graph
Pre-trained Network (TCGPN) to address these limitations. TCGPN utilize
Temporal-correlation fusion encoder to get a mixed representation and
pre-training method with carefully designed temporal and correlation
pre-training tasks. Entire structure is independent of the number and order of
nodes, so better results can be obtained through various data enhancements. And
memory consumption during training can be significantly reduced through
multiple sampling. Experiments are conducted on real stock market data sets
CSI300 and CSI500 that exhibit minimal periodicity. We fine-tune a simple MLP
in downstream tasks and achieve state-of-the-art results, validating the
capability to capture more robust temporal correlation patterns.",2024-07-26,"Wenbo Yan, Ying Tan",http://arxiv.org/pdf/2407.18519v1,cs.LG
WorkR: Occupation Inference for Intelligent Task Assistance,"Occupation information can be utilized by digital assistants to provide
occupation-specific personalized task support, including interruption
management, task planning, and recommendations. Prior research in the digital
workplace assistant domain requires users to input their occupation information
for effective support. However, as many individuals switch between multiple
occupations daily, current solutions falter without continuous user input. To
address this, this study introduces WorkR, a framework that leverages passive
sensing to capture pervasive signals from various task activities, addressing
three challenges: the lack of a passive sensing architecture, personalization
of occupation characteristics, and discovering latent relationships among
occupation variables. We argue that signals from application usage, movements,
social interactions, and the environment can inform a user's occupation. WorkR
uses a Variational Autoencoder (VAE) to derive latent features for training
models to infer occupations. Our experiments with an anonymized, context-rich
activity and task log dataset demonstrate that our models can accurately infer
occupations with more than 91% accuracy across six ISO occupation categories.",2024-07-26,"Yonchanok Khaokaew, Hao Xue, Mohammad Saiedur Rahaman, Flora D. Salim",http://arxiv.org/pdf/2407.18518v1,cs.LG
The formation of perceptual space in early phonetic acquisition: a cross-linguistic modeling approach,"This study investigates how learners organize perceptual space in early
phonetic acquisition by advancing previous studies in two key aspects. Firstly,
it examines the shape of the learned hidden representation as well as its
ability to categorize phonetic categories. Secondly, it explores the impact of
training models on context-free acoustic information, without involving
contextual cues, on phonetic acquisition, closely mimicking the early language
learning stage. Using a cross-linguistic modeling approach, autoencoder models
are trained on English and Mandarin and evaluated in both native and non-native
conditions, following experimental conditions used in infant language
perception studies. The results demonstrate that unsupervised bottom-up
training on context-free acoustic information leads to comparable learned
representations of perceptual space between native and non-native conditions
for both English and Mandarin, resembling the early stage of universal
listening in infants. These findings provide insights into the organization of
perceptual space during early phonetic acquisition and contribute to our
understanding of the formation and representation of phonetic categories.",2024-07-26,"Frank Lihui Tan, Youngah Do",http://arxiv.org/pdf/2407.18501v1,cs.LG
"Towards More Accurate Prediction of Human Empathy and Emotion in Text and Multi-turn Conversations by Combining Advanced NLP, Transformers-based Networks, and Linguistic Methodologies","Based on the WASSA 2022 Shared Task on Empathy Detection and Emotion
Classification, we predict the level of empathic concern and personal distress
displayed in essays. For the first stage of this project we implemented a
Feed-Forward Neural Network using sentence-level embeddings as features. We
experimented with four different embedding models for generating the inputs to
the neural network. The subsequent stage builds upon the previous work and we
have implemented three types of revisions. The first revision focuses on the
enhancements to the model architecture and the training approach. The second
revision focuses on handling class imbalance using stratified data sampling.
The third revision focuses on leveraging lexical resources, where we apply four
different resources to enrich the features associated with the dataset. During
the final stage of this project, we have created the final end-to-end system
for the primary task using an ensemble of models to revise primary task
performance. Additionally, as part of the final stage, these approaches have
been adapted to the WASSA 2023 Shared Task on Empathy Emotion and Personality
Detection in Interactions, in which the empathic concern, emotion polarity, and
emotion intensity in dyadic text conversations are predicted.",2024-07-26,"Manisha Singh, Divy Sharma, Alonso Ma, Nora Goldfine",http://arxiv.org/pdf/2407.18496v1,cs.LG
Conversational Dueling Bandits in Generalized Linear Models,"Conversational recommendation systems elicit user preferences by interacting
with users to obtain their feedback on recommended commodities. Such systems
utilize a multi-armed bandit framework to learn user preferences in an online
manner and have received great success in recent years. However, existing
conversational bandit methods have several limitations. First, they only enable
users to provide explicit binary feedback on the recommended items or
categories, leading to ambiguity in interpretation. In practice, users are
usually faced with more than one choice. Relative feedback, known for its
informativeness, has gained increasing popularity in recommendation system
design. Moreover, current contextual bandit methods mainly work under linear
reward assumptions, ignoring practical non-linear reward structures in
generalized linear models. Therefore, in this paper, we introduce relative
feedback-based conversations into conversational recommendation systems through
the integration of dueling bandits in generalized linear models (GLM) and
propose a novel conversational dueling bandit algorithm called ConDuel.
Theoretical analyses of regret upper bounds and empirical validations on
synthetic and real-world data underscore ConDuel's efficacy. We also
demonstrate the potential to extend our algorithm to multinomial logit bandits
with theoretical and experimental guarantees, which further proves the
applicability of the proposed framework.",2024-07-26,"Shuhua Yang, Hui Yuan, Xiaoying Zhang, Mengdi Wang, Hong Zhang, Huazheng Wang",http://arxiv.org/pdf/2407.18488v1,cs.LG
NeuSemSlice: Towards Effective DNN Model Maintenance via Neuron-level Semantic Slicing,"Deep Neural networks (DNNs), extensively applied across diverse disciplines,
are characterized by their integrated and monolithic architectures, setting
them apart from conventional software systems. This architectural difference
introduces particular challenges to maintenance tasks, such as model
restructuring (e.g., model compression), re-adaptation (e.g., fitting new
samples), and incremental development (e.g., continual knowledge accumulation).
Prior research addresses these challenges by identifying task-critical neuron
layers, and dividing neural networks into semantically-similar sequential
modules. However, such layer-level approaches fail to precisely identify and
manipulate neuron-level semantic components, restricting their applicability to
finer-grained model maintenance tasks. In this work, we implement NeuSemSlice,
a novel framework that introduces the semantic slicing technique to effectively
identify critical neuron-level semantic components in DNN models for
semantic-aware model maintenance tasks. Specifically, semantic slicing
identifies, categorizes and merges critical neurons across different categories
and layers according to their semantic similarity, enabling their flexibility
and effectiveness in the subsequent tasks. For semantic-aware model maintenance
tasks, we provide a series of novel strategies based on semantic slicing to
enhance NeuSemSlice. They include semantic components (i.e., critical neurons)
preservation for model restructuring, critical neuron tuning for model
re-adaptation, and non-critical neuron training for model incremental
development. A thorough evaluation has demonstrated that NeuSemSlice
significantly outperforms baselines in all three tasks.",2024-07-26,"Shide Zhou, Tianlin Li, Yihao Huang, Ling Shi, Kailong Wang, Yang Liu, Haoyu Wang",http://arxiv.org/pdf/2407.20281v1,cs.LG
Practical Attribution Guidance for Rashomon Sets,"Different prediction models might perform equally well (Rashomon set) in the
same task, but offer conflicting interpretations and conclusions about the
data. The Rashomon effect in the context of Explainable AI (XAI) has been
recognized as a critical factor. Although the Rashomon set has been introduced
and studied in various contexts, its practical application is at its infancy
stage and lacks adequate guidance and evaluation. We study the problem of the
Rashomon set sampling from a practical viewpoint and identify two fundamental
axioms - generalizability and implementation sparsity that exploring methods
ought to satisfy in practical usage. These two axioms are not satisfied by most
known attribution methods, which we consider to be a fundamental weakness. We
use the norms to guide the design of an $\epsilon$-subgradient-based sampling
method. We apply this method to a fundamental mathematical problem as a proof
of concept and to a set of practical datasets to demonstrate its ability
compared with existing sampling methods.",2024-07-26,"Sichao Li, Amanda S. Barnard, Quanling Deng",http://arxiv.org/pdf/2407.18482v1,cs.LG
Scalable Graph Compressed Convolutions,"Designing effective graph neural networks (GNNs) with message passing has two
fundamental challenges, i.e., determining optimal message-passing pathways and
designing local aggregators. Previous methods of designing optimal pathways are
limited with information loss on the input features. On the other hand,
existing local aggregators generally fail to extract multi-scale features and
approximate diverse operators under limited parameter scales. In contrast to
these methods, Euclidean convolution has been proven as an expressive
aggregator, making it a perfect candidate for GNN construction. However, the
challenges of generalizing Euclidean convolution to graphs arise from the
irregular structure of graphs. To bridge the gap between Euclidean space and
graph topology, we propose a differentiable method that applies permutations to
calibrate input graphs for Euclidean convolution. The permutations constrain
all nodes in a row regardless of their input order and therefore enable the
flexible generalization of Euclidean convolution to graphs. Based on the graph
calibration, we propose the Compressed Convolution Network (CoCN) for
hierarchical graph representation learning. CoCN follows local feature-learning
and global parameter-sharing mechanisms of convolution neural networks. The
whole model can be trained end-to-end, with compressed convolution applied to
learn individual node features and their corresponding structure features. CoCN
can further borrow successful practices from Euclidean convolution, including
residual connection and inception mechanism. We validate CoCN on both
node-level and graph-level benchmarks. CoCN achieves superior performance over
competitive GNN baselines. Codes are available at
https://github.com/sunjss/CoCN.",2024-07-26,"Junshu Sun, Shuhui Wang, Chenxue Yang, Qingming Huang",http://arxiv.org/pdf/2407.18480v2,cs.LG
FedUD: Exploiting Unaligned Data for Cross-Platform Federated Click-Through Rate Prediction,"Click-through rate (CTR) prediction plays an important role in online
advertising platforms. Most existing methods use data from the advertising
platform itself for CTR prediction. As user behaviors also exist on many other
platforms, e.g., media platforms, it is beneficial to further exploit such
complementary information for better modeling user interest and for improving
CTR prediction performance. However, due to privacy concerns, data from
different platforms cannot be uploaded to a server for centralized model
training. Vertical federated learning (VFL) provides a possible solution which
is able to keep the raw data on respective participating parties and learn a
collaborative model in a privacy-preserving way. However, traditional VFL
methods only utilize aligned data with common keys across parties, which
strongly restricts their application scope. In this paper, we propose FedUD,
which is able to exploit unaligned data, in addition to aligned data, for more
accurate federated CTR prediction. FedUD contains two steps. In the first step,
FedUD utilizes aligned data across parties like traditional VFL, but it
additionally includes a knowledge distillation module. This module distills
useful knowledge from the guest party's high-level representations and guides
the learning of a representation transfer network. In the second step, FedUD
applies the learned knowledge to enrich the representations of the host party's
unaligned data such that both aligned and unaligned data can contribute to
federated model training. Experiments on two real-world datasets demonstrate
the superior performance of FedUD for federated CTR prediction.",2024-07-26,"Wentao Ouyang, Rui Dong, Ri Tao, Xiangzheng Liu",http://arxiv.org/pdf/2407.18472v1,cs.LG
Constructing the CORD-19 Vaccine Dataset,"We introduce new dataset 'CORD-19-Vaccination' to cater to scientists
specifically looking into COVID-19 vaccine-related research. This dataset is
extracted from CORD-19 dataset [Wang et al., 2020] and augmented with new
columns for language detail, author demography, keywords, and topic per paper.
Facebook's fastText model is used to identify languages [Joulin et al., 2016].
To establish author demography (author affiliation, lab/institution location,
and lab/institution country columns) we processed the JSON file for each paper
and then further enhanced using Google's search API to determine country
values. 'Yake' was used to extract keywords from the title, abstract, and body
of each paper and the LDA (Latent Dirichlet Allocation) algorithm was used to
add topic information [Campos et al., 2020, 2018a,b]. To evaluate the dataset,
we demonstrate a question-answering task like the one used in the CORD-19
Kaggle challenge [Goldbloom et al., 2022]. For further evaluation, sequential
sentence classification was performed on each paper's abstract using the model
from Dernoncourt et al. [2016]. We partially hand annotated the training
dataset and used a pre-trained BERT-PubMed layer. 'CORD- 19-Vaccination'
contains 30k research papers and can be immensely valuable for NLP research
such as text mining, information extraction, and question answering, specific
to the domain of COVID-19 vaccine research.",2024-07-26,"Manisha Singh, Divy Sharma, Alonso Ma, Bridget Tyree, Margaret Mitchell",http://arxiv.org/pdf/2407.18471v1,cs.LG
Diffusion-Driven Semantic Communication for Generative Models with Bandwidth Constraints,"Diffusion models have been extensively utilized in AI-generated content
(AIGC) in recent years, thanks to the superior generation capabilities.
Combining with semantic communications, diffusion models are used for tasks
such as denoising, data reconstruction, and content generation. However,
existing diffusion-based generative models do not consider the stringent
bandwidth limitation, which limits its application in wireless communication.
This paper introduces a diffusion-driven semantic communication framework with
advanced VAE-based compression for bandwidth-constrained generative model. Our
designed architecture utilizes the diffusion model, where the signal
transmission process through the wireless channel acts as the forward process
in diffusion. To reduce bandwidth requirements, we incorporate a downsampling
module and a paired upsampling module based on a variational auto-encoder with
reparameterization at the receiver to ensure that the recovered features
conform to the Gaussian distribution. Furthermore, we derive the loss function
for our proposed system and evaluate its performance through comprehensive
experiments. Our experimental results demonstrate significant improvements in
pixel-level metrics such as peak signal to noise ratio (PSNR) and semantic
metrics like learned perceptual image patch similarity (LPIPS). These
enhancements are more profound regarding the compression rates and SNR compared
to deep joint source-channel coding (DJSCC).",2024-07-26,"Lei Guo, Wei Chen, Yuxuan Sun, Bo Ai, Nikolaos Pappas, Tony Quek",http://arxiv.org/pdf/2407.18468v3,cs.LG
Machine Unlearning using a Multi-GAN based Model,"This article presents a new machine unlearning approach that utilizes
multiple Generative Adversarial Network (GAN) based models. The proposed method
comprises two phases: i) data reorganization in which synthetic data using the
GAN model is introduced with inverted class labels of the forget datasets, and
ii) fine-tuning the pre-trained model. The GAN models consist of two pairs of
generators and discriminators. The generator discriminator pairs generate
synthetic data for the retain and forget datasets. Then, a pre-trained model is
utilized to get the class labels of the synthetic datasets. The class labels of
synthetic and original forget datasets are inverted. Finally, all combined
datasets are used to fine-tune the pre-trained model to get the unlearned
model. We have performed the experiments on the CIFAR-10 dataset and tested the
unlearned models using Membership Inference Attacks (MIA). The inverted class
labels procedure and synthetically generated data help to acquire valuable
information that enables the model to outperform state-of-the-art models and
other standard unlearning classifiers.",2024-07-26,"Amartya Hatua, Trung T. Nguyen, Andrew H. Sung",http://arxiv.org/pdf/2407.18467v1,cs.LG
MistralBSM: Leveraging Mistral-7B for Vehicular Networks Misbehavior Detection,"Vehicular networks are exposed to various threats resulting from malicious
attacks. These threats compromise the security and reliability of
communications among road users, thereby jeopardizing road and traffic safety.
One of the main vectors of these attacks within vehicular networks is
misbehaving vehicles. To address this challenge, we propose deploying a
pretrained Large Language Model (LLM)-empowered Misbehavior Detection System
(MDS) within an edge-cloud detection framework. Specifically, we fine-tune
Mistral-7B, a state-of-the-art LLM, as the edge component to enable real-time
detection, whereas a larger LLM deployed in the cloud can conduct a more
comprehensive analysis. Our experiments conducted on the extended VeReMi
dataset demonstrate Mistral-7B's superior performance, achieving 98\% accuracy
compared to other LLMs such as LLAMA2-7B and RoBERTa. Additionally, we
investigate the impact of window size on computational costs to optimize
deployment efficiency. Leveraging LLMs in MDS shows interesting results in
improving the detection of vehicle misbehavior, consequently strengthening
vehicular network security to ensure the safety of road users.",2024-07-26,"Wissal Hamhoum, Soumaya Cherkaoui",http://arxiv.org/pdf/2407.18462v1,cs.LG
Fairness Definitions in Language Models Explained,"Language Models (LMs) have demonstrated exceptional performance across
various Natural Language Processing (NLP) tasks. Despite these advancements,
LMs can inherit and amplify societal biases related to sensitive attributes
such as gender and race, limiting their adoption in real-world applications.
Therefore, fairness has been extensively explored in LMs, leading to the
proposal of various fairness notions. However, the lack of clear agreement on
which fairness definition to apply in specific contexts (\textit{e.g.,}
medium-sized LMs versus large-sized LMs) and the complexity of understanding
the distinctions between these definitions can create confusion and impede
further progress. To this end, this paper proposes a systematic survey that
clarifies the definitions of fairness as they apply to LMs. Specifically, we
begin with a brief introduction to LMs and fairness in LMs, followed by a
comprehensive, up-to-date overview of existing fairness notions in LMs and the
introduction of a novel taxonomy that categorizes these concepts based on their
foundational principles and operational distinctions. We further illustrate
each definition through experiments, showcasing their practical implications
and outcomes. Finally, we discuss current research challenges and open
questions, aiming to foster innovative ideas and advance the field. The
implementation and additional resources are publicly available at
https://github.com/LavinWong/Fairness-in-Large-Language-Models/tree/main/definitions.",2024-07-26,"Thang Viet Doan, Zhibo Chu, Zichong Wang, Wenbin Zhang",http://arxiv.org/pdf/2407.18454v1,cs.LG
Textile Anomaly Detection: Evaluation of the State-of-the-Art for Automated Quality Inspection of Carpet,"In this study, state-of-the-art unsupervised detection models were evaluated
for the purpose of automated anomaly inspection of wool carpets. A custom
dataset of four unique types of carpet textures was created to thoroughly test
the models and their robustness in detecting subtle anomalies in complex
textures. Due to the requirements of an inline inspection system in a
manufacturing use case, the metrics of importance in this study were accuracy
in detecting anomalous areas, the number of false detections, and the inference
times of each model for real-time performance. Of the evaluated models, the
student-teacher network based methods were found on average to yield the
highest detection accuracy and lowest false detection rates. When trained on a
multi-class dataset the models were found to yield comparable if not better
results than single-class training. Finally, in terms of detection speed, with
exception to the generative model, all other evaluated models were found to
have comparable inference times on a GPU, with an average of 0.16s per image.
On a CPU, most of these models typically produced results between 1.5 to 2
times the respective GPU inference times.",2024-07-26,"Briony Forsberg, Dr Henry Williams, Prof Bruce MacDonald, Tracy Chen, Dr Kirstine Hulse",http://arxiv.org/pdf/2407.18450v1,cs.LG
Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation,"Foundation models pretrained on large-scale datasets are revolutionizing the
field of computational pathology (CPath). The generalization ability of
foundation models is crucial for the success in various downstream clinical
tasks. However, current foundation models have only been evaluated on a limited
type and number of tasks, leaving their generalization ability and overall
performance unclear. To address this gap, we established a most comprehensive
benchmark to evaluate the performance of off-the-shelf foundation models across
six distinct clinical task types, encompassing a total of 72 specific tasks,
including slide-level classification, survival prediction, ROI-tissue
classification, ROI retrieval, visual question answering, and report
generation. Our findings reveal that existing foundation models excel at
certain task types but struggle to effectively handle the full breadth of
clinical tasks. To improve the generalization of pathology foundation models,
we propose a unified knowledge distillation framework consisting of both expert
and self-knowledge distillation, where the former allows the model to learn
from the knowledge of multiple expert models, while the latter leverages
self-distillation to enable image representation learning via local-global
alignment. Based on this framework, we curated a dataset of 96,000 whole slide
images (WSIs) and developed a Generalizable Pathology Foundation Model (GPFM).
This advanced model was trained on a substantial dataset comprising 190 million
images extracted from approximately 72,000 publicly available slides,
encompassing 34 major tissue types. Evaluated on the established benchmark,
GPFM achieves an impressive average rank of 1.6, with 42 tasks ranked 1st,
while the second-best model, UNI, attains an average rank of 3.7, with only 6
tasks ranked 1st.",2024-07-26,"Jiabo Ma, Zhengrui Guo, Fengtao Zhou, Yihui Wang, Yingxue Xu, Jinbang Li, Fang Yan, Yu Cai, Zhengjie Zhu, Cheng Jin, Yi Lin, Xinrui Jiang, Chenglong Zhao, Danyi Li, Anjia Han, Zhenhui Li, Ronald Cheong Kin Chan, Jiguang Wang, Peng Fei, Kwang-Ting Cheng, Shaoting Zhang, Li Liang, Hao Chen",http://arxiv.org/pdf/2407.18449v3,cs.LG
Impact of Recurrent Neural Networks and Deep Learning Frameworks on Real-time Lightweight Time Series Anomaly Detection,"Real-time lightweight time series anomaly detection has become increasingly
crucial in cybersecurity and many other domains. Its ability to adapt to
unforeseen pattern changes and swiftly identify anomalies enables prompt
responses and critical decision-making. While several such anomaly detection
approaches have been introduced in recent years, they primarily utilize a
single type of recurrent neural networks (RNNs) and have been implemented in
only one deep learning framework. It is unclear how the use of different types
of RNNs available in various deep learning frameworks affects the performance
of these anomaly detection approaches due to the absence of comprehensive
evaluations. Arbitrarily choosing a RNN variant and a deep learning framework
to implement an anomaly detection approach may not reflect its true performance
and could potentially mislead users into favoring one approach over another. In
this paper, we aim to study the influence of various types of RNNs available in
popular deep learning frameworks on real-time lightweight time series anomaly
detection. We reviewed several state-of-the-art approaches and implemented a
representative anomaly detection approach using well-known RNN variants
supported by three widely recognized deep learning frameworks. A comprehensive
evaluation is then conducted to analyze the performance of each implementation
across real-world, open-source time series datasets. The evaluation results
provide valuable guidance for selecting the appropriate RNN variant and deep
learning framework for real-time, lightweight time series anomaly detection.",2024-07-26,"Ming-Chang Lee, Jia-Chun Lin, Sokratis Katsikas",http://arxiv.org/pdf/2407.18439v1,cs.LG
Robust and Efficient Transfer Learning via Supernet Transfer in Warm-started Neural Architecture Search,"Hand-designing Neural Networks is a tedious process that requires significant
expertise. Neural Architecture Search (NAS) frameworks offer a very useful and
popular solution that helps to democratize AI. However, these NAS frameworks
are often computationally expensive to run, which limits their applicability
and accessibility. In this paper, we propose a novel transfer learning
approach, capable of effectively transferring pretrained supernets based on
Optimal Transport or multi-dataset pretaining. This method can be generally
applied to NAS methods based on Differentiable Architecture Search (DARTS).
Through extensive experiments across dozens of image classification tasks, we
demonstrate that transferring pretrained supernets in this way can not only
drastically speed up the supernet training which then finds optimal models (3
to 5 times faster on average), but even yield that outperform those found when
running DARTS methods from scratch. We also observe positive transfer to almost
all target datasets, making it very robust. Besides drastically improving the
applicability of NAS methods, this also opens up new applications for continual
learning and related fields.",2024-07-26,"Prabhant Singh, Joaquin Vanschoren",http://arxiv.org/pdf/2407.20279v1,cs.LG
A Model for Combinatorial Dictionary Learning and Inference,"We are often interested in decomposing complex, structured data into simple
components that explain the data. The linear version of this problem is
well-studied as dictionary learning and factor analysis. In this work, we
propose a combinatorial model in which to study this question, motivated by the
way objects occlude each other in a scene to form an image. First, we identify
a property we call ""well-structuredness"" of a set of low-dimensional components
which ensures that no two components in the set are too similar. We show how
well-structuredness is sufficient for learning the set of latent components
comprising a set of sample instances. We then consider the problem: given a set
of components and an instance generated from some unknown subset of them,
identify which parts of the instance arise from which components. We consider
two variants: (1) determine the minimal number of components required to
explain the instance; (2) determine the correct explanation for as many
locations as possible. For the latter goal, we also devise a version that is
robust to adversarial corruptions, with just a slightly stronger assumption on
the components. Finally, we show that the learning problem is computationally
infeasible in the absence of any assumptions.",2024-07-26,"Avrim Blum, Kavya Ravichandran",http://arxiv.org/pdf/2407.18436v1,cs.LG
Investigating the Privacy Risk of Using Robot Vacuum Cleaners in Smart Environments,"Robot vacuum cleaners have become increasingly popular and are widely used in
various smart environments. To improve user convenience, manufacturers also
introduced smartphone applications that enable users to customize cleaning
settings or access information about their robot vacuum cleaners. While this
integration enhances the interaction between users and their robot vacuum
cleaners, it results in potential privacy concerns because users' personal
information may be exposed. To address these concerns, end-to-end encryption is
implemented between the application, cloud service, and robot vacuum cleaners
to secure the exchanged information. Nevertheless, network header metadata
remains unencrypted and it is still vulnerable to network eavesdropping. In
this paper, we investigate the potential risk of private information exposure
through such metadata. A popular robot vacuum cleaner was deployed in a real
smart environment where passive network eavesdropping was conducted during
several selected cleaning events. Our extensive analysis, based on Association
Rule Learning, demonstrates that it is feasible to identify certain events
using only the captured Internet traffic metadata, thereby potentially exposing
private user information and raising privacy concerns.",2024-07-26,"Benjamin Ulsmaag, Jia-Chun Lin, Ming-Chang Lee",http://arxiv.org/pdf/2407.18433v1,cs.LG
Weighted Risk Invariance: Domain Generalization under Invariant Feature Shift,"Learning models whose predictions are invariant under multiple environments
is a promising approach for out-of-distribution generalization. Such models are
trained to extract features $X_{\text{inv}}$ where the conditional distribution
$Y \mid X_{\text{inv}}$ of the label given the extracted features does not
change across environments. Invariant models are also supposed to generalize to
shifts in the marginal distribution $p(X_{\text{inv}})$ of the extracted
features $X_{\text{inv}}$, a type of shift we call an $\textit{invariant
covariate shift}$. However, we show that proposed methods for learning
invariant models underperform under invariant covariate shift, either failing
to learn invariant models$\unicode{x2014}$even for data generated from simple
and well-studied linear-Gaussian models$\unicode{x2014}$or having poor
finite-sample performance. To alleviate these problems, we propose
$\textit{weighted risk invariance}$ (WRI). Our framework is based on imposing
invariance of the loss across environments subject to appropriate reweightings
of the training examples. We show that WRI provably learns invariant models,
i.e. discards spurious correlations, in linear-Gaussian settings. We propose a
practical algorithm to implement WRI by learning the density
$p(X_{\text{inv}})$ and the model parameters simultaneously, and we demonstrate
empirically that WRI outperforms previous invariant learning methods under
invariant covariate shift.",2024-07-25,"Gina Wong, Joshua Gleason, Rama Chellappa, Yoav Wald, Anqi Liu",http://arxiv.org/pdf/2407.18428v1,cs.LG
Diffusion-based subsurface CO$_2$ multiphysics monitoring and forecasting,"Carbon capture and storage (CCS) plays a crucial role in mitigating
greenhouse gas emissions, particularly from industrial outputs. Using seismic
monitoring can aid in an accurate and robust monitoring system to ensure the
effectiveness of CCS and mitigate associated risks. However, conventional
seismic wave equation-based approaches are computationally demanding, which
hinders real-time applications. In addition to efficiency, forecasting and
uncertainty analysis are not easy to handle using such
numerical-simulation-based approaches. To this end, we propose a novel
subsurface multiphysics monitoring and forecasting framework utilizing video
diffusion models. This approach can generate high-quality representations of
CO$2$ evolution and associated changes in subsurface elastic properties. With
reconstruction guidance, forecasting and inversion can be achieved conditioned
on historical frames and/or observational data. Meanwhile, due to the
generative nature of the approach, we can quantify uncertainty in the
prediction. Tests based on the Compass model show that the proposed method
successfully captured the inherently complex physical phenomena associated with
CO$_2$ monitoring, and it can predict and invert the subsurface elastic
properties and CO$_2$ saturation with consistency in their evolution.",2024-07-25,"Xinquan Huang, Fu Wang, Tariq Alkhalifah",http://arxiv.org/pdf/2407.18426v3,cs.LG
IntentRec: Predicting User Session Intent with Hierarchical Multi-Task Learning,"Recommender systems have played a critical role in diverse digital services
such as e-commerce, streaming media, social networks, etc. If we know what a
user's intent is in a given session (e.g. do they want to watch short videos or
a movie or play games; are they shopping for a camping trip), it becomes easier
to provide high-quality recommendations. In this paper, we introduce IntentRec,
a novel recommendation framework based on hierarchical multi-task neural
network architecture that tries to estimate a user's latent intent using their
short- and long-term implicit signals as proxies and uses the intent prediction
to predict the next item user is likely to engage with. By directly leveraging
the intent prediction, we can offer accurate and personalized recommendations
to users. Our comprehensive experiments on Netflix user engagement data show
that IntentRec outperforms the state-of-the-art next-item and next-intent
predictors. We also share several findings and downstream applications of
IntentRec.",2024-07-25,"Sejoon Oh, Moumita Bhattacharya, Yesu Feng, Sudarshan Lamkhede",http://arxiv.org/pdf/2408.05353v2,cs.LG
Model-driven Heart Rate Estimation and Heart Murmur Detection based on Phonocardiogram,"Acoustic signals are crucial for health monitoring, particularly heart sounds
which provide essential data like heart rate and detect cardiac anomalies such
as murmurs. This study utilizes a publicly available phonocardiogram (PCG)
dataset to estimate heart rate using model-driven methods and extends the
best-performing model to a multi-task learning (MTL) framework for simultaneous
heart rate estimation and murmur detection. Heart rate estimates are derived
using a sliding window technique on heart sound snippets, analyzed with a
combination of acoustic features (Mel spectrogram, cepstral coefficients, power
spectral density, root mean square energy). Our findings indicate that a 2D
convolutional neural network (\textbf{\texttt{2dCNN}}) is most effective for
heart rate estimation, achieving a mean absolute error (MAE) of 1.312 bpm. We
systematically investigate the impact of different feature combinations and
find that utilizing all four features yields the best results. The MTL model
(\textbf{\texttt{2dCNN-MTL}}) achieves accuracy over 95% in murmur detection,
surpassing existing models, while maintaining an MAE of 1.636 bpm in heart rate
estimation, satisfying the requirements stated by Association for the
Advancement of Medical Instrumentation (AAMI).",2024-07-25,"Jingping Nie, Ran Liu, Behrooz Mahasseni, Erdrin Azemi, Vikramjit Mitra",http://arxiv.org/pdf/2407.18424v1,cs.LG
HDL-GPT: High-Quality HDL is All You Need,"This paper presents Hardware Description Language Generative Pre-trained
Transformers (HDL-GPT), a novel approach that leverages the vast repository of
open-source High Definition Language (HDL) codes to train superior quality
large code models. The core premise of this paper is the hypothesis that
high-quality HDL is all you need to create models with exceptional performance
and broad zero-shot generalization abilities. The paper elucidates the methods
employed for the curation and augmentation of large corpora from open-source
HDL code, transforming highly variable quality data into high-quality data
through careful prompting and context maintenance. We demonstrate that the
careful selection, filtering, and augmentation of data across HDLs can yield
powerful models that surpass current state-of-the-art models. We also explore
the impact of different fine-tuning methods on the quality of results. We
describe experimental results across a range of fine-tuned SOTA LLMs,
substantiating our claims. We demonstrate improvements of 50% to 200% over SOTA
HDL models on current benchmarks in tasks ranging from HDL circuit
explanations, code generation, formal and simulation testbench creation,
triaging bugs, and fixing them. HDL-GPT opens new avenues for the development
of advanced model training techniques for circuit design tasks.",2024-07-25,"Bhuvnesh Kumar, Saurav Nanda, Ganapathy Parthasarathy, Pawan Patil, Austin Tsai, Parivesh Choudhary",http://arxiv.org/pdf/2407.18423v1,cs.LG
A Black Swan Hypothesis: The Role of Human Irrationality in AI Safety,"Black swan events are statistically rare occurrences that carry extremely
high risks. A typical view of defining black swan events is heavily assumed to
originate from an unpredictable time-varying environments; however, the
community lacks a comprehensive definition of black swan events. To this end,
this paper challenges that the standard view is incomplete and claims that
high-risk, statistically rare events can also occur in unchanging environments
due to human misperception of their value and likelihood, which we call as
spatial black swan event. We first carefully categorize black swan events,
focusing on spatial black swan events, and mathematically formalize the
definition of black swan events. We hope these definitions can pave the way for
the development of algorithms to prevent such events by rationally correcting
human perception.",2024-07-25,"Hyunin Lee, Chanwoo Park, David Abel, Ming Jin",http://arxiv.org/pdf/2407.18422v3,cs.LG
Self-Directed Synthetic Dialogues and Revisions Technical Report,"Synthetic data has become an important tool in the fine-tuning of language
models to follow instructions and solve complex problems. Nevertheless, the
majority of open data to date is often lacking multi-turn data and collected on
closed models, limiting progress on advancing open fine-tuning methods. We
introduce Self Directed Synthetic Dialogues (SDSD), an experimental dataset
consisting of guided conversations of language models talking to themselves.
The dataset consists of multi-turn conversations generated with DBRX, Llama 2
70B, and Mistral Large, all instructed to follow a conversation plan generated
prior to the conversation. We also explore including principles from
Constitutional AI and other related works to create synthetic preference data
via revisions to the final conversation turn. We hope this work encourages
further exploration in multi-turn data and the use of open models for expanding
the impact of synthetic data.",2024-07-25,"Nathan Lambert, Hailey Schoelkopf, Aaron Gokaslan, Luca Soldaini, Valentina Pyatkin, Louis Castricato",http://arxiv.org/pdf/2407.18421v1,cs.LG
PersonaGym: Evaluating Persona Agents and LLMs,"Persona agents, which are LLM agents conditioned to act according to an
assigned persona, enable contextually rich and user aligned interactions across
domains like education and healthcare. However, evaluating how faithfully these
agents adhere to their personas remains a significant challenge, particularly
in free-form settings that demand consistency across diverse, persona-relevant
environments. We introduce PersonaGym, the first dynamic evaluation framework
for persona agents, and PersonaScore, a human-aligned automatic metric grounded
in decision theory that enables comprehensive large-scale evaluation. Our
evaluation of 10 leading LLMs across 200 personas and 10,000 questions reveals
significant advancement opportunities. For example, GPT-4.1 had the exact same
PersonaScore as LLaMA-3-8b despite being a more recent and advanced closed
source model. Importantly, increased model size and complexity do not
necessarily enhance persona agent capabilities, underscoring the need for
algorithmic and architectural innovation toward faithful, performant persona
agents.",2024-07-25,"Vinay Samuel, Henry Peng Zou, Yue Zhou, Shreyas Chaudhari, Ashwin Kalyan, Tanmay Rajpurohit, Ameet Deshpande, Karthik Narasimhan, Vishvak Murahari",http://arxiv.org/pdf/2407.18416v4,cs.LG
Adversarially Robust Decision Transformer,"Decision Transformer (DT), as one of the representative Reinforcement
Learning via Supervised Learning (RvS) methods, has achieved strong performance
in offline learning tasks by leveraging the powerful Transformer architecture
for sequential decision-making. However, in adversarial environments, these
methods can be non-robust, since the return is dependent on the strategies of
both the decision-maker and adversary. Training a probabilistic model
conditioned on observed return to predict action can fail to generalize, as the
trajectories that achieve a return in the dataset might have done so due to a
suboptimal behavior adversary. To address this, we propose a worst-case-aware
RvS algorithm, the Adversarially Robust Decision Transformer (ARDT), which
learns and conditions the policy on in-sample minimax returns-to-go. ARDT
aligns the target return with the worst-case return learned through minimax
expectile regression, thereby enhancing robustness against powerful test-time
adversaries. In experiments conducted on sequential games with full data
coverage, ARDT can generate a maximin (Nash Equilibrium) strategy, the solution
with the largest adversarial robustness. In large-scale sequential games and
continuous adversarial RL environments with partial data coverage, ARDT
demonstrates significantly superior robustness to powerful test-time
adversaries and attains higher worst-case returns compared to contemporary DT
methods.",2024-07-25,"Xiaohang Tang, Afonso Marques, Parameswaran Kamalaruban, Ilija Bogunovic",http://arxiv.org/pdf/2407.18414v2,cs.LG
Simulation of Neural Responses to Classical Music Using Organoid Intelligence Methods,"Music is a complex auditory stimulus capable of eliciting significant changes
in brain activity, influencing cognitive processes such as memory, attention,
and emotional regulation. However, the underlying mechanisms of music-induced
cognitive processes remain largely unknown. Organoid intelligence and deep
learning models show promise for simulating and analyzing these neural
responses to classical music, an area significantly unexplored in computational
neuroscience. Hence, we present the PyOrganoid library, an innovative tool that
facilitates the simulation of organoid learning models, integrating
sophisticated machine learning techniques with biologically inspired organoid
simulations. Our study features the development of the Pianoid model, a ""deep
organoid learning"" model that utilizes a Bidirectional LSTM network to predict
EEG responses based on audio features from classical music recordings. This
model demonstrates the feasibility of using computational methods to replicate
complex neural processes, providing valuable insights into music perception and
cognition. Likewise, our findings emphasize the utility of synthetic models in
neuroscience research and highlight the PyOrganoid library's potential as a
versatile tool for advancing studies in neuroscience and artificial
intelligence.",2024-07-25,Daniel Szelogowski,http://arxiv.org/pdf/2407.18413v1,cs.LG
Large Language Model Integrated Healthcare Cyber-Physical Systems Architecture,"Cyber-physical systems have become an essential part of the modern healthcare
industry. The healthcare cyber-physical systems (HCPS) combine physical and
cyber components to improve the healthcare industry. While HCPS has many
advantages, it also has some drawbacks, such as a lengthy data entry process, a
lack of real-time processing, and limited real-time patient visualization. To
overcome these issues, this paper represents an innovative approach to
integrating large language model (LLM) to enhance the efficiency of the
healthcare system. By incorporating LLM at various layers, HCPS can leverage
advanced AI capabilities to improve patient outcomes, advance data processing,
and enhance decision-making.",2024-07-25,"Malithi Wanniarachchi Kankanamge, Syed Mhamudul Hasan, Abdur R. Shahid, Ning Yang",http://arxiv.org/pdf/2407.18407v1,cs.LG
RECOVAR: Representation Covariances on Deep Latent Spaces for Seismic Event Detection,"While modern deep learning methods have shown great promise in the problem of
earthquake detection, the most successful methods so far have been based on
supervised learning, which requires large datasets with ground-truth labels.
The curation of such datasets is both time consuming and prone to systematic
biases, which result in difficulties with cross-dataset generalization,
hindering general applicability. In this paper, we develop an unsupervised
method for earthquake detection that learns to detect earthquakes from raw
waveforms, without access to ground truth labels. The performance is comparable
to, and in some cases better than, some state-of-the-art supervised methods.
Moreover, the method has strong \emph{cross-dataset generalization}
performance. The algorithm utilizes deep autoencoders that learn to reproduce
the waveforms after a data-compressive bottleneck and uses a simple,
cross-covariance-based triggering algorithm at the bottleneck for labeling. The
approach has the potential to be useful for time series datasets from other
domains.",2024-07-25,"Onur Efe, Arkadas Ozakin",http://arxiv.org/pdf/2407.18402v2,cs.LG
Gaussian Process Kolmogorov-Arnold Networks,"In this paper, we introduce a probabilistic extension to Kolmogorov Arnold
Networks (KANs) by incorporating Gaussian Process (GP) as non-linear neurons,
which we refer to as GP-KAN. A fully analytical approach to handling the output
distribution of one GP as an input to another GP is achieved by considering the
function inner product of a GP function sample with the input distribution.
These GP neurons exhibit robust non-linear modelling capabilities while using
few parameters and can be easily and fully integrated in a feed-forward network
structure. They provide inherent uncertainty estimates to the model prediction
and can be trained directly on the log-likelihood objective function, without
needing variational lower bounds or approximations. In the context of MNIST
classification, a model based on GP-KAN of 80 thousand parameters achieved
98.5% prediction accuracy, compared to current state-of-the-art models with 1.5
million parameters.",2024-07-25,Andrew Siyuan Chen,http://arxiv.org/pdf/2407.18397v2,cs.LG
SCALE: Self-regulated Clustered federAted LEarning in a Homogeneous Environment,"Federated Learning (FL) has emerged as a transformative approach for enabling
distributed machine learning while preserving user privacy, yet it faces
challenges like communication inefficiencies and reliance on centralized
infrastructures, leading to increased latency and costs. This paper presents a
novel FL methodology that overcomes these limitations by eliminating the
dependency on edge servers, employing a server-assisted Proximity Evaluation
for dynamic cluster formation based on data similarity, performance indices,
and geographical proximity. Our integrated approach enhances operational
efficiency and scalability through a Hybrid Decentralized Aggregation Protocol,
which merges local model training with peer-to-peer weight exchange and a
centralized final aggregation managed by a dynamically elected driver node,
significantly curtailing global communication overhead. Additionally, the
methodology includes Decentralized Driver Selection, Check-pointing to reduce
network traffic, and a Health Status Verification Mechanism for system
robustness. Validated using the breast cancer dataset, our architecture not
only demonstrates a nearly tenfold reduction in communication overhead but also
shows remarkable improvements in reducing training latency and energy
consumption while maintaining high learning performance, offering a scalable,
efficient, and privacy-preserving solution for the future of federated learning
ecosystems.",2024-07-25,"Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Zahidur Talukder, Syed Bahauddin",http://arxiv.org/pdf/2407.18387v1,cs.LG
Mathematical theory of deep learning,"This book provides an introduction to the mathematical analysis of deep
learning. It covers fundamental results in approximation theory, optimization
theory, and statistical learning theory, which are the three main pillars of
deep neural network theory. Serving as a guide for students and researchers in
mathematics and related fields, the book aims to equip readers with
foundational knowledge on the topic. It prioritizes simplicity over generality,
and presents rigorous yet accessible results to help build an understanding of
the essential mathematical concepts underpinning deep learning.",2024-07-25,"Philipp Petersen, Jakob Zech",http://arxiv.org/pdf/2407.18384v3,cs.LG
Physics Informed Kolmogorov-Arnold Neural Networks for Dynamical Analysis via Efficent-KAN and WAV-KAN,"Physics-informed neural networks have proven to be a powerful tool for
solving differential equations, leveraging the principles of physics to inform
the learning process. However, traditional deep neural networks often face
challenges in achieving high accuracy without incurring significant
computational costs. In this work, we implement the Physics-Informed
Kolmogorov-Arnold Neural Networks (PIKAN) through efficient-KAN and WAV-KAN,
which utilize the Kolmogorov-Arnold representation theorem. PIKAN demonstrates
superior performance compared to conventional deep neural networks, achieving
the same level of accuracy with fewer layers and reduced computational
overhead. We explore both B-spline and wavelet-based implementations of PIKAN
and benchmark their performance across various ordinary and partial
differential equations using unsupervised (data-free) and supervised
(data-driven) techniques. For certain differential equations, the data-free
approach suffices to find accurate solutions, while in more complex scenarios,
the data-driven method enhances the PIKAN's ability to converge to the correct
solution. We validate our results against numerical solutions and achieve $99
\%$ accuracy in most scenarios.",2024-07-25,"Subhajit Patra, Sonali Panda, Bikram Keshari Parida, Mahima Arya, Kurt Jacobs, Denys I. Bondar, Abhijit Sen",http://arxiv.org/pdf/2407.18373v2,cs.LG
Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement,"We present a principled approach to provide LLM-based evaluation with a
rigorous guarantee of human agreement. We first propose that a reliable
evaluation method should not uncritically rely on model preferences for
pairwise evaluation, but rather assess the confidence of judge models and
selectively decide when to trust its judgement. We then show that under this
selective evaluation framework, human agreement can be provably guaranteed --
such that the model evaluation aligns with that of humans to a user-specified
agreement level. As part of our framework, we also introduce Simulated
Annotators, a novel confidence estimation method that significantly improves
judge calibration and thus enables high coverage of evaluated instances.
Finally, we propose Cascaded Selective Evaluation, where we use cheaper models
as initial judges and escalate to stronger models only when necessary -- again,
while still providing a provable guarantee of human agreement. Experimental
results show that Cascaded Selective Evaluation guarantees strong alignment
with humans, far beyond what LLM judges could achieve without selective
evaluation. For example, on a subset of Chatbot Arena where GPT-4 almost never
achieves 80% human agreement, our method, even while employing substantially
cost-effective models such as Mistral-7B, guarantees over 80% human agreement
with almost 80% test coverage.",2024-07-25,"Jaehun Jung, Faeze Brahman, Yejin Choi",http://arxiv.org/pdf/2407.18370v1,cs.LG
FADAS: Towards Federated Adaptive Asynchronous Optimization,"Federated learning (FL) has emerged as a widely adopted training paradigm for
privacy-preserving machine learning. While the SGD-based FL algorithms have
demonstrated considerable success in the past, there is a growing trend towards
adopting adaptive federated optimization methods, particularly for training
large-scale models. However, the conventional synchronous aggregation design
poses a significant challenge to the practical deployment of those adaptive
federated optimization methods, particularly in the presence of straggler
clients. To fill this research gap, this paper introduces federated adaptive
asynchronous optimization, named FADAS, a novel method that incorporates
asynchronous updates into adaptive federated optimization with provable
guarantees. To further enhance the efficiency and resilience of our proposed
method in scenarios with significant asynchronous delays, we also extend FADAS
with a delay-adaptive learning adjustment strategy. We rigorously establish the
convergence rate of the proposed algorithms and empirical results demonstrate
the superior performance of FADAS over other asynchronous FL baselines.",2024-07-25,"Yujia Wang, Shiqiang Wang, Songtao Lu, Jinghui Chen",http://arxiv.org/pdf/2407.18365v1,cs.LG
Retinal IPA: Iterative KeyPoints Alignment for Multimodal Retinal Imaging,"We propose a novel framework for retinal feature point alignment, designed
for learning cross-modality features to enhance matching and registration
across multi-modality retinal images. Our model draws on the success of
previous learning-based feature detection and description methods. To better
leverage unlabeled data and constrain the model to reproduce relevant
keypoints, we integrate a keypoint-based segmentation task. It is trained in a
self-supervised manner by enforcing segmentation consistency between different
augmentations of the same image. By incorporating a keypoint augmented
self-supervised layer, we achieve robust feature extraction across modalities.
Extensive evaluation on two public datasets and one in-house dataset
demonstrates significant improvements in performance for modality-agnostic
retinal feature alignment. Our code and model weights are publicly available at
\url{https://github.com/MedICL-VU/RetinaIPA}.",2024-07-25,"Jiacheng Wang, Hao Li, Dewei Hu, Rui Xu, Xing Yao, Yuankai K. Tao, Ipek Oguz",http://arxiv.org/pdf/2407.18362v1,cs.LG
"Generative AI like ChatGPT in Blockchain Federated Learning: use cases, opportunities and future","Federated learning has become a significant approach for training machine
learning models using decentralized data without necessitating the sharing of
this data. Recently, the incorporation of generative artificial intelligence
(AI) methods has provided new possibilities for improving privacy, augmenting
data, and customizing models. This research explores potential integrations of
generative AI in federated learning, revealing various opportunities to enhance
privacy, data efficiency, and model performance. It particularly emphasizes the
importance of generative models like generative adversarial networks (GANs) and
variational autoencoders (VAEs) in creating synthetic data that replicates the
distribution of real data. Generating synthetic data helps federated learning
address challenges related to limited data availability and supports robust
model development. Additionally, we examine various applications of generative
AI in federated learning that enable more personalized solutions.",2024-07-25,"Sai Puppala, Ismail Hossain, Md Jahangir Alam, Sajedul Talukder, Jannatul Ferdaus, Mahedi Hasan, Sameera Pisupati, Shanmukh Mathukumilli",http://arxiv.org/pdf/2407.18358v1,cs.LG
Privacy-Preserving Hierarchical Model-Distributed Inference,"This paper focuses on designing a privacy-preserving Machine Learning (ML)
inference protocol for a hierarchical setup, where clients own/generate data,
model owners (cloud servers) have a pre-trained ML model, and edge servers
perform ML inference on clients' data using the cloud server's ML model. Our
goal is to speed up ML inference while providing privacy to both data and the
ML model. Our approach (i) uses model-distributed inference (model
parallelization) at the edge servers and (ii) reduces the amount of
communication to/from the cloud server. Our privacy-preserving hierarchical
model-distributed inference, privateMDI design uses additive secret sharing and
linearly homomorphic encryption to handle linear calculations in the ML
inference, and garbled circuit and a novel three-party oblivious transfer are
used to handle non-linear functions. privateMDI consists of offline and online
phases. We designed these phases in a way that most of the data exchange is
done in the offline phase while the communication overhead of the online phase
is reduced. In particular, there is no communication to/from the cloud server
in the online phase, and the amount of communication between the client and
edge servers is minimized. The experimental results demonstrate that privateMDI
significantly reduces the ML inference time as compared to the baselines.",2024-07-25,"Fatemeh Jafarian Dehkordi, Yasaman Keshtkarjahromi, Hulya Seferoglu",http://arxiv.org/pdf/2407.18353v2,cs.LG
Introducing δ-XAI: a novel sensitivity-based method for local AI explanations,"Explainable Artificial Intelligence (XAI) is central to the debate on
integrating Artificial Intelligence (AI) and Machine Learning (ML) algorithms
into clinical practice. High-performing AI/ML models, such as ensemble learners
and deep neural networks, often lack interpretability, hampering clinicians'
trust in their predictions. To address this, XAI techniques are being developed
to describe AI/ML predictions in human-understandable terms. One promising
direction is the adaptation of sensitivity analysis (SA) and global sensitivity
analysis (GSA), which inherently rank model inputs by their impact on
predictions. Here, we introduce a novel delta-XAI method that provides local
explanations of ML model predictions by extending the delta index, a GSA
metric. The delta-XAI index assesses the impact of each feature's value on the
predicted output for individual instances in both regression and classification
problems. We formalize the delta-XAI index and provide code for its
implementation. The delta-XAI method was evaluated on simulated scenarios using
linear regression models, with Shapley values serving as a benchmark. Results
showed that the delta-XAI index is generally consistent with Shapley values,
with notable discrepancies in models with highly impactful or extreme feature
values. The delta-XAI index demonstrated higher sensitivity in detecting
dominant features and handling extreme feature values. Qualitatively, the
delta-XAI provides intuitive explanations by leveraging probability density
functions, making feature rankings clearer and more explainable for
practitioners. Overall, the delta-XAI method appears promising for robustly
obtaining local explanations of ML model predictions. Further investigations in
real-world clinical settings will be conducted to evaluate its impact on
AI-assisted clinical workflows.",2024-07-25,"Alessandro De Carlo, Enea Parimbelli, Nicola Melillo, Giovanna Nicora",http://arxiv.org/pdf/2407.18343v2,cs.LG
CavDetect: A DBSCAN Algorithm based Novel Cavity Detection Model on Protein Structure,"Cavities on the structures of proteins are formed due to interaction between
proteins and some small molecules, known as ligands. These are basically the
locations where ligands bind with proteins. Actual detection of such locations
is all-important to succeed in the entire drug design process. This study
proposes a Voronoi Tessellation based novel cavity detection model that is used
to detect cavities on the structure of proteins. As the atom space of protein
structure is dense and of large volumes and the DBSCAN (Density Based Spatial
Clustering of Applications with Noise) algorithm can handle such type of data
very well as well as it is not mandatory to have knowledge about the numbers of
clusters (cavities) in data as priori in this algorithm, this study proposes to
implement the proposed algorithm with the DBSCAN algorithm.",2024-07-25,"Swati Adhikari, Parthajit Roy",http://arxiv.org/pdf/2407.18317v1,cs.LG
Sparse vs Contiguous Adversarial Pixel Perturbations in Multimodal Models: An Empirical Analysis,"Assessing the robustness of multimodal models against adversarial examples is
an important aspect for the safety of its users. We craft L0-norm perturbation
attacks on the preprocessed input images. We launch them in a black-box setup
against four multimodal models and two unimodal DNNs, considering both targeted
and untargeted misclassification. Our attacks target less than 0.04% of
perturbed image area and integrate different spatial positioning of perturbed
pixels: sparse positioning and pixels arranged in different contiguous shapes
(row, column, diagonal, and patch). To the best of our knowledge, we are the
first to assess the robustness of three state-of-the-art multimodal models
(ALIGN, AltCLIP, GroupViT) against different sparse and contiguous pixel
distribution perturbations. The obtained results indicate that unimodal DNNs
are more robust than multimodal models. Furthermore, models using CNN-based
Image Encoder are more vulnerable than models with ViT - for untargeted
attacks, we obtain a 99% success rate by perturbing less than 0.02% of the
image area.",2024-07-25,"Cristian-Alexandru Botocan, Raphael Meier, Ljiljana Dolamic",http://arxiv.org/pdf/2407.18251v1,cs.LG
VGGHeads: 3D Multi Head Alignment with a Large-Scale Synthetic Dataset,"Human head detection, keypoint estimation, and 3D head model fitting are
essential tasks with many applications. However, traditional real-world
datasets often suffer from bias, privacy, and ethical concerns, and they have
been recorded in laboratory environments, which makes it difficult for trained
models to generalize. Here, we introduce \method -- a large-scale synthetic
dataset generated with diffusion models for human head detection and 3D mesh
estimation. Our dataset comprises over 1 million high-resolution images, each
annotated with detailed 3D head meshes, facial landmarks, and bounding boxes.
Using this dataset, we introduce a new model architecture capable of
simultaneous head detection and head mesh reconstruction from a single image in
a single step. Through extensive experimental evaluations, we demonstrate that
models trained on our synthetic data achieve strong performance on real images.
Furthermore, the versatility of our dataset makes it applicable across a broad
spectrum of tasks, offering a general and comprehensive representation of human
heads.",2024-07-25,"Orest Kupyn, Eugene Khvedchenia, Christian Rupprecht",http://arxiv.org/pdf/2407.18245v2,cs.LG
LoRA-Pro: Are Low-Rank Adapters Properly Optimized?,"Low-rank adaptation, also known as LoRA, has emerged as a prominent method
for parameter-efficient fine-tuning of foundation models. Despite its
computational efficiency, LoRA still yields inferior performance compared to
full fine-tuning. In this paper, we first uncover a fundamental connection
between the optimization processes of LoRA and full fine-tuning: using LoRA for
optimization is mathematically equivalent to full fine-tuning using a low-rank
gradient for parameter updates. And this low-rank gradient can be expressed in
terms of the gradients of the two low-rank matrices in LoRA. Leveraging this
insight, we introduce LoRA-Pro, a method that enhances LoRA's performance by
strategically adjusting the gradients of these low-rank matrices. This
adjustment allows the low-rank gradient to more accurately approximate the full
fine-tuning gradient, thereby narrowing the performance gap between LoRA and
full fine-tuning. Furthermore, we theoretically derive the optimal solutions
for adjusting the gradients of the low-rank matrices, applying them during
fine-tuning in LoRA-Pro. We conduct extensive experiments across natural
language understanding, dialogue generation, mathematical reasoning, code
generation, and image classification tasks, demonstrating that LoRA-Pro
substantially improves LoRA's performance, effectively narrowing the gap with
full fine-tuning. Code is publicly available at
https://github.com/mrflogs/LoRA-Pro.",2024-07-25,"Zhengbo Wang, Jian Liang, Ran He, Zilei Wang, Tieniu Tan",http://arxiv.org/pdf/2407.18242v3,cs.LG
Numerical Literals in Link Prediction: A Critical Examination of Models and Datasets,"Link Prediction(LP) is an essential task over Knowledge Graphs(KGs),
traditionally focussed on using and predicting the relations between entities.
Textual entity descriptions have already been shown to be valuable, but models
that incorporate numerical literals have shown minor improvements on existing
benchmark datasets. It is unclear whether a model is actually better in using
numerical literals, or better capable of utilizing the graph structure. This
raises doubts about the effectiveness of these methods and about the
suitability of the existing benchmark datasets.
  We propose a methodology to evaluate LP models that incorporate numerical
literals. We propose i) a new synthetic dataset to better understand how well
these models use numerical literals and ii) dataset ablations strategies to
investigate potential difficulties with the existing datasets. We identify a
prevalent trend: many models underutilize literal information and potentially
rely on additional parameters for performance gains. Our investigation
highlights the need for more extensive evaluations when releasing new models
and datasets.",2024-07-25,"Moritz Blum, Basil Ell, Hannes Ill, Philipp Cimiano",http://arxiv.org/pdf/2407.18241v1,cs.LG
Automated Ensemble Multimodal Machine Learning for Healthcare,"The application of machine learning in medicine and healthcare has led to the
creation of numerous diagnostic and prognostic models. However, despite their
success, current approaches generally issue predictions using data from a
single modality. This stands in stark contrast with clinician decision-making
which employs diverse information from multiple sources. While several
multimodal machine learning approaches exist, significant challenges in
developing multimodal systems remain that are hindering clinical adoption. In
this paper, we introduce a multimodal framework, AutoPrognosis-M, that enables
the integration of structured clinical (tabular) data and medical imaging using
automated machine learning. AutoPrognosis-M incorporates 17 imaging models,
including convolutional neural networks and vision transformers, and three
distinct multimodal fusion strategies. In an illustrative application using a
multimodal skin lesion dataset, we highlight the importance of multimodal
machine learning and the power of combining multiple fusion strategies using
ensemble learning. We have open-sourced our framework as a tool for the
community and hope it will accelerate the uptake of multimodal machine learning
in healthcare and spur further innovation.",2024-07-25,"Fergus Imrie, Stefan Denner, Lucas S. Brunschwig, Klaus Maier-Hein, Mihaela van der Schaar",http://arxiv.org/pdf/2407.18227v1,cs.LG
GesturePrint: Enabling User Identification for mmWave-based Gesture Recognition Systems,"The millimeter-wave (mmWave) radar has been exploited for gesture
recognition. However, existing mmWave-based gesture recognition methods cannot
identify different users, which is important for ubiquitous gesture interaction
in many applications. In this paper, we propose GesturePrint, which is the
first to achieve gesture recognition and gesture-based user identification
using a commodity mmWave radar sensor. GesturePrint features an effective
pipeline that enables the gesture recognition system to identify users at a
minor additional cost. By introducing an efficient signal preprocessing stage
and a network architecture GesIDNet, which employs an attention-based
multilevel feature fusion mechanism, GesturePrint effectively extracts unique
gesture features for gesture recognition and personalized motion pattern
features for user identification. We implement GesturePrint and collect data
from 17 participants performing 15 gestures in a meeting room and an office,
respectively. GesturePrint achieves a gesture recognition accuracy (GRA) of
98.87% with a user identification accuracy (UIA) of 99.78% in the meeting room,
and 98.22% GRA with 99.26% UIA in the office. Extensive experiments on three
public datasets and a new gesture dataset show GesturePrint's superior
performance in enabling effective user identification for gesture recognition
systems.",2024-07-25,"Lilin Xu, Keyi Wang, Chaojie Gu, Xiuzhen Guo, Shibo He, Jiming Chen",http://arxiv.org/pdf/2408.05358v1,cs.LG
Recursive Introspection: Teaching Language Model Agents How to Self-Improve,"A central piece in enabling intelligent agentic behavior in foundation models
is to make them capable of introspecting upon their behavior, reasoning, and
correcting their mistakes as more computation or interaction is available. Even
the strongest proprietary large language models (LLMs) do not quite exhibit the
ability of continually improving their responses sequentially, even in
scenarios where they are explicitly told that they are making a mistake. In
this paper, we develop RISE: Recursive IntroSpEction, an approach for
fine-tuning LLMs to introduce this capability, despite prior work hypothesizing
that this capability may not be possible to attain. Our approach prescribes an
iterative fine-tuning procedure, which attempts to teach the model how to alter
its response after having executed previously unsuccessful attempts to solve a
hard test-time problem, with optionally additional environment feedback. RISE
poses fine-tuning for a single-turn prompt as solving a multi-turn Markov
decision process (MDP), where the initial state is the prompt. Inspired by
principles in online imitation learning and reinforcement learning, we propose
strategies for multi-turn data collection and training so as to imbue an LLM
with the capability to recursively detect and correct its previous mistakes in
subsequent iterations. Our experiments show that RISE enables Llama2, Llama3,
and Mistral models to improve themselves with more turns on math reasoning
tasks, outperforming several single-turn strategies given an equal amount of
inference-time computation. We also find that RISE scales well, often attaining
larger benefits with more capable models. Our analysis shows that RISE makes
meaningful improvements to responses to arrive at the correct solution for
challenging prompts, without disrupting one-turn abilities as a result of
expressing more complex distributions.",2024-07-25,"Yuxiao Qu, Tianjun Zhang, Naman Garg, Aviral Kumar",http://arxiv.org/pdf/2407.18219v2,cs.LG
Scaling Trends in Language Model Robustness,"Language models exhibit scaling laws, whereby increasing model and dataset
size predictably decrease negative log likelihood, unlocking a dazzling array
of capabilities. At the same time, even the most capable systems are currently
vulnerable to adversarial inputs such as jailbreaks and prompt injections,
despite concerted efforts to make them robust. As compute becomes more
accessible to both attackers and defenders, which side will benefit more from
scale? We attempt to answer this question with a detailed study of robustness
on language models spanning three orders of magnitude in parameter count. From
the defender's perspective, we find that in the absence of other interventions,
increasing model size alone does not consistently improve robustness. In
adversarial training, we find that larger models are more sample-efficient and
less compute-efficient than smaller models, and often better generalize their
defense to new threat models. From the attacker's perspective, we find that
increasing attack compute smoothly and reliably increases attack success rate
against both finetuned and adversarially trained models. Finally, we show that
across model sizes studied, doubling compute on adversarial training only
forces an attacker to less than double attack compute to maintain the same
attack success rate. However, adversarial training becomes more and more
effective on larger models, suggesting that defenders could eventually have the
advantage with increasing model size. These results underscore the value of
adopting a scaling lens when discussing robustness of frontier models.",2024-07-25,"Nikolaus Howe, Ian McKenzie, Oskar Hollinsworth, Michał Zajac, Tom Tseng, Aaron Tucker, Pierre-Luc Bacon, Adam Gleave",http://arxiv.org/pdf/2407.18213v4,cs.LG
Geometry Fidelity for Spherical Images,"Spherical or omni-directional images offer an immersive visual format
appealing to a wide range of computer vision applications. However, geometric
properties of spherical images pose a major challenge for models and metrics
designed for ordinary 2D images. Here, we show that direct application of
Fr\'echet Inception Distance (FID) is insufficient for quantifying geometric
fidelity in spherical images. We introduce two quantitative metrics accounting
for geometric constraints, namely Omnidirectional FID (OmniFID) and
Discontinuity Score (DS). OmniFID is an extension of FID tailored to
additionally capture field-of-view requirements of the spherical format by
leveraging cubemap projections. DS is a kernel-based seam alignment score of
continuity across borders of 2D representations of spherical images. In
experiments, OmniFID and DS quantify geometry fidelity issues that are
undetected by FID.",2024-07-25,"Anders Christensen, Nooshin Mojab, Khushman Patel, Karan Ahuja, Zeynep Akata, Ole Winther, Mar Gonzalez-Franco, Andrea Colaco",http://arxiv.org/pdf/2407.18207v1,cs.LG
Differentiable Quantum Architecture Search in Asynchronous Quantum Reinforcement Learning,"The emergence of quantum reinforcement learning (QRL) is propelled by
advancements in quantum computing (QC) and machine learning (ML), particularly
through quantum neural networks (QNN) built on variational quantum circuits
(VQC). These advancements have proven successful in addressing sequential
decision-making tasks. However, constructing effective QRL models demands
significant expertise due to challenges in designing quantum circuit
architectures, including data encoding and parameterized circuits, which
profoundly influence model performance. In this paper, we propose addressing
this challenge with differentiable quantum architecture search (DiffQAS),
enabling trainable circuit parameters and structure weights using
gradient-based optimization. Furthermore, we enhance training efficiency
through asynchronous reinforcement learning (RL) methods facilitating parallel
training. Through numerical simulations, we demonstrate that our proposed
DiffQAS-QRL approach achieves performance comparable to manually-crafted
circuit architectures across considered environments, showcasing stability
across diverse scenarios. This methodology offers a pathway for designing QRL
models without extensive quantum knowledge, ensuring robust performance and
fostering broader application of QRL.",2024-07-25,Samuel Yen-Chi Chen,http://arxiv.org/pdf/2407.18202v1,cs.LG
Sparse Incremental Aggregation in Multi-Hop Federated Learning,"This paper investigates federated learning (FL) in a multi-hop communication
setup, such as in constellations with inter-satellite links. In this setup,
part of the FL clients are responsible for forwarding other client's results to
the parameter server. Instead of using conventional routing, the communication
efficiency can be improved significantly by using in-network model aggregation
at each intermediate hop, known as incremental aggregation (IA). Prior works
[1] have indicated diminishing gains for IA under gradient sparsification. Here
we study this issue and propose several novel correlated sparsification methods
for IA. Numerical results show that, for some of these algorithms, the full
potential of IA is still available under sparsification without impairing
convergence. We demonstrate a 15x improvement in communication efficiency over
conventional routing and a 11x improvement over state-of-the-art (SoA) sparse
IA.",2024-07-25,"Sourav Mukherjee, Nasrin Razmi, Armin Dekorsy, Petar Popovski, Bho Matthiesen",http://arxiv.org/pdf/2407.18200v1,cs.LG
AsEP: Benchmarking Deep Learning Methods for Antibody-specific Epitope Prediction,"Epitope identification is vital for antibody design yet challenging due to
the inherent variability in antibodies. While many deep learning methods have
been developed for general protein binding site prediction tasks, whether they
work for epitope prediction remains an understudied research question. The
challenge is also heightened by the lack of a consistent evaluation pipeline
with sufficient dataset size and epitope diversity. We introduce a filtered
antibody-antigen complex structure dataset, AsEP (Antibody-specific Epitope
Prediction). AsEP is the largest of its kind and provides clustered epitope
groups, allowing the community to develop and test novel epitope prediction
methods and evaluate their generalisability. AsEP comes with an easy-to-use
interface in Python and pre-built graph representations of each
antibody-antigen complex while also supporting customizable embedding methods.
Using this new dataset, we benchmark several representative general
protein-binding site prediction methods and find that their performances fall
short of expectations for epitope prediction. To address this, we propose a
novel method, WALLE, which leverages both unstructured modeling from protein
language models and structural modeling from graph neural networks. WALLE
demonstrate up to 3-10X performance improvement over the baseline methods. Our
empirical findings suggest that epitope prediction benefits from combining
sequential features provided by language models with geometrical information
from graph representations. This provides a guideline for future epitope
prediction method design. In addition, we reformulate the task as bipartite
link prediction, allowing convenient model performance attribution and
interpretability. We open source our data and code at
https://github.com/biochunan/AsEP-dataset.",2024-07-25,"Chunan Liu, Lilian Denzler, Yihong Chen, Andrew Martin, Brooks Paige",http://arxiv.org/pdf/2407.18184v2,cs.LG
Gene Regulatory Network Inference from Pre-trained Single-Cell Transcriptomics Transformer with Joint Graph Learning,"Inferring gene regulatory networks (GRNs) from single-cell RNA sequencing
(scRNA-seq) data is a complex challenge that requires capturing the intricate
relationships between genes and their regulatory interactions. In this study,
we tackle this challenge by leveraging the single-cell BERT-based pre-trained
transformer model (scBERT), trained on extensive unlabeled scRNA-seq data, to
augment structured biological knowledge from existing GRNs. We introduce a
novel joint graph learning approach that combines the rich contextual
representations learned by pre-trained single-cell language models with the
structured knowledge encoded in GRNs using graph neural networks (GNNs). By
integrating these two modalities, our approach effectively reasons over boththe
gene expression level constraints provided by the scRNA-seq data and the
structured biological knowledge inherent in GRNs. We evaluate our method on
human cell benchmark datasets from the BEELINE study with cell type-specific
ground truth networks. The results demonstrate superior performance over
current state-of-the-art baselines, offering a deeper understanding of cellular
regulatory mechanisms.",2024-07-25,"Sindhura Kommu, Yizhi Wang, Yue Wang, Xuan Wang",http://arxiv.org/pdf/2407.18181v1,cs.LG
Quasar-ViT: Hardware-Oriented Quantization-Aware Architecture Search for Vision Transformers,"Vision transformers (ViTs) have demonstrated their superior accuracy for
computer vision tasks compared to convolutional neural networks (CNNs).
However, ViT models are often computation-intensive for efficient deployment on
resource-limited edge devices. This work proposes Quasar-ViT, a
hardware-oriented quantization-aware architecture search framework for ViTs, to
design efficient ViT models for hardware implementation while preserving the
accuracy. First, Quasar-ViT trains a supernet using our row-wise flexible
mixed-precision quantization scheme, mixed-precision weight entanglement, and
supernet layer scaling techniques. Then, it applies an efficient
hardware-oriented search algorithm, integrated with hardware latency and
resource modeling, to determine a series of optimal subnets from supernet under
different inference latency targets. Finally, we propose a series of
model-adaptive designs on the FPGA platform to support the architecture search
and mitigate the gap between the theoretical computation reduction and the
practical inference speedup. Our searched models achieve 101.5, 159.6, and
251.6 frames-per-second (FPS) inference speed on the AMD/Xilinx ZCU102 FPGA
with 80.4%, 78.6%, and 74.9% top-1 accuracy, respectively, for the ImageNet
dataset, consistently outperforming prior works.",2024-07-25,"Zhengang Li, Alec Lu, Yanyue Xie, Zhenglun Kong, Mengshu Sun, Hao Tang, Zhong Jia Xue, Peiyan Dong, Caiwen Ding, Yanzhi Wang, Xue Lin, Zhenman Fang",http://arxiv.org/pdf/2407.18175v1,cs.LG
RIDA: A Robust Attack Framework on Incomplete Graphs,"Graph Neural Networks (GNNs) are vital in data science but are increasingly
susceptible to adversarial attacks. To help researchers develop more robust GNN
models, it's essential to focus on designing strong attack models as
foundational benchmarks and guiding references. Among adversarial attacks,
gray-box poisoning attacks are noteworthy due to their effectiveness and fewer
constraints. These attacks exploit GNNs' need for retraining on updated data,
thereby impacting their performance by perturbing these datasets. However,
current research overlooks the real-world scenario of incomplete graphs. To
address this gap, we introduce the Robust Incomplete Deep Attack Framework
(RIDA). It is the first algorithm for robust gray-box poisoning attacks on
incomplete graphs. The approach innovatively aggregates distant vertex
information and ensures powerful data utilization. Extensive tests against 9
SOTA baselines on 3 real-world datasets demonstrate that RIDA's superiority in
handling incompleteness and high attack performance on the incomplete graph.",2024-07-25,"Jianke Yu, Hanchen Wang, Chen Chen, Xiaoyang Wang, Lu Qin, Wenjie Zhang, Ying Zhang, Xijuan Liu",http://arxiv.org/pdf/2407.18170v3,cs.LG
Unlocking Tokens as Data Points for Generalization Bounds on Larger Language Models,"Large language models (LLMs) with billions of parameters excel at predicting
the next token in a sequence. Recent work computes non-vacuous
compression-based generalization bounds for LLMs, but these bounds are vacuous
for large models at the billion-parameter scale. Moreover, these bounds are
obtained through restrictive compression techniques, bounding compressed models
that generate low-quality text. Additionally, the tightness of these existing
bounds depends on the number of IID documents in a training set rather than the
much larger number of non-IID constituent tokens, leaving untapped potential
for tighter bounds. In this work, we instead use properties of martingales to
derive generalization bounds that benefit from the vast number of tokens in LLM
training sets. Since a dataset contains far more tokens than documents, our
generalization bounds not only tolerate but actually benefit from far less
restrictive compression schemes. With Monarch matrices, Kronecker
factorizations, and post-training quantization, we achieve non-vacuous
generalization bounds for LLMs as large as LLaMA2-70B. Unlike previous
approaches, our work achieves the first non-vacuous bounds for models that are
deployed in practice and generate high-quality text.",2024-07-25,"Sanae Lotfi, Yilun Kuang, Brandon Amos, Micah Goldblum, Marc Finzi, Andrew Gordon Wilson",http://arxiv.org/pdf/2407.18158v1,cs.LG
StraightLine: An End-to-End Resource-Aware Scheduler for Machine Learning Application Requests,"The life cycle of machine learning (ML) applications consists of two stages:
model development and model deployment. However, traditional ML systems (e.g.,
training-specific or inference-specific systems) focus on one particular stage
or phase of the life cycle of ML applications. These systems often aim at
optimizing model training or accelerating model inference, and they frequently
assume homogeneous infrastructure, which may not always reflect real-world
scenarios that include cloud data centers, local servers, containers, and
serverless platforms. We present StraightLine, an end-to-end resource-aware
scheduler that schedules the optimal resources (e.g., container, virtual
machine, or serverless) for different ML application requests in a hybrid
infrastructure. The key innovation is an empirical dynamic placing algorithm
that intelligently places requests based on their unique characteristics (e.g.,
request frequency, input data size, and data distribution). In contrast to
existing ML systems, StraightLine offers end-to-end resource-aware placement,
thereby it can significantly reduce response time and failure rate for model
deployment when facing different computing resources in the hybrid
infrastructure.",2024-07-25,"Cheng-Wei Ching, Boyuan Guan, Hailu Xu, Liting Hu",http://arxiv.org/pdf/2407.18148v2,cs.LG
Maximum Entropy On-Policy Actor-Critic via Entropy Advantage Estimation,"Entropy Regularisation is a widely adopted technique that enhances policy
optimisation performance and stability. A notable form of entropy
regularisation is augmenting the objective with an entropy term, thereby
simultaneously optimising the expected return and the entropy. This framework,
known as maximum entropy reinforcement learning (MaxEnt RL), has shown
theoretical and empirical successes. However, its practical application in
straightforward on-policy actor-critic settings remains surprisingly
underexplored. We hypothesise that this is due to the difficulty of managing
the entropy reward in practice. This paper proposes a simple method of
separating the entropy objective from the MaxEnt RL objective, which
facilitates the implementation of MaxEnt RL in on-policy settings. Our
empirical evaluations demonstrate that extending Proximal Policy Optimisation
(PPO) and Trust Region Policy Optimisation (TRPO) within the MaxEnt framework
improves policy optimisation performance in both MuJoCo and Procgen tasks.
Additionally, our results highlight MaxEnt RL's capacity to enhance
generalisation.",2024-07-25,"Jean Seong Bjorn Choe, Jong-Kook Kim",http://arxiv.org/pdf/2407.18143v1,cs.LG
IRIS: Wireless Ring for Vision-based Smart Home Interaction,"Integrating cameras into wireless smart rings has been challenging due to
size and power constraints. We introduce IRIS, the first wireless
vision-enabled smart ring system for smart home interactions. Equipped with a
camera, Bluetooth radio, inertial measurement unit (IMU), and an onboard
battery, IRIS meets the small size, weight, and power (SWaP) requirements for
ring devices. IRIS is context-aware, adapting its gesture set to the detected
device, and can last for 16-24 hours on a single charge. IRIS leverages the
scene semantics to achieve instance-level device recognition. In a study
involving 23 participants, IRIS consistently outpaced voice commands, with a
higher proportion of participants expressing a preference for IRIS over voice
commands regarding toggling a device's state, granular control, and social
acceptability. Our work pushes the boundary of what is possible with ring
form-factor devices, addressing system challenges and opening up novel
interaction capabilities.",2024-07-25,"Maruchi Kim, Antonio Glenn, Bandhav Veluri, Yunseo Lee, Eyoel Gebre, Aditya Bagaria, Shwetak Patel, Shyamnath Gollakota",http://arxiv.org/pdf/2407.18141v1,cs.LG
$\mathbb{X}$-Sample Contrastive Loss: Improving Contrastive Learning with Sample Similarity Graphs,"Learning good representations involves capturing the diverse ways in which
data samples relate. Contrastive loss - an objective matching related samples -
underlies methods from self-supervised to multimodal learning. Contrastive
losses, however, can be viewed more broadly as modifying a similarity graph to
indicate how samples should relate in the embedding space. This view reveals a
shortcoming in contrastive learning: the similarity graph is binary, as only
one sample is the related positive sample. Crucially, similarities
\textit{across} samples are ignored. Based on this observation, we revise the
standard contrastive loss to explicitly encode how a sample relates to others.
We experiment with this new objective, called $\mathbb{X}$-Sample Contrastive,
to train vision models based on similarities in class or text caption
descriptions. Our study spans three scales: ImageNet-1k with 1 million, CC3M
with 3 million, and CC12M with 12 million samples. The representations learned
via our objective outperform both contrastive self-supervised and
vision-language models trained on the same data across a range of tasks. When
training on CC12M, we outperform CLIP by $0.6\%$ on both ImageNet and ImageNet
Real. Our objective appears to work particularly well in lower-data regimes,
with gains over CLIP of $16.8\%$ on ImageNet and $18.1\%$ on ImageNet Real when
training with CC3M. Finally, our objective seems to encourage the model to
learn representations that separate objects from their attributes and
backgrounds, with gains of $3.3$-$5.6$\% over CLIP on ImageNet9. We hope the
proposed solution takes a small step towards developing richer learning
objectives for understanding sample relations in foundation models.",2024-07-25,"Vlad Sobal, Mark Ibrahim, Randall Balestriero, Vivien Cabannes, Diane Bouchacourt, Pietro Astolfi, Kyunghyun Cho, Yann LeCun",http://arxiv.org/pdf/2407.18134v2,cs.LG
Unsupervised Training of Neural Cellular Automata on Edge Devices,"The disparity in access to machine learning tools for medical imaging across
different regions significantly limits the potential for universal healthcare
innovation, particularly in remote areas. Our research addresses this issue by
implementing Neural Cellular Automata (NCA) training directly on smartphones
for accessible X-ray lung segmentation. We confirm the practicality and
feasibility of deploying and training these advanced models on five Android
devices, improving medical diagnostics accessibility and bridging the tech
divide to extend machine learning benefits in medical imaging to low- and
middle-income countries (LMICs). We further enhance this approach with an
unsupervised adaptation method using the novel Variance-Weighted Segmentation
Loss (VWSL), which efficiently learns from unlabeled data by minimizing the
variance from multiple NCA predictions. This strategy notably improves model
adaptability and performance across diverse medical imaging contexts without
the need for extensive computational resources or labeled datasets, effectively
lowering the participation threshold. Our methodology, tested on three
multisite X-ray datasets -- Padchest, ChestX-ray8, and MIMIC-III --
demonstrates improvements in segmentation Dice accuracy by 0.7 to 2.8%,
compared to the classic Med-NCA. Additionally, in extreme cases where no
digital copy is available and images must be captured by a phone from an X-ray
lightbox or monitor, VWSL enhances Dice accuracy by 5-20%, demonstrating the
method's robustness even with suboptimal image sources.",2024-07-25,"John Kalkhof, Amin Ranem, Anirban Mukhopadhyay",http://arxiv.org/pdf/2407.18114v1,cs.LG
Graph Neural Ordinary Differential Equations for Coarse-Grained Socioeconomic Dynamics,"We present a data-driven machine-learning approach for modeling space-time
socioeconomic dynamics. Through coarse-graining fine-scale observations, our
modeling framework simplifies these complex systems to a set of tractable
mechanistic relationships -- in the form of ordinary differential equations --
while preserving critical system behaviors. This approach allows for expedited
'what if' studies and sensitivity analyses, essential for informed
policy-making. Our findings, from a case study of Baltimore, MD, indicate that
this machine learning-augmented coarse-grained model serves as a powerful
instrument for deciphering the complex interactions between social factors,
geography, and exogenous stressors, offering a valuable asset for system
forecasting and resilience planning.",2024-07-25,"James Koch, Pranab Roy Chowdhury, Heng Wan, Parin Bhaduri, Jim Yoon, Vivek Srikrishnan, W. Brent Daniel",http://arxiv.org/pdf/2407.18108v1,cs.LG
Fine-Tuning Large Language Models for Stock Return Prediction Using Newsflow,"Large language models (LLMs) and their fine-tuning techniques have
demonstrated superior performance in various language understanding and
generation tasks. This paper explores fine-tuning LLMs for stock return
forecasting with financial newsflow. In quantitative investing, return
forecasting is fundamental for subsequent tasks like stock picking, portfolio
optimization, etc. We formulate the model to include text representation and
forecasting modules. We propose to compare the encoder-only and decoder-only
LLMs, considering they generate text representations in distinct ways. The
impact of these different representations on forecasting performance remains an
open question. Meanwhile, we compare two simple methods of integrating LLMs'
token-level representations into the forecasting module. The experiments on
real news and investment universes reveal that: (1) aggregated representations
from LLMs' token-level embeddings generally produce return predictions that
enhance the performance of long-only and long-short portfolios; (2) in the
relatively large investment universe, the decoder LLMs-based prediction model
leads to stronger portfolios, whereas in the small universes, there are no
consistent winners. Among the three LLMs studied (DeBERTa, Mistral, Llama),
Mistral performs more robustly across different universes; (3) return
predictions derived from LLMs' text representations are a strong signal for
portfolio construction, outperforming conventional sentiment scores.",2024-07-25,"Tian Guo, Emmanuel Hauptmann",http://arxiv.org/pdf/2407.18103v2,cs.LG
Principal-Agent Reinforcement Learning: Orchestrating AI Agents with Contracts,"The increasing deployment of AI is shaping the future landscape of the
internet, which is set to become an integrated ecosystem of AI agents.
Orchestrating the interaction among AI agents necessitates decentralized,
self-sustaining mechanisms that harmonize the tension between individual
interests and social welfare. In this paper we tackle this challenge by
synergizing reinforcement learning with principal-agent theory from economics.
Taken separately, the former allows unrealistic freedom of intervention, while
the latter struggles to scale in sequential settings. Combining them achieves
the best of both worlds. We propose a framework where a principal guides an
agent in a Markov Decision Process (MDP) using a series of contracts, which
specify payments by the principal based on observable outcomes of the agent's
actions. We present and analyze a meta-algorithm that iteratively optimizes the
policies of the principal and agent, showing its equivalence to a contraction
operator on the principal's Q-function, and its convergence to subgame-perfect
equilibrium. We then scale our algorithm with deep Q-learning and analyze its
convergence in the presence of approximation error, both theoretically and
through experiments with randomly generated binary game-trees. Extending our
framework to multiple agents, we apply our methodology to the combinatorial
Coin Game. Addressing this multi-agent sequential social dilemma is a promising
first step toward scaling our approach to more complex, real-world instances.",2024-07-25,"Dima Ivanov, Paul Dütting, Inbal Talgam-Cohen, Tonghan Wang, David C. Parkes",http://arxiv.org/pdf/2407.18074v2,cs.LG
HVM-1: Large-scale video models pretrained with nearly 5000 hours of human-like video data,"We introduce Human-like Video Models (HVM-1), large-scale video models
pretrained with nearly 5000 hours of curated human-like video data (mostly
egocentric, temporally extended, continuous video recordings), using the
spatiotemporal masked autoencoder (ST-MAE) algorithm. We release two 633M
parameter models trained at spatial resolutions of 224x224 and 448x448 pixels.
We evaluate the performance of these models in downstream few-shot video and
image recognition tasks and compare them against a model pretrained with 1330
hours of short action-oriented video clips from YouTube (Kinetics-700). HVM-1
models perform competitively against the Kinetics-700 pretrained model in
downstream evaluations despite substantial qualitative differences between the
spatiotemporal characteristics of the corresponding pretraining datasets. HVM-1
models also learn more accurate and more robust object representations compared
to models pretrained with the image-based MAE algorithm on the same data,
demonstrating the potential benefits of learning to predict temporal
regularities in natural videos for learning better object representations.",2024-07-25,A. Emin Orhan,http://arxiv.org/pdf/2407.18067v1,cs.LG
Multi-Agent Deep Reinforcement Learning for Resilience Optimization in 5G RAN,"Resilience is defined as the ability of a network to resist, adapt, and
quickly recover from disruptions, and to continue to maintain an acceptable
level of services from users' perspective. With the advent of future radio
networks, including advanced 5G and upcoming 6G, critical services become
integral to future networks, requiring uninterrupted service delivery for end
users. Unfortunately, with the growing network complexity, user mobility and
diversity, it becomes challenging to scale current resilience management
techniques that rely on local optimizations to large dense network deployments.
This paper aims to address this problem by globally optimizing the resilience
of a dense multi-cell network based on multi-agent deep reinforcement learning.
Specifically, our proposed solution can dynamically tilt cell antennas and
reconfigure transmit power to mitigate outages and increase both coverage and
service availability. A multi-objective optimization problem is formulated to
simultaneously satisfy resiliency constraints while maximizing the service
quality in the network area in order to minimize the impact of outages on
neighbouring cells. Extensive simulations then demonstrate that with our
proposed solution, the average service availability in terms of user throughput
can be increased by up to 50-60% on average, while reaching a coverage
availability of 99% in best cases.",2024-07-25,"Soumeya Kaada, Dinh-Hieu Tran, Nguyen Van Huynh, Marie-Line Alberi Morel, Sofiene Jelassi, Gerardo Rubino",http://arxiv.org/pdf/2407.18066v1,cs.LG
Cross-Vendor Reproducibility of Radiomics-based Machine Learning Models for Computer-aided Diagnosis,"Background: The reproducibility of machine-learning models in prostate cancer
detection across different MRI vendors remains a significant challenge.
Methods: This study investigates Support Vector Machines (SVM) and Random
Forest (RF) models trained on radiomic features extracted from T2-weighted MRI
images using Pyradiomics and MRCradiomics libraries. Feature selection was
performed using the maximum relevance minimum redundancy (MRMR) technique. We
aimed to enhance clinical decision support through multimodal learning and
feature fusion. Results: Our SVM model, utilizing combined features from
Pyradiomics and MRCradiomics, achieved an AUC of 0.74 on the Multi-Improd
dataset (Siemens scanner) but decreased to 0.60 on the Philips test set. The RF
model showed similar trends, with notable robustness for models using
Pyradiomics features alone (AUC of 0.78 on Philips). Conclusions: These
findings demonstrate the potential of multimodal feature integration to improve
the robustness and generalizability of machine-learning models for clinical
decision support in prostate cancer detection. This study marks a significant
step towards developing reliable AI-driven diagnostic tools that maintain
efficacy across various imaging platforms.",2024-07-25,"Jatin Chaudhary, Ivan Jambor, Hannu Aronen, Otto Ettala, Jani Saunavaara, Peter Boström, Jukka Heikkonen, Rajeev Kanth, Harri Merisaari",http://arxiv.org/pdf/2407.18060v1,cs.LG
I can listen but cannot read: An evaluation of two-tower multimodal systems for instrument recognition,"Music two-tower multimodal systems integrate audio and text modalities into a
joint audio-text space, enabling direct comparison between songs and their
corresponding labels. These systems enable new approaches for classification
and retrieval, leveraging both modalities. Despite the promising results they
have shown for zero-shot classification and retrieval tasks, closer inspection
of the embeddings is needed. This paper evaluates the inherent zero-shot
properties of joint audio-text spaces for the case-study of instrument
recognition. We present an evaluation and analysis of two-tower systems for
zero-shot instrument recognition and a detailed analysis of the properties of
the pre-joint and joint embeddings spaces. Our findings suggest that audio
encoders alone demonstrate good quality, while challenges remain within the
text encoder or joint space projection. Specifically, two-tower systems exhibit
sensitivity towards specific words, favoring generic prompts over musically
informed ones. Despite the large size of textual encoders, they do not yet
leverage additional textual context or infer instruments accurately from their
descriptions. Lastly, a novel approach for quantifying the semantic
meaningfulness of the textual space leveraging an instrument ontology is
proposed. This method reveals deficiencies in the systems' understanding of
instruments and provides evidence of the need for fine-tuning text encoders on
musical data.",2024-07-25,"Yannis Vasilakis, Rachel Bittner, Johan Pauwels",http://arxiv.org/pdf/2407.18058v1,cs.LG
Physics-informed nonlinear vector autoregressive models for the prediction of dynamical systems,"Machine learning techniques have recently been of great interest for solving
differential equations. Training these models is classically a data-fitting
task, but knowledge of the expression of the differential equation can be used
to supplement the training objective, leading to the development of
physics-informed scientific machine learning. In this article, we focus on one
class of models called nonlinear vector autoregression (NVAR) to solve ordinary
differential equations (ODEs). Motivated by connections to numerical
integration and physics-informed neural networks, we explicitly derive the
physics-informed NVAR (piNVAR) which enforces the right-hand side of the
underlying differential equation regardless of NVAR construction. Because NVAR
and piNVAR completely share their learned parameters, we propose an augmented
procedure to jointly train the two models. Then, using both data-driven and
ODE-driven metrics, we evaluate the ability of the piNVAR model to predict
solutions to various ODE systems, such as the undamped spring, a Lotka-Volterra
predator-prey nonlinear model, and the chaotic Lorenz system.",2024-07-25,"James H. Adler, Samuel Hocking, Xiaozhe Hu, Shafiqul Islam",http://arxiv.org/pdf/2407.18057v1,cs.LG
The Geometry of Queries: Query-Based Innovations in Retrieval-Augmented Generation,"Digital health chatbots powered by Large Language Models (LLMs) have the
potential to significantly improve personal health management for chronic
conditions by providing accessible and on-demand health coaching and
question-answering. However, these chatbots risk providing unverified and
inaccurate information because LLMs generate responses based on patterns
learned from diverse internet data. Retrieval Augmented Generation (RAG) can
help mitigate hallucinations and inaccuracies in LLM responses by grounding it
on reliable content. However, efficiently and accurately retrieving most
relevant set of content for real-time user questions remains a challenge. In
this work, we introduce Query-Based Retrieval Augmented Generation (QB-RAG), a
novel approach that pre-computes a database of potential queries from a content
base using LLMs. For an incoming patient question, QB-RAG efficiently matches
it against this pre-generated query database using vector search, improving
alignment between user questions and the content. We establish a theoretical
foundation for QB-RAG and provide a comparative analysis of existing retrieval
enhancement techniques for RAG systems. Finally, our empirical evaluation
demonstrates that QB-RAG significantly improves the accuracy of healthcare
question answering, paving the way for robust and trustworthy LLM applications
in digital health.",2024-07-25,"Eric Yang, Jonathan Amar, Jong Ha Lee, Bhawesh Kumar, Yugang Jia",http://arxiv.org/pdf/2407.18044v1,cs.LG
Lifelong Graph Learning for Graph Summarization,"Summarizing web graphs is challenging due to the heterogeneity of the modeled
information and its changes over time. We investigate the use of neural
networks for lifelong graph summarization. Assuming we observe the web graph at
a certain time, we train the networks to summarize graph vertices. We apply
this trained network to summarize the vertices of the changed graph at the next
point in time. Subsequently, we continue training and evaluating the network to
perform lifelong graph summarization. We use the GNNs Graph-MLP and GraphSAINT,
as well as an MLP baseline, to summarize the temporal graphs. We compare
$1$-hop and $2$-hop summaries. We investigate the impact of reusing parameters
from a previous snapshot by measuring the backward and forward transfer and the
forgetting rate of the neural networks. Our extensive experiments on ten weekly
snapshots of a web graph with over $100$M edges, sampled in 2012 and 2022, show
that all networks predominantly use $1$-hop information to determine the
summary, even when performing $2$-hop summarization. Due to the heterogeneity
of web graphs, in some snapshots, the $2$-hop summary produces over ten times
more vertex summaries than the $1$-hop summary. When using the network trained
on the last snapshot from 2012 and applying it to the first snapshot of 2022,
we observe a strong drop in accuracy. We attribute this drop over the ten-year
time warp to the strongly increased heterogeneity of the web graph in 2022.",2024-07-25,"Jonatan Frank, Marcel Hoffmann, Nicolas Lell, David Richerby, Ansgar Scherp",http://arxiv.org/pdf/2407.18042v2,cs.LG
How to Train the Teacher Model for Effective Knowledge Distillation,"Recently, it was shown that the role of the teacher in knowledge distillation
(KD) is to provide the student with an estimate of the true Bayes conditional
probability density (BCPD). Notably, the new findings propose that the
student's error rate can be upper-bounded by the mean squared error (MSE)
between the teacher's output and BCPD. Consequently, to enhance KD efficacy,
the teacher should be trained such that its output is close to BCPD in MSE
sense. This paper elucidates that training the teacher model with MSE loss
equates to minimizing the MSE between its output and BCPD, aligning with its
core responsibility of providing the student with a BCPD estimate closely
resembling it in MSE terms. In this respect, through a comprehensive set of
experiments, we demonstrate that substituting the conventional teacher trained
with cross-entropy loss with one trained using MSE loss in state-of-the-art KD
methods consistently boosts the student's accuracy, resulting in improvements
of up to 2.6\%.",2024-07-25,"Shayan Mohajer Hamidi, Xizhen Deng, Renhao Tan, Linfeng Ye, Ahmed Hussein Salamah",http://arxiv.org/pdf/2407.18041v1,cs.LG
Peak-Controlled Logits Poisoning Attack in Federated Distillation,"Federated Distillation (FD) offers an innovative approach to distributed
machine learning, leveraging knowledge distillation for efficient and flexible
cross-device knowledge transfer without necessitating the upload of extensive
model parameters to a central server. While FD has gained popularity, its
vulnerability to poisoning attacks remains underexplored. To address this gap,
we previously introduced FDLA (Federated Distillation Logits Attack), a method
that manipulates logits communication to mislead and degrade the performance of
client models. However, the impact of FDLA on participants with different
identities and the effects of malicious modifications at various stages of
knowledge transfer remain unexplored. To this end, we present PCFDLA
(Peak-Controlled Federated Distillation Logits Attack), an advanced and more
stealthy logits poisoning attack method for FD. PCFDLA enhances the
effectiveness of FDLA by carefully controlling the peak values of logits to
create highly misleading yet inconspicuous modifications. Furthermore, we
introduce a novel metric for better evaluating attack efficacy, demonstrating
that PCFDLA maintains stealth while being significantly more disruptive to
victim models compared to its predecessors. Experimental results across various
datasets confirm the superior impact of PCFDLA on model accuracy, solidifying
its potential threat in federated distillation systems.",2024-07-25,"Yuhan Tang, Aoxu Zhang, Zhiyuan Wu, Bo Gao, Tian Wen, Yuwei Wang, Sheng Sun",http://arxiv.org/pdf/2407.18039v1,cs.LG
Estimating the number of clusters of a Block Markov Chain,"Clustering algorithms frequently require the number of clusters to be chosen
in advance, but it is usually not clear how to do this. To tackle this
challenge when clustering within sequential data, we present a method for
estimating the number of clusters when the data is a trajectory of a Block
Markov Chain. Block Markov Chains are Markov Chains that exhibit a block
structure in their transition matrix. The method considers a matrix that counts
the number of transitions between different states within the trajectory, and
transforms this into a spectral embedding whose dimension is set via singular
value thresholding. The number of clusters is subsequently estimated via
density-based clustering of this spectral embedding, an approach inspired by
literature on the Stochastic Block Model. By leveraging and augmenting recent
results on the spectral concentration of random matrices with Markovian
dependence, we show that the method is asymptotically consistent - in spite of
the dependencies between the count matrix's entries, and even when the count
matrix is sparse. We also present a numerical evaluation of our method, and
compare it to alternatives.",2024-07-25,"Thomas van Vuren, Thomas Cronk, Jaron Sanders",http://arxiv.org/pdf/2407.18287v1,cs.LG
ECG Arrhythmia Detection Using Disease-specific Attention-based Deep Learning Model,"The electrocardiogram (ECG) is one of the most commonly-used tools to
diagnose cardiovascular disease in clinical practice. Although deep learning
models have achieved very impressive success in the field of automatic ECG
analysis, they often lack model interpretability that is significantly
important in the healthcare applications. To this end, many schemes such as
general-purpose attention mechanism, Grad-CAM technique and ECG knowledge graph
were proposed to be integrated with deep learning models. However, they either
result in decreased classification performance or do not consist with the one
in cardiologists' mind when interpreting ECG. In this study, we propose a novel
disease-specific attention-based deep learning model (DANet) for arrhythmia
detection from short ECG recordings. The novel idea is to introduce a
soft-coding or hard-coding waveform enhanced module into existing deep neural
networks, which amends original ECG signals with the guidance of the rule for
diagnosis of a given disease type before being fed into the classification
module. For the soft-coding DANet, we also develop a learning framework
combining self-supervised pre-training with two-stage supervised training. To
verify the effectiveness of our proposed DANet, we applied it to the problem of
atrial premature contraction detection and the experimental results shows that
it demonstrates superior performance compared to the benchmark model. Moreover,
it also provides the waveform regions that deserve special attention in the
model's decision-making process, allowing it to be a medical diagnostic
assistant for physicians.",2024-07-25,Linpeng Jin,http://arxiv.org/pdf/2407.18033v1,cs.LG
Learning mental states estimation through self-observation: a developmental synergy between intentions and beliefs representations in a deep-learning model of Theory of Mind,"Theory of Mind (ToM), the ability to attribute beliefs, intentions, or mental
states to others, is a crucial feature of human social interaction. In complex
environments, where the human sensory system reaches its limits, behaviour is
strongly driven by our beliefs about the state of the world around us.
Accessing others' mental states, e.g., beliefs and intentions, allows for more
effective social interactions in natural contexts. Yet, these variables are not
directly observable, making understanding ToM a challenging quest of interest
for different fields, including psychology, machine learning and robotics. In
this paper, we contribute to this topic by showing a developmental synergy
between learning to predict low-level mental states (e.g., intentions, goals)
and attributing high-level ones (i.e., beliefs). Specifically, we assume that
learning beliefs attribution can occur by observing one's own decision
processes involving beliefs, e.g., in a partially observable environment. Using
a simple feed-forward deep learning model, we show that, when learning to
predict others' intentions and actions, more accurate predictions can be
acquired earlier if beliefs attribution is learnt simultaneously. Furthermore,
we show that the learning performance improves even when observed actors have a
different embodiment than the observer and the gain is higher when observing
beliefs-driven chunks of behaviour. We propose that our computational approach
can inform the understanding of human social cognitive development and be
relevant for the design of future adaptive social robots able to autonomously
understand, assist, and learn from human interaction partners in novel natural
environments and tasks.",2024-07-25,"Francesca Bianco, Silvia Rigato, Maria Laura Filippetti, Dimitri Ognibene",http://arxiv.org/pdf/2407.18022v1,cs.LG
Quadratic Advantage with Quantum Randomized Smoothing Applied to Time-Series Analysis,"As quantum machine learning continues to develop at a rapid pace, the
importance of ensuring the robustness and efficiency of quantum algorithms
cannot be overstated. Our research presents an analysis of quantum randomized
smoothing, how data encoding and perturbation modeling approaches can be
matched to achieve meaningful robustness certificates. By utilizing an
innovative approach integrating Grover's algorithm, a quadratic sampling
advantage over classical randomized smoothing is achieved. This strategy
necessitates a basis state encoding, thus restricting the space of meaningful
perturbations. We show how constrained $k$-distant Hamming weight perturbations
are a suitable noise distribution here, and elucidate how they can be
constructed on a quantum computer. The efficacy of the proposed framework is
demonstrated on a time series classification task employing a Bag-of-Words
pre-processing solution. The advantage of quadratic sample reduction is
recovered especially in the regime with large number of samples. This may allow
quantum computers to efficiently scale randomized smoothing to more complex
tasks beyond the reach of classical methods.",2024-07-25,"Nicola Franco, Marie Kempkes, Jakob Spiegelberg, Jeanette Miriam Lorenz",http://arxiv.org/pdf/2407.18021v1,cs.LG
Self-Supervision Improves Diffusion Models for Tabular Data Imputation,"The ubiquity of missing data has sparked considerable attention and focus on
tabular data imputation methods. Diffusion models, recognized as the
cutting-edge technique for data generation, demonstrate significant potential
in tabular data imputation tasks. However, in pursuit of diversity, vanilla
diffusion models often exhibit sensitivity to initialized noises, which hinders
the models from generating stable and accurate imputation results.
Additionally, the sparsity inherent in tabular data poses challenges for
diffusion models in accurately modeling the data manifold, impacting the
robustness of these models for data imputation. To tackle these challenges,
this paper introduces an advanced diffusion model named Self-supervised
imputation Diffusion Model (SimpDM for brevity), specifically tailored for
tabular data imputation tasks. To mitigate sensitivity to noise, we introduce a
self-supervised alignment mechanism that aims to regularize the model, ensuring
consistent and stable imputation predictions. Furthermore, we introduce a
carefully devised state-dependent data augmentation strategy within SimpDM,
enhancing the robustness of the diffusion model when dealing with limited data.
Extensive experiments demonstrate that SimpDM matches or outperforms
state-of-the-art imputation methods across various scenarios.",2024-07-25,"Yixin Liu, Thalaiyasingam Ajanthan, Hisham Husain, Vu Nguyen",http://arxiv.org/pdf/2407.18013v1,cs.LG
HANNA: Hard-constraint Neural Network for Consistent Activity Coefficient Prediction,"We present the first hard-constraint neural network for predicting activity
coefficients (HANNA), a thermodynamic mixture property that is the basis for
many applications in science and engineering. Unlike traditional neural
networks, which ignore physical laws and result in inconsistent predictions,
our model is designed to strictly adhere to all thermodynamic consistency
criteria. By leveraging deep-set neural networks, HANNA maintains symmetry
under the permutation of the components. Furthermore, by hard-coding physical
constraints in the network architecture, we ensure consistency with the
Gibbs-Duhem equation and in modeling the pure components. The model was trained
and evaluated on 317,421 data points for activity coefficients in binary
mixtures from the Dortmund Data Bank, achieving significantly higher prediction
accuracies than the current state-of-the-art model UNIFAC. Moreover, HANNA only
requires the SMILES of the components as input, making it applicable to any
binary mixture of interest. HANNA is fully open-source and available for free
use.",2024-07-25,"Thomas Specht, Mayank Nagda, Sophie Fellenz, Stephan Mandt, Hans Hasse, Fabian Jirasek",http://arxiv.org/pdf/2407.18011v1,cs.LG
Advancing Thermodynamic Group-Contribution Methods by Machine Learning: UNIFAC 2.0,"Accurate prediction of thermodynamic properties is pivotal in chemical
engineering for optimizing process efficiency and sustainability. Physical
group-contribution (GC) methods are widely employed for this purpose but suffer
from historically grown, incomplete parameterizations, limiting their
applicability and accuracy. In this work, we overcome these limitations by
combining GC with matrix completion methods (MCM) from machine learning. We use
the novel approach to predict a complete set of pair-interaction parameters for
the most successful GC method: UNIFAC, the workhorse for predicting activity
coefficients in liquid mixtures. The resulting new method, UNIFAC 2.0, is
trained and validated on more than 224,000 experimental data points, showcasing
significantly enhanced prediction accuracy (e.g., nearly halving the mean
squared error) and increased scope by eliminating gaps in the original model's
parameter table. Moreover, the generic nature of the approach facilitates
updating the method with new data or tailoring it to specific applications.",2024-07-25,"Nicolas Hayer, Thorsten Wendel, Stephan Mandt, Hans Hasse, Fabian Jirasek",http://arxiv.org/pdf/2408.05220v1,cs.LG
Network Inversion of Convolutional Neural Nets,"Neural networks have emerged as powerful tools across various applications,
yet their decision-making process often remains opaque, leading to them being
perceived as ""black boxes."" This opacity raises concerns about their
interpretability and reliability, especially in safety-critical scenarios.
Network inversion techniques offer a solution by allowing us to peek inside
these black boxes, revealing the features and patterns learned by the networks
behind their decision-making processes and thereby provide valuable insights
into how neural networks arrive at their conclusions, making them more
interpretable and trustworthy. This paper presents a simple yet effective
approach to network inversion using a meticulously conditioned generator that
learns the data distribution in the input space of the trained neural network,
enabling the reconstruction of inputs that would most likely lead to the
desired outputs. To capture the diversity in the input space for a given
output, instead of simply revealing the conditioning labels to the generator,
we encode the conditioning label information into vectors and intermediate
matrices and further minimize the cosine similarity between features of the
generated images.",2024-07-25,"Pirzada Suhail, Amit Sethi",http://arxiv.org/pdf/2407.18002v2,cs.LG
Lightweight Industrial Cohorted Federated Learning for Heterogeneous Assets,"Federated Learning (FL) is the most widely adopted collaborative learning
approach for training decentralized Machine Learning (ML) models by exchanging
learning between clients without sharing the data and compromising privacy.
However, since great data similarity or homogeneity is taken for granted in all
FL tasks, FL is still not specifically designed for the industrial setting.
Rarely this is the case in industrial data because there are differences in
machine type, firmware version, operational conditions, environmental factors,
and hence, data distribution. Albeit its popularity, it has been observed that
FL performance degrades if the clients have heterogeneous data distributions.
Therefore, we propose a Lightweight Industrial Cohorted FL (LICFL) algorithm
that uses model parameters for cohorting without any additional on-edge
(clientlevel) computations and communications than standard FL and mitigates
the shortcomings from data heterogeneity in industrial applications. Our
approach enhances client-level model performance by allowing them to
collaborate with similar clients and train more specialized or personalized
models. Also, we propose an adaptive aggregation algorithm that extends the
LICFL to Adaptive LICFL (ALICFL) for further improving the global model
performance and speeding up the convergence. Through numerical experiments on
real-time data, we demonstrate the efficacy of the proposed algorithms and
compare the performance with existing approaches.",2024-07-25,"Madapu Amarlingam, Abhishek Wani, Adarsh NL",http://arxiv.org/pdf/2407.17999v1,cs.LG
"iNNspector: Visual, Interactive Deep Model Debugging","Deep learning model design, development, and debugging is a process driven by
best practices, guidelines, trial-and-error, and the personal experiences of
model developers. At multiple stages of this process, performance and internal
model data can be logged and made available. However, due to the sheer
complexity and scale of this data and process, model developers often resort to
evaluating their model performance based on abstract metrics like accuracy and
loss. We argue that a structured analysis of data along the model's
architecture and at multiple abstraction levels can considerably streamline the
debugging process. Such a systematic analysis can further connect the
developer's design choices to their impacts on the model behavior, facilitating
the understanding, diagnosis, and refinement of deep learning models. Hence, in
this paper, we (1) contribute a conceptual framework structuring the data space
of deep learning experiments. Our framework, grounded in literature analysis
and requirements interviews, captures design dimensions and proposes mechanisms
to make this data explorable and tractable. To operationalize our framework in
a ready-to-use application, we (2) present the iNNspector system. iNNspector
enables tracking of deep learning experiments and provides interactive
visualizations of the data on all levels of abstraction from multiple models to
individual neurons. Finally, we (3) evaluate our approach with three real-world
use-cases and a user study with deep learning developers and data analysts,
proving its effectiveness and usability.",2024-07-25,"Thilo Spinner, Daniel Fürst, Mennatallah El-Assady",http://arxiv.org/pdf/2407.17998v1,cs.LG
On the Effect of Purely Synthetic Training Data for Different Automatic Speech Recognition Architectures,"In this work we evaluate the utility of synthetic data for training automatic
speech recognition (ASR). We use the ASR training data to train a
text-to-speech (TTS) system similar to FastSpeech-2. With this TTS we reproduce
the original training data, training ASR systems solely on synthetic data. For
ASR, we use three different architectures, attention-based encoder-decoder,
hybrid deep neural network hidden Markov model and a Gaussian mixture hidden
Markov model, showing the different sensitivity of the models to synthetic data
generation. In order to extend previous work, we present a number of ablation
studies on the effectiveness of synthetic vs. real training data for ASR. In
particular we focus on how the gap between training on synthetic and real data
changes by varying the speaker embedding or by scaling the model size. For the
latter we show that the TTS models generalize well, even when training scores
indicate overfitting.",2024-07-25,"Benedikt Hilmes, Nick Rossenbach, and Ralf Schlüter",http://arxiv.org/pdf/2407.17997v2,cs.LG
Amortized Active Learning for Nonparametric Functions,"Active learning (AL) is a sequential learning scheme aiming to select the
most informative data. AL reduces data consumption and avoids the cost of
labeling large amounts of data. However, AL trains the model and solves an
acquisition optimization for each selection. It becomes expensive when the
model training or acquisition optimization is challenging. In this paper, we
focus on active nonparametric function learning, where the gold standard
Gaussian process (GP) approaches suffer from cubic time complexity. We propose
an amortized AL method, where new data are suggested by a neural network which
is trained up-front without any real data (Figure 1). Our method avoids
repeated model training and requires no acquisition optimization during the AL
deployment. We (i) utilize GPs as function priors to construct an AL simulator,
(ii) train an AL policy that can zero-shot generalize from simulation to real
learning problems of nonparametric functions and (iii) achieve real-time data
selection and comparable learning performances to time-consuming baseline
methods.",2024-07-25,"Cen-You Li, Marc Toussaint, Barbara Rakitsch, Christoph Zimmer",http://arxiv.org/pdf/2407.17992v2,cs.LG
Stay Tuned: An Empirical Study of the Impact of Hyperparameters on LLM Tuning in Real-World Applications,"Fine-tuning Large Language Models (LLMs) is an effective method to enhance
their performance on downstream tasks. However, choosing the appropriate
setting of tuning hyperparameters (HPs) is a labor-intensive and
computationally expensive process. Here, we provide recommended HP
configurations for practical use-cases that represent a better starting point
for practitioners, when considering two SOTA LLMs and two commonly used tuning
methods. We describe Coverage-based Search (CBS), a process for ranking HP
configurations based on an offline extensive grid search, such that the top
ranked configurations collectively provide a practical robust recommendation
for a wide range of datasets and domains. We focus our experiments on
Llama-3-8B and Mistral-7B, as well as full fine-tuning and LoRa, conducting a
total of > 10,000 tuning experiments. Our results suggest that, in general,
Llama-3-8B and LoRA should be preferred, when possible. Moreover, we show that
for both models and tuning methods, exploring only a few HP configurations, as
recommended by our analysis, can provide excellent results in practice, making
this work a valuable resource for practitioners.",2024-07-25,"Alon Halfon, Shai Gretz, Ofir Arviv, Artem Spector, Orith Toledo-Ronen, Yoav Katz, Liat Ein-Dor, Michal Shmueli-Scheuer, Noam Slonim",http://arxiv.org/pdf/2407.18990v2,cs.LG
Relating the Seemingly Unrelated: Principled Understanding of Generalization for Generative Models in Arithmetic Reasoning Tasks,"Large language models (LLMs) have demonstrated impressive versatility across
numerous tasks, yet their generalization capabilities remain poorly understood.
To investigate these behaviors, arithmetic tasks serve as important venues. In
previous studies, seemingly unrelated mysteries still exist -- (1) models with
appropriate positional embeddings can correctly perform longer unseen
arithmetic operations such as addition, but their effectiveness varies in more
complex tasks like multiplication; (2) models perform well for longer unseen
cases in modular addition under specific moduli (e.g., modulo 100) but struggle
under very close moduli (e.g., modulo 101), regardless of the positional
encoding used. We believe previous studies have been treating the symptoms
rather than addressing the root cause -- they have paid excessive attention to
improving model components, while overlooking the differences in task
properties that may be the real drivers. This is confirmed by our unified
theoretical framework for different arithmetic scenarios. For example, unlike
multiplication, the digital addition task has the property of translation
invariance which naturally aligns with the relative positional encoding, and
this combination leads to successful generalization of addition to unseen
longer domains. The discrepancy in operations modulo 100 and 101 arises from
the base. Modulo 100, unlike 101, is compatible with the decimal system (base
10), such that unseen information in digits beyond the units digit and the tens
digit is actually not needed for the task. Extensive experiments with GPT-like
models validate our theoretical predictions. These findings deepen our
understanding of the generalization mechanisms, and facilitate more
data-efficient model training and objective-oriented AI alignment.",2024-07-25,"Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang",http://arxiv.org/pdf/2407.17963v1,cs.LG
Neural Networks for Generating Better Local Optima in Topology Optimization,"Neural networks have recently been employed as material discretizations
within adjoint optimization frameworks for inverse problems and topology
optimization. While advantageous regularization effects and better optima have
been found for some inverse problems, the benefit for topology optimization has
been limited -- where the focus of investigations has been the compliance
problem. We demonstrate how neural network material discretizations can, under
certain conditions, find better local optima in more challenging optimization
problems, where we here specifically consider acoustic topology optimization.
The chances of identifying a better optimum can significantly be improved by
running multiple partial optimizations with different neural network
initializations. Furthermore, we show that the neural network material
discretization's advantage comes from the interplay with the Adam optimizer and
emphasize its current limitations when competing with constrained and
higher-order optimization techniques. At the moment, this discretization has
only been shown to be beneficial for unconstrained first-order optimization.",2024-07-25,"Leon Herrmann, Ole Sigmund, Viola Muning Li, Christian Vogl, Stefan Kollmannsberger",http://arxiv.org/pdf/2407.17957v1,cs.LG
Scaling Training Data with Lossy Image Compression,"Empirically-determined scaling laws have been broadly successful in
predicting the evolution of large machine learning models with training data
and number of parameters. As a consequence, they have been useful for
optimizing the allocation of limited resources, most notably compute time.
  In certain applications, storage space is an important constraint, and data
format needs to be chosen carefully as a consequence. Computer vision is a
prominent example: images are inherently analog, but are always stored in a
digital format using a finite number of bits. Given a dataset of digital
images, the number of bits $L$ to store each of them can be further reduced
using lossy data compression. This, however, can degrade the quality of the
model trained on such images, since each example has lower resolution.
  In order to capture this trade-off and optimize storage of training data, we
propose a `storage scaling law' that describes the joint evolution of test
error with sample size and number of bits per image. We prove that this law
holds within a stylized model for image compression, and verify it empirically
on two computer vision tasks, extracting the relevant parameters. We then show
that this law can be used to optimize the lossy compression level. At given
storage, models trained on optimally compressed images present a significantly
smaller test error with respect to models trained on the original data.
Finally, we investigate the potential benefits of randomizing the compression
level.",2024-07-25,"Katherine L. Mentzer, Andrea Montanari",http://arxiv.org/pdf/2407.17954v1,cs.LG
Real Time American Sign Language Detection Using Yolo-v9,"This paper focuses on real-time American Sign Language Detection. YOLO is a
convolutional neural network (CNN) based model, which was first released in
2015. In recent years, it gained popularity for its real-time detection
capabilities. Our study specifically targets YOLO-v9 model, released in 2024.
As the model is newly introduced, not much work has been done on it, especially
not in Sign Language Detection. Our paper provides deep insight on how YOLO- v9
works and better than previous model.",2024-07-25,"Amna Imran, Meghana Shashishekhara Hulikal, Hamza A. A. Gardi",http://arxiv.org/pdf/2407.17950v1,cs.LG
Fast convergence of the Expectation Maximization algorithm under a logarithmic Sobolev inequality,"By utilizing recently developed tools for constructing gradient flows on
Wasserstein spaces, we extend an analysis technique commonly employed to
understand alternating minimization algorithms on Euclidean space to the
Expectation Maximization (EM) algorithm via its representation as
coordinate-wise minimization on the product of a Euclidean space and a space of
probability distributions due to Neal and Hinton (1998). In so doing we obtain
finite sample error bounds and exponential convergence of the EM algorithm
under a natural generalisation of a log-Sobolev inequality. We further
demonstrate that the analysis technique is sufficiently flexible to allow also
the analysis of several variants of the EM algorithm.",2024-07-25,"Rocco Caprio, Adam M Johansen",http://arxiv.org/pdf/2407.17949v1,cs.LG
Comparison of different Artificial Neural Networks for Bitcoin price forecasting,"This study investigates the impact of varying sequence lengths on the
accuracy of predicting cryptocurrency returns using Artificial Neural Networks
(ANNs). Utilizing the Mean Absolute Error (MAE) as a threshold criterion, we
aim to enhance prediction accuracy by excluding returns that are smaller than
this threshold, thus mitigating errors associated with minor returns. The
subsequent evaluation focuses on the accuracy of predicted returns that exceed
this threshold. We compare four sequence lengths 168 hours (7 days), 72 hours
(3 days), 24 hours, and 12 hours each with a return prediction interval of 2
hours. Our findings reveal the influence of sequence length on prediction
accuracy and underscore the potential for optimized sequence configurations in
financial forecasting models.",2024-07-25,"Silas Baumann, Karl A. Busch, Hamza A. A. Gardi",http://arxiv.org/pdf/2407.17930v1,cs.LG
Guided Latent Slot Diffusion for Object-Centric Learning,"Slot attention aims to decompose an input image into a set of meaningful
object files (slots). These latent object representations enable various
downstream tasks. Yet, these slots often bind to object parts, not objects
themselves, especially for real-world datasets. To address this, we introduce
Guided Latent Slot Diffusion - GLASS, an object-centric model that uses
generated captions as a guiding signal to better align slots with objects. Our
key insight is to learn the slot-attention module in the space of generated
images. This allows us to repurpose the pre-trained diffusion decoder model,
which reconstructs the images from the slots, as a semantic mask generator
based on the generated captions. GLASS learns an object-level representation
suitable for multiple tasks simultaneously, e.g., segmentation, image
generation, and property prediction, outperforming previous methods. For object
discovery, GLASS achieves approx. a +35% and +10% relative improvement for mIoU
over the previous state-of-the-art (SOTA) method on the VOC and COCO datasets,
respectively, and establishes a new SOTA FID score for conditional image
generation amongst slot-attention-based methods. For the segmentation task,
GLASS surpasses SOTA weakly-supervised and language-based segmentation models,
which were specifically designed for the task.",2024-07-25,"Krishnakant Singh, Simone Schaub-Meyer, Stefan Roth",http://arxiv.org/pdf/2407.17929v1,cs.LG
Exploring the Plausibility of Hate and Counter Speech Detectors with Explainable AI,"In this paper we investigate the explainability of transformer models and
their plausibility for hate speech and counter speech detection. We compare
representatives of four different explainability approaches, i.e.,
gradient-based, perturbation-based, attention-based, and prototype-based
approaches, and analyze them quantitatively with an ablation study and
qualitatively in a user study. Results show that perturbation-based
explainability performs best, followed by gradient-based and attention-based
explainability. Prototypebased experiments did not yield useful results.
Overall, we observe that explainability strongly supports the users in better
understanding the model predictions.",2024-07-25,"Adrian Jaques Böck, Djordje Slijepčević, Matthias Zeppelzauer",http://arxiv.org/pdf/2407.20274v1,cs.LG
Causal Deepsets for Off-policy Evaluation under Spatial or Spatio-temporal Interferences,"Off-policy evaluation (OPE) is widely applied in sectors such as
pharmaceuticals and e-commerce to evaluate the efficacy of novel products or
policies from offline datasets. This paper introduces a causal deepset
framework that relaxes several key structural assumptions, primarily the
mean-field assumption, prevalent in existing OPE methodologies that handle
spatio-temporal interference. These traditional assumptions frequently prove
inadequate in real-world settings, thereby restricting the capability of
current OPE methods to effectively address complex interference effects. In
response, we advocate for the implementation of the permutation invariance (PI)
assumption. This innovative approach enables the data-driven, adaptive learning
of the mean-field function, offering a more flexible estimation method beyond
conventional averaging. Furthermore, we present novel algorithms that
incorporate the PI assumption into OPE and thoroughly examine their theoretical
foundations. Our numerical analyses demonstrate that this novel approach yields
significantly more precise estimations than existing baseline algorithms,
thereby substantially improving the practical applicability and effectiveness
of OPE methodologies. A Python implementation of our proposed method is
available at https://github.com/BIG-S2/Causal-Deepsets.",2024-07-25,"Runpeng Dai, Jianing Wang, Fan Zhou, Shikai Luo, Zhiwei Qin, Chengchun Shi, Hongtu Zhu",http://arxiv.org/pdf/2407.17910v1,cs.LG
Separating Novel Features for Logical Anomaly Detection: A Straightforward yet Effective Approach,"Vision-based inspection algorithms have significantly contributed to quality
control in industrial settings, particularly in addressing structural defects
like dent and contamination which are prevalent in mass production. Extensive
research efforts have led to the development of related benchmarks such as
MVTec AD (Bergmann et al., 2019). However, in industrial settings, there can be
instances of logical defects, where acceptable items are found in unsuitable
locations or product pairs do not match as expected. Recent methods tackling
logical defects effectively employ knowledge distillation to generate
difference maps. Knowledge distillation (KD) is used to learn normal data
distribution in unsupervised manner. Despite their effectiveness, these methods
often overlook the potential false negatives. Excessive similarity between the
teacher network and student network can hinder the generation of a suitable
difference map for logical anomaly detection. This technical report provides
insights on handling potential false negatives by utilizing a simple constraint
in KD-based logical anomaly detection methods. We select EfficientAD as a
state-of-the-art baseline and apply a margin-based constraint to its
unsupervised learning scheme. Applying this constraint, we can improve the
AUROC for MVTec LOCO AD by 1.3 %.",2024-07-25,"Kangil Lee, Geonuk Kim",http://arxiv.org/pdf/2407.17909v1,cs.LG
Amortized Posterior Sampling with Diffusion Prior Distillation,"We propose a variational inference approach to sample from the posterior
distribution for solving inverse problems. From a pre-trained diffusion model,
our approach trains a conditional flow model to minimize the divergence between
the proposal variational distribution and the posterior distribution implicitly
defined through the diffusion model. Once trained, the flow model is capable of
sampling from the posterior distribution with a single NFE, amortized with
respect to the measurement. The proposed method paves a new path for distilling
a diffusion prior for efficient posterior sampling. We show that our method is
applicable to standard signals in Euclidean space, as well as signals on
manifold.",2024-07-25,"Abbas Mammadov, Hyungjin Chung, Jong Chul Ye",http://arxiv.org/pdf/2407.17907v1,cs.LG
The Power of Combining Data and Knowledge: GPT-4o is an Effective Interpreter of Machine Learning Models in Predicting Lymph Node Metastasis of Lung Cancer,"Lymph node metastasis (LNM) is a crucial factor in determining the initial
treatment for patients with lung cancer, yet accurate preoperative diagnosis of
LNM remains challenging. Recently, large language models (LLMs) have garnered
significant attention due to their remarkable text generation capabilities.
Leveraging the extensive medical knowledge learned from vast corpora, LLMs can
estimate probabilities for clinical problems, though their performance has
historically been inferior to data-driven machine learning models. In this
paper, we propose a novel ensemble method that combines the medical knowledge
acquired by LLMs with the latent patterns identified by machine learning models
to enhance LNM prediction performance. Initially, we developed machine learning
models using patient data. We then designed a prompt template to integrate the
patient data with the predicted probability from the machine learning model.
Subsequently, we instructed GPT-4o, the most advanced LLM developed by OpenAI,
to estimate the likelihood of LNM based on patient data and then adjust the
estimate using the machine learning output. Finally, we collected three outputs
from the GPT-4o using the same prompt and ensembled these results as the final
prediction. Using the proposed method, our models achieved an AUC value of
0.778 and an AP value of 0.426 for LNM prediction, significantly improving
predictive performance compared to baseline machine learning models. The
experimental results indicate that GPT-4o can effectively leverage its medical
knowledge and the probabilities predicted by machine learning models to achieve
more accurate LNM predictions. These findings demonstrate that LLMs can perform
well in clinical risk prediction tasks, offering a new paradigm for integrating
medical knowledge and patient data in clinical predictions.",2024-07-25,"Danqing Hu, Bing Liu, Xiaofeng Zhu, Nan Wu",http://arxiv.org/pdf/2407.17900v5,cs.LG
An Iterative Approach to Topic Modelling,"Topic modelling has become increasingly popular for summarizing text data,
such as social media posts and articles. However, topic modelling is usually
completed in one shot. Assessing the quality of resulting topics is
challenging. No effective methods or measures have been developed for assessing
the results or for making further enhancements to the topics. In this research,
we propose we propose to use an iterative process to perform topic modelling
that gives rise to a sense of completeness of the resulting topics when the
process is complete. Using the BERTopic package, a popular method in topic
modelling, we demonstrate how the modelling process can be applied iteratively
to arrive at a set of topics that could not be further improved upon using one
of the three selected measures for clustering comparison as the decision
criteria. This demonstration is conducted using a subset of the COVIDSenti-A
dataset. The early success leads us to believe that further research using in
using this approach in conjunction with other topic modelling algorithms could
be viable.",2024-07-25,"Albert Wong, Florence Wing Yau Cheng, Ashley Keung, Yamileth Hercules, Mary Alexandra Garcia, Yew-Wei Lim, Lien Pham",http://arxiv.org/pdf/2407.17892v1,cs.LG
Ontology of Belief Diversity: A Community-Based Epistemological Approach,"AI applications across classification, fairness, and human interaction often
implicitly require ontologies of social concepts. Constructing these well,
especially when there are many relevant categories, is a controversial task but
is crucial for achieving meaningful inclusivity. Here, we focus on developing a
pragmatic ontology of belief systems, which is a complex and often
controversial space. By iterating on our community-based design until mutual
agreement is reached, we found that epistemological methods were best for
categorizing the fundamental ways beliefs differ, maximally respecting our
principles of inclusivity and brevity. We demonstrate our methodology's utility
and interpretability via user studies in term annotation and sentiment analysis
experiments for belief fairness in language models.",2024-07-25,"Tyler Fischella, Erin van Liemt, Qiuyi, Zhang",http://arxiv.org/pdf/2408.01455v1,cs.LG
DAM: Towards A Foundation Model for Time Series Forecasting,"It is challenging to scale time series forecasting models such that they
forecast accurately for multiple distinct domains and datasets, all with
potentially different underlying collection procedures (e.g., sample
resolution), patterns (e.g., periodicity), and prediction requirements (e.g.,
reconstruction vs. forecasting). We call this general task universal
forecasting. Existing methods usually assume that input data is regularly
sampled, and they forecast to pre-determined horizons, resulting in failure to
generalise outside of the scope of their training. We propose the DAM - a
neural model that takes randomly sampled histories and outputs an adjustable
basis composition as a continuous function of time for forecasting to non-fixed
horizons. It involves three key components: (1) a flexible approach for using
randomly sampled histories from a long-tail distribution, that enables an
efficient global perspective of the underlying temporal dynamics while
retaining focus on the recent history; (2) a transformer backbone that is
trained on these actively sampled histories to produce, as representational
output, (3) the basis coefficients of a continuous function of time. We show
that a single univariate DAM, trained on 25 time series datasets, either
outperformed or closely matched existing SoTA models at multivariate long-term
forecasting across 18 datasets, including 8 held-out for zero-shot transfer,
even though these models were trained to specialise for each dataset-horizon
combination. This single DAM excels at zero-shot transfer and very-long-term
forecasting, performs well at imputation, is interpretable via basis function
composition and attention, can be tuned for different inference-cost
requirements, is robust to missing and irregularly sampled data {by design}.",2024-07-25,"Luke Darlow, Qiwen Deng, Ahmed Hassan, Martin Asenov, Rajkarn Singh, Artjom Joosen, Adam Barker, Amos Storkey",http://arxiv.org/pdf/2407.17880v1,cs.LG
A Large-Scale Sensitivity Analysis on Latent Embeddings and Dimensionality Reductions for Text Spatializations,"The semantic similarity between documents of a text corpus can be visualized
using map-like metaphors based on two-dimensional scatterplot layouts. These
layouts result from a dimensionality reduction on the document-term matrix or a
representation within a latent embedding, including topic models. Thereby, the
resulting layout depends on the input data and hyperparameters of the
dimensionality reduction and is therefore affected by changes in them.
Furthermore, the resulting layout is affected by changes in the input data and
hyperparameters of the dimensionality reduction. However, such changes to the
layout require additional cognitive efforts from the user. In this work, we
present a sensitivity study that analyzes the stability of these layouts
concerning (1) changes in the text corpora, (2) changes in the hyperparameter,
and (3) randomness in the initialization. Our approach has two stages: data
measurement and data analysis. First, we derived layouts for the combination of
three text corpora and six text embeddings and a grid-search-inspired
hyperparameter selection of the dimensionality reductions. Afterward, we
quantified the similarity of the layouts through ten metrics, concerning local
and global structures and class separation. Second, we analyzed the resulting
42817 tabular data points in a descriptive statistical analysis. From this, we
derived guidelines for informed decisions on the layout algorithm and highlight
specific hyperparameter settings. We provide our implementation as a Git
repository at
https://github.com/hpicgs/Topic-Models-and-Dimensionality-Reduction-Sensitivity-Study
and results as Zenodo archive at https://doi.org/10.5281/zenodo.12772898.",2024-07-25,"Daniel Atzberger, Tim Cech, Willy Scheibel, Jürgen Döllner, Michael Behrisch, Tobias Schreck",http://arxiv.org/pdf/2407.17876v1,cs.LG
EllipBench: A Large-scale Benchmark for Machine-learning based Ellipsometry Modeling,"Ellipsometry is used to indirectly measure the optical properties and
thickness of thin films. However, solving the inverse problem of ellipsometry
is time-consuming since it involves human expertise to apply the data fitting
techniques. Many studies use traditional machine learning-based methods to
model the complex mathematical fitting process. In our work, we approach this
problem from a deep learning perspective. First, we introduce a large-scale
benchmark dataset to facilitate deep learning methods. The proposed dataset
encompasses 98 types of thin film materials and 4 types of substrate materials,
including metals, alloys, compounds, and polymers, among others. Additionally,
we propose a deep learning framework that leverages residual connections and
self-attention mechanisms to learn the massive data points. We also introduce a
reconstruction loss to address the common challenge of multiple solutions in
thin film thickness prediction. Compared to traditional machine learning
methods, our framework achieves state-of-the-art (SOTA) performance on our
proposed dataset. The dataset and code will be available upon acceptance.",2024-07-25,"Yiming Ma, Xinjie Li, Xin Sun, Zhiyong Wang, Lionel Z. Wang",http://arxiv.org/pdf/2407.17869v1,cs.LG
Bounds on the geodesic distances on the Stiefel manifold for a family of Riemannian metrics,"We give bounds on geodesic distances on the Stiefel manifold, derived from
new geometric insights. The considered geodesic distances are induced by the
one-parameter family of Riemannian metrics introduced by H\""uper et al. (2021),
which contains the well-known Euclidean and canonical metrics. First, we give
the best Lipschitz constants between the distances induced by any two members
of the family of metrics. Then, we give a lower and an upper bound on the
geodesic distance by the easily computable Frobenius distance. We give explicit
families of pairs of matrices that depend on the parameter of the metric and
the dimensions of the manifold, where the lower and the upper bound are
attained. These bounds aim at improving the theoretical guarantees and
performance of minimal geodesic computation algorithms by reducing the initial
velocity search space. In addition, these findings contribute to advancing the
understanding of geodesic distances on the Stiefel manifold and their
applications.",2024-07-25,"Simon Mataigne, P. -A. Absil, Nina Miolane",http://arxiv.org/pdf/2408.07072v1,cs.LG
Learning Physics-Consistent Material Behavior from Dynamic Displacements,"Accurately modeling the mechanical behavior of materials is crucial for
numerous engineering applications. The quality of these models depends directly
on the accuracy of the constitutive law that defines the stress-strain
relation. However, discovering these constitutive material laws remains a
significant challenge, in particular when only material deformation data is
available. To address this challenge, unsupervised machine learning methods
have been proposed to learn the constitutive law from deformation data.
Nonetheless, existing approaches have several limitations: they either fail to
ensure that the learned constitutive relations are consistent with physical
principles, or they rely on boundary force data for training which are
unavailable in many in-situ scenarios. Here, we introduce a machine learning
approach to learn physics-consistent constitutive relations solely from
material deformation without boundary force information. This is achieved by
considering a dynamic formulation rather than static equilibrium data and
applying an input convex neural network (ICNN). We validate the effectiveness
of the proposed method on a diverse range of hyperelastic material laws. We
demonstrate that it is robust to a significant level of noise and that it
converges to the ground truth with increasing data resolution. We also show
that the model can be effectively trained using a displacement field from a
subdomain of the test specimen and that the learned constitutive relation from
one material sample is transferable to other samples with different geometries.
The developed methodology provides an effective tool for discovering
constitutive relations. It is, due to its design based on dynamics,
particularly suited for applications to strain-rate-dependent materials and
situations where constitutive laws need to be inferred from in-situ
measurements without access to global force data.",2024-07-25,"Zhichao Han, Mohit Pundir, Olga Fink, David S. Kammer",http://arxiv.org/pdf/2407.20273v2,cs.LG
Enhancing clinical decision support with physiological waveforms -- a multimodal benchmark in emergency care,"Background: AI-driven prediction algorithms have the potential to enhance
emergency medicine by enabling rapid and accurate decision-making regarding
patient status and potential deterioration. However, the integration of
multimodal data, including raw waveform signals, remains underexplored in
clinical decision support. Methods: We present a dataset and benchmarking
protocol designed to advance multimodal decision support in emergency care. Our
models utilize demographics, biometrics, vital signs, laboratory values, and
electrocardiogram (ECG) waveforms as inputs to predict both discharge diagnoses
and patient deterioration. Results: The diagnostic model achieves area under
the receiver operating curve (AUROC) scores above 0.8 for 609 out of 1,428
conditions, covering both cardiac (e.g., myocardial infarction) and non-cardiac
(e.g., renal disease, diabetes) diagnoses. The deterioration model attains
AUROC scores above 0.8 for 14 out of 15 targets, accurately predicting critical
events such as cardiac arrest, mechanical ventilation, ICU admission, and
mortality. Conclusions: Our study highlights the positive impact of
incorporating raw waveform data into decision support models, improving
predictive performance. By introducing a unique, publicly available dataset and
baseline models, we provide a foundation for measurable progress in AI-driven
decision support for emergency care.",2024-07-25,"Juan Miguel Lopez Alcaraz, Hjalmar Bouma, Nils Strodthoff",http://arxiv.org/pdf/2407.17856v4,cs.LG
"Physics-guided machine learning predicts the planet-scale performance of solar farms with sparse, heterogeneous, public data","The photovoltaics (PV) technology landscape is evolving rapidly. To predict
the potential and scalability of emerging PV technologies, a global
understanding of these systems' performance is essential. Traditionally,
experimental and computational studies at large national research facilities
have focused on PV performance in specific regional climates. However,
synthesizing these regional studies to understand the worldwide performance
potential has proven difficult. Given the expense of obtaining experimental
data, the challenge of coordinating experiments at national labs across a
politically-divided world, and the data-privacy concerns of large commercial
operators, however, a fundamentally different, data-efficient approach is
desired. Here, we present a physics-guided machine learning (PGML) scheme to
demonstrate that: (a) The world can be divided into a few PV-specific climate
zones, called PVZones, illustrating that the relevant meteorological conditions
are shared across continents; (b) by exploiting the climatic similarities,
high-quality monthly energy yield data from as few as five locations can
accurately predict yearly energy yield potential with high spatial resolution
and a root mean square error of less than 8 kWhm$^{2}$, and (c) even with
noisy, heterogeneous public PV performance data, the global energy yield can be
predicted with less than 6% relative error compared to physics-based
simulations provided that the dataset is representative. This PGML scheme is
agnostic to PV technology and farm topology, making it adaptable to new PV
technologies or farm configurations. The results encourage physics-guided,
data-driven collaboration among national policymakers and research
organizations to build efficient decision support systems for accelerated PV
qualification and deployment across the world.",2024-07-25,"Jabir Bin Jahangir, Muhammad Ashraful Alam",http://arxiv.org/pdf/2407.18284v1,cs.LG
Innovative Speech-Based Deep Learning Approaches for Parkinson's Disease Classification: A Systematic Review,"Parkinson's disease (PD), the second most prevalent neurodegenerative
disorder worldwide, frequently presents with early-stage speech impairments.
Recent advancements in Artificial Intelligence (AI), particularly deep learning
(DL), have significantly enhanced PD diagnosis through the analysis of speech
data. Nevertheless, the progress of research is restricted by the limited
availability of publicly accessible speech-based PD datasets, primarily due to
privacy concerns. The goal of this systematic review is to explore the current
landscape of speech-based DL approaches for PD classification, based on 33
scientific works published between January 2020 and March 2024. We discuss
their available resources, capabilities, and potential limitations, and issues
related to bias, explainability, and privacy. Furthermore, this review provides
an overview of publicly accessible speech-based datasets and open-source
material for PD. The DL approaches identified are categorized into end-to-end
(E2E) learning, transfer learning (TL), and deep acoustic feature extraction
(DAFE). Among E2E approaches, Convolutional Neural Networks (CNNs) are
prevalent, though Transformers are increasingly popular. E2E approaches face
challenges such as limited data and computational resources, especially with
Transformers. TL addresses these issues by providing more robust PD diagnosis
and better generalizability across languages. DAFE aims to improve the
explainability and interpretability of results by examining the specific
effects of deep features on both other DL approaches and more traditional
machine learning (ML) methods. However, it often underperforms compared to E2E
and TL approaches.",2024-07-25,"Lisanne van Gelderen, Cristian Tejedor-García",http://arxiv.org/pdf/2407.17844v4,cs.LG
On the Opportunities of (Re)-Exploring Atmospheric Science by Foundation Models: A Case Study,"Most state-of-the-art AI applications in atmospheric science are based on
classic deep learning approaches. However, such approaches cannot automatically
integrate multiple complicated procedures to construct an intelligent agent,
since each functionality is enabled by a separate model learned from
independent climate datasets. The emergence of foundation models, especially
multimodal foundation models, with their ability to process heterogeneous input
data and execute complex tasks, offers a substantial opportunity to overcome
this challenge. In this report, we want to explore a central question - how the
state-of-the-art foundation model, i.e., GPT-4o, performs various atmospheric
scientific tasks. Toward this end, we conduct a case study by categorizing the
tasks into four main classes, including climate data processing, physical
diagnosis, forecast and prediction, and adaptation and mitigation. For each
task, we comprehensively evaluate the GPT-4o's performance along with a
concrete discussion. We hope that this report may shed new light on future AI
applications and research in atmospheric science.",2024-07-25,"Lujia Zhang, Hanzhe Cui, Yurong Song, Chenyue Li, Binhang Yuan, Mengqian Lu",http://arxiv.org/pdf/2407.17842v1,cs.LG
Long-term Fairness in Ride-Hailing Platform,"Matching in two-sided markets such as ride-hailing has recently received
significant attention. However, existing studies on ride-hailing mainly focus
on optimising efficiency, and fairness issues in ride-hailing have been
neglected. Fairness issues in ride-hailing, including significant earning
differences between drivers and variance of passenger waiting times among
different locations, have potential impacts on economic and ethical aspects.
The recent studies that focus on fairness in ride-hailing exploit traditional
optimisation methods and the Markov Decision Process to balance efficiency and
fairness. However, there are several issues in these existing studies, such as
myopic short-term decision-making from traditional optimisation and instability
of fairness in a comparably longer horizon from both traditional optimisation
and Markov Decision Process-based methods. To address these issues, we propose
a dynamic Markov Decision Process model to alleviate fairness issues currently
faced by ride-hailing, and seek a balance between efficiency and fairness, with
two distinct characteristics: (i) a prediction module to predict the number of
requests that will be raised in the future from different locations to allow
the proposed method to consider long-term fairness based on the whole timeline
instead of consider fairness only based on historical and current data
patterns; (ii) a customised scalarisation function for multi-objective
multi-agent Q Learning that aims to balance efficiency and fairness. Extensive
experiments on a publicly available real-world dataset demonstrate that our
proposed method outperforms existing state-of-the-art methods.",2024-07-25,"Yufan Kang, Jeffrey Chan, Wei Shao, Flora D. Salim, Christopher Leckie",http://arxiv.org/pdf/2407.17839v1,cs.LG
An Efficient Inference Framework for Early-exit Large Language Models,"Building efficient inference framework has gained increasing interests for
research community. Early-exit models, a variant of LLMs, improves the
inference efficiency of LLMs by skipping rest layers and directly generate
output tokens when they are confident enough. However, there is no work of LLM
inference framework that takes early-exit models into consideration. This is
non-trivial as prior art on LLM inference cannot be directly applied to
early-exit models. In this work, we solves two key challenges in building
efficient inference framework for early-exit models: (1) batch inference at
iteration-level granularity; and (2) KV cache management. For the former, we
propose to process the batch until all sequences surpass the early-exit
confidence threshold. For the latter, we propose to fill the KV cache of rest
layers before the iteration terminates. Our evaluation shows that, compared
with the original vLLM operating at full layers, our solution achieves up to
1.25x speed up.",2024-07-25,"Ruijie Miao, Yihan Yan, Xinshuo Yao, Tong Yang",http://arxiv.org/pdf/2407.20272v1,cs.LG
IsUMap: Manifold Learning and Data Visualization leveraging Vietoris-Rips filtrations,"This work introduces IsUMap, a novel manifold learning technique that
enhances data representation by integrating aspects of UMAP and Isomap with
Vietoris-Rips filtrations. We present a systematic and detailed construction of
a metric representation for locally distorted metric spaces that captures
complex data structures more accurately than the previous schemes. Our approach
addresses limitations in existing methods by accommodating non-uniform data
distributions and intricate local geometries. We validate its performance
through extensive experiments on examples of various geometric objects and
benchmark real-world datasets, demonstrating significant improvements in
representation quality.",2024-07-25,"Lukas Silvester Barth, Fatemeh, Fahimi, Parvaneh Joharinad, Jürgen Jost, Janis Keck",http://arxiv.org/pdf/2407.17835v1,cs.LG
Image Segmentation via Divisive Normalization: dealing with environmental diversity,"Autonomous driving is a challenging scenario for image segmentation due to
the presence of uncontrolled environmental conditions and the eventually
catastrophic consequences of failures. Previous work suggested that a
biologically motivated computation, the so-called Divisive Normalization, could
be useful to deal with image variability, but its effects have not been
systematically studied over different data sources and environmental factors.
Here we put segmentation U-nets augmented with Divisive Normalization to work
far from training conditions to find where this adaptation is more critical. We
categorize the scenes according to their radiance level and dynamic range
(day/night), and according to their achromatic/chromatic contrasts. We also
consider video game (synthetic) images to broaden the range of environments. We
check the performance in the extreme percentiles of such categorization. Then,
we push the limits further by artificially modifying the images in
perceptually/environmentally relevant dimensions: luminance, contrasts and
spectral radiance. Results show that neural networks with Divisive
Normalization get better results in all the scenarios and their performance
remains more stable with regard to the considered environmental factors and
nature of the source. Finally, we explain the improvements in segmentation
performance in two ways: (1) by quantifying the invariance of the responses
that incorporate Divisive Normalization, and (2) by illustrating the adaptive
nonlinearity of the different layers that depends on the local activity.",2024-07-25,"Pablo Hernández-Cámara, Jorge Vila-Tomás, Paula Dauden-Oliver, Nuria Alabau-Bosque, Valero Laparra, Jesús Malo",http://arxiv.org/pdf/2407.17829v1,cs.LG
Unified Lexical Representation for Interpretable Visual-Language Alignment,"Visual-Language Alignment (VLA) has gained a lot of attention since CLIP's
groundbreaking work. Although CLIP performs well, the typical direct latent
feature alignment lacks clarity in its representation and similarity scores. On
the other hand, lexical representation, a vector whose element represents the
similarity between the sample and a word from the vocabulary, is a natural
sparse representation and interpretable, providing exact matches for individual
words. However, lexical representations are difficult to learn due to no
ground-truth supervision and false-discovery issues, and thus requires complex
design to train effectively. In this paper, we introduce LexVLA, a more
interpretable VLA framework by learning a unified lexical representation for
both modalities without complex design. We use DINOv2 as our visual model for
its local-inclined features and Llama 2, a generative language model, to
leverage its in-context lexical prediction ability. To avoid the false
discovery, we propose an overuse penalty to refrain the lexical representation
from falsely frequently activating meaningless words. We demonstrate that these
two pre-trained uni-modal models can be well-aligned by fine-tuning on the
modest multi-modal dataset and avoid intricate training configurations. On
cross-modal retrieval benchmarks, LexVLA, trained on the CC-12M multi-modal
dataset, outperforms baselines fine-tuned on larger datasets (e.g., YFCC15M)
and those trained from scratch on even bigger datasets (e.g., 1.1B data,
including CC-12M). We conduct extensive experiments to analyze LexVLA. Codes
are available at https://github.com/Clementine24/LexVLA.",2024-07-25,"Yifan Li, Yikai Wang, Yanwei Fu, Dongyu Ru, Zheng Zhang, Tong He",http://arxiv.org/pdf/2407.17827v2,cs.LG
Optimal Hessian/Jacobian-Free Nonconvex-PL Bilevel Optimization,"Bilevel optimization is widely applied in many machine learning tasks such as
hyper-parameter learning, meta learning and reinforcement learning. Although
many algorithms recently have been developed to solve the bilevel optimization
problems, they generally rely on the (strongly) convex lower-level problems.
More recently, some methods have been proposed to solve the nonconvex-PL
bilevel optimization problems, where their upper-level problems are possibly
nonconvex, and their lower-level problems are also possibly nonconvex while
satisfying Polyak-{\L}ojasiewicz (PL) condition. However, these methods still
have a high convergence complexity or a high computation complexity such as
requiring compute expensive Hessian/Jacobian matrices and its inverses. In the
paper, thus, we propose an efficient Hessian/Jacobian-free method (i.e.,
HJFBiO) with the optimal convergence complexity to solve the nonconvex-PL
bilevel problems. Theoretically, under some mild conditions, we prove that our
HJFBiO method obtains an optimal convergence rate of $O(\frac{1}{T})$, where
$T$ denotes the number of iterations, and has an optimal gradient complexity of
$O(\epsilon^{-1})$ in finding an $\epsilon$-stationary solution. We conduct
some numerical experiments on the bilevel PL game and hyper-representation
learning task to demonstrate efficiency of our proposed method.",2024-07-25,Feihu Huang,http://arxiv.org/pdf/2407.17823v1,cs.LG
Advanced deep-reinforcement-learning methods for flow control: group-invariant and positional-encoding networks improve learning speed and quality,"Flow control is key to maximize energy efficiency in a wide range of
applications. However, traditional flow-control methods face significant
challenges in addressing non-linear systems and high-dimensional data, limiting
their application in realistic energy systems. This study advances
deep-reinforcement-learning (DRL) methods for flow control, particularly
focusing on integrating group-invariant networks and positional encoding into
DRL architectures. Our methods leverage multi-agent reinforcement learning
(MARL) to exploit policy invariance in space, in combination with
group-invariant networks to ensure local symmetry invariance. Additionally, a
positional encoding inspired by the transformer architecture is incorporated to
provide location information to the agents, mitigating action constraints from
strict invariance. The proposed methods are verified using a case study of
Rayleigh-B\'enard convection, where the goal is to minimize the Nusselt number
Nu. The group-invariant neural networks (GI-NNs) show faster convergence
compared to the base MARL, achieving better average policy performance. The
GI-NNs not only cut DRL training time in half but also notably enhance learning
reproducibility. Positional encoding further enhances these results,
effectively reducing the minimum Nu and stabilizing convergence. Interestingly,
group invariant networks specialize in improving learning speed and positional
encoding specializes in improving learning quality. These results demonstrate
that choosing a suitable feature-representation method according to the purpose
as well as the characteristics of each control problem is essential. We believe
that the results of this study will not only inspire novel DRL methods with
invariant and unique representations, but also provide useful insights for
industrial applications.",2024-07-25,"Joongoo Jeon, Jean Rabault, Joel Vasanth, Francisco Alcántara-Ávila, Shilaj Baral, Ricardo Vinuesa",http://arxiv.org/pdf/2407.17822v2,cs.LG
Demystifying Verbatim Memorization in Large Language Models,"Large Language Models (LLMs) frequently memorize long sequences verbatim,
often with serious legal and privacy implications. Much prior work has studied
such verbatim memorization using observational data. To complement such work,
we develop a framework to study verbatim memorization in a controlled setting
by continuing pre-training from Pythia checkpoints with injected sequences. We
find that (1) non-trivial amounts of repetition are necessary for verbatim
memorization to happen; (2) later (and presumably better) checkpoints are more
likely to verbatim memorize sequences, even for out-of-distribution sequences;
(3) the generation of memorized sequences is triggered by distributed model
states that encode high-level features and makes important use of general
language modeling capabilities. Guided by these insights, we develop stress
tests to evaluate unlearning methods and find they often fail to remove the
verbatim memorized information, while also degrading the LM. Overall, these
findings challenge the hypothesis that verbatim memorization stems from
specific model weights or mechanisms. Rather, verbatim memorization is
intertwined with the LM's general capabilities and thus will be very difficult
to isolate and suppress without degrading model quality.",2024-07-25,"Jing Huang, Diyi Yang, Christopher Potts",http://arxiv.org/pdf/2407.17817v1,cs.LG
NC-NCD: Novel Class Discovery for Node Classification,"Novel Class Discovery (NCD) involves identifying new categories within
unlabeled data by utilizing knowledge acquired from previously established
categories. However, existing NCD methods often struggle to maintain a balance
between the performance of old and new categories. Discovering unlabeled new
categories in a class-incremental way is more practical but also more
challenging, as it is frequently hindered by either catastrophic forgetting of
old categories or an inability to learn new ones. Furthermore, the
implementation of NCD on continuously scalable graph-structured data remains an
under-explored area. In response to these challenges, we introduce for the
first time a more practical NCD scenario for node classification (i.e.,
NC-NCD), and propose a novel self-training framework with prototype replay and
distillation called SWORD, adopted to our NC-NCD setting. Our approach enables
the model to cluster unlabeled new category nodes after learning labeled nodes
while preserving performance on old categories without reliance on old category
nodes. SWORD achieves this by employing a self-training strategy to learn new
categories and preventing the forgetting of old categories through the joint
use of feature prototypes and knowledge distillation. Extensive experiments on
four common benchmarks demonstrate the superiority of SWORD over other
state-of-the-art methods.",2024-07-25,"Yue Hou, Xueyuan Chen, He Zhu, Romei Liu, Bowen Shi, Jiaheng Liu, Junran Wu, Ke Xu",http://arxiv.org/pdf/2407.17816v1,cs.LG
"Nested replicator dynamics, nested logit choice, and similarity-based learning","We consider a model of learning and evolution in games whose action sets are
endowed with a partition-based similarity structure intended to capture
exogenous similarities between strategies. In this model, revising agents have
a higher probability of comparing their current strategy with other strategies
that they deem similar, and they switch to the observed strategy with
probability proportional to its payoff excess. Because of this implicit bias
toward similar strategies, the resulting dynamics - which we call the nested
replicator dynamics - do not satisfy any of the standard monotonicity
postulates for imitative game dynamics; nonetheless, we show that they retain
the main long-run rationality properties of the replicator dynamics, albeit at
quantitatively different rates. We also show that the induced dynamics can be
viewed as a stimulus-response model in the spirit of Erev & Roth (1998), with
choice probabilities given by the nested logit choice rule of Ben-Akiva (1973)
and McFadden (1978). This result generalizes an existing relation between the
replicator dynamics and the exponential weights algorithm in online learning,
and provides an additional layer of interpretation to our analysis and results.",2024-07-25,"Panayotis Mertikopoulos, William H. Sandholm",http://arxiv.org/pdf/2407.17815v1,cs.LG
Learn while Unlearn: An Iterative Unlearning Framework for Generative Language Models,"Recent advances in machine learning, particularly in Natural Language
Processing (NLP), have produced powerful models trained on vast datasets.
However, these models risk leaking sensitive information, raising privacy
concerns. In response, regulatory measures such as the European Union's General
Data Protection Regulation (GDPR) have driven increasing interest in Machine
Unlearning techniques, which enable models to selectively forget specific data
entries. Early unlearning approaches primarily relied on pre-processing
methods, while more recent research has shifted towards training-based
solutions. Despite their effectiveness, a key limitation persists: most methods
require access to original training data, which is often unavailable.
Additionally, directly applying unlearning techniques bears the cost of
undermining the model's expressive capabilities. To address these challenges,
we introduce the Iterative Contrastive Unlearning (ICU) framework, which
consists of three core components: A Knowledge Unlearning Induction module
designed to target specific knowledge for removal using an unlearning loss; A
Contrastive Learning Enhancement module to preserve the model's expressive
capabilities against the pure unlearning goal; And an Iterative Unlearning
Refinement module that dynamically adjusts the unlearning process through
ongoing evaluation and updates. Experimental results demonstrate the efficacy
of our ICU method in unlearning sensitive information while maintaining the
model's overall performance, offering a promising solution for
privacy-conscious machine learning applications.",2024-07-25,"Haoyu Tang, Ye Liu, Xi Zhao, Xukai Liu, Yanghai Zhang, Kai Zhang, Xiaofang Zhou, Enhong Chen",http://arxiv.org/pdf/2407.20271v3,cs.LG
Automatic Data Labeling for Software Vulnerability Prediction Models: How Far Are We?,"Background: Software Vulnerability (SV) prediction needs large-sized and
high-quality data to perform well. Current SV datasets mostly require expensive
labeling efforts by experts (human-labeled) and thus are limited in size.
Meanwhile, there are growing efforts in automatic SV labeling at scale.
However, the fitness of auto-labeled data for SV prediction is still largely
unknown. Aims: We quantitatively and qualitatively study the quality and use of
the state-of-the-art auto-labeled SV data, D2A, for SV prediction. Method:
Using multiple sources and manual validation, we curate clean SV data from
human-labeled SV-fixing commits in two well-known projects for investigating
the auto-labeled counterparts. Results: We discover that 50+% of the
auto-labeled SVs are noisy (incorrectly labeled), and they hardly overlap with
the publicly reported ones. Yet, SV prediction models utilizing the noisy
auto-labeled SVs can perform up to 22% and 90% better in Matthews Correlation
Coefficient and Recall, respectively, than the original models. We also reveal
the promises and difficulties of applying noise-reduction methods for
automatically addressing the noise in auto-labeled SV data to maximize the data
utilization for SV prediction. Conclusions: Our study informs the benefits and
challenges of using auto-labeled SVs, paving the way for large-scale SV
prediction.",2024-07-25,"Triet H. M. Le, M. Ali Babar",http://arxiv.org/pdf/2407.17803v1,cs.LG
EEG-SSM: Leveraging State-Space Model for Dementia Detection,"State-space models (SSMs) have garnered attention for effectively processing
long data sequences, reducing the need to segment time series into shorter
intervals for model training and inference. Traditionally, SSMs capture only
the temporal dynamics of time series data, omitting the equally critical
spectral features. This study introduces EEG-SSM, a novel state-space
model-based approach for dementia classification using EEG data. Our model
features two primary innovations: EEG-SSM temporal and EEG-SSM spectral
components. The temporal component is designed to efficiently process EEG
sequences of varying lengths, while the spectral component enhances the model
by integrating frequency-domain information from EEG signals. The synergy of
these components allows EEG-SSM to adeptly manage the complexities of
multivariate EEG data, significantly improving accuracy and stability across
different temporal resolutions. Demonstrating a remarkable 91.0 percent
accuracy in classifying Healthy Control (HC), Frontotemporal Dementia (FTD),
and Alzheimer's Disease (AD) groups, EEG-SSM outperforms existing models on the
same dataset. The development of EEG-SSM represents an improvement in the use
of state-space models for screening dementia, offering more precise and
cost-effective tools for clinical neuroscience.",2024-07-25,"Xuan-The Tran, Linh Le, Quoc Toan Nguyen, Thomas Do, Chin-Teng Lin",http://arxiv.org/pdf/2407.17801v1,cs.LG
Enhancing Diversity in Multi-objective Feature Selection,"Feature selection plays a pivotal role in the data preprocessing and
model-building pipeline, significantly enhancing model performance,
interpretability, and resource efficiency across diverse domains. In
population-based optimization methods, the generation of diverse individuals
holds utmost importance for adequately exploring the problem landscape,
particularly in highly multi-modal multi-objective optimization problems. Our
study reveals that, in line with findings from several prior research papers,
commonly employed crossover and mutation operations lack the capability to
generate high-quality diverse individuals and tend to become confined to
limited areas around various local optima. This paper introduces an
augmentation to the diversity of the population in the well-established
multi-objective scheme of the genetic algorithm, NSGA-II. This enhancement is
achieved through two key components: the genuine initialization method and the
substitution of the worst individuals with new randomly generated individuals
as a re-initialization approach in each generation. The proposed
multi-objective feature selection method undergoes testing on twelve real-world
classification problems, with the number of features ranging from 2,400 to
nearly 50,000. The results demonstrate that replacing the last front of the
population with an equivalent number of new random individuals generated using
the genuine initialization method and featuring a limited number of features
substantially improves the population's quality and, consequently, enhances the
performance of the multi-objective algorithm.",2024-07-25,"Sevil Zanjani Miyandoab, Shahryar Rahnamayan, Azam Asilian Bidgoli, Sevda Ebrahimi, Masoud Makrehchi",http://arxiv.org/pdf/2407.17795v2,cs.LG
Exploring the Limitations of Kolmogorov-Arnold Networks in Classification: Insights to Software Training and Hardware Implementation,"Kolmogorov-Arnold Networks (KANs), a novel type of neural network, have
recently gained popularity and attention due to the ability to substitute
multi-layer perceptions (MLPs) in artificial intelligence (AI) with higher
accuracy and interoperability. However, KAN assessment is still limited and
cannot provide an in-depth analysis of a specific domain. Furthermore, no study
has been conducted on the implementation of KANs in hardware design, which
would directly demonstrate whether KANs are truly superior to MLPs in practical
applications. As a result, in this paper, we focus on verifying KANs for
classification issues, which are a common but significant topic in AI using
four different types of datasets. Furthermore, the corresponding hardware
implementation is considered using the Vitis high-level synthesis (HLS) tool.
To the best of our knowledge, this is the first article to implement hardware
for KAN. The results indicate that KANs cannot achieve more accuracy than MLPs
in high complex datasets while utilizing substantially higher hardware
resources. Therefore, MLP remains an effective approach for achieving accuracy
and efficiency in software and hardware implementation.",2024-07-25,"Van Duy Tran, Tran Xuan Hieu Le, Thi Diem Tran, Hoai Luan Pham, Vu Trung Duong Le, Tuan Hai Vu, Van Tinh Nguyen, Yasuhiko Nakashima",http://arxiv.org/pdf/2407.17790v2,cs.LG
Ensemble data assimilation to diagnose AI-based weather prediction model: A case with ClimaX version 0.3.1,"Artificial intelligence (AI)-based weather prediction research is growing
rapidly and has shown to be competitive with the advanced dynamic numerical
weather prediction models. However, research combining AI-based weather
prediction models with data assimilation remains limited partially because
long-term sequential data assimilation cycles are required to evaluate data
assimilation systems. This study proposes using ensemble data assimilation for
diagnosing AI-based weather prediction models, and marked the first successful
implementation of ensemble Kalman filter with AI-based weather prediction
models. Our experiments with an AI-based model ClimaX demonstrated that the
ensemble data assimilation cycled stably for the AI-based weather prediction
model using covariance inflation and localization techniques within the
ensemble Kalman filter. While ClimaX showed some limitations in capturing
flow-dependent error covariance compared to dynamical models, the AI-based
ensemble forecasts provided reasonable and beneficial error covariance in
sparsely observed regions. In addition, ensemble data assimilation revealed
that error growth based on ensemble ClimaX predictions was weaker than that of
dynamical NWP models, leading to higher inflation factors. A series of
experiments demonstrated that ensemble data assimilation can be used to
diagnose properties of AI weather prediction models such as physical
consistency and accurate error growth representation.",2024-07-25,"Shunji Kotsuki, Kenta Shiraishi, Atsushi Okazaki",http://arxiv.org/pdf/2407.17781v4,cs.LG
Babel: A Scalable Pre-trained Model for Multi-Modal Sensing via Expandable Modality Alignment,"This paper presents Babel, the expandable modality alignment model, specially
designed for multi-modal sensing. While there has been considerable work on
multi-modality alignment, they all struggle to effectively incorporate multiple
sensing modalities due to the data scarcity constraints. How to utilize
multi-modal data with partial pairings in sensing remains an unresolved
challenge. Babel tackles this challenge by introducing the concept of
expandable modality alignment. The key idea involves transforming the
N-modality alignment into a series of binary-modality alignments. Novel
techniques are also proposed to further mitigate data scarcity issue and
balance the contribution of the newly incorporated modality with the previously
established modality alignment during the expandable alignment process. We
provide the comprehensive implementation. In the pre-training phase, Babel
currently aligns 6 sensing modalities, namely Wi-Fi, mmWave, IMU, LiDAR, video,
and depth. For the deployment phase, as a foundation model, any single or
combination of aligned modalities could be selected from Babel and applied to
downstream tasks. Evaluation demonstrates Babel's outstanding performance on
eight human activity recognition datasets, compared to a broad range of
baselines e.g., the SOTA single-modal sensing networks, multi-modal sensing
framework, and multi-modal large language models. Babel not only improves the
performance of individual modality sensing (12% averaged accuracy improvement),
but also effectively fuses multiple available modalities (up to 22% accuracy
increase). Case studies also highlight emerging application scenarios empowered
by Babel, including cross-modality retrieval (i.e., sensing imaging), and
bridging LLM for sensing comprehension.",2024-07-25,"Shenghong Dai, Shiqi Jiang, Yifan Yang, Ting Cao, Mo Li, Suman Banerjee, Lili Qiu",http://arxiv.org/pdf/2407.17777v2,cs.LG
KiVA: Kid-inspired Visual Analogies for Testing Large Multimodal Models,"This paper investigates visual analogical reasoning in large multimodal
models (LMMs) compared to human adults and children. A ""visual analogy"" is an
abstract rule inferred from one image and applied to another. While benchmarks
exist for testing visual reasoning in LMMs, they require advanced skills and
omit basic visual analogies that even young children can make. Inspired by
developmental psychology, we propose a new benchmark of 4,300 visual
transformations of everyday objects to test LMMs on visual analogical reasoning
and compare them to children (ages three to five) and to adults. We structure
the evaluation into three stages: identifying what changed (e.g., color,
number, etc.), how it changed (e.g., added one object), and applying the rule
to new scenarios. Our findings show that while GPT-o1, GPT-4V, LLaVA-1.5, and
MANTIS identify the ""what"" effectively, they struggle with quantifying the
""how"" and extrapolating this rule to new objects. In contrast, children and
adults exhibit much stronger analogical reasoning at all three stages.
Additionally, the strongest tested model, GPT-o1, performs better in tasks
involving simple surface-level visual attributes like color and size,
correlating with quicker human adult response times. Conversely, more complex
tasks such as number, rotation, and reflection, which necessitate extensive
cognitive processing and understanding of extrinsic spatial properties in the
physical world, present more significant challenges. Altogether, these findings
highlight the limitations of training models on data that primarily consists of
2D images and text.",2024-07-25,"Eunice Yiu, Maan Qraitem, Anisa Noor Majhi, Charlie Wong, Yutong Bai, Shiry Ginosar, Alison Gopnik, Kate Saenko",http://arxiv.org/pdf/2407.17773v3,cs.LG
Online Learning for Autonomous Management of Intent-based 6G Networks,"The growing complexity of networks and the variety of future scenarios with
diverse and often stringent performance requirements call for a higher level of
automation. Intent-based management emerges as a solution to attain high level
of automation, enabling human operators to solely communicate with the network
through high-level intents. The intents consist of the targets in the form of
expectations (i.e., latency expectation) from a service and based on the
expectations the required network configurations should be done accordingly. It
is almost inevitable that when a network action is taken to fulfill one intent,
it can cause negative impacts on the performance of another intent, which
results in a conflict. In this paper, we aim to address the conflict issue and
autonomous management of intent-based networking, and propose an online
learning method based on the hierarchical multi-armed bandits approach for an
effective management. Thanks to this hierarchical structure, it performs an
efficient exploration and exploitation of network configurations with respect
to the dynamic network conditions. We show that our algorithm is an effective
approach regarding resource allocation and satisfaction of intent expectations.",2024-07-25,"Erciyes Karakaya, Ozgur Ercetin, Huseyin Ozkan, Mehmet Karaca, Elham Dehghan Biyar, Alexandros Palaios",http://arxiv.org/pdf/2407.17767v1,cs.LG
DualFed: Enjoying both Generalization and Personalization in Federated Learning via Hierachical Representations,"In personalized federated learning (PFL), it is widely recognized that
achieving both high model generalization and effective personalization poses a
significant challenge due to their conflicting nature. As a result, existing
PFL methods can only manage a trade-off between these two objectives. This
raises an interesting question: Is it feasible to develop a model capable of
achieving both objectives simultaneously? Our paper presents an affirmative
answer, and the key lies in the observation that deep models inherently exhibit
hierarchical architectures, which produce representations with various levels
of generalization and personalization at different stages. A straightforward
approach stemming from this observation is to select multiple representations
from these layers and combine them to concurrently achieve generalization and
personalization. However, the number of candidate representations is commonly
huge, which makes this method infeasible due to high computational costs.To
address this problem, we propose DualFed, a new method that can directly yield
dual representations correspond to generalization and personalization
respectively, thereby simplifying the optimization task. Specifically, DualFed
inserts a personalized projection network between the encoder and classifier.
The pre-projection representations are able to capture generalized information
shareable across clients, and the post-projection representations are effective
to capture task-specific information on local clients. This design minimizes
the mutual interference between generalization and personalization, thereby
achieving a win-win situation. Extensive experiments show that DualFed can
outperform other FL methods. Code is available at
https://github.com/GuogangZhu/DualFed.",2024-07-25,"Guogang Zhu, Xuefeng Liu, Jianwei Niu, Shaojie Tang, Xinghao Wu, Jiayuan Zhang",http://arxiv.org/pdf/2407.17754v2,cs.LG
Optimal Trade and Industrial Policies in the Global Economy: A Deep Learning Framework,"We propose a deep learning framework, DL-opt, designed to efficiently solve
for optimal policies in quantifiable general equilibrium trade models. DL-opt
integrates (i) a nested fixed point (NFXP) formulation of the optimization
problem, (ii) automatic implicit differentiation to enhance gradient descent
for solving unilateral optimal policies, and (iii) a best-response dynamics
approach for finding Nash equilibria. Utilizing DL-opt, we solve for
non-cooperative tariffs and industrial subsidies across 7 economies and 44
sectors, incorporating sectoral external economies of scale. Our quantitative
analysis reveals significant sectoral heterogeneity in Nash policies: Nash
industrial subsidies increase with scale elasticities, whereas Nash tariffs
decrease with trade elasticities. Moreover, we show that global dual
competition, involving both tariffs and industrial subsidies, results in lower
tariffs and higher welfare outcomes compared to a global tariff war. These
findings highlight the importance of considering sectoral heterogeneity and
policy combinations in understanding global economic competition.",2024-07-25,"Zi Wang, Xingcheng Xu, Yanqing Yang, Xiaodong Zhu",http://arxiv.org/pdf/2407.17731v1,cs.LG
Multi-group Uncertainty Quantification for Long-form Text Generation,"While large language models are rapidly moving towards consumer-facing
applications, they are often still prone to factual errors and hallucinations.
In order to reduce the potential harms that may come from these errors, it is
important for users to know to what extent they can trust an LLM when it makes
a factual claim. To this end, we study the problem of uncertainty
quantification of factual correctness in long-form natural language generation.
Given some output from a large language model, we study both uncertainty at the
level of individual claims contained within the output (via calibration) and
uncertainty across the entire output itself (via conformal prediction).
Moreover, we invoke multicalibration and multivalid conformal prediction to
ensure that such uncertainty guarantees are valid both marginally and across
distinct groups of prompts. Using the task of biography generation, we
demonstrate empirically that having access to and making use of additional
group attributes for each prompt improves both overall and group-wise
performance. As the problems of calibration, conformal prediction, and their
multi-group counterparts have not been extensively explored previously in the
context of long-form text generation, we consider these empirical results to
form a benchmark for this setting.",2024-07-25,"Terrance Liu, Zhiwei Steven Wu",http://arxiv.org/pdf/2407.21057v1,cs.LG
Multi-modal Data Binding for Survival Analysis Modeling with Incomplete Data and Annotations,"Survival analysis stands as a pivotal process in cancer treatment research,
crucial for predicting patient survival rates accurately. Recent advancements
in data collection techniques have paved the way for enhancing survival
predictions by integrating information from multiple modalities. However,
real-world scenarios often present challenges with incomplete data,
particularly when dealing with censored survival labels. Prior works have
addressed missing modalities but have overlooked incomplete labels, which can
introduce bias and limit model efficacy. To bridge this gap, we introduce a
novel framework that simultaneously handles incomplete data across modalities
and censored survival labels. Our approach employs advanced foundation models
to encode individual modalities and align them into a universal representation
space for seamless fusion. By generating pseudo labels and incorporating
uncertainty, we significantly enhance predictive accuracy. The proposed method
demonstrates outstanding prediction accuracy in two survival analysis tasks on
both employed datasets. This innovative approach overcomes limitations
associated with disparate modalities and improves the feasibility of
comprehensive survival analysis using multiple large foundation models.",2024-07-25,"Linhao Qu, Dan Huang, Shaoting Zhang, Xiaosong Wang",http://arxiv.org/pdf/2407.17726v1,cs.LG
Your Graph Recommender is Provably a Single-view Graph Contrastive Learning,"Graph recommender (GR) is a type of graph neural network (GNNs) encoder that
is customized for extracting information from the user-item interaction graph.
Due to its strong performance on the recommendation task, GR has gained
significant attention recently. Graph contrastive learning (GCL) is also a
popular research direction that aims to learn, often unsupervised, GNNs with
certain contrastive objectives. As a general graph representation learning
method, GCLs have been widely adopted with the supervised recommendation loss
for joint training of GRs. Despite the intersection of GR and GCL research,
theoretical understanding of the relationship between the two fields is
surprisingly sparse. This vacancy inevitably leads to inefficient scientific
research.
  In this paper, we aim to bridge the gap between the field of GR and GCL from
the perspective of encoders and loss functions. With mild assumptions, we
theoretically show an astonishing fact that graph recommender is equivalent to
a commonly-used single-view graph contrastive model. Specifically, we find that
(1) the classic encoder in GR is essentially a linear graph convolutional
network with one-hot inputs, and (2) the loss function in GR is well bounded by
a single-view GCL loss with certain hyperparameters. The first observation
enables us to explain crucial designs of GR models, e.g., the removal of
self-loop and nonlinearity. And the second finding can easily prompt many
cross-field research directions. We empirically show a remarkable result that
the recommendation loss and the GCL loss can be used interchangeably. The fact
that we can train GR models solely with the GCL loss is particularly
insightful, since before this work, GCLs were typically viewed as unsupervised
methods that need fine-tuning. We also discuss some potential future works
inspired by our theory.",2024-07-25,"Wenjie Yang, Shengzhong Zhang, Jiaxing Guo, Zengfeng Huang",http://arxiv.org/pdf/2407.17723v1,cs.LG
Text-Driven Neural Collaborative Filtering Model for Paper Source Tracing,"Identifying significant references within the complex interrelations of a
citation knowledge graph is challenging, which encompasses connections through
citations, authorship, keywords, and other relational attributes. The Paper
Source Tracing (PST) task seeks to automate the identification of pivotal
references for given scholarly articles utilizing advanced data mining
techniques. In the KDD CUP OAG-Challenge PST track, we design a
recommendation-based framework tailored for the PST task. This framework
employs the Neural Collaborative Filtering (NCF) model to generate final
predictions. To process the textual attributes of the papers and extract input
features for the model, we utilize SciBERT, a pre-trained language model.
According to the experimental results, our method achieved a score of 0.37814
on the Mean Average Precision (MAP) metric, outperforming baseline models and
ranking 11th among all participating teams. The source code is publicly
available at https://github.com/MyLove-XAB/KDDCupFinal.",2024-07-25,"Aobo Xu, Bingyu Chang, Qingpeng Liu, Ling Jian",http://arxiv.org/pdf/2407.17722v2,cs.LG
A Two-Stage Imaging Framework Combining CNN and Physics-Informed Neural Networks for Full-Inverse Tomography: A Case Study in Electrical Impedance Tomography (EIT),"Electrical Impedance Tomography (EIT) is a highly ill-posed inverse problem,
with the challenge of reconstructing internal conductivities using only
boundary voltage measurements. Although Physics-Informed Neural Networks
(PINNs) have shown potential in solving inverse problems, existing approaches
are limited in their applicability to EIT, as they often rely on impractical
prior knowledge and assumptions that cannot be satisfied in real-world
scenarios. To address these limitations, we propose a two-stage hybrid learning
framework that combines Convolutional Neural Networks (CNNs) and PINNs. This
framework integrates data-driven and model-driven paradigms, blending
supervised and unsupervised learning to reconstruct conductivity distributions
while ensuring adherence to the underlying physical laws, thereby overcoming
the constraints of existing methods.",2024-07-25,"Xuanxuan Yang, Yangming Zhang, Haofeng Chen, Gang Ma, Xiaojie Wang",http://arxiv.org/pdf/2407.17721v2,cs.LG
Describe Where You Are: Improving Noise-Robustness for Speech Emotion Recognition with Text Description of the Environment,"Speech emotion recognition (SER) systems often struggle in real-world
environments, where ambient noise severely degrades their performance. This
paper explores a novel approach that exploits prior knowledge of testing
environments to maximize SER performance under noisy conditions. To address
this task, we propose a text-guided, environment-aware training where an SER
model is trained with contaminated speech samples and their paired noise
description. We use a pre-trained text encoder to extract the text-based
environment embedding and then fuse it to a transformer-based SER model during
training and inference. We demonstrate the effectiveness of our approach
through our experiment with the MSP-Podcast corpus and real-world additive
noise samples collected from the Freesound repository. Our experiment indicates
that the text-based environment descriptions processed by a large language
model (LLM) produce representations that improve the noise-robustness of the
SER system. In addition, our proposed approach with an LLM yields better
performance than our environment-agnostic baselines, especially in low
signal-to-noise ratio (SNR) conditions. When testing at -5dB SNR level, our
proposed method shows better performance than our best baseline model by 31.8 %
(arousal), 23.5% (dominance), and 9.5% (valence).",2024-07-25,"Seong-Gyun Leem, Daniel Fulford, Jukka-Pekka Onnela, David Gard, Carlos Busso",http://arxiv.org/pdf/2407.17716v1,cs.LG
Improving Online Algorithms via ML Predictions,"In this work we study the problem of using machine-learned predictions to
improve the performance of online algorithms. We consider two classical
problems, ski rental and non-clairvoyant job scheduling, and obtain new online
algorithms that use predictions to make their decisions. These algorithms are
oblivious to the performance of the predictor, improve with better predictions,
but do not degrade much if the predictions are poor.",2024-07-25,"Ravi Kumar, Manish Purohit, Zoya Svitkina",http://arxiv.org/pdf/2407.17712v1,cs.LG
Revisiting Machine Unlearning with Dimensional Alignment,"Machine unlearning, an emerging research topic focusing on compliance with
data privacy regulations, enables trained models to remove the information
learned from specific data. While many existing methods indirectly address this
issue by intentionally injecting incorrect supervisions, they can drastically
and unpredictably alter the decision boundaries and feature spaces, leading to
training instability and undesired side effects. To fundamentally approach this
task, we first analyze the changes in latent feature spaces between original
and retrained models, and observe that the feature representations of samples
not involved in training are closely aligned with the feature manifolds of
previously seen samples in training. Based on these findings, we introduce a
novel evaluation metric for machine unlearning, coined dimensional alignment,
which measures the alignment between the eigenspaces of the forget and retain
set samples. We employ this metric as a regularizer loss to build a robust and
stable unlearning framework, which is further enhanced by integrating a
self-distillation loss and an alternating training scheme. Our framework
effectively eliminates information from the forget set and preserves knowledge
from the retain set. Lastly, we identify critical flaws in established
evaluation metrics for machine unlearning, and introduce new evaluation tools
that more accurately reflect the fundamental goals of machine unlearning.",2024-07-25,"Seonguk Seo, Dongwan Kim, Bohyung Han",http://arxiv.org/pdf/2407.17710v3,cs.LG
Investigating and Mitigating Barren Plateaus in Variational Quantum Circuits: A Survey,"In recent years, variational quantum circuits (VQCs) have been widely
explored to advance quantum circuits against classic models on various domains,
such as quantum chemistry and quantum machine learning. Similar to classic
machine-learning models, VQCs can be trained through various optimization
approaches, such as gradient-based or gradient-free methods. However, when
employing gradient-based methods, the gradient variance of VQCs may
dramatically vanish as the number of qubits or layers increases. This issue,
a.k.a. Barren Plateaus (BPs), seriously hinders the scaling of VQCs on large
datasets. To mitigate the barren plateaus, extensive efforts have been devoted
to tackling this issue through diverse strategies. In this survey, we conduct a
systematic literature review of recent works from both investigation and
mitigation perspectives. Furthermore, we propose a new taxonomy to categorize
most existing mitigation strategies into five groups and introduce them in
detail. Also, we compare the concurrent survey papers about BPs. Finally, we
provide insightful discussion on future directions for BPs.",2024-07-25,"Jack Cunningham, Jun Zhuang",http://arxiv.org/pdf/2407.17706v2,cs.LG
Context-aware knowledge graph framework for traffic speed forecasting using graph neural network,"Human mobility is intricately influenced by urban contexts spatially and
temporally, constituting essential domain knowledge in understanding traffic
systems. While existing traffic forecasting models primarily rely on raw
traffic data and advanced deep learning techniques, incorporating contextual
information remains underexplored due to insufficient integration frameworks
and the complexity of urban contexts. This study proposes a novel context-aware
knowledge graph (CKG) framework to enhance traffic speed forecasting by
effectively modeling spatial and temporal contexts. Employing a
relation-dependent integration strategy, the framework generates context-aware
representations from the spatial and temporal units of CKG to capture
spatio-temporal dependencies of urban contexts. A CKG-GNN model, combining the
CKG, dual-view multi-head self-attention (MHSA), and graph neural network
(GNN), is then designed to predict traffic speed utilizing these context-aware
representations. Our experiments demonstrate that CKG's configuration
significantly influences embedding performance, with ComplEx and KG2E emerging
as optimal for embedding spatial and temporal units, respectively. The CKG-GNN
model establishes a benchmark for 10-120 min predictions, achieving average
MAE, MAPE, and RMSE of $3.46\pm0.01$, $14.76\pm0.09\%$, and $5.08\pm0.01$,
respectively. Compared to the baseline DCRNN model, integrating the spatial
unit improves the MAE by 0.04 and the temporal unit by 0.13, while integrating
both units further reduces it by 0.18. The dual-view MHSA analysis reveals the
crucial role of relation-dependent features from the context-based view and the
model's ability to prioritize recent time slots in prediction from the
sequence-based view. Overall, this study underscores the importance of merging
context-aware knowledge graphs with graph neural networks to improve traffic
forecasting.",2024-07-25,"Yatao Zhang, Yi Wang, Song Gao, Martin Raubal",http://arxiv.org/pdf/2407.17703v2,cs.LG
Superior Scoring Rules for Probabilistic Evaluation of Single-Label Multi-Class Classification Tasks,"This study introduces novel superior scoring rules called Penalized Brier
Score (PBS) and Penalized Logarithmic Loss (PLL) to improve model evaluation
for probabilistic classification. Traditional scoring rules like Brier Score
and Logarithmic Loss sometimes assign better scores to misclassifications in
comparison with correct classifications. This discrepancy from the actual
preference for rewarding correct classifications can lead to suboptimal model
selection. By integrating penalties for misclassifications, PBS and PLL modify
traditional proper scoring rules to consistently assign better scores to
correct predictions. Formal proofs demonstrate that PBS and PLL satisfy
strictly proper scoring rule properties while also preferentially rewarding
accurate classifications. Experiments showcase the benefits of using PBS and
PLL for model selection, model checkpointing, and early stopping. PBS exhibits
a higher negative correlation with the F1 score compared to the Brier Score
during training. Thus, PBS more effectively identifies optimal checkpoints and
early stopping points, leading to improved F1 scores. Comparative analysis
verifies models selected by PBS and PLL achieve superior F1 scores. Therefore,
PBS and PLL address the gap between uncertainty quantification and accuracy
maximization by encapsulating both proper scoring principles and explicit
preference for true classifications. The proposed metrics can enhance model
evaluation and selection for reliable probabilistic classification.",2024-07-25,"Rouhollah Ahmadian, Mehdi Ghatee, Johan Wahlström",http://arxiv.org/pdf/2407.17697v1,cs.LG
Transformers on Markov Data: Constant Depth Suffices,"Attention-based transformers have been remarkably successful at modeling
generative processes across various domains and modalities. In this paper, we
study the behavior of transformers on data drawn from \kth Markov processes,
where the conditional distribution of the next symbol in a sequence depends on
the previous $k$ symbols observed. We observe a surprising phenomenon
empirically which contradicts previous findings: when trained for sufficiently
long, a transformer with a fixed depth and $1$ head per layer is able to
achieve low test loss on sequences drawn from \kth Markov sources, even as $k$
grows. Furthermore, this low test loss is achieved by the transformer's ability
to represent and learn the in-context conditional empirical distribution. On
the theoretical side, our main result is that a transformer with a single head
and three layers can represent the in-context conditional empirical
distribution for \kth Markov sources, concurring with our empirical
observations. Along the way, we prove that \textit{attention-only} transformers
with $O(\log_2(k))$ layers can represent the in-context conditional empirical
distribution by composing induction heads to track the previous $k$ symbols in
the sequence. These results provide more insight into our current understanding
of the mechanisms by which transformers learn to capture context, by
understanding their behavior on Markov sources.",2024-07-25,"Nived Rajaraman, Marco Bondaschi, Kannan Ramchandran, Michael Gastpar, Ashok Vardhan Makkuva",http://arxiv.org/pdf/2407.17686v1,cs.LG
Struc2mapGAN: improving synthetic cryo-EM density maps with generative adversarial networks,"Generating synthetic cryogenic electron microscopy 3D density maps from
molecular structures has potential important applications in structural
biology. Yet existing simulation-based methods cannot mimic all the complex
features present in experimental maps, such as secondary structure elements. As
an alternative, we propose struc2mapGAN, a novel data-driven method that
employs a generative adversarial network to produce improved experimental-like
density maps from molecular structures. More specifically, struc2mapGAN uses a
nested U-Net architecture as the generator, with an additional L1 loss term and
further processing of raw training experimental maps to enhance learning
efficiency. While struc2mapGAN can promptly generate maps after training, we
demonstrate that it outperforms existing simulation-based methods for a wide
array of tested maps and across various evaluation metrics.",2024-07-24,"Chenwei Zhang, Anne Condon, Khanh Dao Duc",http://arxiv.org/pdf/2407.17674v2,cs.LG
Spiking Neural Networks in Vertical Federated Learning: Performance Trade-offs,"Federated machine learning enables model training across multiple clients
while maintaining data privacy. Vertical Federated Learning (VFL) specifically
deals with instances where the clients have different feature sets of the same
samples. As federated learning models aim to improve efficiency and
adaptability, innovative neural network architectures like Spiking Neural
Networks (SNNs) are being leveraged to enable fast and accurate processing at
the edge. SNNs, known for their efficiency over Artificial Neural Networks
(ANNs), have not been analyzed for their applicability in VFL, thus far. In
this paper, we investigate the benefits and trade-offs of using SNN models in a
vertical federated learning setting. We implement two different federated
learning architectures -- with model splitting and without model splitting --
that have different privacy and performance implications. We evaluate the setup
using CIFAR-10 and CIFAR-100 benchmark datasets along with SNN implementations
of VGG9 and ResNET classification models. Comparative evaluations demonstrate
that the accuracy of SNN models is comparable to that of traditional ANNs for
VFL applications, albeit significantly more energy efficient.",2024-07-24,"Maryam Abbasihafshejani, Anindya Maiti, Murtuza Jadliwala",http://arxiv.org/pdf/2407.17672v2,cs.LG
Unsqueeze [CLS] Bottleneck to Learn Rich Representations,"Distillation-based self-supervised learning typically leads to more
compressed representations due to its radical clustering process and the
implementation of a sharper target distribution. To overcome this limitation
and preserve more information from input, we introduce UDI, conceptualized as
Unsqueezed Distillation-based self-supervised learning (SSL). UDI enriches the
learned representation by encouraging multimodal prediction distilled from a
consolidated profile of local predictions that are derived via stratified
sampling. Our evaluations show that UDI not only promotes semantically
meaningful representations at instance level, delivering superior or
competitive results to state-of-the-art SSL methods in image classification,
but also effectively preserves the nuisance of input, which yields significant
improvement in dense prediction tasks, including object detection and
segmentation. Additionally, UDI performs competitively in low-shot image
classification, improving the scalability of joint-embedding pipelines. Various
visualizations and ablation studies are presented to further elucidate the
mechanisms behind UDI. Our source code is available at
https://github.com/ISL-CV/udi.",2024-07-24,"Qing Su, Shihao Ji",http://arxiv.org/pdf/2407.17671v2,cs.LG
"Tackling the Problem of Distributional Shifts: Correcting Misspecified, High-Dimensional Data-Driven Priors for Inverse Problems","Bayesian inference for inverse problems hinges critically on the choice of
priors. In the absence of specific prior information, population-level
distributions can serve as effective priors for parameters of interest. With
the advent of machine learning, the use of data-driven population-level
distributions (encoded, e.g., in a trained deep neural network) as priors is
emerging as an appealing alternative to simple parametric priors in a variety
of inverse problems. However, in many astrophysical applications, it is often
difficult or even impossible to acquire independent and identically distributed
samples from the underlying data-generating process of interest to train these
models. In these cases, corrupted data or a surrogate, e.g. a simulator, is
often used to produce training samples, meaning that there is a risk of
obtaining misspecified priors. This, in turn, can bias the inferred posteriors
in ways that are difficult to quantify, which limits the potential
applicability of these models in real-world scenarios. In this work, we propose
addressing this issue by iteratively updating the population-level
distributions by retraining the model with posterior samples from different
sets of observations, and we showcase the potential of this method on the
problem of background image reconstruction in strong gravitational lensing when
score-based models are used as data-driven priors. We show that, starting from
a misspecified prior distribution, the updated distribution becomes
progressively closer to the underlying population-level distribution, and the
resulting posterior samples exhibit reduced bias after several updates.",2024-07-24,"Gabriel Missael Barco, Alexandre Adam, Connor Stone, Yashar Hezaveh, Laurence Perreault-Levasseur",http://arxiv.org/pdf/2407.17667v2,cs.LG
"Explaining the Model, Protecting Your Data: Revealing and Mitigating the Data Privacy Risks of Post-Hoc Model Explanations via Membership Inference","Predictive machine learning models are becoming increasingly deployed in
high-stakes contexts involving sensitive personal data; in these contexts,
there is a trade-off between model explainability and data privacy. In this
work, we push the boundaries of this trade-off: with a focus on foundation
models for image classification fine-tuning, we reveal unforeseen privacy risks
of post-hoc model explanations and subsequently offer mitigation strategies for
such risks. First, we construct VAR-LRT and L1/L2-LRT, two new membership
inference attacks based on feature attribution explanations that are
significantly more successful than existing explanation-leveraging attacks,
particularly in the low false-positive rate regime that allows an adversary to
identify specific training set members with confidence. Second, we find
empirically that optimized differentially private fine-tuning substantially
diminishes the success of the aforementioned attacks, while maintaining high
model accuracy. We carry out a systematic empirical investigation of our 2 new
attacks with 5 vision transformer architectures, 5 benchmark datasets, 4
state-of-the-art post-hoc explanation methods, and 4 privacy strength settings.",2024-07-24,"Catherine Huang, Martin Pawelczyk, Himabindu Lakkaraju",http://arxiv.org/pdf/2407.17663v1,cs.LG
Generative Learning for Simulation of Vehicle Faults,"We develop a novel generative model to simulate vehicle health and forecast
faults, conditioned on practical operational considerations. The model, trained
on data from the US Army's Predictive Logistics program, aims to support
predictive maintenance. It forecasts faults far enough in advance to execute a
maintenance intervention before a breakdown occurs. The model incorporates
real-world factors that affect vehicle health. It also allows us to understand
the vehicle's condition by analyzing operating data, and characterizing each
vehicle into discrete states. Importantly, the model predicts the time to first
fault with high accuracy. We compare its performance to other models and
demonstrate its successful training.",2024-07-24,"Patrick Kuiper, Sirui Lin, Jose Blanchet, Vahid Tarokh",http://arxiv.org/pdf/2407.17654v2,cs.LG
Hopfield Networks for Asset Allocation,"We present the first application of modern Hopfield networks to the problem
of portfolio optimization. We performed an extensive study based on
combinatorial purged cross-validation over several datasets and compared our
results to both traditional and deep-learning-based methods for portfolio
selection. Compared to state-of-the-art deep-learning methods such as
Long-Short Term Memory networks and Transformers, we find that the proposed
approach performs on par or better, while providing faster training times and
better stability. Our results show that Modern Hopfield Networks represent a
promising approach to portfolio optimization, allowing for an efficient,
scalable, and robust solution for asset allocation, risk management, and
dynamic rebalancing.",2024-07-24,"Carlo Nicolini, Monisha Gopalan, Jacopo Staiano, Bruno Lepri",http://arxiv.org/pdf/2407.17645v1,cs.LG
SMA-Hyper: Spatiotemporal Multi-View Fusion Hypergraph Learning for Traffic Accident Prediction,"Predicting traffic accidents is the key to sustainable city management, which
requires effective address of the dynamic and complex spatiotemporal
characteristics of cities. Current data-driven models often struggle with data
sparsity and typically overlook the integration of diverse urban data sources
and the high-order dependencies within them. Additionally, they frequently rely
on predefined topologies or weights, limiting their adaptability in
spatiotemporal predictions. To address these issues, we introduce the
Spatiotemporal Multiview Adaptive HyperGraph Learning (SMA-Hyper) model, a
dynamic deep learning framework designed for traffic accident prediction.
Building on previous research, this innovative model incorporates dual adaptive
spatiotemporal graph learning mechanisms that enable high-order cross-regional
learning through hypergraphs and dynamic adaptation to evolving urban data. It
also utilises contrastive learning to enhance global and local data
representations in sparse datasets and employs an advance attention mechanism
to fuse multiple views of accident data and urban functional features, thereby
enriching the contextual understanding of risk factors. Extensive testing on
the London traffic accident dataset demonstrates that the SMA-Hyper model
significantly outperforms baseline models across various temporal horizons and
multistep outputs, affirming the effectiveness of its multiview fusion and
adaptive learning strategies. The interpretability of the results further
underscores its potential to improve urban traffic management and safety by
leveraging complex spatiotemporal urban data, offering a scalable framework
adaptable to diverse urban environments.",2024-07-24,"Xiaowei Gao, James Haworth, Ilya Ilyankou, Xianghui Zhang, Tao Cheng, Stephen Law, Huanfa Chen",http://arxiv.org/pdf/2407.17642v1,cs.LG
BLAZE: Cross-Language and Cross-Project Bug Localization via Dynamic Chunking and Hard Example Learning,"Software bugs require developers to exert significant effort to identify and
resolve them, often consuming about one-third of their time. Bug localization,
the process of pinpointing the exact source code files that need modification,
is crucial in reducing this effort. Existing bug localization tools, typically
reliant on deep learning techniques, face limitations in cross-project
applicability and effectiveness in multi-language environments. Recent
advancements with Large Language Models (LLMs) offer detailed representations
for bug localization. However, they encounter challenges with limited context
windows and mapping accuracy. To address these issues, we propose BLAZE, an
approach that employs dynamic chunking and hard example learning. First, BLAZE
dynamically segments source code to minimize continuity loss. Then, BLAZE
fine-tunes a GPT-based model using challenging bug cases, in order to enhance
cross-project and cross-language bug localization. To support the capability of
BLAZE, we create the BEETLEBOX dataset, which comprises 26,321 bugs from 29
large and thriving open-source projects across five different programming
languages (Java, C++, Python, Go, and JavaScript). Our evaluations of BLAZE on
three benchmark datasets BEETLEBOX, SWE-Bench, and Ye et al. demonstrate
substantial improvements compared to six state-of-the-art baselines.
Specifically, BLAZE achieves up to an increase of 120% in Top 1 accuracy, 144%
in Mean Average Precision (MAP), and 100% in Mean Reciprocal Rank (MRR). An
extensive ablation study confirms the contributions of our pipeline components
to the overall performance enhancement.",2024-07-24,"Partha Chakraborty, Mahmoud Alfadel, Meiyappan Nagappan",http://arxiv.org/pdf/2407.17631v2,cs.LG
Utilizing Generative Adversarial Networks for Image Data Augmentation and Classification of Semiconductor Wafer Dicing Induced Defects,"In semiconductor manufacturing, the wafer dicing process is central yet
vulnerable to defects that significantly impair yield - the proportion of
defect-free chips. Deep neural networks are the current state of the art in
(semi-)automated visual inspection. However, they are notoriously known to
require a particularly large amount of data for model training. To address
these challenges, we explore the application of generative adversarial networks
(GAN) for image data augmentation and classification of semiconductor wafer
dicing induced defects to enhance the variety and balance of training data for
visual inspection systems. With this approach, synthetic yet realistic images
are generated that mimic real-world dicing defects. We employ three different
GAN variants for high-resolution image synthesis: Deep Convolutional GAN
(DCGAN), CycleGAN, and StyleGAN3. Our work-in-progress results demonstrate that
improved classification accuracies can be obtained, showing an average
improvement of up to 23.1 % from 65.1 % (baseline experiment) to 88.2 % (DCGAN
experiment) in balanced accuracy, which may enable yield optimization in
production.",2024-07-24,"Zhining Hu, Tobias Schlosser, Michael Friedrich, André Luiz Vieira e Silva, Frederik Beuth, Danny Kowerko",http://arxiv.org/pdf/2407.20268v1,cs.LG
A Large Encoder-Decoder Family of Foundation Models For Chemical Language,"Large-scale pre-training methodologies for chemical language models represent
a breakthrough in cheminformatics. These methods excel in tasks such as
property prediction and molecule generation by learning contextualized
representations of input tokens through self-supervised learning on large
unlabeled corpora. Typically, this involves pre-training on unlabeled data
followed by fine-tuning on specific tasks, reducing dependence on annotated
datasets and broadening chemical language representation understanding. This
paper introduces a large encoder-decoder chemical foundation models pre-trained
on a curated dataset of 91 million SMILES samples sourced from PubChem, which
is equivalent to 4 billion of molecular tokens. The proposed foundation model
supports different complex tasks, including quantum property prediction, and
offer flexibility with two main variants (289M and $8\times289M$). Our
experiments across multiple benchmark datasets validate the capacity of the
proposed model in providing state-of-the-art results for different tasks. We
also provide a preliminary assessment of the compositionality of the embedding
space as a prerequisite for the reasoning tasks. We demonstrate that the
produced latent space is separable compared to the state-of-the-art with
few-shot learning capabilities.",2024-07-24,"Eduardo Soares, Victor Shirasuna, Emilio Vital Brazil, Renato Cerqueira, Dmitry Zubarev, Kristin Schmidt",http://arxiv.org/pdf/2407.20267v1,cs.LG
SAfEPaTh: A System-Level Approach for Efficient Power and Thermal Estimation of Convolutional Neural Network Accelerator,"The design of energy-efficient, high-performance, and reliable Convolutional
Neural Network (CNN) accelerators involves significant challenges due to
complex power and thermal management issues. This paper introduces SAfEPaTh, a
novel system-level approach for accurately estimating power and temperature in
tile-based CNN accelerators. By addressing both steady-state and
transient-state scenarios, SAfEPaTh effectively captures the dynamic effects of
pipeline bubbles in interlayer pipelines, utilizing real CNN workloads for
comprehensive evaluation. Unlike traditional methods, it eliminates the need
for circuit-level simulations or on-chip measurements. Our methodology
leverages TANIA, a cutting-edge hybrid digital-analog tile-based accelerator
featuring analog-in-memory computing cores alongside digital cores. Through
rigorous simulation results using the ResNet18 model, we demonstrate SAfEPaTh's
capability to accurately estimate power and temperature within 500 seconds,
encompassing CNN model accelerator mapping exploration and detailed power and
thermal estimations. This efficiency and accuracy make SAfEPaTh an invaluable
tool for designers, enabling them to optimize performance while adhering to
stringent power and thermal constraints. Furthermore, SAfEPaTh's adaptability
extends its utility across various CNN models and accelerator architectures,
underscoring its broad applicability in the field. This study contributes
significantly to the advancement of energy-efficient and reliable CNN
accelerator designs, addressing critical challenges in dynamic power and
thermal management.",2024-07-24,"Yukai Chen, Simei Yang, Debjyoti Bhattacharjee, Francky Catthoor, Arindam Mallik",http://arxiv.org/pdf/2407.17623v1,cs.LG
Towards Neural Network based Cognitive Models of Dynamic Decision-Making by Humans,"Modeling human cognitive processes in dynamic decision-making tasks has been
an endeavor in AI for a long time because such models can help make AI systems
more intuitive, personalized, mitigate any human biases, and enhance training
in simulation. Some initial work has attempted to utilize neural networks (and
large language models) but often assumes one common model for all humans and
aims to emulate human behavior in aggregate. However, the behavior of each
human is distinct, heterogeneous, and relies on specific past experiences in
certain tasks. For instance, consider two individuals responding to a phishing
email: one who has previously encountered and identified similar threats may
recognize it quickly, while another without such experience might fall for the
scam. In this work, we build on Instance Based Learning (IBL) that posits that
human decisions are based on similar situations encountered in the past.
However, IBL relies on simple fixed form functions to capture the mapping from
past situations to current decisions. To that end, we propose two new
attention-based neural network models to have open form non-linear functions to
model distinct and heterogeneous human decision-making in dynamic settings. We
experiment with two distinct datasets gathered from human subject experiment
data, one focusing on detection of phishing email by humans and another where
humans act as attackers in a cybersecurity setting and decide on an attack
option. We conducted extensive experiments with our two neural network models,
IBL, and GPT3.5, and demonstrate that the neural network models outperform IBL
significantly in representing human decision-making, while providing similar
interpretability of human decisions as IBL. Overall, our work yields promising
results for further use of neural networks in cognitive modeling of human
decision making.",2024-07-24,"Changyu Chen, Shashank Reddy Chirra, Maria José Ferreira, Cleotilde Gonzalez, Arunesh Sinha, Pradeep Varakantham",http://arxiv.org/pdf/2407.17622v2,cs.LG
Accelerating the Low-Rank Decomposed Models,"Tensor decomposition is a mathematically supported technique for data
compression. It consists of applying some kind of a Low Rank Decomposition
technique on the tensors or matrices in order to reduce the redundancy of the
data. However, it is not a popular technique for compressing the AI models duo
to the high number of new layers added to the architecture after decomposition.
Although the number of parameters could shrink significantly, it could result
in the model be more than twice deeper which could add some latency to the
training or inference. In this paper, we present a comprehensive study about
how to modify low rank decomposition technique in AI models so that we could
benefit from both high accuracy and low memory consumption as well as speeding
up the training and inference",2024-07-24,"Habib Hajimolahoseini, Walid Ahmed, Austin Wen, Yang Liu",http://arxiv.org/pdf/2407.20266v1,cs.LG
Pretraining a Neural Operator in Lower Dimensions,"There has recently been increasing attention towards developing foundational
neural Partial Differential Equation (PDE) solvers and neural operators through
large-scale pretraining. However, unlike vision and language models that make
use of abundant and inexpensive (unlabeled) data for pretraining, these neural
solvers usually rely on simulated PDE data, which can be costly to obtain,
especially for high-dimensional PDEs. In this work, we aim to Pretrain neural
PDE solvers on Lower Dimensional PDEs (PreLowD) where data collection is the
least expensive. We evaluated the effectiveness of this pretraining strategy in
similar PDEs in higher dimensions. We use the Factorized Fourier Neural
Operator (FFNO) due to having the necessary flexibility to be applied to PDE
data of arbitrary spatial dimensions and reuse trained parameters in lower
dimensions. In addition, our work sheds light on the effect of the fine-tuning
configuration to make the most of this pretraining strategy. Code is available
at https://github.com/BaratiLab/PreLowD.",2024-07-24,"AmirPouya Hemmasian, Amir Barati Farimani",http://arxiv.org/pdf/2407.17616v2,cs.LG
Adaptive Training of Grid-Dependent Physics-Informed Kolmogorov-Arnold Networks,"Physics-Informed Neural Networks (PINNs) have emerged as a robust framework
for solving Partial Differential Equations (PDEs) by approximating their
solutions via neural networks and imposing physics-based constraints on the
loss function. Traditionally, Multilayer Perceptrons (MLPs) have been the
neural network of choice, with significant progress made in optimizing their
training. Recently, Kolmogorov-Arnold Networks (KANs) were introduced as a
viable alternative, with the potential of offering better interpretability and
efficiency while requiring fewer parameters. In this paper, we present a fast
JAX-based implementation of grid-dependent Physics-Informed Kolmogorov-Arnold
Networks (PIKANs) for solving PDEs, achieving up to 84 times faster training
times than the original KAN implementation. We propose an adaptive training
scheme for PIKANs, introducing an adaptive state transition technique to avoid
loss function peaks between grid extensions, and a methodology for designing
PIKANs with alternative basis functions. Through comparative experiments, we
demonstrate that the adaptive features significantly enhance solution accuracy,
decreasing the L^2 error relative to the reference solution by up to 43.02%.
For the studied PDEs, our methodology approaches or surpasses the results
obtained from architectures that utilize up to 8.5 times more parameters,
highlighting the potential of adaptive, grid-dependent PIKANs as a superior
alternative in scientific and engineering applications.",2024-07-24,"Spyros Rigas, Michalis Papachristou, Theofilos Papadopoulos, Fotios Anagnostopoulos, Georgios Alexandridis",http://arxiv.org/pdf/2407.17611v2,cs.LG
Coupling Speech Encoders with Downstream Text Models,"We present a modular approach to building cascade speech translation (AST)
models that guarantees that the resulting model performs no worse than the
1-best cascade baseline while preserving state-of-the-art speech recognition
(ASR) and text translation (MT) performance for a given task. Our novel
contribution is the use of an ``exporter'' layer that is trained under L2-loss
to ensure a strong match between ASR embeddings and the MT token embeddings for
the 1-best sequence. The ``exporter'' output embeddings are fed directly to the
MT model in lieu of 1-best token embeddings, thus guaranteeing that the
resulting model performs no worse than the 1-best cascade baseline, while
allowing back-propagation gradient to flow from the MT model into the ASR
components. The matched-embeddings cascade architecture provide a significant
improvement over its 1-best counterpart in scenarios where incremental training
of the MT model is not an option and yet we seek to improve quality by
leveraging (speech, transcription, translated transcription) data provided with
the AST task. The gain disappears when the MT model is incrementally trained on
the parallel text data available with the AST task. The approach holds promise
for other scenarios that seek to couple ASR encoders and immutable text models,
such at large language models (LLM).",2024-07-24,"Ciprian Chelba, Johan Schalkwyk",http://arxiv.org/pdf/2407.17605v1,cs.LG
Quality Assured: Rethinking Annotation Strategies in Imaging AI,"This paper does not describe a novel method. Instead, it studies an essential
foundation for reliable benchmarking and ultimately real-world application of
AI-based image analysis: generating high-quality reference annotations.
Previous research has focused on crowdsourcing as a means of outsourcing
annotations. However, little attention has so far been given to annotation
companies, specifically regarding their internal quality assurance (QA)
processes. Therefore, our aim is to evaluate the influence of QA employed by
annotation companies on annotation quality and devise methodologies for
maximizing data annotation efficacy. Based on a total of 57,648 instance
segmented images obtained from a total of 924 annotators and 34 QA workers from
four annotation companies and Amazon Mechanical Turk (MTurk), we derived the
following insights: (1) Annotation companies perform better both in terms of
quantity and quality compared to the widely used platform MTurk. (2) Annotation
companies' internal QA only provides marginal improvements, if any. However,
improving labeling instructions instead of investing in QA can substantially
boost annotation performance. (3) The benefit of internal QA depends on
specific image characteristics. Our work could enable researchers to derive
substantially more value from a fixed annotation budget and change the way
annotation companies conduct internal QA.",2024-07-24,"Tim Rädsch, Annika Reinke, Vivienn Weru, Minu D. Tizabi, Nicholas Heller, Fabian Isensee, Annette Kopp-Schneider, Lena Maier-Hein",http://arxiv.org/pdf/2407.17596v2,cs.LG
CMR Scaling Law: Predicting Critical Mixture Ratios for Continual Pre-training of Language Models,"Large Language Models (LLMs) excel in diverse tasks but often underperform in
specialized fields due to limited domain-specific or proprietary corpus.
Continual pre-training (CPT) enhances LLM capabilities by imbuing new
domain-specific or proprietary knowledge while replaying general corpus to
prevent catastrophic forgetting. The data mixture ratio of general corpus and
domain-specific corpus, however, has been chosen heuristically, leading to
sub-optimal training efficiency in practice. In this context, we attempt to
re-visit the scaling behavior of LLMs under the hood of CPT, and discover a
power-law relationship between loss, mixture ratio, and training tokens scale.
We formalize the trade-off between general and domain-specific capabilities,
leading to a well-defined Critical Mixture Ratio (CMR) of general and domain
data. By striking the balance, CMR maintains the model's general ability and
achieves the desired domain transfer, ensuring the highest utilization of
available resources. Considering the balance between efficiency and
effectiveness, CMR can be regarded as the optimal mixture ratio. Through
extensive experiments, we ascertain the predictability of CMR, propose CMR
scaling law and have substantiated its generalization. These findings offer
practical guidelines for optimizing LLM training in specialized domains,
ensuring both general and domain-specific performance while efficiently
managing training resources.",2024-07-24,"Jiawei Gu, Zacc Yang, Chuanghao Ding, Rui Zhao, Fei Tan",http://arxiv.org/pdf/2407.17467v2,cs.LG
Traversing Pareto Optimal Policies: Provably Efficient Multi-Objective Reinforcement Learning,"This paper investigates multi-objective reinforcement learning (MORL), which
focuses on learning Pareto optimal policies in the presence of multiple reward
functions. Despite MORL's significant empirical success, there is still a lack
of satisfactory understanding of various MORL optimization targets and
efficient learning algorithms. Our work offers a systematic analysis of several
optimization targets to assess their abilities to find all Pareto optimal
policies and controllability over learned policies by the preferences for
different objectives. We then identify Tchebycheff scalarization as a favorable
scalarization method for MORL. Considering the non-smoothness of Tchebycheff
scalarization, we reformulate its minimization problem into a new min-max-max
optimization problem. Then, for the stochastic policy class, we propose
efficient algorithms using this reformulation to learn Pareto optimal policies.
We first propose an online UCB-based algorithm to achieve an $\varepsilon$
learning error with an $\tilde{\mathcal{O}}(\varepsilon^{-2})$ sample
complexity for a single given preference. To further reduce the cost of
environment exploration under different preferences, we propose a
preference-free framework that first explores the environment without
pre-defined preferences and then generates solutions for any number of
preferences. We prove that it only requires an
$\tilde{\mathcal{O}}(\varepsilon^{-2})$ exploration complexity in the
exploration phase and demands no additional exploration afterward. Lastly, we
analyze the smooth Tchebycheff scalarization, an extension of Tchebycheff
scalarization, which is proved to be more advantageous in distinguishing the
Pareto optimal policies from other weakly Pareto optimal policies based on
entry values of preference vectors. Furthermore, we extend our algorithms and
theoretical analysis to accommodate this optimization target.",2024-07-24,"Shuang Qiu, Dake Zhang, Rui Yang, Boxiang Lyu, Tong Zhang",http://arxiv.org/pdf/2407.17466v1,cs.LG
u-$μ$P: The Unit-Scaled Maximal Update Parametrization,"The Maximal Update Parametrization ($\mu$P) aims to make the optimal
hyperparameters (HPs) of a model independent of its size, allowing them to be
swept using a cheap proxy model rather than the full-size target model. We
present a new scheme, u-$\mu$P, which improves upon $\mu$P by combining it with
Unit Scaling, a method for designing models that makes them easy to train in
low-precision. The two techniques have a natural affinity: $\mu$P ensures that
the scale of activations is independent of model size, and Unit Scaling ensures
that activations, weights and gradients begin training with a scale of one.
This synthesis opens the door to a simpler scheme, whose default values are
near-optimal. This in turn facilitates a more efficient sweeping strategy, with
u-$\mu$P models reaching a loss that is equal to or lower than comparable
$\mu$P models and working out-of-the-box in FP8.",2024-07-24,"Charlie Blake, Constantin Eichenberg, Josef Dean, Lukas Balles, Luke Y. Prince, Björn Deiseroth, Andres Felipe Cruz-Salinas, Carlo Luschi, Samuel Weinbach, Douglas Orr",http://arxiv.org/pdf/2407.17465v3,cs.LG
SoNIC: Safe Social Navigation with Adaptive Conformal Inference and Constrained Reinforcement Learning,"Reinforcement learning (RL) enables social robots to generate trajectories
without relying on human-designed rules or interventions, making it generally
more effective than rule-based systems in adapting to complex, dynamic
real-world scenarios. However, social navigation is a safety-critical task that
requires robots to avoid collisions with pedestrians, whereas existing RL-based
solutions often fall short of ensuring safety in complex environments. In this
paper, we propose SoNIC, which to the best of our knowledge is the first
algorithm that integrates adaptive conformal inference (ACI) with constrained
reinforcement learning (CRL) to enable safe policy learning for social
navigation. Specifically, our method not only augments RL observations with
ACI-generated nonconformity scores, which inform the agent of the quantified
uncertainty but also employs these uncertainty estimates to effectively guide
the behaviors of RL agents by using constrained reinforcement learning. This
integration regulates the behaviors of RL agents and enables them to handle
safety-critical situations. On the standard CrowdNav benchmark, our method
achieves a success rate of 96.93%, which is 11.67% higher than the previous
state-of-the-art RL method and results in 4.5 times fewer collisions and 2.8
times fewer intrusions to ground-truth human future trajectories as well as
enhanced robustness in out-of-distribution scenarios. To further validate our
approach, we deploy our algorithm on a real robot by developing a ROS2-based
navigation system. Our experiments demonstrate that the system can generate
robust and socially polite decision-making when interacting with both sparse
and dense crowds. The video demos can be found on our project website:
https://sonic-social-nav.github.io/.",2024-07-24,"Jianpeng Yao, Xiaopan Zhang, Yu Xia, Zejin Wang, Amit K. Roy-Chowdhury, Jiachen Li",http://arxiv.org/pdf/2407.17460v2,cs.LG
Hidden or Inferred: Fair Learning-To-Rank with Unknown Demographics,"As learning-to-rank models are increasingly deployed for decision-making in
areas with profound life implications, the FairML community has been developing
fair learning-to-rank (LTR) models. These models rely on the availability of
sensitive demographic features such as race or sex. However, in practice,
regulatory obstacles and privacy concerns protect this data from collection and
use. As a result, practitioners may either need to promote fairness despite the
absence of these features or turn to demographic inference tools to attempt to
infer them. Given that these tools are fallible, this paper aims to further
understand how errors in demographic inference impact the fairness performance
of popular fair LTR strategies. In which cases would it be better to keep such
demographic attributes hidden from models versus infer them? We examine a
spectrum of fair LTR strategies ranging from fair LTR with and without
demographic features hidden versus inferred to fairness-unaware LTR followed by
fair re-ranking. We conduct a controlled empirical investigation modeling
different levels of inference errors by systematically perturbing the inferred
sensitive attribute. We also perform three case studies with real-world
datasets and popular open-source inference methods. Our findings reveal that as
inference noise grows, LTR-based methods that incorporate fairness
considerations into the learning process may increase bias. In contrast, fair
re-ranking strategies are more robust to inference errors. All source code,
data, and experimental artifacts of our experimental study are available here:
https://github.com/sewen007/hoiltr.git",2024-07-24,"Oluseun Olulana, Kathleen Cachel, Fabricio Murai, Elke Rundensteiner",http://arxiv.org/pdf/2407.17459v1,cs.LG
EuroCropsML: A Time Series Benchmark Dataset For Few-Shot Crop Type Classification,"We introduce EuroCropsML, an analysis-ready remote sensing machine learning
dataset for time series crop type classification of agricultural parcels in
Europe. It is the first dataset designed to benchmark transnational few-shot
crop type classification algorithms that supports advancements in algorithmic
development and research comparability. It comprises 706 683 multi-class
labeled data points across 176 classes, featuring annual time series of
per-parcel median pixel values from Sentinel-2 L1C data for 2021, along with
crop type labels and spatial coordinates. Based on the open-source EuroCrops
collection, EuroCropsML is publicly available on Zenodo.",2024-07-24,"Joana Reuss, Jan Macdonald, Simon Becker, Lorenz Richter, Marco Körner",http://arxiv.org/pdf/2407.17458v2,cs.LG
Looking at Model Debiasing through the Lens of Anomaly Detection,"It is widely recognized that deep neural networks are sensitive to bias in
the data. This means that during training these models are likely to learn
spurious correlations between data and labels, resulting in limited
generalization abilities and low performance. In this context, model debiasing
approaches can be devised aiming at reducing the model's dependency on such
unwanted correlations, either leveraging the knowledge of bias information or
not. In this work, we focus on the latter and more realistic scenario, showing
the importance of accurately predicting the bias-conflicting and bias-aligned
samples to obtain compelling performance in bias mitigation. On this ground, we
propose to conceive the problem of model bias from an out-of-distribution
perspective, introducing a new bias identification method based on anomaly
detection. We claim that when data is mostly biased, bias-conflicting samples
can be regarded as outliers with respect to the bias-aligned distribution in
the feature space of a biased model, thus allowing for precisely detecting them
with an anomaly detection method. Coupling the proposed bias identification
approach with bias-conflicting data upsampling and augmentation in a two-step
strategy, we reach state-of-the-art performance on synthetic and real benchmark
datasets. Ultimately, our proposed approach shows that the data bias issue does
not necessarily require complex debiasing methods, given that an accurate bias
identification procedure is defined. Source code is available at
https://github.com/Malga-Vision/MoDAD",2024-07-24,"Vito Paolo Pastore, Massimiliano Ciranni, Davide Marinelli, Francesca Odone, Vittorio Murino",http://arxiv.org/pdf/2407.17449v3,cs.LG
Exploring Domain Robust Lightweight Reward Models based on Router Mechanism,"Recent advancements in large language models have heavily relied on the large
reward model from reinforcement learning from human feedback for fine-tuning.
However, the use of a single reward model across various domains may not always
be optimal, often requiring retraining from scratch when new domain data is
introduced. To address these challenges, we explore the utilization of small
language models operating in a domain-specific manner based on router
mechanisms. Our three approaches are: 1) utilize mixture of experts to form a
single reward model by modularizing an internal router and experts, 2)
employing external router to select the appropriate reward model from multiple
domain-specific models, and 3) the framework reduces parameter size by loading
reward models and router adapters onto a single small language model using
adapters. Experimental validation underscores the effectiveness of our
approach, demonstrating performance comparable to baseline methods while also
reducing the total parameter size.",2024-07-24,"Hyuk Namgoong, Jeesu Jung, Sangkeun Jung, Yoonhyung Roh",http://arxiv.org/pdf/2407.17546v1,cs.LG
Fractional signature: a generalisation of the signature inspired by fractional calculus,"In this paper, we propose a novel generalisation of the signature of a path,
motivated by fractional calculus, which is able to describe the solutions of
linear Caputo controlled FDEs. We also propose another generalisation of the
signature, inspired by the previous one, but more convenient to use in machine
learning. Finally, we test this last signature in a toy application to the
problem of handwritten digit recognition, where significant improvements in
accuracy rates are observed compared to those of the original signature.",2024-07-24,"José Manuel Corcuera, Rubén Jiménez",http://arxiv.org/pdf/2407.17446v1,cs.LG
HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation,"Human image animation involves generating videos from a character photo,
allowing user control and unlocking the potential for video and movie
production. While recent approaches yield impressive results using high-quality
training data, the inaccessibility of these datasets hampers fair and
transparent benchmarking. Moreover, these approaches prioritize 2D human motion
and overlook the significance of camera motions in videos, leading to limited
control and unstable video generation. To demystify the training data, we
present HumanVid, the first large-scale high-quality dataset tailored for human
image animation, which combines crafted real-world and synthetic data. For the
real-world data, we compile a vast collection of real-world videos from the
internet. We developed and applied careful filtering rules to ensure video
quality, resulting in a curated collection of 20K high-resolution (1080P)
human-centric videos. Human and camera motion annotation is accomplished using
a 2D pose estimator and a SLAM-based method. To expand our synthetic dataset,
we collected 10K 3D avatar assets and leveraged existing assets of body shapes,
skin textures and clothings. Notably, we introduce a rule-based camera
trajectory generation method, enabling the synthetic pipeline to incorporate
diverse and precise camera motion annotation, which can rarely be found in
real-world data. To verify the effectiveness of HumanVid, we establish a
baseline model named CamAnimate, short for Camera-controllable Human Animation,
that considers both human and camera motions as conditions. Through extensive
experimentation, we demonstrate that such simple baseline training on our
HumanVid achieves state-of-the-art performance in controlling both human pose
and camera motions, setting a new benchmark. Demo, data and code could be found
in the project website: https://humanvid.github.io/.",2024-07-24,"Zhenzhi Wang, Yixuan Li, Yanhong Zeng, Youqing Fang, Yuwei Guo, Wenran Liu, Jing Tan, Kai Chen, Tianfan Xue, Bo Dai, Dahua Lin",http://arxiv.org/pdf/2407.17438v3,cs.LG
Nerva: a Truly Sparse Implementation of Neural Networks,"We introduce Nerva, a fast neural network library under development in C++.
It supports sparsity by using the sparse matrix operations of Intel's Math
Kernel Library (MKL), which eliminates the need for binary masks. We show that
Nerva significantly decreases training time and memory usage while reaching
equivalent accuracy to PyTorch. We run static sparse experiments with an MLP on
CIFAR-10. On high sparsity levels like $99\%$, the runtime is reduced by a
factor of $4\times$ compared to a PyTorch model using masks. Similar to other
popular frameworks such as PyTorch and Keras, Nerva offers a Python interface
for users to work with.",2024-07-24,"Wieger Wesselink, Bram Grooten, Qiao Xiao, Cassio de Campos, Mykola Pechenizkiy",http://arxiv.org/pdf/2407.17437v1,cs.LG
Can Watermarking Large Language Models Prevent Copyrighted Text Generation and Hide Training Data?,"Large Language Models (LLMs) have demonstrated impressive capabilities in
generating diverse and contextually rich text. However, concerns regarding
copyright infringement arise as LLMs may inadvertently produce copyrighted
material. In this paper, we first investigate the effectiveness of watermarking
LLMs as a deterrent against the generation of copyrighted texts. Through
theoretical analysis and empirical evaluation, we demonstrate that
incorporating watermarks into LLMs significantly reduces the likelihood of
generating copyrighted content, thereby addressing a critical concern in the
deployment of LLMs. However, we also find that watermarking can have unintended
consequences on Membership Inference Attacks (MIAs), which aim to discern
whether a sample was part of the pretraining dataset and may be used to detect
copyright violations. Surprisingly, we find that watermarking adversely affects
the success rate of MIAs, complicating the task of detecting copyrighted text
in the pretraining dataset. These results reveal the complex interplay between
different regulatory measures, which may impact each other in unforeseen ways.
Finally, we propose an adaptive technique to improve the success rate of a
recent MIA under watermarking. Our findings underscore the importance of
developing adaptive methods to study critical problems in LLMs with potential
legal implications.",2024-07-24,"Michael-Andrei Panaitescu-Liess, Zora Che, Bang An, Yuancheng Xu, Pankayaraj Pathmanathan, Souradip Chakraborty, Sicheng Zhu, Tom Goldstein, Furong Huang",http://arxiv.org/pdf/2407.17417v2,cs.LG
Systematic Relational Reasoning With Epistemic Graph Neural Networks,"Developing models that can learn to reason is a notoriously challenging
problem. We focus on reasoning in relational domains, where the use of Graph
Neural Networks (GNNs) seems like a natural choice. However, previous work has
shown that regular GNNs lack the ability to systematically generalize from
training examples on test graphs requiring longer inference chains, which
fundamentally limits their reasoning abilities. A common solution relies on
neuro-symbolic methods that systematically reason by learning rules, but their
scalability is often limited and they tend to make unrealistically strong
assumptions, e.g.\ that the answer can always be inferred from a single
relational path. We propose the Epistemic GNN (EpiGNN), a novel
parameter-efficient and scalable GNN architecture with an epistemic inductive
bias for systematic reasoning. Node embeddings in EpiGNNs are treated as
epistemic states, and message passing is implemented accordingly. We show that
EpiGNNs achieve state-of-the-art results on link prediction tasks that require
systematic reasoning. Furthermore, for inductive knowledge graph completion,
EpiGNNs rival the performance of state-of-the-art specialized approaches.
Finally, we introduce two new benchmarks that go beyond standard relational
reasoning by requiring the aggregation of information from multiple paths.
Here, existing neuro-symbolic approaches fail, yet EpiGNNs learn to reason
accurately. Code and datasets are available at
https://github.com/erg0dic/gnn-sg.",2024-07-24,"Irtaza Khalid, Steven Schockaert",http://arxiv.org/pdf/2407.17396v2,cs.LG
Which distribution were you sampled from? Towards a more tangible conception of data,"Machine Learning research, as most of Statistics, heavily relies on the
concept of a data-generating probability distribution. The standard presumption
is that since data points are `sampled from' such a distribution, one can learn
from observed data about this distribution and, thus, predict future data
points which, it is presumed, are also drawn from it. Drawing on scholarship
across disciplines, we here argue that this framework is not always a good
model. Not only do such true probability distributions not exist; the framework
can also be misleading and obscure both the choices made and the goals pursued
in machine learning practice. We suggest an alternative framework that focuses
on finite populations rather than abstract distributions; while classical
learning theory can be left almost unchanged, it opens new opportunities,
especially to model sampling. We compile these considerations into five reasons
for modelling machine learning -- in some settings -- with finite populations
rather than generative distributions, both to be more faithful to practice and
to provide novel theoretical insights.",2024-07-24,"Benedikt Höltgen, Robert C. Williamson",http://arxiv.org/pdf/2407.17395v3,cs.LG
Causal modelling without introducing counterfactuals or abstract distributions,"The most common approach to causal modelling is the potential outcomes
framework due to Neyman and Rubin. In this framework, outcomes of
counterfactual treatments are assumed to be well-defined. This metaphysical
assumption is often thought to be problematic yet indispensable. The
conventional approach relies not only on counterfactuals but also on abstract
notions of distributions and assumptions of independence that are not directly
testable. In this paper, we construe causal inference as treatment-wise
predictions for finite populations where all assumptions are testable; this
means that one can not only test predictions themselves (without any
fundamental problem) but also investigate sources of error when they fail. The
new framework highlights the model-dependence of causal claims as well as the
difference between statistical and scientific inference.",2024-07-24,"Benedikt Höltgen, Robert C. Williamson",http://arxiv.org/pdf/2407.17385v2,cs.LG
A Comprehensive Approach to Misspelling Correction with BERT and Levenshtein Distance,"Writing, as an omnipresent form of human communication, permeates nearly
every aspect of contemporary life. Consequently, inaccuracies or errors in
written communication can lead to profound consequences, ranging from financial
losses to potentially life-threatening situations. Spelling mistakes, among the
most prevalent writing errors, are frequently encountered due to various
factors. This research aims to identify and rectify diverse spelling errors in
text using neural networks, specifically leveraging the Bidirectional Encoder
Representations from Transformers (BERT) masked language model. To achieve this
goal, we compiled a comprehensive dataset encompassing both non-real-word and
real-word errors after categorizing different types of spelling mistakes.
Subsequently, multiple pre-trained BERT models were employed. To ensure optimal
performance in correcting misspelling errors, we propose a combined approach
utilizing the BERT masked language model and Levenshtein distance. The results
from our evaluation data demonstrate that the system presented herein exhibits
remarkable capabilities in identifying and rectifying spelling mistakes, often
surpassing existing systems tailored for the Persian language.",2024-07-24,"Amirreza Naziri, Hossein Zeinali",http://arxiv.org/pdf/2407.17383v1,cs.LG
Entropy Reweighted Conformal Classification,"Conformal Prediction (CP) is a powerful framework for constructing prediction
sets with guaranteed coverage. However, recent studies have shown that
integrating confidence calibration with CP can lead to a degradation in
efficiency. In this paper, We propose an adaptive approach that considers the
classifier's uncertainty and employs entropy-based reweighting to enhance the
efficiency of prediction sets for conformal classification. Our experimental
results demonstrate that this method significantly improves efficiency.",2024-07-24,"Rui Luo, Nicolo Colombo",http://arxiv.org/pdf/2407.17377v1,cs.LG
Building a Domain-specific Guardrail Model in Production,"Generative AI holds the promise of enabling a range of sought-after
capabilities and revolutionizing workflows in various consumer and enterprise
verticals. However, putting a model in production involves much more than just
generating an output. It involves ensuring the model is reliable, safe,
performant and also adheres to the policy of operation in a particular domain.
Guardrails as a necessity for models has evolved around the need to enforce
appropriate behavior of models, especially when they are in production. In this
paper, we use education as a use case, given its stringent requirements of the
appropriateness of content in the domain, to demonstrate how a guardrail model
can be trained and deployed in production. Specifically, we describe our
experience in building a production-grade guardrail model for a K-12
educational platform. We begin by formulating the requirements for deployment
to this sensitive domain. We then describe the training and benchmarking of our
domain-specific guardrail model, which outperforms competing open- and closed-
instruction-tuned models of similar and larger size, on proprietary
education-related benchmarks and public benchmarks related to general aspects
of safety. Finally, we detail the choices we made on architecture and the
optimizations for deploying this service in production; these range across the
stack from the hardware infrastructure to the serving layer to language model
inference optimizations. We hope this paper will be instructive to other
practitioners looking to create production-grade domain-specific services based
on generative AI and large language models.",2024-07-24,"Mohammad Niknazar, Paul V Haley, Latha Ramanan, Sang T. Truong, Yedendra Shrinivasan, Ayan Kumar Bhowmick, Prasenjit Dey, Ashish Jagmohan, Hema Maheshwari, Shom Ponoth, Robert Smith, Aditya Vempaty, Nick Haber, Sanmi Koyejo, Sharad Sundararajan",http://arxiv.org/pdf/2408.01452v1,cs.LG
Quantile Learn-Then-Test: Quantile-Based Risk Control for Hyperparameter Optimization,"The increasing adoption of Artificial Intelligence (AI) in engineering
problems calls for the development of calibration methods capable of offering
robust statistical reliability guarantees. The calibration of black box AI
models is carried out via the optimization of hyperparameters dictating
architecture, optimization, and/or inference configuration. Prior work has
introduced learn-then-test (LTT), a calibration procedure for hyperparameter
optimization (HPO) that provides statistical guarantees on average performance
measures. Recognizing the importance of controlling risk-aware objectives in
engineering contexts, this work introduces a variant of LTT that is designed to
provide statistical guarantees on quantiles of a risk measure. We illustrate
the practical advantages of this approach by applying the proposed algorithm to
a radio access scheduling problem.",2024-07-24,"Amirmohammad Farzaneh, Sangwoo Park, Osvaldo Simeone",http://arxiv.org/pdf/2407.17358v1,cs.LG
Gradient-based inference of abstract task representations for generalization in neural networks,"Humans and many animals show remarkably adaptive behavior and can respond
differently to the same input depending on their internal goals. The brain not
only represents the intermediate abstractions needed to perform a computation
but also actively maintains a representation of the computation itself (task
abstraction). Such separation of the computation and its abstraction is
associated with faster learning, flexible decision-making, and broad
generalization capacity. We investigate if such benefits might extend to neural
networks trained with task abstractions. For such benefits to emerge, one needs
a task inference mechanism that possesses two crucial abilities: First, the
ability to infer abstract task representations when no longer explicitly
provided (task inference), and second, manipulate task representations to adapt
to novel problems (task recomposition). To tackle this, we cast task inference
as an optimization problem from a variational inference perspective and ground
our approach in an expectation-maximization framework. We show that gradients
backpropagated through a neural network to a task representation layer are an
efficient heuristic to infer current task demands, a process we refer to as
gradient-based inference (GBI). Further iterative optimization of the task
representation layer allows for recomposing abstractions to adapt to novel
situations. Using a toy example, a novel image classifier, and a language
model, we demonstrate that GBI provides higher learning efficiency and
generalization to novel tasks and limits forgetting. Moreover, we show that GBI
has unique advantages such as preserving information for uncertainty estimation
and detecting out-of-distribution samples.",2024-07-24,"Ali Hummos, Felipe del Río, Brabeeba Mien Wang, Julio Hurtado, Cristian B. Calderon, Guangyu Robert Yang",http://arxiv.org/pdf/2407.17356v1,cs.LG
Scalify: scale propagation for efficient low-precision LLM training,"Low-precision formats such as float8 have been introduced in machine learning
accelerated hardware to improve computational efficiency for large language
models training and inference. Nevertheless, adoption by the ML community has
been slowed down by the complex, and sometimes brittle, techniques required to
match higher precision training accuracy. In this work, we present Scalify, a
end-to-end scale propagation paradigm for computational graphs, generalizing
and formalizing existing tensor scaling methods. Experiment results show that
Scalify supports out-of-the-box float8 matrix multiplication and gradients
representation, as well as float16 optimizer state storage. Our JAX
implementation of Scalify is open-sourced at
https://github.com/graphcore-research/jax-scalify",2024-07-24,"Paul Balança, Sam Hosegood, Carlo Luschi, Andrew Fitzgibbon",http://arxiv.org/pdf/2407.17353v1,cs.LG
Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning,"The influence of bias in datasets on the fairness of model predictions is a
topic of ongoing research in various fields. We evaluate the performance of
skin lesion classification using ResNet-based CNNs, focusing on patient sex
variations in training data and three different learning strategies. We present
a linear programming method for generating datasets with varying patient sex
and class labels, taking into account the correlations between these variables.
We evaluated the model performance using three different learning strategies: a
single-task model, a reinforcing multi-task model, and an adversarial learning
scheme. Our observations include: 1) sex-specific training data yields better
results, 2) single-task models exhibit sex bias, 3) the reinforcement approach
does not remove sex bias, 4) the adversarial model eliminates sex bias in cases
involving only female patients, and 5) datasets that include male patients
enhance model performance for the male subgroup, even when female patients are
the majority. To generalise these findings, in future research, we will examine
more demographic attributes, like age, and other possibly confounding factors,
such as skin colour and artefacts in the skin lesions. We make all data and
models available on GitHub.",2024-07-24,"Ralf Raumanns, Gerard Schouten, Josien P. W. Pluim, Veronika Cheplygina",http://arxiv.org/pdf/2407.17543v2,cs.LG
Mathematical Programming Algorithms for Convex Hull Approximation with a Hyperplane Budget,"We consider the following problem in computational geometry: given, in the
d-dimensional real space, a set of points marked as positive and a set of
points marked as negative, such that the convex hull of the positive set does
not intersect the negative set, find K hyperplanes that separate, if possible,
all the positive points from the negative ones. That is, we search for a convex
polyhedron with at most K faces, containing all the positive points and no
negative point. The problem is known in the literature for pure convex
polyhedral approximation; our interest stems from its possible applications in
constraint learning, where points are feasible or infeasible solutions of a
Mixed Integer Program, and the K hyperplanes are linear constraints to be
found. We cast the problem as an optimization one, minimizing the number of
negative points inside the convex polyhedron, whenever exact separation cannot
be achieved. We introduce models inspired by support vector machines and we
design two mathematical programming formulations with binary variables. We
exploit Dantzig-Wolfe decomposition to obtain extended formulations, and we
devise column generation algorithms with ad-hoc pricing routines. We compare
computing time and separation error values obtained by all our approaches on
synthetic datasets, with number of points from hundreds up to a few thousands,
showing our approaches to perform better than existing ones from the
literature. Furthermore, we observe that key computational differences arise,
depending on whether the budget K is sufficient to completely separate the
positive points from the negative ones or not. On 8-dimensional instances (and
over), existing convex hull algorithms become computational inapplicable, while
our algorithms allow to identify good convex hull approximations in minutes of
computation.",2024-07-24,"Michele Barbato, Alberto Ceselli, Rosario Messana",http://arxiv.org/pdf/2407.17341v2,cs.LG
Global Confidence Degree Based Graph Neural Network for Financial Fraud Detection,"Graph Neural Networks (GNNs) are widely used in financial fraud detection due
to their excellent ability on handling graph-structured financial data and
modeling multilayer connections by aggregating information of neighbors.
However, these GNN-based methods focus on extracting neighbor-level information
but neglect a global perspective. This paper presents the concept and
calculation formula of Global Confidence Degree (GCD) and thus designs
GCD-based GNN (GCD-GNN) that can address the challenges of camouflage in
fraudulent activities and thus can capture more global information. To obtain a
precise GCD for each node, we use a multilayer perceptron to transform features
and then the new features and the corresponding prototype are used to eliminate
unnecessary information. The GCD of a node evaluates the typicality of the node
and thus we can leverage GCD to generate attention values for message
aggregation. This process is carried out through both the original GCD and its
inverse, allowing us to capture both the typical neighbors with high GCD and
the atypical ones with low GCD. Extensive experiments on two public datasets
demonstrate that GCD-GNN outperforms state-of-the-art baselines, highlighting
the effectiveness of GCD. We also design a lightweight GCD-GNN
(GCD-GNN$_{light}$) that also outperforms the baselines but is slightly weaker
than GCD-GNN on fraud detection performance. However, GCD-GNN$_{light}$
obviously outperforms GCD-GNN on convergence and inference speed.",2024-07-24,"Jiaxun Liu, Yue Tian, Guanjun Liu",http://arxiv.org/pdf/2407.17333v2,cs.LG
Low dimensional representation of multi-patient flow cytometry datasets using optimal transport for minimal residual disease detection in leukemia,"Representing and quantifying Minimal Residual Disease (MRD) in Acute Myeloid
Leukemia (AML), a type of cancer that affects the blood and bone marrow, is
essential in the prognosis and follow-up of AML patients. As traditional
cytological analysis cannot detect leukemia cells below 5\%, the analysis of
flow cytometry dataset is expected to provide more reliable results. In this
paper, we explore statistical learning methods based on optimal transport (OT)
to achieve a relevant low-dimensional representation of multi-patient flow
cytometry measurements (FCM) datasets considered as high-dimensional
probability distributions. Using the framework of OT, we justify the use of the
K-means algorithm for dimensionality reduction of multiple large-scale point
clouds through mean measure quantization by merging all the data into a single
point cloud. After this quantization step, the visualization of the intra and
inter-patients FCM variability is carried out by embedding low-dimensional
quantized probability measures into a linear space using either Wasserstein
Principal Component Analysis (PCA) through linearized OT or log-ratio PCA of
compositional data. Using a publicly available FCM dataset and a FCM dataset
from Bordeaux University Hospital, we demonstrate the benefits of our approach
over the popular kernel mean embedding technique for statistical learning from
multiple high-dimensional probability distributions. We also highlight the
usefulness of our methodology for low-dimensional projection and clustering
patient measurements according to their level of MRD in AML from FCM. In
particular, our OT-based approach allows a relevant and informative
two-dimensional representation of the results of the FlowSom algorithm, a
state-of-the-art method for the detection of MRD in AML using multi-patient
FCM.",2024-07-24,"Erell Gachon, Jérémie Bigot, Elsa Cazelles, Audrey Bidet, Jean-Philippe Vial, Pierre-Yves Dumas, Aguirre Mimoun",http://arxiv.org/pdf/2407.17329v3,cs.LG
COEFF-KANs: A Paradigm to Address the Electrolyte Field with KANs,"To reduce the experimental validation workload for chemical researchers and
accelerate the design and optimization of high-energy-density lithium metal
batteries, we aim to leverage models to automatically predict Coulombic
Efficiency (CE) based on the composition of liquid electrolytes. There are
mainly two representative paradigms in existing methods: machine learning and
deep learning. However, the former requires intelligent input feature selection
and reliable computational methods, leading to error propagation from feature
estimation to model prediction, while the latter (e.g. MultiModal-MoLFormer)
faces challenges of poor predictive performance and overfitting due to limited
diversity in augmented data. To tackle these issues, we propose a novel method
COEFF (COlumbic EFficiency prediction via Fine-tuned models), which consists of
two stages: pre-training a chemical general model and fine-tuning on downstream
domain data. Firstly, we adopt the publicly available MoLFormer model to obtain
feature vectors for each solvent and salt in the electrolyte. Then, we perform
a weighted average of embeddings for each token across all molecules, with
weights determined by the respective electrolyte component ratios. Finally, we
input the obtained electrolyte features into a Multi-layer Perceptron or
Kolmogorov-Arnold Network to predict CE. Experimental results on a real-world
dataset demonstrate that our method achieves SOTA for predicting CE compared to
all baselines. Data and code used in this work will be made publicly available
after the paper is published.",2024-07-24,"Xinhe Li, Zhuoying Feng, Yezeng Chen, Weichen Dai, Zixu He, Yi Zhou, Shuhong Jiao",http://arxiv.org/pdf/2407.20265v1,cs.LG
MoveLight: Enhancing Traffic Signal Control through Movement-Centric Deep Reinforcement Learning,"This paper introduces MoveLight, a novel traffic signal control system that
enhances urban traffic management through movement-centric deep reinforcement
learning. By leveraging detailed real-time data and advanced machine learning
techniques, MoveLight overcomes the limitations of traditional traffic signal
control methods. It employs a lane-level control approach using the FRAP
algorithm to achieve dynamic and adaptive traffic signal control, optimizing
traffic flow, reducing congestion, and improving overall efficiency. Our
research demonstrates the scalability and effectiveness of MoveLight across
single intersections, arterial roads, and network levels. Experimental results
using real-world datasets from Cologne and Hangzhou show significant
improvements in metrics such as queue length, delay, and throughput compared to
existing methods. This study highlights the transformative potential of deep
reinforcement learning in intelligent traffic signal control, setting a new
standard for sustainable and efficient urban transportation systems.",2024-07-24,"Junqi Shao, Chenhao Zheng, Yuxuan Chen, Yucheng Huang, Rui Zhang",http://arxiv.org/pdf/2407.17303v1,cs.LG
Enhanced SMC$^2$: Leveraging Gradient Information from Differentiable Particle Filters Within Langevin Proposals,"Sequential Monte Carlo Squared (SMC$^2$) is a Bayesian method which can infer
the states and parameters of non-linear, non-Gaussian state-space models. The
standard random-walk proposal in SMC$^2$ faces challenges, particularly with
high-dimensional parameter spaces. This study outlines a novel approach by
harnessing first-order gradients derived from a Common Random Numbers -
Particle Filter (CRN-PF) using PyTorch. The resulting gradients can be
leveraged within a Langevin proposal without accept/reject. Including Langevin
dynamics within the proposal can result in a higher effective sample size and
more accurate parameter estimates when compared with the random-walk. The
resulting algorithm is parallelized on distributed memory using Message Passing
Interface (MPI) and runs in $\mathcal{O}(\log_2N)$ time complexity. Utilizing
64 computational cores we obtain a 51x speed-up when compared to a single core.
A GitHub link is given which provides access to the code.",2024-07-24,"Conor Rosato, Joshua Murphy, Alessandro Varsi, Paul Horridge, Simon Maskell",http://arxiv.org/pdf/2407.17296v1,cs.LG
A Novel Two-Step Fine-Tuning Pipeline for Cold-Start Active Learning in Text Classification Tasks,"This is the first work to investigate the effectiveness of BERT-based
contextual embeddings in active learning (AL) tasks on cold-start scenarios,
where traditional fine-tuning is infeasible due to the absence of labeled data.
Our primary contribution is the proposal of a more robust fine-tuning pipeline
- DoTCAL - that diminishes the reliance on labeled data in AL using two steps:
(1) fully leveraging unlabeled data through domain adaptation of the embeddings
via masked language modeling and (2) further adjusting model weights using
labeled data selected by AL. Our evaluation contrasts BERT-based embeddings
with other prevalent text representation paradigms, including Bag of Words
(BoW), Latent Semantic Indexing (LSI), and FastText, at two critical stages of
the AL process: instance selection and classification. Experiments conducted on
eight ATC benchmarks with varying AL budgets (number of labeled instances) and
number of instances (about 5,000 to 300,000) demonstrate DoTCAL's superior
effectiveness, achieving up to a 33% improvement in Macro-F1 while reducing
labeling efforts by half compared to the traditional one-step method. We also
found that in several tasks, BoW and LSI (due to information aggregation)
produce results superior (up to 59% ) to BERT, especially in low-budget
scenarios and hard-to-classify tasks, which is quite surprising.",2024-07-24,"Fabiano Belém, Washington Cunha, Celso França, Claudio Andrade, Leonardo Rocha, Marcos André Gonçalves",http://arxiv.org/pdf/2407.17284v1,cs.LG
Enhanced Feature Learning via Regularisation: Integrating Neural Networks and Kernel Methods,"We propose a new method for feature learning and function estimation in
supervised learning via regularised empirical risk minimisation. Our approach
considers functions as expectations of Sobolev functions over all possible
one-dimensional projections of the data. This framework is similar to kernel
ridge regression, where the kernel is $\mathbb{E}_w ( k^{(B)}(w^\top x,w^\top
x^\prime))$, with $k^{(B)}(a,b) := \min(|a|, |b|)\mathds{1}_{ab>0}$ the
Brownian kernel, and the distribution of the projections $w$ is learnt. This
can also be viewed as an infinite-width one-hidden layer neural network,
optimising the first layer's weights through gradient descent and explicitly
adjusting the non-linearity and weights of the second layer. We introduce a
gradient-based computational method for the estimator, called Brownian Kernel
Neural Network (BKerNN), using particles to approximate the expectation, where
the positive homogeneity of the Brownian kernel \red{leads to improved
robustness to local minima}. Using Rademacher complexity, we show that BKerNN's
expected risk converges to the minimal risk with explicit high-probability
rates of $O( \min((d/n)^{1/2}, n^{-1/6}))$ (up to logarithmic factors).
Numerical experiments confirm our optimisation intuitions, and BKerNN
outperforms kernel ridge regression, and favourably compares to a one-hidden
layer neural network with ReLU activations in various settings and real data
sets.",2024-07-24,"Bertille Follain, Francis Bach",http://arxiv.org/pdf/2407.17280v2,cs.LG
Channel-Aware Low-Rank Adaptation in Time Series Forecasting,"The balance between model capacity and generalization has been a key focus of
recent discussions in long-term time series forecasting. Two representative
channel strategies are closely associated with model expressivity and
robustness, including channel independence (CI) and channel dependence (CD).
The former adopts individual channel treatment and has been shown to be more
robust to distribution shifts, but lacks sufficient capacity to model
meaningful channel interactions. The latter is more expressive for representing
complex cross-channel dependencies, but is prone to overfitting. To balance the
two strategies, we present a channel-aware low-rank adaptation method to
condition CD models on identity-aware individual components. As a plug-in
solution, it is adaptable for a wide range of backbone architectures. Extensive
experiments show that it can consistently and significantly improve the
performance of both CI and CD models with demonstrated efficiency and
flexibility. The code is available at https://github.com/tongnie/C-LoRA.",2024-07-24,"Tong Nie, Yuewen Mei, Guoyang Qin, Jian Sun, Wei Ma",http://arxiv.org/pdf/2407.17246v1,cs.LG
Pretrained Visual Representations in Reinforcement Learning,"Visual reinforcement learning (RL) has made significant progress in recent
years, but the choice of visual feature extractor remains a crucial design
decision. This paper compares the performance of RL algorithms that train a
convolutional neural network (CNN) from scratch with those that utilize
pre-trained visual representations (PVRs). We evaluate the Dormant Ratio
Minimization (DRM) algorithm, a state-of-the-art visual RL method, against
three PVRs: ResNet18, DINOv2, and Visual Cortex (VC). We use the Metaworld
Push-v2 and Drawer-Open-v2 tasks for our comparison. Our results show that the
choice of training from scratch compared to using PVRs for maximising
performance is task-dependent, but PVRs offer advantages in terms of reduced
replay buffer size and faster training times. We also identify a strong
correlation between the dormant ratio and model performance, highlighting the
importance of exploration in visual RL. Our study provides insights into the
trade-offs between training from scratch and using PVRs, informing the design
of future visual RL algorithms.",2024-07-24,"Emlyn Williams, Athanasios Polydoros",http://arxiv.org/pdf/2407.17238v1,cs.LG
Statistical Batch-Based Bearing Fault Detection,"In the domain of rotating machinery, bearings are vulnerable to different
mechanical faults, including ball, inner, and outer race faults. Various
techniques can be used in condition-based monitoring, from classical signal
analysis to deep learning methods. Based on the complex working conditions of
rotary machines, multivariate statistical process control charts such as
Hotelling's $T^2$ and Squared Prediction Error are useful for providing early
warnings. However, these methods are rarely applied to condition monitoring of
rotating machinery due to the univariate nature of the datasets. In the present
paper, we propose a multivariate statistical process control-based fault
detection method that utilizes multivariate data composed of Fourier transform
features extracted for fixed-time batches. Our approach makes use of the
multidimensional nature of Fourier transform characteristics, which record more
detailed information about the machine's status, in an effort to enhance early
defect detection and diagnosis. Experiments with varying vibration measurement
locations (Fan End, Drive End), fault types (ball, inner, and outer race
faults), and motor loads (0-3 horsepower) are used to validate the suggested
approach. The outcomes illustrate our method's effectiveness in fault detection
and point to possible broader uses in industrial maintenance.",2024-07-24,"Victoria Jorry, Zina-Sabrina Duma, Tuomas Sihvonen, Satu-Pia Reinikainen, Lassi Roininen",http://arxiv.org/pdf/2407.17236v2,cs.LG
A Hybrid Federated Kernel Regularized Least Squares Algorithm,"Federated learning is becoming an increasingly viable and accepted strategy
for building machine learning models in critical privacy-preserving scenarios
such as clinical settings. Often, the data involved is not limited to clinical
data but also includes additional omics features (e.g. proteomics).
Consequently, data is distributed not only across hospitals but also across
omics centers, which are labs capable of generating such additional features
from biosamples. This scenario leads to a hybrid setting where data is
scattered both in terms of samples and features. In this hybrid setting, we
present an efficient reformulation of the Kernel Regularized Least Squares
algorithm, introduce two variants and validate them using well-established
datasets. Lastly, we discuss security measures to defend against possible
attacks.",2024-07-24,"Celeste Damiani, Yulia Rodina, Sergio Decherchi",http://arxiv.org/pdf/2407.17228v1,cs.LG
Sublinear Regret for a Class of Continuous-Time Linear-Quadratic Reinforcement Learning Problems,"We study reinforcement learning (RL) for a class of continuous-time
linear-quadratic (LQ) control problems for diffusions, where states are
scalar-valued and running control rewards are absent but volatilities of the
state processes depend on both state and control variables. We apply a
model-free approach that relies neither on knowledge of model parameters nor on
their estimations, and devise an RL algorithm to learn the optimal policy
parameter directly. Our main contributions include the introduction of an
exploration schedule and a regret analysis of the proposed algorithm. We
provide the convergence rate of the policy parameter to the optimal one, and
prove that the algorithm achieves a regret bound of $O(N^{\frac{3}{4}})$ up to
a logarithmic factor, where $N$ is the number of learning episodes. We conduct
a simulation study to validate the theoretical results and demonstrate the
effectiveness and reliability of the proposed algorithm. We also perform
numerical comparisons between our method and those of the recent model-based
stochastic LQ RL studies adapted to the state- and control-dependent volatility
setting, demonstrating a better performance of the former in terms of regret
bounds.",2024-07-24,"Yilie Huang, Yanwei Jia, Xun Yu Zhou",http://arxiv.org/pdf/2407.17226v4,cs.LG
Alternating Iteratively Reweighted $\ell_1$ and Subspace Newton Algorithms for Nonconvex Sparse Optimization,"This paper presents a novel hybrid algorithm for minimizing the sum of a
continuously differentiable loss function and a nonsmooth, possibly nonconvex,
sparse regularization function. The proposed method alternates between solving
a reweighted $\ell_1$-regularized subproblem and performing an inexact subspace
Newton step. The reweighted $\ell_1$-subproblem allows for efficient
closed-form solutions via the soft-thresholding operator, avoiding the
computational overhead of proximity operator calculations. As the algorithm
approaches an optimal solution, it maintains a stable support set, ensuring
that nonzero components stay uniformly bounded away from zero. It then switches
to a perturbed regularized Newton method, further accelerating the convergence.
We prove global convergence to a critical point and, under suitable conditions,
demonstrate that the algorithm exhibits local linear and quadratic convergence
rates. Numerical experiments show that our algorithm outperforms existing
methods in both efficiency and solution quality across various model prediction
problems.",2024-07-24,"Hao Wang, Xiangyu Yang, Yichen Zhu",http://arxiv.org/pdf/2407.17216v4,cs.LG
Application of Machine Learning and Convex Limiting to Subgrid Flux Modeling in the Shallow-Water Equations,"We propose a combination of machine learning and flux limiting for
property-preserving subgrid scale modeling in the context of flux-limited
finite volume methods for the one-dimensional shallow-water equations. The
numerical fluxes of a conservative target scheme are fitted to the coarse-mesh
averages of a monotone fine-grid discretization using a neural network to
parametrize the subgrid scale components. To ensure positivity preservation and
the validity of local maximum principles, we use a flux limiter that constrains
the intermediate states of an equivalent fluctuation form to stay in a convex
admissible set. The results of our numerical studies confirm that the proposed
combination of machine learning with monolithic convex limiting produces
meaningful closures even in scenarios for which the network was not trained.",2024-07-24,"Ilya Timofeyev, Alexey Schwarzmann, Dmitri Kuzmin",http://arxiv.org/pdf/2407.17214v2,cs.LG
Spectrum-Informed Multistage Neural Networks: Multiscale Function Approximators of Machine Precision,"Deep learning frameworks have become powerful tools for approaching
scientific problems such as turbulent flow, which has wide-ranging
applications. In practice, however, existing scientific machine learning
approaches have difficulty fitting complex, multi-scale dynamical systems to
very high precision, as required in scientific contexts. We propose using the
novel multistage neural network approach with a spectrum-informed
initialization to learn the residue from the previous stage, utilizing the
spectral biases associated with neural networks to capture high frequency
features in the residue, and successfully tackle the spectral bias of neural
networks. This approach allows the neural network to fit target functions to
double floating-point machine precision $O(10^{-16})$.",2024-07-24,"Jakin Ng, Yongji Wang, Ching-Yao Lai",http://arxiv.org/pdf/2407.17213v1,cs.LG
Nonverbal Immediacy Analysis in Education: A Multimodal Computational Model,"This paper introduces a novel computational approach for analyzing nonverbal
social behavior in educational settings. Integrating multimodal behavioral
cues, including facial expressions, gesture intensity, and spatial dynamics,
the model assesses the nonverbal immediacy (NVI) of teachers from RGB classroom
videos. A dataset of 400 30-second video segments from German classrooms was
constructed for model training and validation. The gesture intensity regressor
achieved a correlation of 0.84, the perceived distance regressor 0.55, and the
NVI model 0.44 with median human ratings. The model demonstrates the potential
to provide a valuable support in nonverbal behavior assessment, approximating
the accuracy of individual human raters. Validated against both questionnaire
data and trained observer ratings, our models show moderate to strong
correlations with relevant educational outcomes, indicating their efficacy in
reflecting effective teaching behaviors. This research advances the objective
assessment of nonverbal communication behaviors, opening new pathways for
educational research.",2024-07-24,"Uroš Petković, Jonas Frenkel, Olaf Hellwich, Rebecca Lazarides",http://arxiv.org/pdf/2407.17209v1,cs.LG
Sentiment Reasoning for Healthcare,"Transparency in AI healthcare decision-making is crucial for building trust
among AI and users. Incorporating reasoning capabilities enables Large Language
Models (LLMs) to understand emotions in context, handle nuanced language, and
infer unstated sentiments. In this work, we introduce a new task -- Sentiment
Reasoning -- for both speech and text modalities, along with our proposed
multimodal multitask framework and dataset. Sentiment Reasoning is an auxiliary
task in sentiment analysis where the model predicts both the sentiment label
and generates the rationale behind it based on the input transcript. Our study
conducted on both human transcripts and Automatic Speech Recognition (ASR)
transcripts shows that Sentiment Reasoning helps improve model transparency by
providing rationale for model prediction with quality semantically comparable
to humans while also improving model performance (1% increase in both accuracy
and macro-F1) via rationale-augmented fine-tuning. Also, no significant
difference in the semantic quality of generated rationales between human and
ASR transcripts. All code, data (English-translated and Vietnamese) and models
are published online: https://github.com/leduckhai/MultiMed.",2024-07-24,"Khai-Nguyen Nguyen, Khai Le-Duc, Bach Phan Tat, Duy Le, Long Vo-Dang, Truong-Son Hy",http://arxiv.org/pdf/2407.21054v3,cs.LG
Take a Step and Reconsider: Sequence Decoding for Self-Improved Neural Combinatorial Optimization,"The constructive approach within Neural Combinatorial Optimization (NCO)
treats a combinatorial optimization problem as a finite Markov decision
process, where solutions are built incrementally through a sequence of
decisions guided by a neural policy network. To train the policy, recent
research is shifting toward a 'self-improved' learning methodology that
addresses the limitations of reinforcement learning and supervised approaches.
Here, the policy is iteratively trained in a supervised manner, with solutions
derived from the current policy serving as pseudo-labels. The way these
solutions are obtained from the policy determines the quality of the
pseudo-labels. In this paper, we present a simple and problem-independent
sequence decoding method for self-improved learning based on sampling sequences
without replacement. We incrementally follow the best solution found and repeat
the sampling process from intermediate partial solutions. By modifying the
policy to ignore previously sampled sequences, we force it to consider only
unseen alternatives, thereby increasing solution diversity. Experimental
results for the Traveling Salesman and Capacitated Vehicle Routing Problem
demonstrate its strong performance. Furthermore, our method outperforms
previous NCO approaches on the Job Shop Scheduling Problem.",2024-07-24,"Jonathan Pirnay, Dominik G. Grimm",http://arxiv.org/pdf/2407.17206v1,cs.LG
Generalization Bounds of Surrogate Policies for Combinatorial Optimization Problems,"A recent stream of structured learning approaches has improved the practical
state of the art for a range of combinatorial optimization problems with
complex objectives encountered in operations research. Such approaches train
policies that chain a statistical model with a surrogate combinatorial
optimization oracle to map any instance of the problem to a feasible solution.
The key idea is to exploit the statistical distribution over instances instead
of dealing with instances separately. However learning such policies by risk
minimization is challenging because the empirical risk is piecewise constant in
the parameters, and few theoretical guarantees have been provided so far. In
this article, we investigate methods that smooth the risk by perturbing the
policy, which eases optimization and improves generalization. Our main
contribution is a generalization bound that controls the perturbation bias, the
statistical learning error, and the optimization error. Our analysis relies on
the introduction of a uniform weak property, which captures and quantifies the
interplay of the statistical model and the surrogate combinatorial optimization
oracle. This property holds under mild assumptions on the statistical model,
the surrogate optimization, and the instance data distribution. We illustrate
the result on a range of applications such as stochastic vehicle scheduling. In
particular, such policies are relevant for contextual stochastic optimization
and our results cover this case.",2024-07-24,"Pierre-Cyril Aubin-Frankowski, Yohann De Castro, Axel Parmentier, Alessandro Rudi",http://arxiv.org/pdf/2407.17200v1,cs.LG
Surrogate-guided optimization in quantum networks,"We propose an optimization algorithm to improve the design and performance of
quantum communication networks. When physical architectures become too complex
for analytical methods, numerical simulation becomes essential to study quantum
network behavior. Although highly informative, these simulations involve
complex numerical functions without known analytical forms, making traditional
optimization techniques that assume continuity, differentiability, or convexity
inapplicable. Additionally, quantum network simulations are computationally
demanding, rendering global approaches like Simulated Annealing or genetic
algorithms,
  which require extensive function evaluations, impractical. We introduce a
more efficient optimization workflow using machine learning models, which serve
as surrogates for a given objective function. We demonstrate the effectiveness
of our approach by applying it to three well-known optimization problems in
quantum networking: quantum memory allocation for multiple network nodes,
tuning an experimental parameter in all physical links of a quantum
entanglement switch, and finding efficient protocol settings within a large
asymmetric quantum network. The solutions found by our algorithm consistently
outperform those obtained with our baseline approaches -- Simulated Annealing
and Bayesian optimization -- in the allotted time limit by up to 18\% and 20\%,
respectively. Our framework thus allows for more comprehensive quantum network
studies, integrating surrogate-assisted optimization with existing quantum
network simulators.",2024-07-24,"Luise Prielinger, Álvaro G. Iñesta, Gayane Vardoyan",http://arxiv.org/pdf/2407.17195v1,cs.LG
A DeepONet for inverting the Neumann-to-Dirichlet Operator in Electrical Impedance Tomography: An approximation theoretic perspective and numerical results,"In this work, we consider the non-invasive medical imaging modality of
Electrical Impedance Tomography, where the problem is to recover the
conductivity in a medium from a set of data that arises out of a
current-to-voltage map (Neumann-to-Dirichlet operator) defined on the boundary
of the medium. We formulate this inverse problem as an operator-learning
problem where the goal is to learn the implicitly defined operator-to-function
map between the space of Neumann-to-Dirichlet operators to the space of
admissible conductivities. Subsequently, we use an operator-learning
architecture, popularly called DeepONets, to learn this operator-to-function
map. Thus far, most of the operator learning architectures have been
implemented to learn operators between function spaces. In this work, we
generalize the earlier works and use a DeepONet to actually {learn an
operator-to-function} map. We provide a Universal Approximation Theorem type
result which guarantees that this implicitly defined operator-to-function map
between the space of Neumann-to-Dirichlet operator to the space of conductivity
function can be approximated to an arbitrary degree using such a DeepONet.
Furthermore, we provide a computational implementation of our proposed approach
and compare it against a standard baseline. We show that the proposed approach
achieves good reconstructions and outperforms the baseline method in our
experiments.",2024-07-24,"Anuj Abhishek, Thilo Strauss",http://arxiv.org/pdf/2407.17182v3,cs.LG
NarrationDep: Narratives on Social Media For Automatic Depression Detection,"Social media posts provide valuable insight into the narrative of users and
their intentions, including providing an opportunity to automatically model
whether a social media user is depressed or not. The challenge lies in
faithfully modelling user narratives from their online social media posts,
which could potentially be useful in several different applications. We have
developed a novel and effective model called \texttt{NarrationDep}, which
focuses on detecting narratives associated with depression. By analyzing a
user's tweets, \texttt{NarrationDep} accurately identifies crucial narratives.
\texttt{NarrationDep} is a deep learning framework that jointly models
individual user tweet representations and clusters of users' tweets. As a
result, \texttt{NarrationDep} is characterized by a novel two-layer deep
learning model: the first layer models using social media text posts, and the
second layer learns semantic representations of tweets associated with a
cluster. To faithfully model these cluster representations, the second layer
incorporates a novel component that hierarchically learns from users' posts.
The results demonstrate that our framework outperforms other comparative models
including recently developed models on a variety of datasets.",2024-07-24,"Hamad Zogan, Imran Razzak, Shoaib Jameel, Guandong Xu",http://arxiv.org/pdf/2407.17174v1,cs.LG
Robust Deep Hawkes Process under Label Noise of Both Event and Occurrence,"Integrating deep neural networks with the Hawkes process has significantly
improved predictive capabilities in finance, health informatics, and
information technology. Nevertheless, these models often face challenges in
real-world settings, particularly due to substantial label noise. This issue is
of significant concern in the medical field, where label noise can arise from
delayed updates in electronic medical records or misdiagnoses, leading to
increased prediction risks. Our research indicates that deep Hawkes process
models exhibit reduced robustness when dealing with label noise, particularly
when it affects both event types and timing. To address these challenges, we
first investigate the influence of label noise in approximated intensity
functions and present a novel framework, the Robust Deep Hawkes Process (RDHP),
to overcome the impact of label noise on the intensity function of Hawkes
models, considering both the events and their occurrences. We tested RDHP using
multiple open-source benchmarks with synthetic noise and conducted a case study
on obstructive sleep apnea-hypopnea syndrome (OSAHS) in a real-world setting
with inherent label noise. The results demonstrate that RDHP can effectively
perform classification and regression tasks, even in the presence of noise
related to events and their timing. To the best of our knowledge, this is the
first study to successfully address both event and time label noise in deep
Hawkes process models, offering a promising solution for medical applications,
specifically in diagnosing OSAHS.",2024-07-24,"Xiaoyu Tan, Bin Li, Xihe Qiu, Jingjing Huang, Yinghui Xu, Wei Chu",http://arxiv.org/pdf/2407.17164v2,cs.LG
Explainable Artificial Intelligence Techniques for Irregular Temporal Classification of Multidrug Resistance Acquisition in Intensive Care Unit Patients,"Antimicrobial Resistance represents a significant challenge in the Intensive
Care Unit (ICU), where patients are at heightened risk of Multidrug-Resistant
(MDR) infections-pathogens resistant to multiple antimicrobial agents. This
study introduces a novel methodology that integrates Gated Recurrent Units
(GRUs) with advanced intrinsic and post-hoc interpretability techniques for
detecting the onset of MDR in patients across time. Within interpretability
methods, we propose Explainable Artificial Intelligence (XAI) approaches to
handle irregular Multivariate Time Series (MTS), introducing Irregular Time
Shapley Additive Explanations (IT-SHAP), a modification of Shapley Additive
Explanations designed for irregular MTS with Recurrent Neural Networks focused
on temporal outputs. Our methodology aims to identify specific risk factors
associated with MDR in ICU patients. GRU with Hadamard's attention demonstrated
high initial specificity and increasing sensitivity over time, correlating with
increased nosocomial infection risks during prolonged ICU stays. XAI analysis,
enhanced by Hadamard attention and IT-SHAP, identified critical factors such as
previous non-resistant cultures, specific antibiotic usage patterns, and
hospital environment dynamics. These insights suggest that early detection of
at-risk patients can inform interventions such as preventive isolation and
customized treatments, significantly improving clinical outcomes. The proposed
GRU model for temporal classification achieved an average Receiver Operating
Characteristic Area Under the Curve of 78.27 +- 1.26 over time, indicating
strong predictive performance. In summary, this study highlights the clinical
utility of our methodology, which combines predictive accuracy with
interpretability, thereby facilitating more effective healthcare interventions
by professionals.",2024-07-24,"Óscar Escudero-Arnanz, Cristina Soguero-Ruiz, Joaquín Álvarez-Rodríguez, Antonio G. Marques",http://arxiv.org/pdf/2407.17165v1,cs.LG
dlordinal: a Python package for deep ordinal classification,"dlordinal is a new Python library that unifies many recent deep ordinal
classification methodologies available in the literature. Developed using
PyTorch as underlying framework, it implements the top performing
state-of-the-art deep learning techniques for ordinal classification problems.
Ordinal approaches are designed to leverage the ordering information present in
the target variable. Specifically, it includes loss functions, various output
layers, dropout techniques, soft labelling methodologies, and other
classification strategies, all of which are appropriately designed to
incorporate the ordinal information. Furthermore, as the performance metrics to
assess novel proposals in ordinal classification depend on the distance between
target and predicted classes in the ordinal scale, suitable ordinal evaluation
metrics are also included. dlordinal is distributed under the BSD-3-Clause
license and is available at https://github.com/ayrna/dlordinal.",2024-07-24,"Francisco Bérchez-Moreno, Víctor M. Vargas, Rafael Ayllón-Gavilán, David Guijo-Rubio, César Hervás-Martínez, Juan C. Fernández, Pedro A. Gutiérrez",http://arxiv.org/pdf/2407.17163v3,cs.LG
Quantum Supervised Learning,"Recent advancements in quantum computing have positioned it as a prospective
solution for tackling intricate computational challenges, with supervised
learning emerging as a promising domain for its application. Despite this
potential, the field of quantum machine learning is still in its early stages,
and there persists a level of skepticism regarding a possible near-term quantum
advantage. This paper aims to provide a classical perspective on current
quantum algorithms for supervised learning, effectively bridging traditional
machine learning principles with advancements in quantum machine learning.
Specifically, this study charts a research trajectory that diverges from the
predominant focus of quantum machine learning literature, originating from the
prerequisites of classical methodologies and elucidating the potential impact
of quantum approaches. Through this exploration, our objective is to deepen the
understanding of the convergence between classical and quantum methods, thereby
laying the groundwork for future advancements in both domains and fostering the
involvement of classical practitioners in the field of quantum machine
learning.",2024-07-24,Antonio Macaluso,http://arxiv.org/pdf/2407.17161v1,cs.LG
Path Following and Stabilisation of a Bicycle Model using a Reinforcement Learning Approach,"Over the years, complex control approaches have been developed to control the
motion of a bicycle. Reinforcement Learning (RL), a branch of machine learning,
promises easy deployment of so-called agents. Deployed agents are increasingly
considered as an alternative to controllers for mechanical systems. The present
work introduces an RL approach to do path following with a virtual bicycle
model while simultaneously stabilising it laterally. The bicycle, modelled as
the Whipple benchmark model and using multibody system dynamics, has no
stabilisation aids. The agent succeeds in both path following and stabilisation
of the bicycle model exclusively by outputting steering angles, which are
converted into steering torques via a PD controller. Curriculum learning is
applied as a state-of-the-art training strategy. Different settings for the
implemented RL framework are investigated and compared to each other. The
performance of the deployed agents is evaluated using different types of paths
and measurements. The ability of the deployed agents to do path following and
stabilisation of the bicycle model travelling between 2m/s and 7m/s along
complex paths including full circles, slalom manoeuvres, and lane changes is
demonstrated. Explanatory methods for machine learning are used to analyse the
functionality of a deployed agent and link the introduced RL approach with
research in the field of bicycle dynamics.",2024-07-24,"Sebastian Weyrer, Peter Manzl, A. L. Schwab, Johannes Gerstmayr",http://arxiv.org/pdf/2407.17156v1,cs.LG
Automated transport separation using the neural shifted proper orthogonal decomposition,"This paper presents a neural network-based methodology for the decomposition
of transport-dominated fields using the shifted proper orthogonal decomposition
(sPOD). Classical sPOD methods typically require an a priori knowledge of the
transport operators to determine the co-moving fields. However, in many
real-life problems, such knowledge is difficult or even impossible to obtain,
limiting the applicability and benefits of the sPOD. To address this issue, our
approach estimates both the transport and co-moving fields simultaneously using
neural networks. This is achieved by training two sub-networks dedicated to
learning the transports and the co-moving fields, respectively. Applications to
synthetic data and a wildland fire model illustrate the capabilities and
efficiency of this neural sPOD approach, demonstrating its ability to separate
the different fields effectively.",2024-07-24,"Beata Zorawski, Shubhaditya Burela, Philipp Krah, Arthur Marmin, Kai Schneider",http://arxiv.org/pdf/2407.17539v1,cs.LG
To Know or Not To Know? Analyzing Self-Consistency of Large Language Models under Ambiguity,"One of the major aspects contributing to the striking performance of large
language models (LLMs) is the vast amount of factual knowledge accumulated
during pre-training. Yet, many LLMs suffer from self-inconsistency, which
raises doubts about their trustworthiness and reliability. This paper focuses
on entity type ambiguity, analyzing the proficiency and consistency of
state-of-the-art LLMs in applying factual knowledge when prompted with
ambiguous entities. To do so, we propose an evaluation protocol that
disentangles knowing from applying knowledge, and test state-of-the-art LLMs on
49 ambiguous entities. Our experiments reveal that LLMs struggle with choosing
the correct entity reading, achieving an average accuracy of only 85%, and as
low as 75% with underspecified prompts. The results also reveal systematic
discrepancies in LLM behavior, showing that while the models may possess
knowledge, they struggle to apply it consistently, exhibit biases toward
preferred readings, and display self-inconsistencies. This highlights the need
to address entity ambiguity in the future for more trustworthy LLMs.",2024-07-24,"Anastasiia Sedova, Robert Litschko, Diego Frassinelli, Benjamin Roth, Barbara Plank",http://arxiv.org/pdf/2407.17125v3,cs.LG
Parameter-Efficient Fine-Tuning for Continual Learning: A Neural Tangent Kernel Perspective,"Parameter-efficient fine-tuning for continual learning (PEFT-CL) has shown
promise in adapting pre-trained models to sequential tasks while mitigating
catastrophic forgetting problem. However, understanding the mechanisms that
dictate continual performance in this paradigm remains elusive. To unravel this
mystery, we undertake a rigorous analysis of PEFT-CL dynamics to derive
relevant metrics for continual scenarios using Neural Tangent Kernel (NTK)
theory. With the aid of NTK as a mathematical analysis tool, we recast the
challenge of test-time forgetting into the quantifiable generalization gaps
during training, identifying three key factors that influence these gaps and
the performance of PEFT-CL: training sample size, task-level feature
orthogonality, and regularization. To address these challenges, we introduce
NTK-CL, a novel framework that eliminates task-specific parameter storage while
adaptively generating task-relevant features. Aligning with theoretical
guidance, NTK-CL triples the feature representation of each sample,
theoretically and empirically reducing the magnitude of both task-interplay and
task-specific generalization gaps. Grounded in NTK analysis, our framework
imposes an adaptive exponential moving average mechanism and constraints on
task-level feature orthogonality, maintaining intra-task NTK forms while
attenuating inter-task NTK forms. Ultimately, by fine-tuning optimizable
parameters with appropriate regularization, NTK-CL achieves state-of-the-art
performance on established PEFT-CL benchmarks. This work provides a theoretical
foundation for understanding and improving PEFT-CL models, offering insights
into the interplay between feature representation, task orthogonality, and
generalization, contributing to the development of more efficient continual
learning systems.",2024-07-24,"Jingren Liu, Zhong Ji, YunLong Yu, Jiale Cao, Yanwei Pang, Jungong Han, Xuelong Li",http://arxiv.org/pdf/2407.17120v2,cs.LG
EverAdapt: Continuous Adaptation for Dynamic Machine Fault Diagnosis Environments,"Unsupervised Domain Adaptation (UDA) has emerged as a key solution in
data-driven fault diagnosis, addressing domain shift where models underperform
in changing environments. However, under the realm of continually changing
environments, UDA tends to underperform on previously seen domains when
adapting to new ones - a problem known as catastrophic forgetting. To address
this limitation, we introduce the EverAdapt framework, specifically designed
for continuous model adaptation in dynamic environments. Central to EverAdapt
is a novel Continual Batch Normalization (CBN), which leverages source domain
statistics as a reference point to standardize feature representations across
domains. EverAdapt not only retains statistical information from previous
domains but also adapts effectively to new scenarios. Complementing CBN, we
design a class-conditional domain alignment module for effective integration of
target domains, and a Sample-efficient Replay strategy to reinforce memory
retention. Experiments on real-world datasets demonstrate EverAdapt superiority
in maintaining robust fault diagnosis in dynamic environments. Our code is
available: https://github.com/mohamedr002/EverAdapt",2024-07-24,"Edward, Mohamed Ragab, Yuecong Xu, Min Wu, Yuecong Xu, Zhenghua Chen, Abdulla Alseiari, Xiaoli Li",http://arxiv.org/pdf/2407.17117v1,cs.LG
Neural Dueling Bandits: Preference-Based Optimization with Human Feedback,"Contextual dueling bandit is used to model the bandit problems, where a
learner's goal is to find the best arm for a given context using observed noisy
human preference feedback over the selected arms for the past contexts.
However, existing algorithms assume the reward function is linear, which can be
complex and non-linear in many real-life applications like online
recommendations or ranking web search results. To overcome this challenge, we
use a neural network to estimate the reward function using preference feedback
for the previously selected arms. We propose upper confidence bound- and
Thompson sampling-based algorithms with sub-linear regret guarantees that
efficiently select arms in each round. We also extend our theoretical results
to contextual bandit problems with binary feedback, which is in itself a
non-trivial contribution. Experimental results on the problem instances derived
from synthetic datasets corroborate our theoretical results.",2024-07-24,"Arun Verma, Zhongxiang Dai, Xiaoqiang Lin, Patrick Jaillet, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2407.17112v2,cs.LG
Towards Robust Knowledge Tracing Models via k-Sparse Attention,"Knowledge tracing (KT) is the problem of predicting students' future
performance based on their historical interaction sequences. With the advanced
capability of capturing contextual long-term dependency, attention mechanism
becomes one of the essential components in many deep learning based KT (DLKT)
models. In spite of the impressive performance achieved by these attentional
DLKT models, many of them are often vulnerable to run the risk of overfitting,
especially on small-scale educational datasets. Therefore, in this paper, we
propose \textsc{sparseKT}, a simple yet effective framework to improve the
robustness and generalization of the attention based DLKT approaches.
Specifically, we incorporate a k-selection module to only pick items with the
highest attention scores. We propose two sparsification heuristics : (1)
soft-thresholding sparse attention and (2) top-$K$ sparse attention. We show
that our \textsc{sparseKT} is able to help attentional KT models get rid of
irrelevant student interactions and have comparable predictive performance when
compared to 11 state-of-the-art KT models on three publicly available
real-world educational datasets. To encourage reproducible research, we make
our data and code publicly available at
\url{https://github.com/pykt-team/pykt-toolkit}\footnote{We merged our model to
the \textsc{pyKT} benchmark at \url{https://pykt.org/}.}.",2024-07-24,"Shuyan Huang, Zitao Liu, Xiangyu Zhao, Weiqi Luo, Jian Weng",http://arxiv.org/pdf/2407.17097v1,cs.LG
Assessing Non-Nested Configurations of Multifidelity Machine Learning for Quantum-Chemical Properties,"Multifidelity machine learning (MFML) for quantum chemical (QC) properties
has seen strong development in the recent years. The method has been shown to
reduce the cost of generating training data for high-accuracy low-cost ML
models. In such a set-up, the ML models are trained on molecular geometries and
some property of interest computed at various computational chemistry
accuracies, or fidelities. These are then combined in training the MFML models.
In some multifidelity models, the training data is required to be nested, that
is the same molecular geometries are included to calculate the property across
all the fidelities. In these multifidelity models, the requirement of a nested
configuration restricts the kind of sampling that can be performed while
selection training samples at different fidelities.
  This work assesses the use of non-nested training data for two of these
multifidelity methods, namely MFML and optimized MFML (o-MFML). The assessment
is carried out for the prediction of ground state energies and first vertical
excitation energies of a diverse collection of molecules of the CheMFi dataset.
Results indicate that the MFML method still requires a nested structure of
training data across the fidelities. However, the o-MFML method shows promising
results for non-nested multifidelity training data with model errors comparable
to the nested configurations.",2024-07-24,"Vivin Vinod, Peter Zaspel",http://arxiv.org/pdf/2407.17087v1,cs.LG
OVR: A Dataset for Open Vocabulary Temporal Repetition Counting in Videos,"We introduce a dataset of annotations of temporal repetitions in videos. The
dataset, OVR (pronounced as over), contains annotations for over 72K videos,
with each annotation specifying the number of repetitions, the start and end
time of the repetitions, and also a free-form description of what is repeating.
The annotations are provided for videos sourced from Kinetics and Ego4D, and
consequently cover both Exo and Ego viewing conditions, with a huge variety of
actions and activities. Moreover, OVR is almost an order of magnitude larger
than previous datasets for video repetition. We also propose a baseline
transformer-based counting model, OVRCounter, that can localise and count
repetitions in videos that are up to 320 frames long. The model is trained and
evaluated on the OVR dataset, and its performance assessed with and without
using text to specify the target class to count. The performance is also
compared to a prior repetition counting model. The dataset is available for
download at: https://sites.google.com/view/openvocabreps/",2024-07-24,"Debidatta Dwibedi, Yusuf Aytar, Jonathan Tompson, Andrew Zisserman",http://arxiv.org/pdf/2407.17085v1,cs.LG
An Efficient and Flexible Deep Learning Method for Signal Delineation via Keypoints Estimation,"Deep Learning (DL) methods have been used for electrocardiogram (ECG)
processing in a wide variety of tasks, demonstrating good performance compared
with traditional signal processing algorithms. These methods offer an efficient
framework with a limited need for apriori data pre-processing and feature
engineering. While several studies use this approach for ECG signal
delineation, a significant gap persists between the expected and the actual
outcome. Existing methods rely on a sample-to-sample classifier. However, the
clinical expected outcome consists of a set of onset, offset, and peak for the
different waves that compose each R-R interval. To align the actual with the
expected output, it is necessary to incorporate post-processing algorithms.
This counteracts two of the main advantages of DL models, since these
algorithms are based on assumptions and slow down the method's performance. In
this paper, we present Keypoint Estimation for Electrocardiogram Delineation
(KEED), a novel DL model designed for keypoint estimation, which organically
offers an output aligned with clinical expectations. By standing apart from the
conventional sample-to-sample classifier, we achieve two benefits: (i)
Eliminate the need for additional post-processing, and (ii) Establish a
flexible framework that allows the adjustment of the threshold value
considering the sensitivity-specificity tradeoff regarding the particular
clinical requirements. The proposed method's performance is compared with
state-of-the-art (SOTA) signal processing methods. Remarkably, KEED
significantly outperforms despite being optimized with an extremely limited
annotated data. In addition, KEED decreases the inference time by a factor
ranging from 52x to 703x.",2024-07-24,"Adrian Atienza, Jakob Bardram, Sadasivan Puthusserypady",http://arxiv.org/pdf/2407.20258v1,cs.LG
Contrastive Learning Is Not Optimal for Quasiperiodic Time Series,"Despite recent advancements in Self-Supervised Learning (SSL) for time series
analysis, a noticeable gap persists between the anticipated achievements and
actual performance. While these methods have demonstrated formidable
generalization capabilities with minimal labels in various domains, their
effectiveness in distinguishing between different classes based on a limited
number of annotated records is notably lacking. Our hypothesis attributes this
bottleneck to the prevalent use of Contrastive Learning, a shared training
objective in previous state-of-the-art (SOTA) methods. By mandating
distinctiveness between representations for negative pairs drawn from separate
records, this approach compels the model to encode unique record-based patterns
but simultaneously neglects changes occurring across the entire record. To
overcome this challenge, we introduce Distilled Embedding for Almost-Periodic
Time Series (DEAPS) in this paper, offering a non-contrastive method tailored
for quasiperiodic time series, such as electrocardiogram (ECG) data. By
avoiding the use of negative pairs, we not only mitigate the model's blindness
to temporal changes but also enable the integration of a ""Gradual Loss (Lgra)""
function. This function guides the model to effectively capture dynamic
patterns evolving throughout the record. The outcomes are promising, as DEAPS
demonstrates a notable improvement of +10% over existing SOTA methods when just
a few annotated records are presented to fit a Machine Learning (ML) model
based on the learned representation.",2024-07-24,"Adrian Atienza, Jakob Bardram, Sadasivan Puthusserypady",http://arxiv.org/pdf/2407.17073v1,cs.LG
An Efficient Procedure for Computing Bayesian Network Structure Learning,"We propose a globally optimal Bayesian network structure discovery algorithm
based on a progressively leveled scoring approach. Bayesian network structure
discovery is a fundamental yet NP-hard problem in the field of probabilistic
graphical models, and as the number of variables increases, memory usage grows
exponentially. The simple and effective method proposed by Silander and
Myllym\""aki has been widely applied in this field, as it incrementally
calculates local scores to achieve global optimality. However, existing methods
that utilize disk storage, while capable of handling networks with a larger
number of variables, introduce issues such as latency, fragmentation, and
additional overhead associated with disk I/O operations. To avoid these
problems, we explore how to further enhance computational efficiency and reduce
peak memory usage using only memory. We introduce an efficient hierarchical
computation method that requires only a single traversal of all local
structures, retaining only the data and information necessary for the current
computation, thereby improving efficiency and significantly reducing memory
requirements. Experimental results indicate that our method, when using only
memory, not only reduces peak memory usage but also improves computational
efficiency compared to existing methods, demonstrating good scalability for
handling larger networks and exhibiting stable experimental results.
Ultimately, we successfully achieved the processing of a Bayesian network with
28 variables using only memory.",2024-07-24,"Hongming Huang, Joe Suzuki",http://arxiv.org/pdf/2407.17072v1,cs.LG
Curriculum Negative Mining For Temporal Networks,"Temporal networks are effective in capturing the evolving interactions of
networks over time, such as social networks and e-commerce networks. In recent
years, researchers have primarily concentrated on developing specific model
architectures for Temporal Graph Neural Networks (TGNNs) in order to improve
the representation quality of temporal nodes and edges. However, limited
attention has been given to the quality of negative samples during the training
of TGNNs. When compared with static networks, temporal networks present two
specific challenges for negative sampling: positive sparsity and positive
shift. Positive sparsity refers to the presence of a single positive sample
amidst numerous negative samples at each timestamp, while positive shift
relates to the variations in positive samples across different timestamps. To
robustly address these challenges in training TGNNs, we introduce Curriculum
Negative Mining (CurNM), a model-aware curriculum learning framework that
adaptively adjusts the difficulty of negative samples. Within this framework,
we first establish a dynamically updated negative pool that balances random,
historical, and hard negatives to address the challenges posed by positive
sparsity. Secondly, we implement a temporal-aware negative selection module
that focuses on learning from the disentangled factors of recently active
edges, thus accurately capturing shifting preferences. Extensive experiments on
12 datasets and 3 TGNNs demonstrate that our method outperforms baseline
methods by a significant margin. Additionally, thorough ablation studies and
parameter sensitivity experiments verify the usefulness and robustness of our
approach. Our code is available at https://github.com/zziyue83/CurNM.",2024-07-24,"Ziyue Chen, Tongya Zheng, Mingli Song",http://arxiv.org/pdf/2407.17070v1,cs.LG
Automated Code-centric Software Vulnerability Assessment: How Far Are We? An Empirical Study in C/C++,"Background: The C and C++ languages hold significant importance in Software
Engineering research because of their widespread use in practice. Numerous
studies have utilized Machine Learning (ML) and Deep Learning (DL) techniques
to detect software vulnerabilities (SVs) in the source code written in these
languages. However, the application of these techniques in function-level SV
assessment has been largely unexplored. SV assessment is increasingly crucial
as it provides detailed information on the exploitability, impacts, and
severity of security defects, thereby aiding in their prioritization and
remediation. Aims: We conduct the first empirical study to investigate and
compare the performance of ML and DL models, many of which have been used for
SV detection, for function-level SV assessment in C/C++. Method: Using 9,993
vulnerable C/C++ functions, we evaluated the performance of six multi-class ML
models and five multi-class DL models for the SV assessment at the function
level based on the Common Vulnerability Scoring System (CVSS). We further
explore multi-task learning, which can leverage common vulnerable code to
predict all SV assessment outputs simultaneously in a single model, and compare
the effectiveness and efficiency of this model type with those of the original
multi-class models. Results: We show that ML has matching or even better
performance compared to the multi-class DL models for function-level SV
assessment with significantly less training time. Employing multi-task learning
allows the DL models to perform significantly better, with an average of 8-22%
increase in Matthews Correlation Coefficient (MCC). Conclusions: We distill the
practices of using data-driven techniques for function-level SV assessment in
C/C++, including the use of multi-task DL to balance efficiency and
effectiveness. This can establish a strong foundation for future work in this
area.",2024-07-24,"Anh The Nguyen, Triet Huynh Minh Le, M. Ali Babar",http://arxiv.org/pdf/2407.17053v4,cs.LG
Time Series Imputation with Multivariate Radial Basis Function Neural Network,"Researchers have been persistently working to address the issue of missing
values in time series data. Numerous models have been proposed, striving to
estimate the distribution of the data. The Radial Basis Functions Neural
Network (RBFNN) has recently exhibited exceptional performance in estimating
data distribution. In this paper, we propose a time series imputation model
based on RBFNN. Our imputation model learns local information from timestamps
to create a continuous function. Additionally, we incorporate time gaps to
facilitate learning information considering the missing terms of missing
values. We name this model the Missing Imputation Multivariate RBFNN
(MIM-RBFNN). However, MIM-RBFNN relies on a local information-based learning
approach, which presents difficulties in utilizing temporal information.
Therefore, we propose an extension called the Missing Value Imputation
Recurrent Neural Network with Continuous Function (MIRNN-CF) using the
continuous function generated by MIM-RBFNN. We evaluate the performance using
two real-world datasets with non-random missing and random missing patterns,
and conduct an ablation study comparing MIM-RBFNN and MIRNN-CF.",2024-07-24,"Chanyoung Jung, Yun Jang",http://arxiv.org/pdf/2407.17040v2,cs.LG
Low-Latency Privacy-Preserving Deep Learning Design via Secure MPC,"Secure multi-party computation (MPC) facilitates privacy-preserving
computation between multiple parties without leaking private information. While
most secure deep learning techniques utilize MPC operations to achieve feasible
privacy-preserving machine learning on downstream tasks, the overhead of the
computation and communication still hampers their practical application. This
work proposes a low-latency secret-sharing-based MPC design that reduces
unnecessary communication rounds during the execution of MPC protocols. We also
present a method for improving the computation of commonly used nonlinear
functions in deep learning by integrating multivariate multiplication and
coalescing different packets into one to maximize network utilization. Our
experimental results indicate that our method is effective in a variety of
settings, with a speedup in communication latency of $10\sim20\%$.",2024-07-24,"Ke Lin, Yasir Glani, Ping Luo",http://arxiv.org/pdf/2407.18982v1,cs.LG
Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference,"Deep Gaussian processes (DGPs) provide a robust paradigm for Bayesian deep
learning. In DGPs, a set of sparse integration locations called inducing points
are selected to approximate the posterior distribution of the model. This is
done to reduce computational complexity and improve model efficiency. However,
inferring the posterior distribution of inducing points is not straightforward.
Traditional variational inference approaches to posterior approximation often
lead to significant bias. To address this issue, we propose an alternative
method called Denoising Diffusion Variational Inference (DDVI) that uses a
denoising diffusion stochastic differential equation (SDE) to generate
posterior samples of inducing variables. We rely on score matching methods for
denoising diffusion model to approximate score functions with a neural network.
Furthermore, by combining classical mathematical theory of SDEs with the
minimization of KL divergence between the approximate and true processes, we
propose a novel explicit variational lower bound for the marginal likelihood
function of DGP. Through experiments on various datasets and comparisons with
baseline methods, we empirically demonstrate the effectiveness of DDVI for
posterior inference of inducing points for DGP models.",2024-07-24,"Jian Xu, Delu Zeng, John Paisley",http://arxiv.org/pdf/2407.17033v1,cs.LG
Gymnasium: A Standard Interface for Reinforcement Learning Environments,"Reinforcement Learning (RL) is a continuously growing field that has the
potential to revolutionize many areas of artificial intelligence. However,
despite its promise, RL research is often hindered by the lack of
standardization in environment and algorithm implementations. This makes it
difficult for researchers to compare and build upon each other's work, slowing
down progress in the field. Gymnasium is an open-source library that provides a
standard API for RL environments, aiming to tackle this issue. Gymnasium's main
feature is a set of abstractions that allow for wide interoperability between
environments and training algorithms, making it easier for researchers to
develop and test RL algorithms. In addition, Gymnasium provides a collection of
easy-to-use environments, tools for easily customizing environments, and tools
to ensure the reproducibility and robustness of RL research. Through this
unified framework, Gymnasium significantly streamlines the process of
developing and testing RL algorithms, enabling researchers to focus more on
innovation and less on implementation details. By providing a standardized
platform for RL research, Gymnasium helps to drive forward the field of
reinforcement learning and unlock its full potential. Gymnasium is available
online at https://github.com/Farama-Foundation/Gymnasium",2024-07-24,"Mark Towers, Ariel Kwiatkowski, Jordan Terry, John U. Balis, Gianluca De Cola, Tristan Deleu, Manuel Goulão, Andreas Kallinteris, Markus Krimmel, Arjun KG, Rodrigo Perez-Vicente, Andrea Pierré, Sander Schulhoff, Jun Jet Tai, Hannah Tan, Omar G. Younis",http://arxiv.org/pdf/2407.17032v3,cs.LG
LAMBDA: A Large Model Based Data Agent,"We introduce LArge Model Based Data Agent (LAMBDA), a novel open-source,
code-free multi-agent data analysis system that leverages the power of large
models. LAMBDA is designed to address data analysis challenges in complex
data-driven applications through innovatively designed data agents that operate
iteratively and generatively using natural language. At the core of LAMBDA are
two key agent roles: the programmer and the inspector, which are engineered to
work together seamlessly. Specifically, the programmer generates code based on
the user's instructions and domain-specific knowledge, enhanced by advanced
models. Meanwhile, the inspector debugs the code when necessary. To ensure
robustness and handle adverse scenarios, LAMBDA features a user interface that
allows direct user intervention in the operational loop. Additionally, LAMBDA
can flexibly integrate external models and algorithms through our proposed
Knowledge Integration Mechanism, catering to the needs of customized data
analysis. LAMBDA has demonstrated strong performance on various data analysis
tasks. It has the potential to enhance data analysis paradigms by seamlessly
integrating human and artificial intelligence, making it more accessible,
effective, and efficient for users from diverse backgrounds. The strong
performance of LAMBDA in solving data analysis problems is demonstrated using
real-world data examples. Videos of several case studies are available at
https://xxxlambda.github.io/lambda_webpage.",2024-07-24,"Maojun Sun, Ruijian Han, Binyan Jiang, Houduo Qi, Defeng Sun, Yancheng Yuan, Jian Huang",http://arxiv.org/pdf/2407.17535v2,cs.LG
Accurate and Efficient Fine-Tuning of Quantized Large Language Models Through Optimal Balance,"Large Language Models (LLMs) have demonstrated impressive performance across
various domains. However, the enormous number of model parameters makes
fine-tuning challenging, significantly limiting their application and
deployment. Existing solutions combine parameter quantization with Low-Rank
Adaptation (LoRA), greatly reducing memory usage but resulting in noticeable
performance degradation. In this paper, we identify an imbalance in fine-tuning
quantized pre-trained models: overly complex adapter inputs and outputs versus
low effective trainability of the adaptation. We propose Quantized LLMs with
Balanced-rank Adaptation (Q-BaRA), which simplifies the adapter inputs and
outputs while increasing the adapter's rank to achieve a more suitable balance
for fine-tuning quantized LLMs. Additionally, for scenarios where fine-tuned
LLMs need to be deployed as low-precision inference models, we introduce
Quantization-Aware Fine-tuning with Higher Rank Adaptation (QA-HiRA), which
simplifies the adapter inputs and outputs to align with the pre-trained model's
block-wise quantization while employing a single matrix to achieve a higher
rank. Both Q-BaRA and QA-HiRA are easily implemented and offer the following
optimizations: (i) Q-BaRA consistently achieves the highest accuracy compared
to baselines and other variants, requiring the same number of trainable
parameters and computational effort; (ii) QA-HiRA naturally merges adapter
parameters into the block-wise quantized model after fine-tuning, achieving the
highest accuracy compared to other methods. We apply our Q-BaRA and QA-HiRA to
the LLaMA and LLaMA2 model families and validate their effectiveness across
different fine-tuning datasets and downstream scenarios.
  Code will be made available at
\href{https://github.com/xiaocaigou/qbaraqahira}{https://github.com/xiaocaigou/qbaraqahira}",2024-07-24,"Ao Shen, Qiang Wang, Zhiquan Lai, Xionglve Li, Dongsheng Li",http://arxiv.org/pdf/2407.17029v1,cs.LG
SepsisLab: Early Sepsis Prediction with Uncertainty Quantification and Active Sensing,"Sepsis is the leading cause of in-hospital mortality in the USA. Early sepsis
onset prediction and diagnosis could significantly improve the survival of
sepsis patients. Existing predictive models are usually trained on high-quality
data with few missing information, while missing values widely exist in
real-world clinical scenarios (especially in the first hours of admissions to
the hospital), which causes a significant decrease in accuracy and an increase
in uncertainty for the predictive models. The common method to handle missing
values is imputation, which replaces the unavailable variables with estimates
from the observed data. The uncertainty of imputation results can be propagated
to the sepsis prediction outputs, which have not been studied in existing works
on either sepsis prediction or uncertainty quantification. In this study, we
first define such propagated uncertainty as the variance of prediction output
and then introduce uncertainty propagation methods to quantify the propagated
uncertainty. Moreover, for the potential high-risk patients with low confidence
due to limited observations, we propose a robust active sensing algorithm to
increase confidence by actively recommending clinicians to observe the most
informative variables. We validate the proposed models in both publicly
available data (i.e., MIMIC-III and AmsterdamUMCdb) and proprietary data in The
Ohio State University Wexner Medical Center (OSUWMC). The experimental results
show that the propagated uncertainty is dominant at the beginning of admissions
to hospitals and the proposed algorithm outperforms state-of-the-art active
sensing methods. Finally, we implement a SepsisLab system for early sepsis
prediction and active sensing based on our pre-trained models. Clinicians and
potential sepsis patients can benefit from the system in early prediction and
diagnosis of sepsis.",2024-07-24,"Changchang Yin, Pin-Yu Chen, Bingsheng Yao, Dakuo Wang, Jeffrey Caterino, Ping Zhang",http://arxiv.org/pdf/2407.16999v1,cs.LG
A Voter-Based Stochastic Rejection-Method Framework for Asymptotically Safe Language Model Outputs,"This paper proposes a new method for preventing unsafe or otherwise low
quality large language model (LLM) outputs, by leveraging the stochasticity of
LLMs. We propose a system whereby LLM checkers vote on the acceptability of a
generated output, regenerating it if a threshold of disapproval is reached,
until sufficient checkers approve. We further propose estimators for cost and
failure rate, and based on those estimators and experimental data tailored to
the application, we propose an algorithm that achieves a desired failure rate
at the least possible cost. We demonstrate that, under these models, failure
rate decreases exponentially as a function of cost when voter count and
threshold are chosen according to the algorithm, and that the models reasonably
estimate the actual performance of such a system in action, even with limited
data.",2024-07-24,"Jake R. Watts, Joel Sokol",http://arxiv.org/pdf/2407.16994v2,cs.LG
SFPrompt: Communication-Efficient Split Federated Fine-Tuning for Large Pre-Trained Models over Resource-Limited Devices,"Large pre-trained models have exhibited remarkable achievements across
various domains. The substantial training costs associated with these models
have led to wide studies of fine-tuning for effectively harnessing their
capabilities in solving downstream tasks. Yet, conventional fine-tuning
approaches become infeasible when the model lacks access to downstream data due
to privacy concerns. Naively integrating fine-tuning approaches with the
emerging federated learning frameworks incurs substantial communication
overhead and exerts high demand on local computing resources, making it
impractical for common resource-limited devices. In this paper, we introduce
SFPrompt, an innovative privacy-preserving fine-tuning method tailored for the
federated setting where direct uploading of raw data is prohibited and local
devices are resource-constrained to run a complete pre-trained model. In
essence, SFPrompt judiciously combines split learning with federated learning
to handle these challenges. Specifically, the pre-trained model is first
partitioned into client and server components, thereby streamlining the
client-side model and substantially alleviating computational demands on local
resources. SFPrompt then introduces soft prompts into the federated model to
enhance the fine-tuning performance. To further reduce communication costs, a
novel dataset pruning algorithm and a local-loss update strategy are devised
during the fine-tuning process. Extensive experiments demonstrate that SFPrompt
delivers competitive performance as the federated full fine-tuning approach
while consuming a mere 0.46% of local computing resources and incurring 53%
less communication cost.",2024-07-24,"Linxiao Cao, Yifei Zhu, Wei Gong",http://arxiv.org/pdf/2407.17533v1,cs.LG
Predicting cognitive load in immersive driving scenarios with a hybrid CNN-RNN model,"One debatable issue in traffic safety research is that cognitive load from
sec-ondary tasks reduces primary task performance, such as driving. Although
physiological signals have been extensively used in driving-related research to
assess cognitive load, only a few studies have specifically focused on high
cognitive load scenarios. Most existing studies tend to examine moderate or low
levels of cognitive load In this study, we adopted an auditory version of the
n-back task of three levels as a cognitively loading secondary task while
driving in a driving simulator. During the simultaneous execution of driving
and the n-back task, we recorded fNIRS, eye-tracking, and driving behavior data
to predict cognitive load at three different levels. To the best of our
knowledge, this combination of data sources has never been used before. Un-like
most previous studies that utilize binary classification of cognitive load and
driving in conditions without traffic, our study involved three levels of
cognitive load, with drivers operating in normal traffic conditions under low
visibility, specifically during nighttime and rainy weather. We proposed a
hybrid neural network combining a 1D Convolutional Neural Network and a
Recurrent Neural Network to predict cognitive load. Our experimental re-sults
demonstrate that the proposed model, with fewer parameters, increases accuracy
from 99.82% to 99.99% using physiological data, and from 87.26% to 92.02% using
driving behavior data alone. This significant improvement highlights the
effectiveness of our hybrid neural network in accurately pre-dicting cognitive
load during driving under challenging conditions.",2024-07-24,"Mehshan Ahmed Khan, Houshyar Asadi, Mohammad Reza Chalak Qazani, Adetokunbo Arogbonlo, Saeid Nahavandi, Chee Peng Lim",http://arxiv.org/pdf/2408.06350v1,cs.LG
Sparse Tensor PCA via Tensor Decomposition for Unsupervised Feature Selection,"Recently, introducing Tensor Decomposition (TD) techniques into unsupervised
feature selection (UFS) has been an emerging research topic. A tensor structure
is beneficial for mining the relations between different modes and helps
relieve the computation burden. However, while existing methods exploit TD to
preserve the data tensor structure, they do not consider the influence of data
orientation and thus have difficulty in handling orientation-specific data such
as time series. To solve the above problem, we utilize the
orientation-dependent tensor-tensor product from Tensor Singular Value
Decomposition based on *M-product (T-SVDM) and extend the one-dimensional
Sparse Principal Component Analysis (SPCA) to a tensor form. The proposed
sparse tensor PCA model can constrain sparsity at the specified mode and yield
sparse tensor principal components, enhancing flexibility and accuracy in
learning feature relations. To ensure fast convergence and a flexible
description of feature correlation, we develop a convex version specially
designed for general UFS tasks and propose an efficient slice-by-slice
algorithm that performs dual optimization in the transform domain. Experimental
results on real-world datasets demonstrate the effectiveness and remarkable
computational efficiency of the proposed method for tensor data of diverse
structures over the state-of-the-arts. With a proper combination of data
orientation and transform domain, our method is promising for various
applications. The codes related to our proposed methods and the experiments are
available at https://github.com/zjj20212035/STPCA.git.",2024-07-24,"Junjing Zheng, Xinyu Zhang, Weidong Jiang, Xiangfeng Qiu, Mingjian Ren",http://arxiv.org/pdf/2407.16985v2,cs.LG
scGHSOM: Hierarchical clustering and visualization of single-cell and CRISPR data using growing hierarchical SOM,"High-dimensional single-cell data poses significant challenges in identifying
underlying biological patterns due to the complexity and heterogeneity of
cellular states. We propose a comprehensive gene-cell dependency visualization
via unsupervised clustering, Growing Hierarchical Self-Organizing Map (GHSOM),
specifically designed for analyzing high-dimensional single-cell data like
single-cell sequencing and CRISPR screens. GHSOM is applied to cluster samples
in a hierarchical structure such that the self-growth structure of clusters
satisfies the required variations between and within. We propose a novel
Significant Attributes Identification Algorithm to identify features that
distinguish clusters. This algorithm pinpoints attributes with minimal
variation within a cluster but substantial variation between clusters. These
key attributes can then be used for targeted data retrieval and downstream
analysis. Furthermore, we present two innovative visualization tools: Cluster
Feature Map and Cluster Distribution Map. The Cluster Feature Map highlights
the distribution of specific features across the hierarchical structure of
GHSOM clusters. This allows for rapid visual assessment of cluster uniqueness
based on chosen features. The Cluster Distribution Map depicts leaf clusters as
circles on the GHSOM grid, with circle size reflecting cluster data size and
color customizable to visualize features like cell type or other attributes. We
apply our analysis to three single-cell datasets and one CRISPR dataset
(cell-gene database) and evaluate clustering methods with internal and external
CH and ARI scores. GHSOM performs well, being the best performer in internal
evaluation (CH=4.2). In external evaluation, GHSOM has the third-best
performance of all methods.",2024-07-24,"Shang-Jung Wen, Jia-Ming Chang, Fang Yu",http://arxiv.org/pdf/2407.16984v1,cs.LG
On the Parameter Identifiability of Partially Observed Linear Causal Models,"Linear causal models are important tools for modeling causal dependencies and
yet in practice, only a subset of the variables can be observed. In this paper,
we examine the parameter identifiability of these models by investigating
whether the edge coefficients can be recovered given the causal structure and
partially observed data. Our setting is more general than that of prior
research - we allow all variables, including both observed and latent ones, to
be flexibly related, and we consider the coefficients of all edges, whereas
most existing works focus only on the edges between observed variables.
Theoretically, we identify three types of indeterminacy for the parameters in
partially observed linear causal models. We then provide graphical conditions
that are sufficient for all parameters to be identifiable and show that some of
them are provably necessary. Methodologically, we propose a novel
likelihood-based parameter estimation method that addresses the variance
indeterminacy of latent variables in a specific way and can asymptotically
recover the underlying parameters up to trivial indeterminacy. Empirical
studies on both synthetic and real-world datasets validate our identifiability
theory and the effectiveness of the proposed method in the finite-sample
regime. Code: https://github.com/dongxinshuai/scm-identify.",2024-07-24,"Xinshuai Dong, Ignavier Ng, Biwei Huang, Yuewen Sun, Songyao Jin, Roberto Legaspi, Peter Spirtes, Kun Zhang",http://arxiv.org/pdf/2407.16975v2,cs.LG
Towards Aligning Language Models with Textual Feedback,"We present ALT (ALignment with Textual feedback), an approach that aligns
language models with user preferences expressed in text. We argue that text
offers greater expressiveness, enabling users to provide richer feedback than
simple comparative preferences and this richer feedback can lead to more
efficient and effective alignment. ALT aligns the model by conditioning its
generation on the textual feedback. Our method relies solely on language
modeling techniques and requires minimal hyper-parameter tuning, though it
still presents the main benefits of RL-based alignment algorithms and can
effectively learn from textual feedback. We explore the efficacy and efficiency
of textual feedback across different tasks such as toxicity reduction,
summarization, and dialog response generation. We find that ALT outperforms PPO
for the task of toxicity reduction while being able to match its performance on
summarization with only 20% of the samples. We also explore how ALT can be used
with feedback provided by an existing LLM where we explore an LLM providing
constrained and unconstrained textual feedback. We also outline future
directions to align models with natural language feedback.",2024-07-24,"Saüc Abadal Lloret, Shehzaad Dhuliawala, Keerthiram Murugesan, Mrinmaya Sachan",http://arxiv.org/pdf/2407.16970v3,cs.LG
Stochastic Variance-Reduced Iterative Hard Thresholding in Graph Sparsity Optimization,"Stochastic optimization algorithms are widely used for large-scale data
analysis due to their low per-iteration costs, but they often suffer from slow
asymptotic convergence caused by inherent variance. Variance-reduced techniques
have been therefore used to address this issue in structured sparse models
utilizing sparsity-inducing norms or $\ell_0$-norms. However, these techniques
are not directly applicable to complex (non-convex) graph sparsity models,
which are essential in applications like disease outbreak monitoring and social
network analysis. In this paper, we introduce two stochastic variance-reduced
gradient-based methods to solve graph sparsity optimization: GraphSVRG-IHT and
GraphSCSG-IHT. We provide a general framework for theoretical analysis,
demonstrating that our methods enjoy a linear convergence speed. Extensive
experiments validate",2024-07-24,"Derek Fox, Samuel Hernandez, Qianqian Tong",http://arxiv.org/pdf/2407.16968v1,cs.LG
When AI Defeats Password Deception! A Deep Learning Framework to Distinguish Passwords and Honeywords,"""Honeywords"" have emerged as a promising defense mechanism for detecting data
breaches and foiling offline dictionary attacks (ODA) by deceiving attackers
with false passwords. In this paper, we propose PassFilter, a novel deep
learning (DL) based attack framework, fundamental in its ability to identify
passwords from a set of sweetwords associated with a user account, effectively
challenging a variety of honeywords generation techniques (HGTs). The DL model
in PassFilter is trained with a set of previously collected or adversarially
generated passwords and honeywords, and carefully orchestrated to predict
whether a sweetword is the password or a honeyword. Our model can compromise
the security of state-of-the-art, heuristics-based, and representation
learning-based HGTs proposed by Dionysiou et al. Specifically, our analysis
with nine publicly available password datasets shows that PassFilter
significantly outperforms the baseline random guessing success rate of 5%,
achieving 6.10% to 52.78% on the 1st guessing attempt, considering 20
sweetwords per account. This success rate rapidly increases with additional
login attempts before account lock-outs, often allowed on many real-world
online services to maintain reasonable usability. For example, it ranges from
41.78% to 96.80% for five attempts, and from 72.87% to 99.00% for ten attempts,
compared to 25% and 50% random guessing, respectively. We also examined
PassFilter against general-purpose language models used for honeyword
generation, like those proposed by Yu et al. These honeywords also proved
vulnerable to our attack, with success rates of 14.19% for 1st guessing
attempt, increasing to 30.23%, 41.70%, and 63.10% after 3rd, 5th, and 10th
guessing attempts, respectively. Our findings demonstrate the effectiveness of
DL model deployed in PassFilter in breaching state-of-the-art HGTs and
compromising password security based on ODA.",2024-07-24,"Jimmy Dani, Brandon McCulloh, Nitesh Saxena",http://arxiv.org/pdf/2407.16964v1,cs.LG
Dynamic Graph Transformer with Correlated Spatial-Temporal Positional Encoding,"Learning effective representations for Continuous-Time Dynamic Graphs (CTDGs)
has garnered significant research interest, largely due to its powerful
capabilities in modeling complex interactions between nodes. A fundamental and
crucial requirement for representation learning in CTDGs is the appropriate
estimation and preservation of proximity. However, due to the sparse and
evolving characteristics of CTDGs, the spatial-temporal properties inherent in
high-order proximity remain largely unexplored. Despite its importance, this
property presents significant challenges due to the computationally intensive
nature of personalized interaction intensity estimation and the dynamic
attributes of CTDGs. To this end, we propose a novel Correlated
Spatial-Temporal Positional encoding that incorporates a parameter-free
personalized interaction intensity estimation under the weak assumption of the
Poisson Point Process. Building on this, we introduce the Dynamic Graph
Transformer with Correlated Spatial-Temporal Positional Encoding (CorDGT),
which efficiently retains the evolving spatial-temporal high-order proximity
for effective node representation learning in CTDGs. Extensive experiments on
seven small and two large-scale datasets demonstrate the superior performance
and scalability of the proposed CorDGT. The code is available at:
https://github.com/wangz3066/CorDGT.",2024-07-24,"Zhe Wang, Sheng Zhou, Jiawei Chen, Zhen Zhang, Binbin Hu, Yan Feng, Chun Chen, Can Wang",http://arxiv.org/pdf/2407.16959v2,cs.LG
Wonderful Matrices: More Efficient and Effective Architecture for Language Modeling Tasks,"We prove the availability of inner product form position encoding in the
state space dual algorithm and study the effectiveness of different position
embeddings in the hybrid quadratic causal self-attention and state space dual
algorithms. We propose inner function attention with dynamic mask, which can
improve the expressiveness of the attention algorithm and avoid the sequence
noise significantly affecting the accuracy of the attention score. We also
design cross domain mixture of experts, which can improve the granularity of
the sparse activation feedforward network while maintaining the efficiency of
parameter utilization and retrieval. The combination of these methods
constitutes our foundation model architecture: Wonderful Matrices. We conduct
experiments on the language modeling task and find that Wonderful Matrices are
more efficient and effective in handling complex language tasks.",2024-07-24,"Jingze Shi, Bingheng Wu, Lu He, Luchang Jiang",http://arxiv.org/pdf/2407.16958v6,cs.LG
Online Social Network Data-Driven Early Detection on Short-Form Video Addiction,"Short-form video (SFV) has become a globally popular form of entertainment in
recent years, appearing on major social media platforms. However, current
research indicate that short video addiction can lead to numerous negative
effects on both physical and psychological health, such as decreased attention
span and reduced motivation to learn. Additionally, Short-form Video Addiction
(SFVA) has been linked to other issues such as a lack of psychological support
in real life, family or academic pressure, and social anxiety. Currently, the
detection of SFVA typically occurs only after users experience negative
consequences. Therefore, we aim to construct a short video addiction dataset
based on social network behavior and design an early detection framework for
SFVA. Previous mental health detection research on online social media has
mostly focused on detecting depression and suicidal tendency. In this study, we
propose the first early detection framework for SFVA EarlySD. We first
introduce large language models (LLMs) to address the common issues of sparsity
and missing data in graph datasets. Meanwhile, we categorize social network
behavior data into different modalities and design a heterogeneous social
network structure as the primary basis for detecting SFVA. We conduct a series
of quantitative analysis on short video addicts using our self-constructed
dataset, and perform extensive experiments to validate the effectiveness of our
method EarlySD, using social data and heterogeneous social graphs in the
detection of short video addiction.",2024-07-24,Fang-Yu Kuo,http://arxiv.org/pdf/2407.18277v1,cs.LG
Towards Transfer Unlearning: Empirical Evidence of Cross-Domain Bias Mitigation,"Large language models (LLMs) often inherit biases from vast amounts of
training corpora. Traditional debiasing methods, while effective to some
extent, do not completely eliminate memorized biases and toxicity in LLMs. In
this paper, we study an unlearning-based approach to debiasing in LLMs by
performing gradient ascent on hate speech against minority groups, i.e.,
minimizing the likelihood of biased or toxic content. Specifically, we propose
a mask language modeling unlearning technique, which unlearns the harmful part
of the text. This method enables LLMs to selectively forget and disassociate
from biased and harmful content. Experimental results demonstrate the
effectiveness of our approach in diminishing bias while maintaining the
language modeling abilities. Surprisingly, the results also unveil an
unexpected potential for cross-domain transfer unlearning: debiasing in one
bias form (e.g. gender) may contribute to mitigating others (e.g. race and
religion).",2024-07-24,"Huimin Lu, Masaru Isonuma, Junichiro Mori, Ichiro Sakata",http://arxiv.org/pdf/2407.16951v1,cs.LG
Adaptive Gradient Regularization: A Faster and Generalizable Optimization Technique for Deep Neural Networks,"Stochastic optimization plays a crucial role in the advancement of deep
learning technologies. Over the decades, significant effort has been dedicated
to improving the training efficiency and robustness of deep neural networks,
via various strategies including gradient normalization (GN) and gradient
centralization (GC). Nevertheless, to the best of our knowledge, no one has
considered to capture the optimal gradient descent trajectory, by adaptively
controlling gradient descent direction. To address this concern, this paper is
the first attempt to study a new optimization technique for deep neural
networks, using the sum normalization of a gradient vector as coefficients, to
dynamically regularize gradients and thus to effectively control optimization
direction. The proposed technique is hence named as the adaptive gradient
regularization (AGR). It can be viewed as an adaptive gradient clipping method.
The theoretical analysis reveals that the AGR can effectively smooth the loss
landscape, and hence can significantly improve the training efficiency and
model generalization performance. We note that AGR can greatly improve the
training efficiency of vanilla optimizers' including Adan and AdamW, by adding
only three lines of code. The final experiments conducted on image generation,
image classification, and language representation, demonstrate that the AGR
method can not only improve the training efficiency but also enhance the model
generalization performance.",2024-07-24,"Huixiu Jiang, Ling Yang, Yu Bao, Rutong Si, Sikun Yang",http://arxiv.org/pdf/2407.16944v4,cs.LG
GV-Rep: A Large-Scale Dataset for Genetic Variant Representation Learning,"Genetic variants (GVs) are defined as differences in the DNA sequences among
individuals and play a crucial role in diagnosing and treating genetic
diseases. The rapid decrease in next generation sequencing cost has led to an
exponential increase in patient-level GV data. This growth poses a challenge
for clinicians who must efficiently prioritize patient-specific GVs and
integrate them with existing genomic databases to inform patient management. To
addressing the interpretation of GVs, genomic foundation models (GFMs) have
emerged. However, these models lack standardized performance assessments,
leading to considerable variability in model evaluations. This poses the
question: How effectively do deep learning methods classify unknown GVs and
align them with clinically-verified GVs? We argue that representation learning,
which transforms raw data into meaningful feature spaces, is an effective
approach for addressing both indexing and classification challenges. We
introduce a large-scale Genetic Variant dataset, named GV-Rep, featuring
variable-length contexts and detailed annotations, designed for deep learning
models to learn GV representations across various traits, diseases, tissue
types, and experimental contexts. Our contributions are three-fold: (i)
Construction of a comprehensive dataset with 7 million records, each labeled
with characteristics of the corresponding variants, alongside additional data
from 17,548 gene knockout tests across 1,107 cell types, 1,808 variant
combinations, and 156 unique clinically verified GVs from real-world patients.
(ii) Analysis of the structure and properties of the dataset. (iii)
Experimentation of the dataset with pre-trained GFMs. The results show a
significant gap between GFMs current capabilities and accurate GV
representation. We hope this dataset will help advance genomic deep learning to
bridge this gap.",2024-07-24,"Zehui Li, Vallijah Subasri, Guy-Bart Stan, Yiren Zhao, Bo Wang",http://arxiv.org/pdf/2407.16940v2,cs.LG
Synthetic Trajectory Generation Through Convolutional Neural Networks,"Location trajectories provide valuable insights for applications from urban
planning to pandemic control. However, mobility data can also reveal sensitive
information about individuals, such as political opinions, religious beliefs,
or sexual orientations. Existing privacy-preserving approaches for publishing
this data face a significant utility-privacy trade-off. Releasing synthetic
trajectory data generated through deep learning offers a promising solution.
Due to the trajectories' sequential nature, most existing models are based on
recurrent neural networks (RNNs). However, research in generative adversarial
networks (GANs) largely employs convolutional neural networks (CNNs) for image
generation. This discrepancy raises the question of whether advances in
computer vision can be applied to trajectory generation. In this work, we
introduce a Reversible Trajectory-to-CNN Transformation (RTCT) that adapts
trajectories into a format suitable for CNN-based models. We integrated this
transformation with the well-known DCGAN in a proof-of-concept (PoC) and
evaluated its performance against an RNN-based trajectory GAN using four
metrics across two datasets. The PoC was superior in capturing spatial
distributions compared to the RNN model but had difficulty replicating
sequential and temporal properties. Although the PoC's utility is not
sufficient for practical applications, the results demonstrate the
transformation's potential to facilitate the use of CNNs for trajectory
generation, opening up avenues for future research. To support continued
research, all source code has been made available under an open-source license.",2024-07-24,"Jesse Merhi, Erik Buchholz, Salil S. Kanhere",http://arxiv.org/pdf/2407.16938v1,cs.LG
Provable Benefit of Annealed Langevin Monte Carlo for Non-log-concave Sampling,"We consider the outstanding problem of sampling from an unnormalized density
that may be non-log-concave and multimodal. To enhance the performance of
simple Markov chain Monte Carlo (MCMC) methods, techniques of annealing type
have been widely used. However, quantitative theoretical guarantees of these
techniques are under-explored. This study takes a first step toward providing a
non-asymptotic analysis of annealed MCMC. Specifically, we establish, for the
first time, an oracle complexity of $\widetilde{O}\left(\frac{d\beta^2{\cal
A}^2}{\varepsilon^6}\right)$ for the simple annealed Langevin Monte Carlo
algorithm to achieve $\varepsilon^2$ accuracy in Kullback-Leibler divergence to
the target distribution $\pi\propto{\rm e}^{-V}$ on $\mathbb{R}^d$ with
$\beta$-smooth potential $V$. Here, ${\cal A}$ represents the action of a curve
of probability measures interpolating the target distribution $\pi$ and a
readily sampleable distribution.",2024-07-24,"Wei Guo, Molei Tao, Yongxin Chen",http://arxiv.org/pdf/2407.16936v2,cs.LG
Federated Automatic Latent Variable Selection in Multi-output Gaussian Processes,"This paper explores a federated learning approach that automatically selects
the number of latent processes in multi-output Gaussian processes (MGPs). The
MGP has seen great success as a transfer learning tool when data is generated
from multiple sources/units/entities. A common approach in MGPs to transfer
knowledge across units involves gathering all data from each unit to a central
server and extracting common independent latent processes to express each unit
as a linear combination of the shared latent patterns. However, this approach
poses key challenges in (i) determining the adequate number of latent processes
and (ii) relying on centralized learning which leads to potential privacy risks
and significant computational burdens on the central server. To address these
issues, we propose a hierarchical model that places spike-and-slab priors on
the coefficients of each latent process. These priors help automatically select
only needed latent processes by shrinking the coefficients of unnecessary ones
to zero. To estimate the model while avoiding the drawbacks of centralized
learning, we propose a variational inference-based approach, that formulates
model inference as an optimization problem compatible with federated settings.
We then design a federated learning algorithm that allows units to jointly
select and infer the common latent processes without sharing their data. We
also discuss an efficient learning approach for a new unit within our proposed
federated framework. Simulation and case studies on Li-ion battery degradation
and air temperature data demonstrate the advantageous features of our proposed
approach.",2024-07-24,"Jingyi Gao, Seokhyun Chung",http://arxiv.org/pdf/2407.16935v1,cs.LG
Deep Koopman-based Control of Quality Variation in Multistage Manufacturing Systems,"This paper presents a modeling-control synthesis to address the quality
control challenges in multistage manufacturing systems (MMSs). A new
feedforward control scheme is developed to minimize the quality variations
caused by process disturbances in MMSs. Notably, the control framework
leverages a stochastic deep Koopman (SDK) model to capture the quality
propagation mechanism in the MMSs, highlighted by its ability to transform the
nonlinear propagation dynamics into a linear one. Two roll-to-roll case studies
are presented to validate the proposed method and demonstrate its
effectiveness. The overall method is suitable for nonlinear MMSs and does not
require extensive expert knowledge.",2024-07-24,"Zhiyi Chen, Harshal Maske, Devesh Upadhyay, Huanyi Shui, Xun Huan, Jun Ni",http://arxiv.org/pdf/2407.16933v1,cs.LG
DeepCell: A Ubiquitous Accurate Provider-side Cellular-based Localization,"Although outdoor localization is already available to the general public and
businesses through the wide spread use of the GPS, it is not supported by
low-end phones, requires a direct line of sight to satellites and can drain
phone battery quickly. The current fingerprinting solutions can provide
high-accuracy localization but are based on the client side. This limits their
ubiquitous deployment and accuracy. In this paper, we introduce DeepCell: a
provider-side fingerprinting localization system that can provide high accuracy
localization for any cell phone. To build its fingerprint, DeepCell leverages
the unlabeled cellular measurements recorded by the cellular provider while
opportunistically synchronizing with selected client devices to get location
labels. The fingerprint is then used to train a deep neural network model that
is harnessed for localization. To achieve this goal, DeepCell need to address a
number of challenges including using unlabeled data from the provider side,
handling noise and sparsity, scaling the data to large areas, and finally
providing enough data that is required for training deep models without
overhead. Evaluation of DeepCell in a typical realistic environment shows that
it can achieve a consistent median accuracy of 29m. This accuracy outperforms
the state-of-the-art client-based cellular-based systems by more than 75.4%. In
addition, the same accuracy is extended to low-end phones.",2024-07-24,"Ahmed Shokry, Moustafa Youssef",http://arxiv.org/pdf/2407.16927v1,cs.LG
Handling Device Heterogeneity for Deep Learning-based Localization,"Deep learning-based fingerprinting is one of the current promising
technologies for outdoor localization in cellular networks. However, deploying
such localization systems for heterogeneous phones affects their accuracy as
the cellular received signal strength (RSS) readings vary for different types
of phones. In this paper, we introduce a number of techniques for addressing
the phones heterogeneity problem in the deep-learning based localization
systems. The basic idea is either to approximate a function that maps the
cellular RSS measurements between different devices or to transfer the
knowledge across them.
  Evaluation of the proposed techniques using different Android phones on four
independent testbeds shows that our techniques can improve the localization
accuracy by more than 220% for the four testbeds as compared to the
state-of-the-art systems. This highlights the promise of the proposed device
heterogeneity handling techniques for enabling a wide deployment of deep
learning-based localization systems over different devices.",2024-07-24,"Ahmed Shokry, Moustafa Youssef",http://arxiv.org/pdf/2407.16923v1,cs.LG
"TelescopeML -- I. An End-to-End Python Package for Interpreting Telescope Datasets through Training Machine Learning Models, Generating Statistical Reports, and Visualizing Results","We are on the verge of a revolutionary era in space exploration, thanks to
advancements in telescopes such as the James Webb Space Telescope
(\textit{JWST}). High-resolution, high signal-to-noise spectra from exoplanet
and brown dwarf atmospheres have been collected over the past few decades,
requiring the development of accurate and reliable pipelines and tools for
their analysis. Accurately and swiftly determining the spectroscopic parameters
from the observational spectra of these objects is crucial for understanding
their atmospheric composition and guiding future follow-up observations.
\texttt{TelescopeML} is a Python package developed to perform three main tasks:
1. Process the synthetic astronomical datasets for training a CNN model and
prepare the observational dataset for later use for prediction; 2. Train a CNN
model by implementing the optimal hyperparameters; and 3. Deploy the trained
CNN models on the actual observational data to derive the output spectroscopic
parameters.",2024-07-24,"Ehsan, Gharib-Nezhad, Natasha E. Batalha, Hamed Valizadegan, Miguel J. S. Martinho, Mahdi Habibi, Gopal Nookula",http://arxiv.org/pdf/2407.16917v1,cs.LG
Cross-Domain Policy Transfer by Representation Alignment via Multi-Domain Behavioral Cloning,"Transferring learned skills across diverse situations remains a fundamental
challenge for autonomous agents, particularly when agents are not allowed to
interact with an exact target setup. While prior approaches have predominantly
focused on learning domain translation, they often struggle with handling
significant domain gaps or out-of-distribution tasks. In this paper, we present
a simple approach for cross-domain policy transfer that learns a shared latent
representation across domains and a common abstract policy on top of it. Our
approach leverages multi-domain behavioral cloning on unaligned trajectories of
proxy tasks and employs maximum mean discrepancy (MMD) as a regularization term
to encourage cross-domain alignment. The MMD regularization better preserves
structures of latent state distributions than commonly used
domain-discriminative distribution matching, leading to higher transfer
performance. Moreover, our approach involves training only one multi-domain
policy, which makes extension easier than existing methods. Empirical
evaluations demonstrate the efficacy of our method across various domain
shifts, especially in scenarios where exact domain translation is challenging,
such as cross-morphology or cross-viewpoint settings. Our ablation studies
further reveal that multi-domain behavioral cloning implicitly contributes to
representation alignment alongside domain-adversarial regularization.",2024-07-24,"Hayato Watahiki, Ryo Iwase, Ryosuke Unno, Yoshimasa Tsuruoka",http://arxiv.org/pdf/2407.16912v1,cs.LG
Generation Constraint Scaling Can Mitigate Hallucination,"Addressing the issue of hallucinations in large language models (LLMs) is a
critical challenge. As the cognitive mechanisms of hallucination have been
related to memory, here we explore hallucination for LLM that is enabled with
explicit memory mechanisms. We empirically demonstrate that by simply scaling
the readout vector that constrains generation in a memory-augmented LLM
decoder, hallucination mitigation can be achieved in a training-free manner.
Our method is geometry-inspired and outperforms a state-of-the-art LLM editing
method on the task of generation of Wikipedia-like biography entries both in
terms of generation quality and runtime complexity.",2024-07-23,"Georgios Kollias, Payel Das, Subhajit Chaudhury",http://arxiv.org/pdf/2407.16908v1,cs.LG
ScaleLLM: A Resource-Frugal LLM Serving Framework by Optimizing End-to-End Efficiency,"Large language models (LLMs) have surged in popularity and are extensively
used in commercial applications, where the efficiency of model serving is
crucial for the user experience. Most current research focuses on optimizing
individual sub-procedures, e.g. local inference and communication, however,
there is no comprehensive framework that provides a holistic system view for
optimizing LLM serving in an end-to-end manner. In this work, we conduct a
detailed analysis to identify major bottlenecks that impact end-to-end latency
in LLM serving systems. Our analysis reveals that a comprehensive LLM serving
endpoint must address a series of efficiency bottlenecks that extend beyond LLM
inference. We then propose ScaleLLM, an optimized system for resource-efficient
LLM serving. Our extensive experiments reveal that with 64 concurrent requests,
ScaleLLM achieves a 4.3x speed up over vLLM and outperforms state-of-the-arts
with 1.5x higher throughput.",2024-07-23,"Yuhang Yao, Han Jin, Alay Dilipbhai Shah, Shanshan Han, Zijian Hu, Yide Ran, Dimitris Stripelis, Zhaozhuo Xu, Salman Avestimehr, Chaoyang He",http://arxiv.org/pdf/2408.00008v2,cs.LG
Neural Network-Based Bandit: A Medium Access Control for the IIoT Alarm Scenario,"Efficient Random Access (RA) is critical for enabling reliable communication
in Industrial Internet of Things (IIoT) networks. Herein, we propose a deep
reinforcement learning based distributed RA scheme, entitled Neural
Network-Based Bandit (NNBB), for the IIoT alarm scenario. In such a scenario,
the devices may detect a common critical event, and the goal is to ensure the
alarm information is delivered successfully from at least one device. The
proposed NNBB scheme is implemented at each device, where it trains itself
online and establishes implicit inter-device coordination to achieve the common
goal. Devices can transmit simultaneously on multiple orthogonal channels and
each possible transmission pattern constitutes a possible action for the NNBB,
which uses a deep neural network to determine the action. Our simulation
results show that as the number of devices in the network increases, so does
the performance gain of the NNBB compared to the Multi-Armed Bandit (MAB) RA
benchmark. For instance, NNBB experiences a 7% success rate drop when there are
four channels and the number of devices increases from 10 to 60, while MAB
faces a 25% drop.",2024-07-23,"Prasoon Raghuwanshi, Onel Luis Alcaraz López, Neelesh B. Mehta, Hirley Alves, Matti Latva-aho",http://arxiv.org/pdf/2407.16877v2,cs.LG
How Can Deep Neural Networks Fail Even With Global Optima?,"Fully connected deep neural networks are successfully applied to
classification and function approximation problems. By minimizing the cost
function, i.e., finding the proper weights and biases, models can be built for
accurate predictions. The ideal optimization process can achieve global optima.
However, do global optima always perform well? If not, how bad can it be? In
this work, we aim to: 1) extend the expressive power of shallow neural networks
to networks of any depth using a simple trick, 2) construct extremely
overfitting deep neural networks that, despite having global optima, still fail
to perform well on classification and function approximation problems.
Different types of activation functions are considered, including ReLU,
Parametric ReLU, and Sigmoid functions. Extensive theoretical analysis has been
conducted, ranging from one-dimensional models to models of any dimensionality.
Numerical results illustrate our theoretical findings.",2024-07-23,Qingguang Guan,http://arxiv.org/pdf/2407.16872v1,cs.LG
Trust Your Gut: Comparing Human and Machine Inference from Noisy Visualizations,"People commonly utilize visualizations not only to examine a given dataset,
but also to draw generalizable conclusions about the underlying models or
phenomena. Prior research has compared human visual inference to that of an
optimal Bayesian agent, with deviations from rational analysis viewed as
problematic. However, human reliance on non-normative heuristics may prove
advantageous in certain circumstances. We investigate scenarios where human
intuition might surpass idealized statistical rationality. In two experiments,
we examine individuals' accuracy in characterizing the parameters of known
data-generating models from bivariate visualizations. Our findings indicate
that, although participants generally exhibited lower accuracy compared to
statistical models, they frequently outperformed Bayesian agents, particularly
when faced with extreme samples. Participants appeared to rely on their
internal models to filter out noisy visualizations, thus improving their
resilience against spurious data. However, participants displayed
overconfidence and struggled with uncertainty estimation. They also exhibited
higher variance than statistical machines. Our findings suggest that analyst
gut reactions to visualizations may provide an advantage, even when departing
from rationality. These results carry implications for designing visual
analytics tools, offering new perspectives on how to integrate statistical
models and analyst intuition for improved inference and decision-making. The
data and materials for this paper are available at https://osf.io/qmfv6",2024-07-23,"Ratanond Koonchanok, Michael E. Papka, Khairi Reda",http://arxiv.org/pdf/2407.16871v1,cs.LG
From Text to Insight: Large Language Models for Materials Science Data Extraction,"The vast majority of materials science knowledge exists in unstructured
natural language, yet structured data is crucial for innovative and systematic
materials design. Traditionally, the field has relied on manual curation and
partial automation for data extraction for specific use cases. The advent of
large language models (LLMs) represents a significant shift, potentially
enabling efficient extraction of structured, actionable data from unstructured
text by non-experts. While applying LLMs to materials science data extraction
presents unique challenges, domain knowledge offers opportunities to guide and
validate LLM outputs. This review provides a comprehensive overview of
LLM-based structured data extraction in materials science, synthesizing current
knowledge and outlining future directions. We address the lack of standardized
guidelines and present frameworks for leveraging the synergy between LLMs and
materials science expertise. This work serves as a foundational resource for
researchers aiming to harness LLMs for data-driven materials research. The
insights presented here could significantly enhance how researchers across
disciplines access and utilize scientific information, potentially accelerating
the development of novel materials for critical societal needs.",2024-07-23,"Mara Schilling-Wilhelmi, Martiño Ríos-García, Sherjeel Shabih, María Victoria Gil, Santiago Miret, Christoph T. Koch, José A. Márquez, Kevin Maik Jablonka",http://arxiv.org/pdf/2407.16867v2,cs.LG
Balanced Multi-Relational Graph Clustering,"Multi-relational graph clustering has demonstrated remarkable success in
uncovering underlying patterns in complex networks. Representative methods
manage to align different views motivated by advances in contrastive learning.
Our empirical study finds the pervasive presence of imbalance in real-world
graphs, which is in principle contradictory to the motivation of alignment. In
this paper, we first propose a novel metric, the Aggregation Class Distance, to
empirically quantify structural disparities among different graphs. To address
the challenge of view imbalance, we propose Balanced Multi-Relational Graph
Clustering (BMGC), comprising unsupervised dominant view mining and dual
signals guided representation learning. It dynamically mines the dominant view
throughout the training process, synergistically improving clustering
performance with representation learning. Theoretical analysis ensures the
effectiveness of dominant view mining. Extensive experiments and in-depth
analysis on real-world and synthetic datasets showcase that BMGC achieves
state-of-the-art performance, underscoring its superiority in addressing the
view imbalance inherent in multi-relational graphs. The source code and
datasets are available at https://github.com/zxlearningdeep/BMGC.",2024-07-23,"Zhixiang Shen, Haolan He, Zhao Kang",http://arxiv.org/pdf/2407.16863v1,cs.LG
SECRM-2D: RL-Based Efficient and Comfortable Route-Following Autonomous Driving with Analytic Safety Guarantees,"Over the last decade, there has been increasing interest in autonomous
driving systems. Reinforcement Learning (RL) shows great promise for training
autonomous driving controllers, being able to directly optimize a combination
of criteria such as efficiency comfort, and stability. However, RL- based
controllers typically offer no safety guarantees, making their readiness for
real deployment questionable. In this paper, we propose SECRM-2D (the Safe,
Efficient and Comfortable RL- based driving Model with Lane-Changing), an RL
autonomous driving controller (both longitudinal and lateral) that balances
optimization of efficiency and comfort and follows a fixed route, while being
subject to hard analytic safety constraints. The aforementioned safety
constraints are derived from the criterion that the follower vehicle must have
sufficient headway to be able to avoid a crash if the leader vehicle brakes
suddenly. We evaluate SECRM-2D against several learning and non-learning
baselines in simulated test scenarios, including freeway driving, exiting,
merging, and emergency braking. Our results confirm that representative
previously-published RL AV controllers may crash in both training and testing,
even if they are optimizing a safety objective. By contrast, our controller
SECRM-2D is successful in avoiding crashes during both training and testing,
improves over the baselines in measures of efficiency and comfort, and is more
faithful in following the prescribed route. In addition, we achieve a good
theoretical understanding of the longitudinal steady-state of a collection of
SECRM-2D vehicles.",2024-07-23,"Tianyu Shi, Ilia Smirnov, Omar ElSamadisy, Baher Abdulhai",http://arxiv.org/pdf/2407.16857v1,cs.LG
SPLAT: A framework for optimised GPU code-generation for SParse reguLar ATtention,"Multi-head-self-attention (MHSA) mechanisms achieve state-of-the-art (SOTA)
performance across natural language processing and vision tasks. However, their
quadratic dependence on sequence lengths has bottlenecked inference speeds. To
circumvent this bottleneck, researchers have proposed various sparse-MHSA
models, where a subset of full attention is computed. Despite their promise,
current sparse libraries and compilers do not support high-performance
implementations for diverse sparse-MHSA patterns due to the underlying sparse
formats they operate on. These formats, which are typically designed for
high-performance & scientific computing applications, are either curated for
extreme amounts of random sparsity (<1% non-zero values), or specific sparsity
patterns. However, the sparsity patterns in sparse-MHSA are moderately sparse
(10-50% non-zero values) and varied, resulting in existing sparse-formats
trading off generality for performance.
  We bridge this gap, achieving both generality and performance, by proposing a
novel sparse format: affine-compressed-sparse-row (ACSR) and supporting
code-generation scheme, SPLAT, that generates high-performance implementations
for diverse sparse-MHSA patterns on GPUs. Core to our proposed format and code
generation algorithm is the observation that common sparse-MHSA patterns have
uniquely regular geometric properties. These properties, which can be analyzed
just-in-time, expose novel optimizations and tiling strategies that SPLAT
exploits to generate high-performance implementations for diverse patterns. To
demonstrate SPLAT's efficacy, we use it to generate code for various
sparse-MHSA models, achieving geomean speedups of 2.05x and 4.05x over
hand-written kernels written in triton and TVM respectively on A100 GPUs.
Moreover, its interfaces are intuitive and easy to use with existing
implementations of MHSA in JAX.",2024-07-23,"Ahan Gupta, Yueming Yuan, Devansh Jain, Yuhao Ge, David Aponte, Yanqi Zhou, Charith Mendis",http://arxiv.org/pdf/2407.16847v1,cs.LG
A Multi-Level Hierarchical Framework for the Classification of Weather Conditions and Hazard Prediction,"This paper presents a multilevel hierarchical framework for the
classification of weather conditions and hazard prediction. In recent years,
the importance of data has grown significantly, with various types like text,
numbers, images, audio, and videos playing a key role. Among these, images make
up a large portion of the data available. This application shows promise for
various purposes, especially when combined with decision support systems for
traffic management, afforestation, and weather forecasting. It's particularly
useful in situations where traditional weather predictions are not very
accurate, such as ensuring the safe operation of self driving cars in dangerous
weather. While previous studies have looked at this topic with fewer
categories, this paper focuses on eleven specific types of weather images. The
goal is to create a model that can accurately predict weather conditions after
being trained on a large dataset of images. Accuracy is crucial in real-life
situations to prevent accidents, making it the top priority for this paper.
This work lays the groundwork for future applications in weather prediction,
especially in situations where human expertise is not available or may be
biased. The framework, capable of classifying images into eleven weather
categories: dew, frost, glaze, rime, snow, hail, rain, lightning, rainbow, and
sandstorm, provides real-time weather information with an accuracy of 0.9329.
The proposed framework addresses the growing need for accurate weather
classification and hazard prediction, offering a robust solution for various
applications in the field.",2024-07-23,Harish Neelam,http://arxiv.org/pdf/2407.16834v1,cs.LG
Retrieval Augmented Generation or Long-Context LLMs? A Comprehensive Study and Hybrid Approach,"Retrieval Augmented Generation (RAG) has been a powerful tool for Large
Language Models (LLMs) to efficiently process overly lengthy contexts. However,
recent LLMs like Gemini-1.5 and GPT-4 show exceptional capabilities to
understand long contexts directly. We conduct a comprehensive comparison
between RAG and long-context (LC) LLMs, aiming to leverage the strengths of
both. We benchmark RAG and LC across various public datasets using three latest
LLMs. Results reveal that when resourced sufficiently, LC consistently
outperforms RAG in terms of average performance. However, RAG's significantly
lower cost remains a distinct advantage. Based on this observation, we propose
Self-Route, a simple yet effective method that routes queries to RAG or LC
based on model self-reflection. Self-Route significantly reduces the
computation cost while maintaining a comparable performance to LC. Our findings
provide a guideline for long-context applications of LLMs using RAG and LC.",2024-07-23,"Zhuowan Li, Cheng Li, Mingyang Zhang, Qiaozhu Mei, Michael Bendersky",http://arxiv.org/pdf/2407.16833v2,cs.LG
Pareto Front Approximation for Multi-Objective Session-Based Recommender Systems,"This work introduces MultiTRON, an approach that adapts Pareto front
approximation techniques to multi-objective session-based recommender systems
using a transformer neural network. Our approach optimizes trade-offs between
key metrics such as click-through and conversion rates by training on sampled
preference vectors. A significant advantage is that after training, a single
model can access the entire Pareto front, allowing it to be tailored to meet
the specific requirements of different stakeholders by adjusting an additional
input vector that weights the objectives. We validate the model's performance
through extensive offline and online evaluation. For broader application and
research, the source code is made available at
https://github.com/otto-de/MultiTRON. The results confirm the model's ability
to manage multiple recommendation objectives effectively, offering a flexible
tool for diverse business needs.",2024-07-23,"Timo Wilm, Philipp Normann, Felix Stepprath",http://arxiv.org/pdf/2407.16828v3,cs.LG
In Search for Architectures and Loss Functions in Multi-Objective Reinforcement Learning,"Multi-objective reinforcement learning (MORL) is essential for addressing the
intricacies of real-world RL problems, which often require trade-offs between
multiple utility functions. However, MORL is challenging due to unstable
learning dynamics with deep learning-based function approximators. The research
path most taken has been to explore different value-based loss functions for
MORL to overcome this issue. Our work empirically explores model-free policy
learning loss functions and the impact of different architectural choices. We
introduce two different approaches: Multi-objective Proximal Policy
Optimization (MOPPO), which extends PPO to MORL, and Multi-objective Advantage
Actor Critic (MOA2C), which acts as a simple baseline in our ablations. Our
proposed approach is straightforward to implement, requiring only small
modifications at the level of function approximator. We conduct comprehensive
evaluations on the MORL Deep Sea Treasure, Minecart, and Reacher environments
and show that MOPPO effectively captures the Pareto front. Our extensive
ablation studies and empirical analyses reveal the impact of different
architectural choices, underscoring the robustness and versatility of MOPPO
compared to popular MORL approaches like Pareto Conditioned Networks (PCN) and
Envelope Q-learning in terms of MORL metrics, including hypervolume and
expected utility.",2024-07-23,"Mikhail Terekhov, Caglar Gulcehre",http://arxiv.org/pdf/2407.16807v1,cs.LG
"Multimodal Machine Learning in Mental Health: A Survey of Data, Algorithms, and Challenges","The application of machine learning (ML) in detecting, diagnosing, and
treating mental health disorders is garnering increasing attention.
Traditionally, research has focused on single modalities, such as text from
clinical notes, audio from speech samples, or video of interaction patterns.
Recently, multimodal ML, which combines information from multiple modalities,
has demonstrated significant promise in offering novel insights into human
behavior patterns and recognizing mental health symptoms and risk factors.
Despite its potential, multimodal ML in mental health remains an emerging
field, facing several complex challenges before practical applications can be
effectively developed. This survey provides a comprehensive overview of the
data availability and current state-of-the-art multimodal ML applications for
mental health. It discusses key challenges that must be addressed to advance
the field. The insights from this survey aim to deepen the understanding of the
potential and limitations of multimodal ML in mental health, guiding future
research and development in this evolving domain.",2024-07-23,"Zahraa Al Sahili, Ioannis Patras, Matthew Purver",http://arxiv.org/pdf/2407.16804v1,cs.LG
C3T: Cross-modal Transfer Through Time for Human Action Recognition,"In order to unlock the potential of diverse sensors, we investigate a method
to transfer knowledge between modalities using the structure of a unified
multimodal representation space for Human Action Recognition (HAR). We
formalize and explore an understudied cross-modal transfer setting we term
Unsupervised Modality Adaptation (UMA), where the modality used in testing is
not used in supervised training, i.e. zero labeled instances of the test
modality are available during training. We develop three methods to perform
UMA: Student-Teacher (ST), Contrastive Alignment (CA), and Cross-modal Transfer
Through Time (C3T). Our extensive experiments on various camera+IMU datasets
compare these methods to each other in the UMA setting, and to their empirical
upper bound in the supervised setting. The results indicate C3T is the most
robust and highest performing by at least a margin of 8%, and nears the
supervised setting performance even in the presence of temporal noise. This
method introduces a novel mechanism for aligning signals across time-varying
latent vectors, extracted from the receptive field of temporal convolutions.
Our findings suggest that C3T has significant potential for developing
generalizable models for time-series sensor data, opening new avenues for
multi-modal learning in various applications.",2024-07-23,"Abhi Kamboj, Anh Duy Nguyen, Minh Do",http://arxiv.org/pdf/2407.16803v2,cs.LG
Distribution-Aware Robust Learning from Long-Tailed Data with Noisy Labels,"Deep neural networks have demonstrated remarkable advancements in various
fields using large, well-annotated datasets. However, real-world data often
exhibit long-tailed distributions and label noise, significantly degrading
generalization performance. Recent studies addressing these issues have focused
on noisy sample selection methods that estimate the centroid of each class
based on high-confidence samples within each target class. The performance of
these methods is limited because they use only the training samples within each
class for class centroid estimation, making the quality of centroids
susceptible to long-tailed distributions and noisy labels. In this study, we
present a robust training framework called Distribution-aware Sample Selection
and Contrastive Learning (DaSC). Specifically, DaSC introduces a
Distribution-aware Class Centroid Estimation (DaCC) to generate enhanced class
centroids. DaCC performs weighted averaging of the features from all samples,
with weights determined based on model predictions. Additionally, we propose a
confidence-aware contrastive learning strategy to obtain balanced and robust
representations. The training samples are categorized into high-confidence and
low-confidence samples. Our method then applies Semi-supervised Balanced
Contrastive Loss (SBCL) using high-confidence samples, leveraging reliable
label information to mitigate class bias. For the low-confidence samples, our
method computes Mixup-enhanced Instance Discrimination Loss (MIDL) to improve
their representations in a self-supervised manner. Our experimental results on
CIFAR and real-world noisy-label datasets demonstrate the superior performance
of the proposed DaSC compared to previous approaches.",2024-07-23,"Jae Soon Baik, In Young Yoon, Kun Hoon Kim, Jun Won Choi",http://arxiv.org/pdf/2407.16802v1,cs.LG
Wasserstein Distributionally Robust Shallow Convex Neural Networks,"In this work, we propose Wasserstein distributionally robust shallow convex
neural networks (WaDiRo-SCNNs) to provide reliable nonlinear predictions when
subject to adverse and corrupted datasets. Our approach is based on a new
convex training program for $\ReLU$-based shallow neural networks which allows
us to cast the problem as an exact, tractable reformulation of its order-1
Wasserstein distributionally robust counterpart. Our training procedure is
conservative, has low stochasticity, is solvable with open-source solvers, and
is scalable to large industrial deployments. We provide out-of-sample
performance guarantees, show that hard convex physical constraints can be
enforced in the training program, and propose a mixed-integer convex
post-training verification program to evaluate model stability. WaDiRo-SCNN
aims to make neural networks safer for critical applications, such as in the
energy sector. Finally, we numerically demonstrate the performance of our model
on a synthetic experiment, a real-world power system application, i.e., the
prediction of non-residential buildings' hourly energy consumption in the
context of virtual power plants, and on benchmark datasets. The experimental
results are convincing and showcase the strengths of the proposed model.",2024-07-23,"Julien Pallage, Antoine Lesage-Landry",http://arxiv.org/pdf/2407.16800v2,cs.LG
What Matters in Range View 3D Object Detection,"Lidar-based perception pipelines rely on 3D object detection models to
interpret complex scenes. While multiple representations for lidar exist, the
range-view is enticing since it losslessly encodes the entire lidar sensor
output. In this work, we achieve state-of-the-art amongst range-view 3D object
detection models without using multiple techniques proposed in past range-view
literature. We explore range-view 3D object detection across two modern
datasets with substantially different properties: Argoverse 2 and Waymo Open.
Our investigation reveals key insights: (1) input feature dimensionality
significantly influences the overall performance, (2) surprisingly, employing a
classification loss grounded in 3D spatial proximity works as well or better
compared to more elaborate IoU-based losses, and (3) addressing non-uniform
lidar density via a straightforward range subsampling technique outperforms
existing multi-resolution, range-conditioned networks. Our experiments reveal
that techniques proposed in recent range-view literature are not needed to
achieve state-of-the-art performance. Combining the above findings, we
establish a new state-of-the-art model for range-view 3D object detection --
improving AP by 2.2% on the Waymo Open dataset while maintaining a runtime of
10 Hz. We establish the first range-view model on the Argoverse 2 dataset and
outperform strong voxel-based baselines. All models are multi-class and
open-source. Code is available at
https://github.com/benjaminrwilson/range-view-3d-detection.",2024-07-23,"Benjamin Wilson, Nicholas Autio Mitchell, Jhony Kaesemodel Pontes, James Hays",http://arxiv.org/pdf/2407.16789v2,cs.LG
VisMin: Visual Minimal-Change Understanding,"Fine-grained understanding of objects, attributes, and relationships between
objects is crucial for visual-language models (VLMs). Existing benchmarks
primarily focus on evaluating VLMs' capability to distinguish between two very
similar captions given an image. In this paper, we introduce a new, challenging
benchmark termed Visual Minimal-Change Understanding (VisMin), which requires
models to predict the correct image-caption match given two images and two
captions. The image pair and caption pair contain minimal changes, i.e., only
one aspect changes at a time from among the following: object, attribute,
count, and spatial relation. These changes test the models' understanding of
objects, attributes (such as color, material, shape), counts, and spatial
relationships between objects. We built an automatic framework using large
language models and diffusion models, followed by a rigorous 4-step
verification process by human annotators. Empirical experiments reveal that
current VLMs exhibit notable deficiencies in understanding spatial
relationships and counting abilities. We also generate a large-scale training
dataset to finetune CLIP and Idefics2, showing significant improvements in
fine-grained understanding across benchmarks and in CLIP's general image-text
alignment. We release all resources, including the benchmark, training data,
and finetuned model checkpoints, at https://vismin.net/.",2024-07-23,"Rabiul Awal, Saba Ahmadi, Le Zhang, Aishwarya Agrawal",http://arxiv.org/pdf/2407.16772v2,cs.LG
Stress-Testing Long-Context Language Models with Lifelong ICL and Task Haystack,"We introduce Lifelong ICL, a problem setting that challenges long-context
language models (LMs) to learn a sequence of language tasks through in-context
learning (ICL). We further introduce Task Haystack, an evaluation suite
dedicated to assessing and diagnosing how long-context LMs utilizes contexts in
Lifelong ICL. When given a task instruction and test inputs, long-context LMs
are expected to leverage the relevant demonstrations in the Lifelong ICL
prompt, avoid distraction and interference from other tasks, and achieve test
accuracies that are not significantly worse than those of the Single-task ICL
baseline.
  Task Haystack draws inspiration from the widely-adopted
""needle-in-a-haystack"" (NIAH) evaluation, but presents distinct new challenges.
It requires models (1) to utilize the contexts at a deeper level, rather than
resorting to simple copying and pasting; (2) to navigate through long streams
of evolving topics and tasks, proxying the complexities and dynamism of
contexts in real-world scenarios. Additionally, Task Haystack inherits the
controllability of NIAH, providing model developers with tools and
visualizations to identify model vulnerabilities effectively.
  We benchmark 14 long-context LMs using Task Haystack, finding that frontier
models like GPT-4o still struggle with the setting, failing on 15% of cases on
average. Most open-weight models further lack behind by a large margin, with
failure rates reaching up to 61%. In our controlled analysis, we identify
factors such as distraction and recency bias as contributors to these failure
cases. Further, performance declines when task instructions are paraphrased at
test time or when ICL demonstrations are repeated excessively, raising concerns
about the robustness, instruction understanding, and true context utilization
of long-context LMs.",2024-07-23,"Xiaoyue Xu, Qinyuan Ye, Xiang Ren",http://arxiv.org/pdf/2407.16695v2,cs.LG
Automatic Equalization for Individual Instrument Tracks Using Convolutional Neural Networks,"We propose a novel approach for the automatic equalization of individual
musical instrument tracks. Our method begins by identifying the instrument
present within a source recording in order to choose its corresponding ideal
spectrum as a target. Next, the spectral difference between the recording and
the target is calculated, and accordingly, an equalizer matching model is used
to predict settings for a parametric equalizer. To this end, we build upon a
differentiable parametric equalizer matching neural network, demonstrating
improvements relative to previously established state-of-the-art. Unlike past
approaches, we show how our system naturally allows real-world audio data to be
leveraged during the training of our matching model, effectively generating
suitably produced training targets in an automated manner mirroring conditions
at inference time. Consequently, we illustrate how fine-tuning our matching
model on such examples considerably improves parametric equalizer matching
performance in real-world scenarios, decreasing mean absolute error by 24%
relative to methods relying solely on random parameter sampling techniques as a
self-supervised learning strategy. We perform listening tests, and demonstrate
that our proposed automatic equalization solution subjectively enhances the
tonal characteristics for recordings of common instrument types.",2024-07-23,"Florian Mockenhaupt, Joscha Simon Rieber, Shahan Nercessian",http://arxiv.org/pdf/2407.16691v1,cs.LG
A Simulation Benchmark for Autonomous Racing with Large-Scale Human Data,"Despite the availability of international prize-money competitions, scaled
vehicles, and simulation environments, research on autonomous racing and the
control of sports cars operating close to the limit of handling has been
limited by the high costs of vehicle acquisition and management, as well as the
limited physics accuracy of open-source simulators. In this paper, we propose a
racing simulation platform based on the simulator Assetto Corsa to test,
validate, and benchmark autonomous driving algorithms, including reinforcement
learning (RL) and classical Model Predictive Control (MPC), in realistic and
challenging scenarios. Our contributions include the development of this
simulation platform, several state-of-the-art algorithms tailored to the racing
environment, and a comprehensive dataset collected from human drivers.
Additionally, we evaluate algorithms in the offline RL setting. All the
necessary code (including environment and benchmarks), working examples,
datasets, and videos are publicly released and can be found at:
https://assetto-corsa-gym.github.io",2024-07-23,"Adrian Remonda, Nicklas Hansen, Ayoub Raji, Nicola Musiu, Marko Bertogna, Eduardo Veas, Xiaolong Wang",http://arxiv.org/pdf/2407.16680v2,cs.LG
From Imitation to Refinement -- Residual RL for Precise Assembly,"Recent advances in Behavior Cloning (BC) have made it easy to teach robots
new tasks. However, we find that the ease of teaching comes at the cost of
unreliable performance that saturates with increasing data for tasks requiring
precision. The performance saturation can be attributed to two critical
factors: (a) distribution shift resulting from the use of offline data and (b)
the lack of closed-loop corrective control caused by action chucking
(predicting a set of future actions executed open-loop) critical for BC
performance. Our key insight is that by predicting action chunks, BC policies
function more like trajectory ""planners"" than closed-loop controllers necessary
for reliable execution. To address these challenges, we devise a simple yet
effective method, ResiP (Residual for Precise Manipulation), that overcomes the
reliability problem while retaining BC's ease of teaching and long-horizon
capabilities. ResiP augments a frozen, chunked BC model with a fully
closed-loop residual policy trained with reinforcement learning (RL) that
addresses distribution shifts and introduces closed-loop corrections over
open-loop execution of action chunks predicted by the BC trajectory planner.
Videos, code, and data: https://residual-assembly.github.io.",2024-07-23,"Lars Ankile, Anthony Simeonov, Idan Shenfeld, Marcel Torne, Pulkit Agrawal",http://arxiv.org/pdf/2407.16677v4,cs.LG
KAN or MLP: A Fairer Comparison,"This paper does not introduce a novel method. Instead, it offers a fairer and
more comprehensive comparison of KAN and MLP models across various tasks,
including machine learning, computer vision, audio processing, natural language
processing, and symbolic formula representation. Specifically, we control the
number of parameters and FLOPs to compare the performance of KAN and MLP. Our
main observation is that, except for symbolic formula representation tasks, MLP
generally outperforms KAN. We also conduct ablation studies on KAN and find
that its advantage in symbolic formula representation mainly stems from its
B-spline activation function. When B-spline is applied to MLP, performance in
symbolic formula representation significantly improves, surpassing or matching
that of KAN. However, in other tasks where MLP already excels over KAN,
B-spline does not substantially enhance MLP's performance. Furthermore, we find
that KAN's forgetting issue is more severe than that of MLP in a standard
class-incremental continual learning setting, which differs from the findings
reported in the KAN paper. We hope these results provide insights for future
research on KAN and other MLP alternatives. Project link:
https://github.com/yu-rp/KANbeFair",2024-07-23,"Runpeng Yu, Weihao Yu, Xinchao Wang",http://arxiv.org/pdf/2407.16674v2,cs.LG
PLM-Net: Perception Latency Mitigation Network for Vision-Based Lateral Control of Autonomous Vehicles,"This study introduces the Perception Latency Mitigation Network (PLM-Net), a
novel deep learning approach for addressing perception latency in vision-based
Autonomous Vehicle (AV) lateral control systems. Perception latency is the
delay between capturing the environment through vision sensors (e.g., cameras)
and applying an action (e.g., steering). This issue is understudied in both
classical and neural-network-based control methods. Reducing this latency with
powerful GPUs and FPGAs is possible but impractical for automotive platforms.
PLM-Net comprises the Base Model (BM) and the Timed Action Prediction Model
(TAPM). BM represents the original Lane Keeping Assist (LKA) system, while TAPM
predicts future actions for different latency values. By integrating these
models, PLM-Net mitigates perception latency. The final output is determined
through linear interpolation of BM and TAPM outputs based on real-time latency.
This design addresses both constant and varying latency, improving driving
trajectories and steering control. Experimental results validate the efficacy
of PLM-Net across various latency conditions. Source code:
https://github.com/AwsKhalil/oscar/tree/devel-plm-net.",2024-07-23,"Aws Khalil, Jaerock Kwon",http://arxiv.org/pdf/2407.16740v1,cs.LG
Forecasting Automotive Supply Chain Shortfalls with Heterogeneous Time Series,"Operational disruptions can significantly impact companies performance. Ford,
with its 37 plants globally, uses 17 billion parts annually to manufacture six
million cars and trucks. With up to ten tiers of suppliers between the company
and raw materials, any extended disruption in this supply chain can cause
substantial financial losses. Therefore, the ability to forecast and identify
such disruptions early is crucial for maintaining seamless operations. In this
study, we demonstrate how we construct a dataset consisting of many
multivariate time series to forecast first-tier supply chain disruptions,
utilizing features related to capacity, inventory, utilization, and processing,
as outlined in the classical Factory Physics framework. This dataset is
technically challenging due to its vast scale of over five hundred thousand
time series. Furthermore, these time series, while exhibiting certain
similarities, also display heterogeneity within specific subgroups. To address
these challenges, we propose a novel methodology that integrates an enhanced
Attention Sequence to Sequence Deep Learning architecture, using Neural Network
Embeddings to model group effects, with a Survival Analysis model. This model
is designed to learn intricate heterogeneous data patterns related to
operational disruptions. Our model has demonstrated a strong performance,
achieving 0.85 precision and 0.8 recall during the Quality Assurance (QA) phase
across Ford's five North American plants. Additionally, to address the common
criticism of Machine Learning models as black boxes, we show how the SHAP
framework can be used to generate feature importance from the model
predictions. It offers valuable insights that can lead to actionable strategies
and highlights the potential of advanced machine learning for managing and
mitigating supply chain risks in the automotive industry.",2024-07-23,"Bach Viet Do, Xingyu Li, Chaoye Pan, Oleg Gusikhin",http://arxiv.org/pdf/2407.16739v2,cs.LG
Computable learning of natural hypothesis classes,"This paper is about the recent notion of computably probably approximately
correct learning, which lies between the statistical learning theory where
there is no computational requirement on the learner and efficient PAC where
the learner must be polynomially bounded. Examples have recently been given of
hypothesis classes which are PAC learnable but not computably PAC learnable,
but these hypothesis classes are unnatural or non-canonical in the sense that
they depend on a numbering of proofs, formulas, or programs. We use the
on-a-cone machinery from computability theory to prove that, under mild
assumptions such as that the hypothesis class can be computably listable, any
natural hypothesis class which is learnable must be computably learnable. Thus
the counterexamples given previously are necessarily unnatural.",2024-07-23,"Matthew Harrison-Trainor, Syed Akbari",http://arxiv.org/pdf/2407.16663v2,cs.LG
S-E Pipeline: A Vision Transformer (ViT) based Resilient Classification Pipeline for Medical Imaging Against Adversarial Attacks,"Vision Transformer (ViT) is becoming widely popular in automating accurate
disease diagnosis in medical imaging owing to its robust self-attention
mechanism. However, ViTs remain vulnerable to adversarial attacks that may
thwart the diagnosis process by leading it to intentional misclassification of
critical disease. In this paper, we propose a novel image classification
pipeline, namely, S-E Pipeline, that performs multiple pre-processing steps
that allow ViT to be trained on critical features so as to reduce the impact of
input perturbations by adversaries. Our method uses a combination of
segmentation and image enhancement techniques such as Contrast Limited Adaptive
Histogram Equalization (CLAHE), Unsharp Masking (UM), and High-Frequency
Emphasis filtering (HFE) as preprocessing steps to identify critical features
that remain intact even after adversarial perturbations. The experimental study
demonstrates that our novel pipeline helps in reducing the effect of
adversarial attacks by 72.22% for the ViT-b32 model and 86.58% for the ViT-l32
model. Furthermore, we have shown an end-to-end deployment of our proposed
method on the NVIDIA Jetson Orin Nano board to demonstrate its practical use
case in modern hand-held devices that are usually resource-constrained.",2024-07-23,"Neha A S, Vivek Chaturvedi, Muhammad Shafique",http://arxiv.org/pdf/2407.17587v1,cs.LG
Synthesizer Sound Matching Using Audio Spectrogram Transformers,"Systems for synthesizer sound matching, which automatically set the
parameters of a synthesizer to emulate an input sound, have the potential to
make the process of synthesizer programming faster and easier for novice and
experienced musicians alike, whilst also affording new means of interaction
with synthesizers. Considering the enormous variety of synthesizers in the
marketplace, and the complexity of many of them, general-purpose sound matching
systems that function with minimal knowledge or prior assumptions about the
underlying synthesis architecture are particularly desirable. With this in
mind, we introduce a synthesizer sound matching model based on the Audio
Spectrogram Transformer. We demonstrate the viability of this model by training
on a large synthetic dataset of randomly generated samples from the popular
Massive synthesizer. We show that this model can reconstruct parameters of
samples generated from a set of 16 parameters, highlighting its improved
fidelity relative to multi-layer perceptron and convolutional neural network
baselines. We also provide audio examples demonstrating the out-of-domain model
performance in emulating vocal imitations, and sounds from other synthesizers
and musical instruments.",2024-07-23,"Fred Bruford, Frederik Blang, Shahan Nercessian",http://arxiv.org/pdf/2407.16643v1,cs.LG
Sharp bounds on aggregate expert error,"We revisit the classic problem of aggregating binary advice from
conditionally independent experts, also known as the Naive Bayes setting. Our
quantity of interest is the error probability of the optimal decision rule. In
the case of symmetric errors (sensitivity = specificity), reasonably tight
bounds on the optimal error probability are known. In the general asymmetric
case, we are not aware of any nontrivial estimates on this quantity. Our
contribution consists of sharp upper and lower bounds on the optimal error
probability in the general case, which recover and sharpen the best known
results in the symmetric special case. Since this turns out to be equivalent to
estimating the total variation distance between two product distributions, our
results also have bearing on this important and challenging problem.",2024-07-23,"Aryeh Kontorovich, Ariel Avital",http://arxiv.org/pdf/2407.16642v4,cs.LG
A Geometry-Aware Algorithm to Learn Hierarchical Embeddings in Hyperbolic Space,"Hyperbolic embeddings are a class of representation learning methods that
offer competitive performances when data can be abstracted as a tree-like
graph. However, in practice, learning hyperbolic embeddings of hierarchical
data is difficult due to the different geometry between hyperbolic space and
the Euclidean space. To address such difficulties, we first categorize three
kinds of illness that harm the performance of the embeddings. Then, we develop
a geometry-aware algorithm using a dilation operation and a transitive closure
regularization to tackle these illnesses. We empirically validate these
techniques and present a theoretical analysis of the mechanism behind the
dilation operation. Experiments on synthetic and real-world datasets reveal
superior performances of our algorithm.",2024-07-23,"Zhangyu Wang, Lantian Xu, Zhifeng Kong, Weilong Wang, Xuyu Peng, Enyang Zheng",http://arxiv.org/pdf/2407.16641v1,cs.LG
Course-Correction: Safety Alignment Using Synthetic Preferences,"The risk of harmful content generated by large language models (LLMs) becomes
a critical concern. This paper presents a systematic study on assessing and
improving LLMs' capability to perform the task of \textbf{course-correction},
\ie, the model can steer away from generating harmful content autonomously. To
start with, we introduce the \textsc{C$^2$-Eval} benchmark for quantitative
assessment and analyze 10 popular LLMs, revealing varying proficiency of
current safety-tuned LLMs in course-correction. To improve, we propose
fine-tuning LLMs with preference learning, emphasizing the preference for
timely course-correction. Using an automated pipeline, we create
\textsc{C$^2$-Syn}, a synthetic dataset with 750K pairwise preferences, to
teach models the concept of timely course-correction through data-driven
preference learning. Experiments on 2 LLMs, \textsc{Llama2-Chat 7B} and
\textsc{Qwen2 7B}, show that our method effectively enhances course-correction
skills without affecting general performance. Additionally, it effectively
improves LLMs' safety, particularly in resisting jailbreak attacks.",2024-07-23,"Rongwu Xu, Yishuo Cai, Zhenhong Zhou, Renjie Gu, Haiqin Weng, Yan Liu, Tianwei Zhang, Wei Xu, Han Qiu",http://arxiv.org/pdf/2407.16637v2,cs.LG
Theoretical Analysis of Privacy Leakage in Trustworthy Federated Learning: A Perspective from Linear Algebra and Optimization Theory,"Federated learning has emerged as a promising paradigm for collaborative
model training while preserving data privacy. However, recent studies have
shown that it is vulnerable to various privacy attacks, such as data
reconstruction attacks. In this paper, we provide a theoretical analysis of
privacy leakage in federated learning from two perspectives: linear algebra and
optimization theory. From the linear algebra perspective, we prove that when
the Jacobian matrix of the batch data is not full rank, there exist different
batches of data that produce the same model update, thereby ensuring a level of
privacy. We derive a sufficient condition on the batch size to prevent data
reconstruction attacks. From the optimization theory perspective, we establish
an upper bound on the privacy leakage in terms of the batch size, the
distortion extent, and several other factors. Our analysis provides insights
into the relationship between privacy leakage and various aspects of federated
learning, offering a theoretical foundation for designing privacy-preserving
federated learning algorithms.",2024-07-23,"Xiaojin Zhang, Wei Chen",http://arxiv.org/pdf/2407.16735v1,cs.LG
Lawma: The Power of Specialization for Legal Annotation,"Annotation and classification of legal text are central components of
empirical legal research. Traditionally, these tasks are often delegated to
trained research assistants. Motivated by the advances in language modeling,
empirical legal scholars are increasingly turning to prompting commercial
models, hoping that it will alleviate the significant cost of human annotation.
Despite growing use, our understanding of how to best utilize large language
models for legal annotation remains limited. To bridge this gap, we introduce
CaselawQA, a benchmark comprising 260 legal annotation tasks, nearly all new to
the machine learning community. We demonstrate that commercial models, such as
GPT-4.5 and Claude 3.7 Sonnet, achieve non-trivial yet highly variable
accuracy, generally falling short of the performance required for legal work.
We then demonstrate that small, lightly fine-tuned models outperform commercial
models. A few hundred to a thousand labeled examples are usually enough to
achieve higher accuracy. Our work points to a viable alternative to the
predominant practice of prompting commercial models. For concrete legal
annotation tasks with some available labeled data, researchers are likely
better off using a fine-tuned open-source model.",2024-07-23,"Ricardo Dominguez-Olmedo, Vedant Nanda, Rediet Abebe, Stefan Bechtold, Christoph Engel, Jens Frankenreiter, Krishna Gummadi, Moritz Hardt, Michael Livermore",http://arxiv.org/pdf/2407.16615v2,cs.LG
Local vs Global continual learning,"Continual learning is the problem of integrating new information in a model
while retaining the knowledge acquired in the past. Despite the tangible
improvements achieved in recent years, the problem of continual learning is
still an open one. A better understanding of the mechanisms behind the
successes and failures of existing continual learning algorithms can unlock the
development of new successful strategies. In this work, we view continual
learning from the perspective of the multi-task loss approximation, and we
compare two alternative strategies, namely local and global approximations. We
classify existing continual learning algorithms based on the approximation
used, and we assess the practical effects of this distinction in common
continual learning settings.Additionally, we study optimal continual learning
objectives in the case of local polynomial approximations and we provide
examples of existing algorithms implementing the optimal objectives",2024-07-23,"Giulia Lanzillotta, Sidak Pal Singh, Benjamin F. Grewe, Thomas Hofmann",http://arxiv.org/pdf/2407.16611v1,cs.LG
Data Mixture Inference: What do BPE Tokenizers Reveal about their Training Data?,"The pretraining data of today's strongest language models is opaque; in
particular, little is known about the proportions of various domains or
languages represented. In this work, we tackle a task which we call data
mixture inference, which aims to uncover the distributional make-up of training
data. We introduce a novel attack based on a previously overlooked source of
information: byte-pair encoding (BPE) tokenizers, used by the vast majority of
modern language models. Our key insight is that the ordered list of merge rules
learned by a BPE tokenizer naturally reveals information about the token
frequencies in its training data. Given a tokenizer's merge list along with
example data for each category of interest, we formulate a linear program that
solves for the proportion of each category in the tokenizer's training set. In
controlled experiments, we show that our attack recovers mixture ratios with
high precision for tokenizers trained on known mixtures of natural languages,
programming languages, and data sources. We then apply our approach to
off-the-shelf tokenizers released with recent LMs. We confirm much publicly
disclosed information about these models, and also make several new inferences:
GPT-4o and Mistral NeMo's tokenizers are much more multilingual than their
predecessors, training on 39% and 47% non-English language data, respectively;
Llama 3 extends GPT-3.5's tokenizer primarily for multilingual (48%) use;
GPT-3.5's and Claude's tokenizers are trained on predominantly code (~60%). We
hope our work sheds light on current design practices for pretraining data, and
inspires continued research into data mixture inference for LMs.",2024-07-23,"Jonathan Hayase, Alisa Liu, Yejin Choi, Sewoong Oh, Noah A. Smith",http://arxiv.org/pdf/2407.16607v4,cs.LG
Learning to Play Foosball: System and Baselines,"This work stages Foosball as a versatile platform for advancing scientific
research, particularly in the realm of robot learning. We present an automated
Foosball table along with its corresponding simulated counterpart, showcasing a
diverse range of challenges through example tasks within the Foosball
environment. Initial findings are shared using a simple baseline approach.
Foosball constitutes a versatile learning environment with the potential to
yield cutting-edge research in various fields of artificial intelligence and
machine learning, notably robust learning, while also extending its
applicability to industrial robotics and automation setups. To transform our
physical Foosball table into a research-friendly system, we augmented it with a
2 degrees of freedom kinematic chain to control the goalkeeper rod as an
initial setup with the intention to be extended to the full game as soon as
possible. Our experiments reveal that a realistic simulation is essential for
mastering complex robotic tasks, yet translating these accomplishments to the
real system remains challenging, often accompanied by a performance decline.
This emphasizes the critical importance of research in this direction. In this
concern, we spotlight the automated Foosball table as an invaluable tool,
possessing numerous desirable attributes, to serve as a demanding learning
environment for advancing robotics and automation research.",2024-07-23,"Janosch Moos, Cedric Derstroff, Niklas Schröder, Debora Clever",http://arxiv.org/pdf/2407.16606v1,cs.LG
Functional Acceleration for Policy Mirror Descent,"We apply functional acceleration to the Policy Mirror Descent (PMD) general
family of algorithms, which cover a wide range of novel and fundamental methods
in Reinforcement Learning (RL). Leveraging duality, we propose a momentum-based
PMD update. By taking the functional route, our approach is independent of the
policy parametrization and applicable to large-scale optimization, covering
previous applications of momentum at the level of policy parameters as a
special case. We theoretically analyze several properties of this approach and
complement with a numerical ablation study, which serves to illustrate the
policy optimization dynamics on the value polytope, relative to different
algorithmic design choices in this space. We further characterize numerically
several features of the problem setting relevant for functional acceleration,
and lastly, we investigate the impact of approximation on their learning
mechanics.",2024-07-23,"Veronica Chelu, Doina Precup",http://arxiv.org/pdf/2407.16602v2,cs.LG
Conformally Natural Families of Probability Distributions on Hyperbolic Disc with a View on Geometric Deep Learning,"We introduce the novel family of probability distributions on hyperbolic
disc. The distinctive property of the proposed family is invariance under the
actions of the group of disc-preserving conformal mappings. The
group-invariance property renders it a convenient and tractable model for
encoding uncertainties in hyperbolic data. Potential applications in Geometric
Deep Learning and bioinformatics are numerous, some of them are briefly
discussed. We also emphasize analogies with hyperbolic coherent states in
quantum physics.",2024-07-23,"Vladimir Jacimovic, Marijan Markovic",http://arxiv.org/pdf/2407.16733v1,cs.LG
Prompt Injection Attacks on Large Language Models in Oncology,"Vision-language artificial intelligence models (VLMs) possess medical
knowledge and can be employed in healthcare in numerous ways, including as
image interpreters, virtual scribes, and general decision support systems.
However, here, we demonstrate that current VLMs applied to medical tasks
exhibit a fundamental security flaw: they can be attacked by prompt injection
attacks, which can be used to output harmful information just by interacting
with the VLM, without any access to its parameters. We performed a quantitative
study to evaluate the vulnerabilities to these attacks in four state of the art
VLMs which have been proposed to be of utility in healthcare: Claude 3 Opus,
Claude 3.5 Sonnet, Reka Core, and GPT-4o. Using a set of N=297 attacks, we show
that all of these models are susceptible. Specifically, we show that embedding
sub-visual prompts in medical imaging data can cause the model to provide
harmful output, and that these prompts are non-obvious to human observers.
Thus, our study demonstrates a key vulnerability in medical VLMs which should
be mitigated before widespread clinical adoption.",2024-07-23,"Jan Clusmann, Dyke Ferber, Isabella C. Wiest, Carolin V. Schneider, Titus J. Brinker, Sebastian Foersch, Daniel Truhn, Jakob N. Kather",http://arxiv.org/pdf/2407.18981v1,cs.LG
DC is all you need: describing ReLU from a signal processing standpoint,"Non-linear activation functions are crucial in Convolutional Neural Networks.
However, until now they have not been well described in the frequency domain.
In this work, we study the spectral behavior of ReLU, a popular activation
function. We use the ReLU's Taylor expansion to derive its frequency domain
behavior. We demonstrate that ReLU introduces higher frequency oscillations in
the signal and a constant DC component. Furthermore, we investigate the
importance of this DC component, where we demonstrate that it helps the model
extract meaningful features related to the input frequency content. We
accompany our theoretical derivations with experiments and real-world examples.
First, we numerically validate our frequency response model. Then we observe
ReLU's spectral behavior on two example models and a real-world one. Finally,
we experimentally investigate the role of the DC component introduced by ReLU
in the CNN's representations. Our results indicate that the DC helps to
converge to a weight configuration that is close to the initial random weights.",2024-07-23,"Christodoulos Kechris, Jonathan Dan, Jose Miranda, David Atienza",http://arxiv.org/pdf/2407.16556v2,cs.LG
PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning,"Generating human mobility trajectories is of great importance to solve the
lack of large-scale trajectory data in numerous applications, which is caused
by privacy concerns. However, existing mobility trajectory generation methods
still require real-world human trajectories centrally collected as the training
data, where there exists an inescapable risk of privacy leakage. To overcome
this limitation, in this paper, we propose PateGail, a privacy-preserving
imitation learning model to generate mobility trajectories, which utilizes the
powerful generative adversary imitation learning model to simulate the
decision-making process of humans. Further, in order to protect user privacy,
we train this model collectively based on decentralized mobility data stored in
user devices, where personal discriminators are trained locally to distinguish
and reward the real and generated human trajectories. In the training process,
only the generated trajectories and their rewards obtained based on personal
discriminators are shared between the server and devices, whose privacy is
further preserved by our proposed perturbation mechanisms with theoretical
proof to satisfy differential privacy. Further, to better model the human
decision-making process, we propose a novel aggregation mechanism of the
rewards obtained from personal discriminators. We theoretically prove that
under the reward obtained based on the aggregation mechanism, our proposed
model maximizes the lower bound of the discounted total rewards of users.
Extensive experiments show that the trajectories generated by our model are
able to resemble real-world trajectories in terms of five key statistical
metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore,
we demonstrate that the synthetic trajectories are able to efficiently support
practical applications, including mobility prediction and location
recommendation.",2024-07-23,"Huandong Wang, Changzheng Gao, Yuchen Wu, Depeng Jin, Lina Yao, Yong Li",http://arxiv.org/pdf/2407.16729v1,cs.LG
Enhancing Encrypted Internet Traffic Classification Through Advanced Data Augmentation Techniques,"The increasing popularity of online services has made Internet Traffic
Classification a critical field of study. However, the rapid development of
internet protocols and encryption limits usable data availability. This paper
addresses the challenges of classifying encrypted internet traffic, focusing on
the scarcity of open-source datasets and limitations of existing ones. We
propose two Data Augmentation (DA) techniques to synthetically generate data
based on real samples: Average augmentation and MTU augmentation. Both
augmentations are aimed to improve the performance of the classifier, each from
a different perspective: The Average augmentation aims to increase dataset size
by generating new synthetic samples, while the MTU augmentation enhances
classifier robustness to varying Maximum Transmission Units (MTUs). Our
experiments, conducted on two well-known academic datasets and a commercial
dataset, demonstrate the effectiveness of these approaches in improving model
performance and mitigating constraints associated with limited and homogeneous
datasets. Our findings underscore the potential of data augmentation in
addressing the challenges of modern internet traffic classification.
Specifically, we show that our augmentation techniques significantly enhance
encrypted traffic classification models. This improvement can positively impact
user Quality of Experience (QoE) by more accurately classifying traffic as
video streaming (e.g., YouTube) or chat (e.g., Google Chat). Additionally, it
can enhance Quality of Service (QoS) for file downloading activities (e.g.,
Google Docs).",2024-07-23,"Yehonatan Zion, Porat Aharon, Ran Dubin, Amit Dvir, Chen Hajaj",http://arxiv.org/pdf/2407.16539v1,cs.LG
Imperfect Vision Encoders: Efficient and Robust Tuning for Vision-Language Models,"Vision language models (VLMs) demonstrate impressive capabilities in visual
question answering and image captioning, acting as a crucial link between
visual and language models. However, existing open-source VLMs heavily rely on
pretrained and frozen vision encoders (such as CLIP). Despite CLIP's robustness
across diverse domains, it still exhibits non-negligible image understanding
errors. These errors propagate to the VLM responses, resulting in sub-optimal
performance. In our work, we propose an efficient and robust method for
updating vision encoders within VLMs. Our approach selectively and locally
updates encoders, leading to substantial performance improvements on data where
previous mistakes occurred, while maintaining overall robustness. Furthermore,
we demonstrate the effectiveness of our method during continual few-shot
updates. Theoretical grounding, generality, and computational efficiency
characterize our approach.",2024-07-23,"Aristeidis Panos, Rahaf Aljundi, Daniel Olmeda Reino, Richard E Turner",http://arxiv.org/pdf/2407.16526v1,cs.LG
Spurious Correlations in Concept Drift: Can Explanatory Interaction Help?,"Long-running machine learning models face the issue of concept drift (CD),
whereby the data distribution changes over time, compromising prediction
performance. Updating the model requires detecting drift by monitoring the data
and/or the model for unexpected changes. We show that, however, spurious
correlations (SCs) can spoil the statistics tracked by detection algorithms.
Motivated by this, we introduce ebc-exstream, a novel detector that leverages
model explanations to identify potential SCs and human feedback to correct for
them. It leverages an entropy-based heuristic to reduce the amount of necessary
feedback, cutting annotation costs. Our preliminary experiments on artificially
confounded data highlight the promise of ebc-exstream for reducing the impact
of SCs on detection.",2024-07-23,"Cristiana Lalletti, Stefano Teso",http://arxiv.org/pdf/2407.16515v1,cs.LG
Articulation Work and Tinkering for Fairness in Machine Learning,"The field of fair AI aims to counter biased algorithms through computational
modelling. However, it faces increasing criticism for perpetuating the use of
overly technical and reductionist methods. As a result, novel approaches appear
in the field to address more socially-oriented and interdisciplinary (SOI)
perspectives on fair AI. In this paper, we take this dynamic as the starting
point to study the tension between computer science (CS) and SOI research. By
drawing on STS and CSCW theory, we position fair AI research as a matter of
'organizational alignment': what makes research 'doable' is the successful
alignment of three levels of work organization (the social world, the
laboratory, and the experiment). Based on qualitative interviews with CS
researchers, we analyze the tasks, resources, and actors required for doable
research in the case of fair AI. We find that CS researchers engage with SOI
research to some extent, but organizational conditions, articulation work, and
ambiguities of the social world constrain the doability of SOI research for
them. Based on our findings, we identify and discuss problems for aligning CS
and SOI as fair AI continues to evolve.",2024-07-23,"Miriam Fahimi, Mayra Russo, Kristen M. Scott, Maria-Esther Vidal, Bettina Berendt, Katharina Kinder-Kurlanda",http://arxiv.org/pdf/2407.16496v2,cs.LG
Learning Constraint Network from Demonstrations via Positive-Unlabeled Learning with Memory Replay,"Planning for a wide range of real-world tasks necessitates to know and write
all constraints. However, instances exist where these constraints are either
unknown or challenging to specify accurately. A possible solution is to infer
the unknown constraints from expert demonstration. The majority of prior works
limit themselves to learning simple linear constraints, or require strong
knowledge of the true constraint parameterization or environmental model. To
mitigate these problems, this paper presents a positive-unlabeled (PU) learning
approach to infer a continuous, arbitrary and possibly nonlinear, constraint
from demonstration. From a PU learning view, We treat all data in
demonstrations as positive (feasible) data, and learn a (sub)-optimal policy to
generate high-reward-winning but potentially infeasible trajectories, which
serve as unlabeled data containing both feasible and infeasible states. Under
an assumption on data distribution, a feasible-infeasible classifier (i.e.,
constraint model) is learned from the two datasets through a postprocessing PU
learning technique. The entire method employs an iterative framework
alternating between updating the policy, which generates and selects
higher-reward policies, and updating the constraint model. Additionally, a
memory buffer is introduced to record and reuse samples from previous
iterations to prevent forgetting. The effectiveness of the proposed method is
validated in two Mujoco environments, successfully inferring continuous
nonlinear constraints and outperforming a baseline method in terms of
constraint accuracy and policy safety.",2024-07-23,"Baiyu Peng, Aude Billard",http://arxiv.org/pdf/2407.16485v3,cs.LG
Topology Reorganized Graph Contrastive Learning with Mitigating Semantic Drift,"Graph contrastive learning (GCL) is an effective paradigm for node
representation learning in graphs. The key components hidden behind GCL are
data augmentation and positive-negative pair selection. Typical data
augmentations in GCL, such as uniform deletion of edges, are generally blind
and resort to local perturbation, which is prone to producing under-diversity
views. Additionally, there is a risk of making the augmented data traverse to
other classes. Moreover, most methods always treat all other samples as
negatives. Such a negative pairing naturally results in sampling bias and
likewise may make the learned representation suffer from semantic drift.
Therefore, to increase the diversity of the contrastive view, we propose two
simple and effective global topological augmentations to compensate current
GCL. One is to mine the semantic correlation between nodes in the feature
space. The other is to utilize the algebraic properties of the adjacency matrix
to characterize the topology by eigen-decomposition. With the help of both, we
can retain important edges to build a better view. To reduce the risk of
semantic drift, a prototype-based negative pair selection is further designed
which can filter false negative samples. Extensive experiments on various tasks
demonstrate the advantages of the model compared to the state-of-the-art
methods.",2024-07-23,"Jiaqiang Zhang, Songcan Chen",http://arxiv.org/pdf/2407.16726v1,cs.LG
BONES: a Benchmark fOr Neural Estimation of Shapley values,"Shapley Values are concepts established for eXplainable AI. They are used to
explain black-box predictive models by quantifying the features' contributions
to the model's outcomes. Since computing the exact Shapley Values is known to
be computationally intractable on real-world datasets, neural estimators have
emerged as alternative, more scalable approaches to get approximated Shapley
Values estimates. However, experiments with neural estimators are currently
hard to replicate as algorithm implementations, explainer evaluators, and
results visualizations are neither standardized nor promptly usable. To bridge
this gap, we present BONES, a new benchmark focused on neural estimation of
Shapley Value. It provides researchers with a suite of state-of-the-art neural
and traditional estimators, a set of commonly used benchmark datasets, ad hoc
modules for training black-box models, as well as specific functions to easily
compute the most popular evaluation metrics and visualize results. The purpose
is to simplify XAI model usage, evaluation, and comparison. In this paper, we
showcase BONES results and visualizations for XAI model benchmarking on both
tabular and image data. The open-source library is available at the following
link: https://github.com/DavideNapolitano/BONES.",2024-07-23,"Davide Napolitano, Luca Cagliero",http://arxiv.org/pdf/2407.16482v1,cs.LG
Enhancing GNNs Performance on Combinatorial Optimization by Recurrent Feature Update,"Combinatorial optimization (CO) problems are crucial in various scientific
and industrial applications. Recently, researchers have proposed using
unsupervised Graph Neural Networks (GNNs) to address NP-hard combinatorial
optimization problems, which can be reformulated as Quadratic Unconstrained
Binary Optimization (QUBO) problems. GNNs have demonstrated high performance
with nearly linear scalability and significantly outperformed classic
heuristic-based algorithms in terms of computational efficiency on large-scale
problems. However, when utilizing standard node features, GNNs tend to get
trapped to suboptimal local minima of the energy landscape, resulting in low
quality solutions. We introduce a novel algorithm, denoted hereafter as
QRF-GNN, leveraging the power of GNNs to efficiently solve CO problems with
QUBO formulation. It relies on unsupervised learning by minimizing the loss
function derived from QUBO relaxation. The proposed key components of the
architecture include the recurrent use of intermediate GNN predictions,
parallel convolutional layers and combination of static node features as input.
Altogether, it helps to adapt the intermediate solution candidate to minimize
QUBO-based loss function, taking into account not only static graph features,
but also intermediate predictions treated as dynamic, i.e. iteratively changing
recurrent features. The performance of the proposed algorithm has been
evaluated on the canonical benchmark datasets for maximum cut, graph coloring
and maximum independent set problems. Results of experiments show that QRF-GNN
drastically surpasses existing learning-based approaches and is comparable to
the state-of-the-art conventional heuristics, improving their scalability on
large instances.",2024-07-23,"Daria Pugacheva, Andrei Ermakov, Igor Lyskov, Ilya Makarov, Yuriy Zotov",http://arxiv.org/pdf/2407.16468v1,cs.LG
Sobolev neural network with residual weighting as a surrogate in linear and non-linear mechanics,"Areas of computational mechanics such as uncertainty quantification and
optimization usually involve repeated evaluation of numerical models that
represent the behavior of engineering systems. In the case of complex nonlinear
systems however, these models tend to be expensive to evaluate, making
surrogate models quite valuable. Artificial neural networks approximate systems
very well by taking advantage of the inherent information of its given training
data. In this context, this paper investigates the improvement of the training
process by including sensitivity information, which are partial derivatives
w.r.t. inputs, as outlined by Sobolev training. In computational mechanics,
sensitivities can be applied to neural networks by expanding the training loss
function with additional loss terms, thereby improving training convergence
resulting in lower generalisation error. This improvement is shown in two
examples of linear and non-linear material behavior. More specifically, the
Sobolev designed loss function is expanded with residual weights adjusting the
effect of each loss on the training step. Residual weighting is the given
scaling to the different training data, which in this case are response and
sensitivities. These residual weights are optimized by an adaptive scheme,
whereby varying objective functions are explored, with some showing
improvements in accuracy and precision of the general training convergence.",2024-07-23,"A. O. M. Kilicsoy, J. Liedmann, M. A. Valdebenito, F. -J. Barthold, M. G. R. Faes",http://arxiv.org/pdf/2407.16466v1,cs.LG
Lymphoid Infiltration Assessment of the Tumor Margins in H&E Slides,"Lymphoid infiltration at tumor margins is a key prognostic marker in solid
tumors, playing a crucial role in guiding immunotherapy decisions. Current
assessment methods, heavily reliant on immunohistochemistry (IHC), face
challenges in tumor margin delineation and are affected by tissue preservation
conditions. In contrast, we propose a Hematoxylin and Eosin (H&E)
staining-based approach, underpinned by an advanced lymphocyte segmentation
model trained on a public dataset for the precise detection of CD3+ and CD20+
lymphocytes. In our colorectal cancer study, we demonstrate that our H&E-based
method offers a compelling alternative to traditional IHC, achieving comparable
results in many cases. Our method's validity is further explored through a
Turing test, involving blinded assessments by a pathologist of anonymized
curves from H&E and IHC slides. This approach invites the medical community to
consider Turing tests as a standard for evaluating medical applications
involving expert human evaluation, thereby opening new avenues for enhancing
cancer management and immunotherapy planning.",2024-07-23,"Zhuxian Guo, Amine Marzouki, Jean-François Emile, Henning Müller, Camille Kurtz, Nicolas Loménie",http://arxiv.org/pdf/2407.16464v1,cs.LG
"Advances in Land Surface Model-based Forecasting: A comparative study of LSTM, Gradient Boosting, and Feedforward Neural Network Models as prognostic state emulators","Most useful weather prediction for the public is near the surface. The
processes that are most relevant for near-surface weather prediction are also
those that are most interactive and exhibit positive feedback or have key role
in energy partitioning. Land surface models (LSMs) consider these processes
together with surface heterogeneity and forecast water, carbon and energy
fluxes, and coupled with an atmospheric model provide boundary and initial
conditions. This numerical parametrization of atmospheric boundaries being
computationally expensive, statistical surrogate models are increasingly used
to accelerated progress in experimental research. We evaluated the efficiency
of three surrogate models in speeding up experimental research by simulating
land surface processes, which are integral to forecasting water, carbon, and
energy fluxes in coupled atmospheric models. Specifically, we compared the
performance of a Long-Short Term Memory (LSTM) encoder-decoder network, extreme
gradient boosting, and a feed-forward neural network within a physics-informed
multi-objective framework. This framework emulates key states of the ECMWF's
Integrated Forecasting System (IFS) land surface scheme, ECLand, across
continental and global scales. Our findings indicate that while all models on
average demonstrate high accuracy over the forecast period, the LSTM network
excels in continental long-range predictions when carefully tuned, the XGB
scores consistently high across tasks and the MLP provides an excellent
implementation-time-accuracy trade-off. The runtime reduction achieved by the
emulators in comparison to the full numerical models are significant, offering
a faster, yet reliable alternative for conducting numerical experiments on land
surfaces.",2024-07-23,"Marieke Wesselkamp, Matthew Chantry, Ewan Pinnington, Margarita Choulga, Souhail Boussetta, Maria Kalweit, Joschka Boedecker, Carsten F. Dormann, Florian Pappenberger, Gianpaolo Balsamo",http://arxiv.org/pdf/2407.16463v1,cs.LG
Can time series forecasting be automated? A benchmark and analysis,"In the field of machine learning and artificial intelligence, time series
forecasting plays a pivotal role across various domains such as finance,
healthcare, and weather. However, the task of selecting the most suitable
forecasting method for a given dataset is a complex task due to the diversity
of data patterns and characteristics. This research aims to address this
challenge by proposing a comprehensive benchmark for evaluating and ranking
time series forecasting methods across a wide range of datasets. This study
investigates the comparative performance of many methods from two prominent
time series forecasting frameworks, AutoGluon-Timeseries, and sktime to shed
light on their applicability in different real-world scenarios. This research
contributes to the field of time series forecasting by providing a robust
benchmarking methodology and facilitating informed decision-making when
choosing forecasting methods for achieving optimal prediction.",2024-07-23,"Anvitha Thirthapura Sreedhara, Joaquin Vanschoren",http://arxiv.org/pdf/2407.16445v2,cs.LG
Physics-Informed Weakly Supervised Learning for Interatomic Potentials,"Machine learning plays an increasingly important role in computational
chemistry and materials science, complementing computationally intensive ab
initio and first-principles methods. Despite their utility, machine-learning
models often lack generalization capability and robustness during atomistic
simulations, yielding unphysical energy and force predictions that hinder their
real-world applications. We address this challenge by introducing a
physics-informed, weakly supervised approach for training machine-learned
interatomic potentials (MLIPs). We introduce two novel loss functions,
extrapolating the potential energy via a Taylor expansion and using the concept
of conservative forces. Our approach improves the accuracy of MLIPs applied to
training tasks with sparse training data sets and reduces the need for
pre-training computationally demanding models with large data sets.
Particularly, we perform extensive experiments demonstrating reduced energy and
force errors -- often lower by a factor of two -- for various baseline models
and benchmark data sets. Moreover, we demonstrate improved robustness during MD
simulations of the MLIP models trained with the proposed weakly supervised
loss. Finally, our approach improves the fine-tuning of foundation models on
sparse, highly accurate ab initio data. An implementation of our method and
scripts for executing experiments are available at
https://github.com/nec-research/PICPS-ML4Sci.",2024-07-23,"Makoto Takamoto, Viktor Zaverkin, Mathias Niepert",http://arxiv.org/pdf/2408.05215v2,cs.LG
Stochastic weight matrix dynamics during learning and Dyson Brownian motion,"We demonstrate that the update of weight matrices in learning algorithms can
be described in the framework of Dyson Brownian motion, thereby inheriting many
features of random matrix theory. We relate the level of stochasticity to the
ratio of the learning rate and the mini-batch size, providing more robust
evidence to a previously conjectured scaling relationship. We discuss universal
and non-universal features in the resulting Coulomb gas distribution and
identify the Wigner surmise and Wigner semicircle explicitly in a
teacher-student model and in the (near-)solvable case of the Gaussian
restricted Boltzmann machine.",2024-07-23,"Gert Aarts, Biagio Lucini, Chanju Park",http://arxiv.org/pdf/2407.16427v2,cs.LG
On the Utility of Speech and Audio Foundation Models for Marmoset Call Analysis,"Marmoset monkeys encode vital information in their calls and serve as a
surrogate model for neuro-biologists to understand the evolutionary origins of
human vocal communication. Traditionally analyzed with signal processing-based
features, recent approaches have utilized self-supervised models pre-trained on
human speech for feature extraction, capitalizing on their ability to learn a
signal's intrinsic structure independently of its acoustic domain. However, the
utility of such foundation models remains unclear for marmoset call analysis in
terms of multi-class classification, bandwidth, and pre-training domain. This
study assesses feature representations derived from speech and general audio
domains, across pre-training bandwidths of 4, 8, and 16 kHz for marmoset
call-type and caller classification tasks. Results show that models with higher
bandwidth improve performance, and pre-training on speech or general audio
yields comparable results, improving over a spectral baseline.",2024-07-23,"Eklavya Sarkar, Mathew Magimai. -Doss",http://arxiv.org/pdf/2407.16417v2,cs.LG
Data-Driven Optimal Feedback Laws via Kernel Mean Embeddings,"This paper proposes a fully data-driven approach for optimal control of
nonlinear control-affine systems represented by a stochastic diffusion. The
focus is on the scenario where both the nonlinear dynamics and stage cost
functions are unknown, while only control penalty function and constraints are
provided. Leveraging the theory of reproducing kernel Hilbert spaces, we
introduce novel kernel mean embeddings (KMEs) to identify the Markov transition
operators associated with controlled diffusion processes. The KME learning
approach seamlessly integrates with modern convex operator-theoretic
Hamilton-Jacobi-Bellman recursions. Thus, unlike traditional dynamic
programming methods, our approach exploits the ``kernel trick'' to break the
curse of dimensionality. We demonstrate the effectiveness of our method through
numerical examples, highlighting its ability to solve a large class of
nonlinear optimal control problems.",2024-07-23,"Petar Bevanda, Nicolas Hoischen, Stefan Sosnowski, Sandra Hirche, Boris Houska",http://arxiv.org/pdf/2407.16407v1,cs.LG
Hi-EF: Benchmarking Emotion Forecasting in Human-interaction,"Affective Forecasting, a research direction in psychology that predicts
individuals future emotions, is often constrained by numerous external factors
like social influence and temporal distance. To address this, we transform
Affective Forecasting into a Deep Learning problem by designing an Emotion
Forecasting paradigm based on two-party interactions. We propose a novel
Emotion Forecasting (EF) task grounded in the theory that an individuals
emotions are easily influenced by the emotions or other information conveyed
during interactions with another person. To tackle this task, we have developed
a specialized dataset, Human-interaction-based Emotion Forecasting (Hi-EF),
which contains 3069 two-party Multilayered-Contextual Interaction Samples
(MCIS) with abundant affective-relevant labels and three modalities. Hi-EF not
only demonstrates the feasibility of the EF task but also highlights its
potential. Additionally, we propose a methodology that establishes a
foundational and referential baseline model for the EF task and extensive
experiments are provided. The dataset and code is available at
https://github.com/Anonymize-Author/Hi-EF.",2024-07-23,"Haoran Wang, Xinji Mai, Zeng Tao, Yan Wang, Jiawen Yu, Ziheng Zhou, Xuan Tong, Shaoqi Yan, Qing Zhao, Shuyong Gao, Wenqiang Zhang",http://arxiv.org/pdf/2407.16406v1,cs.LG
"On ADMM in Heterogeneous Federated Learning: Personalization, Robustness, and Fairness","Statistical heterogeneity is a root cause of tension among accuracy,
fairness, and robustness of federated learning (FL), and is key in paving a
path forward. Personalized FL (PFL) is an approach that aims to reduce the
impact of statistical heterogeneity by developing personalized models for
individual users, while also inherently providing benefits in terms of fairness
and robustness. However, existing PFL frameworks focus on improving the
performance of personalized models while neglecting the global model. Moreover,
these frameworks achieve sublinear convergence rates and rely on strong
assumptions. In this paper, we propose FLAME, an optimization framework by
utilizing the alternating direction method of multipliers (ADMM) to train
personalized and global models. We propose a model selection strategy to
improve performance in situations where clients have different types of
heterogeneous data. Our theoretical analysis establishes the global convergence
and two kinds of convergence rates for FLAME under mild assumptions. We
theoretically demonstrate that FLAME is more robust and fair than the
state-of-the-art methods on a class of linear problems. Our experimental
findings show that FLAME outperforms state-of-the-art methods in convergence
and accuracy, and it achieves higher test accuracy under various attacks and
performs more uniformly across clients.",2024-07-23,"Shengkun Zhu, Jinshan Zeng, Sheng Wang, Yuan Sun, Xiaodong Li, Yuan Yao, Zhiyong Peng",http://arxiv.org/pdf/2407.16397v1,cs.LG
Interval Forecasts for Gas Prices in the Face of Structural Breaks -- Statistical Models vs. Neural Networks,"Reliable gas price forecasts are an essential information for gas and energy
traders, for risk managers and also economists. However, ahead of the war in
Ukraine Europe began to suffer from substantially increased and volatile gas
prices which culminated in the aftermath of the North Stream 1 explosion. This
shock changed both trend and volatility structure of the prices and has
considerable effects on forecasting models. In this study we investigate
whether modern machine learning methods such as neural networks are more
resilient against such changes than statistical models such as autoregressive
moving average (ARMA) models with conditional heteroskedasticity, or
copula-based time series models. Thereby the focus lies on interval forecasting
and applying respective evaluation measures. As data, the Front Month prices
from the Dutch Title Transfer Facility, currently the predominant European
exchange, are used. We see that, during the shock period, most models
underestimate the variance while overestimating the variance in the after-shock
period. Furthermore, we recognize that, during the shock, the simpler models,
i.e. an ARMA model with conditional heteroskedasticity and the multilayer
perceptron (a neural network), perform best with regards to prediction interval
coverage. Interestingly, the widely-used long-short term neural network is
outperformed by its competitors.",2024-07-23,"Stephan Schlüter, Sven Pappert, Martin Neumann",http://arxiv.org/pdf/2407.16723v1,cs.LG
Anwendung von Causal-Discovery-Algorithmen zur Root-Cause-Analyse in der Fahrzeugmontage,"Root Cause Analysis (RCA) is a quality management method that aims to
systematically investigate and identify the cause-and-effect relationships of
problems and their underlying causes. Traditional methods are based on the
analysis of problems by subject matter experts. In modern production processes,
large amounts of data are collected. For this reason, increasingly
computer-aided and data-driven methods are used for RCA. One of these methods
are Causal Discovery Algorithms (CDA). This publication demonstrates the
application of CDA on data from the assembly of a leading automotive
manufacturer. The algorithms used learn the causal structure between the
characteristics of the manufactured vehicles, the ergonomics and the temporal
scope of the involved assembly processes, and quality-relevant product features
based on representative data. This publication compares various CDAs in terms
of their suitability in the context of quality management. For this purpose,
the causal structures learned by the algorithms as well as their runtime are
compared. This publication provides a contribution to quality management and
demonstrates how CDAs can be used for RCA in assembly processes.",2024-07-23,"Lucas Possner, Lukas Bahr, Leonard Roehl, Christoph Wehner, Sophie Groeger",http://arxiv.org/pdf/2407.16388v1,cs.LG
Machine Learning Models for the Identification of Cardiovascular Diseases Using UK Biobank Data,"Machine learning models have the potential to identify cardiovascular
diseases (CVDs) early and accurately in primary healthcare settings, which is
crucial for delivering timely treatment and management. Although
population-based CVD risk models have been used traditionally, these models
often do not consider variations in lifestyles, socioeconomic conditions, or
genetic predispositions. Therefore, we aimed to develop machine learning models
for CVD detection using primary healthcare data, compare the performance of
different models, and identify the best models. We used data from the UK
Biobank study, which included over 500,000 middle-aged participants from
different primary healthcare centers in the UK. Data collected at baseline
(2006--2010) and during imaging visits after 2014 were used in this study.
Baseline characteristics, including sex, age, and the Townsend Deprivation
Index, were included. Participants were classified as having CVD if they
reported at least one of the following conditions: heart attack, angina,
stroke, or high blood pressure. Cardiac imaging data such as electrocardiogram
and echocardiography data, including left ventricular size and function,
cardiac output, and stroke volume, were also used. We used 9 machine learning
models (LSVM, RBFSVM, GP, DT, RF, NN, AdaBoost, NB, and QDA), which are
explainable and easily interpretable. We reported the accuracy, precision,
recall, and F-1 scores; confusion matrices; and area under the curve (AUC)
curves.",2024-07-23,"Sheikh Mohammed Shariful Islam, Moloud Abrar, Teketo Tegegne, Liliana Loranjo, Chandan Karmakar, Md Abdul Awal, Md. Shahadat Hossain, Muhammad Ashad Kabir, Mufti Mahmud, Abbas Khosravi, George Siopis, Jeban C Moses, Ralph Maddison",http://arxiv.org/pdf/2407.16721v1,cs.LG
Reinforcement Learning-based Adaptive Mitigation of Uncorrected DRAM Errors in the Field,"Scaling to larger systems, with current levels of reliability, requires
cost-effective methods to mitigate hardware failures. One of the main causes of
hardware failure is an uncorrected error in memory, which terminates the
current job and wastes all computation since the last checkpoint. This paper
presents the first adaptive method for triggering uncorrected error mitigation.
It uses a prediction approach that considers the likelihood of an uncorrected
error and its current potential cost. The method is based on reinforcement
learning, and the only user-defined parameters are the mitigation cost and
whether the job can be restarted from a mitigation point. We evaluate our
method using classical machine learning metrics together with a cost-benefit
analysis, which compares the cost of mitigation actions with the benefits from
mitigating some of the errors. On two years of production logs from the
MareNostrum supercomputer, our method reduces lost compute time by 54% compared
with no mitigation and is just 6% below the optimal Oracle method. All source
code is open source.",2024-07-23,"Isaac Boixaderas, Sergi Moré, Javier Bartolome, David Vicente, Petar Radojković, Paul M. Carpenter, Eduard Ayguadé",http://arxiv.org/pdf/2407.16377v1,cs.LG
Bayesian Autoregressive Online Change-Point Detection with Time-Varying Parameters,"Change points in real-world systems mark significant regime shifts in system
dynamics, possibly triggered by exogenous or endogenous factors. These points
define regimes for the time evolution of the system and are crucial for
understanding transitions in financial, economic, social, environmental, and
technological contexts. Building upon the Bayesian approach introduced in
\cite{c:07}, we devise a new method for online change point detection in the
mean of a univariate time series, which is well suited for real-time
applications and is able to handle the general temporal patterns displayed by
data in many empirical contexts. We first describe time series as an
autoregressive process of an arbitrary order. Second, the variance and
correlation of the data are allowed to vary within each regime driven by a
scoring rule that updates the value of the parameters for a better fit of the
observations. Finally, a change point is detected in a probabilistic framework
via the posterior distribution of the current regime length. By modeling
temporal dependencies and time-varying parameters, the proposed approach
enhances both the estimate accuracy and the forecasting power. Empirical
validations using various datasets demonstrate the method's effectiveness in
capturing memory and dynamic patterns, offering deeper insights into the
non-stationary dynamics of real-world systems.",2024-07-23,"Ioanna-Yvonni Tsaknaki, Fabrizio Lillo, Piero Mazzarisi",http://arxiv.org/pdf/2407.16376v1,cs.LG
Navigating Uncertainty in Medical Image Segmentation,"We address the selection and evaluation of uncertain segmentation methods in
medical imaging and present two case studies: prostate segmentation,
illustrating that for minimal annotator variation simple deterministic models
can suffice, and lung lesion segmentation, highlighting the limitations of the
Generalized Energy Distance (GED) in model selection. Our findings lead to
guidelines for accurately choosing and developing uncertain segmentation
models, that integrate aleatoric and epistemic components. These guidelines are
designed to aid researchers and practitioners in better developing, selecting,
and evaluating uncertain segmentation methods, thereby facilitating enhanced
adoption and effective application of segmentation uncertainty in practice.",2024-07-23,"Kilian Zepf, Jes Frellsen, Aasa Feragen",http://arxiv.org/pdf/2407.16367v1,cs.LG
Online Learning with Sublinear Best-Action Queries,"In online learning, a decision maker repeatedly selects one of a set of
actions, with the goal of minimizing the overall loss incurred. Following the
recent line of research on algorithms endowed with additional predictive
features, we revisit this problem by allowing the decision maker to acquire
additional information on the actions to be selected. In particular, we study
the power of \emph{best-action queries}, which reveal beforehand the identity
of the best action at a given time step. In practice, predictive features may
be expensive, so we allow the decision maker to issue at most $k$ such queries.
We establish tight bounds on the performance any algorithm can achieve when
given access to $k$ best-action queries for different types of feedback models.
In particular, we prove that in the full feedback model, $k$ queries are enough
to achieve an optimal regret of $\Theta\left(\min\left\{\sqrt T, \frac
Tk\right\}\right)$. This finding highlights the significant multiplicative
advantage in the regret rate achievable with even a modest (sublinear) number
$k \in \Omega(\sqrt{T})$ of queries. Additionally, we study the challenging
setting in which the only available feedback is obtained during the time steps
corresponding to the $k$ best-action queries. There, we provide a tight regret
rate of $\Theta\left(\min\left\{\frac{T}{\sqrt
k},\frac{T^2}{k^2}\right\}\right)$, which improves over the standard
$\Theta\left(\frac{T}{\sqrt k}\right)$ regret rate for label efficient
prediction for $k \in \Omega(T^{2/3})$.",2024-07-23,"Matteo Russo, Andrea Celli, Riccardo Colini Baldeschi, Federico Fusco, Daniel Haimovich, Dima Karamshuk, Stefano Leonardi, Niek Tax",http://arxiv.org/pdf/2407.16355v1,cs.LG
Strike a Balance in Continual Panoptic Segmentation,"This study explores the emerging area of continual panoptic segmentation,
highlighting three key balances. First, we introduce past-class backtrace
distillation to balance the stability of existing knowledge with the
adaptability to new information. This technique retraces the features
associated with past classes based on the final label assignment results,
performing knowledge distillation targeting these specific features from the
previous model while allowing other features to flexibly adapt to new
information. Additionally, we introduce a class-proportional memory strategy,
which aligns the class distribution in the replay sample set with that of the
historical training data. This strategy maintains a balanced class
representation during replay, enhancing the utility of the limited-capacity
replay sample set in recalling prior classes. Moreover, recognizing that replay
samples are annotated only for the classes of their original step, we devise
balanced anti-misguidance losses, which combat the impact of incomplete
annotations without incurring classification bias. Building upon these
innovations, we present a new method named Balanced Continual Panoptic
Segmentation (BalConpas). Our evaluation on the challenging ADE20K dataset
demonstrates its superior performance compared to existing state-of-the-art
methods. The official code is available at
https://github.com/jinpeng0528/BalConpas.",2024-07-23,"Jinpeng Chen, Runmin Cong, Yuxuan Luo, Horace Ho Shing Ip, Sam Kwong",http://arxiv.org/pdf/2407.16354v1,cs.LG
Data-driven Multistage Distributionally Robust Linear Optimization with Nested Distance,"We study multistage distributionally robust linear optimization, where the
uncertainty set is defined as a ball of distribution centered at a scenario
tree using the nested distance. The resulting minimax problem is notoriously
difficult to solve due to its inherent non-convexity. In this paper, we
demonstrate that, under mild conditions, the robust risk evaluation of a given
policy can be expressed in an equivalent recursive form. Furthermore, assuming
stagewise independence, we derive equivalent dynamic programming reformulations
to find an optimal robust policy that is time-consistent and well-defined on
unseen sample paths. Our reformulations reconcile two modeling frameworks: the
multistage-static formulation (with nested distance) and the multistage-dynamic
formulation (with one-period Wasserstein distance). Moreover, we identify
tractable cases when the value functions can be computed efficiently using
convex optimization techniques.",2024-07-23,"Rui Gao, Rohit Arora, Yizhe Huang",http://arxiv.org/pdf/2407.16346v1,cs.LG
STATE: A Robust ATE Estimator of Heavy-Tailed Metrics for Variance Reduction in Online Controlled Experiments,"Online controlled experiments play a crucial role in enabling data-driven
decisions across a wide range of companies. Variance reduction is an effective
technique to improve the sensitivity of experiments, achieving higher
statistical power while using fewer samples and shorter experimental periods.
However, typical variance reduction methods (e.g., regression-adjusted
estimators) are built upon the intuitional assumption of Gaussian distributions
and cannot properly characterize the real business metrics with heavy-tailed
distributions. Furthermore, outliers diminish the correlation between
pre-experiment covariates and outcome metrics, greatly limiting the
effectiveness of variance reduction.
  In this paper, we develop a novel framework that integrates the Student's
t-distribution with machine learning tools to fit heavy-tailed metrics and
construct a robust average treatment effect estimator in online controlled
experiments, which we call STATE. By adopting a variational EM method to
optimize the loglikehood function, we can infer a robust solution that greatly
eliminates the negative impact of outliers and achieves significant variance
reduction. Moreover, we extend the STATE method from count metrics to ratio
metrics by utilizing linear transformation that preserves unbiased estimation,
whose variance reduction is more complex but less investigated in existing
works. Finally, both simulations on synthetic data and long-term empirical
results on Meituan experiment platform demonstrate the effectiveness of our
method. Compared with the state-of-the-art estimators (CUPAC/MLRATE), STATE
achieves over 50% variance reduction, indicating it can reach the same
statistical power with only half of the observations, or half the experimental
duration.",2024-07-23,"Hao Zhou, Kun Sun, Shaoming Li, Yangfeng Fan, Guibin Jiang, Jiaqi Zheng, Tao Li",http://arxiv.org/pdf/2407.16337v1,cs.LG
On The Expressive Power of Knowledge Graph Embedding Methods,"Knowledge Graph Embedding (KGE) is a popular approach, which aims to
represent entities and relations of a knowledge graph in latent spaces. Their
representations are known as embeddings. To measure the plausibility of
triplets, score functions are defined over embedding spaces. Despite wide
dissemination of KGE in various tasks, KGE methods have limitations in
reasoning abilities. In this paper we propose a mathematical framework to
compare reasoning abilities of KGE methods. We show that STransE has a higher
capability than TransComplEx, and then present new STransCoRe method, which
improves the STransE by combining it with the TransCoRe insights, which can
reduce the STransE space complexity.",2024-07-23,"Jiexing Gao, Dmitry Rodin, Vasily Motolygin, Denis Zaytsev",http://arxiv.org/pdf/2407.16326v2,cs.LG
Deep Learning for Pancreas Segmentation: a Systematic Review,"Pancreas segmentation has been traditionally challenging due to its small
size in computed tomography abdominal volumes, high variability of shape and
positions among patients, and blurred boundaries due to low contrast between
the pancreas and surrounding organs. Many deep learning models for pancreas
segmentation have been proposed in the past few years. We present a thorough
systematic review based on the Preferred Reporting Items for Systematic Reviews
and Meta-analyses (PRISMA) statement. The literature search was conducted on
PubMed, Web of Science, Scopus, and IEEE Xplore on original studies published
in peer-reviewed journals from 2013 to 2023. Overall, 130 studies were
retrieved. We initially provided an overview of the technical background of the
most common network architectures and publicly available datasets. Then, the
analysis of the studies combining visual presentation in tabular form and text
description was reported. The tables grouped the studies specifying the
application, dataset size, design (model architecture, learning strategy, and
loss function), results, and main contributions. We first analyzed the studies
focusing on parenchyma segmentation using coarse-to-fine approaches,
multi-organ segmentation, semi-supervised learning, and unsupervised learning,
followed by those studies on generalization to other datasets and those
concerning the design of new loss functions. Then, we analyzed the studies on
segmentation of tumors, cysts, and inflammation reporting multi-stage methods,
semi-supervised learning, generalization to other datasets, and design of new
loss functions. Finally, we provided a critical discussion on the subject based
on the published evidence underlining current issues that need to be addressed
before clinical translation.",2024-07-23,"Andrea Moglia, Matteo Cavicchioli, Luca Mainardi, Pietro Cerveri",http://arxiv.org/pdf/2407.16313v1,cs.LG
EffiSegNet: Gastrointestinal Polyp Segmentation through a Pre-Trained EfficientNet-based Network with a Simplified Decoder,"This work introduces EffiSegNet, a novel segmentation framework leveraging
transfer learning with a pre-trained Convolutional Neural Network (CNN)
classifier as its backbone. Deviating from traditional architectures with a
symmetric U-shape, EffiSegNet simplifies the decoder and utilizes full-scale
feature fusion to minimize computational cost and the number of parameters. We
evaluated our model on the gastrointestinal polyp segmentation task using the
publicly available Kvasir-SEG dataset, achieving state-of-the-art results.
Specifically, the EffiSegNet-B4 network variant achieved an F1 score of 0.9552,
mean Dice (mDice) 0.9483, mean Intersection over Union (mIoU) 0.9056, Precision
0.9679, and Recall 0.9429 with a pre-trained backbone - to the best of our
knowledge, the highest reported scores in the literature for this dataset.
Additional training from scratch also demonstrated exceptional performance
compared to previous work, achieving an F1 score of 0.9286, mDice 0.9207, mIoU
0.8668, Precision 0.9311 and Recall 0.9262. These results underscore the
importance of a well-designed encoder in image segmentation networks and the
effectiveness of transfer learning approaches.",2024-07-23,"Ioannis A. Vezakis, Konstantinos Georgas, Dimitrios Fotiadis, George K. Matsopoulos",http://arxiv.org/pdf/2407.16298v1,cs.LG
"A new Linear Time Bi-level $\ell_{1,\infty}$ projection ; Application to the sparsification of auto-encoders neural networks","The $\ell_{1,\infty}$ norm is an efficient-structured projection, but the
complexity of the best algorithm is, unfortunately, $\mathcal{O}\big(n m \log(n
m)\big)$ for a matrix $n\times m$.\\ In this paper, we propose a new bi-level
projection method, for which we show that the time complexity for the
$\ell_{1,\infty}$ norm is only $\mathcal{O}\big(n m \big)$ for a matrix
$n\times m$. Moreover, we provide a new $\ell_{1,\infty}$ identity with
mathematical proof and experimental validation. Experiments show that our
bi-level $\ell_{1,\infty}$ projection is $2.5$ times faster than the actual
fastest algorithm and provides the best sparsity while keeping the same
accuracy in classification applications.",2024-07-23,"Michel Barlaud, Guillaume Perez, Jean-Paul Marmorat",http://arxiv.org/pdf/2407.16293v2,cs.LG
Federated Learning for Face Recognition via Intra-subject Self-supervised Learning,"Federated Learning (FL) for face recognition aggregates locally optimized
models from individual clients to construct a generalized face recognition
model. However, previous studies present two major challenges: insufficient
incorporation of self-supervised learning and the necessity for clients to
accommodate multiple subjects. To tackle these limitations, we propose FedFS
(Federated Learning for personalized Face recognition via intra-subject
Self-supervised learning framework), a novel federated learning architecture
tailored to train personalized face recognition models without imposing
subjects. Our proposed FedFS comprises two crucial components that leverage
aggregated features of the local and global models to cooperate with
representations of an off-the-shelf model. These components are (1) adaptive
soft label construction, utilizing dot product operations to reformat labels
within intra-instances, and (2) intra-subject self-supervised learning,
employing cosine similarity operations to strengthen robust intra-subject
representations. Additionally, we introduce a regularization loss to prevent
overfitting and ensure the stability of the optimized model. To assess the
effectiveness of FedFS, we conduct comprehensive experiments on the DigiFace-1M
and VGGFace datasets, demonstrating superior performance compared to previous
methods.",2024-07-23,"Hansol Kim, Hoyeol Choi, Youngjun Kwak",http://arxiv.org/pdf/2407.16289v1,cs.LG
A deeper look at depth pruning of LLMs,"Large Language Models (LLMs) are not only resource-intensive to train but
even more costly to deploy in production. Therefore, recent work has attempted
to prune blocks of LLMs based on cheap proxies for estimating block importance,
effectively removing 10% of blocks in well-trained LLaMa-2 and Mistral 7b
models without any significant degradation of downstream metrics. In this
paper, we explore different block importance metrics by considering adaptive
metrics such as Shapley value in addition to static ones explored in prior
work. We show that adaptive metrics exhibit a trade-off in performance between
tasks i.e., improvement on one task may degrade performance on the other due to
differences in the computed block influences. Furthermore, we extend this
analysis from a complete block to individual self-attention and feed-forward
layers, highlighting the propensity of the self-attention layers to be more
amendable to pruning, even allowing removal of upto 33% of the self-attention
layers without incurring any performance degradation on MMLU for Mistral 7b
(significant reduction in costly maintenance of KV-cache). Finally, we look at
simple performance recovery techniques to emulate the pruned layers by training
lightweight additive bias or low-rank linear adapters. Performance recovery
using emulated updates avoids performance degradation for the initial blocks
(up to 5% absolute improvement on MMLU), which is either competitive or
superior to the learning-based technique.",2024-07-23,"Shoaib Ahmed Siddiqui, Xin Dong, Greg Heinrich, Thomas Breuel, Jan Kautz, David Krueger, Pavlo Molchanov",http://arxiv.org/pdf/2407.16286v1,cs.LG
Efficient Detection of Commutative Factors in Factor Graphs,"Lifted probabilistic inference exploits symmetries in probabilistic graphical
models to allow for tractable probabilistic inference with respect to domain
sizes. To exploit symmetries in, e.g., factor graphs, it is crucial to identify
commutative factors, i.e., factors having symmetries within themselves due to
their arguments being exchangeable. The current state of the art to check
whether a factor is commutative with respect to a subset of its arguments
iterates over all possible subsets of the factor's arguments, i.e., $O(2^n)$
iterations for a factor with $n$ arguments in the worst case. In this paper, we
efficiently solve the problem of detecting commutative factors in a factor
graph. In particular, we introduce the detection of commutative factors (DECOR)
algorithm, which allows us to drastically reduce the computational effort for
checking whether a factor is commutative in practice. We prove that DECOR
efficiently identifies restrictions to drastically reduce the number of
required iterations and validate the efficiency of DECOR in our empirical
evaluation.",2024-07-23,"Malte Luttermann, Johann Machemer, Marcel Gehrke",http://arxiv.org/pdf/2407.16280v1,cs.LG
Deep Learning based Key Information Extraction from Business Documents: Systematic Literature Review,"Extracting key information from documents represents a large portion of
business workloads and therefore offers a high potential for efficiency
improvements and process automation. With recent advances in deep learning, a
plethora of deep learning-based approaches for Key Information Extraction have
been proposed under the umbrella term Document Understanding that enable the
processing of complex business documents. The goal of this systematic
literature review is an in-depth analysis of existing approaches in this domain
and the identification of opportunities for further research. To this end, 96
approaches published between 2017 and 2023 are analyzed in this study.",2024-07-23,"Alexander Rombach, Peter Fettke",http://arxiv.org/pdf/2408.06345v1,cs.LG
Self-Reasoning Assistant Learning for non-Abelian Gauge Fields Design,"Non-Abelian braiding has attracted substantial attention because of its
pivotal role in describing the exchange behaviour of anyons, in which the input
and outcome of non-Abelian braiding are connected by a unitary matrix.
Implementing braiding in a classical system can assist the experimental
investigation of non-Abelian physics. However, the design of non-Abelian gauge
fields faces numerous challenges stemmed from the intricate interplay of group
structures, Lie algebra properties, representation theory, topology, and
symmetry breaking. The extreme diversity makes it a powerful tool for the study
of condensed matter physics. Whereas the widely used artificial intelligence
with data-driven approaches has greatly promoted the development of physics,
most works are limited on the data-to-data design. Here we propose a
self-reasoning assistant learning framework capable of directly generating
non-Abelian gauge fields. This framework utilizes the forward diffusion process
to capture and reproduce the complex patterns and details inherent in the
target distribution through continuous transformation. Then the reverse
diffusion process is used to make the generated data closer to the distribution
of the original situation. Thus, it owns strong self-reasoning capabilities,
allowing to automatically discover the feature representation and capture more
subtle relationships from the dataset. Moreover, the self-reasoning eliminates
the need for manual feature engineering and simplifies the process of model
building. Our framework offers a disruptive paradigm shift to parse complex
physical processes, automatically uncovering patterns from massive datasets.",2024-07-23,"Jinyang Sun, Xi Chen, Xiumei Wang, Dandan Zhu, Xingping Zhou",http://arxiv.org/pdf/2407.16255v1,cs.LG
Identifiable latent bandits: Combining observational data and exploration for personalized healthcare,"Bandit algorithms hold great promise for improving personalized
decision-making but are notoriously sample-hungry. In most health applications,
it is infeasible to fit a new bandit for each patient, and observable variables
are often insufficient to determine optimal treatments, ruling out applying
contextual bandits learned from multiple patients. Latent bandits offer both
rapid exploration and personalization beyond what context variables can reveal
but require that a latent variable model can be learned consistently. In this
work, we propose bandit algorithms based on nonlinear independent component
analysis that can be provably identified from observational data to a degree
sufficient to infer the optimal action in a new bandit instance consistently.
We verify this strategy in simulated data, showing substantial improvement over
learning independent multi-armed bandits for every instance.",2024-07-23,"Ahmet Zahid Balcıoğlu, Emil Carlsson, Fredrik D. Johansson",http://arxiv.org/pdf/2407.16239v2,cs.LG
OriGen:Enhancing RTL Code Generation with Code-to-Code Augmentation and Self-Reflection,"Recent studies have demonstrated the significant potential of Large Language
Models (LLMs) in generating Register Transfer Level (RTL) code, with notable
advancements showcased by commercial models such as GPT-4 and Claude3-Opus.
However, these proprietary LLMs often raise concerns regarding privacy and
security. While open-source LLMs offer solutions to these concerns, they
typically underperform commercial models in RTL code generation tasks,
primarily due to the scarcity of high-quality open-source RTL datasets. To
address this challenge, we introduce OriGen , a fully open-source framework
that incorporates self-reflection capabilities and a novel dataset augmentation
methodology for generating high-quality, large-scale RTL code. Our approach
employs a code-tocode augmentation technique to enhance the quality of
open-source RTL code datasets. Furthermore, OriGen can rectify syntactic errors
through a self-reflection process that leverages compiler feedback.
Experimental results demonstrate that OriGen significantly outperforms other
open-source alternatives in RTL code generation. It surpasses the previous
best-performing open-source LLM by 12.8% and even exceeds GPT-4 Turbo in the
pass@1 metric on the VerilogEval-Human benchmark. Moreover, OriGen exhibits
superior capabilities in self-reflection and error correction, outperforming
GPT-4 by 19.9% on a benchmark designed to evaluate self-reflection
capabilities.",2024-07-23,"Fan Cui, Chenyang Yin, Kexing Zhou, Youwei Xiao, Guangyu Sun, Qiang Xu, Qipeng Guo, Demin Song, Dahua Lin, Xingcheng Zhang, Yun, Liang",http://arxiv.org/pdf/2407.16237v2,cs.LG
Algebraic Adversarial Attacks on Integrated Gradients,"Adversarial attacks on explainability models have drastic consequences when
explanations are used to understand the reasoning of neural networks in safety
critical systems. Path methods are one such class of attribution methods
susceptible to adversarial attacks. Adversarial learning is typically phrased
as a constrained optimisation problem. In this work, we propose algebraic
adversarial examples and study the conditions under which one can generate
adversarial examples for integrated gradients. Algebraic adversarial examples
provide a mathematically tractable approach to adversarial examples.",2024-07-23,"Lachlan Simpson, Federico Costanza, Kyle Millar, Adriel Cheng, Cheng-Chew Lim, Hong Gunn Chew",http://arxiv.org/pdf/2407.16233v2,cs.LG
ODGR: Online Dynamic Goal Recognition,"Traditionally, Reinforcement Learning (RL) problems are aimed at optimization
of the behavior of an agent. This paper proposes a novel take on RL, which is
used to learn the policy of another agent, to allow real-time recognition of
that agent's goals. Goal Recognition (GR) has traditionally been framed as a
planning problem where one must recognize an agent's objectives based on its
observed actions. Recent approaches have shown how reinforcement learning can
be used as part of the GR pipeline, but are limited to recognizing predefined
goals and lack scalability in domains with a large goal space. This paper
formulates a novel problem, ""Online Dynamic Goal Recognition"" (ODGR), as a
first step to address these limitations. Contributions include introducing the
concept of dynamic goals into the standard GR problem definition, revisiting
common approaches by reformulating them using ODGR, and demonstrating the
feasibility of solving ODGR in a navigation domain using transfer learning.
These novel formulations open the door for future extensions of existing
transfer learning-based GR methods, which will be robust to changing and
expansive real-time environments.",2024-07-23,"Matan Shamir, Osher Elhadad, Matthew E. Taylor, Reuth Mirsky",http://arxiv.org/pdf/2407.16220v1,cs.LG
Strategy and Skill Learning for Physics-based Table Tennis Animation,"Recent advancements in physics-based character animation leverage deep
learning to generate agile and natural motion, enabling characters to execute
movements such as backflips, boxing, and tennis. However, reproducing the
selection and use of diverse motor skills in dynamic environments to solve
complex tasks, as humans do, still remains a challenge. We present a strategy
and skill learning approach for physics-based table tennis animation. Our
method addresses the issue of mode collapse, where the characters do not fully
utilize the motor skills they need to perform to execute complex tasks. More
specifically, we demonstrate a hierarchical control system for diversified
skill learning and a strategy learning framework for effective decision-making.
We showcase the efficacy of our method through comparative analysis with
state-of-the-art methods, demonstrating its capabilities in executing various
skills for table tennis. Our strategy learning framework is validated through
both agent-agent interaction and human-agent interaction in Virtual Reality,
handling both competitive and cooperative tasks.",2024-07-23,"Jiashun Wang, Jessica Hodgins, Jungdam Won",http://arxiv.org/pdf/2407.16210v1,cs.LG
LLMs can be Dangerous Reasoners: Analyzing-based Jailbreak Attack on Large Language Models,"The rapid development of Large Language Models (LLMs) has brought significant
advancements across various tasks. However, despite these achievements, LLMs
still exhibit inherent safety vulnerabilities, especially when confronted with
jailbreak attacks. Existing jailbreak methods suffer from two main limitations:
reliance on complicated prompt engineering and iterative optimization, which
lead to low attack success rate (ASR) and attack efficiency (AE). In this work,
we propose an efficient jailbreak attack method, Analyzing-based Jailbreak
(ABJ), which leverages the advanced reasoning capability of LLMs to
autonomously generate harmful content, revealing their underlying safety
vulnerabilities during complex reasoning process. We conduct comprehensive
experiments on ABJ across various open-source and closed-source LLMs. In
particular, ABJ achieves high ASR (82.1% on GPT-4o-2024-11-20) with exceptional
AE among all target LLMs, showcasing its remarkable attack effectiveness,
transferability, and efficiency. Our findings underscore the urgent need to
prioritize and improve the safety of LLMs to mitigate the risks of misuse.",2024-07-23,"Shi Lin, Hongming Yang, Dingyang Lin, Rongchang Li, Xun Wang, Changting Lin, Wenpeng Xing, Meng Han",http://arxiv.org/pdf/2407.16205v5,cs.LG
Automatic Environment Shaping is the Next Frontier in RL,"Many roboticists dream of presenting a robot with a task in the evening and
returning the next morning to find the robot capable of solving the task. What
is preventing us from achieving this? Sim-to-real reinforcement learning (RL)
has achieved impressive performance on challenging robotics tasks, but requires
substantial human effort to set up the task in a way that is amenable to RL.
It's our position that algorithmic improvements in policy optimization and
other ideas should be guided towards resolving the primary bottleneck of
shaping the training environment, i.e., designing observations, actions,
rewards and simulation dynamics. Most practitioners don't tune the RL
algorithm, but other environment parameters to obtain a desirable controller.
We posit that scaling RL to diverse robotic tasks will only be achieved if the
community focuses on automating environment shaping procedures.",2024-07-23,"Younghyo Park, Gabriel B. Margolis, Pulkit Agrawal",http://arxiv.org/pdf/2407.16186v1,cs.LG
Logifold: A Geometrical Foundation of Ensemble Machine Learning,"We present a local-to-global and measure-theoretical approach to
understanding datasets. The core idea is to formulate a logifold structure and
to interpret network models with restricted domains as local charts of
datasets. In particular, this provides a mathematical foundation for ensemble
machine learning. Our experiments demonstrate that logifolds can be implemented
to identify fuzzy domains and improve accuracy compared to taking average of
model outputs. Additionally, we provide a theoretical example of a logifold,
highlighting the importance of restricting to domains of classifiers in an
ensemble.",2024-07-23,"Inkee Jung, Siu-Cheong Lau",http://arxiv.org/pdf/2407.16177v2,cs.LG
Pixel Embedding: Fully Quantized Convolutional Neural Network with Differentiable Lookup Table,"By quantizing network weights and activations to low bitwidth, we can obtain
hardware-friendly and energy-efficient networks. However, existing quantization
techniques utilizing the straight-through estimator and piecewise constant
functions face the issue of how to represent originally high-bit input data
with low-bit values. To fully quantize deep neural networks, we propose pixel
embedding, which replaces each float-valued input pixel with a vector of
quantized values by using a lookup table. The lookup table or low-bit
representation of pixels is differentiable and trainable by backpropagation.
Such replacement of inputs with vectors is similar to word embedding in the
natural language processing field. Experiments on ImageNet and CIFAR-100 show
that pixel embedding reduces the top-5 error gap caused by quantizing the
floating points at the first layer to only 1% for the ImageNet dataset, and the
top-1 error gap caused by quantizing first and last layers to slightly over 1%
for the CIFAR-100 dataset. The usefulness of pixel embedding is further
demonstrated by inference time measurements, which demonstrate over 1.7 times
speedup compared to floating point precision first layer.",2024-07-23,"Hiroyuki Tokunaga, Joel Nicholls, Daria Vazhenina, Atsunori Kanemura",http://arxiv.org/pdf/2407.16174v1,cs.LG
Advanced AI Framework for Enhanced Detection and Assessment of Abdominal Trauma: Integrating 3D Segmentation with 2D CNN and RNN Models,"Trauma is a significant cause of mortality and disability, particularly among
individuals under forty. Traditional diagnostic methods for traumatic injuries,
such as X-rays, CT scans, and MRI, are often time-consuming and dependent on
medical expertise, which can delay critical interventions. This study explores
the application of artificial intelligence (AI) and machine learning (ML) to
improve the speed and accuracy of abdominal trauma diagnosis. We developed an
advanced AI-based model combining 3D segmentation, 2D Convolutional Neural
Networks (CNN), and Recurrent Neural Networks (RNN) to enhance diagnostic
performance. Our model processes abdominal CT scans to provide real-time,
precise assessments, thereby improving clinical decision-making and patient
outcomes. Comprehensive experiments demonstrated that our approach
significantly outperforms traditional diagnostic methods, as evidenced by
rigorous evaluation metrics. This research sets a new benchmark for automated
trauma detection, leveraging the strengths of AI and ML to revolutionize trauma
care.",2024-07-23,"Liheng Jiang, Xuechun yang, Chang Yu, Zhizhong Wu, Yuting Wang",http://arxiv.org/pdf/2407.16165v1,cs.LG
Representation Magnitude has a Liability to Privacy Vulnerability,"The privacy-preserving approaches to machine learning (ML) models have made
substantial progress in recent years. However, it is still opaque in which
circumstances and conditions the model becomes privacy-vulnerable, leading to a
challenge for ML models to maintain both performance and privacy. In this
paper, we first explore the disparity between member and non-member data in the
representation of models under common training frameworks. We identify how the
representation magnitude disparity correlates with privacy vulnerability and
address how this correlation impacts privacy vulnerability. Based on the
observations, we propose Saturn Ring Classifier Module (SRCM), a plug-in
model-level solution to mitigate membership privacy leakage. Through a confined
yet effective representation space, our approach ameliorates models' privacy
vulnerability while maintaining generalizability. The code of this work can be
found here: \url{https://github.com/JEKimLab/AIES2024_SRCM}",2024-07-23,"Xingli Fang, Jung-Eun Kim",http://arxiv.org/pdf/2407.16164v1,cs.LG
TransFeat-TPP: An Interpretable Deep Covariate Temporal Point Processes,"The classical temporal point process (TPP) constructs an intensity function
by taking the occurrence times into account. Nevertheless, occurrence time may
not be the only relevant factor, other contextual data, termed covariates, may
also impact the event evolution. Incorporating such covariates into the model
is beneficial, while distinguishing their relevance to the event dynamics is of
great practical significance. In this work, we propose a Transformer-based
covariate temporal point process (TransFeat-TPP) model to improve the
interpretability of deep covariate-TPPs while maintaining powerful
expressiveness. TransFeat-TPP can effectively model complex relationships
between events and covariates, and provide enhanced interpretability by
discerning the importance of various covariates. Experimental results on
synthetic and real datasets demonstrate improved prediction accuracy and
consistently interpretable feature importance when compared to existing deep
covariate-TPPs.",2024-07-23,"Zizhuo Meng, Boyu Li, Xuhui Fan, Zhidong Li, Yang Wang, Fang Chen, Feng Zhou",http://arxiv.org/pdf/2407.16161v1,cs.LG
Estimating Environmental Cost Throughout Model's Adaptive Life Cycle,"With the rapid increase in the research, development, and application of
neural networks in the current era, there is a proportional increase in the
energy needed to train and use models. Crucially, this is accompanied by the
increase in carbon emissions into the environment. A sustainable and socially
beneficial approach to reducing the carbon footprint and rising energy demands
associated with the modern age of AI/deep learning is the adaptive and
continuous reuse of models with regard to changes in the environment of model
deployment or variations/changes in the input data. In this paper, we propose
PreIndex, a predictive index to estimate the environmental and compute
resources associated with model retraining to distributional shifts in data.
PreIndex can be used to estimate environmental costs such as carbon emissions
and energy usage when retraining from current data distribution to new data
distribution. It also correlates with and can be used to estimate other
resource indicators associated with deep learning, such as epochs, gradient
norm, and magnitude of model parameter change. PreIndex requires only one
forward pass of the data, following which it provides a single concise value to
estimate resources associated with retraining to the new distribution shifted
data. We show that PreIndex can be reliably used across various datasets, model
architectures, different types, and intensities of distribution shifts. Thus,
PreIndex enables users to make informed decisions for retraining to different
distribution shifts and determine the most cost-effective and sustainable
option, allowing for the reuse of a model with a much smaller footprint in the
environment. The code for this work is available here:
https://github.com/JEKimLab/AIES2024PreIndex",2024-07-23,"Vishwesh Sangarya, Richard Bradford, Jung-Eun Kim",http://arxiv.org/pdf/2408.01446v1,cs.LG
Exploring The Neural Burden In Pruned Models: An Insight Inspired By Neuroscience,"Vision Transformer and its variants have been adopted in many visual tasks
due to their powerful capabilities, which also bring significant challenges in
computation and storage. Consequently, researchers have introduced various
compression methods in recent years, among which the pruning techniques are
widely used to remove a significant fraction of the network. Therefore, these
methods can reduce significant percent of the FLOPs, but often lead to a
decrease in model performance. To investigate the underlying causes, we focus
on the pruning methods specifically belonging to the pruning-during-training
category, then drew inspiration from neuroscience and propose a new concept for
artificial neural network models named Neural Burden. We investigate its impact
in the model pruning process, and subsequently explore a simple yet effective
approach to mitigate the decline in model performance, which can be applied to
any pruning-during-training technique. Extensive experiments indicate that the
neural burden phenomenon indeed exists, and show the potential of our method.
We hope that our findings can provide valuable insights for future research.
Code will be made publicly available after this paper is published.",2024-07-23,"Zeyu Wang, Weichen Dai, Xiangyu Zhou, Ji Qi, Yi Zhou",http://arxiv.org/pdf/2407.16716v2,cs.LG
On the Benefits of Rank in Attention Layers,"Attention-based mechanisms are widely used in machine learning, most
prominently in transformers. However, hyperparameters such as the rank of the
attention matrices and the number of heads are scaled nearly the same way in
all realizations of this architecture, without theoretical justification. In
this work we show that there are dramatic trade-offs between the rank and
number of heads of the attention mechanism. Specifically, we present a simple
and natural target function that can be represented using a single full-rank
attention head for any context length, but that cannot be approximated by
low-rank attention unless the number of heads is exponential in the embedding
dimension, even for short context lengths. Moreover, we prove that, for short
context lengths, adding depth allows the target to be approximated by low-rank
attention. For long contexts, we conjecture that full-rank attention is
necessary. Finally, we present experiments with off-the-shelf transformers that
validate our theoretical findings.",2024-07-23,"Noah Amsel, Gilad Yehudai, Joan Bruna",http://arxiv.org/pdf/2407.16153v1,cs.LG
Predicting Stock Prices with FinBERT-LSTM: Integrating News Sentiment Analysis,"The stock market's ascent typically mirrors the flourishing state of the
economy, whereas its decline is often an indicator of an economic downturn.
Therefore, for a long time, significant correlation elements for predicting
trends in financial stock markets have been widely discussed, and people are
becoming increasingly interested in the task of financial text mining. The
inherent instability of stock prices makes them acutely responsive to
fluctuations within the financial markets. In this article, we use deep
learning networks, based on the history of stock prices and articles of
financial, business, technical news that introduce market information to
predict stock prices. We illustrate the enhancement of predictive precision by
integrating weighted news categories into the forecasting model. We developed a
pre-trained NLP model known as FinBERT, designed to discern the sentiments
within financial texts. Subsequently, we advanced this model by incorporating
the sophisticated Long Short Term Memory (LSTM) architecture, thus constructing
the innovative FinBERT-LSTM model. This model utilizes news categories related
to the stock market structure hierarchy, namely market, industry, and stock
related news categories, combined with the stock market's stock price situation
in the previous week for prediction. We selected NASDAQ-100 index stock data
and trained the model on Benzinga news articles, and utilized Mean Absolute
Error (MAE), Mean Absolute Percentage Error (MAPE), and Accuracy as the key
metrics for the assessment and comparative analysis of the model's performance.
The results indicate that FinBERT-LSTM performs the best, followed by LSTM, and
DNN model ranks third in terms of effectiveness.",2024-07-23,"Wenjun Gu, Yihao Zhong, Shizun Li, Changsong Wei, Liting Dong, Zhuoyue Wang, Chao Yan",http://arxiv.org/pdf/2407.16150v1,cs.LG
Research on Adverse Drug Reaction Prediction Model Combining Knowledge Graph Embedding and Deep Learning,"In clinical treatment, identifying potential adverse reactions of drugs can
help assist doctors in making medication decisions. In response to the problems
in previous studies that features are high-dimensional and sparse, independent
prediction models need to be constructed for each adverse reaction of drugs,
and the prediction accuracy is low, this paper develops an adverse drug
reaction prediction model based on knowledge graph embedding and deep learning,
which can predict experimental results. Unified prediction of adverse drug
reactions covered. Knowledge graph embedding technology can fuse the associated
information between drugs and alleviate the shortcomings of high-dimensional
sparsity in feature matrices, and the efficient training capabilities of deep
learning can improve the prediction accuracy of the model. This article builds
an adverse drug reaction knowledge graph based on drug feature data; by
analyzing the embedding effect of the knowledge graph under different embedding
strategies, the best embedding strategy is selected to obtain sample vectors;
and then a convolutional neural network model is constructed to predict adverse
reactions. The results show that under the DistMult embedding model and
400-dimensional embedding strategy, the convolutional neural network model has
the best prediction effect; the average accuracy, F_1 score, recall rate and
area under the curve of repeated experiments are better than the methods
reported in the literature. The obtained prediction model has good prediction
accuracy and stability, and can provide an effective reference for later safe
medication guidance.",2024-07-23,"Yufeng Li, Wenchao Zhao, Bo Dang, Xu Yan, Weimin Wang, Min Gao, Mingxuan Xiao",http://arxiv.org/pdf/2407.16715v2,cs.LG
Improved Few-Shot Image Classification Through Multiple-Choice Questions,"Through a simple multiple choice language prompt a VQA model can operate as a
zero-shot image classifier, producing a classification label. Compared to
typical image encoders, VQA models offer an advantage: VQA-produced image
embeddings can be infused with the most relevant visual information through
tailored language prompts. Nevertheless, for most tasks, zero-shot VQA
performance is lacking, either because of unfamiliar category names, or
dissimilar pre-training data and test data distributions. We propose a simple
method to boost VQA performance for image classification using only a handful
of labeled examples and a multiple-choice question. This few-shot method is
training-free and maintains the dynamic and flexible advantages of the VQA
model. Rather than relying on the final language output, our approach uses
multiple-choice questions to extract prompt-specific latent representations,
which are enriched with relevant visual information. These representations are
combined to create a final overall image embedding, which is decoded via
reference to latent class prototypes constructed from the few labeled examples.
We demonstrate this method outperforms both pure visual encoders and zero-shot
VQA baselines to achieve impressive performance on common few-shot tasks
including MiniImageNet, Caltech-UCSD Birds, and CIFAR-100. Finally, we show our
approach does particularly well in settings with numerous diverse visual
attributes such as the fabric, article-style, texture, and view of different
articles of clothing, where other few-shot approaches struggle, as we can
tailor our image representations only on the semantic features of interest.",2024-07-23,"Dipika Khullar, Emmett Goodman, Negin Sokhandan",http://arxiv.org/pdf/2407.16145v1,cs.LG
Diffusion Models as Optimizers for Efficient Planning in Offline RL,"Diffusion models have shown strong competitiveness in offline reinforcement
learning tasks by formulating decision-making as sequential generation.
However, the practicality of these methods is limited due to the lengthy
inference processes they require. In this paper, we address this problem by
decomposing the sampling process of diffusion models into two decoupled
subprocesses: 1) generating a feasible trajectory, which is a time-consuming
process, and 2) optimizing the trajectory. With this decomposition approach, we
are able to partially separate efficiency and quality factors, enabling us to
simultaneously gain efficiency advantages and ensure quality assurance. We
propose the Trajectory Diffuser, which utilizes a faster autoregressive model
to handle the generation of feasible trajectories while retaining the
trajectory optimization process of diffusion models. This allows us to achieve
more efficient planning without sacrificing capability. To evaluate the
effectiveness and efficiency of the Trajectory Diffuser, we conduct experiments
on the D4RL benchmarks. The results demonstrate that our method achieves $\it
3$-$\it 10 \times$ faster inference speed compared to previous sequence
modeling methods, while also outperforming them in terms of overall
performance. https://github.com/RenMing-Huang/TrajectoryDiffuser
  Keywords: Reinforcement Learning and Efficient Planning and Diffusion Model",2024-07-23,"Renming Huang, Yunqiang Pei, Guoqing Wang, Yangming Zhang, Yang Yang, Peng Wang, Hengtao Shen",http://arxiv.org/pdf/2407.16142v1,cs.LG
Tackling Feature-Classifier Mismatch in Federated Learning via Prompt-Driven Feature Transformation,"In traditional Federated Learning approaches like FedAvg, the global model
underperforms when faced with data heterogeneity. Personalized Federated
Learning (PFL) enables clients to train personalized models to fit their local
data distribution better. However, we surprisingly find that the feature
extractor in FedAvg is superior to those in most PFL methods. More
interestingly, by applying a linear transformation on local features extracted
by the feature extractor to align with the classifier, FedAvg can surpass the
majority of PFL methods. This suggests that the primary cause of FedAvg's
inadequate performance stems from the mismatch between the locally extracted
features and the classifier. While current PFL methods mitigate this issue to
some extent, their designs compromise the quality of the feature extractor,
thus limiting the full potential of PFL. In this paper, we propose a new PFL
framework called FedPFT to address the mismatch problem while enhancing the
quality of the feature extractor. FedPFT integrates a feature transformation
module, driven by personalized prompts, between the global feature extractor
and classifier. In each round, clients first train prompts to transform local
features to match the global classifier, followed by training model parameters.
This approach can also align the training objectives of clients, reducing the
impact of data heterogeneity on model collaboration. Moreover, FedPFT's feature
transformation module is highly scalable, allowing for the use of different
prompts to tailor local features to various tasks. Leveraging this, we
introduce a collaborative contrastive learning task to further refine feature
extractor quality. Our experiments demonstrate that FedPFT outperforms
state-of-the-art methods by up to 7.08%.",2024-07-23,"Xinghao Wu, Jianwei Niu, Xuefeng Liu, Mingjia Shi, Guogang Zhu, Shaojie Tang",http://arxiv.org/pdf/2407.16139v1,cs.LG
Evaluating Long Range Dependency Handling in Code Generation Models using Multi-Step Key Retrieval,"As language models support larger and larger context sizes, evaluating their
ability to make effective use of that context becomes increasingly important.
We analyze the ability of several code generation models to handle long range
dependencies using a suite of multi-step key retrieval tasks in context windows
up to 8k tokens in length. The tasks progressively increase in difficulty and
allow more nuanced evaluation of model capabilities than tests like the popular
needle-in-the-haystack test. We find that performance degrades significantly
(up to 2x) when a function references another function that is defined later in
the prompt. We also observe that models that use sliding window attention
mechanisms have difficulty handling references further than the size of a
single window. We perform simple prompt modifications using call graph
information to improve multi-step retrieval performance up to 3x. Our analysis
highlights different facets of long-context performance and is suggestive of
prompt construction strategies for code completion tools",2024-07-23,"Yannick Assogba, Donghao Ren",http://arxiv.org/pdf/2407.21049v1,cs.LG
Diffusion Transformer Captures Spatial-Temporal Dependencies: A Theory for Gaussian Process Data,"Diffusion Transformer, the backbone of Sora for video generation,
successfully scales the capacity of diffusion models, pioneering new avenues
for high-fidelity sequential data generation. Unlike static data such as
images, sequential data consists of consecutive data frames indexed by time,
exhibiting rich spatial and temporal dependencies. These dependencies represent
the underlying dynamic model and are critical to validate the generated data.
In this paper, we make the first theoretical step towards bridging diffusion
transformers for capturing spatial-temporal dependencies. Specifically, we
establish score approximation and distribution estimation guarantees of
diffusion transformers for learning Gaussian process data with covariance
functions of various decay patterns. We highlight how the spatial-temporal
dependencies are captured and affect learning efficiency. Our study proposes a
novel transformer approximation theory, where the transformer acts to unroll an
algorithm. We support our theoretical results by numerical experiments,
providing strong evidence that spatial-temporal dependencies are captured
within attention layers, aligning with our approximation theory.",2024-07-23,"Hengyu Fu, Zehao Dou, Jiawei Guo, Mengdi Wang, Minshuo Chen",http://arxiv.org/pdf/2407.16134v2,cs.LG
CrysToGraph: A Comprehensive Predictive Model for Crystal Materials Properties and the Benchmark,"The ionic bonding across the lattice and ordered microscopic structures endow
crystals with unique symmetry and determine their macroscopic properties.
Unconventional crystals, in particular, exhibit non-traditional lattice
structures or possess exotic physical properties, making them intriguing
subjects for investigation. Therefore, to accurately predict the physical and
chemical properties of crystals, it is crucial to consider long-range orders.
While GNN excels at capturing the local environment of atoms in crystals, they
often face challenges in effectively capturing longer-ranged interactions due
to their limited depth. In this paper, we propose CrysToGraph
($\textbf{Crys}$tals with $\textbf{T}$ransformers $\textbf{o}$n
$\textbf{Graph}$s), a novel transformer-based geometric graph network designed
specifically for unconventional crystalline systems, and UnconvBench, a
comprehensive benchmark to evaluate models' predictive performance on
unconventional crystal materials such as defected crystals, low-dimension
crystals and MOF. CrysToGraph effectively captures short-range interactions
with transformer-based graph convolution blocks as well as long-range
interactions with graph-wise transformer blocks. CrysToGraph proofs its
effectiveness in modelling unconventional crystal materials in multiple tasks,
and moreover, it outperforms most existing methods, achieving new
state-of-the-art results on the benchmarks of both unconventional crystals and
traditional crystals.",2024-07-23,"Hongyi Wang, Ji Sun, Jinzhe Liang, Li Zhai, Zitian Tang, Zijian Li, Wei Zhai, Xusheng Wang, Weihao Gao, Sheng Gong",http://arxiv.org/pdf/2407.16131v2,cs.LG
Masked Graph Learning with Recurrent Alignment for Multimodal Emotion Recognition in Conversation,"Since Multimodal Emotion Recognition in Conversation (MERC) can be applied to
public opinion monitoring, intelligent dialogue robots, and other fields, it
has received extensive research attention in recent years. Unlike traditional
unimodal emotion recognition, MERC can fuse complementary semantic information
between multiple modalities (e.g., text, audio, and vision) to improve emotion
recognition. However, previous work ignored the inter-modal alignment process
and the intra-modal noise information before multimodal fusion but directly
fuses multimodal features, which will hinder the model for representation
learning. In this study, we have developed a novel approach called Masked Graph
Learning with Recursive Alignment (MGLRA) to tackle this problem, which uses a
recurrent iterative module with memory to align multimodal features, and then
uses the masked GCN for multimodal feature fusion. First, we employ LSTM to
capture contextual information and use a graph attention-filtering mechanism to
eliminate noise effectively within the modality. Second, we build a recurrent
iteration module with a memory function, which can use communication between
different modalities to eliminate the gap between modalities and achieve the
preliminary alignment of features between modalities. Then, a cross-modal
multi-head attention mechanism is introduced to achieve feature alignment
between modalities and construct a masked GCN for multimodal feature fusion,
which can perform random mask reconstruction on the nodes in the graph to
obtain better node feature representation. Finally, we utilize a multilayer
perceptron (MLP) for emotion recognition. Extensive experiments on two
benchmark datasets (i.e., IEMOCAP and MELD) demonstrate that {MGLRA}
outperforms state-of-the-art methods.",2024-07-23,"Tao Meng, Fuchen Zhang, Yuntao Shou, Hongen Shao, Wei Ai, Keqin Li",http://arxiv.org/pdf/2407.16714v1,cs.LG
Towards Effective Fusion and Forecasting of Multimodal Spatio-temporal Data for Smart Mobility,"With the rapid development of location based services, multimodal
spatio-temporal (ST) data including trajectories, transportation modes, traffic
flow and social check-ins are being collected for deep learning based methods.
These deep learning based methods learn ST correlations to support the
downstream tasks in the fields such as smart mobility, smart city and other
intelligent transportation systems. Despite their effectiveness, ST data fusion
and forecasting methods face practical challenges in real-world scenarios.
First, forecasting performance for ST data-insufficient area is inferior,
making it necessary to transfer meta knowledge from heterogeneous area to
enhance the sparse representations. Second, it is nontrivial to accurately
forecast in multi-transportation-mode scenarios due to the fine-grained ST
features of similar transportation modes, making it necessary to distinguish
and measure the ST correlations to alleviate the influence caused by entangled
ST features. At last, partial data modalities (e.g., transportation mode) are
lost due to privacy or technical issues in certain scenarios, making it
necessary to effectively fuse the multimodal sparse ST features and enrich the
ST representations. To tackle these challenges, our research work aim to
develop effective fusion and forecasting methods for multimodal ST data in
smart mobility scenario. In this paper, we will introduce our recent works that
investigates the challenges in terms of various real-world applications and
establish the open challenges in this field for future work.",2024-07-23,Chenxing Wang,http://arxiv.org/pdf/2407.16123v1,cs.LG
Uncertainty-Aware Deep Neural Representations for Visual Analysis of Vector Field Data,"The widespread use of Deep Neural Networks (DNNs) has recently resulted in
their application to challenging scientific visualization tasks. While advanced
DNNs demonstrate impressive generalization abilities, understanding factors
like prediction quality, confidence, robustness, and uncertainty is crucial.
These insights aid application scientists in making informed decisions.
However, DNNs lack inherent mechanisms to measure prediction uncertainty,
prompting the creation of distinct frameworks for constructing robust
uncertainty-aware models tailored to various visualization tasks. In this work,
we develop uncertainty-aware implicit neural representations to model
steady-state vector fields effectively. We comprehensively evaluate the
efficacy of two principled deep uncertainty estimation techniques: (1) Deep
Ensemble and (2) Monte Carlo Dropout, aimed at enabling uncertainty-informed
visual analysis of features within steady vector field data. Our detailed
exploration using several vector data sets indicate that uncertainty-aware
models generate informative visualization results of vector field features.
Furthermore, incorporating prediction uncertainty improves the resilience and
interpretability of our DNN model, rendering it applicable for the analysis of
non-trivial vector field data sets.",2024-07-23,"Atul Kumar, Siddharth Garg, Soumya Dutta",http://arxiv.org/pdf/2407.16119v2,cs.LG
Transformer-based Graph Neural Networks for Battery Range Prediction in AIoT Battery-Swap Services,"The concept of the sharing economy has gained broad recognition, and within
this context, Sharing E-Bike Battery (SEB) have emerged as a focal point of
societal interest. Despite the popularity, a notable discrepancy remains
between user expectations regarding the remaining battery range of SEBs and the
reality, leading to a pronounced inclination among users to find an available
SEB during emergency situations. In response to this challenge, the integration
of Artificial Intelligence of Things (AIoT) and battery-swap services has
surfaced as a viable solution. In this paper, we propose a novel structural
Transformer-based model, referred to as the SEB-Transformer, designed
specifically for predicting the battery range of SEBs. The scenario is
conceptualized as a dynamic heterogeneous graph that encapsulates the
interactions between users and bicycles, providing a comprehensive framework
for analysis. Furthermore, we incorporate the graph structure into the
SEB-Transformer to facilitate the estimation of the remaining e-bike battery
range, in conjunction with mean structural similarity, enhancing the prediction
accuracy. By employing the predictions made by our model, we are able to
dynamically adjust the optimal cycling routes for users in real-time, while
also considering the strategic locations of charging stations, thereby
optimizing the user experience. Empirically our results on real-world datasets
demonstrate the superiority of our model against nine competitive baselines.
These innovations, powered by AIoT, not only bridge the gap between user
expectations and the physical limitations of battery range but also
significantly improve the operational efficiency and sustainability of SEB
services. Through these advancements, the shared electric bicycle ecosystem is
evolving, making strides towards a more reliable, user-friendly, and
sustainable mode of transportation.",2024-07-23,"Zhao Li, Yang Liu, Chuan Zhou, Xuanwu Liu, Xuming Pan, Buqing Cao, Xindong Wu",http://arxiv.org/pdf/2407.16115v2,cs.LG
MiranDa: Mimicking the Learning Processes of Human Doctors to Achieve Causal Inference for Medication Recommendation,"To enhance therapeutic outcomes from a pharmacological perspective, we
propose MiranDa, designed for medication recommendation, which is the first
actionable model capable of providing the estimated length of stay in hospitals
(ELOS) as counterfactual outcomes that guide clinical practice and model
training. In detail, MiranDa emulates the educational trajectory of doctors
through two gradient-scaling phases shifted by ELOS: an Evidence-based Training
Phase that utilizes supervised learning and a Therapeutic Optimization Phase
grounds in reinforcement learning within the gradient space, explores optimal
medications by perturbations from ELOS. Evaluation of the Medical Information
Mart for Intensive Care III dataset and IV dataset, showcased the superior
results of our model across five metrics, particularly in reducing the ELOS.
Surprisingly, our model provides structural attributes of medication
combinations proved in hyperbolic space and advocated ""procedure-specific""
medication combinations. These findings posit that MiranDa enhanced medication
efficacy. Notably, our paradigm can be applied to nearly all medical tasks and
those with information to evaluate predicted outcomes. The source code of the
MiranDa model is available at https://github.com/azusakou/MiranDa.",2024-07-23,"Ziheng Wang, Xinhe Li, Haruki Momma, Ryoichi Nagatomi",http://arxiv.org/pdf/2408.01445v1,cs.LG
Reinforcement Learning Pair Trading: A Dynamic Scaling approach,"Cryptocurrency is a cryptography-based digital asset with extremely volatile
prices. Around USD 70 billion worth of cryptocurrency is traded daily on
exchanges. Trading cryptocurrency is difficult due to the inherent volatility
of the crypto market. This study investigates whether Reinforcement Learning
(RL) can enhance decision-making in cryptocurrency algorithmic trading compared
to traditional methods. In order to address this question, we combined
reinforcement learning with a statistical arbitrage trading technique, pair
trading, which exploits the price difference between statistically correlated
assets. We constructed RL environments and trained RL agents to determine when
and how to trade pairs of cryptocurrencies. We developed new reward shaping and
observation/action spaces for reinforcement learning. We performed experiments
with the developed reinforcement learner on pairs of BTC-GBP and BTC-EUR data
separated by 1 min intervals (n=263,520). The traditional non-RL pair trading
technique achieved an annualized profit of 8.33%, while the proposed RL-based
pair trading technique achieved annualized profits from 9.94% to 31.53%,
depending upon the RL learner. Our results show that RL can significantly
outperform manual and traditional pair trading techniques when applied to
volatile markets such as~cryptocurrencies.",2024-07-23,"Hongshen Yang, Avinash Malik",http://arxiv.org/pdf/2407.16103v2,cs.LG
Universal Spectral Transfer with Physical Prior-Informed Deep Generative Learning,"Spectroscopy is a powerful analytical technique for characterizing matter
across physical and biological realms1-5. However, its fundamental principle
necessitates specialized instrumentation per physical phenomena probed,
limiting broad adoption and use in all relevant research. In this study, we
introduce SpectroGen, a novel physical prior-informed deep generative model for
generating relevant spectral signatures across modalities using experimentally
collected spectral input only from a single modality. We achieve this by
reimagining the representation of spectral data as mathematical constructs of
distributions instead of their traditional physical and molecular state
representations. The results from 319 standard mineral samples tested
demonstrate generating with 99% correlation and 0.01 root mean square error
with superior resolution than experimentally acquired ground truth spectra. We
showed transferring capability across Raman, Infrared, and X-ray Diffraction
modalities with Gaussian, Lorentzian, and Voigt distribution priors
respectively6-10. This approach however is globally generalizable for any
spectral input that can be represented by a distribution prior, making it
universally applicable. We believe our work revolutionizes the application
sphere of spectroscopy, which has traditionally been limited by access to the
required sophisticated and often expensive equipment towards accelerating
material, pharmaceutical, and biological discoveries.",2024-07-22,"Yanmin Zhu, Loza F. Tadesse",http://arxiv.org/pdf/2407.16094v1,cs.LG
Early Recognition of Parkinson's Disease Through Acoustic Analysis and Machine Learning,"Parkinson's Disease (PD) is a progressive neurodegenerative disorder that
significantly impacts both motor and non-motor functions, including speech.
Early and accurate recognition of PD through speech analysis can greatly
enhance patient outcomes by enabling timely intervention. This paper provides a
comprehensive review of methods for PD recognition using speech data,
highlighting advances in machine learning and data-driven approaches. We
discuss the process of data wrangling, including data collection, cleaning,
transformation, and exploratory data analysis, to prepare the dataset for
machine learning applications. Various classification algorithms are explored,
including logistic regression, SVM, and neural networks, with and without
feature selection. Each method is evaluated based on accuracy, precision, and
training time. Our findings indicate that specific acoustic features and
advanced machine-learning techniques can effectively differentiate between
individuals with PD and healthy controls. The study concludes with a comparison
of the different models, identifying the most effective approaches for PD
recognition, and suggesting potential directions for future research.",2024-07-22,"Niloofar Fadavi, Nazanin Fadavi",http://arxiv.org/pdf/2407.16091v1,cs.LG
Self-driving lab discovers principles for steering spontaneous emission,"We developed an autonomous experimentation platform to accelerate
interpretable scientific discovery in ultrafast nanophotonics, targeting a
novel method to steer spontaneous emission from reconfigurable semiconductor
metasurfaces. Controlling spontaneous emission is crucial for clean-energy
solutions in illumination, thermal radiation engineering, and remote sensing.
Despite the potential of reconfigurable semiconductor metasurfaces with
embedded sources for spatiotemporal control, achieving arbitrary far-field
control remains challenging. Here, we present a self-driving lab (SDL) platform
that addresses this challenge by discovering the governing equations for
predicting the far-field emission profile from light-emitting metasurfaces. We
discover that both the spatial gradient (grating-like) and the curvature
(lens-like) of the local refractive index are key factors in steering
spontaneous emission. The SDL employs a machine-learning framework comprising:
(1) a variational autoencoder for generating complex spatial refractive index
profiles, (2) an active learning agent for guiding experiments with real-time
closed-loop feedback, and (3) a neural network-based equation learner to
uncover structure-property relationships. The SDL demonstrated a four-fold
enhancement in peak emission directivity (up to 77%) over a 72{\deg} field of
view within ~300 experiments. Our findings reveal that combinations of positive
gratings and lenses are as effective as negative lenses and gratings for all
emission angles, offering a novel strategy for controlling spontaneous emission
beyond conventional Fourier optics.",2024-07-22,"Saaketh Desai, Sadhvikas Addamane, Jeffery Y. Tsao, Igal Brener, Remi Dingreville, Prasad P. Iyer",http://arxiv.org/pdf/2407.16083v2,cs.LG
Rapid Switching and Multi-Adapter Fusion via Sparse High Rank Adapters,"In this paper, we propose Sparse High Rank Adapters (SHiRA) that directly
finetune 1-2% of the base model weights while leaving others unchanged, thus,
resulting in a highly sparse adapter. This high sparsity incurs no inference
overhead, enables rapid switching directly in the fused mode, and significantly
reduces concept-loss during multi-adapter fusion. Our extensive experiments on
LVMs and LLMs demonstrate that finetuning merely 1-2% parameters in the base
model is sufficient for many adapter tasks and significantly outperforms Low
Rank Adaptation (LoRA). We also show that SHiRA is orthogonal to advanced LoRA
methods such as DoRA and can be easily combined with existing techniques.",2024-07-22,"Kartikeya Bhardwaj, Nilesh Prasad Pandey, Sweta Priyadarshi, Viswanath Ganapathy, Rafael Esteves, Shreya Kadambi, Shubhankar Borse, Paul Whatmough, Risheek Garrepalli, Mart Van Baalen, Harris Teague, Markus Nagel",http://arxiv.org/pdf/2407.16712v1,cs.LG
LCA-on-the-Line: Benchmarking Out-of-Distribution Generalization with Class Taxonomies,"We tackle the challenge of predicting models' Out-of-Distribution (OOD)
performance using in-distribution (ID) measurements without requiring OOD data.
Existing evaluations with ""Effective Robustness"", which use ID accuracy as an
indicator of OOD accuracy, encounter limitations when models are trained with
diverse supervision and distributions, such as class labels (Vision Models,
VMs, on ImageNet) and textual descriptions (Visual-Language Models, VLMs, on
LAION). VLMs often generalize better to OOD data than VMs despite having
similar or lower ID performance. To improve the prediction of models' OOD
performance from ID measurements, we introduce the Lowest Common Ancestor
(LCA)-on-the-Line framework. This approach revisits the established concept of
LCA distance, which measures the hierarchical distance between labels and
predictions within a predefined class hierarchy, such as WordNet. We assess 75
models using ImageNet as the ID dataset and five significantly shifted OOD
variants, uncovering a strong linear correlation between ID LCA distance and
OOD top-1 accuracy. Our method provides a compelling alternative for
understanding why VLMs tend to generalize better. Additionally, we propose a
technique to construct a taxonomic hierarchy on any dataset using K-means
clustering, demonstrating that LCA distance is robust to the constructed
taxonomic hierarchy. Moreover, we demonstrate that aligning model predictions
with class taxonomies, through soft labels or prompt engineering, can enhance
model generalization. Open source code in our Project Page:
https://elvishelvis.github.io/papers/lca/.",2024-07-22,"Jia Shi, Gautam Gare, Jinjin Tian, Siqi Chai, Zhiqiu Lin, Arun Vasudevan, Di Feng, Francesco Ferroni, Shu Kong",http://arxiv.org/pdf/2407.16067v1,cs.LG
Artificial Intelligence-based Decision Support Systems for Precision and Digital Health,"Precision health, increasingly supported by digital technologies, is a domain
of research that broadens the paradigm of precision medicine, advancing
everyday healthcare. This vision goes hand in hand with the groundbreaking
advent of artificial intelligence (AI), which is reshaping the way we diagnose,
treat, and monitor both clinical subjects and the general population. AI tools
powered by machine learning have shown considerable improvements in a variety
of healthcare domains. In particular, reinforcement learning (RL) holds great
promise for sequential and dynamic problems such as dynamic treatment regimes
and just-in-time adaptive interventions in digital health. In this work, we
discuss the opportunity offered by AI, more specifically RL, to current trends
in healthcare, providing a methodological survey of RL methods in the context
of precision and digital health. Focusing on the area of adaptive
interventions, we expand the methodological survey with illustrative case
studies that used RL in real practice.
  This invited article has undergone anonymous review and is intended as a book
chapter for the volume ""Frontiers of Statistics and Data Science"" edited by
Subhashis Ghoshal and Anindya Roy for the International Indian Statistical
Association Series on Statistics and Data Science, published by Springer. It
covers the material from a short course titled ""Artificial Intelligence in
Precision and Digital Health"" taught by the author Bibhas Chakraborty at the
IISA 2022 Conference, December 26-30 2022, at the Indian Institute of Science,
Bengaluru.",2024-07-22,"Nina Deliu, Bibhas Chakraborty",http://arxiv.org/pdf/2407.16062v1,cs.LG
Revisiting Score Function Estimators for $k$-Subset Sampling,"Are score function estimators an underestimated approach to learning with
$k$-subset sampling? Sampling $k$-subsets is a fundamental operation in many
machine learning tasks that is not amenable to differentiable parametrization,
impeding gradient-based optimization. Prior work has focused on relaxed
sampling or pathwise gradient estimators. Inspired by the success of score
function estimators in variational inference and reinforcement learning, we
revisit them within the context of $k$-subset sampling. Specifically, we
demonstrate how to efficiently compute the $k$-subset distribution's score
function using a discrete Fourier transform, and reduce the estimator's
variance with control variates. The resulting estimator provides both exact
samples and unbiased gradient estimates while also applying to
non-differentiable downstream models, unlike existing methods. Experiments in
feature selection show results competitive with current methods, despite weaker
assumptions.",2024-07-22,"Klas Wijk, Ricardo Vinuesa, Hossein Azizpour",http://arxiv.org/pdf/2407.16058v2,cs.LG
Making LLMs Work for Enterprise Data Tasks,"Large language models (LLMs) know little about enterprise database tables in
the private data ecosystem, which substantially differ from web text in
structure and content. As LLMs' performance is tied to their training data, a
crucial question is how useful they can be in improving enterprise database
management and analysis tasks. To address this, we contribute experimental
results on LLMs' performance for text-to-SQL and semantic column-type detection
tasks on enterprise datasets. The performance of LLMs on enterprise data is
significantly lower than on benchmark datasets commonly used. Informed by our
findings and feedback from industry practitioners, we identify three
fundamental challenges -- latency, cost, and quality -- and propose potential
solutions to use LLMs in enterprise data workflows effectively.",2024-07-22,"Çağatay Demiralp, Fabian Wenz, Peter Baile Chen, Moe Kayali, Nesime Tatbul, Michael Stonebraker",http://arxiv.org/pdf/2407.20256v1,cs.LG
HIERVAR: A Hierarchical Feature Selection Method for Time Series Analysis,"Time series classification stands as a pivotal and intricate challenge across
various domains, including finance, healthcare, and industrial systems. In
contemporary research, there has been a notable upsurge in exploring feature
extraction through random sampling. Unlike deep convolutional networks, these
methods sidestep elaborate training procedures, yet they often necessitate
generating a surplus of features to comprehensively encapsulate time series
nuances. Consequently, some features may lack relevance to labels or exhibit
multi-collinearity with others. In this paper, we propose a novel hierarchical
feature selection method aided by ANOVA variance analysis to address this
challenge. Through meticulous experimentation, we demonstrate that our method
substantially reduces features by over 94% while preserving accuracy -- a
significant advancement in the field of time series analysis and feature
selection.",2024-07-22,"Alireza Keshavarzian, Shahrokh Valaee",http://arxiv.org/pdf/2407.16048v1,cs.LG
Generalizing Teacher Networks for Effective Knowledge Distillation Across Student Architectures,"Knowledge distillation (KD) is a model compression method that entails
training a compact student model to emulate the performance of a more complex
teacher model. However, the architectural capacity gap between the two models
limits the effectiveness of knowledge transfer. Addressing this issue, previous
works focused on customizing teacher-student pairs to improve compatibility, a
computationally expensive process that needs to be repeated every time either
model changes. Hence, these methods are impractical when a teacher model has to
be compressed into different student models for deployment on multiple hardware
devices with distinct resource constraints. In this work, we propose Generic
Teacher Network (GTN), a one-off KD-aware training to create a generic teacher
capable of effectively transferring knowledge to any student model sampled from
a given finite pool of architectures. To this end, we represent the student
pool as a weight-sharing supernet and condition our generic teacher to align
with the capacities of various student architectures sampled from this
supernet. Experimental evaluation shows that our method both improves overall
KD effectiveness and amortizes the minimal additional training cost of the
generic teacher across students in the pool.",2024-07-22,"Kuluhan Binici, Weiming Wu, Tulika Mitra",http://arxiv.org/pdf/2407.16040v2,cs.LG
AICircuit: A Multi-Level Dataset and Benchmark for AI-Driven Analog Integrated Circuit Design,"Analog and radio-frequency circuit design requires extensive exploration of
both circuit topology and parameters to meet specific design criteria like
power consumption and bandwidth. Designers must review state-of-the-art
topology configurations in the literature and sweep various circuit parameters
within each configuration. This design process is highly specialized and
time-intensive, particularly as the number of circuit parameters increases and
the circuit becomes more complex. Prior research has explored the potential of
machine learning to enhance circuit design procedures. However, these studies
primarily focus on simple circuits, overlooking the more practical and complex
analog and radio-frequency systems. A major obstacle for bearing the power of
machine learning in circuit design is the availability of a generic and diverse
dataset, along with robust metrics, which are essential for thoroughly
evaluating and improving machine learning algorithms in the analog and
radio-frequency circuit domain. We present AICircuit, a comprehensive
multi-level dataset and benchmark for developing and evaluating ML algorithms
in analog and radio-frequency circuit design. AICircuit comprises seven
commonly used basic circuits and two complex wireless transceiver systems
composed of multiple circuit blocks, encompassing a wide array of design
scenarios encountered in real-world applications. We extensively evaluate
various ML algorithms on the dataset, revealing the potential of ML algorithms
in learning the mapping from the design specifications to the desired circuit
parameters.",2024-07-22,"Asal Mehradfar, Xuzhe Zhao, Yue Niu, Sara Babakniya, Mahdi Alesheikh, Hamidreza Aghasi, Salman Avestimehr",http://arxiv.org/pdf/2407.18272v1,cs.LG
Transformer-based Capacity Prediction for Lithium-ion Batteries with Data Augmentation,"Lithium-ion batteries are pivotal to technological advancements in
transportation, electronics, and clean energy storage. The optimal operation
and safety of these batteries require proper and reliable estimation of battery
capacities to monitor the state of health. Current methods for estimating the
capacities fail to adequately account for long-term temporal dependencies of
key variables (e.g., voltage, current, and temperature) associated with battery
aging and degradation. In this study, we explore the usage of transformer
networks to enhance the estimation of battery capacity. We develop a
transformer-based battery capacity prediction model that accounts for both
long-term and short-term patterns in battery data. Further, to tackle the data
scarcity issue, data augmentation is used to increase the data size, which
helps to improve the performance of the model. Our proposed method is validated
with benchmark datasets. Simulation results show the effectiveness of data
augmentation and the transformer network in improving the accuracy and
robustness of battery capacity prediction.",2024-07-22,"Gift Modekwe, Saif Al-Wahaibi, Qiugang Lu",http://arxiv.org/pdf/2407.16036v1,cs.LG
Leveraging LLM Reasoning Enhances Personalized Recommender Systems,"Recent advancements have showcased the potential of Large Language Models
(LLMs) in executing reasoning tasks, particularly facilitated by
Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve
clear, definitive answers and logical chains of thought, the application of LLM
reasoning in recommendation systems (RecSys) presents a distinct challenge.
RecSys tasks revolve around subjectivity and personalized preferences, an
under-explored domain in utilizing LLMs' reasoning capabilities. Our study
explores several aspects to better understand reasoning for RecSys and
demonstrate how task quality improves by utilizing LLM reasoning in both
zero-shot and finetuning settings. Additionally, we propose RecSAVER
(Recommender Systems Automatic Verification and Evaluation of Reasoning) to
automatically assess the quality of LLM reasoning responses without the
requirement of curated gold references or human raters. We show that our
framework aligns with real human judgment on the coherence and faithfulness of
reasoning responses. Overall, our work shows that incorporating reasoning into
RecSys can improve personalized tasks, paving the way for further advancements
in recommender system methodologies.",2024-07-22,"Alicia Y. Tsai, Adam Kraft, Long Jin, Chenwei Cai, Anahita Hosseini, Taibai Xu, Zemin Zhang, Lichan Hong, Ed H. Chi, Xinyang Yi",http://arxiv.org/pdf/2408.00802v1,cs.LG
Enhancing Temporal Understanding in LLMs for Semi-structured Tables,"Temporal reasoning over tabular data presents substantial challenges for
large language models (LLMs), as evidenced by recent research. In this study,
we conduct a comprehensive analysis of temporal datasets to pinpoint the
specific limitations of LLMs. Our investigation leads to enhancements in
TempTabQA, a dataset specifically designed for tabular temporal question
answering. We provide critical insights for improving LLM performance in
temporal reasoning tasks with tabular data. Furthermore, we introduce a novel
approach, C.L.E.A.R to strengthen LLM capabilities in this domain. Our findings
demonstrate that our method significantly improves evidence-based reasoning
across various models. Additionally, our experimental results reveal that
indirect supervision with auxiliary data substantially boosts model performance
in these tasks. This work contributes to a deeper understanding of LLMs'
temporal reasoning abilities over tabular data and promotes advancements in
their application across diverse fields.",2024-07-22,"Irwin Deng, Kushagra Dixit, Vivek Gupta, Dan Roth",http://arxiv.org/pdf/2407.16030v1,cs.LG
Exploring and Addressing Reward Confusion in Offline Preference Learning,"Spurious correlations in a reward model's training data can prevent
Reinforcement Learning from Human Feedback (RLHF) from identifying the desired
goal and induce unwanted behaviors. This paper shows that offline RLHF is
susceptible to reward confusion, especially in the presence of spurious
correlations in offline data. We create a benchmark to study this problem and
propose a method that can significantly reduce reward confusion by leveraging
transitivity of preferences while building a global preference chain with
active learning.",2024-07-22,"Xin Chen, Sam Toyer, Florian Shkurti",http://arxiv.org/pdf/2407.16025v2,cs.LG
Pavement Fatigue Crack Detection and Severity Classification Based on Convolutional Neural Network,"Due to the varying intensity of pavement cracks, the complexity of
topological structure, and the noise of texture background, image
classification for asphalt pavement cracking has proven to be a challenging
problem. Fatigue cracking, also known as alligator cracking, is one of the
common distresses of asphalt pavement. It is thus important to detect and
monitor the condition of alligator cracking on roadway pavements. Most research
in this area has typically focused on pixel-level detection of cracking using
limited datasets. A novel deep convolutional neural network that can achieve
two objectives is proposed. The first objective of the proposed neural network
is to classify presence of fatigue cracking based on pavement surface images.
The second objective is to classify the fatigue cracking severity level based
on the Distress Identification Manual (DIM) standard. In this paper, a databank
of 4484 high-resolution pavement surface images is established in which images
are taken locally in the Town of Blacksburg, Virginia, USA. In the data
pre-preparation, over 4000 images are labeled into 4 categories manually
according to DIM standards. A four-layer convolutional neural network model is
then built to achieve the goal of classification of images by pavement crack
severity category. The trained model reached the highest accuracy among all
existing methods. After only 30 epochs of training, the model achieved a crack
existence classification accuracy of 96.23% and a severity level classification
accuracy of 96.74%. After 20 epochs of training, the model achieved a pavement
marking presence classification accuracy of 97.64%.",2024-07-22,"Zhen Wang, Dylan G. Ildefonzo, Linbing Wang",http://arxiv.org/pdf/2407.16021v1,cs.LG
Sparks of Quantum Advantage and Rapid Retraining in Machine Learning,"The advent of quantum computing holds the potential to revolutionize various
fields by solving complex problems more efficiently than classical computers.
Despite this promise, practical quantum advantage is hindered by current
hardware limitations, notably the small number of qubits and high noise levels.
In this study, we leverage adiabatic quantum computers to optimize
Kolmogorov-Arnold Networks, a powerful neural network architecture for
representing complex functions with minimal parameters. By modifying the
network to use Bezier curves as the basis functions and formulating the
optimization problem into a Quadratic Unconstrained Binary Optimization
problem, we create a fixed-sized solution space, independent of the number of
training samples. This strategy allows for the optimization of an entire neural
network in a single training iteration in which, due to order of operations, a
majority of the processing is done using a collapsed version of the training
dataset. This inherently creates extremely fast training speeds, which are
validated experimentally, compared to classical optimizers including Adam,
Stochastic Gradient Descent, Adaptive Gradient, and simulated annealing.
Additionally, we introduce a novel rapid retraining capability, enabling the
network to be retrained with new data without reprocessing old samples, thus
enhancing learning efficiency in dynamic environments. Experiments on
retraining demonstrate a hundred times speed up using adiabatic quantum
computing based optimization compared to that of the gradient descent based
optimizers, with theoretical models allowing this speed up to be much larger!
Our findings suggest that with further advancements in quantum hardware and
algorithm optimization, quantum-optimized machine learning models could have
broad applications across various domains, with initial focus on rapid
retraining.",2024-07-22,William Troy,http://arxiv.org/pdf/2407.16020v4,cs.LG
"AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations","For many use-cases, it is often important to explain the prediction of a
black-box model by identifying the most influential training data samples.
Existing approaches lack customization for user intent and often provide a
homogeneous set of explanation samples, failing to reveal the model's reasoning
from different angles.
  In this paper, we propose AIDE, an approach for providing antithetical (i.e.,
contrastive), intent-based, diverse explanations for opaque and complex models.
AIDE distinguishes three types of explainability intents: interpreting a
correct, investigating a wrong, and clarifying an ambiguous prediction. For
each intent, AIDE selects an appropriate set of influential training samples
that support or oppose the prediction either directly or by contrast. To
provide a succinct summary, AIDE uses diversity-aware sampling to avoid
redundancy and increase coverage of the training data.
  We demonstrate the effectiveness of AIDE on image and text classification
tasks, in three ways: quantitatively, assessing correctness and continuity;
qualitatively, comparing anecdotal evidence from AIDE and other example-based
approaches; and via a user study, evaluating multiple aspects of AIDE. The
results show that AIDE addresses the limitations of existing methods and
exhibits desirable traits for an explainability method.",2024-07-22,"Ikhtiyor Nematov, Dimitris Sacharidis, Tomer Sagi, Katja Hose",http://arxiv.org/pdf/2407.16010v2,cs.LG
Promises and Pitfalls of Generative Masked Language Modeling: Theoretical Framework and Practical Guidelines,"Autoregressive language models are the currently dominant paradigm for text
generation, but they have some fundamental limitations that cannot be remedied
by scale-for example inherently sequential and unidirectional generation. While
alternate classes of models have been explored, we have limited mathematical
understanding of their fundamental power and limitations. In this paper we
focus on Generative Masked Language Models (GMLMs), a non-autoregressive
paradigm in which we train a model to fit conditional probabilities of the data
distribution via masking, which are subsequently used as inputs to a Markov
Chain to draw samples from the model, These models empirically strike a
promising speed-quality trade-off as each step can be typically parallelized by
decoding the entire sequence in parallel. We develop a mathematical framework
for analyzing and improving such models which sheds light on questions of
sample complexity and inference speed and quality. Empirically, we adapt the T5
model for iteratively-refined parallel decoding, achieving 2-3x speedup in
machine translation with minimal sacrifice in quality compared with
autoregressive models. We run careful ablation experiments to give
recommendations on key design choices, and make fine-grained observations on
the common error modes in connection with our theory. Our mathematical analyses
and empirical observations characterize both potentials and limitations of this
approach, and can be applied to future works on improving understanding and
performance of GMLMs. Our codes are released at
https://github.com/google-research/google-research/tree/master/padir",2024-07-22,"Yuchen Li, Alexandre Kirchmeyer, Aashay Mehta, Yilong Qin, Boris Dadachev, Kishore Papineni, Sanjiv Kumar, Andrej Risteski",http://arxiv.org/pdf/2407.21046v1,cs.LG
Reconstructing Training Data From Real World Models Trained with Transfer Learning,"Current methods for reconstructing training data from trained classifiers are
restricted to very small models, limited training set sizes, and low-resolution
images. Such restrictions hinder their applicability to real-world scenarios.
In this paper, we present a novel approach enabling data reconstruction in
realistic settings for models trained on high-resolution images. Our method
adapts the reconstruction scheme of arXiv:2206.07758 to real-world scenarios --
specifically, targeting models trained via transfer learning over image
embeddings of large pre-trained models like DINO-ViT and CLIP. Our work employs
data reconstruction in the embedding space rather than in the image space,
showcasing its applicability beyond visual data. Moreover, we introduce a novel
clustering-based method to identify good reconstructions from thousands of
candidates. This significantly improves on previous works that relied on
knowledge of the training set to identify good reconstructed images. Our
findings shed light on a potential privacy risk for data leakage from models
trained using transfer learning.",2024-07-22,"Yakir Oz, Gilad Yehudai, Gal Vardi, Itai Antebi, Michal Irani, Niv Haim",http://arxiv.org/pdf/2407.15845v1,cs.LG
HandDGP: Camera-Space Hand Mesh Prediction with Differentiable Global Positioning,"Predicting camera-space hand meshes from single RGB images is crucial for
enabling realistic hand interactions in 3D virtual and augmented worlds.
Previous work typically divided the task into two stages: given a cropped image
of the hand, predict meshes in relative coordinates, followed by lifting these
predictions into camera space in a separate and independent stage, often
resulting in the loss of valuable contextual and scale information. To prevent
the loss of these cues, we propose unifying these two stages into an end-to-end
solution that addresses the 2D-3D correspondence problem. This solution enables
back-propagation from camera space outputs to the rest of the network through a
new differentiable global positioning module. We also introduce an image
rectification step that harmonizes both the training dataset and the input
image as if they were acquired with the same camera, helping to alleviate the
inherent scale-depth ambiguity of the problem. We validate the effectiveness of
our framework in evaluations against several baselines and state-of-the-art
approaches across three public benchmarks.",2024-07-22,"Eugene Valassakis, Guillermo Garcia-Hernando",http://arxiv.org/pdf/2407.15844v1,cs.LG
Perceptions of Linguistic Uncertainty by Language Models and Humans,"_Uncertainty expressions_ such as ""probably"" or ""highly unlikely"" are
pervasive in human language. While prior work has established that there is
population-level agreement in terms of how humans quantitatively interpret
these expressions, there has been little inquiry into the abilities of language
models in the same context. In this paper, we investigate how language models
map linguistic expressions of uncertainty to numerical responses. Our approach
assesses whether language models can employ theory of mind in this setting:
understanding the uncertainty of another agent about a particular statement,
independently of the model's own certainty about that statement. We find that 7
out of 10 models are able to map uncertainty expressions to probabilistic
responses in a human-like manner. However, we observe systematically different
behavior depending on whether a statement is actually true or false. This
sensitivity indicates that language models are substantially more susceptible
to bias based on their prior knowledge (as compared to humans). These findings
raise important questions and have broad implications for human-AI and AI-AI
communication.",2024-07-22,"Catarina G Belem, Markelle Kelly, Mark Steyvers, Sameer Singh, Padhraic Smyth",http://arxiv.org/pdf/2407.15814v2,cs.LG
Stretching Each Dollar: Diffusion Training from Scratch on a Micro-Budget,"As scaling laws in generative AI push performance, they also simultaneously
concentrate the development of these models among actors with large
computational resources. With a focus on text-to-image (T2I) generative models,
we aim to address this bottleneck by demonstrating very low-cost training of
large-scale T2I diffusion transformer models. As the computational cost of
transformers increases with the number of patches in each image, we propose to
randomly mask up to 75% of the image patches during training. We propose a
deferred masking strategy that preprocesses all patches using a patch-mixer
before masking, thus significantly reducing the performance degradation with
masking, making it superior to model downscaling in reducing computational
cost. We also incorporate the latest improvements in transformer architecture,
such as the use of mixture-of-experts layers, to improve performance and
further identify the critical benefit of using synthetic images in micro-budget
training. Finally, using only 37M publicly available real and synthetic images,
we train a 1.16 billion parameter sparse transformer with only \$1,890
economical cost and achieve a 12.7 FID in zero-shot generation on the COCO
dataset. Notably, our model achieves competitive FID and high-quality
generations while incurring 118$\times$ lower cost than stable diffusion models
and 14$\times$ lower cost than the current state-of-the-art approach that costs
\$28,400. We aim to release our end-to-end training pipeline to further
democratize the training of large-scale diffusion models on micro-budgets.",2024-07-22,"Vikash Sehwag, Xianghao Kong, Jingtao Li, Michael Spranger, Lingjuan Lyu",http://arxiv.org/pdf/2407.15811v1,cs.LG
Development of Multistage Machine Learning Classifier using Decision Trees and Boosting Algorithms over Darknet Network Traffic,"In recent years, the clandestine nature of darknet activities has presented
an escalating challenge to cybersecurity efforts, necessitating sophisticated
methods for the detection and classification of network traffic associated with
these covert operations. The system addresses the significant challenge of
class imbalance within Darknet traffic datasets, where malicious traffic
constitutes a minority, hindering effective discrimination between normal and
malicious behavior. By leveraging boosting algorithms like AdaBoost and
Gradient Boosting coupled with decision trees, this study proposes a robust
solution for network traffic classification. Boosting algorithms ensemble
learning corrects errors iteratively and assigns higher weights to minority
class instances, complemented by the hierarchical structure of decision trees.
The additional Feature Selection which is a preprocessing method by utilizing
Information Gain metrics, Fisher's Score, and Chi-Square test selection for
features is employed. Rigorous experimentation with diverse Darknet traffic
datasets validates the efficacy of the proposed multistage classifier,
evaluated through various performance metrics such as accuracy, precision,
recall, and F1-score, offering a comprehensive solution for accurate detection
and classification of Darknet activities.",2024-07-22,"Anjali Sureshkumar Nair, Prashant Nitnaware",http://arxiv.org/pdf/2407.15910v1,cs.LG
A Survey of Explainable Artificial Intelligence (XAI) in Financial Time Series Forecasting,"Artificial Intelligence (AI) models have reached a very significant level of
accuracy. While their superior performance offers considerable benefits, their
inherent complexity often decreases human trust, which slows their application
in high-risk decision-making domains, such as finance. The field of eXplainable
AI (XAI) seeks to bridge this gap, aiming to make AI models more
understandable. This survey, focusing on published work from the past five
years, categorizes XAI approaches that predict financial time series. In this
paper, explainability and interpretability are distinguished, emphasizing the
need to treat these concepts separately as they are not applied the same way in
practice. Through clear definitions, a rigorous taxonomy of XAI approaches, a
complementary characterization, and examples of XAI's application in the
finance industry, this paper provides a comprehensive view of XAI's current
role in finance. It can also serve as a guide for selecting the most
appropriate XAI approach for future applications.",2024-07-22,"Pierre-Daniel Arsenault, Shengrui Wang, Jean-Marc Patenande",http://arxiv.org/pdf/2407.15909v1,cs.LG
CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning,"With the emergence of Transformers and Vision-Language Models (VLMs) such as
CLIP, fine-tuning large pre-trained models has recently become a prevalent
strategy in Continual Learning. This has led to the development of numerous
prompting strategies to adapt transformer-based models without incurring
catastrophic forgetting. However, these strategies often compromise the
original zero-shot capabilities of the pre-trained CLIP model and struggle to
adapt to domains that significantly deviate from the pre-training data. In this
work, we propose Continual Generative training for Incremental prompt-Learning,
a simple and novel approach to mitigate forgetting while adapting CLIP.
Briefly, we employ Variational Autoencoders (VAEs) to learn class-conditioned
distributions within the embedding space of the visual encoder. We then exploit
these distributions to sample new synthetic visual embeddings and train the
corresponding class-specific textual prompts during subsequent tasks. Through
extensive experiments on different domains, we show that such a generative
replay approach can adapt to new tasks while improving zero-shot capabilities,
evaluated using a novel metric tailored for CL scenarios. Notably, further
analysis reveals that our approach can bridge the gap with joint prompt tuning.
The codebase is available at https://github.com/aimagelab/mammoth.",2024-07-22,"Emanuele Frascaroli, Aniello Panariello, Pietro Buzzega, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara",http://arxiv.org/pdf/2407.15793v4,cs.LG
Robust Mixture Learning when Outliers Overwhelm Small Groups,"We study the problem of estimating the means of well-separated mixtures when
an adversary may add arbitrary outliers. While strong guarantees are available
when the outlier fraction is significantly smaller than the minimum mixing
weight, much less is known when outliers may crowd out low-weight clusters - a
setting we refer to as list-decodable mixture learning (LD-ML). In this case,
adversarial outliers can simulate additional spurious mixture components.
Hence, if all means of the mixture must be recovered up to a small error in the
output list, the list size needs to be larger than the number of (true)
components. We propose an algorithm that obtains order-optimal error guarantees
for each mixture mean with a minimal list-size overhead, significantly
improving upon list-decodable mean estimation, the only existing method that is
applicable for LD-ML. Although improvements are observed even when the mixture
is non-separated, our algorithm achieves particularly strong guarantees when
the mixture is separated: it can leverage the mixture structure to partially
cluster the samples before carefully iterating a base learner for
list-decodable mean estimation at different scales.",2024-07-22,"Daniil Dmitriev, Rares-Darius Buhai, Stefan Tiegel, Alexander Wolters, Gleb Novikov, Amartya Sanyal, David Steurer, Fanny Yang",http://arxiv.org/pdf/2407.15792v1,cs.LG
LICORICE: Label-Efficient Concept-Based Interpretable Reinforcement Learning,"Recent advances in reinforcement learning (RL) have predominantly leveraged
neural network policies for decision-making, yet these models often lack
interpretability, posing challenges for stakeholder comprehension and trust.
Concept bottleneck models offer an interpretable alternative by integrating
human-understandable concepts into policies. However, prior work assumes that
concept annotations are readily available during training. For RL, this
requirement poses a significant limitation: it necessitates continuous
real-time concept annotation, which either places an impractical burden on
human annotators or incurs substantial costs in API queries and inference time
when employing automated labeling methods. To overcome this limitation, we
introduce a novel training scheme that enables RL agents to efficiently learn a
concept-based policy by only querying annotators to label a small set of data.
Our algorithm, LICORICE, involves three main contributions: interleaving
concept learning and RL training, using an ensemble to actively select
informative data points for labeling, and decorrelating the concept data. We
show how LICORICE reduces human labeling efforts to 500 or fewer concept labels
in three environments, and 5000 or fewer in two more complex environments, all
at no cost to performance. We also explore the use of VLMs as automated concept
annotators, finding them effective in some cases but imperfect in others. Our
work significantly reduces the annotation burden for interpretable RL, making
it more practical for real-world applications that necessitate transparency.",2024-07-22,"Zhuorui Ye, Stephanie Milani, Geoffrey J. Gordon, Fei Fang",http://arxiv.org/pdf/2407.15786v2,cs.LG
In Search of Quantum Advantage: Estimating the Number of Shots in Quantum Kernel Methods,"Quantum Machine Learning (QML) has gathered significant attention through
approaches like Quantum Kernel Machines. While these methods hold considerable
promise, their quantum nature presents inherent challenges. One major challenge
is the limited resolution of estimated kernel values caused by the finite
number of circuit runs performed on a quantum device. In this study, we propose
a comprehensive system of rules and heuristics for estimating the required
number of circuit runs in quantum kernel methods. We introduce two critical
effects that necessitate an increased measurement precision through additional
circuit runs: the spread effect and the concentration effect. The effects are
analyzed in the context of fidelity and projected quantum kernels. To address
these phenomena, we develop an approach for estimating desired precision of
kernel values, which, in turn, is translated into the number of circuit runs.
Our methodology is validated through extensive numerical simulations, focusing
on the problem of exponential value concentration. We stress that quantum
kernel methods should not only be considered from the machine learning
performance perspective, but also from the context of the resource consumption.
The results provide insights into the possible benefits of quantum kernel
methods, offering a guidance for their application in quantum machine learning
tasks.",2024-07-22,"Artur Miroszewski, Marco Fellous Asiani, Jakub Mielczarek, Bertrand Le Saux, Jakub Nalepa",http://arxiv.org/pdf/2407.15776v1,cs.LG
STAMP: Outlier-Aware Test-Time Adaptation with Stable Memory Replay,"Test-time adaptation (TTA) aims to address the distribution shift between the
training and test data with only unlabeled data at test time. Existing TTA
methods often focus on improving recognition performance specifically for test
data associated with classes in the training set. However, during the
open-world inference process, there are inevitably test data instances from
unknown classes, commonly referred to as outliers. This paper pays attention to
the problem that conducts both sample recognition and outlier rejection during
inference while outliers exist. To address this problem, we propose a new
approach called STAble Memory rePlay (STAMP), which performs optimization over
a stable memory bank instead of the risky mini-batch. In particular, the memory
bank is dynamically updated by selecting low-entropy and label-consistent
samples in a class-balanced manner. In addition, we develop a self-weighted
entropy minimization strategy that assigns higher weight to low-entropy
samples. Extensive results demonstrate that STAMP outperforms existing TTA
methods in terms of both recognition and outlier detection performance. The
code is released at https://github.com/yuyongcan/STAMP.",2024-07-22,"Yongcan Yu, Lijun Sheng, Ran He, Jian Liang",http://arxiv.org/pdf/2407.15773v2,cs.LG
Conditional Language Policy: A General Framework for Steerable Multi-Objective Finetuning,"Reward-based finetuning is crucial for aligning language policies with
intended behaviors (e.g., creativity and safety). A key challenge is to develop
steerable language models that trade-off multiple (conflicting) objectives in a
flexible and efficient manner. This paper presents Conditional Language Policy
(CLP), a general framework for finetuning language models on multiple
objectives. Building on techniques from multi-task training and
parameter-efficient finetuning, CLP learn steerable models that effectively
trade-off conflicting objectives at inference time. Notably, this does not
require training or maintaining multiple models to achieve different trade-offs
between the objectives. Through extensive experiments and ablations on two
summarization datasets, we show that CLP learns steerable language models that
outperform and Pareto-dominate the existing approaches for multi-objective
finetuning.",2024-07-22,"Kaiwen Wang, Rahul Kidambi, Ryan Sullivan, Alekh Agarwal, Christoph Dann, Andrea Michi, Marco Gelmi, Yunxuan Li, Raghav Gupta, Avinava Dubey, Alexandre Ramé, Johan Ferret, Geoffrey Cideron, Le Hou, Hongkun Yu, Amr Ahmed, Aranyak Mehta, Léonard Hussenot, Olivier Bachem, Edouard Leurent",http://arxiv.org/pdf/2407.15762v2,cs.LG
Model editing for distribution shifts in uranium oxide morphological analysis,"Deep learning still struggles with certain kinds of scientific data. Notably,
pretraining data may not provide coverage of relevant distribution shifts
(e.g., shifts induced via the use of different measurement instruments). We
consider deep learning models trained to classify the synthesis conditions of
uranium ore concentrates (UOCs) and show that model editing is particularly
effective for improving generalization to distribution shifts common in this
domain. In particular, model editing outperforms finetuning on two curated
datasets comprising of micrographs taken of U$_{3}$O$_{8}$ aged in humidity
chambers and micrographs acquired with different scanning electron microscopes,
respectively.",2024-07-22,"Davis Brown, Cody Nizinski, Madelyn Shapiro, Corey Fallon, Tianzhixi Yin, Henry Kvinge, Jonathan H. Tu",http://arxiv.org/pdf/2407.15756v1,cs.LG
LongVideoBench: A Benchmark for Long-context Interleaved Video-Language Understanding,"Large multimodal models (LMMs) are processing increasingly longer and richer
inputs. Albeit the progress, few public benchmark is available to measure such
development. To mitigate this gap, we introduce LongVideoBench, a
question-answering benchmark that features video-language interleaved inputs up
to an hour long. Our benchmark includes 3,763 varying-length web-collected
videos with their subtitles across diverse themes, designed to comprehensively
evaluate LMMs on long-term multimodal understanding. To achieve this, we
interpret the primary challenge as to accurately retrieve and reason over
detailed multimodal information from long inputs. As such, we formulate a novel
video question-answering task termed referring reasoning. Specifically, as part
of the question, it contains a referring query that references related video
contexts, called referred context. The model is then required to reason over
relevant video details from the referred context. Following the paradigm of
referring reasoning, we curate 6,678 human-annotated multiple-choice questions
in 17 fine-grained categories, establishing one of the most comprehensive
benchmarks for long-form video understanding. Evaluations suggest that the
LongVideoBench presents significant challenges even for the most advanced
proprietary models (e.g. GPT-4o, Gemini-1.5-Pro, GPT-4-Turbo), while their
open-source counterparts show an even larger performance gap. In addition, our
results indicate that model performance on the benchmark improves only when
they are capable of processing more frames, positioning LongVideoBench as a
valuable benchmark for evaluating future-generation long-context LMMs.",2024-07-22,"Haoning Wu, Dongxu Li, Bei Chen, Junnan Li",http://arxiv.org/pdf/2407.15754v1,cs.LG
Robustness of Speech Separation Models for Similar-pitch Speakers,"Single-channel speech separation is a crucial task for enhancing speech
recognition systems in multi-speaker environments. This paper investigates the
robustness of state-of-the-art Neural Network models in scenarios where the
pitch differences between speakers are minimal. Building on earlier findings by
Ditter and Gerkmann, which identified a significant performance drop for the
2018 Chimera++ under similar-pitch conditions, our study extends the analysis
to more recent and sophisticated Neural Network models. Our experiments reveal
that modern models have substantially reduced the performance gap for matched
training and testing conditions. However, a substantial performance gap
persists under mismatched conditions, with models performing well for large
pitch differences but showing worse performance if the speakers' pitches are
similar. These findings motivate further research into the generalizability of
speech separation models to similar-pitch speakers and unseen data.",2024-07-22,"Bunlong Lay, Sebastian Zaczek, Kristina Tesch, Timo Gerkmann",http://arxiv.org/pdf/2407.15749v1,cs.LG
Diffusion for Out-of-Distribution Detection on Road Scenes and Beyond,"In recent years, research on out-of-distribution (OoD) detection for semantic
segmentation has mainly focused on road scenes -- a domain with a constrained
amount of semantic diversity. In this work, we challenge this constraint and
extend the domain of this task to general natural images. To this end, we
introduce: 1. the ADE-OoD benchmark, which is based on the ADE20k dataset and
includes images from diverse domains with a high semantic diversity, and 2. a
novel approach that uses Diffusion score matching for OoD detection (DOoD) and
is robust to the increased semantic diversity. ADE-OoD features indoor and
outdoor images, defines 150 semantic categories as in-distribution, and
contains a variety of OoD objects. For DOoD, we train a diffusion model with an
MLP architecture on semantic in-distribution embeddings and build on the score
matching interpretation to compute pixel-wise OoD scores at inference time. On
common road scene OoD benchmarks, DOoD performs on par or better than the state
of the art, without using outliers for training or making assumptions about the
data domain. On ADE-OoD, DOoD outperforms previous approaches, but leaves much
room for future improvements.",2024-07-22,"Silvio Galesso, Philipp Schröppel, Hssan Driss, Thomas Brox",http://arxiv.org/pdf/2407.15739v1,cs.LG
Parallel Split Learning with Global Sampling,"Distributed deep learning in resource-constrained environments faces
scalability and generalization challenges due to large effective batch sizes
and non-identically distributed client data. We introduce a server-driven
sampling strategy that maintains a fixed global batch size by dynamically
adjusting client-side batch sizes. This decouples the effective batch size from
the number of participating devices and ensures that global batches better
reflect the overall data distribution. Using standard concentration bounds, we
establish tighter deviation guarantees compared to existing approaches.
Empirical results on a benchmark dataset confirm that the proposed method
improves model accuracy, training efficiency, and convergence stability,
offering a scalable solution for learning at the network edge.",2024-07-22,"Mohammad Kohankhaki, Ahmad Ayad, Mahdi Barhoush, Anke Schmeink",http://arxiv.org/pdf/2407.15738v3,cs.LG
Inferring turbulent velocity and temperature fields and their statistics from Lagrangian velocity measurements using physics-informed Kolmogorov-Arnold Networks,"We propose the Artificial Intelligence Velocimetry-Thermometry (AIVT) method
to infer hidden temperature fields from experimental turbulent velocity data.
This physics-informed machine learning method enables us to infer continuous
temperature fields using only sparse velocity data, hence eliminating the need
for direct temperature measurements. Specifically, AIVT is based on
physics-informed Kolmogorov-Arnold Networks (not neural networks) and is
trained by optimizing a combined loss function that minimizes the residuals of
the velocity data, boundary conditions, and the governing equations. We apply
AIVT to a unique set of experimental volumetric and simultaneous temperature
and velocity data of Rayleigh-B\'enard convection (RBC) that we acquired by
combining Particle Image Thermometry and Lagrangian Particle Tracking. This
allows us to compare AIVT predictions and measurements directly. We demonstrate
that we can reconstruct and infer continuous and instantaneous velocity and
temperature fields from sparse experimental data at a fidelity comparable to
direct numerical simulations (DNS) of turbulence. This, in turn, enables us to
compute important quantities for quantifying turbulence, such as fluctuations,
viscous and thermal dissipation, and QR distribution. This paradigm shift in
processing experimental data using AIVT to infer turbulent fields at DNS-level
fidelity is a promising avenue in breaking the current deadlock of quantitative
understanding of turbulence at high Reynolds numbers, where DNS is
computationally infeasible.",2024-07-22,"Juan Diego Toscano, Theo Käufer, Zhibo Wang, Martin Maxey, Christian Cierpka, George Em Karniadakis",http://arxiv.org/pdf/2407.15727v2,cs.LG
Beyond Size and Class Balance: Alpha as a New Dataset Quality Metric for Deep Learning,"In deep learning, achieving high performance on image classification tasks
requires diverse training sets. However, the current best
practice$\unicode{x2013}$maximizing dataset size and class
balance$\unicode{x2013}$does not guarantee dataset diversity. We hypothesized
that, for a given model architecture, model performance can be improved by
maximizing diversity more directly. To test this hypothesis, we introduce a
comprehensive framework of diversity measures from ecology that generalizes
familiar quantities like Shannon entropy by accounting for similarities among
images. (Size and class balance emerge as special cases.) Analyzing thousands
of subsets from seven medical datasets showed that the best correlates of
performance were not size or class balance but $A$$\unicode{x2013}$""big
alpha""$\unicode{x2013}$a set of generalized entropy measures interpreted as the
effective number of image-class pairs in the dataset, after accounting for
image similarities. One of these, $A_0$, explained 67% of the variance in
balanced accuracy, vs. 54% for class balance and just 39% for size. The best
pair of measures was size-plus-$A_1$ (79%), which outperformed
size-plus-class-balance (74%). Subsets with the largest $A_0$ performed up to
16% better than those with the largest size (median improvement, 8%). We
propose maximizing $A$ as a way to improve deep learning performance in medical
imaging.",2024-07-22,"Josiah Couch, Rima Arnaout, Ramy Arnaout",http://arxiv.org/pdf/2407.15724v2,cs.LG
Do Large Language Models Have Compositional Ability? An Investigation into Limitations and Scalability,"Large language models (LLMs) have emerged as powerful tools for many AI
problems and exhibit remarkable in-context learning (ICL) capabilities.
Compositional ability, solving unseen complex tasks that combine two or more
simple tasks, is an essential reasoning ability for Artificial General
Intelligence. Despite the tremendous success of LLMs, how they approach
composite tasks, especially those not encountered during the pretraining phase,
remains an open and largely underexplored question. In this study, we delve
into the ICL capabilities of LLMs on composite tasks, with only simple tasks as
in-context examples. We develop a test suite of composite tasks including
linguistic and logical challenges and perform empirical studies across
different LLM families. We observe that models exhibit divergent behaviors: (1)
For simpler composite tasks that apply distinct mapping mechanisms to different
input segments, the models demonstrate decent compositional ability, while
scaling up the model enhances this ability; (2) for more complex composite
tasks involving reasoning multiple steps, where each step represents one task,
models typically underperform, and scaling up generally provides no
improvements. We offer theoretical analysis in a simplified setting, explaining
that models exhibit compositional capability when the task handles different
input parts separately. We believe our work sheds new light on the capabilities
of LLMs in solving composite tasks regarding the nature of the tasks and model
scale. Our dataset and code are available at
{\url{https://github.com/OliverXUZY/LLM_Compose}}.",2024-07-22,"Zhuoyan Xu, Zhenmei Shi, Yingyu Liang",http://arxiv.org/pdf/2407.15720v2,cs.LG
Estimating Probability Densities with Transformer and Denoising Diffusion,"Transformers are often the go-to architecture to build foundation models that
ingest a large amount of training data. But these models do not estimate the
probability density distribution when trained on regression problems, yet
obtaining full probabilistic outputs is crucial to many fields of science,
where the probability distribution of the answer can be non-Gaussian and
multimodal. In this work, we demonstrate that training a probabilistic model
using a denoising diffusion head on top of the Transformer provides reasonable
probability density estimation even for high-dimensional inputs. The combined
Transformer+Denoising Diffusion model allows conditioning the output
probability density on arbitrary combinations of inputs and it is thus a highly
flexible density function emulator of all possible input/output combinations.
We illustrate our Transformer+Denoising Diffusion model by training it on a
large dataset of astronomical observations and measured labels of stars within
our Galaxy and we apply it to a variety of inference tasks to show that the
model can infer labels accurately with reasonable distributions.",2024-07-22,"Henry W. Leung, Jo Bovy, Joshua S. Speagle",http://arxiv.org/pdf/2407.15703v1,cs.LG
Fisher-Rao Gradient Flow: Geodesic Convexity and Functional Inequalities,"The dynamics of probability density functions has been extensively studied in
science and engineering to understand physical phenomena and facilitate
algorithmic design. Of particular interest are dynamics that can be formulated
as gradient flows of energy functionals under the Wasserstein metric. The
development of functional inequalities, such as the log-Sobolev inequality,
plays a pivotal role in analyzing the convergence of these dynamics. The goal
of this paper is to parallel the success of techniques using functional
inequalities, for dynamics that are gradient flows under the Fisher-Rao metric,
with various $f$-divergences as energy functionals. Such dynamics take the form
of a nonlocal differential equation, for which existing analysis critically
relies on using the explicit solution formula in special cases. We provide a
comprehensive study on functional inequalities and the relevant geodesic
convexity for Fisher-Rao gradient flows under minimal assumptions. A notable
feature of the obtained functional inequalities is that they do not depend on
the log-concavity or log-Sobolev constants of the target distribution.
Consequently, the convergence rate of the dynamics (assuming well-posed) is
uniform across general target distributions, making them potentially desirable
dynamics for posterior sampling applications in Bayesian inference.",2024-07-22,"José A. Carrillo, Yifan Chen, Daniel Zhengyu Huang, Jiaoyang Huang, Dongyi Wei",http://arxiv.org/pdf/2407.15693v1,cs.LG
SoftCVI: Contrastive variational inference with self-generated soft labels,"Estimating a distribution given access to its unnormalized density is pivotal
in Bayesian inference, where the posterior is generally known only up to an
unknown normalizing constant. Variational inference and Markov chain Monte
Carlo methods are the predominant tools for this task; however, both are often
challenging to apply reliably, particularly when the posterior has complex
geometry. Here, we introduce Soft Contrastive Variational Inference (SoftCVI),
which allows a family of variational objectives to be derived through a
contrastive estimation framework. The approach parameterizes a classifier in
terms of a variational distribution, reframing the inference task as a
contrastive estimation problem aiming to identify a single true posterior
sample among a set of samples. Despite this framing, we do not require positive
or negative samples, but rather learn by sampling the variational distribution
and computing ground truth soft classification labels from the unnormalized
posterior itself. The objectives have zero variance gradient when the
variational approximation is exact, without the need for specialized gradient
estimators. We empirically investigate the performance on a variety of Bayesian
inference tasks, using both simple (e.g. normal) and expressive (normalizing
flow) variational distributions. We find that SoftCVI can be used to form
objectives which are stable to train and mass-covering, frequently
outperforming inference with other variational approaches.",2024-07-22,"Daniel Ward, Mark Beaumont, Matteo Fasiolo",http://arxiv.org/pdf/2407.15687v4,cs.LG
HaloQuest: A Visual Hallucination Dataset for Advancing Multimodal Reasoning,"Hallucination has been a major problem for large language models and remains
a critical challenge when it comes to multimodality in which vision-language
models (VLMs) have to deal with not just textual but also visual inputs.
Despite rapid progress in VLMs, resources for evaluating and addressing
multimodal hallucination are limited and mostly focused on evaluation. This
work introduces HaloQuest, a novel visual question answering dataset that
captures various aspects of multimodal hallucination such as false premises,
insufficient contexts, and visual challenges. A novel idea from HaloQuest is to
leverage synthetic images, apart from real ones, to enable dataset creation at
scale. With over 7.7K examples spanning across a wide variety of categories,
HaloQuest was designed to be both a challenging benchmark for VLMs and a
fine-tuning dataset for advancing multimodal reasoning. Our experiments reveal
that current models struggle with HaloQuest, with all open-source VLMs
achieving below 36% accuracy. On the other hand, fine-tuning on HaloQuest
significantly reduces hallucination rates while preserving performance on
standard reasoning tasks. Our results discover that benchmarking with generated
images is highly correlated (r=0.97) with real images. Last but not least, we
propose a novel Auto-Eval mechanism that is highly correlated with human raters
(r=0.99) for evaluating VLMs. In sum, this work makes concrete strides towards
understanding, evaluating, and mitigating hallucination in VLMs, serving as an
important step towards more reliable multimodal AI systems in the future.",2024-07-22,"Zhecan Wang, Garrett Bingham, Adams Yu, Quoc Le, Thang Luong, Golnaz Ghiasi",http://arxiv.org/pdf/2407.15680v1,cs.LG
"IVISIT: An Interactive Visual Simulation Tool for system simulation, visualization, optimization, and parameter management","IVISIT is a generic interactive visual simulation tool that is based on
Python/Numpy and can be used for system simulation, parameter optimization,
parameter management, and visualization of system dynamics as required, for
example,for developing neural network simulations, machine learning
applications, or computer vision systems. It provides classes for rapid
prototyping of applications and visualization and manipulation of system
properties using interactive GUI elements like sliders, images, textboxes,
option lists, checkboxes and buttons based on Tkinter and Matplotlib.
Parameters and simulation configurations can be stored and managed based on
SQLite database functions. This technical report describes the main
architecture and functions of IVISIT, and provides easy examples how to rapidly
implement interactive applications and manage parameter settings.",2024-07-22,Andreas Knoblauch,http://arxiv.org/pdf/2408.03341v2,cs.LG
An Ad-hoc graph node vector embedding algorithm for general knowledge graphs using Kinetica-Graph,"This paper discusses how to generate general graph node embeddings from
knowledge graph representations. The embedded space is composed of a number of
sub-features to mimic both local affinity and remote structural relevance.
These sub-feature dimensions are defined by several indicators that we
speculate to catch nodal similarities, such as hop-based topological patterns,
the number of overlapping labels, the transitional probabilities (markov-chain
probabilities), and the cluster indices computed by our recursive spectral
bisection (RSB) algorithm. These measures are flattened over the one
dimensional vector space into their respective sub-component ranges such that
the entire set of vector similarity functions could be used for finding similar
nodes. The error is defined by the sum of pairwise square differences across a
randomly selected sample of graph nodes between the assumed embeddings and the
ground truth estimates as our novel loss function. The ground truth is
estimated to be a combination of pairwise Jaccard similarity and the number of
overlapping labels. Finally, we demonstrate a multi-variate stochastic gradient
descent (SGD) algorithm to compute the weighing factors among sub-vector spaces
to minimize the average error using a random sampling logic.",2024-07-22,"B. Kaan Karamete, Eli Glaser",http://arxiv.org/pdf/2407.15906v3,cs.LG
vTensor: Flexible Virtual Tensor Management for Efficient LLM Serving,"Large Language Models (LLMs) are widely used across various domains,
processing millions of daily requests. This surge in demand poses significant
challenges in optimizing throughput and latency while keeping costs manageable.
The Key-Value (KV) cache, a standard method for retaining previous
computations, makes LLM inference highly bounded by memory. While batching
strategies can enhance performance, they frequently lead to significant memory
fragmentation. Even though cutting-edge systems like vLLM mitigate KV cache
fragmentation using paged Attention mechanisms, they still suffer from
inefficient memory and computational operations due to the tightly coupled page
management and computation kernels.
  This study introduces the vTensor, an innovative tensor structure for LLM
inference based on GPU virtual memory management (VMM). vTensor addresses
existing limitations by decoupling computation from memory defragmentation and
offering dynamic extensibility. Our framework employs a CPU-GPU heterogeneous
approach, ensuring efficient, fragmentation-free memory management while
accommodating various computation kernels across different LLM architectures.
Experimental results indicate that vTensor achieves an average speedup of 1.86x
across different models, with up to 2.42x in multi-turn chat scenarios.
Additionally, vTensor provides average speedups of 2.12x and 3.15x in kernel
evaluation, reaching up to 3.92x and 3.27x compared to SGLang Triton
prefix-prefilling kernels and vLLM paged Attention kernel, respectively.
Furthermore, it frees approximately 71.25% (57GB) of memory on the NVIDIA A100
GPU compared to vLLM, enabling more memory-intensive workloads.",2024-07-22,"Jiale Xu, Rui Zhang, Cong Guo, Weiming Hu, Zihan Liu, Feiyang Wu, Yu Feng, Shixuan Sun, Changxu Shao, Yuhong Guo, Junping Zhao, Ke Zhang, Minyi Guo, Jingwen Leng",http://arxiv.org/pdf/2407.15309v1,cs.LG
A spatiotemporal deep learning framework for prediction of crack dynamics in heterogeneous solids: efficient mapping of concrete microstructures to its fracture properties,"A spatiotemporal deep learning framework is proposed that is capable of 2D
full-field prediction of fracture in concrete mesostructures. This framework
not only predicts fractures but also captures the entire history of the
fracture process, from the crack initiation in the interfacial transition zone
to the subsequent propagation of the cracks in the mortar matrix. In addition,
a convolutional neural network is developed which can predict the averaged
stress-strain curve of the mesostructures. The UNet modeling framework, which
comprises an encoder-decoder section with skip connections, is used as the deep
learning surrogate model. Training and test data are generated from
high-fidelity fracture simulations of randomly generated concrete
mesostructures. These mesostructures include geometric variabilities such as
different aggregate particle geometrical features, spatial distribution, and
the total volume fraction of aggregates. The fracture simulations are carried
out in Abaqus, utilizing the cohesive phase-field fracture modeling technique
as the fracture modeling approach. In this work, to reduce the number of
training datasets, the spatial distribution of three sets of material
properties for three-phase concrete mesostructures, along with the spatial
phase-field damage index, are fed to the UNet to predict the corresponding
stress and spatial damage index at the subsequent step. It is shown that after
the training process using this methodology, the UNet model is capable of
accurately predicting damage on the unseen test dataset by using 470 datasets.
Moreover, another novel aspect of this work is the conversion of irregular
finite element data into regular grids using a developed pipeline. This
approach allows for the implementation of less complex UNet architecture and
facilitates the integration of phase-field fracture equations into surrogate
models for future developments.",2024-07-22,"Rasoul Najafi Koopas, Shahed Rezaei, Natalie Rauter, Richard Ostwald, Rolf Lammering",http://arxiv.org/pdf/2407.15665v2,cs.LG
Comprehensive Study on Performance Evaluation and Optimization of Model Compression: Bridging Traditional Deep Learning and Large Language Models,"Deep learning models have achieved tremendous success in most of the
industries in recent years. The evolution of these models has also led to an
increase in the model size and energy requirement, making it difficult to
deploy in production on low compute devices. An increase in the number of
connected devices around the world warrants compressed models that can be
easily deployed at the local devices with low compute capacity and power
accessibility. A wide range of solutions have been proposed by different
researchers to reduce the size and complexity of such models, prominent among
them are, Weight Quantization, Parameter Pruning, Network Pruning, low-rank
representation, weights sharing, neural architecture search, knowledge
distillation etc. In this research work, we investigate the performance impacts
on various trained deep learning models, compressed using quantization and
pruning techniques. We implemented both, quantization and pruning, compression
techniques on popular deep learning models used in the image classification,
object detection, language models and generative models-based problem
statements. We also explored performance of various large language models
(LLMs) after quantization and low rank adaptation. We used the standard
evaluation metrics (model's size, accuracy, and inference time) for all the
related problem statements and concluded this paper by discussing the
challenges and future work.",2024-07-22,"Aayush Saxena, Arit Kumar Bishwas, Ayush Ashok Mishra, Ryan Armstrong",http://arxiv.org/pdf/2407.15904v1,cs.LG
How to Shrink Confidence Sets for Many Equivalent Discrete Distributions?,"We consider the situation when a learner faces a set of unknown discrete
distributions $(p_k)_{k\in \mathcal K}$ defined over a common alphabet
$\mathcal X$, and can build for each distribution $p_k$ an individual
high-probability confidence set thanks to $n_k$ observations sampled from
$p_k$. The set $(p_k)_{k\in \mathcal K}$ is structured: each distribution $p_k$
is obtained from the same common, but unknown, distribution q via applying an
unknown permutation to $\mathcal X$. We call this
\emph{permutation-equivalence}. The goal is to build refined confidence sets
\emph{exploiting} this structural property. Like other popular notions of
structure (Lipschitz smoothness, Linearity, etc.) permutation-equivalence
naturally appears in machine learning problems, and to benefit from its
potential gain calls for a specific approach. We present a strategy to
effectively exploit permutation-equivalence, and provide a finite-time
high-probability bound on the size of the refined confidence sets output by the
strategy. Since a refinement is not possible for too few observations in
general, under mild technical assumptions, our finite-time analysis establish
when the number of observations $(n_k)_{k\in \mathcal K}$ are large enough so
that the output confidence sets improve over initial individual sets. We
carefully characterize this event and the corresponding improvement. Further,
our result implies that the size of confidence sets shrink at asymptotic rates
of $O(1/\sqrt{\sum_{k\in \mathcal K} n_k})$ and $O(1/\max_{k\in K} n_{k})$,
respectively for elements inside and outside the support of q, when the size of
each individual confidence set shrinks at respective rates of $O(1/\sqrt{n_k})$
and $O(1/n_k)$. We illustrate the practical benefit of exploiting permutation
equivalence on a reinforcement learning task.",2024-07-22,"Odalric-Ambrym Maillard, Mohammad Sadegh Talebi",http://arxiv.org/pdf/2407.15662v1,cs.LG
MuTT: A Multimodal Trajectory Transformer for Robot Skills,"High-level robot skills represent an increasingly popular paradigm in robot
programming. However, configuring the skills' parameters for a specific task
remains a manual and time-consuming endeavor. Existing approaches for learning
or optimizing these parameters often require numerous real-world executions or
do not work in dynamic environments. To address these challenges, we propose
MuTT, a novel encoder-decoder transformer architecture designed to predict
environment-aware executions of robot skills by integrating vision, trajectory,
and robot skill parameters. Notably, we pioneer the fusion of vision and
trajectory, introducing a novel trajectory projection. Furthermore, we
illustrate MuTT's efficacy as a predictor when combined with a model-based
robot skill optimizer. This approach facilitates the optimization of robot
skill parameters for the current environment, without the need for real-world
executions during optimization. Designed for compatibility with any
representation of robot skills, MuTT demonstrates its versatility across three
comprehensive experiments, showcasing superior performance across two different
skill representations.",2024-07-22,"Claudius Kienle, Benjamin Alt, Onur Celik, Philipp Becker, Darko Katic, Rainer Jäkel, Gerhard Neumann",http://arxiv.org/pdf/2407.15660v2,cs.LG
Low Rank Field-Weighted Factorization Machines for Low Latency Item Recommendation,"Factorization machine (FM) variants are widely used in recommendation systems
that operate under strict throughput and latency requirements, such as online
advertising systems. FMs are known both due to their ability to model pairwise
feature interactions while being resilient to data sparsity, and their
computational graphs that facilitate fast inference and training. Moreover,
when items are ranked as a part of a query for each incoming user, these graphs
facilitate computing the portion stemming from the user and context fields only
once per query. Consequently, in terms of inference cost, the number of user or
context fields is practically unlimited. More advanced FM variants, such as
FwFM, provide better accuracy by learning a representation of field-wise
interactions, but require computing all pairwise interaction terms explicitly.
The computational cost during inference is proportional to the square of the
number of fields, including user, context, and item. When the number of fields
is large, this is prohibitive in systems with strict latency constraints. To
mitigate this caveat, heuristic pruning of low intensity field interactions is
commonly used to accelerate inference. In this work we propose an alternative
to the pruning heuristic in FwFMs using a diagonal plus symmetric low-rank
decomposition. Our technique reduces the computational cost of inference, by
allowing it to be proportional to the number of item fields only. Using a set
of experiments on real-world datasets, we show that aggressive rank reduction
outperforms similarly aggressive pruning, both in terms of accuracy and item
recommendation speed. We corroborate our claim of faster inference
experimentally, both via a synthetic test, and by having deployed our solution
to a major online advertising system. The code to reproduce our experimental
results is at https://github.com/michaelviderman/pytorch-fm/tree/dev.",2024-07-22,"Alex Shtoff, Michael Viderman, Naama Haramaty-Krasne, Oren Somekh, Ariel Raviv, Tularam Ban",http://arxiv.org/pdf/2408.00801v1,cs.LG
Link Polarity Prediction from Sparse and Noisy Labels via Multiscale Social Balance,"Signed Graph Neural Networks (SGNNs) have recently gained attention as an
effective tool for several learning tasks on signed networks, i.e., graphs
where edges have an associated polarity. One of these tasks is to predict the
polarity of the links for which this information is missing, starting from the
network structure and the other available polarities. However, when the
available polarities are few and potentially noisy, such a task becomes
challenging.
  In this work, we devise a semi-supervised learning framework that builds
around the novel concept of \emph{multiscale social balance} to improve the
prediction of link polarities in settings characterized by limited data
quantity and quality. Our model-agnostic approach can seamlessly integrate with
any SGNN architecture, dynamically reweighting the importance of each data
sample while making strategic use of the structural information from unlabeled
edges combined with social balance theory.
  Empirical validation demonstrates that our approach outperforms established
baseline models, effectively addressing the limitations imposed by noisy and
sparse data. This result underlines the benefits of incorporating multiscale
social balance into SGNNs, opening new avenues for robust and accurate
predictions in signed network analysis.",2024-07-22,"Marco Minici, Federico Cinus, Francesco Bonchi, Giuseppe Manco",http://arxiv.org/pdf/2407.15643v1,cs.LG
Generating Sample-Based Musical Instruments Using Neural Audio Codec Language Models,"In this paper, we propose and investigate the use of neural audio codec
language models for the automatic generation of sample-based musical
instruments based on text or reference audio prompts. Our approach extends a
generative audio framework to condition on pitch across an 88-key spectrum,
velocity, and a combined text/audio embedding. We identify maintaining timbral
consistency within the generated instruments as a major challenge. To tackle
this issue, we introduce three distinct conditioning schemes. We analyze our
methods through objective metrics and human listening tests, demonstrating that
our approach can produce compelling musical instruments. Specifically, we
introduce a new objective metric to evaluate the timbral consistency of the
generated instruments and adapt the average Contrastive Language-Audio
Pretraining (CLAP) score for the text-to-instrument case, noting that its naive
application is unsuitable for assessing this task. Our findings reveal a
complex interplay between timbral consistency, the quality of generated
samples, and their correspondence to the input prompt.",2024-07-22,"Shahan Nercessian, Johannes Imort, Ninon Devis, Frederik Blang",http://arxiv.org/pdf/2407.15641v1,cs.LG
RadioRAG: Factual large language models for enhanced diagnostics in radiology using online retrieval augmented generation,"Large language models (LLMs) often generate outdated or inaccurate
information based on static training datasets. Retrieval augmented generation
(RAG) mitigates this by integrating outside data sources. While previous RAG
systems used pre-assembled, fixed databases with limited flexibility, we have
developed Radiology RAG (RadioRAG), an end-to-end framework that retrieves data
from authoritative radiologic online sources in real-time. We evaluate the
diagnostic accuracy of various LLMs when answering radiology-specific questions
with and without access to additional online information via RAG. Using 80
questions from the RSNA Case Collection across radiologic subspecialties and 24
additional expert-curated questions with reference standard answers, LLMs
(GPT-3.5-turbo, GPT-4, Mistral-7B, Mixtral-8x7B, and Llama3 [8B and 70B]) were
prompted with and without RadioRAG in a zero-shot inference scenario RadioRAG
retrieved context-specific information from www.radiopaedia.org in real-time.
Accuracy was investigated. Statistical analyses were performed using
bootstrapping. The results were further compared with human performance.
RadioRAG improved diagnostic accuracy across most LLMs, with relative accuracy
increases ranging up to 54% for different LLMs. It matched or exceeded non-RAG
models and the human radiologist in question answering across radiologic
subspecialties, particularly in breast imaging and emergency radiology.
However, the degree of improvement varied among models; GPT-3.5-turbo and
Mixtral-8x7B-instruct-v0.1 saw notable gains, while Mistral-7B-instruct-v0.2
showed no improvement, highlighting variability in RadioRAG's effectiveness.
LLMs benefit when provided access to domain-specific data beyond their training
data. For radiology, RadioRAG establishes a robust framework that substantially
improves diagnostic accuracy and factuality in radiological question answering.",2024-07-22,"Soroosh Tayebi Arasteh, Mahshad Lotfinia, Keno Bressem, Robert Siepmann, Lisa Adams, Dyke Ferber, Christiane Kuhl, Jakob Nikolas Kather, Sven Nebelung, Daniel Truhn",http://arxiv.org/pdf/2407.15621v2,cs.LG
Dual Test-time Training for Out-of-distribution Recommender System,"Deep learning has been widely applied in recommender systems, which has
achieved revolutionary progress recently. However, most existing learning-based
methods assume that the user and item distributions remain unchanged between
the training phase and the test phase. However, the distribution of user and
item features can naturally shift in real-world scenarios, potentially
resulting in a substantial decrease in recommendation performance. This
phenomenon can be formulated as an Out-Of-Distribution (OOD) recommendation
problem. To address this challenge, we propose a novel Dual Test-Time-Training
framework for OOD Recommendation, termed DT3OR. In DT3OR, we incorporate a
model adaptation mechanism during the test-time phase to carefully update the
recommendation model, allowing the model to specially adapt to the shifting
user and item features. To be specific, we propose a self-distillation task and
a contrastive task to assist the model learning both the user's invariant
interest preferences and the variant user/item characteristics during the
test-time phase, thus facilitating a smooth adaptation to the shifting
features. Furthermore, we provide theoretical analysis to support the rationale
behind our dual test-time training framework. To the best of our knowledge,
this paper is the first work to address OOD recommendation via a
test-time-training strategy. We conduct experiments on three datasets with
various backbones. Comprehensive experimental results have demonstrated the
effectiveness of DT3OR compared to other state-of-the-art baselines.",2024-07-22,"Xihong Yang, Yiqi Wang, Jin Chen, Wenqi Fan, Xiangyu Zhao, En Zhu, Xinwang Liu, Defu Lian",http://arxiv.org/pdf/2407.15620v2,cs.LG
Distance-based mutual congestion feature selection with genetic algorithm for high-dimensional medical datasets,"Feature selection poses a challenge in small-sample high-dimensional
datasets, where the number of features exceeds the number of observations, as
seen in microarray, gene expression, and medical datasets. There isn't a
universally optimal feature selection method applicable to any data
distribution, and as a result, the literature consistently endeavors to address
this issue. One recent approach in feature selection is termed frequency-based
feature selection. However, existing methods in this domain tend to overlook
feature values, focusing solely on the distribution in the response variable.
In response, this paper introduces the Distance-based Mutual Congestion (DMC)
as a filter method that considers both the feature values and the distribution
of observations in the response variable. DMC sorts the features of datasets,
and the top 5% are retained and clustered by KMeans to mitigate
multicollinearity. This is achieved by randomly selecting one feature from each
cluster. The selected features form the feature space, and the search space for
the Genetic Algorithm with Adaptive Rates (GAwAR) will be approximated using
this feature space. GAwAR approximates the combination of the top 10 features
that maximizes prediction accuracy within a wrapper scheme. To prevent
premature convergence, GAwAR adaptively updates the crossover and mutation
rates. The hybrid DMC-GAwAR is applicable to binary classification datasets,
and experimental results demonstrate its superiority over some recent works.
The implementation and corresponding data are available at
https://github.com/hnematzadeh/DMC-GAwAR",2024-07-22,"Hossein Nematzadeh, Joseph Mani, Zahra Nematzadeh, Ebrahim Akbari, Radziah Mohamad",http://arxiv.org/pdf/2407.15611v1,cs.LG
Discrete Flow Matching,"Despite Flow Matching and diffusion models having emerged as powerful
generative paradigms for continuous variables such as images and videos, their
application to high-dimensional discrete data, such as language, is still
limited. In this work, we present Discrete Flow Matching, a novel discrete flow
paradigm designed specifically for generating discrete data. Discrete Flow
Matching offers several key contributions:(i) it works with a general family of
probability paths interpolating between source and target distributions; (ii)
it allows for a generic formula for sampling from these probability paths using
learned posteriors such as the probability denoiser ($x$-prediction) and
noise-prediction ($\epsilon$-prediction); (iii) practically, focusing on
specific probability paths defined with different schedulers improves
generative perplexity compared to previous discrete diffusion and flow models;
and (iv) by scaling Discrete Flow Matching models up to 1.7B parameters, we
reach 6.7% Pass@1 and 13.4% Pass@10 on HumanEval and 6.7% Pass@1 and 20.6%
Pass@10 on 1-shot MBPP coding benchmarks. Our approach is capable of generating
high-quality discrete data in a non-autoregressive fashion, significantly
closing the gap between autoregressive models and discrete flow models.",2024-07-22,"Itai Gat, Tal Remez, Neta Shaul, Felix Kreuk, Ricky T. Q. Chen, Gabriel Synnaeve, Yossi Adi, Yaron Lipman",http://arxiv.org/pdf/2407.15595v2,cs.LG
Exploring the Effectiveness of Object-Centric Representations in Visual Question Answering: Comparative Insights with Foundation Models,"Object-centric (OC) representations, which model visual scenes as
compositions of discrete objects, have the potential to be used in various
downstream tasks to achieve systematic compositional generalization and
facilitate reasoning. However, these claims have yet to be thoroughly validated
empirically. Recently, foundation models have demonstrated unparalleled
capabilities across diverse domains, from language to computer vision,
positioning them as a potential cornerstone of future research for a wide range
of computational tasks. In this paper, we conduct an extensive empirical study
on representation learning for downstream Visual Question Answering (VQA),
which requires an accurate compositional understanding of the scene. We
thoroughly investigate the benefits and trade-offs of OC models and alternative
approaches including large pre-trained foundation models on both synthetic and
real-world data, ultimately identifying a promising path to leverage the
strengths of both paradigms. The extensiveness of our study, encompassing over
600 downstream VQA models and 15 different types of upstream representations,
also provides several additional insights that we believe will be of interest
to the community at large.",2024-07-22,"Amir Mohammad Karimi Mamaghan, Samuele Papa, Karl Henrik Johansson, Stefan Bauer, Andrea Dittadi",http://arxiv.org/pdf/2407.15589v5,cs.LG
Data driven weather forecasts trained and initialised directly from observations,"Skilful Machine Learned weather forecasts have challenged our approach to
numerical weather prediction, demonstrating competitive performance compared to
traditional physics-based approaches. Data-driven systems have been trained to
forecast future weather by learning from long historical records of past
weather such as the ECMWF ERA5. These datasets have been made freely available
to the wider research community, including the commercial sector, which has
been a major factor in the rapid rise of ML forecast systems and the levels of
accuracy they have achieved. However, historical reanalyses used for training
and real-time analyses used for initial conditions are produced by data
assimilation, an optimal blending of observations with a physics-based forecast
model. As such, many ML forecast systems have an implicit and unquantified
dependence on the physics-based models they seek to challenge. Here we propose
a new approach, training a neural network to predict future weather purely from
historical observations with no dependence on reanalyses. We use raw
observations to initialise a model of the atmosphere (in observation space)
learned directly from the observations themselves. Forecasts of crucial weather
parameters (such as surface temperature and wind) are obtained by predicting
weather parameter observations (e.g. SYNOP surface data) at future times and
arbitrary locations. We present preliminary results on forecasting observations
12-hours into the future. These already demonstrate successful learning of time
evolutions of the physical processes captured in real observations. We argue
that this new approach, by staying purely in observation space, avoids many of
the challenges of traditional data assimilation, can exploit a wider range of
observations and is readily expanded to simultaneous forecasting of the full
Earth system (atmosphere, land, ocean and composition).",2024-07-22,"Anthony McNally, Christian Lessig, Peter Lean, Eulalie Boucher, Mihai Alexe, Ewan Pinnington, Matthew Chantry, Simon Lang, Chris Burrows, Marcin Chrust, Florian Pinault, Ethel Villeneuve, Niels Bormann, Sean Healy",http://arxiv.org/pdf/2407.15586v1,cs.LG
Annealed Multiple Choice Learning: Overcoming limitations of Winner-takes-all with annealing,"We introduce Annealed Multiple Choice Learning (aMCL) which combines
simulated annealing with MCL. MCL is a learning framework handling ambiguous
tasks by predicting a small set of plausible hypotheses. These hypotheses are
trained using the Winner-takes-all (WTA) scheme, which promotes the diversity
of the predictions. However, this scheme may converge toward an arbitrarily
suboptimal local minimum, due to the greedy nature of WTA. We overcome this
limitation using annealing, which enhances the exploration of the hypothesis
space during training. We leverage insights from statistical physics and
information theory to provide a detailed description of the model training
trajectory. Additionally, we validate our algorithm by extensive experiments on
synthetic datasets, on the standard UCI benchmark, and on speech separation.",2024-07-22,"David Perera, Victor Letzelter, Théo Mariotte, Adrien Cortés, Mickael Chen, Slim Essid, Gaël Richard",http://arxiv.org/pdf/2407.15580v3,cs.LG
A New Theoretical Perspective on Data Heterogeneity in Federated Optimization,"In federated learning (FL), data heterogeneity is the main reason that
existing theoretical analyses are pessimistic about the convergence rate. In
particular, for many FL algorithms, the convergence rate grows dramatically
when the number of local updates becomes large, especially when the product of
the gradient divergence and local Lipschitz constant is large. However,
empirical studies can show that more local updates can improve the convergence
rate even when these two parameters are large, which is inconsistent with the
theoretical findings. This paper aims to bridge this gap between theoretical
understanding and practical performance by providing a theoretical analysis
from a new perspective on data heterogeneity. In particular, we propose a new
and weaker assumption compared to the local Lipschitz gradient assumption,
named the heterogeneity-driven pseudo-Lipschitz assumption. We show that this
and the gradient divergence assumptions can jointly characterize the effect of
data heterogeneity. By deriving a convergence upper bound for FedAvg and its
extensions, we show that, compared to the existing works, local Lipschitz
constant is replaced by the much smaller heterogeneity-driven pseudo-Lipschitz
constant and the corresponding convergence upper bound can be significantly
reduced for the same number of local updates, although its order stays the
same. In addition, when the local objective function is quadratic, more
insights on the impact of data heterogeneity can be obtained using the
heterogeneity-driven pseudo-Lipschitz constant. For example, we can identify a
region where FedAvg can outperform mini-batch SGD even when the gradient
divergence can be arbitrarily large. Our findings are validated using
experiments.",2024-07-22,"Jiayi Wang, Shiqiang Wang, Rong-Rong Chen, Mingyue Ji",http://arxiv.org/pdf/2407.15567v1,cs.LG
The Rlign Algorithm for Enhanced Electrocardiogram Analysis through R-Peak Alignment for Explainable Classification and Clustering,"Electrocardiogram (ECG) recordings have long been vital in diagnosing
different cardiac conditions. Recently, research in the field of automatic ECG
processing using machine learning methods has gained importance, mainly by
utilizing deep learning methods on raw ECG signals. A major advantage of models
like convolutional neural networks (CNNs) is their ability to effectively
process biomedical imaging or signal data. However, this strength is tempered
by challenges related to their lack of explainability, the need for a large
amount of training data, and the complexities involved in adapting them for
unsupervised clustering tasks. In addressing these tasks, we aim to reintroduce
shallow learning techniques, including support vector machines and principal
components analysis, into ECG signal processing by leveraging their
semi-structured, cyclic form. To this end, we developed and evaluated a
transformation that effectively restructures ECG signals into a fully
structured format, facilitating their subsequent analysis using shallow
learning algorithms. In this study, we present this adaptive transformative
approach that aligns R-peaks across all signals in a dataset and resamples the
segments between R-peaks, both with and without heart rate dependencies. We
illustrate the substantial benefit of this transformation for traditional
analysis techniques in the areas of classification, clustering, and
explainability, outperforming commercial software for median beat
transformation and CNN approaches. Our approach demonstrates a significant
advantage for shallow machine learning methods over CNNs, especially when
dealing with limited training data. Additionally, we release a fully tested and
publicly accessible code framework, providing a robust alignment pipeline to
support future research, available at https://github.com/imi-ms/rlign.",2024-07-22,"Lucas Plagwitz, Lucas Bickmann, Michael Fujarski, Alexander Brenner, Warnes Gobalakrishnan, Lars Eckardt, Antonius Büscher, Julian Varghese",http://arxiv.org/pdf/2407.15555v2,cs.LG
Enhancing Cognitive Workload Classification Using Integrated LSTM Layers and CNNs for fNIRS Data Analysis,"Functional near-infrared spectroscopy (fNIRS) is employed as a non-invasive
method to monitor functional brain activation by capturing changes in the
concentrations of oxygenated haemoglobin (HbO) and deoxygenated haemo-globin
(HbR). Various machine learning classification techniques have been utilized to
distinguish cognitive states. However, conventional machine learning methods,
although simpler to implement, undergo a complex pre-processing phase before
network training and demonstrate reduced accuracy due to inadequate data
preprocessing. Additionally, previous research in cog-nitive load assessment
using fNIRS has predominantly focused on differ-sizeentiating between two
levels of mental workload. These studies mainly aim to classify low and high
levels of cognitive load or distinguish between easy and difficult tasks. To
address these limitations associated with conven-tional methods, this paper
conducts a comprehensive exploration of the im-pact of Long Short-Term Memory
(LSTM) layers on the effectiveness of Convolutional Neural Networks (CNNs)
within deep learning models. This is to address the issues related to spatial
features overfitting and lack of tem-poral dependencies in CNN in the previous
studies. By integrating LSTM layers, the model can capture temporal
dependencies in the fNIRS data, al-lowing for a more comprehensive
understanding of cognitive states. The primary objective is to assess how
incorporating LSTM layers enhances the performance of CNNs. The experimental
results presented in this paper demonstrate that the integration of LSTM layers
with Convolutional layers results in an increase in the accuracy of deep
learning models from 97.40% to 97.92%.",2024-07-22,"Mehshan Ahmed Khan, Houshyar Asadi, Mohammad Reza Chalak Qazani, Adetokunbo Arogbonlo, Siamak Pedrammehr, Adnan Anwar, Asim Bhatti, Saeid Nahavandi, Chee Peng Lim",http://arxiv.org/pdf/2407.15901v1,cs.LG
Latent Adversarial Training Improves Robustness to Persistent Harmful Behaviors in LLMs,"Large language models (LLMs) can often be made to behave in undesirable ways
that they are explicitly fine-tuned not to. For example, the LLM red-teaming
literature has produced a wide variety of 'jailbreaking' techniques to elicit
harmful text from models that were fine-tuned to be harmless. Recent work on
red-teaming, model editing, and interpretability suggests that this challenge
stems from how (adversarial) fine-tuning largely serves to suppress rather than
remove undesirable capabilities from LLMs. Prior work has introduced latent
adversarial training (LAT) as a way to improve robustness to broad classes of
failures. These prior works have considered untargeted latent space attacks
where the adversary perturbs latent activations to maximize loss on examples of
desirable behavior. Untargeted LAT can provide a generic type of robustness but
does not leverage information about specific failure modes. Here, we experiment
with targeted LAT where the adversary seeks to minimize loss on a specific
competing task. We find that it can augment a wide variety of state-of-the-art
methods. First, we use targeted LAT to improve robustness to jailbreaks,
outperforming a strong R2D2 baseline with orders of magnitude less compute.
Second, we use it to more effectively remove backdoors with no knowledge of the
trigger. Finally, we use it to more effectively unlearn knowledge for specific
undesirable tasks in a way that is also more robust to re-learning. Overall,
our results suggest that targeted LAT can be an effective tool for defending
against harmful behaviors from LLMs.",2024-07-22,"Abhay Sheshadri, Aidan Ewart, Phillip Guo, Aengus Lynch, Cindy Wu, Vivek Hebbar, Henry Sleight, Asa Cooper Stickland, Ethan Perez, Dylan Hadfield-Menell, Stephen Casper",http://arxiv.org/pdf/2407.15549v2,cs.LG
Inverted Activations: Reducing Memory Footprint in Neural Network Training,"The scaling of neural networks with increasing data and model sizes
necessitates the development of more efficient deep learning algorithms. A
significant challenge in neural network training is the memory footprint
associated with activation tensors, particularly in pointwise nonlinearity
layers that traditionally save the entire input tensor for the backward pass,
leading to substantial memory consumption.
  In this paper, we propose a modification to the handling of activation
tensors in pointwise nonlinearity layers. Our method involves saving the output
tensor instead of the input tensor during the forward pass. Since the
subsequent layer typically also saves its input tensor, this approach reduces
the total memory required by storing only one tensor between layers instead of
two. This optimization is especially beneficial for transformer-based
architectures like GPT, BERT, Mistral, and Llama. To enable this approach, we
utilize the inverse function of the nonlinearity during the backward pass. As
the inverse cannot be computed analytically for most nonlinearities, we
construct accurate approximations using simpler functions. Experimental results
demonstrate that our method significantly reduces memory usage without
affecting training accuracy or computational performance.
  Our implementation is provided as a drop-in replacement for standard
nonlinearity layers in the PyTorch framework, facilitating easy adoption
without requiring architectural modifications.",2024-07-22,"Georgii Novikov, Ivan Oseledets",http://arxiv.org/pdf/2407.15545v2,cs.LG
Improving probabilistic forecasts of extreme wind speeds by training statistical post-processing models with weighted scoring rules,"Accurate forecasts of extreme wind speeds are of high importance for many
applications. Such forecasts are usually generated by ensembles of numerical
weather prediction (NWP) models, which however can be biased and have errors in
dispersion, thus necessitating the application of statistical post-processing
techniques. In this work we aim to improve statistical post-processing models
for probabilistic predictions of extreme wind speeds. We do this by adjusting
the training procedure used to fit ensemble model output statistics (EMOS)
models - a commonly applied post-processing technique - and propose estimating
parameters using the so-called threshold-weighted continuous ranked probability
score (twCRPS), a proper scoring rule that places special emphasis on
predictions over a threshold. We show that training using the twCRPS leads to
improved extreme event performance of post-processing models for a variety of
thresholds. We find a distribution body-tail trade-off where improved
performance for probabilistic predictions of extreme events comes with worse
performance for predictions of the distribution body. However, we introduce
strategies to mitigate this trade-off based on weighted training and linear
pooling. Finally, we consider some synthetic experiments to explain the
training impact of the twCRPS and derive closed-form expressions of the twCRPS
for a number of distributions, giving the first such collection in the
literature. The results will enable researchers and practitioners alike to
improve the performance of probabilistic forecasting models for extremes and
other events of interest.",2024-07-22,"Jakob Benjamin Wessel, Christopher A. T. Ferro, Gavin R. Evans, Frank Kwasniok",http://arxiv.org/pdf/2407.15900v4,cs.LG
Exterior Penalty Policy Optimization with Penalty Metric Network under Constraints,"In Constrained Reinforcement Learning (CRL), agents explore the environment
to learn the optimal policy while satisfying constraints. The penalty function
method has recently been studied as an effective approach for handling
constraints, which imposes constraints penalties on the objective to transform
the constrained problem into an unconstrained one. However, it is challenging
to choose appropriate penalties that balance policy performance and constraint
satisfaction efficiently. In this paper, we propose a theoretically guaranteed
penalty function method, Exterior Penalty Policy Optimization (EPO), with
adaptive penalties generated by a Penalty Metric Network (PMN). PMN responds
appropriately to varying degrees of constraint violations, enabling efficient
constraint satisfaction and safe exploration. We theoretically prove that EPO
consistently improves constraint satisfaction with a convergence guarantee. We
propose a new surrogate function and provide worst-case constraint violation
and approximation error. In practice, we propose an effective smooth penalty
function, which can be easily implemented with a first-order optimizer.
Extensive experiments are conducted, showing that EPO outperforms the baselines
in terms of policy performance and constraint satisfaction with a stable
training process, particularly on complex tasks.",2024-07-22,"Shiqing Gao, Jiaxin Ding, Luoyi Fu, Xinbing Wang, Chenghu Zhou",http://arxiv.org/pdf/2407.15537v1,cs.LG
Interpretable Concept-Based Memory Reasoning,"The lack of transparency in the decision-making processes of deep learning
systems presents a significant challenge in modern artificial intelligence
(AI), as it impairs users' ability to rely on and verify these systems. To
address this challenge, Concept Bottleneck Models (CBMs) have made significant
progress by incorporating human-interpretable concepts into deep learning
architectures. This approach allows predictions to be traced back to specific
concept patterns that users can understand and potentially intervene on.
However, existing CBMs' task predictors are not fully interpretable, preventing
a thorough analysis and any form of formal verification of their
decision-making process prior to deployment, thereby raising significant
reliability concerns. To bridge this gap, we introduce Concept-based Memory
Reasoner (CMR), a novel CBM designed to provide a human-understandable and
provably-verifiable task prediction process. Our approach is to model each task
prediction as a neural selection mechanism over a memory of learnable logic
rules, followed by a symbolic evaluation of the selected rule. The presence of
an explicit memory and the symbolic evaluation allow domain experts to inspect
and formally verify the validity of certain global properties of interest for
the task prediction process. Experimental results demonstrate that CMR achieves
better accuracy-interpretability trade-offs to state-of-the-art CBMs, discovers
logic rules consistent with ground truths, allows for rule interventions, and
allows pre-deployment verification.",2024-07-22,"David Debot, Pietro Barbiero, Francesco Giannini, Gabriele Ciravegna, Michelangelo Diligenti, Giuseppe Marra",http://arxiv.org/pdf/2407.15527v2,cs.LG
Synthetic Image Learning: Preserving Performance and Preventing Membership Inference Attacks,"Generative artificial intelligence has transformed the generation of
synthetic data, providing innovative solutions to challenges like data scarcity
and privacy, which are particularly critical in fields such as medicine.
However, the effective use of this synthetic data to train high-performance
models remains a significant challenge. This paper addresses this issue by
introducing Knowledge Recycling (KR), a pipeline designed to optimise the
generation and use of synthetic data for training downstream classifiers. At
the heart of this pipeline is Generative Knowledge Distillation (GKD), the
proposed technique that significantly improves the quality and usefulness of
the information provided to classifiers through a synthetic dataset
regeneration and soft labelling mechanism. The KR pipeline has been tested on a
variety of datasets, with a focus on six highly heterogeneous medical image
datasets, ranging from retinal images to organ scans. The results show a
significant reduction in the performance gap between models trained on real and
synthetic data, with models based on synthetic data outperforming those trained
on real data in some cases. Furthermore, the resulting models show almost
complete immunity to Membership Inference Attacks, manifesting privacy
properties missing in models trained with conventional techniques.",2024-07-22,"Eugenio Lomurno, Matteo Matteucci",http://arxiv.org/pdf/2407.15526v2,cs.LG
The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface,"As the number of scientific publications and preprints is growing
exponentially, several attempts have been made to navigate this complex and
increasingly detailed landscape. These have almost exclusively taken
unsupervised approaches that fail to incorporate domain knowledge and lack the
structural organisation required for intuitive interactive human exploration
and discovery. Especially in highly interdisciplinary fields, a deep
understanding of the connectedness of research works across topics is essential
for generating insights. We have developed a unique approach to data navigation
that leans on geographical visualisation and uses hierarchically structured
domain knowledge to enable end-users to explore knowledge spaces grounded in
their desired domains of interest. This can take advantage of existing
ontologies, proprietary intelligence schemata, or be directly derived from the
underlying data through hierarchical topic modelling. Our approach uses natural
language processing techniques to extract named entities from the underlying
data and normalise them against relevant domain references and navigational
structures. The knowledge is integrated by first calculating similarities
between entities based on their shared extracted feature space and then by
alignment to the navigational structures. The result is a knowledge graph that
allows for full text and semantic graph query and structured topic driven
navigation. This allows end-users to identify entities relevant to their needs
and access extensive graph analytics. The user interface facilitates graphical
interaction with the underlying knowledge graph and mimics a cartographic map
to maximise ease of use and widen adoption. We demonstrate an exemplar project
using our generalisable and scalable infrastructure for an academic biomedical
literature corpus that is grounded against hundreds of different named domain
entities.",2024-07-22,"Johannes Zimmermann, Dariusz Wiktorek, Thomas Meusburger, Miquel Monge-Dalmau, Antonio Fabregat, Alexander Jarasch, Günter Schmidt, Jorge S. Reis-Filho, T. Ian Simpson",http://arxiv.org/pdf/2408.03339v1,cs.LG
Multiple Importance Sampling for Stochastic Gradient Estimation,"We introduce a theoretical and practical framework for efficient importance
sampling of mini-batch samples for gradient estimation from single and multiple
probability distributions. To handle noisy gradients, our framework dynamically
evolves the importance distribution during training by utilizing a
self-adaptive metric. Our framework combines multiple, diverse sampling
distributions, each tailored to specific parameter gradients. This approach
facilitates the importance sampling of vector-valued gradient estimation.
Rather than naively combining multiple distributions, our framework involves
optimally weighting data contribution across multiple distributions. This
adapted combination of multiple importance yields superior gradient estimates,
leading to faster training convergence. We demonstrate the effectiveness of our
approach through empirical evaluations across a range of optimization tasks
like classification and regression on both image and point cloud datasets.",2024-07-22,"Corentin Salaün, Xingchang Huang, Iliyan Georgiev, Niloy J. Mitra, Gurprit Singh",http://arxiv.org/pdf/2407.15525v2,cs.LG
Spatial-Temporal Cross-View Contrastive Pre-training for Check-in Sequence Representation Learning,"The rapid growth of location-based services (LBS) has yielded massive amounts
of data on human mobility. Effectively extracting meaningful representations
for user-generated check-in sequences is pivotal for facilitating various
downstream services. However, the user-generated check-in data are
simultaneously influenced by the surrounding objective circumstances and the
user's subjective intention. Specifically, the temporal uncertainty and spatial
diversity exhibited in check-in data make it difficult to capture the
macroscopic spatial-temporal patterns of users and to understand the semantics
of user mobility activities. Furthermore, the distinct characteristics of the
temporal and spatial information in check-in sequences call for an effective
fusion method to incorporate these two types of information. In this paper, we
propose a novel Spatial-Temporal Cross-view Contrastive Representation (STCCR)
framework for check-in sequence representation learning. Specifically, STCCR
addresses the above challenges by employing self-supervision from ""spatial
topic"" and ""temporal intention"" views, facilitating effective fusion of spatial
and temporal information at the semantic level. Besides, STCCR leverages
contrastive clustering to uncover users' shared spatial topics from diverse
mobility activities, while employing angular momentum contrast to mitigate the
impact of temporal uncertainty and noise. We extensively evaluate STCCR on
three real-world datasets and demonstrate its superior performance across three
downstream tasks.",2024-07-22,"Letian Gong, Huaiyu Wan, Shengnan Guo, Xiucheng Li, Yan Lin, Erwen Zheng, Tianyi Wang, Zeyu Zhou, Youfang Lin",http://arxiv.org/pdf/2407.15899v3,cs.LG
Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models,"The inference demand for LLMs has skyrocketed in recent months, and serving
models with low latencies remains challenging due to the quadratic input length
complexity of the attention layers. In this work, we investigate the effect of
dropping MLP and attention layers at inference time on the performance of
Llama-v2 models. We find that dropping dreeper attention layers only marginally
decreases performance but leads to the best speedups alongside dropping entire
layers. For example, removing 33\% of attention layers in a 13B Llama2 model
results in a 1.8\% drop in average performance over the OpenLLM benchmark. We
also observe that skipping layers except the latter layers reduces performances
for more layers skipped, except for skipping the attention layers.",2024-07-22,"Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini",http://arxiv.org/pdf/2407.15516v1,cs.LG
Increasing the Robustness of Model Predictions to Missing Sensors in Earth Observation,"Multi-sensor ML models for EO aim to enhance prediction accuracy by
integrating data from various sources. However, the presence of missing data
poses a significant challenge, particularly in non-persistent sensors that can
be affected by external factors. Existing literature has explored strategies
like temporal dropout and sensor-invariant models to address the generalization
to missing data issues. Inspired by these works, we study two novel methods
tailored for multi-sensor scenarios, namely Input Sensor Dropout (ISensD) and
Ensemble Sensor Invariant (ESensI). Through experimentation on three
multi-sensor temporal EO datasets, we demonstrate that these methods
effectively increase the robustness of model predictions to missing sensors.
Particularly, we focus on how the predictive performance of models drops when
sensors are missing at different levels. We observe that ensemble multi-sensor
models are the most robust to the lack of sensors. In addition, the sensor
dropout component in ISensD shows promising robustness results.",2024-07-22,"Francisco Mena, Diego Arenas, Andreas Dengel",http://arxiv.org/pdf/2407.15512v2,cs.LG
Fundamental Limits of Prompt Compression: A Rate-Distortion Framework for Black-Box Language Models,"We formalize the problem of prompt compression for large language models
(LLMs) and present a framework to unify token-level prompt compression methods
which create hard prompts for black-box models. We derive the distortion-rate
function for this setup as a linear program, and provide an efficient algorithm
to compute this fundamental limit via the dual of the linear program. Using the
distortion-rate function as the baseline, we study the performance of existing
compression schemes on a synthetic dataset consisting of prompts generated from
a Markov chain, natural language queries, and their respective answers. Our
empirical analysis demonstrates the criticality of query-aware prompt
compression, where the compressor has knowledge of the downstream task/query
for the black-box LLM. We show that there is a large gap between the
performance of current prompt compression methods and the optimal strategy, and
propose Adaptive QuerySelect, a query-aware, variable-rate adaptation of a
prior work to close the gap. We extend our experiments to a small natural
language dataset to further confirm our findings on our synthetic dataset.",2024-07-22,"Alliot Nagle, Adway Girish, Marco Bondaschi, Michael Gastpar, Ashok Vardhan Makkuva, Hyeji Kim",http://arxiv.org/pdf/2407.15504v2,cs.LG
Comprehensive Overview of Reward Engineering and Shaping in Advancing Reinforcement Learning Applications,"The aim of Reinforcement Learning (RL) in real-world applications is to
create systems capable of making autonomous decisions by learning from their
environment through trial and error. This paper emphasizes the importance of
reward engineering and reward shaping in enhancing the efficiency and
effectiveness of reinforcement learning algorithms. Reward engineering involves
designing reward functions that accurately reflect the desired outcomes, while
reward shaping provides additional feedback to guide the learning process,
accelerating convergence to optimal policies. Despite significant advancements
in reinforcement learning, several limitations persist. One key challenge is
the sparse and delayed nature of rewards in many real-world scenarios, which
can hinder learning progress. Additionally, the complexity of accurately
modeling real-world environments and the computational demands of reinforcement
learning algorithms remain substantial obstacles. On the other hand, recent
advancements in deep learning and neural networks have significantly improved
the capability of reinforcement learning systems to handle high-dimensional
state and action spaces, enabling their application to complex tasks such as
robotics, autonomous driving, and game playing. This paper provides a
comprehensive review of the current state of reinforcement learning, focusing
on the methodologies and techniques used in reward engineering and reward
shaping. It critically analyzes the limitations and recent advancements in the
field, offering insights into future research directions and potential
applications in various domains.",2024-07-22,"Sinan Ibrahim, Mostafa Mostafa, Ali Jnadi, Hadi Salloum, Pavel Osinenko",http://arxiv.org/pdf/2408.10215v2,cs.LG
Affordance Labeling and Exploration: A Manifold-Based Approach,"The advancement in computing power has significantly reduced the training
times for deep learning, fostering the rapid development of networks designed
for object recognition. However, the exploration of object utility, which is
the affordance of the object, as opposed to object recognition, has received
comparatively less attention. This work focuses on the problem of exploration
of object affordances using existing networks trained on the object
classification dataset. While pre-trained networks have proven to be
instrumental in transfer learning for classification tasks, this work diverges
from conventional object classification methods. Instead, it employs
pre-trained networks to discern affordance labels without the need for
specialized layers, abstaining from modifying the final layers through the
addition of classification layers. To facilitate the determination of
affordance labels without such modifications, two approaches, i.e. subspace
clustering and manifold curvature methods are tested. These methods offer a
distinct perspective on affordance label recognition. Especially, manifold
curvature method has been successfully tested with nine distinct pre-trained
networks, each achieving an accuracy exceeding 95%. Moreover, it is observed
that manifold curvature and subspace clustering methods explore affordance
labels that are not marked in the ground truth, but object affords in various
cases.",2024-07-22,"İsmail Özçil, A. Buğra Koku",http://arxiv.org/pdf/2407.15479v1,cs.LG
MODRL-TA:A Multi-Objective Deep Reinforcement Learning Framework for Traffic Allocation in E-Commerce Search,"Traffic allocation is a process of redistributing natural traffic to products
by adjusting their positions in the post-search phase, aimed at effectively
fostering merchant growth, precisely meeting customer demands, and ensuring the
maximization of interests across various parties within e-commerce platforms.
Existing methods based on learning to rank neglect the long-term value of
traffic allocation, whereas approaches of reinforcement learning suffer from
balancing multiple objectives and the difficulties of cold starts within
realworld data environments. To address the aforementioned issues, this paper
propose a multi-objective deep reinforcement learning framework consisting of
multi-objective Q-learning (MOQ), a decision fusion algorithm (DFM) based on
the cross-entropy method(CEM), and a progressive data augmentation system(PDA).
Specifically. MOQ constructs ensemble RL models, each dedicated to an
objective, such as click-through rate, conversion rate, etc. These models
individually determine the position of items as actions, aiming to estimate the
long-term value of multiple objectives from an individual perspective. Then we
employ DFM to dynamically adjust weights among objectives to maximize long-term
value, addressing temporal dynamics in objective preferences in e-commerce
scenarios. Initially, PDA trained MOQ with simulated data from offline logs. As
experiments progressed, it strategically integrated real user interaction data,
ultimately replacing the simulated dataset to alleviate distributional shifts
and the cold start problem. Experimental results on real-world online
e-commerce systems demonstrate the significant improvements of MODRL-TA, and we
have successfully deployed MODRL-TA on an e-commerce search platform.",2024-07-22,"Peng Cheng, Huimu Wang, Jinyuan Zhao, Yihao Wang, Enqiang Xu, Yu Zhao, Zhuojian Xiao, Songlin Wang, Guoyu Tang, Lin Liu, Sulong Xu",http://arxiv.org/pdf/2407.15476v1,cs.LG
The Diversity Bonus: Learning from Dissimilar Distributed Clients in Personalized Federated Learning,"Personalized Federated Learning (PFL) is a commonly used framework that
allows clients to collaboratively train their personalized models. PFL is
particularly useful for handling situations where data from different clients
are not independent and identically distributed (non-IID). Previous research in
PFL implicitly assumes that clients can gain more benefits from those with
similar data distributions. Correspondingly, methods such as personalized
weight aggregation are developed to assign higher weights to similar clients
during training. We pose a question: can a client benefit from other clients
with dissimilar data distributions and if so, how? This question is
particularly relevant in scenarios with a high degree of non-IID, where clients
have widely different data distributions, and learning from only similar
clients will lose knowledge from many other clients. We note that when dealing
with clients with similar data distributions, methods such as personalized
weight aggregation tend to enforce their models to be close in the parameter
space. It is reasonable to conjecture that a client can benefit from dissimilar
clients if we allow their models to depart from each other. Based on this idea,
we propose DiversiFed which allows each client to learn from clients with
diversified data distribution in personalized federated learning. DiversiFed
pushes personalized models of clients with dissimilar data distributions apart
in the parameter space while pulling together those with similar distributions.
In addition, to achieve the above effect without using prior knowledge of data
distribution, we design a loss function that leverages the model similarity to
determine the degree of attraction and repulsion between any two models.
Experiments on several datasets show that DiversiFed can benefit from
dissimilar clients and thus outperform the state-of-the-art methods.",2024-07-22,"Xinghao Wu, Xuefeng Liu, Jianwei Niu, Guogang Zhu, Shaojie Tang, Xiaotian Li, Jiannong Cao",http://arxiv.org/pdf/2407.15464v1,cs.LG
Retrieval with Learned Similarities,"Retrieval plays a fundamental role in recommendation systems, search, and
natural language processing (NLP) by efficiently finding relevant items from a
large corpus given a query. Dot products have been widely used as the
similarity function in such tasks, enabled by Maximum Inner Product Search
(MIPS) algorithms for efficient retrieval. However, state-of-the-art retrieval
algorithms have migrated to learned similarities. These advanced approaches
encompass multiple query embeddings, complex neural networks, direct item ID
decoding via beam search, and hybrid solutions. Unfortunately, we lack
efficient solutions for retrieval in these state-of-the-art setups. Our work
addresses this gap by investigating efficient retrieval techniques with
expressive learned similarity functions. We establish Mixture-of-Logits (MoL)
as a universal approximator of similarity functions, demonstrate that MoL's
expressiveness can be realized empirically to achieve superior performance on
diverse retrieval scenarios, and propose techniques to retrieve the approximate
top-k results using MoL with tight error bounds. Through extensive
experimentation, we show that MoL, enhanced by our proposed mutual
information-based load balancing loss, sets new state-of-the-art results across
heterogeneous scenarios, including sequential retrieval models in
recommendation systems and finetuning language models for question answering;
and our approximate top-$k$ algorithms outperform baselines by up to 66x in
latency while achieving >.99 recall rate compared to exact algorithms.",2024-07-22,"Bailu Ding, Jiaqi Zhai",http://arxiv.org/pdf/2407.15462v4,cs.LG
Score matching for bridges without learning time-reversals,"We propose a new algorithm for learning bridged diffusion processes using
score-matching methods. Our method relies on reversing the dynamics of the
forward process and using this to learn a score function, which, via Doob's
$h$-transform, yields a bridged diffusion process; that is, a process
conditioned on an endpoint. In contrast to prior methods, we learn the score
term $\nabla_x \log p(t, x; T, y)$ directly, for given $t, y$, completely
avoiding first learning a time-reversal. We compare the performance of our
algorithm with existing methods and see that it outperforms using the (learned)
time-reversals to learn the score term. The code can be found at
https://github.com/libbylbaker/forward_bridge.",2024-07-22,"Elizabeth L. Baker, Moritz Schauer, Stefan Sommer",http://arxiv.org/pdf/2407.15455v3,cs.LG
Regression under demographic parity constraints via unlabeled post-processing,"We address the problem of performing regression while ensuring demographic
parity, even without access to sensitive attributes during inference. We
present a general-purpose post-processing algorithm that, using accurate
estimates of the regression function and a sensitive attribute predictor,
generates predictions that meet the demographic parity constraint. Our method
involves discretization and stochastic minimization of a smooth convex
function. It is suitable for online post-processing and multi-class
classification tasks only involving unlabeled data for the post-processing.
Unlike prior methods, our approach is fully theory-driven. We require precise
control over the gradient norm of the convex function, and thus, we rely on
more advanced techniques than standard stochastic gradient descent. Our
algorithm is backed by finite-sample analysis and post-processing bounds, with
experimental results validating our theoretical findings.",2024-07-22,"Evgenii Chzhen, Mohamed Hebiri, Gayane Taturyan",http://arxiv.org/pdf/2407.15453v1,cs.LG
GraphScale: A Framework to Enable Machine Learning over Billion-node Graphs,"Graph Neural Networks (GNNs) have emerged as powerful tools for supervised
machine learning over graph-structured data, while sampling-based node
representation learning is widely utilized in unsupervised learning. However,
scalability remains a major challenge in both supervised and unsupervised
learning for large graphs (e.g., those with over 1 billion nodes). The
scalability bottleneck largely stems from the mini-batch sampling phase in GNNs
and the random walk sampling phase in unsupervised methods. These processes
often require storing features or embeddings in memory. In the context of
distributed training, they require frequent, inefficient random access to data
stored across different workers. Such repeated inter-worker communication for
each mini-batch leads to high communication overhead and computational
inefficiency.
  We propose GraphScale, a unified framework for both supervised and
unsupervised learning to store and process large graph data distributedly. The
key insight in our design is the separation of workers who store data and those
who perform the training. This separation allows us to decouple computing and
storage in graph training, thus effectively building a pipeline where data
fetching and data computation can overlap asynchronously. Our experiments show
that GraphScale outperforms state-of-the-art methods for distributed training
of both GNNs and node embeddings. We evaluate GraphScale both on public and
proprietary graph datasets and observe a reduction of at least 40% in
end-to-end training times compared to popular distributed frameworks, without
any loss in performance. While most existing methods don't support billion-node
graphs for training node embeddings, GraphScale is currently deployed in
production at TikTok enabling efficient learning over such large graphs.",2024-07-22,"Vipul Gupta, Xin Chen, Ruoyun Huang, Fanlong Meng, Jianjun Chen, Yujun Yan",http://arxiv.org/pdf/2407.15452v1,cs.LG
Merit-based Fair Combinatorial Semi-Bandit with Unrestricted Feedback Delays,"We study the stochastic combinatorial semi-bandit problem with unrestricted
feedback delays under merit-based fairness constraints. This is motivated by
applications such as crowdsourcing, and online advertising, where immediate
feedback is not immediately available and fairness among different choices (or
arms) is crucial. We consider two types of unrestricted feedback delays:
reward-independent delays where the feedback delays are independent of the
rewards, and reward-dependent delays where the feedback delays are correlated
with the rewards. Furthermore, we introduce merit-based fairness constraints to
ensure a fair selection of the arms. We define the reward regret and the
fairness regret and present new bandit algorithms to select arms under
unrestricted feedback delays based on their merits. We prove that our
algorithms all achieve sublinear expected reward regret and expected fairness
regret, with a dependence on the quantiles of the delay distribution. We also
conduct extensive experiments using synthetic and real-world data and show that
our algorithms can fairly select arms with different feedback delays.",2024-07-22,"Ziqun Chen, Kechao Cai, Zhuoyue Chen, Jinbei Zhang, John C. S. Lui",http://arxiv.org/pdf/2407.15439v3,cs.LG
Pre-Training and Prompting for Few-Shot Node Classification on Text-Attributed Graphs,"The text-attributed graph (TAG) is one kind of important real-world
graph-structured data with each node associated with raw texts. For TAGs,
traditional few-shot node classification methods directly conduct training on
the pre-processed node features and do not consider the raw texts. The
performance is highly dependent on the choice of the feature pre-processing
method. In this paper, we propose P2TAG, a framework designed for few-shot node
classification on TAGs with graph pre-training and prompting. P2TAG first
pre-trains the language model (LM) and graph neural network (GNN) on TAGs with
self-supervised loss. To fully utilize the ability of language models, we adapt
the masked language modeling objective for our framework. The pre-trained model
is then used for the few-shot node classification with a mixed prompt method,
which simultaneously considers both text and graph information. We conduct
experiments on six real-world TAGs, including paper citation networks and
product co-purchasing networks. Experimental results demonstrate that our
proposed framework outperforms existing graph few-shot learning methods on
these datasets with +18.98% ~ +35.98% improvements.",2024-07-22,"Huanjing Zhao, Beining Yang, Yukuo Cen, Junyu Ren, Chenhui Zhang, Yuxiao Dong, Evgeny Kharlamov, Shu Zhao, Jie Tang",http://arxiv.org/pdf/2407.15431v1,cs.LG
Left-Right Swapping and Upper-Lower Limb Pairing for Robust Multi-Wearable Workout Activity Detection,"This work presents the solution of the Signal Sleuths team for the 2024 HASCA
WEAR challenge. The challenge focuses on detecting 18 workout activities (and
the null class) using accelerometer data from 4 wearables - one worn on each
limb. Data analysis revealed inconsistencies in wearable orientation within and
across participants, leading to exploring novel multi-wearable data
augmentation techniques. We investigate three models using a fixed feature set:
(i) ""raw"": using all data as is, (ii) ""left-right swapping"": augmenting data by
swapping left and right limb pairs, and (iii) ""upper-lower limb paring"":
stacking data by using upper-lower limb pair combinations (2 wearables). Our
experiments utilize traditional machine learning with multi-window feature
extraction and temporal smoothing. Using 3-fold cross-validation, the raw model
achieves a macro F1-score of 90.01%, whereas left-right swapping and
upper-lower limb paring improve the scores to 91.30% and 91.87% respectively.",2024-07-22,"Jonas Van Der Donckt, Jeroen Van Der Donckt, Sofie Van Hoecke",http://arxiv.org/pdf/2408.03947v1,cs.LG
PsyDI: Towards a Personalized and Progressively In-depth Chatbot for Psychological Measurements,"In the field of psychology, traditional assessment methods, such as
standardized scales, are frequently critiqued for their static nature, lack of
personalization, and reduced participant engagement, while comprehensive
counseling evaluations are often inaccessible. The complexity of quantifying
psychological traits further limits these methods. Despite advances with large
language models (LLMs), many still depend on single-round Question-and-Answer
interactions. To bridge this gap, we introduce PsyDI, a personalized and
progressively in-depth chatbot designed for psychological measurements,
exemplified by its application in the Myers-Briggs Type Indicator (MBTI)
framework. PsyDI leverages user-related multi-modal information and engages in
customized, multi-turn interactions to provide personalized, easily accessible
measurements, while ensuring precise MBTI type determination. To address the
challenge of unquantifiable psychological traits, we introduce a novel training
paradigm that involves learning the ranking of proxy variables associated with
these traits, culminating in a robust score model for MBTI measurements. The
score model enables PsyDI to conduct comprehensive and precise measurements
through multi-turn interactions within a unified estimation context. Through
various experiments, we validate the efficacy of both the score model and the
PsyDI pipeline, demonstrating its potential to serve as a general framework for
psychological measurements. Furthermore, the online deployment of PsyDI has
garnered substantial user engagement, with over 3,000 visits, resulting in the
collection of numerous multi-turn dialogues annotated with MBTI types, which
facilitates further research. The source code for the training and web service
components is publicly available as a part of OpenDILab at:
https://github.com/opendilab/PsyDI",2024-07-22,"Xueyan Li, Xinyan Chen, Yazhe Niu, Shuai Hu, Yu Liu",http://arxiv.org/pdf/2408.03337v4,cs.LG
Resource-Efficient Federated Multimodal Learning via Layer-wise and Progressive Training,"Combining different data modalities enables deep neural networks to tackle
complex tasks more effectively, making multimodal learning increasingly
popular. To harness multimodal data closer to end users, it is essential to
integrate multimodal learning with privacy-preserving approaches like federated
learning (FL). However, compared to conventional unimodal learning, multimodal
setting requires dedicated encoders for each modality, resulting in larger and
more complex models. Training these models requires significant resources,
presenting a substantial challenge for FL clients operating with limited
computation and communication resources. To address these challenges, we
introduce LW-FedMML, a layer-wise federated multimodal learning approach which
decomposes the training process into multiple stages. Each stage focuses on
training only a portion of the model, thereby significantly reducing the memory
and computational requirements. Moreover, FL clients only need to exchange the
trained model portion with the central server, lowering the resulting
communication cost. We conduct extensive experiments across various FL and
multimodal learning settings to validate the effectiveness of our proposed
method. The results demonstrate that LW-FedMML can compete with conventional
end-to-end federated multimodal learning (FedMML) while significantly reducing
the resource burden on FL clients. Specifically, LW-FedMML reduces memory usage
by up to $2.7\times$, computational operations (FLOPs) by $2.4\times$, and
total communication cost by $2.3\times$. We also explore a progressive training
approach called Prog-FedMML. While it offers lesser resource efficiency than
LW-FedMML, Prog-FedMML has the potential to surpass the performance of
end-to-end FedMML, making it a viable option for scenarios with fewer resource
constraints.",2024-07-22,"Ye Lin Tun, Chu Myaet Thwal, Minh N. H. Nguyen, Choong Seon Hong",http://arxiv.org/pdf/2407.15426v2,cs.LG
Empirical Capacity Model for Self-Attention Neural Networks,"Large pretrained self-attention neural networks, or transformers, have been
very successful in various tasks recently. The performance of a model on a
given task depends on its ability to memorize and generalize the training data.
Large transformer models, which may have billions of parameters, in theory have
a huge capacity to memorize content. However, the current algorithms for the
optimization fall short of the theoretical capacity, and the capacity is also
highly dependent on the content. In this paper, we focus on the memory capacity
of these models obtained using common training algorithms and synthetic
training data. Based on the results, we derive an empirical capacity model
(ECM) for a generic transformer. The ECM can be used to design task-specific
transformer models with an optimal number of parameters in cases where the
target memorization capability of the task can be defined.",2024-07-22,"Aki Härmä, Marcin Pietrasik, Anna Wilbik",http://arxiv.org/pdf/2407.15425v2,cs.LG
Planning in a recurrent neural network that plays Sokoban,"How a neural network (NN) generalizes to novel situations depends on whether
it has learned to select actions heuristically or via a planning process. ""An
investigation of model-free planning"" (Guez et al. 2019) found that a recurrent
NN (RNN) trained to play Sokoban appears to plan, with extra computation steps
improving the RNN's success rate. We replicate and expand on their behavioral
analysis, finding the RNN learns to give itself extra computation steps in
complex situations by ""pacing"" in cycles. Moreover, we train linear probes that
predict the future actions taken by the network and find that intervening on
the hidden state using these probes controls the agent's subsequent actions.
Leveraging these insights, we perform model surgery, enabling the convolutional
NN to generalize beyond its 10x10 architectural limit to arbitrarily sized
inputs. The resulting model solves challenging, highly off-distribution levels.
We open-source our model and code, and believe the neural network's small size
(1.29M parameters) makes it an excellent model organism to deepen our
understanding of learned planning.",2024-07-22,"Mohammad Taufeeque, Philip Quirke, Maximilian Li, Chris Cundy, Aaron David Tucker, Adam Gleave, Adrià Garriga-Alonso",http://arxiv.org/pdf/2407.15421v2,cs.LG
Weights Shuffling for Improving DPSGD in Transformer-based Models,"Differential Privacy (DP) mechanisms, especially in high-dimensional
settings, often face the challenge of maintaining privacy without compromising
the data utility. This work introduces an innovative shuffling mechanism in
Differentially-Private Stochastic Gradient Descent (DPSGD) to enhance the
utility of large models at the same privacy guarantee of the unshuffled case.
Specifically, we reveal that random shuffling brings additional randomness to
the trajectory of gradient descent while not impacting the model accuracy by
the permutation invariance property -- the model can be equivalently computed
in both forward and backward propagations under permutation. We show that
permutation indeed improves the privacy guarantee of DPSGD in theory, but
tracking the exact privacy loss on shuffled model is particularly challenging.
Hence we exploit the approximation on sum of lognormal distributions to derive
the condition for the shuffled DPSGD to meet the DP guarantee. Auditing results
show that our condition offers a DP guarantee quite close to the audited
privacy level, demonstrating our approach an effective estimation in practice.
Experimental results have verified our theoretical derivation and illustrate
that our mechanism improves the accuracy of DPSGD over the state-of-the-art
baselines on a variety of models and tasks.",2024-07-22,"Jungang Yang, Zhe Ji, Liyao Xiang",http://arxiv.org/pdf/2407.15414v1,cs.LG
Knowledge Mechanisms in Large Language Models: A Survey and Perspective,"Understanding knowledge mechanisms in Large Language Models (LLMs) is crucial
for advancing towards trustworthy AGI. This paper reviews knowledge mechanism
analysis from a novel taxonomy including knowledge utilization and evolution.
Knowledge utilization delves into the mechanism of memorization, comprehension
and application, and creation. Knowledge evolution focuses on the dynamic
progression of knowledge within individual and group LLMs. Moreover, we discuss
what knowledge LLMs have learned, the reasons for the fragility of parametric
knowledge, and the potential dark knowledge (hypothesis) that will be
challenging to address. We hope this work can help understand knowledge in LLMs
and provide insights for future research.",2024-07-22,"Mengru Wang, Yunzhi Yao, Ziwen Xu, Shuofei Qiao, Shumin Deng, Peng Wang, Xiang Chen, Jia-Chen Gu, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen, Ningyu Zhang",http://arxiv.org/pdf/2407.15017v4,cs.LG
Offline Imitation Learning Through Graph Search and Retrieval,"Imitation learning is a powerful machine learning algorithm for a robot to
acquire manipulation skills. Nevertheless, many real-world manipulation tasks
involve precise and dexterous robot-object interactions, which make it
difficult for humans to collect high-quality expert demonstrations. As a
result, a robot has to learn skills from suboptimal demonstrations and
unstructured interactions, which remains a key challenge. Existing works
typically use offline deep reinforcement learning (RL) to solve this challenge,
but in practice these algorithms are unstable and fragile due to the deadly
triad issue. To overcome this problem, we propose GSR, a simple yet effective
algorithm that learns from suboptimal demonstrations through Graph Search and
Retrieval. We first use pretrained representation to organize the interaction
experience into a graph and perform a graph search to calculate the values of
different behaviors. Then, we apply a retrieval-based procedure to identify the
best behavior (actions) on each state and use behavior cloning to learn that
behavior. We evaluate our method in both simulation and real-world robotic
manipulation tasks with complex visual inputs, covering various precise and
dexterous manipulation skills with objects of different physical properties.
GSR can achieve a 10% to 30% higher success rate and over 30% higher
proficiency compared to baselines. Our project page is at
https://zhaohengyin.github.io/gsr.",2024-07-22,"Zhao-Heng Yin, Pieter Abbeel",http://arxiv.org/pdf/2407.15403v1,cs.LG
Tackling Selfish Clients in Federated Learning,"Federated Learning (FL) is a distributed machine learning paradigm
facilitating participants to collaboratively train a model without revealing
their local data. However, when FL is deployed into the wild, some intelligent
clients can deliberately deviate from the standard training process to make the
global model inclined toward their local model, thereby prioritizing their
local data distribution. We refer to this novel category of misbehaving clients
as selfish. In this paper, we propose a Robust aggregation strategy for FL
server to mitigate the effect of Selfishness (in short RFL-Self). RFL-Self
incorporates an innovative method to recover (or estimate) the true updates of
selfish clients from the received ones, leveraging robust statistics (median of
norms) of the updates at every round. By including the recovered updates in
aggregation, our strategy offers strong robustness against selfishness. Our
experimental results, obtained on MNIST and CIFAR-10 datasets, demonstrate that
just 2% of clients behaving selfishly can decrease the accuracy by up to 36%,
and RFL-Self can mitigate that effect without degrading the global model
performance.",2024-07-22,"Andrea Augello, Ashish Gupta, Giuseppe Lo Re, Sajal K. Das",http://arxiv.org/pdf/2407.15402v1,cs.LG
Poisoning with A Pill: Circumventing Detection in Federated Learning,"Without direct access to the client's data, federated learning (FL) is
well-known for its unique strength in data privacy protection among existing
distributed machine learning techniques. However, its distributive and
iterative nature makes FL inherently vulnerable to various poisoning attacks.
To counteract these threats, extensive defenses have been proposed to filter
out malicious clients, using various detection metrics. Based on our analysis
of existing attacks and defenses, we find that there is a lack of attention to
model redundancy. In neural networks, various model parameters contribute
differently to the model's performance. However, existing attacks in FL
manipulate all the model update parameters with the same strategy, making them
easily detectable by common defenses. Meanwhile, the defenses also tend to
analyze the overall statistical features of the entire model updates, leaving
room for sophisticated attacks. Based on these observations, this paper
proposes a generic and attack-agnostic augmentation approach designed to
enhance the effectiveness and stealthiness of existing FL poisoning attacks
against detection in FL, pointing out the inherent flaws of existing defenses
and exposing the necessity of fine-grained FL security. Specifically, we employ
a three-stage methodology that strategically constructs, generates, and injects
poison (generated by existing attacks) into a pill (a tiny subnet with a novel
structure) during the FL training, named as pill construction, pill poisoning,
and pill injection accordingly. Extensive experimental results show that FL
poisoning attacks enhanced by our method can bypass all the popular defenses,
and can gain an up to 7x error rate increase, as well as on average a more than
2x error rate increase on both IID and non-IID data, in both cross-silo and
cross-device FL systems.",2024-07-22,"Hanxi Guo, Hao Wang, Tao Song, Tianhang Zheng, Yang Hua, Haibing Guan, Xiangyu Zhang",http://arxiv.org/pdf/2407.15389v1,cs.LG
CP-Prompt: Composition-Based Cross-modal Prompting for Domain-Incremental Continual Learning,"The key challenge of cross-modal domain-incremental learning (DIL) is to
enable the learning model to continuously learn from novel data with different
feature distributions under the same task without forgetting old ones. However,
existing top-performing methods still cause high forgetting rates, by lacking
intra-domain knowledge extraction and inter-domain common prompting strategy.
In this paper, we propose a simple yet effective framework, CP-Prompt, by
training limited parameters to instruct a pre-trained model to learn new
domains and avoid forgetting existing feature distributions. CP-Prompt captures
intra-domain knowledge by compositionally inserting personalized prompts on
multi-head self-attention layers and then learns the inter-domain knowledge
with a common prompting strategy. CP-Prompt shows superiority compared with
state-of-the-art baselines among three widely evaluated DIL tasks. The source
code is available at https://github.com/dannis97500/CP_Prompt.",2024-07-22,"Yu Feng, Zhen Tian, Yifan Zhu, Zongfu Han, Haoran Luo, Guangwei Zhang, Meina Song",http://arxiv.org/pdf/2407.21043v2,cs.LG
Improving Fast Adversarial Training Paradigm: An Example Taxonomy Perspective,"While adversarial training is an effective defense method against adversarial
attacks, it notably increases the training cost. To this end, fast adversarial
training (FAT) is presented for efficient training and has become a hot
research topic. However, FAT suffers from catastrophic overfitting, which leads
to a performance drop compared with multi-step adversarial training. However,
the cause of catastrophic overfitting remains unclear and lacks exploration. In
this paper, we present an example taxonomy in FAT, which identifies that
catastrophic overfitting is caused by the imbalance between the inner and outer
optimization in FAT. Furthermore, we investigated the impact of varying degrees
of training loss, revealing a correlation between training loss and
catastrophic overfitting. Based on these observations, we redesign the loss
function in FAT with the proposed dynamic label relaxation to concentrate the
loss range and reduce the impact of misclassified examples. Meanwhile, we
introduce batch momentum initialization to enhance the diversity to prevent
catastrophic overfitting in an efficient manner. Furthermore, we also propose
Catastrophic Overfitting aware Loss Adaptation (COLA), which employs a separate
training strategy for examples based on their loss degree. Our proposed method,
named example taxonomy aware FAT (ETA), establishes an improved paradigm for
FAT. Experiment results demonstrate our ETA achieves state-of-the-art
performance. Comprehensive experiments on four standard datasets demonstrate
the competitiveness of our proposed method.",2024-07-22,"Jie Gui, Chengze Jiang, Minjing Dong, Kun Tong, Xinli Shi, Yuan Yan Tang, Dacheng Tao",http://arxiv.org/pdf/2408.03944v2,cs.LG
LLMExplainer: Large Language Model based Bayesian Inference for Graph Explanation Generation,"Recent studies seek to provide Graph Neural Network (GNN) interpretability
via multiple unsupervised learning models. Due to the scarcity of datasets,
current methods easily suffer from learning bias. To solve this problem, we
embed a Large Language Model (LLM) as knowledge into the GNN explanation
network to avoid the learning bias problem. We inject LLM as a Bayesian
Inference (BI) module to mitigate learning bias. The efficacy of the BI module
has been proven both theoretically and experimentally. We conduct experiments
on both synthetic and real-world datasets. The innovation of our work lies in
two parts: 1. We provide a novel view of the possibility of an LLM functioning
as a Bayesian inference to improve the performance of existing algorithms; 2.
We are the first to discuss the learning bias issues in the GNN explanation
problem.",2024-07-22,"Jiaxing Zhang, Jiayi Liu, Dongsheng Luo, Jennifer Neville, Hua Wei",http://arxiv.org/pdf/2407.15351v2,cs.LG
Cascaded two-stage feature clustering and selection via separability and consistency in fuzzy decision systems,"Feature selection is a vital technique in machine learning, as it can reduce
computational complexity, improve model performance, and mitigate the risk of
overfitting. However, the increasing complexity and dimensionality of datasets
pose significant challenges in the selection of features. Focusing on these
challenges, this paper proposes a cascaded two-stage feature clustering and
selection algorithm for fuzzy decision systems. In the first stage, we reduce
the search space by clustering relevant features and addressing inter-feature
redundancy. In the second stage, a clustering-based sequentially forward
selection method that explores the global and local structure of data is
presented. We propose a novel metric for assessing the significance of
features, which considers both global separability and local consistency.
Global separability measures the degree of intra-class cohesion and inter-class
separation based on fuzzy membership, providing a comprehensive understanding
of data separability. Meanwhile, local consistency leverages the fuzzy
neighborhood rough set model to capture uncertainty and fuzziness in the data.
The effectiveness of our proposed algorithm is evaluated through experiments
conducted on 18 public datasets and a real-world schizophrenia dataset. The
experiment results demonstrate our algorithm's superiority over benchmarking
algorithms in both classification accuracy and the number of selected features.",2024-07-22,"Yuepeng Chen, Weiping Ding, Hengrong Ju, Jiashuang Huang, Tao Yin",http://arxiv.org/pdf/2407.15893v1,cs.LG
Building Machines that Learn and Think with People,"What do we want from machine intelligence? We envision machines that are not
just tools for thought, but partners in thought: reasonable, insightful,
knowledgeable, reliable, and trustworthy systems that think with us. Current
artificial intelligence (AI) systems satisfy some of these criteria, some of
the time. In this Perspective, we show how the science of collaborative
cognition can be put to work to engineer systems that really can be called
``thought partners,'' systems built to meet our expectations and complement our
limitations. We lay out several modes of collaborative thought in which humans
and AI thought partners can engage and propose desiderata for human-compatible
thought partnerships. Drawing on motifs from computational cognitive science,
we motivate an alternative scaling path for the design of thought partners and
ecosystems around their use through a Bayesian lens, whereby the partners we
construct actively build and reason over models of the human and world.",2024-07-22,"Katherine M. Collins, Ilia Sucholutsky, Umang Bhatt, Kartik Chandra, Lionel Wong, Mina Lee, Cedegao E. Zhang, Tan Zhi-Xuan, Mark Ho, Vikash Mansinghka, Adrian Weller, Joshua B. Tenenbaum, Thomas L. Griffiths",http://arxiv.org/pdf/2408.03943v1,cs.LG
Deep Uncertainty-Based Explore for Index Construction and Retrieval in Recommendation System,"In recommendation systems, the relevance and novelty of the final results are
selected through a cascade system of Matching -> Ranking -> Strategy. The
matching model serves as the starting point of the pipeline and determines the
upper bound of the subsequent stages. Balancing the relevance and novelty of
matching results is a crucial step in the design and optimization of
recommendation systems, contributing significantly to improving recommendation
quality. However, the typical matching algorithms have not simultaneously
addressed the relevance and novelty perfectly. One main reason is that deep
matching algorithms exhibit significant uncertainty when estimating items in
the long tail (e.g., due to insufficient training samples) items.The
uncertainty not only affects the training of the models but also influences the
confidence in the index construction and beam search retrieval process of these
models. This paper proposes the UICR (Uncertainty-based explore for Index
Construction and Retrieval) algorithm, which introduces the concept of
uncertainty modeling in the matching stage and achieves multi-task modeling of
model uncertainty and index uncertainty. The final matching results are
obtained by combining the relevance score and uncertainty score infered by the
model. Experimental results demonstrate that the UICR improves novelty without
sacrificing relevance on realworld industrial productive environments and
multiple open-source datasets. Remarkably, online A/B test results of display
advertising in Shopee demonstrates the effectiveness of the proposed algorithm.",2024-07-22,"Xin Jiang, Kaiqiang Wang, Yinlong Wang, Fengchang Lv, Taiyang Peng, Shuai Yang, Xianteng Wu, Pengye Zhang, Shuo Yuan, Yifan Zeng",http://arxiv.org/pdf/2408.00799v2,cs.LG
Mini-Sequence Transformer: Optimizing Intermediate Memory for Long Sequences Training,"We introduce Mini-Sequence Transformer (MsT), a simple and effective
methodology for highly efficient and accurate LLM training with extremely long
sequences. MsT partitions input sequences and iteratively processes
mini-sequences to reduce intermediate memory usage. Integrated with activation
recomputation, it enables significant memory savings in both forward and
backward passes. In experiments with the Llama3-8B model, with MsT, we measure
no degradation in throughput or convergence even with 12x longer sequences than
standard implementations. MsT is fully general, implementation-agnostic, and
requires minimal code changes to integrate with existing LLM training
frameworks. Integrated with the huggingface library, MsT successfully extends
the maximum context length of Qwen, Mistral, and Gemma-2 by 12-24x.",2024-07-22,"Cheng Luo, Jiawei Zhao, Zhuoming Chen, Beidi Chen, Anima Anandkumar",http://arxiv.org/pdf/2407.15892v4,cs.LG
RazorAttention: Efficient KV Cache Compression Through Retrieval Heads,"The memory and computational demands of Key-Value (KV) cache present
significant challenges for deploying long-context language models. Previous
approaches attempt to mitigate this issue by selectively dropping tokens, which
irreversibly erases critical information that might be needed for future
queries. In this paper, we propose a novel compression technique for KV cache
that preserves all token information. Our investigation reveals that: i) Most
attention heads primarily focus on the local context; ii) Only a few heads,
denoted as retrieval heads, can essentially pay attention to all input tokens.
These key observations motivate us to use separate caching strategy for
attention heads. Therefore, we propose RazorAttention, a training-free KV cache
compression algorithm, which maintains a full cache for these crucial retrieval
heads and discards the remote tokens in non-retrieval heads. Furthermore, we
introduce a novel mechanism involving a ""compensation token"" to further recover
the information in the dropped tokens. Extensive evaluations across a diverse
set of large language models (LLMs) demonstrate that RazorAttention achieves a
reduction in KV cache size by over 70% without noticeable impacts on
performance. Additionally, RazorAttention is compatible with FlashAttention,
rendering it an efficient and plug-and-play solution that enhances LLM
inference efficiency without overhead or retraining of the original model.",2024-07-22,"Hanlin Tang, Yang Lin, Jing Lin, Qingsen Han, Shikuan Hong, Yiwu Yao, Gongyi Wang",http://arxiv.org/pdf/2407.15891v1,cs.LG
Fever Detection with Infrared Thermography: Enhancing Accuracy through Machine Learning Techniques,"The COVID-19 pandemic has underscored the necessity for advanced diagnostic
tools in global health systems. Infrared Thermography (IRT) has proven to be a
crucial non-contact method for measuring body temperature, vital for
identifying febrile conditions associated with infectious diseases like
COVID-19. Traditional non-contact infrared thermometers (NCITs) often exhibit
significant variability in readings. To address this, we integrated machine
learning algorithms with IRT to enhance the accuracy and reliability of
temperature measurements. Our study systematically evaluated various regression
models using heuristic feature engineering techniques, focusing on features'
physiological relevance and statistical significance. The Convolutional Neural
Network (CNN) model, utilizing these techniques, achieved the lowest RMSE of
0.2223, demonstrating superior performance compared to results reported in
previous literature. Among non-neural network models, the Binning method
achieved the best performance with an RMSE of 0.2296. Our findings highlight
the potential of combining advanced feature engineering with machine learning
to improve diagnostic tools' effectiveness, with implications extending to
other non-contact or remote sensing biomedical applications. This paper offers
a comprehensive analysis of these methodologies, providing a foundation for
future research in the field of non-invasive medical diagnostics.",2024-07-22,"Parsa Razmara, Tina Khezresmaeilzadeh, B. Keith Jenkins",http://arxiv.org/pdf/2407.15302v2,cs.LG
U-learning for Prediction Inference via Combinatory Multi-Subsampling: With Applications to LASSO and Neural Networks,"Epigenetic aging clocks play a pivotal role in estimating an individual's
biological age through the examination of DNA methylation patterns at numerous
CpG (Cytosine-phosphate-Guanine) sites within their genome. However, making
valid inferences on predicted epigenetic ages, or more broadly, on predictions
derived from high-dimensional inputs, presents challenges. We introduce a novel
U-learning approach via combinatory multi-subsampling for making ensemble
predictions and constructing confidence intervals for predictions of continuous
outcomes when traditional asymptotic methods are not applicable. More
specifically, our approach conceptualizes the ensemble estimators within the
framework of generalized U-statistics and invokes the H\'ajek projection for
deriving the variances of predictions and constructing confidence intervals
with valid conditional coverage probabilities. We apply our approach to two
commonly used predictive algorithms, Lasso and deep neural networks (DNNs), and
illustrate the validity of inferences with extensive numerical studies. We have
applied these methods to predict the DNA methylation age (DNAmAge) of patients
with various health conditions, aiming to accurately characterize the aging
process and potentially guide anti-aging interventions.",2024-07-22,"Zhe Fei, Yi Li",http://arxiv.org/pdf/2407.15301v1,cs.LG
Weak-to-Strong Compositional Learning from Generative Models for Language-based Object Detection,"Vision-language (VL) models often exhibit a limited understanding of complex
expressions of visual objects (e.g., attributes, shapes, and their relations),
given complex and diverse language queries. Traditional approaches attempt to
improve VL models using hard negative synthetic text, but their effectiveness
is limited. In this paper, we harness the exceptional compositional
understanding capabilities of generative foundational models. We introduce a
novel method for structured synthetic data generation aimed at enhancing the
compositional understanding of VL models in language-based object detection.
Our framework generates densely paired positive and negative triplets (image,
text descriptions, and bounding boxes) in both image and text domains. By
leveraging these synthetic triplets, we transform 'weaker' VL models into
'stronger' models in terms of compositional understanding, a process we call
""Weak-to-Strong Compositional Learning"" (WSCL). To achieve this, we propose a
new compositional contrastive learning formulation that discovers semantics and
structures in complex descriptions from synthetic triplets. As a result, VL
models trained with our synthetic data generation exhibit a significant
performance boost in the Omnilabel benchmark by up to +5AP and the D3 benchmark
by +6.9AP upon existing baselines.",2024-07-21,"Kwanyong Park, Kuniaki Saito, Donghyun Kim",http://arxiv.org/pdf/2407.15296v1,cs.LG
Revisiting Neighborhood Aggregation in Graph Neural Networks for Node Classification using Statistical Signal Processing,"We delve into the issue of node classification within graphs, specifically
reevaluating the concept of neighborhood aggregation, which is a fundamental
component in graph neural networks (GNNs). Our analysis reveals conceptual
flaws within certain benchmark GNN models when operating under the assumption
of edge-independent node labels, a condition commonly observed in benchmark
graphs employed for node classification. Approaching neighborhood aggregation
from a statistical signal processing perspective, our investigation provides
novel insights which may be used to design more efficient GNN models.",2024-07-21,Mounir Ghogho,http://arxiv.org/pdf/2407.15284v1,cs.LG
Enhancing Hardware Fault Tolerance in Machines with Reinforcement Learning Policy Gradient Algorithms,"Industry is rapidly moving towards fully autonomous and interconnected
systems that can detect and adapt to changing conditions, including machine
hardware faults. Traditional methods for adding hardware fault tolerance to
machines involve duplicating components and algorithmically reconfiguring a
machine's processes when a fault occurs. However, the growing interest in
reinforcement learning-based robotic control offers a new perspective on
achieving hardware fault tolerance. However, limited research has explored the
potential of these approaches for hardware fault tolerance in machines. This
paper investigates the potential of two state-of-the-art reinforcement learning
algorithms, Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC), to
enhance hardware fault tolerance into machines. We assess the performance of
these algorithms in two OpenAI Gym simulated environments, Ant-v2 and
FetchReach-v1. Robot models in these environments are subjected to six
simulated hardware faults. Additionally, we conduct an ablation study to
determine the optimal method for transferring an agent's knowledge, acquired
through learning in a normal (pre-fault) environment, to a (post-)fault
environment in a continual learning setting. Our results demonstrate that
reinforcement learning-based approaches can enhance hardware fault tolerance in
simulated machines, with adaptation occurring within minutes. Specifically, PPO
exhibits the fastest adaptation when retaining the knowledge within its models,
while SAC performs best when discarding all acquired knowledge. Overall, this
study highlights the potential of reinforcement learning-based approaches, such
as PPO and SAC, for hardware fault tolerance in machines. These findings pave
the way for the development of robust and adaptive machines capable of
effectively operating in real-world scenarios.",2024-07-21,"Sheila Schoepp, Mehran Taghian, Shotaro Miwa, Yoshihiro Mitsuka, Shadan Golestan, Osmar Zaïane",http://arxiv.org/pdf/2407.15283v1,cs.LG
Conformal Predictions under Markovian Data,"We study the split Conformal Prediction method when applied to Markovian
data. We quantify the gap in terms of coverage induced by the correlations in
the data (compared to exchangeable data). This gap strongly depends on the
mixing properties of the underlying Markov chain, and we prove that it
typically scales as $\sqrt{t_\mathrm{mix}\ln(n)/n}$ (where $t_\mathrm{mix}$ is
the mixing time of the chain). We also derive upper bounds on the impact of the
correlations on the size of the prediction set. Finally we present $K$-split
CP, a method that consists in thinning the calibration dataset and that adapts
to the mixing properties of the chain. Its coverage gap is reduced to
$t_\mathrm{mix}/(n\ln(n))$ without really affecting the size of the prediction
set. We finally test our algorithms on synthetic and real-world datasets.",2024-07-21,"Frédéric Zheng, Alexandre Proutiere",http://arxiv.org/pdf/2407.15277v1,cs.LG
Unifying Invariant and Variant Features for Graph Out-of-Distribution via Probability of Necessity and Sufficiency,"Graph Out-of-Distribution (OOD), requiring that models trained on biased data
generalize to the unseen test data, has considerable real-world applications.
One of the most mainstream methods is to extract the invariant subgraph by
aligning the original and augmented data with the help of environment
augmentation. However, these solutions might lead to the loss or redundancy of
semantic subgraphs and result in suboptimal generalization. To address this
challenge, we propose exploiting Probability of Necessity and Sufficiency (PNS)
to extract sufficient and necessary invariant substructures. Beyond that, we
further leverage the domain variant subgraphs related to the labels to boost
the generalization performance in an ensemble manner. Specifically, we first
consider the data generation process for graph data. Under mild conditions, we
show that the sufficient and necessary invariant subgraph can be extracted by
minimizing an upper bound, built on the theoretical advance of the probability
of necessity and sufficiency. To further bridge the theory and algorithm, we
devise the model called Sufficiency and Necessity Inspired Graph Learning
(SNIGL), which ensembles an invariant subgraph classifier on top of latent
sufficient and necessary invariant subgraphs, and a domain variant subgraph
classifier specific to the test domain for generalization enhancement.
Experimental results demonstrate that our SNIGL model outperforms the
state-of-the-art techniques on six public benchmarks, highlighting its
effectiveness in real-world scenarios.",2024-07-21,"Xuexin Chen, Ruichu Cai, Kaitao Zheng, Zhifan Jiang, Zhengting Huang, Zhifeng Hao, Zijian Li",http://arxiv.org/pdf/2407.15273v1,cs.LG
LSM-GNN: Large-scale Storage-based Multi-GPU GNN Training by Optimizing Data Transfer Scheme,"Graph Neural Networks (GNNs) are widely used today in recommendation systems,
fraud detection, and node/link classification tasks. Real world GNNs continue
to scale in size and require a large memory footprint for storing graphs and
embeddings that often exceed the memory capacities of the target GPUs used for
training. To address limited memory capacities, traditional GNN training
approaches use graph partitioning and sharding techniques to scale up across
multiple GPUs within a node and/or scale out across multiple nodes. However,
this approach suffers from the high computational costs of graph partitioning
algorithms and inefficient communication across GPUs.
  To address these overheads, we propose Large-scale Storage-based Multi-GPU
GNN framework (LSM-GNN), a storagebased approach to train GNN models that
utilizes a novel communication layer enabling GPU software caches to function
as a system-wide shared cache with low overheads.LSM-GNN incorporates a hybrid
eviction policy that intelligently manages cache space by using both static and
dynamic node information to significantly enhance cache performance.
Furthermore, we introduce the Preemptive Victim-buffer Prefetcher (PVP), a
mechanism for prefetching node feature data from a Victim Buffer located in CPU
pinned-memory to further reduce the pressure on the storage devices.
Experimental results show that despite the lower compute capabilities and
memory capacities, LSM-GNN in a single node with two GPUs offers superior
performance over two-node-four-GPU Dist-DGL baseline and provides up to 3.75x
speed up on end-to-end epoch time while running large-scale GNN training",2024-07-21,"Jeongmin Brian Park, Kun Wu, Vikram Sharma Mailthody, Zaid Quresh, Scott Mahlke, Wen-mei Hwu",http://arxiv.org/pdf/2407.15264v1,cs.LG
A Benchmark Dataset for Multimodal Prediction of Enzymatic Function Coupling DNA Sequences and Natural Language,"Predicting gene function from its DNA sequence is a fundamental challenge in
biology. Many deep learning models have been proposed to embed DNA sequences
and predict their enzymatic function, leveraging information in public
databases linking DNA sequences to an enzymatic function label. However, much
of the scientific community's knowledge of biological function is not
represented in these categorical labels, and is instead captured in
unstructured text descriptions of mechanisms, reactions, and enzyme behavior.
These descriptions are often captured alongside DNA sequences in biological
databases, albeit in an unstructured manner. Deep learning of models predicting
enzymatic function are likely to benefit from incorporating this multi-modal
data encoding scientific knowledge of biological function. There is, however,
no dataset designed for machine learning algorithms to leverage this
multi-modal information. Here we propose a novel dataset and benchmark suite
that enables the exploration and development of large multi-modal neural
network models on gene DNA sequences and natural language descriptions of gene
function. We present baseline performance on benchmarks for both unsupervised
and supervised tasks that demonstrate the difficulty of this modeling
objective, while demonstrating the potential benefit of incorporating
multi-modal data types in function prediction compared to DNA sequences alone.
Our dataset is at: https://hoarfrost-lab.github.io/BioTalk/.",2024-07-21,"Yuchen Zhang, Ratish Kumar Chandrakant Jha, Soumya Bharadwaj, Vatsal Sanjaykumar Thakkar, Adrienne Hoarfrost, Jin Sun",http://arxiv.org/pdf/2407.15888v1,cs.LG
TimeInf: Time Series Data Contribution via Influence Functions,"Evaluating the contribution of individual data points to a model's prediction
is critical for interpreting model predictions and improving model performance.
Existing data contribution methods have been applied to various data types,
including tabular data, images, and texts; however, their primary focus has
been on i.i.d. settings. Despite the pressing need for principled approaches
tailored to time series datasets, the problem of estimating data contribution
in such settings remains unexplored, possibly due to challenges associated with
handling inherent temporal dependencies. This paper introduces TimeInf, a data
contribution estimation method for time-series datasets. TimeInf uses influence
functions to attribute model predictions to individual time points while
preserving temporal structures. Our extensive empirical results demonstrate
that TimeInf outperforms state-of-the-art methods in identifying harmful
anomalies and helpful time points for forecasting. Additionally, TimeInf offers
intuitive and interpretable attributions of data values, allowing us to easily
distinguish diverse anomaly patterns through visualizations.",2024-07-21,"Yizi Zhang, Jingyan Shen, Xiaoxue Xiong, Yongchan Kwon",http://arxiv.org/pdf/2407.15247v2,cs.LG
Weyl Calculus and Exactly Solvable Schrödinger Bridges with Quadratic State Cost,"Schr\""{o}dinger bridge--a stochastic dynamical generalization of optimal mass
transport--exhibits a learning-control duality. Viewed as a stochastic control
problem, the Schr\""{o}dinger bridge finds an optimal control policy that steers
a given joint state statistics to another while minimizing the total control
effort subject to controlled diffusion and deadline constraints. Viewed as a
stochastic learning problem, the Schr\""{o}dinger bridge finds the most-likely
distribution-valued trajectory connecting endpoint distributional observations,
i.e., solves the two point boundary-constrained maximum likelihood problem over
the manifold of probability distributions. Recent works have shown that solving
the Schr\""{o}dinger bridge problem with state cost requires finding the Markov
kernel associated with a reaction-diffusion PDE where the state cost appears as
a state-dependent reaction rate. We explain how ideas from Weyl calculus in
quantum mechanics, specifically the Weyl operator and the Weyl symbol, can help
determine such Markov kernels. We illustrate these ideas by explicitly finding
the Markov kernel for the case of quadratic state cost via Weyl calculus,
recovering our earlier results but avoiding tedious computation with Hermite
polynomials.",2024-07-21,"Alexis M. H. Teter, Wenqing Wang, Abhishek Halder",http://arxiv.org/pdf/2407.15245v3,cs.LG
Temporal Abstraction in Reinforcement Learning with Offline Data,"Standard reinforcement learning algorithms with a single policy perform
poorly on tasks in complex environments involving sparse rewards, diverse
behaviors, or long-term planning. This led to the study of algorithms that
incorporate temporal abstraction by training a hierarchy of policies that plan
over different time scales. The options framework has been introduced to
implement such temporal abstraction by learning low-level options that act as
extended actions controlled by a high-level policy. The main challenge in
applying these algorithms to real-world problems is that they suffer from high
sample complexity to train multiple levels of the hierarchy, which is
impossible in online settings. Motivated by this, in this paper, we propose an
offline hierarchical RL method that can learn options from existing offline
datasets collected by other unknown agents. This is a very challenging problem
due to the distribution mismatch between the learned options and the policies
responsible for the offline dataset and to our knowledge, this is the first
work in this direction. In this work, we propose a framework by which an online
hierarchical reinforcement learning algorithm can be trained on an offline
dataset of transitions collected by an unknown behavior policy. We validate our
method on Gym MuJoCo locomotion environments and robotic gripper block-stacking
tasks in the standard as well as transfer and goal-conditioned settings.",2024-07-21,"Ranga Shaarad Ayyagari, Anurita Ghosh, Ambedkar Dukkipati",http://arxiv.org/pdf/2407.15241v1,cs.LG
Variational Potential Flow: A Novel Probabilistic Framework for Energy-Based Generative Modelling,"Energy based models (EBMs) are appealing for their generality and simplicity
in data likelihood modeling, but have conventionally been difficult to train
due to the unstable and time-consuming implicit MCMC sampling during
contrastive divergence training. In this paper, we present a novel energy-based
generative framework, Variational Potential Flow (VAPO), that entirely
dispenses with implicit MCMC sampling and does not rely on complementary latent
models or cooperative training. The VAPO framework aims to learn a potential
energy function whose gradient (flow) guides the prior samples, so that their
density evolution closely follows an approximate data likelihood homotopy. An
energy loss function is then formulated to minimize the Kullback-Leibler
divergence between density evolution of the flow-driven prior and the data
likelihood homotopy. Images can be generated after training the potential
energy, by initializing the samples from Gaussian prior and solving the ODE
governing the potential flow on a fixed time interval using generic ODE
solvers. Experiment results show that the proposed VAPO framework is capable of
generating realistic images on various image datasets. In particular, our
proposed framework achieves competitive FID scores for unconditional image
generation on the CIFAR-10 and CelebA datasets.",2024-07-21,"Junn Yong Loo, Michelle Adeline, Arghya Pal, Vishnu Monn Baskaran, Chee-Ming Ting, Raphael C. -W. Phan",http://arxiv.org/pdf/2407.15238v1,cs.LG
Deep State Space Recurrent Neural Networks for Time Series Forecasting,"We explore various neural network architectures for modeling the dynamics of
the cryptocurrency market. Traditional linear models often fall short in
accurately capturing the unique and complex dynamics of this market. In
contrast, Deep Neural Networks (DNNs) have demonstrated considerable
proficiency in time series forecasting. This papers introduces novel neural
network framework that blend the principles of econometric state space models
with the dynamic capabilities of Recurrent Neural Networks (RNNs). We propose
state space models using Long Short Term Memory (LSTM), Gated Residual Units
(GRU) and Temporal Kolmogorov-Arnold Networks (TKANs). According to the
results, TKANs, inspired by Kolmogorov-Arnold Networks (KANs) and LSTM,
demonstrate promising outcomes.",2024-07-21,Hugo Inzirillo,http://arxiv.org/pdf/2407.15236v1,cs.LG
TAGCOS: Task-agnostic Gradient Clustered Coreset Selection for Instruction Tuning Data,"Instruction tuning has achieved unprecedented success in NLP, turning large
language models into versatile chatbots. However, the increasing variety and
volume of instruction datasets demand significant computational resources. To
address this, it is essential to extract a small and highly informative subset
(i.e., Coreset) that achieves comparable performance to the full dataset.
Achieving this goal poses non-trivial challenges: 1) data selection requires
accurate data representations that reflect the training samples' quality, 2)
considering the diverse nature of instruction datasets, and 3) ensuring the
efficiency of the coreset selection algorithm for large models. To address
these challenges, we propose Task-Agnostic Gradient Clustered COreset Selection
(TAGCOS). Specifically, we leverage sample gradients as the data
representations, perform clustering to group similar data, and apply an
efficient greedy algorithm for coreset selection. Experimental results show
that our algorithm, selecting only 5% of the data, surpasses other unsupervised
methods and achieves performance close to that of the full dataset.",2024-07-21,"Jipeng Zhang, Yaxuan Qin, Renjie Pi, Weizhong Zhang, Rui Pan, Tong Zhang",http://arxiv.org/pdf/2407.15235v1,cs.LG
"PUFFLE: Balancing Privacy, Utility, and Fairness in Federated Learning","Training and deploying Machine Learning models that simultaneously adhere to
principles of fairness and privacy while ensuring good utility poses a
significant challenge. The interplay between these three factors of
trustworthiness is frequently underestimated and remains insufficiently
explored. Consequently, many efforts focus on ensuring only two of these
factors, neglecting one in the process. The decentralization of the datasets
and the variations in distributions among the clients exacerbate the complexity
of achieving this ethical trade-off in the context of Federated Learning (FL).
For the first time in FL literature, we address these three factors of
trustworthiness. We introduce PUFFLE, a high-level parameterised approach that
can help in the exploration of the balance between utility, privacy, and
fairness in FL scenarios. We prove that PUFFLE can be effective across diverse
datasets, models, and data distributions, reducing the model unfairness up to
75%, with a maximum reduction in the utility of 17% in the worst-case scenario,
while maintaining strict privacy guarantees during the FL training.",2024-07-21,"Luca Corbucci, Mikko A Heikkila, David Solans Noguero, Anna Monreale, Nicolas Kourtellis",http://arxiv.org/pdf/2407.15224v1,cs.LG
Privacy-Preserving Multi-Center Differential Protein Abundance Analysis with FedProt,"Quantitative mass spectrometry has revolutionized proteomics by enabling
simultaneous quantification of thousands of proteins. Pooling patient-derived
data from multiple institutions enhances statistical power but raises
significant privacy concerns. Here we introduce FedProt, the first
privacy-preserving tool for collaborative differential protein abundance
analysis of distributed data, which utilizes federated learning and additive
secret sharing. In the absence of a multicenter patient-derived dataset for
evaluation, we created two, one at five centers from LFQ E.coli experiments and
one at three centers from TMT human serum. Evaluations using these datasets
confirm that FedProt achieves accuracy equivalent to DEqMS applied to pooled
data, with completely negligible absolute differences no greater than $\text{$4
\times 10^{-12}$}$. In contrast, -log10(p-values) computed by the most accurate
meta-analysis methods diverged from the centralized analysis results by up to
25-27. FedProt is available as a web tool with detailed documentation as a
FeatureCloud App.",2024-07-21,"Yuliya Burankova, Miriam Abele, Mohammad Bakhtiari, Christine von Törne, Teresa Barth, Lisa Schweizer, Pieter Giesbertz, Johannes R. Schmidt, Stefan Kalkhof, Janina Müller-Deile, Peter A van Veelen, Yassene Mohammed, Elke Hammer, Lis Arend, Klaudia Adamowicz, Tanja Laske, Anne Hartebrodt, Tobias Frisch, Chen Meng, Julian Matschinske, Julian Späth, Richard Röttger, Veit Schwämmle, Stefanie M. Hauck, Stefan Lichtenthaler, Axel Imhof, Matthias Mann, Christina Ludwig, Bernhard Kuster, Jan Baumbach, Olga Zolotareva",http://arxiv.org/pdf/2407.15220v1,cs.LG
Efficient Visual Transformer by Learnable Token Merging,"Self-attention and transformers have been widely used in deep learning.
Recent efforts have been devoted to incorporating transformer blocks into
different neural architectures, including those with convolutions, leading to
various visual transformers for computer vision tasks. In this paper, we
propose a novel and compact transformer block, Transformer with Learnable Token
Merging (LTM), or LTM-Transformer. LTM-Transformer performs token merging in a
learnable scheme. LTM-Transformer is compatible with many popular and compact
transformer networks, and it reduces the FLOPs and the inference time of the
visual transformers while maintaining or even improving the prediction
accuracy. In the experiments, we replace all the transformer blocks in popular
visual transformers, including MobileViT, EfficientViT, ViT-S/16, and Swin-T,
with LTM-Transformer blocks, leading to LTM-Transformer networks with different
backbones. The LTM-Transformer is motivated by reduction of Information
Bottleneck, and a novel and separable variational upper bound for the IB loss
is derived. The architecture of mask module in our LTM blocks which generate
the token merging mask is designed to reduce the derived upper bound for the IB
loss. Extensive results on computer vision tasks evidence that LTM-Transformer
renders compact and efficient visual transformers with comparable or much
better prediction accuracy than the original visual transformers. The code of
the LTM-Transformer is available at
\url{https://github.com/Statistical-Deep-Learning/LTM}.",2024-07-21,"Yancheng Wang, Yingzhen Yang",http://arxiv.org/pdf/2407.15219v1,cs.LG
Separable DeepONet: Breaking the Curse of Dimensionality in Physics-Informed Machine Learning,"The deep operator network (DeepONet) is a popular neural operator
architecture that has shown promise in solving partial differential equations
(PDEs) by using deep neural networks to map between infinite-dimensional
function spaces. In the absence of labeled datasets, we utilize the PDE
residual loss to learn the physical system, an approach known as
physics-informed DeepONet. This method faces significant computational
challenges, primarily due to the curse of dimensionality, as the computational
cost increases exponentially with finer discretization. In this paper, we
introduce the Separable DeepONet framework to address these challenges and
improve scalability for high-dimensional PDEs. Our approach involves a
factorization technique where sub-networks handle individual one-dimensional
coordinates, thereby reducing the number of forward passes and the size of the
Jacobian matrix. By using forward-mode automatic differentiation, we further
optimize the computational cost related to the Jacobian matrix. As a result,
our modifications lead to a linear scaling of computational cost with
discretization density, making Separable DeepONet suitable for high-dimensional
PDEs. We validate the effectiveness of the separable architecture through three
benchmark PDE models: the viscous Burgers equation, Biot's consolidation
theory, and a parametrized heat equation. In all cases, our proposed framework
achieves comparable or improved accuracy while significantly reducing
computational time compared to conventional DeepONet. These results demonstrate
the potential of Separable DeepONet in efficiently solving complex,
high-dimensional PDEs, advancing the field of physics-informed machine
learning.",2024-07-21,"Luis Mandl, Somdatta Goswami, Lena Lambers, Tim Ricken",http://arxiv.org/pdf/2407.15887v3,cs.LG
Failures to Find Transferable Image Jailbreaks Between Vision-Language Models,"The integration of new modalities into frontier AI systems offers exciting
capabilities, but also increases the possibility such systems can be
adversarially manipulated in undesirable ways. In this work, we focus on a
popular class of vision-language models (VLMs) that generate text outputs
conditioned on visual and textual inputs. We conducted a large-scale empirical
study to assess the transferability of gradient-based universal image
``jailbreaks"" using a diverse set of over 40 open-parameter VLMs, including 18
new VLMs that we publicly release. Overall, we find that transferable
gradient-based image jailbreaks are extremely difficult to obtain. When an
image jailbreak is optimized against a single VLM or against an ensemble of
VLMs, the jailbreak successfully jailbreaks the attacked VLM(s), but exhibits
little-to-no transfer to any other VLMs; transfer is not affected by whether
the attacked and target VLMs possess matching vision backbones or language
models, whether the language model underwent instruction-following and/or
safety-alignment training, or many other factors. Only two settings display
partially successful transfer: between identically-pretrained and
identically-initialized VLMs with slightly different VLM training data, and
between different training checkpoints of a single VLM. Leveraging these
results, we then demonstrate that transfer can be significantly improved
against a specific target VLM by attacking larger ensembles of
``highly-similar"" VLMs. These results stand in stark contrast to existing
evidence of universal and transferable text jailbreaks against language models
and transferable adversarial attacks against image classifiers, suggesting that
VLMs may be more robust to gradient-based transfer attacks.",2024-07-21,"Rylan Schaeffer, Dan Valentine, Luke Bailey, James Chua, Cristóbal Eyzaguirre, Zane Durante, Joe Benton, Brando Miranda, Henry Sleight, John Hughes, Rajashree Agrawal, Mrinank Sharma, Scott Emmons, Sanmi Koyejo, Ethan Perez",http://arxiv.org/pdf/2407.15211v2,cs.LG
LSTM Autoencoder-based Deep Neural Networks for Barley Genotype-to-Phenotype Prediction,"Artificial Intelligence (AI) has emerged as a key driver of precision
agriculture, facilitating enhanced crop productivity, optimized resource use,
farm sustainability, and informed decision-making. Also, the expansion of
genome sequencing technology has greatly increased crop genomic resources,
deepening our understanding of genetic variation and enhancing desirable crop
traits to optimize performance in various environments. There is increasing
interest in using machine learning (ML) and deep learning (DL) algorithms for
genotype-to-phenotype prediction due to their excellence in capturing complex
interactions within large, high-dimensional datasets. In this work, we propose
a new LSTM autoencoder-based model for barley genotype-to-phenotype prediction,
specifically for flowering time and grain yield estimation, which could
potentially help optimize yields and management practices. Our model
outperformed the other baseline methods, demonstrating its potential in
handling complex high-dimensional agricultural datasets and enhancing crop
phenotype prediction performance.",2024-07-21,"Guanjin Wang, Junyu Xuan, Penghao Wang, Chengdao Li, Jie Lu",http://arxiv.org/pdf/2407.16709v1,cs.LG
Exploiting Pre-trained Models for Drug Target Affinity Prediction with Nearest Neighbors,"Drug-Target binding Affinity (DTA) prediction is essential for drug
discovery. Despite the application of deep learning methods to DTA prediction,
the achieved accuracy remain suboptimal. In this work, inspired by the recent
success of retrieval methods, we propose $k$NN-DTA, a non-parametric
embedding-based retrieval method adopted on a pre-trained DTA prediction model,
which can extend the power of the DTA model with no or negligible cost.
Different from existing methods, we introduce two neighbor aggregation ways
from both embedding space and label space that are integrated into a unified
framework. Specifically, we propose a \emph{label aggregation} with
\emph{pair-wise retrieval} and a \emph{representation aggregation} with
\emph{point-wise retrieval} of the nearest neighbors. This method executes in
the inference phase and can efficiently boost the DTA prediction performance
with no training cost. In addition, we propose an extension, Ada-$k$NN-DTA, an
instance-wise and adaptive aggregation with lightweight learning. Results on
four benchmark datasets show that $k$NN-DTA brings significant improvements,
outperforming previous state-of-the-art (SOTA) results, e.g, on BindingDB
IC$_{50}$ and $K_i$ testbeds, $k$NN-DTA obtains new records of RMSE
$\bf{0.684}$ and $\bf{0.750}$. The extended Ada-$k$NN-DTA further improves the
performance to be $\bf{0.675}$ and $\bf{0.735}$ RMSE. These results strongly
prove the effectiveness of our method. Results in other settings and
comprehensive studies/analyses also show the great potential of our $k$NN-DTA
approach.",2024-07-21,"Qizhi Pei, Lijun Wu, Zhenyu He, Jinhua Zhu, Yingce Xia, Shufang Xie, Rui Yan",http://arxiv.org/pdf/2407.15202v1,cs.LG
HyperbolicLR: Epoch insensitive learning rate scheduler,"This study proposes two novel learning rate schedulers -- Hyperbolic Learning
Rate Scheduler (HyperbolicLR) and Exponential Hyperbolic Learning Rate
Scheduler (ExpHyperbolicLR) -- to address the epoch sensitivity problem that
often causes inconsistent learning curves in conventional methods. By
leveraging the asymptotic behavior of hyperbolic curves, the proposed
schedulers maintain more stable learning curves across varying epoch settings.
Specifically, HyperbolicLR applies this property directly in the epoch-learning
rate space, while ExpHyperbolicLR extends it to an exponential space. We first
determine optimal hyperparameters for each scheduler on a small number of
epochs, fix these hyperparameters, and then evaluate performance as the number
of epochs increases. Experimental results on various deep learning tasks (e.g.,
image classification, time series forecasting, and operator learning)
demonstrate that both HyperbolicLR and ExpHyperbolicLR achieve more consistent
performance improvements than conventional schedulers as training duration
grows. These findings suggest that our hyperbolic-based schedulers offer a more
robust and efficient approach to deep network optimization, particularly in
scenarios constrained by computational resources or time.",2024-07-21,Tae-Geun Kim,http://arxiv.org/pdf/2407.15200v3,cs.LG
Few-Shot Transfer Learning for Individualized Braking Intent Detection on Neuromorphic Hardware,"Objective: This work explores use of a few-shot transfer learning method to
train and implement a convolutional spiking neural network (CSNN) on a
BrainChip Akida AKD1000 neuromorphic system-on-chip for developing
individual-level, instead of traditionally used group-level, models using
electroencephalographic data. Main Results: Efficacy of the above methodology
to develop individual-specific braking intention predictive models by rapidly
adapting the group-level model in as few as three training epochs while
achieving at least 90% accuracy, true positive rate and true negative rate is
presented. Further, results show the energy-efficiency of the neuromorphic
hardware through a power reduction of over 97% with only a $1.3* increase in
latency when using the Akida AKD1000 processor for network inference compared
to an Intel Xeon central processing unit. Similar results were obtained in a
subsequent ablation study using a subset of five out of 19 channels.",2024-07-21,"Nathan Lutes, Venkata Sriram Siddhardh Nadendla, K. Krishnamurthy",http://arxiv.org/pdf/2408.03336v2,cs.LG
Error Detection and Constraint Recovery in Hierarchical Multi-Label Classification without Prior Knowledge,"Recent advances in Hierarchical Multi-label Classification (HMC),
particularly neurosymbolic-based approaches, have demonstrated improved
consistency and accuracy by enforcing constraints on a neural model during
training. However, such work assumes the existence of such constraints
a-priori. In this paper, we relax this strong assumption and present an
approach based on Error Detection Rules (EDR) that allow for learning
explainable rules about the failure modes of machine learning models. We show
that these rules are not only effective in detecting when a machine learning
classifier has made an error but also can be leveraged as constraints for HMC,
thereby allowing the recovery of explainable constraints even if they are not
provided. We show that our approach is effective in detecting machine learning
errors and recovering constraints, is noise tolerant, and can function as a
source of knowledge for neurosymbolic models on multiple datasets, including a
newly introduced military vehicle recognition dataset.",2024-07-21,"Joshua Shay Kricheli, Khoa Vo, Aniruddha Datta, Spencer Ozgur, Paulo Shakarian",http://arxiv.org/pdf/2407.15192v2,cs.LG
Generalizing Trilateration: Approximate Maximum Likelihood Estimator for Initial Orbit Determination in Low-Earth Orbit,"With the increase in the number of active satellites and space debris in
orbit, the problem of initial orbit determination (IOD) becomes increasingly
important, demanding a high accuracy. Over the years, different approaches have
been presented such as filtering methods (for example, Extended Kalman Filter),
differential algebra or solving Lambert's problem. In this work, we consider a
setting of three monostatic radars, where all available measurements are taken
approximately at the same instant. This follows a similar setting as
trilateration, a state-of-the-art approach, where each radar is able to obtain
a single measurement of range and range-rate. Differently, and due to advances
in Multiple-Input Multiple-Output (MIMO) radars, we assume that each location
is able to obtain a larger set of range, angle and Doppler shift measurements.
Thus, our method can be understood as an extension of trilateration leveraging
more recent technology and incorporating additional data. We formulate the
problem as a Maximum Likelihood Estimator (MLE), which for some number of
observations is asymptotically unbiased and asymptotically efficient. Through
numerical experiments, we demonstrate that our method attains the same accuracy
as the trilateration method for the same number of measurements and offers an
alternative and generalization, returning a more accurate estimation of the
satellite's state vector, as the number of available measurements increases.",2024-07-21,"Ricardo Ferreira, Filipa Valdeira, Marta Guimarães, Cláudia Soares",http://arxiv.org/pdf/2407.15180v2,cs.LG
"${\it Asparagus}$: A Toolkit for Autonomous, User-Guided Construction of Machine-Learned Potential Energy Surfaces","With the establishment of machine learning (ML) techniques in the scientific
community, the construction of ML potential energy surfaces (ML-PES) has become
a standard process in physics and chemistry. So far, improvements in the
construction of ML-PES models have been conducted independently, creating an
initial hurdle for new users to overcome and complicating the reproducibility
of results. Aiming to reduce the bar for the extensive use of ML-PES, we
introduce ${\it Asparagus}$, a software package encompassing the different
parts into one coherent implementation that allows an autonomous, user-guided
construction of ML-PES models. ${\it Asparagus}$ combines capabilities of
initial data sampling with interfaces to ${\it ab
  initio}$ calculation programs, ML model training, as well as model evaluation
and its application within other codes such as ASE or CHARMM. The
functionalities of the code are illustrated in different examples, including
the dynamics of small molecules, the representation of reactive potentials in
organometallic compounds, and atom diffusion on periodic surface structures.
The modular framework of ${\it Asparagus}$ is designed to allow simple
implementations of further ML-related methods and models to provide constant
user-friendly access to state-of-the-art ML techniques.",2024-07-21,"Kai Töpfer, Luis Itza Vazquez-Salazar, Markus Meuwly",http://arxiv.org/pdf/2407.15175v1,cs.LG
TADA: Temporal Adversarial Data Augmentation for Time Series Data,"Domain generalization aim to train models to effectively perform on samples
that are unseen and outside of the distribution. Adversarial data augmentation
(ADA) is a widely used technique in domain generalization. It enhances the
model robustness by including synthetic samples designed to simulate potential
unseen scenarios into the training datasets, which is then used to train the
model. However, in time series data, traditional ADA approaches often fail to
address distribution shifts related to temporal characteristics. To address
this limitation, we propose Temporal Adversarial Data Augmentation (TADA) for
time series data, which incorporate time warping into ADA. Although time
warping is inherently non-differentiable, ADA relies on generating samples
through backpropagation. We resolve this issue by leveraging the duality
between phase shifts in the frequency domain and time shifts in the time
domain, thereby making the process differentiable. Our evaluations across
various time series datasets demonstrate that TADA outperforms existing methods
for domain generalization. In addition, using distribution visualization, we
confirmed that the distribution shifts induced by TADA are clearly different
from those induced by ADA, and together, they effectively simulate real-world
distribution shifts.",2024-07-21,"Byeong Tak Lee, Joon-myoung Kwon, Yong-Yeon Jo",http://arxiv.org/pdf/2407.15174v2,cs.LG
Mitigating Deep Reinforcement Learning Backdoors in the Neural Activation Space,"This paper investigates the threat of backdoors in Deep Reinforcement
Learning (DRL) agent policies and proposes a novel method for their detection
at runtime. Our study focuses on elusive in-distribution backdoor triggers.
Such triggers are designed to induce a deviation in the behaviour of a
backdoored agent while blending into the expected data distribution to evade
detection. Through experiments conducted in the Atari Breakout environment, we
demonstrate the limitations of current sanitisation methods when faced with
such triggers and investigate why they present a challenging defence problem.
We then evaluate the hypothesis that backdoor triggers might be easier to
detect in the neural activation space of the DRL agent's policy network. Our
statistical analysis shows that indeed the activation patterns in the agent's
policy network are distinct in the presence of a trigger, regardless of how
well the trigger is concealed in the environment. Based on this, we propose a
new defence approach that uses a classifier trained on clean environment
samples and detects abnormal activations. Our results show that even
lightweight classifiers can effectively prevent malicious actions with
considerable accuracy, indicating the potential of this research direction even
against sophisticated adversaries.",2024-07-21,"Sanyam Vyas, Chris Hicks, Vasilios Mavroudis",http://arxiv.org/pdf/2407.15168v1,cs.LG
Adversarial Circuit Evaluation,"Circuits are supposed to accurately describe how a neural network performs a
specific task, but do they really? We evaluate three circuits found in the
literature (IOI, greater-than, and docstring) in an adversarial manner,
considering inputs where the circuit's behavior maximally diverges from the
full model. Concretely, we measure the KL divergence between the full model's
output and the circuit's output, calculated through resample ablation, and we
analyze the worst-performing inputs. Our results show that the circuits for the
IOI and docstring tasks fail to behave similarly to the full model even on
completely benign inputs from the original task, indicating that more robust
circuits are needed for safety-critical applications.",2024-07-21,"Niels uit de Bos, Adrià Garriga-Alonso",http://arxiv.org/pdf/2407.15166v1,cs.LG
FFHFlow: A Flow-based Variational Approach for Learning Diverse Dexterous Grasps with Shape-Aware Introspection,"Synthesizing diverse dexterous grasps from uncertain partial observation is
an important yet challenging task for physically intelligent embodiments.
Previous works on generative grasp synthesis fell short of precisely capturing
the complex grasp distribution and reasoning about shape uncertainty in the
unstructured and often partially perceived reality. In this work, we introduce
a novel model that can generate diverse grasps for a multi-fingered hand while
introspectively handling perceptual uncertainty and recognizing unknown object
geometry to avoid performance degradation. Specifically, we devise a Deep
Latent Variable Model (DLVM) based on Normalizing Flows (NFs), facilitating
hierarchical and expressive latent representation for modeling versatile
grasps. Our model design counteracts typical pitfalls of its popular
alternative in generative grasping, i.e., conditional Variational Autoencoders
(cVAEs) whose performance is limited by mode collapse and miss-specified prior
issues. Moreover, the resultant feature hierarchy and the exact flow likelihood
computation endow our model with shape-aware introspective capabilities,
enabling it to quantify the shape uncertainty of partial point clouds and
detect objects of novel geometry. We further achieve performance gain by fusing
this information with a discriminative grasp evaluator, facilitating a novel
hybrid way for grasp evaluation. Comprehensive simulated and real-world
experiments show that the proposed idea gains superior performance and higher
run-time efficiency against strong baselines, including diffusion models. We
also demonstrate substantial benefits of greater diversity for grasping objects
in clutter and a confined workspace in the real world.",2024-07-21,"Qian Feng, Jianxiang Feng, Zhaopeng Chen, Rudolph Triebel, Alois Knoll",http://arxiv.org/pdf/2407.15161v2,cs.LG
When Can Transformers Count to n?,"Large language models based on the transformer architectures can solve highly
complex tasks. But are there simple tasks that such models cannot solve? Here
we focus on very simple counting tasks, that involve counting how many times a
token in the vocabulary have appeared in a string. We show that if the
dimension of the transformer state is linear in the context length, this task
can be solved. However, the solution we propose does not scale beyond this
limit, and we provide theoretical arguments for why it is likely impossible for
a size limited transformer to implement this task. Our empirical results
demonstrate the same phase-transition in performance, as anticipated by the
theoretical argument. Our results demonstrate the importance of understanding
how transformers can solve simple tasks.",2024-07-21,"Gilad Yehudai, Haim Kaplan, Asma Ghandeharioun, Mor Geva, Amir Globerson",http://arxiv.org/pdf/2407.15160v2,cs.LG
Text-Augmented Multimodal LLMs for Chemical Reaction Condition Recommendation,"High-throughput reaction condition (RC) screening is fundamental to chemical
synthesis. However, current RC screening suffers from laborious and costly
trial-and-error workflows. Traditional computer-aided synthesis planning (CASP)
tools fail to find suitable RCs due to data sparsity and inadequate reaction
representations. Nowadays, large language models (LLMs) are capable of tackling
chemistry-related problems, such as molecule design, and chemical logic Q\&A
tasks. However, LLMs have not yet achieved accurate predictions of chemical
reaction conditions. Here, we present MM-RCR, a text-augmented multimodal LLM
that learns a unified reaction representation from SMILES, reaction graphs, and
textual corpus for chemical reaction recommendation (RCR). To train MM-RCR, we
construct 1.2 million pair-wised Q\&A instruction datasets. Our experimental
results demonstrate that MM-RCR achieves state-of-the-art performance on two
open benchmark datasets and exhibits strong generalization capabilities on
out-of-domain (OOD) and High-Throughput Experimentation (HTE) datasets. MM-RCR
has the potential to accelerate high-throughput condition screening in chemical
synthesis.",2024-07-21,"Yu Zhang, Ruijie Yu, Kaipeng Zeng, Ding Li, Feng Zhu, Xiaokang Yang, Yaohui Jin, Yanyan Xu",http://arxiv.org/pdf/2407.15141v1,cs.LG
Proximal Policy Distillation,"We introduce Proximal Policy Distillation (PPD), a novel policy distillation
method that integrates student-driven distillation and Proximal Policy
Optimization (PPO) to increase sample efficiency and to leverage the additional
rewards that the student policy collects during distillation. To assess the
efficacy of our method, we compare PPD with two common alternatives,
student-distill and teacher-distill, over a wide range of reinforcement
learning environments that include discrete actions and continuous control
(ATARI, Mujoco, and Procgen). For each environment and method, we perform
distillation to a set of target student neural networks that are smaller,
identical (self-distillation), or larger than the teacher network. Our findings
indicate that PPD improves sample efficiency and produces better student
policies compared to typical policy distillation approaches. Moreover, PPD
demonstrates greater robustness than alternative methods when distilling
policies from imperfect demonstrations. The code for the paper is released as
part of a new Python library built on top of stable-baselines3 to facilitate
policy distillation: `sb3-distill'.",2024-07-21,Giacomo Spigler,http://arxiv.org/pdf/2407.15134v1,cs.LG
Deep multimodal saliency parcellation of cerebellar pathways: linking microstructure and individual function through explainable multitask learning,"Parcellation of human cerebellar pathways is essential for advancing our
understanding of the human brain. Existing diffusion MRI tractography
parcellation methods have been successful in defining major cerebellar fibre
tracts, while relying solely on fibre tract structure. However, each fibre
tract may relay information related to multiple cognitive and motor functions
of the cerebellum. Hence, it may be beneficial for parcellation to consider the
potential importance of the fibre tracts for individual motor and cognitive
functional performance measures. In this work, we propose a multimodal
data-driven method for cerebellar pathway parcellation, which incorporates both
measures of microstructure and connectivity, and measures of individual
functional performance. Our method involves first training a multitask deep
network to predict various cognitive and motor measures from a set of fibre
tract structural features. The importance of each structural feature for
predicting each functional measure is then computed, resulting in a set of
structure-function saliency values that are clustered to parcellate cerebellar
pathways. We refer to our method as Deep Multimodal Saliency Parcellation
(DeepMSP), as it computes the saliency of structural measures for predicting
cognitive and motor functional performance, with these saliencies being applied
to the task of parcellation. Applying DeepMSP we found that it was feasible to
identify multiple cerebellar pathway parcels with unique structure-function
saliency patterns that were stable across training folds.",2024-07-21,"Ari Tchetchenian, Leo Zekelman, Yuqian Chen, Jarrett Rushmore, Fan Zhang, Edward H. Yeterian, Nikos Makris, Yogesh Rathi, Erik Meijering, Yang Song, Lauren J. O'Donnell",http://arxiv.org/pdf/2407.15132v1,cs.LG
Token-Picker: Accelerating Attention in Text Generation with Minimized Memory Transfer via Probability Estimation,"The attention mechanism in text generation is memory-bounded due to its
sequential characteristics. Therefore, off-chip memory accesses should be
minimized for faster execution. Although previous methods addressed this by
pruning unimportant tokens, they fall short in selectively removing tokens with
near-zero attention probabilities in each instance. Our method estimates the
probability before the softmax function, effectively removing low probability
tokens and achieving an 12.1x pruning ratio without fine-tuning. Additionally,
we present a hardware design supporting seamless on-demand off-chip access. Our
approach shows 2.6x reduced memory accesses, leading to an average 2.3x speedup
and a 2.4x energy efficiency.",2024-07-21,"Junyoung Park, Myeonggu Kang, Yunki Han, Yanggon Kim, Jaekang Shin, Lee-Sup Kim",http://arxiv.org/pdf/2407.15131v1,cs.LG
Chemical Reaction Extraction from Long Patent Documents,"The task of searching through patent documents is crucial for chemical patent
recommendation and retrieval. This can be enhanced by creating a patent
knowledge base (ChemPatKB) to aid in prior art searches and to provide a
platform for domain experts to explore new innovations in chemical compound
synthesis and use-cases. An essential foundational component of this KB is the
extraction of important reaction snippets from long patents documents which
facilitates multiple downstream tasks such as reaction co-reference resolution
and chemical entity role identification. In this work, we explore the problem
of extracting reactions spans from chemical patents in order to create a
reactions resource database. We formulate this task as a paragraph-level
sequence tagging problem, where the system is required to return a sequence of
paragraphs that contain a description of a reaction. We propose several
approaches and modifications of the baseline models and study how different
methods generalize across different domains of chemical patents.",2024-07-21,"Aishwarya Jadhav, Ritam Dutt",http://arxiv.org/pdf/2407.15124v2,cs.LG
Synthetic Time Series for Anomaly Detection in Cloud Microservices,"This paper proposes a framework for time series generation built to
investigate anomaly detection in cloud microservices. In the field of cloud
computing, ensuring the reliability of microservices is of paramount concern
and yet a remarkably challenging task. Despite the large amount of research in
this area, validation of anomaly detection algorithms in realistic environments
is difficult to achieve. To address this challenge, we propose a framework to
mimic the complex time series patterns representative of both normal and
anomalous cloud microservices behaviors. We detail the pipeline implementation
that allows deployment and management of microservices as well as the
theoretical approach required to generate anomalies. Two datasets generated
using the proposed framework have been made publicly available through GitHub.",2024-07-21,"Mohamed Allam, Noureddine Boujnah, Noel E. O'Connor, Mingming Liu",http://arxiv.org/pdf/2408.00006v1,cs.LG
Practical multi-fidelity machine learning: fusion of deterministic and Bayesian models,"Multi-fidelity machine learning methods address the accuracy-efficiency
trade-off by integrating scarce, resource-intensive high-fidelity data with
abundant but less accurate low-fidelity data. We propose a practical
multi-fidelity strategy for problems spanning low- and high-dimensional
domains, integrating a non-probabilistic regression model for the low-fidelity
with a Bayesian model for the high-fidelity. The models are trained in a
staggered scheme, where the low-fidelity model is transfer-learned to the
high-fidelity data and a Bayesian model is trained to learn the residual
between the data and the transfer-learned model. This three-model strategy --
deterministic low-fidelity, transfer-learning, and Bayesian residual -- leads
to a prediction that includes uncertainty quantification for noisy and
noiseless multi-fidelity data. The strategy is general and unifies the topic,
highlighting the expressivity trade-off between the transfer-learning and
Bayesian models (a complex transfer-learning model leads to a simpler Bayesian
model, and vice versa). We propose modeling choices for two scenarios, and
argue in favor of using a linear transfer-learning model that fuses 1) kernel
ridge regression for low-fidelity with Gaussian processes for high-fidelity; or
2) deep neural network for low-fidelity with a Bayesian neural network for
high-fidelity. We demonstrate the effectiveness and efficiency of the proposed
strategies and contrast them with the state-of-the-art based on various
numerical examples and two engineering problems. The results indicate that the
proposed approach achieves comparable performance in both mean and uncertainty
estimation while significantly reducing training time for machine learning
modeling in data-scarce scenarios. Moreover, in data-rich settings, it
outperforms other multi-fidelity architectures by effectively mitigating
overfitting.",2024-07-21,"Jiaxiang Yi, Ji Cheng, Miguel A. Bessa",http://arxiv.org/pdf/2407.15110v2,cs.LG
Improving Prediction of Need for Mechanical Ventilation using Cross-Attention,"In the intensive care unit, the capability to predict the need for mechanical
ventilation (MV) facilitates more timely interventions to improve patient
outcomes. Recent works have demonstrated good performance in this task
utilizing machine learning models. This paper explores the novel application of
a deep learning model with multi-head attention (FFNN-MHA) to make more
accurate MV predictions and reduce false positives by learning personalized
contextual information of individual patients. Utilizing the publicly available
MIMIC-IV dataset, FFNN-MHA demonstrates an improvement of 0.0379 in AUC and a
17.8\% decrease in false positives compared to baseline models such as
feed-forward neural networks. Our results highlight the potential of the
FFNN-MHA model as an effective tool for accurate prediction of the need for
mechanical ventilation in critical care settings.",2024-07-21,"Anwesh Mohanty, Supreeth P. Shashikumar, Jonathan Y. Lam, Shamim Nemati",http://arxiv.org/pdf/2407.15885v1,cs.LG
A General Framework for Data-Use Auditing of ML Models,"Auditing the use of data in training machine-learning (ML) models is an
increasingly pressing challenge, as myriad ML practitioners routinely leverage
the effort of content creators to train models without their permission. In
this paper, we propose a general method to audit an ML model for the use of a
data-owner's data in training, without prior knowledge of the ML task for which
the data might be used. Our method leverages any existing black-box membership
inference method, together with a sequential hypothesis test of our own design,
to detect data use with a quantifiable, tunable false-detection rate. We show
the effectiveness of our proposed framework by applying it to audit data use in
two types of ML models, namely image classifiers and foundation models.",2024-07-21,"Zonghao Huang, Neil Zhenqiang Gong, Michael K. Reiter",http://arxiv.org/pdf/2407.15100v3,cs.LG
SeqMIA: Sequential-Metric Based Membership Inference Attack,"Most existing membership inference attacks (MIAs) utilize metrics (e.g.,
loss) calculated on the model's final state, while recent advanced attacks
leverage metrics computed at various stages, including both intermediate and
final stages, throughout the model training. Nevertheless, these attacks often
process multiple intermediate states of the metric independently, ignoring
their time-dependent patterns. Consequently, they struggle to effectively
distinguish between members and non-members who exhibit similar metric values,
particularly resulting in a high false-positive rate.
  In this study, we delve deeper into the new membership signals in the
black-box scenario. We identify a new, more integrated membership signal: the
Pattern of Metric Sequence, derived from the various stages of model training.
We contend that current signals provide only partial perspectives of this new
signal: the new one encompasses both the model's multiple intermediate and
final states, with a greater emphasis on temporal patterns among them. Building
upon this signal, we introduce a novel attack method called Sequential-metric
based Membership Inference Attack (SeqMIA). Specifically, we utilize knowledge
distillation to obtain a set of distilled models representing various stages of
the target model's training. We then assess multiple metrics on these distilled
models in chronological order, creating distilled metric sequence. We finally
integrate distilled multi-metric sequences as a sequential multiformat and
employ an attention-based RNN attack model for inference. Empirical results
show SeqMIA outperforms all baselines, especially can achieve an order of
magnitude improvement in terms of TPR @ 0.1% FPR. Furthermore, we delve into
the reasons why this signal contributes to SeqMIA's high attack performance,
and assess various defense mechanisms against SeqMIA.",2024-07-21,"Hao Li, Zheng Li, Siyuan Wu, Chengrui Hu, Yutong Ye, Min Zhang, Dengguo Feng, Yang Zhang",http://arxiv.org/pdf/2407.15098v1,cs.LG
Learning Physics for Unveiling Hidden Earthquake Ground Motions via Conditional Generative Modeling,"Predicting high-fidelity ground motions for future earthquakes is crucial for
seismic hazard assessment and infrastructure resilience. Conventional empirical
simulations suffer from sparse sensor distribution and geographically localized
earthquake locations, while physics-based methods are computationally intensive
and require accurate representations of Earth structures and earthquake
sources. We propose a novel artificial intelligence (AI) simulator, Conditional
Generative Modeling for Ground Motion (CGM-GM), to synthesize high-frequency
and spatially continuous earthquake ground motion waveforms. CGM-GM leverages
earthquake magnitudes and geographic coordinates of earthquakes and sensors as
inputs, learning complex wave physics and Earth heterogeneities, without
explicit physics constraints. This is achieved through a probabilistic
autoencoder that captures latent distributions in the time-frequency domain and
variational sequential models for prior and posterior distributions. We
evaluate the performance of CGM-GM using small-magnitude earthquake records
from the San Francisco Bay Area, a region with high seismic risks. CGM-GM
demonstrates a strong potential for outperforming a state-of-the-art
non-ergodic empirical ground motion model and shows great promise in seismology
and beyond.",2024-07-21,"Pu Ren, Rie Nakata, Maxime Lacour, Ilan Naiman, Nori Nakata, Jialin Song, Zhengfa Bi, Osman Asif Malik, Dmitriy Morozov, Omri Azencot, N. Benjamin Erichson, Michael W. Mahoney",http://arxiv.org/pdf/2407.15089v1,cs.LG
Rocket Landing Control with Random Annealing Jump Start Reinforcement Learning,"Rocket recycling is a crucial pursuit in aerospace technology, aimed at
reducing costs and environmental impact in space exploration. The primary focus
centers on rocket landing control, involving the guidance of a nonlinear
underactuated rocket with limited fuel in real-time. This challenging task
prompts the application of reinforcement learning (RL), yet goal-oriented
nature of the problem poses difficulties for standard RL algorithms due to the
absence of intermediate reward signals. This paper, for the first time,
significantly elevates the success rate of rocket landing control from 8% with
a baseline controller to 97% on a high-fidelity rocket model using RL. Our
approach, called Random Annealing Jump Start (RAJS), is tailored for real-world
goal-oriented problems by leveraging prior feedback controllers as guide policy
to facilitate environmental exploration and policy learning in RL. In each
episode, the guide policy navigates the environment for the guide horizon,
followed by the exploration policy taking charge to complete remaining steps.
This jump-start strategy prunes exploration space, rendering the problem more
tractable to RL algorithms. The guide horizon is sampled from a uniform
distribution, with its upper bound annealing to zero based on performance
metrics, mitigating distribution shift and mismatch issues in existing methods.
Additional enhancements, including cascading jump start, refined reward and
terminal condition, and action smoothness regulation, further improve policy
performance and practical applicability. The proposed method is validated
through extensive evaluation and Hardware-in-the-Loop testing, affirming the
effectiveness, real-time feasibility, and smoothness of the proposed
controller.",2024-07-21,"Yuxuan Jiang, Yujie Yang, Zhiqian Lan, Guojian Zhan, Shengbo Eben Li, Qi Sun, Jian Ma, Tianwen Yu, Changwu Zhang",http://arxiv.org/pdf/2407.15083v1,cs.LG
Learning to Compile Programs to Neural Networks,"A $\textit{neural surrogate of a program}$ is a neural network that mimics
the behavior of a program. Researchers have used these neural surrogates to
automatically tune program inputs, adapt programs to new settings, and
accelerate computations. Researchers traditionally develop neural surrogates by
training on input-output examples from a single program. Alternatively,
language models trained on a large dataset including many programs can consume
program text, to act as a neural surrogate. Using a language model to both
generate a surrogate and act as a surrogate, however, leading to a trade-off
between resource consumption and accuracy. We present $\textit{neural surrogate
compilation}$, a technique for producing neural surrogates directly from
program text without coupling neural surrogate generation and execution. We
implement neural surrogate compilers using hypernetworks trained on a dataset
of C programs and find that they produce neural surrogates that are
$1.9$-$9.5\times$ as data-efficient, produce visual results that are
$1.0$-$1.3\times$ more similar to ground truth, and train in $4.3$-$7.3\times$
fewer epochs than neural surrogates trained from scratch.",2024-07-21,"Logan Weber, Jesse Michel, Alex Renda, Michael Carbin",http://arxiv.org/pdf/2407.15078v1,cs.LG
Trading Devil Final: Backdoor attack via Stock market and Bayesian Optimization,"Since the advent of generative artificial intelligence, every company and
researcher has been rushing to develop their own generative models, whether
commercial or not. Given the large number of users of these powerful new tools,
there is currently no intrinsically verifiable way to explain from the ground
up what happens when LLMs (large language models) learn. For example, those
based on automatic speech recognition systems, which have to rely on huge and
astronomical amounts of data collected from all over the web to produce fast
and efficient results, In this article, we develop a backdoor attack called
MarketBackFinal 2.0, based on acoustic data poisoning, MarketBackFinal 2.0 is
mainly based on modern stock market models. In order to show the possible
vulnerabilities of speech-based transformers that may rely on LLMs.",2024-07-21,Orson Mengara,http://arxiv.org/pdf/2407.14573v7,cs.LG
Arondight: Red Teaming Large Vision Language Models with Auto-generated Multi-modal Jailbreak Prompts,"Large Vision Language Models (VLMs) extend and enhance the perceptual
abilities of Large Language Models (LLMs). Despite offering new possibilities
for LLM applications, these advancements raise significant security and ethical
concerns, particularly regarding the generation of harmful content. While LLMs
have undergone extensive security evaluations with the aid of red teaming
frameworks, VLMs currently lack a well-developed one. To fill this gap, we
introduce Arondight, a standardized red team framework tailored specifically
for VLMs. Arondight is dedicated to resolving issues related to the absence of
visual modality and inadequate diversity encountered when transitioning
existing red teaming methodologies from LLMs to VLMs. Our framework features an
automated multi-modal jailbreak attack, wherein visual jailbreak prompts are
produced by a red team VLM, and textual prompts are generated by a red team LLM
guided by a reinforcement learning agent. To enhance the comprehensiveness of
VLM security evaluation, we integrate entropy bonuses and novelty reward
metrics. These elements incentivize the RL agent to guide the red team LLM in
creating a wider array of diverse and previously unseen test cases. Our
evaluation of ten cutting-edge VLMs exposes significant security
vulnerabilities, particularly in generating toxic images and aligning
multi-modal prompts. In particular, our Arondight achieves an average attack
success rate of 84.5\% on GPT-4 in all fourteen prohibited scenarios defined by
OpenAI in terms of generating toxic text. For a clearer comparison, we also
categorize existing VLMs based on their safety levels and provide corresponding
reinforcement recommendations. Our multimodal prompt dataset and red team code
will be released after ethics committee approval. CONTENT WARNING: THIS PAPER
CONTAINS HARMFUL MODEL RESPONSES.",2024-07-21,"Yi Liu, Chengjun Cai, Xiaoli Zhang, Xingliang Yuan, Cong Wang",http://arxiv.org/pdf/2407.15050v1,cs.LG
Efficient Sampling for Data-Driven Frequency Stability Constraint via Forward-Mode Automatic Differentiation,"Encoding frequency stability constraints in the operation problem is
challenging due to its complex dynamics. Recently, data-driven approaches have
been proposed to learn the stability criteria offline with the trained model
embedded as a constraint of online optimization. However, random sampling of
stationary operation points is less efficient in generating balanced stable and
unstable samples. Meanwhile, the performance of such a model is strongly
dependent on the quality of the training dataset. Observing this research gap,
we propose a gradient-based data generation method via forward-mode automatic
differentiation. In this method, the original dynamic system is augmented with
new states that represent the dynamic of sensitivities of the original states,
which can be solved by invoking any ODE solver for a single time. To compensate
for the contradiction between the gradient of various frequency stability
criteria, gradient surgery is proposed by projecting the gradient on the normal
plane of the other. In the end, we demonstrate the superior performance of the
proposed sampling algorithm, compared with the unrolling differentiation and
finite difference. All codes are available at
https://github.com/xuwkk/frequency_sample_ad.",2024-07-21,"Wangkun Xu, Qian Chen, Pudong Ge, Zhongda Chu, Fei Teng",http://arxiv.org/pdf/2407.15045v1,cs.LG
AsyCo: An Asymmetric Dual-task Co-training Model for Partial-label Learning,"Partial-Label Learning (PLL) is a typical problem of weakly supervised
learning, where each training instance is annotated with a set of candidate
labels. Self-training PLL models achieve state-of-the-art performance but
suffer from error accumulation problem caused by mistakenly disambiguated
instances. Although co-training can alleviate this issue by training two
networks simultaneously and allowing them to interact with each other, most
existing co-training methods train two structurally identical networks with the
same task, i.e., are symmetric, rendering it insufficient for them to correct
each other due to their similar limitations. Therefore, in this paper, we
propose an asymmetric dual-task co-training PLL model called AsyCo, which
forces its two networks, i.e., a disambiguation network and an auxiliary
network, to learn from different views explicitly by optimizing distinct tasks.
Specifically, the disambiguation network is trained with self-training PLL task
to learn label confidence, while the auxiliary network is trained in a
supervised learning paradigm to learn from the noisy pairwise similarity labels
that are constructed according to the learned label confidence. Finally, the
error accumulation problem is mitigated via information distillation and
confidence refinement. Extensive experiments on both uniform and
instance-dependent partially labeled datasets demonstrate the effectiveness of
AsyCo. The code is available at https://github.com/libeibeics/AsyCo.",2024-07-21,"Beibei Li, Yiyuan Zheng, Beihong Jin, Tao Xiang, Haobo Wang, Lei Feng",http://arxiv.org/pdf/2407.15036v1,cs.LG
Ensemble quantile-based deep learning framework for streamflow and flood prediction in Australian catchments,"In recent years, climate extremes such as floods have created significant
environmental and economic hazards for Australia. Deep learning methods have
been promising for predicting extreme climate events; however, large flooding
events present a critical challenge due to factors such as model calibration
and missing data. We present an ensemble quantile-based deep learning framework
that addresses large-scale streamflow forecasts using quantile regression for
uncertainty projections in prediction. We evaluate selected univariate and
multivariate deep learning models and catchment strategies. Furthermore, we
implement a multistep time-series prediction model using the CAMELS dataset for
selected catchments across Australia. The ensemble model employs a set of
quantile deep learning models for streamflow determined by historical
streamflow data. We utilise the streamflow prediction and obtain flood
probability using flood frequency analysis and compare it with historical
flooding events for selected catchments. Our results demonstrate notable
efficacy and uncertainties in streamflow forecasts with varied catchment
properties. Our flood probability estimates show good accuracy in capturing the
historical floods from the selected catchments. This underscores the potential
for our deep learning framework to revolutionise flood forecasting across
diverse regions and be implemented as an early warning system.",2024-07-20,"Rohitash Chandra, Arpit Kapoor, Siddharth Khedkar, Jim Ng, R. Willem Vervoort",http://arxiv.org/pdf/2407.15882v2,cs.LG
Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning,"Imitation learning (IL) aims to mimic the behavior of an expert in a
sequential decision making task by learning from demonstrations, and has been
widely applied to robotics, autonomous driving, and autoregressive text
generation. The simplest approach to IL, behavior cloning (BC), is thought to
incur sample complexity with unfavorable quadratic dependence on the problem
horizon, motivating a variety of different online algorithms that attain
improved linear horizon dependence under stronger assumptions on the data and
the learner's access to the expert.
  We revisit the apparent gap between offline and online IL from a
learning-theoretic perspective, with a focus on the realizable/well-specified
setting with general policy classes up to and including deep neural networks.
Through a new analysis of behavior cloning with the logarithmic loss, we show
that it is possible to achieve horizon-independent sample complexity in offline
IL whenever (i) the range of the cumulative payoffs is controlled, and (ii) an
appropriate notion of supervised learning complexity for the policy class is
controlled. Specializing our results to deterministic, stationary policies, we
show that the gap between offline and online IL is smaller than previously
thought: (i) it is possible to achieve linear dependence on horizon in offline
IL under dense rewards (matching what was previously only known to be
achievable in online IL); and (ii) without further assumptions on the policy
class, online IL cannot improve over offline IL with the logarithmic loss, even
in benign MDPs. We complement our theoretical results with experiments on
standard RL tasks and autoregressive language generation to validate the
practical relevance of our findings.",2024-07-20,"Dylan J. Foster, Adam Block, Dipendra Misra",http://arxiv.org/pdf/2407.15007v2,cs.LG
All Against Some: Efficient Integration of Large Language Models for Message Passing in Graph Neural Networks,"Graph Neural Networks (GNNs) have attracted immense attention in the past
decade due to their numerous real-world applications built around
graph-structured data. On the other hand, Large Language Models (LLMs) with
extensive pretrained knowledge and powerful semantic comprehension abilities
have recently shown a remarkable ability to benefit applications using vision
and text data. In this paper, we investigate how LLMs can be leveraged in a
computationally efficient fashion to benefit rich graph-structured data, a
modality relatively unexplored in LLM literature. Prior works in this area
exploit LLMs to augment every node features in an ad-hoc fashion (not scalable
for large graphs), use natural language to describe the complex structural
information of graphs, or perform computationally expensive finetuning of LLMs
in conjunction with GNNs. We propose E-LLaGNN (Efficient LLMs augmented GNNs),
a framework with an on-demand LLM service that enriches message passing
procedure of graph learning by enhancing a limited fraction of nodes from the
graph. More specifically, E-LLaGNN relies on sampling high-quality
neighborhoods using LLMs, followed by on-demand neighborhood feature
enhancement using diverse prompts from our prompt catalog, and finally
information aggregation using message passing from conventional GNN
architectures. We explore several heuristics-based active node selection
strategies to limit the computational and memory footprint of LLMs when
handling millions of nodes. Through extensive experiments & ablation on popular
graph benchmarks of varying scales (Cora, PubMed, ArXiv, & Products), we
illustrate the effectiveness of our E-LLaGNN framework and reveal many
interesting capabilities such as improved gradient flow in deep GNNs, LLM-free
inference ability etc.",2024-07-20,"Ajay Jaiswal, Nurendra Choudhary, Ravinarayana Adkathimar, Muthu P. Alagappan, Gaurush Hiranandani, Ying Ding, Zhangyang Wang, Edward W Huang, Karthik Subbian",http://arxiv.org/pdf/2407.14996v1,cs.LG
Generalization v.s. Memorization: Tracing Language Models' Capabilities Back to Pretraining Data,"The impressive capabilities of large language models (LLMs) have sparked
debate over whether these models genuinely generalize to unseen tasks or
predominantly rely on memorizing vast amounts of pretraining data. To explore
this issue, we introduce an extended concept of memorization, distributional
memorization, which measures the correlation between the LLM output
probabilities and the pretraining data frequency. To effectively capture
task-specific pretraining data frequency, we propose a novel task-gram language
model, which is built by counting the co-occurrence of semantically related
$n$-gram pairs from task inputs and outputs in the pretraining corpus. Using
the Pythia models trained on the Pile dataset, we evaluate four distinct tasks:
machine translation, factual question answering, world knowledge understanding,
and math reasoning. Our findings reveal varying levels of memorization, with
the strongest effect observed in factual question answering. Furthermore, while
model performance improves across all tasks as LLM size increases, only factual
question answering shows an increase in memorization, whereas machine
translation and reasoning tasks exhibit greater generalization, producing more
novel outputs. This study demonstrates that memorization plays a larger role in
simpler, knowledge-intensive tasks, while generalization is the key for harder,
reasoning-based tasks, providing a scalable method for analyzing large
pretraining corpora in greater depth.",2024-07-20,"Xinyi Wang, Antonis Antoniades, Yanai Elazar, Alfonso Amayuelas, Alon Albalak, Kexun Zhang, William Yang Wang",http://arxiv.org/pdf/2407.14985v5,cs.LG
Enhancing Microgrid Performance Prediction with Attention-based Deep Learning Models,"In this research, an effort is made to address microgrid systems' operational
challenges, characterized by power oscillations that eventually contribute to
grid instability. An integrated strategy is proposed, leveraging the strengths
of convolutional and Gated Recurrent Unit (GRU) layers. This approach is aimed
at effectively extracting temporal data from energy datasets to improve the
precision of microgrid behavior forecasts. Additionally, an attention layer is
employed to underscore significant features within the time-series data,
optimizing the forecasting process. The framework is anchored by a Multi-Layer
Perceptron (MLP) model, which is tasked with comprehensive load forecasting and
the identification of abnormal grid behaviors. Our methodology underwent
rigorous evaluation using the Micro-grid Tariff Assessment Tool dataset, with
Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and the coefficient
of determination (r2-score) serving as the primary metrics. The approach
demonstrated exemplary performance, evidenced by a MAE of 0.39, RMSE of 0.28,
and an r2-score of 98.89\% in load forecasting, along with near-perfect zero
state prediction accuracy (approximately 99.9\%). Significantly outperforming
conventional machine learning models such as support vector regression and
random forest regression, our model's streamlined architecture is particularly
suitable for real-time applications, thereby facilitating more effective and
reliable microgrid management.",2024-07-20,"Vinod Kumar Maddineni, Naga Babu Koganti, Praveen Damacharla",http://arxiv.org/pdf/2407.14984v1,cs.LG
Out of spuriousity: Improving robustness to spurious correlations without group annotations,"Machine learning models are known to learn spurious correlations, i.e.,
features having strong relations with class labels but no causal relation.
Relying on those correlations leads to poor performance in the data groups
without these correlations and poor generalization ability. To improve the
robustness of machine learning models to spurious correlations, we propose an
approach to extract a subnetwork from a fully trained network that does not
rely on spurious correlations. The subnetwork is found by the assumption that
data points with the same spurious attribute will be close to each other in the
representation space when training with ERM, then we employ supervised
contrastive loss in a novel way to force models to unlearn the spurious
connections. The increase in the worst-group performance of our approach
contributes to strengthening the hypothesis that there exists a subnetwork in a
fully trained dense network that is responsible for using only invariant
features in classification tasks, therefore erasing the influence of spurious
features even in the setup of multi spurious attributes and no prior knowledge
of attributes labels.",2024-07-20,"Phuong Quynh Le, Jörg Schlötterer, Christin Seifert",http://arxiv.org/pdf/2407.14974v1,cs.LG
Sim-CLIP: Unsupervised Siamese Adversarial Fine-Tuning for Robust and Semantically-Rich Vision-Language Models,"Vision-language models (VLMs) have achieved significant strides in recent
times specially in multimodal tasks, yet they remain susceptible to adversarial
attacks on their vision components. To address this, we propose Sim-CLIP, an
unsupervised adversarial fine-tuning method that enhances the robustness of the
widely-used CLIP vision encoder against such attacks while maintaining semantic
richness and specificity. By employing a Siamese architecture with cosine
similarity loss, Sim-CLIP learns semantically meaningful and attack-resilient
visual representations without requiring large batch sizes or momentum
encoders. Our results demonstrate that VLMs enhanced with Sim-CLIP's fine-tuned
CLIP encoder exhibit significantly enhanced robustness against adversarial
attacks, while preserving semantic meaning of the perturbed images. Notably,
Sim-CLIP does not require additional training or fine-tuning of the VLM itself;
replacing the original vision encoder with our fine-tuned Sim-CLIP suffices to
provide robustness. This work underscores the significance of reinforcing
foundational models like CLIP to safeguard the reliability of downstream VLM
applications, paving the way for more secure and effective multimodal systems.",2024-07-20,"Md Zarif Hossain, Ahmed Imteaj",http://arxiv.org/pdf/2407.14971v2,cs.LG
Technical report: Improving the properties of molecules generated by LIMO,"This technical report investigates variants of the Latent Inceptionism on
Molecules (LIMO) framework to improve the properties of generated molecules. We
conduct ablative studies of molecular representation, decoder model, and
surrogate model training scheme. The experiments suggest that an autogressive
Transformer decoder with GroupSELFIES achieves the best average properties for
the random generation task.",2024-07-20,"Vineet Thumuluri, Peter Eckmann, Michael K. Gilson, Rose Yu",http://arxiv.org/pdf/2407.14968v1,cs.LG
Base and Exponent Prediction in Mathematical Expressions using Multi-Output CNN,"The use of neural networks and deep learning techniques in image processing
has significantly advanced the field, enabling highly accurate recognition
results. However, achieving high recognition rates often necessitates complex
network models, which can be challenging to train and require substantial
computational resources. This research presents a simplified yet effective
approach to predicting both the base and exponent from images of mathematical
expressions using a multi-output Convolutional Neural Network (CNN). The model
is trained on 10,900 synthetically generated images containing exponent
expressions, incorporating random noise, font size variations, and blur
intensity to simulate real-world conditions. The proposed CNN model
demonstrates robust performance with efficient training time. The experimental
results indicate that the model achieves high accuracy in predicting the base
and exponent values, proving the efficacy of this approach in handling noisy
and varied input images.",2024-07-20,"Md Laraib Salam, Akash S Balsaraf, Gaurav Gupta",http://arxiv.org/pdf/2407.14967v1,cs.LG
"Recent Advances in Generative AI and Large Language Models: Current Status, Challenges, and Perspectives","The emergence of Generative Artificial Intelligence (AI) and Large Language
Models (LLMs) has marked a new era of Natural Language Processing (NLP),
introducing unprecedented capabilities that are revolutionizing various
domains. This paper explores the current state of these cutting-edge
technologies, demonstrating their remarkable advancements and wide-ranging
applications. Our paper contributes to providing a holistic perspective on the
technical foundations, practical applications, and emerging challenges within
the evolving landscape of Generative AI and LLMs. We believe that understanding
the generative capabilities of AI systems and the specific context of LLMs is
crucial for researchers, practitioners, and policymakers to collaboratively
shape the responsible and ethical integration of these technologies into
various domains. Furthermore, we identify and address main research gaps,
providing valuable insights to guide future research endeavors within the AI
research community.",2024-07-20,"Desta Haileselassie Hagos, Rick Battle, Danda B. Rawat",http://arxiv.org/pdf/2407.14962v5,cs.LG
Addressing Data Heterogeneity in Federated Learning of Cox Proportional Hazards Models,"The diversity in disease profiles and therapeutic approaches between
hospitals and health professionals underscores the need for patient-centric
personalized strategies in healthcare. Alongside this, similarities in disease
progression across patients can be utilized to improve prediction models in
survival analysis. The need for patient privacy and the utility of prediction
models can be simultaneously addressed in the framework of Federated Learning
(FL). This paper outlines an approach in the domain of federated survival
analysis, specifically the Cox Proportional Hazards (CoxPH) model, with a
specific focus on mitigating data heterogeneity and elevating model
performance. We present an FL approach that employs feature-based clustering to
enhance model accuracy across synthetic datasets and real-world applications,
including the Surveillance, Epidemiology, and End Results (SEER) database.
Furthermore, we consider an event-based reporting strategy that provides a
dynamic approach to model adaptation by responding to local data changes. Our
experiments show the efficacy of our approach and discuss future directions for
a practical application of FL in healthcare.",2024-07-20,"Navid Seidi, Satyaki Roy, Sajal K. Das, Ardhendu Tripathy",http://arxiv.org/pdf/2407.14960v1,cs.LG
Strongly Isomorphic Neural Optimal Transport Across Incomparable Spaces,"Optimal Transport (OT) has recently emerged as a powerful framework for
learning minimal-displacement maps between distributions. The predominant
approach involves a neural parametrization of the Monge formulation of OT,
typically assuming the same space for both distributions. However, the setting
across ``incomparable spaces'' (e.g., of different dimensionality),
corresponding to the Gromov- Wasserstein distance, remains underexplored, with
existing methods often imposing restrictive assumptions on the cost function.
In this paper, we present a novel neural formulation of the Gromov-Monge (GM)
problem rooted in one of its fundamental properties: invariance to strong
isomorphisms. We operationalize this property by decomposing the learnable OT
map into two components: (i) an approximate strong isomorphism between the
source distribution and an intermediate reference distribution, and (ii) a
GM-optimal map between this reference and the target distribution. Our
formulation leverages and extends the Monge gap regularizer of Uscidda & Cuturi
(2023) to eliminate the need for complex architectural requirements of other
neural OT methods, yielding a simple but practical method that enjoys favorable
theoretical guarantees. Our preliminary empirical results show that our
framework provides a promising approach to learn OT maps across diverse spaces.",2024-07-20,"Athina Sotiropoulou, David Alvarez-Melis",http://arxiv.org/pdf/2407.14957v1,cs.LG
Data Sharing for Mean Estimation Among Heterogeneous Strategic Agents,"We study a collaborative learning problem where $m$ agents estimate a vector
$\mu\in\mathbb{R}^d$ by collecting samples from normal distributions, with each
agent $i$ incurring a cost $c_{i,k} \in (0, \infty]$ to sample from the
$k^{\text{th}}$ distribution $\mathcal{N}(\mu_k, \sigma^2)$. Instead of working
on their own, agents can collect data that is cheap to them, and share it with
others in exchange for data that is expensive or even inaccessible to them,
thereby simultaneously reducing data collection costs and estimation error.
However, when agents have different collection costs, we need to first decide
how to fairly divide the work of data collection so as to benefit all agents.
Moreover, in naive sharing protocols, strategic agents may under-collect and/or
fabricate data, leading to socially undesirable outcomes. Our mechanism
addresses these challenges by combining ideas from cooperative and
non-cooperative game theory. We use ideas from axiomatic bargaining to divide
the cost of data collection. Given such a solution, we develop a Nash
incentive-compatible (NIC) mechanism to enforce truthful reporting. We achieve
a $\mathcal{O}(\sqrt{m})$ approximation to the minimum social penalty (sum of
agent estimation errors and data collection costs) in the worst case, and a
$\mathcal{O}(1)$ approximation under favorable conditions. We complement this
with a hardness result, showing that $\Omega(\sqrt{m})$ is unavoidable in any
NIC mechanism.",2024-07-20,"Alex Clinton, Yiding Chen, Xiaojin Zhu, Kirthevasan Kandasamy",http://arxiv.org/pdf/2407.15881v1,cs.LG
Conversational Rubert for Detecting Competitive Interruptions in ASR-Transcribed Dialogues,"Interruption in a dialogue occurs when the listener begins their speech
before the current speaker finishes speaking. Interruptions can be broadly
divided into two groups: cooperative (when the listener wants to support the
speaker), and competitive (when the listener tries to take control of the
conversation against the speaker's will). A system that automatically
classifies interruptions can be used in call centers, specifically in the tasks
of customer satisfaction monitoring and agent monitoring. In this study, we
developed a text-based interruption classification model by preparing an
in-house dataset consisting of ASR-transcribed customer support telephone
dialogues in Russian. We fine-tuned Conversational RuBERT on our dataset and
optimized hyperparameters, and the model performed well. With further
improvements, the proposed model can be applied to automatic monitoring
systems.",2024-07-20,"Dmitrii Galimzianov, Viacheslav Vyshegorodtsev",http://arxiv.org/pdf/2407.14940v1,cs.LG
Consent in Crisis: The Rapid Decline of the AI Data Commons,"General-purpose artificial intelligence (AI) systems are built on massive
swathes of public web data, assembled into corpora such as C4, RefinedWeb, and
Dolma. To our knowledge, we conduct the first, large-scale, longitudinal audit
of the consent protocols for the web domains underlying AI training corpora.
Our audit of 14,000 web domains provides an expansive view of crawlable web
data and how codified data use preferences are changing over time. We observe a
proliferation of AI-specific clauses to limit use, acute differences in
restrictions on AI developers, as well as general inconsistencies between
websites' expressed intentions in their Terms of Service and their robots.txt.
We diagnose these as symptoms of ineffective web protocols, not designed to
cope with the widespread re-purposing of the internet for AI. Our longitudinal
analyses show that in a single year (2023-2024) there has been a rapid
crescendo of data restrictions from web sources, rendering ~5%+ of all tokens
in C4, or 28%+ of the most actively maintained, critical sources in C4, fully
restricted from use. For Terms of Service crawling restrictions, a full 45% of
C4 is now restricted. If respected or enforced, these restrictions are rapidly
biasing the diversity, freshness, and scaling laws for general-purpose AI
systems. We hope to illustrate the emerging crises in data consent, for both
developers and creators. The foreclosure of much of the open web will impact
not only commercial AI, but also non-commercial AI and academic research.",2024-07-20,"Shayne Longpre, Robert Mahari, Ariel Lee, Campbell Lund, Hamidah Oderinwale, William Brannon, Nayan Saxena, Naana Obeng-Marnu, Tobin South, Cole Hunter, Kevin Klyman, Christopher Klamm, Hailey Schoelkopf, Nikhil Singh, Manuel Cherep, Ahmad Anis, An Dinh, Caroline Chitongo, Da Yin, Damien Sileo, Deividas Mataciunas, Diganta Misra, Emad Alghamdi, Enrico Shippole, Jianguo Zhang, Joanna Materzynska, Kun Qian, Kush Tiwary, Lester Miranda, Manan Dey, Minnie Liang, Mohammed Hamdy, Niklas Muennighoff, Seonghyeon Ye, Seungone Kim, Shrestha Mohanty, Vipul Gupta, Vivek Sharma, Vu Minh Chien, Xuhui Zhou, Yizhi Li, Caiming Xiong, Luis Villa, Stella Biderman, Hanlin Li, Daphne Ippolito, Sara Hooker, Jad Kabbara, Sandy Pentland",http://arxiv.org/pdf/2407.14933v2,cs.LG
POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding,"Multi-agent reinforcement learning (MARL) has recently excelled in solving
challenging cooperative and competitive multi-agent problems in various
environments, typically involving a small number of agents and full
observability. Moreover, a range of crucial robotics-related tasks, such as
multi-robot pathfinding, which have traditionally been approached with
classical non-learnable methods (e.g., heuristic search), are now being
suggested for solution using learning-based or hybrid methods. However, in this
domain, it remains difficult, if not impossible, to conduct a fair comparison
between classical, learning-based, and hybrid approaches due to the lack of a
unified framework that supports both learning and evaluation. To address this,
we introduce POGEMA, a comprehensive set of tools that includes a fast
environment for learning, a problem instance generator, a collection of
predefined problem instances, a visualization toolkit, and a benchmarking tool
for automated evaluation. We also introduce and define an evaluation protocol
that specifies a range of domain-related metrics, computed based on primary
evaluation indicators (such as success rate and path length), enabling a fair
multi-fold comparison. The results of this comparison, which involves a variety
of state-of-the-art MARL, search-based, and hybrid methods, are presented.",2024-07-20,"Alexey Skrynnik, Anton Andreychuk, Anatolii Borzilov, Alexander Chernyavskiy, Konstantin Yakovlev, Aleksandr Panov",http://arxiv.org/pdf/2407.14931v3,cs.LG
Improving Context-Aware Preference Modeling for Language Models,"While finetuning language models from pairwise preferences has proven
remarkably effective, the underspecified nature of natural language presents
critical challenges. Direct preference feedback is uninterpretable, difficult
to provide where multidimensional criteria may apply, and often inconsistent,
either because it is based on incomplete instructions or provided by diverse
principals. To address these challenges, we consider the two-step preference
modeling procedure that first resolves the under-specification by selecting a
context, and then evaluates preference with respect to the chosen context. We
decompose reward modeling error according to these two steps, which suggests
that supervising context in addition to context-specific preference may be a
viable approach to aligning models with diverse human preferences. For this to
work, the ability of models to evaluate context-specific preference is
critical. To this end, we contribute context-conditioned preference datasets
and accompanying experiments that investigate the ability of language models to
evaluate context-specific preference. We use our datasets to (1) show that
existing preference models benefit from, but fail to fully consider, added
context, (2) finetune a context-aware reward model with context-specific
performance exceeding that of GPT-4 and Llama 3 70B on tested datasets, and (3)
investigate the value of context-aware preference modeling.",2024-07-20,"Silviu Pitis, Ziang Xiao, Nicolas Le Roux, Alessandro Sordoni",http://arxiv.org/pdf/2407.14916v2,cs.LG
Hyperspectral Unmixing Under Endmember Variability: A Variational Inference Framework,"This work proposes a variational inference (VI) framework for hyperspectral
unmixing in the presence of endmember variability (HU-EV). An EV-accounted
noisy linear mixture model (LMM) is considered, and the presence of outliers is
also incorporated into the model. Following the marginalized maximum likelihood
(MML) principle, a VI algorithmic structure is designed for probabilistic
inference for HU-EV. Specifically, a patch-wise static endmember assumption is
employed to exploit spatial smoothness and to try to overcome the ill-posed
nature of the HU-EV problem. The design facilitates lightweight, continuous
optimization-based updates under a variety of endmember priors. Some of the
priors, such as the Beta prior, were previously used under computationally
heavy, sampling-based probabilistic HU-EV methods. The effectiveness of the
proposed framework is demonstrated through synthetic, semi-real, and real-data
experiments.",2024-07-20,"Yuening Li, Xiao Fu, Junbin Liu, Wing-Kin Ma",http://arxiv.org/pdf/2407.14899v1,cs.LG
Mapping Patient Trajectories: Understanding and Visualizing Sepsis Prognostic Pathways from Patients Clinical Narratives,"In recent years, healthcare professionals are increasingly emphasizing on
personalized and evidence-based patient care through the exploration of
prognostic pathways. To study this, structured clinical variables from
Electronic Health Records (EHRs) data have traditionally been employed by many
researchers. Presently, Natural Language Processing models have received great
attention in clinical research which expanded the possibilities of using
clinical narratives. In this paper, we propose a systematic methodology for
developing sepsis prognostic pathways derived from clinical notes, focusing on
diverse patient subgroups identified by exploring comorbidities associated with
sepsis and generating explanations of these subgroups using SHAP. The extracted
prognostic pathways of these subgroups provide valuable insights into the
dynamic trajectories of sepsis severity over time. Visualizing these pathways
sheds light on the likelihood and direction of disease progression across
various contexts and reveals patterns and pivotal factors or biomarkers
influencing the transition between sepsis stages, whether toward deterioration
or improvement. This empowers healthcare providers to implement more
personalized and effective healthcare strategies for individual patients.",2024-07-20,"Sudeshna Jana, Tirthankar Dasgupta, Lipika Dey",http://arxiv.org/pdf/2407.21039v1,cs.LG
Latent Pollution Model: The Hidden Carbon Footprint in 3D Image Synthesis,"Contemporary developments in generative AI are rapidly transforming the field
of medical AI. These developments have been predominantly driven by the
availability of large datasets and high computing power, which have facilitated
a significant increase in model capacity. Despite their considerable potential,
these models demand substantially high power, leading to high carbon dioxide
(CO2) emissions. Given the harm such models are causing to the environment,
there has been little focus on the carbon footprints of such models. This study
analyzes carbon emissions from 2D and 3D latent diffusion models (LDMs) during
training and data generation phases, revealing a surprising finding: the
synthesis of large images contributes most significantly to these emissions. We
assess different scenarios including model sizes, image dimensions, distributed
training, and data generation steps. Our findings reveal substantial carbon
emissions from these models, with training 2D and 3D models comparable to
driving a car for 10 km and 90 km, respectively. The process of data generation
is even more significant, with CO2 emissions equivalent to driving 160 km for
2D models and driving for up to 3345 km for 3D synthesis. Additionally, we
found that the location of the experiment can increase carbon emissions by up
to 94 times, and even the time of year can influence emissions by up to 50%.
These figures are alarming, considering they represent only a single training
and data generation phase for each model. Our results emphasize the urgent need
for developing environmentally sustainable strategies in generative AI.",2024-07-20,"Marvin Seyfarth, Salman Ul Hassan Dar, Sandy Engelhardt",http://arxiv.org/pdf/2407.14892v1,cs.LG
Reduced Effectiveness of Kolmogorov-Arnold Networks on Functions with Noise,"It has been observed that even a small amount of noise introduced into the
dataset can significantly degrade the performance of KAN. In this brief note,
we aim to quantitatively evaluate the performance when noise is added to the
dataset. We propose an oversampling technique combined with denoising to
alleviate the impact of noise. Specifically, we employ kernel filtering based
on diffusion maps for pre-filtering the noisy data for training KAN network.
Our experiments show that while adding i.i.d. noise with any fixed SNR, when we
increase the amount of training data by a factor of $r$, the test-loss (RMSE)
of KANs will exhibit a performance trend like $\text{test-loss} \sim
\mathcal{O}(r^{-\frac{1}{2}})$ as $r\to +\infty$. We conclude that applying
both oversampling and filtering strategies can reduce the detrimental effects
of noise. Nevertheless, determining the optimal variance for the kernel
filtering process is challenging, and enhancing the volume of training data
substantially increases the associated costs, because the training dataset
needs to be expanded multiple times in comparison to the initial clean data. As
a result, the noise present in the data ultimately diminishes the effectiveness
of Kolmogorov-Arnold networks.",2024-07-20,"Haoran Shen, Chen Zeng, Jiahui Wang, Qiao Wang",http://arxiv.org/pdf/2407.14882v1,cs.LG
Thompson Sampling Itself is Differentially Private,"In this work we first show that the classical Thompson sampling algorithm for
multi-arm bandits is differentially private as-is, without any modification. We
provide per-round privacy guarantees as a function of problem parameters and
show composition over $T$ rounds; since the algorithm is unchanged, existing
$O(\sqrt{NT\log N})$ regret bounds still hold and there is no loss in
performance due to privacy. We then show that simple modifications -- such as
pre-pulling all arms a fixed number of times, increasing the sampling variance
-- can provide tighter privacy guarantees. We again provide privacy guarantees
that now depend on the new parameters introduced in the modification, which
allows the analyst to tune the privacy guarantee as desired. We also provide a
novel regret analysis for this new algorithm, and show how the new parameters
also impact expected regret. Finally, we empirically validate and illustrate
our theoretical findings in two parameter regimes and demonstrate that tuning
the new parameters substantially improve the privacy-regret tradeoff.",2024-07-20,"Tingting Ou, Marco Avella Medina, Rachel Cummings",http://arxiv.org/pdf/2407.14879v1,cs.LG
An Explainable Fast Deep Neural Network for Emotion Recognition,"In the context of artificial intelligence, the inherent human attribute of
engaging in logical reasoning to facilitate decision-making is mirrored by the
concept of explainability, which pertains to the ability of a model to provide
a clear and interpretable account of how it arrived at a particular outcome.
This study explores explainability techniques for binary deep neural
architectures in the framework of emotion classification through video
analysis. We investigate the optimization of input features to binary
classifiers for emotion recognition, with face landmarks detection using an
improved version of the Integrated Gradients explainability method. The main
contribution of this paper consists in the employment of an innovative
explainable artificial intelligence algorithm to understand the crucial facial
landmarks movements during emotional feeling, using this information also for
improving the performances of deep learning-based emotion classifiers. By means
of explainability, we can optimize the number and the position of the facial
landmarks used as input features for facial emotion recognition, lowering the
impact of noisy landmarks and thus increasing the accuracy of the developed
models. In order to test the effectiveness of the proposed approach, we
considered a set of deep binary models for emotion classification trained
initially with a complete set of facial landmarks, which are progressively
reduced based on a suitable optimization procedure. The obtained results prove
the robustness of the proposed explainable approach in terms of understanding
the relevance of the different facial points for the different emotions, also
improving the classification accuracy and diminishing the computational cost.",2024-07-20,"Francesco Di Luzio, Antonello Rosato, Massimo Panella",http://arxiv.org/pdf/2407.14865v1,cs.LG
Improving Bias Correction Standards by Quantifying its Effects on Treatment Outcomes,"With the growing access to administrative health databases, retrospective
studies have become crucial evidence for medical treatments. Yet,
non-randomized studies frequently face selection biases, requiring mitigation
strategies. Propensity score matching (PSM) addresses these biases by selecting
comparable populations, allowing for analysis without further methodological
constraints. However, PSM has several drawbacks. Different matching methods can
produce significantly different Average Treatment Effects (ATE) for the same
task, even when meeting all validation criteria. To prevent cherry-picking the
best method, public authorities must involve field experts and engage in
extensive discussions with researchers.
  To address this issue, we introduce a novel metric, A2A, to reduce the number
of valid matches. A2A constructs artificial matching tasks that mirror the
original ones but with known outcomes, assessing each matching method's
performance comprehensively from propensity estimation to ATE estimation. When
combined with Standardized Mean Difference, A2A enhances the precision of model
selection, resulting in a reduction of up to 50% in ATE estimation errors
across synthetic tasks and up to 90% in predicted ATE variability across both
synthetic and real-world datasets. To our knowledge, A2A is the first metric
capable of evaluating outcome correction accuracy using covariates not involved
in selection.
  Computing A2A requires solving hundreds of PSMs, we therefore automate all
manual steps of the PSM pipeline. We integrate PSM methods from Python and R,
our automated pipeline, a new metric, and reproducible experiments into
popmatch, our new Python package, to enhance reproducibility and accessibility
to bias correction methods.",2024-07-20,"Alexandre Abraham, Andrés Hoyos Idrobo",http://arxiv.org/pdf/2407.14861v2,cs.LG
Enhancing High-Energy Particle Physics Collision Analysis through Graph Data Attribution Techniques,"The experiments at the Large Hadron Collider at CERN generate vast amounts of
complex data from high-energy particle collisions. This data presents
significant challenges due to its volume and complex reconstruction,
necessitating the use of advanced analysis techniques for analysis. Recent
advancements in deep learning, particularly Graph Neural Networks, have shown
promising results in addressing the challenges but remain computationally
expensive. The study presented in this paper uses a simulated particle
collision dataset to integrate influence analysis inside the graph
classification pipeline aiming at improving the accuracy and efficiency of
collision event prediction tasks. By using a Graph Neural Network for initial
training, we applied a gradient-based data influence method to identify
influential training samples and then we refined the dataset by removing
non-contributory elements: the model trained on this new reduced dataset can
achieve good performances at a reduced computational cost. The method is
completely agnostic to the specific influence method: different influence
modalities can be easily integrated into our methodology. Moreover, by
analyzing the discarded elements we can provide further insights about the
event classification task. The novelty of integrating data attribution
techniques together with Graph Neural Networks in high-energy physics tasks can
offer a robust solution for managing large-scale data problems, capturing
critical patterns, and maximizing accuracy across several high-data demand
domains.",2024-07-20,"A. Verdone, A. Devoto, C. Sebastiani, J. Carmignani, M. D'Onofrio, S. Giagu, S. Scardapane, M. Panella",http://arxiv.org/pdf/2407.14859v1,cs.LG
Diff4VS: HIV-inhibiting Molecules Generation with Classifier Guidance Diffusion for Virtual Screening,"The AIDS epidemic has killed 40 million people and caused serious global
problems. The identification of new HIV-inhibiting molecules is of great
importance for combating the AIDS epidemic. Here, the Classifier Guidance
Diffusion model and ligand-based virtual screening strategy are combined to
discover potential HIV-inhibiting molecules for the first time. We call it
Diff4VS. An extra classifier is trained using the HIV molecule dataset, and the
gradient of the classifier is used to guide the Diffusion to generate
HIV-inhibiting molecules. Experiments show that Diff4VS can generate more
candidate HIV-inhibiting molecules than other methods. Inspired by ligand-based
virtual screening, a new metric DrugIndex is proposed. The DrugIndex is the
ratio of the proportion of candidate drug molecules in the generated molecule
to the proportion of candidate drug molecules in the training set. DrugIndex
provides a new evaluation method for evolving molecular generative models from
a pharmaceutical perspective. Besides, we report a new phenomenon observed when
using molecule generation models for virtual screening. Compared to real
molecules, the generated molecules have a lower proportion that is highly
similar to known drug molecules. We call it Degradation in molecule generation.
Based on the data analysis, the Degradation may result from the difficulty of
generating molecules with a specific structure in the generative model. Our
research contributes to the application of generative models in drug design
from method, metric, and phenomenon analysis.",2024-07-20,"Jiaqing Lyu, Changjie Chen, Bing Liang, Yijia Zhang",http://arxiv.org/pdf/2407.15880v1,cs.LG
Integrated BIM and Machine Learning System for Circularity Prediction of Construction Demolition Waste,"Effective management of construction and demolition waste (C&DW) is crucial
for sustainable development, as the industry accounts for 40% of the waste
generated globally. The effectiveness of the C&DW management relies on the
proper quantification of C&DW to be generated. Despite demolition activities
having larger contributions to C&DW generation, extant studies have focused on
construction waste. The few extant studies on demolition are often from the
regional level perspective and provide no circularity insights. Thus, this
study advances demolition quantification via Variable Modelling (VM) with
Machine Learning (ML). The demolition dataset of 2280 projects were leveraged
for the ML modelling, with XGBoost model emerging as the best (based on the
Copeland algorithm), achieving R2 of 0.9977 and a Mean Absolute Error of 5.0910
on the testing dataset. Through the integration of the ML model with Building
Information Modelling (BIM), the study developed a system for predicting
quantities of recyclable and landfill materials from building demolitions. This
provides detailed insights into the circularity of demolition waste and
facilitates better planning and management. The SHapley Additive exPlanations
(SHAP) method highlighted the implications of the features for demolition waste
circularity. The study contributes to empirical studies on pre-demolition
auditing at the project level and provides practical tools for implementation.
Its findings would benefit stakeholders in driving a circular economy in the
industry.",2024-07-20,"Abdullahi Saka, Ridwan Taiwo, Nurudeen Saka, Benjamin Oluleye, Jamiu Dauda, Lukman Akanbi",http://arxiv.org/pdf/2407.14847v1,cs.LG
Understanding the Relationship between Prompts and Response Uncertainty in Large Language Models,"Large language models (LLMs) are widely used in decision-making, but their
reliability, especially in critical tasks like healthcare, is not
well-established. Therefore, understanding how LLMs reason and make decisions
is crucial for their safe deployment. This paper investigates how the
uncertainty of responses generated by LLMs relates to the information provided
in the input prompt. Leveraging the insight that LLMs learn to infer latent
concepts during pretraining, we propose a prompt-response concept model that
explains how LLMs generate responses and helps understand the relationship
between prompts and response uncertainty. We show that the uncertainty
decreases as the prompt's informativeness increases, similar to epistemic
uncertainty. Our detailed experimental results on real-world datasets validate
our proposed model.",2024-07-20,"Ze Yu Zhang, Arun Verma, Finale Doshi-Velez, Bryan Kian Hsiang Low",http://arxiv.org/pdf/2407.14845v3,cs.LG
EEGMamba: Bidirectional State Space Model with Mixture of Experts for EEG Multi-task Classification,"In recent years, with the development of deep learning, electroencephalogram
(EEG) classification networks have achieved certain progress. Transformer-based
models can perform well in capturing long-term dependencies in EEG signals.
However, their quadratic computational complexity poses a substantial
computational challenge. Moreover, most EEG classification models are only
suitable for single tasks and struggle with generalization across different
tasks, particularly when faced with variations in signal length and channel
count. In this paper, we introduce EEGMamba, the first universal EEG
classification network to truly implement multi-task learning for EEG
applications. EEGMamba seamlessly integrates the Spatio-Temporal-Adaptive
(ST-Adaptive) module, bidirectional Mamba, and Mixture of Experts (MoE) into a
unified framework. The proposed ST-Adaptive module performs unified feature
extraction on EEG signals of different lengths and channel counts through
spatial-adaptive convolution and incorporates a class token to achieve
temporal-adaptability. Moreover, we design a bidirectional Mamba particularly
suitable for EEG signals for further feature extraction, balancing high
accuracy, fast inference speed, and efficient memory-usage in processing long
EEG signals. To enhance the processing of EEG data across multiple tasks, we
introduce task-aware MoE with a universal expert, effectively capturing both
differences and commonalities among EEG data from different tasks. We evaluate
our model on eight publicly available EEG datasets, and the experimental
results demonstrate its superior performance in four types of tasks: seizure
detection, emotion recognition, sleep stage classification, and motor imagery.
The code is set to be released soon.",2024-07-20,"Yiyu Gui, MingZhi Chen, Yuqi Su, Guibo Luo, Yuchao Yang",http://arxiv.org/pdf/2407.20254v2,cs.LG
Decentralized Federated Anomaly Detection in Smart Grids: A P2P Gossip Approach,"The increasing security and privacy concerns in the Smart Grid sector have
led to a significant demand for robust intrusion detection systems within
critical smart grid infrastructure. To address the challenges posed by privacy
preservation and decentralized power system zones with distinct data ownership,
Federated Learning (FL) has emerged as a promising privacy-preserving solution
which facilitates collaborative training of attack detection models without
necessitating the sharing of raw data. However, FL presents several
implementation limitations in the power system domain due to its heavy reliance
on a centralized aggregator and the risks of privacy leakage during model
update transmission. To overcome these technical bottlenecks, this paper
introduces a novel decentralized federated anomaly detection scheme based on
two main gossip protocols namely Random Walk and Epidemic. Our findings
indicate that the Random Walk protocol exhibits superior performance compared
to the Epidemic protocol, highlighting its efficacy in decentralized federated
learning environments. Experimental validation of the proposed framework
utilizing publicly available industrial control systems datasets demonstrates
superior attack detection accuracy while safeguarding data confidentiality and
mitigating the impact of communication latency and stragglers. Furthermore, our
approach yields a notable 35% improvement in training time compared to
conventional FL, underscoring the efficacy and robustness of our decentralized
learning method.",2024-07-20,"Muhammad Akbar Husnoo, Adnan Anwar, Md Enamul Haque, A. N. Mahmood",http://arxiv.org/pdf/2407.15879v2,cs.LG
Toward Efficient Convolutional Neural Networks With Structured Ternary Patterns,"High-efficiency deep learning (DL) models are necessary not only to
facilitate their use in devices with limited resources but also to improve
resources required for training. Convolutional neural networks (ConvNets)
typically exert severe demands on local device resources and this
conventionally limits their adoption within mobile and embedded platforms. This
brief presents work toward utilizing static convolutional filters generated
from the space of local binary patterns (LBPs) and Haar features to design
efficient ConvNet architectures. These are referred to as Structured Ternary
Patterns (STePs) and can be generated during network initialization in a
systematic way instead of having learnable weight parameters thus reducing the
total weight updates. The ternary values require significantly less storage and
with the appropriate low-level implementation, can also lead to inference
improvements. The proposed approach is validated using four image
classification datasets, demonstrating that common network backbones can be
made more efficient and provide competitive results. It is also demonstrated
that it is possible to generate completely custom STeP-based networks that
provide good trade-offs for on-device applications such as unmanned aerial
vehicle (UAV)-based aerial vehicle detection. The experimental results show
that the proposed method maintains high detection accuracy while reducing the
trainable parameters by 40-80%. This work motivates further research toward
good priors for non-learnable weights that can make DL architectures more
efficient without having to alter the network during or after training.",2024-07-20,Christos Kyrkou,http://arxiv.org/pdf/2407.14831v1,cs.LG
Scaling Up Single Image Dehazing Algorithm by Cross-Data Vision Alignment for Richer Representation Learning and Beyond,"In recent years, deep neural networks tasks have increasingly relied on
high-quality image inputs. With the development of high-resolution
representation learning, the task of image dehazing has received significant
attention. Previously, many methods collect diverse image data for large-scale
training to boost the performance on a target scene. Ignoring the domain gap
between different data, former de-hazing methods simply adopt multiple datasets
for explicit large-scale training, which often makes the methods themselves be
violated. To address this problem, we propose a novel method of cross-data
vision alignment for richer representation learning to improve the existing
dehazing methodology. Specifically, we call for the internal- and external
knowledge should be further adapted with a self-supervised manner to fill up
the domain gap. By using cross-data external alignment, the datasets inherit
samples from different domains that are firmly aligned, making the model learn
more robust and generalizable features. By using the internal augmentation
method, the model can fully exploit local information within the images, and
then obtaining more image details. To demonstrate the effectiveness of our
proposed method, we conduct training on the Natural Image Dataset (NID).
Experimental results show that our method clearly resolves the domain gap in
different dehazing datasets and presents a new pipeline for large-scale
training in the dehazing task. Our approach significantly outperforms other
advanced methods in dehazing and produces dehazed images that are closest to
real haze-free images.",2024-07-20,"Yukai Shi, Zhipeng Weng, Yupei Lin, Cidan Shi, Xiaojun Yang, Liang Lin",http://arxiv.org/pdf/2407.14823v2,cs.LG
FMamba: Mamba based on Fast-attention for Multivariate Time-series Forecasting,"In multivariate time-series forecasting (MTSF), extracting the temporal
correlations of the input sequences is crucial. While popular Transformer-based
predictive models can perform well, their quadratic computational complexity
results in inefficiency and high overhead. The recently emerged Mamba, a
selective state space model, has shown promising results in many fields due to
its strong temporal feature extraction capabilities and linear computational
complexity. However, due to the unilateral nature of Mamba, channel-independent
predictive models based on Mamba cannot attend to the relationships among all
variables in the manner of Transformer-based models. To address this issue, we
combine fast-attention with Mamba to introduce a novel framework named FMamba
for MTSF. Technically, we first extract the temporal features of the input
variables through an embedding layer, then compute the dependencies among input
variables via the fast-attention module. Subsequently, we use Mamba to
selectively deal with the input features and further extract the temporal
dependencies of the variables through the multi-layer perceptron block
(MLP-block). Finally, FMamba obtains the predictive results through the
projector, a linear layer. Experimental results on eight public datasets
demonstrate that FMamba can achieve state-of-the-art performance while
maintaining low computational overhead.",2024-07-20,"Shusen Ma, Yu Kang, Peng Bai, Yun-Bo Zhao",http://arxiv.org/pdf/2407.14814v1,cs.LG
On the Design and Analysis of LLM-Based Algorithms,"We initiate a formal investigation into the design and analysis of LLM-based
algorithms, i.e. algorithms that contain one or multiple calls of large
language models (LLMs) as sub-routines and critically rely on the capabilities
of LLMs. While LLM-based algorithms, ranging from basic LLM calls with prompt
engineering to complicated LLM-powered agent systems and compound AI systems,
have achieved remarkable empirical success, the design and optimization of them
have mostly relied on heuristics and trial-and-errors, which is largely due to
a lack of formal and analytical study for these algorithms. To fill this gap,
we start by identifying the computational-graph representation of LLM-based
algorithms, the design principle of task decomposition, and some key
abstractions, which then facilitate our formal analysis for the accuracy and
efficiency of LLM-based algorithms, despite the black-box nature of LLMs.
Through extensive analytical and empirical investigation in a series of case
studies, we demonstrate that the proposed framework is broadly applicable to a
wide range of scenarios and diverse patterns of LLM-based algorithms, such as
parallel, hierarchical and recursive task decomposition. Our proposed framework
holds promise for advancing LLM-based algorithms, by revealing the reasons
behind curious empirical phenomena, guiding the choices of hyperparameters,
predicting the empirical performance of algorithms, and inspiring new algorithm
design. To promote further study of LLM-based algorithms, we release our source
code at
https://github.com/modelscope/agentscope/tree/main/examples/paper_llm_based_algorithm.",2024-07-20,"Yanxi Chen, Yaliang Li, Bolin Ding, Jingren Zhou",http://arxiv.org/pdf/2407.14788v2,cs.LG
Improving EEG Classification Through Randomly Reassembling Original and Generated Data with Transformer-based Diffusion Models,"Electroencephalogram (EEG) classification has been widely used in various
medical and engineering applications, where it is important for understanding
brain function, diagnosing diseases, and assessing mental health conditions.
However, the scarcity of EEG data severely restricts the performance of EEG
classification networks, and generative model-based data augmentation methods
have emerged as potential solutions to overcome this challenge. There are two
problems with existing methods: (1) The quality of the generated EEG signals is
not high; (2) The enhancement of EEG classification networks is not effective.
In this paper, we propose a Transformer-based denoising diffusion probabilistic
model and a generated data-based augmentation method to address the above two
problems. For the characteristics of EEG signals, we propose a constant-factor
scaling method to preprocess the signals, which reduces the loss of
information. We incorporated Multi-Scale Convolution and Dynamic Fourier
Spectrum Information modules into the model, improving the stability of the
training process and the quality of the generated data. The proposed
augmentation method randomly reassemble the generated data with original data
in the time-domain to obtain vicinal data, which improves the model performance
by minimizing the empirical risk and the vicinal risk. We verify the proposed
augmentation method on four EEG datasets for four tasks and observe significant
accuracy performance improvements: 14.00% on the Bonn dataset; 6.38% on the
SleepEDF-20 dataset; 9.42% on the FACED dataset; 2.5% on the Shu dataset. We
will make the code of our method publicly accessible soon.",2024-07-20,"Mingzhi Chen, Yiyu Gui, Yuqi Su, Yuesheng Zhu, Guibo Luo, Yuchao Yang",http://arxiv.org/pdf/2407.20253v2,cs.LG
"Teach Harder, Learn Poorer: Rethinking Hard Sample Distillation for GNN-to-MLP Knowledge Distillation","To bridge the gaps between powerful Graph Neural Networks (GNNs) and
lightweight Multi-Layer Perceptron (MLPs), GNN-to-MLP Knowledge Distillation
(KD) proposes to distill knowledge from a well-trained teacher GNN into a
student MLP. In this paper, we revisit the knowledge samples (nodes) in teacher
GNNs from the perspective of hardness, and identify that hard sample
distillation may be a major performance bottleneck of existing graph KD
algorithms. The GNN-to-MLP KD involves two different types of hardness, one
student-free knowledge hardness describing the inherent complexity of GNN
knowledge, and the other student-dependent distillation hardness describing the
difficulty of teacher-to-student distillation. However, most of the existing
work focuses on only one of these aspects or regards them as one thing. This
paper proposes a simple yet effective Hardness-aware GNN-to-MLP Distillation
(HGMD) framework, which decouples the two hardnesses and estimates them using a
non-parametric approach. Finally, two hardness-aware distillation schemes
(i.e., HGMD-weight and HGMD-mixup) are further proposed to distill
hardness-aware knowledge from teacher GNNs into the corresponding nodes of
student MLPs. As non-parametric distillation, HGMD does not involve any
additional learnable parameters beyond the student MLPs, but it still
outperforms most of the state-of-the-art competitors. HGMD-mixup improves over
the vanilla MLPs by 12.95% and outperforms its teacher GNNs by 2.48% averaged
over seven real-world datasets.",2024-07-20,"Lirong Wu, Yunfan Liu, Haitao Lin, Yufei Huang, Stan Z. Li",http://arxiv.org/pdf/2407.14768v1,cs.LG
Implementing Fairness in AI Classification: The Role of Explainability,"In this paper, we propose a philosophical and experimental investigation of
the problem of AI fairness in classification. We argue that implementing
fairness in AI classification involves more work than just operationalizing a
fairness metric. It requires establishing the explainability of the
classification model chosen and of the principles behind it. Specifically, it
involves making the training processes transparent, determining what outcomes
the fairness criteria actually produce, and assessing their trade-offs by
comparison with closely related models that would lead to a different outcome.
To exemplify this methodology, we trained a model and developed a tool for
disparity detection and fairness interventions, the package FairDream. While
FairDream is set to enforce Demographic Parity, experiments reveal that it
fulfills the constraint of Equalized Odds. The algorithm is thus more
conservative than the user might expect. To justify this outcome, we first
clarify the relation between Demographic Parity and Equalized Odds as fairness
criteria. We then explain FairDream's reweighting method and justify the
trade-offs reached by FairDream by a benchmark comparison with closely related
GridSearch models. We draw conclusions regarding the way in which these
explanatory steps can make an AI model trustworthy.",2024-07-20,"Thomas Souverain, Johnathan Nguyen, Nicolas Meric, Paul Égré",http://arxiv.org/pdf/2407.14766v2,cs.LG
Data Augmentation in Graph Neural Networks: The Role of Generated Synthetic Graphs,"Graphs are crucial for representing interrelated data and aiding predictive
modeling by capturing complex relationships. Achieving high-quality graph
representation is important for identifying linked patterns, leading to
improvements in Graph Neural Networks (GNNs) to better capture data structures.
However, challenges such as data scarcity, high collection costs, and ethical
concerns limit progress. As a result, generative models and data augmentation
have become more and more popular. This study explores using generated graphs
for data augmentation, comparing the performance of combining generated graphs
with real graphs, and examining the effect of different quantities of generated
graphs on graph classification tasks. The experiments show that balancing
scalability and quality requires different generators based on graph size. Our
results introduce a new approach to graph data augmentation, ensuring
consistent labels and enhancing classification performance.",2024-07-20,"Sumeyye Bas, Kiymet Kaya, Resul Tugay, Sule Gunduz Oguducu",http://arxiv.org/pdf/2407.14765v1,cs.LG
Flatness-aware Sequential Learning Generates Resilient Backdoors,"Recently, backdoor attacks have become an emerging threat to the security of
machine learning models. From the adversary's perspective, the implanted
backdoors should be resistant to defensive algorithms, but some recently
proposed fine-tuning defenses can remove these backdoors with notable efficacy.
This is mainly due to the catastrophic forgetting (CF) property of deep neural
networks. This paper counters CF of backdoors by leveraging continual learning
(CL) techniques. We begin by investigating the connectivity between a
backdoored and fine-tuned model in the loss landscape. Our analysis confirms
that fine-tuning defenses, especially the more advanced ones, can easily push a
poisoned model out of the backdoor regions, making it forget all about the
backdoors. Based on this finding, we re-formulate backdoor training through the
lens of CL and propose a novel framework, named Sequential Backdoor Learning
(SBL), that can generate resilient backdoors. This framework separates the
backdoor poisoning process into two tasks: the first task learns a backdoored
model, while the second task, based on the CL principles, moves it to a
backdoored region resistant to fine-tuning. We additionally propose to seek
flatter backdoor regions via a sharpness-aware minimizer in the framework,
further strengthening the durability of the implanted backdoor. Finally, we
demonstrate the effectiveness of our method through extensive empirical
experiments on several benchmark datasets in the backdoor domain. The source
code is available at https://github.com/mail-research/SBL-resilient-backdoors",2024-07-20,"Hoang Pham, The-Anh Ta, Anh Tran, Khoa D. Doan",http://arxiv.org/pdf/2407.14738v1,cs.LG
Early Detection of Coffee Leaf Rust Through Convolutional Neural Networks Trained on Low-Resolution Images,"Coffee leaf rust, a foliar disease caused by the fungus Hemileia vastatrix,
poses a major threat to coffee production, especially in Central America.
Climate change further aggravates this issue, as it shortens the latency period
between initial infection and the emergence of visible symptoms in diseases
like leaf rust. Shortened latency periods can lead to more severe plant
epidemics and faster spread of diseases. There is, hence, an urgent need for
effective disease management strategies. To address these challenges, we
explore the potential of deep learning models for enhancing early disease
detection. However, deep learning models require extensive processing power and
large amounts of data for model training, resources that are typically scarce.
To overcome these barriers, we propose a preprocessing technique that involves
convolving training images with a high-pass filter to enhance lesion-leaf
contrast, significantly improving model efficacy in resource-limited
environments. This method and our model demonstrated a strong performance,
achieving over 90% across all evaluation metrics--including precision, recall,
F1-score, and the Dice coefficient. Our experiments show that this approach
outperforms other methods, including two different image preprocessing
techniques and using unaltered, full-color images.",2024-07-20,"Angelly Cabrera, Kleanthis Avramidis, Shrikanth Narayanan",http://arxiv.org/pdf/2407.14737v1,cs.LG
ECRTime: Ensemble Integration of Classification and Retrieval for Time Series Classification,"Deep learning-based methods for Time Series Classification (TSC) typically
utilize deep networks to extract features, which are then processed through a
combination of a Fully Connected (FC) layer and a SoftMax function. However, we
have observed the phenomenon of inter-class similarity and intra-class
inconsistency in the datasets from the UCR archive and further analyzed how
this phenomenon adversely affects the ""FC+SoftMax"" paradigm. To address the
issue, we introduce ECR, which, for the first time to our knowledge, applies
deep learning-based retrieval algorithm to the TSC problem and integrates
classification and retrieval models. Experimental results on 112 UCR datasets
demonstrate that ECR is state-of-the-art(sota) compared to existing deep
learning-based methods. Furthermore, we have developed a more precise
classifier, ECRTime, which is an ensemble of ECR. ECRTime surpasses the
currently most accurate deep learning classifier, InceptionTime, in terms of
accuracy, achieving this with reduced training time and comparable scalability.",2024-07-20,"Fan Zhao, You Chen",http://arxiv.org/pdf/2407.14735v1,cs.LG
Hard Prompts Made Interpretable: Sparse Entropy Regularization for Prompt Tuning with RL,"With the advent of foundation models, prompt tuning has positioned itself as
an important technique for directing model behaviors and eliciting desired
responses. Prompt tuning regards selecting appropriate keywords included into
the input, thereby adapting to the downstream task without adjusting or
fine-tuning the model parameters. There is a wide range of work in prompt
tuning, from approaches that directly harness the backpropagated gradient
signals from the model, to those employing black-box optimization such as
reinforcement learning (RL) methods. Our primary focus is on RLPrompt, which
aims to find optimal prompt tokens leveraging soft Q-learning. While the
results show promise, we have observed that the prompts frequently appear
unnatural, which impedes their interpretability. We address this limitation by
using sparse Tsallis entropy regularization, a principled approach to filtering
out unlikely tokens from consideration. We extensively evaluate our approach
across various tasks, including few-shot text classification, unsupervised text
style transfer, and textual inversion from images. The results indicate a
notable improvement over baselines, highlighting the efficacy of our approach
in addressing the challenges of prompt tuning. Moreover, we show that the
prompts discovered using our method are more natural and interpretable compared
to those from other baselines.",2024-07-20,"Yunseon Choi, Sangmin Bae, Seonghyun Ban, Minchan Jeong, Chuheng Zhang, Lei Song, Li Zhao, Jiang Bian, Kee-Eung Kim",http://arxiv.org/pdf/2407.14733v1,cs.LG
Meta-GPS++: Enhancing Graph Meta-Learning with Contrastive Learning and Self-Training,"Node classification is an essential problem in graph learning. However, many
models typically obtain unsatisfactory performance when applied to few-shot
scenarios. Some studies have attempted to combine meta-learning with graph
neural networks to solve few-shot node classification on graphs. Despite their
promising performance, some limitations remain. First, they employ the node
encoding mechanism of homophilic graphs to learn node embeddings, even in
heterophilic graphs. Second, existing models based on meta-learning ignore the
interference of randomness in the learning process. Third, they are trained
using only limited labeled nodes within the specific task, without explicitly
utilizing numerous unlabeled nodes. Finally, they treat almost all sampled
tasks equally without customizing them for their uniqueness. To address these
issues, we propose a novel framework for few-shot node classification called
Meta-GPS++. Specifically, we first adopt an efficient method to learn
discriminative node representations on homophilic and heterophilic graphs.
Then, we leverage a prototype-based approach to initialize parameters and
contrastive learning for regularizing the distribution of node embeddings.
Moreover, we apply self-training to extract valuable information from unlabeled
nodes. Additionally, we adopt S$^2$ (scaling & shifting) transformation to
learn transferable knowledge from diverse tasks. The results on real-world
datasets show the superiority of Meta-GPS++. Our code is available here.",2024-07-20,"Yonghao Liu, Mengyu Li, Ximing Li, Lan Huang, Fausto Giunchiglia, Yanchun Liang, Xiaoyue Feng, Renchu Guan",http://arxiv.org/pdf/2407.14732v1,cs.LG
FedDM: Enhancing Communication Efficiency and Handling Data Heterogeneity in Federated Diffusion Models,"We introduce FedDM, a novel training framework designed for the federated
training of diffusion models. Our theoretical analysis establishes the
convergence of diffusion models when trained in a federated setting, presenting
the specific conditions under which this convergence is guaranteed. We propose
a suite of training algorithms that leverage the U-Net architecture as the
backbone for our diffusion models. These include a basic Federated Averaging
variant, FedDM-vanilla, FedDM-prox to handle data heterogeneity among clients,
and FedDM-quant, which incorporates a quantization module to reduce the model
update size, thereby enhancing communication efficiency across the federated
network.
  We evaluate our algorithms on FashionMNIST (28x28 resolution), CIFAR-10
(32x32 resolution), and CelebA (64x64 resolution) for DDPMs, as well as LSUN
Church Outdoors (256x256 resolution) for LDMs, focusing exclusively on the
imaging modality. Our evaluation results demonstrate that FedDM algorithms
maintain high generation quality across image resolutions. At the same time,
the use of quantized updates and proximal terms in the local training objective
significantly enhances communication efficiency (up to 4x) and model
convergence, particularly in non-IID data settings, at the cost of increased
FID scores (up to 1.75x).",2024-07-20,"Jayneel Vora, Nader Bouacida, Aditya Krishnan, Prasant Mohapatra",http://arxiv.org/pdf/2407.14730v1,cs.LG
MetaAug: Meta-Data Augmentation for Post-Training Quantization,"Post-Training Quantization (PTQ) has received significant attention because
it requires only a small set of calibration data to quantize a full-precision
model, which is more practical in real-world applications in which full access
to a large training set is not available. However, it often leads to
overfitting on the small calibration dataset. Several methods have been
proposed to address this issue, yet they still rely on only the calibration set
for the quantization and they do not validate the quantized model due to the
lack of a validation set. In this work, we propose a novel meta-learning based
approach to enhance the performance of post-training quantization.
Specifically, to mitigate the overfitting problem, instead of only training the
quantized model using the original calibration set without any validation
during the learning process as in previous PTQ works, in our approach, we both
train and validate the quantized model using two different sets of images. In
particular, we propose a meta-learning based approach to jointly optimize a
transformation network and a quantized model through bi-level optimization. The
transformation network modifies the original calibration data and the modified
data will be used as the training set to learn the quantized model with the
objective that the quantized model achieves a good performance on the original
calibration data. Extensive experiments on the widely used ImageNet dataset
with different neural network architectures demonstrate that our approach
outperforms the state-of-the-art PTQ methods.",2024-07-20,"Cuong Pham, Hoang Anh Dung, Cuong C. Nguyen, Trung Le, Dinh Phung, Gustavo Carneiro, Thanh-Toan Do",http://arxiv.org/pdf/2407.14726v2,cs.LG
"Enhancing Wildfire Forecasting Through Multisource Spatio-Temporal Data, Deep Learning, Ensemble Models and Transfer Learning","This paper presents a novel approach in wildfire prediction through the
integration of multisource spatiotemporal data, including satellite data, and
the application of deep learning techniques. Specifically, we utilize an
ensemble model built on transfer learning algorithms to forecast wildfires. The
key focus is on understanding the significance of weather sequences, human
activities, and specific weather parameters in wildfire prediction. The study
encounters challenges in acquiring real-time data for training the network,
especially in Moroccan wildlands. The future work intends to develop a global
model capable of processing multichannel, multidimensional, and unformatted
data sources to enhance our understanding of the future entropy of surface
tiles.",2024-07-20,"Ayoub Jadouli, Chaker El Amrani",http://arxiv.org/pdf/2407.15878v1,cs.LG
Downstream-Pretext Domain Knowledge Traceback for Active Learning,"Active learning (AL) is designed to construct a high-quality labeled dataset
by iteratively selecting the most informative samples. Such sampling heavily
relies on data representation, while recently pre-training is popular for
robust feature learning. However, as pre-training utilizes low-level pretext
tasks that lack annotation, directly using pre-trained representation in AL is
inadequate for determining the sampling score. To address this problem, we
propose a downstream-pretext domain knowledge traceback (DOKT) method that
traces the data interactions of downstream knowledge and pre-training guidance
for selecting diverse and instructive samples near the decision boundary. DOKT
consists of a traceback diversity indicator and a domain-based uncertainty
estimator. The diversity indicator constructs two feature spaces based on the
pre-training pretext model and the downstream knowledge from annotation, by
which it locates the neighbors of unlabeled data from the downstream space in
the pretext space to explore the interaction of samples. With this mechanism,
DOKT unifies the data relations of low-level and high-level representations to
estimate traceback diversity. Next, in the uncertainty estimator, domain mixing
is designed to enforce perceptual perturbing to unlabeled samples with similar
visual patches in the pretext space. Then the divergence of perturbed samples
is measured to estimate the domain uncertainty. As a result, DOKT selects the
most diverse and important samples based on these two modules. The experiments
conducted on ten datasets show that our model outperforms other
state-of-the-art methods and generalizes well to various application scenarios
such as semantic segmentation and image captioning.",2024-07-20,"Beichen Zhang, Liang Li, Zheng-Jun Zha, Jiebo Luo, Qingming Huang",http://arxiv.org/pdf/2407.14720v1,cs.LG
Differential Privacy of Cross-Attention with Provable Guarantee,"Cross-attention has become a fundamental module nowadays in many important
artificial intelligence applications, e.g., retrieval-augmented generation
(RAG), system prompt, guided stable diffusion, and many more. Ensuring
cross-attention privacy is crucial and urgently needed because its key and
value matrices may contain sensitive information about model providers and
their users. In this work, we design a novel differential privacy (DP) data
structure to address the privacy security of cross-attention with a theoretical
guarantee. In detail, let $n$ be the input token length of system prompt/RAG
data, $d$ be the feature dimension, $0 < \alpha \le 1$ be the relative error
parameter, $R$ be the maximum value of the query and key matrices, $R_w$ be the
maximum value of the value matrix, and $r,s,\epsilon_s$ be parameters of
polynomial kernel methods. Then, our data structure requires
$\widetilde{O}(ndr^2)$ memory consumption with $\widetilde{O}(nr^2)$
initialization time complexity and $\widetilde{O}(\alpha^{-1} r^2)$ query time
complexity for a single token query. In addition, our data structure can
guarantee that the process of answering user query satisfies $(\epsilon,
\delta)$-DP with $\widetilde{O}(n^{-1} \epsilon^{-1} \alpha^{-1/2} R^{2s} R_w
r^2)$ additive error and $n^{-1} (\alpha + \epsilon_s)$ relative error between
our output and the true answer. Furthermore, our result is robust to adaptive
queries in which users can intentionally attack the cross-attention system. To
our knowledge, this is the first work to provide DP for cross-attention and is
promising to inspire more privacy algorithm design in large generative models
(LGMs).",2024-07-20,"Yingyu Liang, Zhenmei Shi, Zhao Song, Yufa Zhou",http://arxiv.org/pdf/2407.14717v2,cs.LG
Unveiling the Decision-Making Process in Reinforcement Learning with Genetic Programming,"Despite tremendous progress, machine learning and deep learning still suffer
from incomprehensible predictions. Incomprehensibility, however, is not an
option for the use of (deep) reinforcement learning in the real world, as
unpredictable actions can seriously harm the involved individuals. In this
work, we propose a genetic programming framework to generate explanations for
the decision-making process of already trained agents by imitating them with
programs. Programs are interpretable and can be executed to generate
explanations of why the agent chooses a particular action. Furthermore, we
conduct an ablation study that investigates how extending the domain-specific
language by using library learning alters the performance of the method. We
compare our results with the previous state of the art for this problem and
show that we are comparable in performance but require much less hardware
resources and computation time.",2024-07-20,"Manuel Eberhardinger, Florian Rupp, Johannes Maucher, Setareh Maghsudi",http://arxiv.org/pdf/2407.14714v1,cs.LG
Universally Harmonizing Differential Privacy Mechanisms for Federated Learning: Boosting Accuracy and Convergence,"Differentially private federated learning (DP-FL) is a promising technique
for collaborative model training while ensuring provable privacy for clients.
However, optimizing the tradeoff between privacy and accuracy remains a
critical challenge. To our best knowledge, we propose the first DP-FL framework
(namely UDP-FL), which universally harmonizes any randomization mechanism
(e.g., an optimal one) with the Gaussian Moments Accountant (viz. DP-SGD) to
significantly boost accuracy and convergence. Specifically, UDP-FL demonstrates
enhanced model performance by mitigating the reliance on Gaussian noise. The
key mediator variable in this transformation is the R\'enyi Differential
Privacy notion, which is carefully used to harmonize privacy budgets. We also
propose an innovative method to theoretically analyze the convergence for DP-FL
(including our UDP-FL ) based on mode connectivity analysis. Moreover, we
evaluate our UDP-FL through extensive experiments benchmarked against
state-of-the-art (SOTA) methods, demonstrating superior performance on both
privacy guarantees and model performance. Notably, UDP-FL exhibits substantial
resilience against different inference attacks, indicating a significant
advance in safeguarding sensitive data in federated learning environments.",2024-07-20,"Shuya Feng, Meisam Mohammady, Hanbin Hong, Shenao Yan, Ashish Kundu, Binghui Wang, Yuan Hong",http://arxiv.org/pdf/2407.14710v2,cs.LG
Composer's Assistant 2: Interactive Multi-Track MIDI Infilling with Fine-Grained User Control,"We introduce Composer's Assistant 2, a system for interactive human-computer
composition in the REAPER digital audio workstation. Our work upgrades the
Composer's Assistant system (which performs multi-track infilling of symbolic
music at the track-measure level) with a wide range of new controls to give
users fine-grained control over the system's outputs. Controls introduced in
this work include two types of rhythmic conditioning controls, horizontal and
vertical note onset density controls, several types of pitch controls, and a
rhythmic interest control. We train a T5-like transformer model to implement
these controls and to serve as the backbone of our system. With these controls,
we achieve a dramatic improvement in objective metrics over the original
system. We also study how well our model understands the meaning of our
controls, and we conduct a listening study that does not find a significant
difference between real music and music composed in a co-creative fashion with
our system. We release our complete system, consisting of source code,
pretrained models, and REAPER scripts.",2024-07-19,Martin E. Malandro,http://arxiv.org/pdf/2407.14700v1,cs.LG
"A Comprehensive Guide to Combining R and Python code for Data Science, Machine Learning and Reinforcement Learning","Python has gained widespread popularity in the fields of machine learning,
artificial intelligence, and data engineering due to its effectiveness and
extensive libraries. R, on its side, remains a dominant language for
statistical analysis and visualization. However, certain libraries have become
outdated, limiting their functionality and performance. Users can use Python's
advanced machine learning and AI capabilities alongside R's robust statistical
packages by combining these two programming languages. This paper explores
using R's reticulate package to call Python from R, providing practical
examples and highlighting scenarios where this integration enhances
productivity and analytical capabilities. With a few hello-world code snippets,
we demonstrate how to run Python's scikit-learn, pytorch and OpenAI gym
libraries for building Machine Learning, Deep Learning, and Reinforcement
Learning projects easily.",2024-07-19,"Alejandro L. García Navarro, Nataliia Koneva, Alfonso Sánchez-Macián, José Alberto Hernández",http://arxiv.org/pdf/2407.14695v1,cs.LG
LaMAGIC: Language-Model-based Topology Generation for Analog Integrated Circuits,"In the realm of electronic and electrical engineering, automation of analog
circuit is increasingly vital given the complexity and customized requirements
of modern applications. However, existing methods only develop search-based
algorithms that require many simulation iterations to design a custom circuit
topology, which is usually a time-consuming process. To this end, we introduce
LaMAGIC, a pioneering language model-based topology generation model that
leverages supervised finetuning for automated analog circuit design. LaMAGIC
can efficiently generate an optimized circuit design from the custom
specification in a single pass. Our approach involves a meticulous development
and analysis of various input and output formulations for circuit. These
formulations can ensure canonical representations of circuits and align with
the autoregressive nature of LMs to effectively addressing the challenges of
representing analog circuits as graphs. The experimental results show that
LaMAGIC achieves a success rate of up to 96\% under a strict tolerance of 0.01.
We also examine the scalability and adaptability of LaMAGIC, specifically
testing its performance on more complex circuits. Our findings reveal the
enhanced effectiveness of our adjacency matrix-based circuit formulation with
floating-point input, suggesting its suitability for handling intricate circuit
designs. This research not only demonstrates the potential of language models
in graph generation, but also builds a foundational framework for future
explorations in automated analog circuit design.",2024-07-19,"Chen-Chia Chang, Yikang Shen, Shaoze Fan, Jing Li, Shun Zhang, Ningyuan Cao, Yiran Chen, Xin Zhang",http://arxiv.org/pdf/2407.18269v2,cs.LG
An Uncertainty-aware Deep Learning Framework-based Robust Design Optimization of Metamaterial Units,"Mechanical metamaterials represent an innovative class of artificial
structures, distinguished by their extraordinary mechanical characteristics,
which are beyond the scope of traditional natural materials. The use of deep
generative models has become increasingly popular in the design of metamaterial
units. The effectiveness of using deep generative models lies in their capacity
to compress complex input data into a simplified, lower-dimensional latent
space, while also enabling the creation of novel optimal designs through
sampling within this space. However, the design process does not take into
account the effect of model uncertainty due to data sparsity or the effect of
input data uncertainty due to inherent randomness in the data. This might lead
to the generation of undesirable structures with high sensitivity to the
uncertainties in the system. To address this issue, a novel uncertainty-aware
deep learning framework-based robust design approach is proposed for the design
of metamaterial units with optimal target properties. The proposed approach
utilizes the probabilistic nature of the deep learning framework and quantifies
both aleatoric and epistemic uncertainties associated with surrogate-based
design optimization. We demonstrate that the proposed design approach is
capable of designing high-performance metamaterial units with high reliability.
To showcase the effectiveness of the proposed design approach, a
single-objective design optimization problem and a multi-objective design
optimization problem are presented. The optimal robust designs obtained are
validated by comparing them to the designs obtained from the topology
optimization method as well as the designs obtained from a deterministic deep
learning framework-based design optimization where none of the uncertainties in
the system are explicitly considered.",2024-07-19,"Zihan Wang, Anindya Bhaduri, Hongyi Xu, Liping Wang",http://arxiv.org/pdf/2407.20251v1,cs.LG
Data Poisoning: An Overlooked Threat to Power Grid Resilience,"As the complexities of Dynamic Data Driven Applications Systems increase,
preserving their resilience becomes more challenging. For instance, maintaining
power grid resilience is becoming increasingly complicated due to the growing
number of stochastic variables (such as renewable outputs) and extreme weather
events that add uncertainty to the grid. Current optimization methods have
struggled to accommodate this rise in complexity. This has fueled the growing
interest in data-driven methods used to operate the grid, leading to more
vulnerability to cyberattacks. One such disruption that is commonly discussed
is the adversarial disruption, where the intruder attempts to add a small
perturbation to input data in order to ""manipulate"" the system operation.
During the last few years, work on adversarial training and disruptions on the
power system has gained popularity. In this paper, we will first review these
applications, specifically on the most common types of adversarial disruptions:
evasion and poisoning disruptions. Through this review, we highlight the gap
between poisoning and evasion research when applied to the power grid. This is
due to the underlying assumption that model training is secure, leading to
evasion disruptions being the primary type of studied disruption. Finally, we
will examine the impacts of data poisoning interventions and showcase how they
can endanger power grid resilience.",2024-07-19,"Nora Agah, Javad Mohammadi, Alex Aved, David Ferris, Erika Ardiles Cruz, Philip Morrone",http://arxiv.org/pdf/2407.14684v1,cs.LG
Value Internalization: Learning and Generalizing from Social Reward,"Social rewards shape human behavior. During development, a caregiver guides a
learner's behavior towards culturally aligned goals and values. How do these
behaviors persist and generalize when the caregiver is no longer present, and
the learner must continue autonomously? Here, we propose a model of value
internalization where social feedback trains an internal social reward (ISR)
model that generates internal rewards when social rewards are unavailable.
Through empirical simulations, we show that an ISR model prevents agents from
unlearning socialized behaviors and enables generalization in
out-of-distribution tasks. We characterize the implications of incomplete
internalization, akin to ""reward hacking"" on the ISR. Additionally, we show
that our model internalizes prosocial behavior in a multi-agent environment.
Our work provides a foundation for understanding how humans acquire and
generalize values and offers insights for aligning AI with human values.",2024-07-19,"Frieda Rong, Max Kleiman-Weiner",http://arxiv.org/pdf/2407.14681v1,cs.LG
Compact Language Models via Pruning and Knowledge Distillation,"Large language models (LLMs) targeting different deployment scales and sizes
are currently produced by training each variant from scratch; this is extremely
compute-intensive. In this paper, we investigate if pruning an existing LLM and
then re-training it with a fraction (<3%) of the original training data can be
a suitable alternative to repeated, full retraining. To this end, we develop a
set of practical and effective compression best practices for LLMs that combine
depth, width, attention and MLP pruning with knowledge distillation-based
retraining; we arrive at these best practices through a detailed empirical
exploration of pruning strategies for each axis, methods to combine axes,
distillation strategies, and search techniques for arriving at optimal
compressed architectures. We use this guide to compress the Nemotron-4 family
of LLMs by a factor of 2-4x, and compare their performance to similarly-sized
models on a variety of language modeling tasks. Deriving 8B and 4B models from
an already pretrained 15B model using our approach requires up to 40x fewer
training tokens per model compared to training from scratch; this results in
compute cost savings of 1.8x for training the full model family (15B, 8B, and
4B). Minitron models exhibit up to a 16% improvement in MMLU scores compared to
training from scratch, perform comparably to other community models such as
Mistral 7B, Gemma 7B and Llama-3 8B, and outperform state-of-the-art
compression techniques from the literature. We have open-sourced Minitron model
weights on Huggingface, with corresponding supplementary material including
example code available on GitHub.",2024-07-19,"Saurav Muralidharan, Sharath Turuvekere Sreenivas, Raviraj Joshi, Marcin Chochowski, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro, Jan Kautz, Pavlo Molchanov",http://arxiv.org/pdf/2407.14679v2,cs.LG
"Towards a ""universal translator"" for neural dynamics at single-cell, single-spike resolution","Neuroscience research has made immense progress over the last decade, but our
understanding of the brain remains fragmented and piecemeal: the dream of
probing an arbitrary brain region and automatically reading out the information
encoded in its neural activity remains out of reach. In this work, we build
towards a first foundation model for neural spiking data that can solve a
diverse set of tasks across multiple brain areas. We introduce a novel
self-supervised modeling approach for population activity in which the model
alternates between masking out and reconstructing neural activity across
different time steps, neurons, and brain regions. To evaluate our approach, we
design unsupervised and supervised prediction tasks using the International
Brain Laboratory repeated site dataset, which is comprised of Neuropixels
recordings targeting the same brain locations across 48 animals and
experimental sessions. The prediction tasks include single-neuron and
region-level activity prediction, forward prediction, and behavior decoding. We
demonstrate that our multi-task-masking (MtM) approach significantly improves
the performance of current state-of-the-art population models and enables
multi-task learning. We also show that by training on multiple animals, we can
improve the generalization ability of the model to unseen animals, paving the
way for a foundation model of the brain at single-cell, single-spike
resolution.",2024-07-19,"Yizi Zhang, Yanchen Wang, Donato Jimenez-Beneto, Zixuan Wang, Mehdi Azabou, Blake Richards, Olivier Winter, International Brain Laboratory, Eva Dyer, Liam Paninski, Cole Hurwitz",http://arxiv.org/pdf/2407.14668v2,cs.LG
"Is $F_1$ Score Suboptimal for Cybersecurity Models? Introducing $C_{score}$, a Cost-Aware Alternative for Model Assessment","The cost of errors related to machine learning classifiers, namely, false
positives and false negatives, are not equal and are application dependent. For
example, in cybersecurity applications, the cost of not detecting an attack is
very different from marking a benign activity as an attack. Various design
choices during machine learning model building, such as hyperparameter tuning
and model selection, allow a data scientist to trade-off between these two
errors. However, most of the commonly used metrics to evaluate model quality,
such as $F_1$ score, which is defined in terms of model precision and recall,
treat both these errors equally, making it difficult for users to optimize for
the actual cost of these errors. In this paper, we propose a new cost-aware
metric, $C_{score}$ based on precision and recall that can replace $F_1$ score
for model evaluation and selection. It includes a cost ratio that takes into
account the differing costs of handling false positives and false negatives. We
derive and characterize the new cost metric, and compare it to $F_1$ score.
Further, we use this metric for model thresholding for five cybersecurity
related datasets for multiple cost ratios. The results show an average cost
savings of 49%.",2024-07-19,"Manish Marwah, Asad Narayanan, Stephan Jou, Martin Arlitt, Maria Pospelova",http://arxiv.org/pdf/2407.14664v2,cs.LG
Relational Composition in Neural Networks: A Survey and Call to Action,"Many neural nets appear to represent data as linear combinations of ""feature
vectors."" Algorithms for discovering these vectors have seen impressive recent
success. However, we argue that this success is incomplete without an
understanding of relational composition: how (or whether) neural nets combine
feature vectors to represent more complicated relationships. To facilitate
research in this area, this paper offers a guided tour of various relational
mechanisms that have been proposed, along with preliminary analysis of how such
mechanisms might affect the search for interpretable features. We end with a
series of promising areas for empirical research, which may help determine how
neural networks represent structured data.",2024-07-19,"Martin Wattenberg, Fernanda B. Viégas",http://arxiv.org/pdf/2407.14662v1,cs.LG
OASIS: Conditional Distribution Shaping for Offline Safe Reinforcement Learning,"Offline safe reinforcement learning (RL) aims to train a policy that
satisfies constraints using a pre-collected dataset. Most current methods
struggle with the mismatch between imperfect demonstrations and the desired
safe and rewarding performance. In this paper, we introduce OASIS (cOnditionAl
diStributIon Shaping), a new paradigm in offline safe RL designed to overcome
these critical limitations. OASIS utilizes a conditional diffusion model to
synthesize offline datasets, thus shaping the data distribution toward a
beneficial target domain. Our approach makes compliance with safety constraints
through effective data utilization and regularization techniques to benefit
offline safe RL training. Comprehensive evaluations on public benchmarks and
varying datasets showcase OASIS's superiority in benefiting offline safe RL
agents to achieve high-reward behavior while satisfying the safety constraints,
outperforming established baselines. Furthermore, OASIS exhibits high data
efficiency and robustness, making it suitable for real-world applications,
particularly in tasks where safety is imperative and high-quality
demonstrations are scarce.",2024-07-19,"Yihang Yao, Zhepeng Cen, Wenhao Ding, Haohong Lin, Shiqi Liu, Tingnan Zhang, Wenhao Yu, Ding Zhao",http://arxiv.org/pdf/2407.14653v1,cs.LG
Performance Modeling and Workload Analysis of Distributed Large Language Model Training and Inference,"Aligning future system design with the ever-increasing compute needs of large
language models (LLMs) is undoubtedly an important problem in today's world.
Here, we propose a general performance modeling methodology and workload
analysis of distributed LLM training and inference through an analytical
framework that accurately considers compute, memory sub-system, network, and
various parallelization strategies (model parallel, data parallel, pipeline
parallel, and sequence parallel). We validate our performance predictions with
published data from literature and relevant industry vendors (e.g., NVIDIA).
For distributed training, we investigate the memory footprint of LLMs for
different activation re-computation methods, dissect the key factors behind the
massive performance gain from A100 to B200 ($\sim$ 35x speed-up closely
following NVIDIA's scaling trend), and further run a design space exploration
at different technology nodes (12 nm to 1 nm) to study the impact of logic,
memory, and network scaling on the performance. For inference, we analyze the
compute versus memory boundedness of different operations at a matrix-multiply
level for different GPU systems and further explore the impact of DRAM memory
technology scaling on inference latency. Utilizing our modeling framework, we
reveal the evolution of performance bottlenecks for both LLM training and
inference with technology scaling, thus, providing insights to design future
systems for LLM training and inference.",2024-07-19,"Joyjit Kundu, Wenzhe Guo, Ali BanaGozar, Udari De Alwis, Sourav Sengupta, Puneet Gupta, Arindam Mallik",http://arxiv.org/pdf/2407.14645v1,cs.LG
Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis,"Breast cancer is not preventable because of its unknown causes. However, its
early diagnosis increases patients' recovery chances. Machine learning (ML) can
be utilized to improve treatment outcomes in healthcare operations while
diminishing costs and time. In this research, we suggest two novel feature
selection (FS) methods based upon an imperialist competitive algorithm (ICA)
and a bat algorithm (BA) and their combination with ML algorithms. This study
aims to enhance diagnostic models' efficiency and present a comprehensive
analysis to help clinical physicians make much more precise and reliable
decisions than before. K-nearest neighbors, support vector machine, decision
tree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest,
logistic regression, and artificial neural network are some of the methods
employed. This paper applied a distinctive integration of evaluation measures
and ML algorithms using the wrapper feature selection based on ICA (WFSIC) and
BA (WFSB) separately. We compared two proposed approaches for the performance
of the classifiers. Also, we compared our best diagnostic model with previous
works reported in the literature survey. Experimentations were performed on the
Wisconsin diagnostic breast cancer dataset. Results reveal that the proposed
framework that uses the BA with an accuracy of 99.12\%, surpasses the framework
using the ICA and most previous works. Additionally, the RF classifier in the
approach of FS based on BA emerges as the best model and outperforms others
regarding its criteria. Besides, the results illustrate the role of our
techniques in reducing the dataset dimensions up to 90\% and increasing the
performance of diagnostic models by over 99\%. Moreover, the result
demonstrates that there are more critical features than the optimum dataset
obtained by proposed FS approaches that have been selected by most ML models.",2024-07-19,"Kamyab Karimi, Ali Ghodratnama, Reza Tavakkoli-Moghaddam",http://arxiv.org/pdf/2407.14631v2,cs.LG
Advancing Melanoma Diagnosis with Self-Supervised Neural Networks: Evaluating the Effectiveness of Different Techniques,"We investigate the potential of self-supervision in improving the accuracy of
deep learning models trained to classify melanoma patches. Various
self-supervision techniques such as rotation prediction, missing patch
prediction, and corruption removal were implemented and assessed for their
impact on the convolutional neural network's performance. Preliminary results
suggest a positive influence of self-supervision methods on the model's
accuracy. The study notably demonstrates the efficacy of the corruption removal
method in enhancing model performance. Despite observable improvements, we
conclude that the self-supervised models have considerable potential for
further enhancement, achievable through training over more epochs or expanding
the dataset. We suggest exploring other self-supervision methods like Bootstrap
Your Own Latent (BYOL) and contrastive learning in future research, emphasizing
the cost-benefit trade-off due to their resource-intensive nature. The findings
underline the promise of self-supervision in augmenting melanoma detection
capabilities of deep learning models.",2024-07-19,"Srivishnu Vusirikala, Suraj Rajendran",http://arxiv.org/pdf/2407.14628v1,cs.LG
BOND: Aligning LLMs with Best-of-N Distillation,"Reinforcement learning from human feedback (RLHF) is a key driver of quality
and safety in state-of-the-art large language models. Yet, a surprisingly
simple and strong inference-time strategy is Best-of-N sampling that selects
the best generation among N candidates. In this paper, we propose Best-of-N
Distillation (BOND), a novel RLHF algorithm that seeks to emulate Best-of-N but
without its significant computational overhead at inference time. Specifically,
BOND is a distribution matching algorithm that forces the distribution of
generations from the policy to get closer to the Best-of-N distribution. We use
the Jeffreys divergence (a linear combination of forward and backward KL) to
balance between mode-covering and mode-seeking behavior, and derive an
iterative formulation that utilizes a moving anchor for efficiency. We
demonstrate the effectiveness of our approach and several design choices
through experiments on abstractive summarization and Gemma models. Aligning
Gemma policies with BOND outperforms other RLHF algorithms by improving results
on several benchmarks.",2024-07-19,"Pier Giuseppe Sessa, Robert Dadashi, Léonard Hussenot, Johan Ferret, Nino Vieillard, Alexandre Ramé, Bobak Shariari, Sarah Perrin, Abe Friesen, Geoffrey Cideron, Sertan Girgin, Piotr Stanczyk, Andrea Michi, Danila Sinopalnikov, Sabela Ramos, Amélie Héliou, Aliaksei Severyn, Matt Hoffman, Nikola Momchev, Olivier Bachem",http://arxiv.org/pdf/2407.14622v1,cs.LG
SOREL: A Stochastic Algorithm for Spectral Risks Minimization,"The spectral risk has wide applications in machine learning, especially in
real-world decision-making, where people are not only concerned with models'
average performance. By assigning different weights to the losses of different
sample points, rather than the same weights as in the empirical risk, it allows
the model's performance to lie between the average performance and the
worst-case performance. In this paper, we propose SOREL, the first stochastic
gradient-based algorithm with convergence guarantees for the spectral risk
minimization. Previous algorithms often consider adding a strongly concave
function to smooth the spectral risk, thus lacking convergence guarantees for
the original spectral risk. We theoretically prove that our algorithm achieves
a near-optimal rate of $\widetilde{O}(1/\sqrt{\epsilon})$ in terms of
$\epsilon$. Experiments on real datasets show that our algorithm outperforms
existing algorithms in most cases, both in terms of runtime and sample
complexity.",2024-07-19,"Yuze Ge, Rujun Jiang",http://arxiv.org/pdf/2407.14618v1,cs.LG
Evaluating language models as risk scores,"Current question-answering benchmarks predominantly focus on accuracy in
realizable prediction tasks. Conditioned on a question and answer-key, does the
most likely token match the ground truth? Such benchmarks necessarily fail to
evaluate LLMs' ability to quantify ground-truth outcome uncertainty. In this
work, we focus on the use of LLMs as risk scores for unrealizable prediction
tasks. We introduce folktexts, a software package to systematically generate
risk scores using LLMs, and evaluate them against US Census data products. A
flexible API enables the use of different prompting schemes, local or
web-hosted models, and diverse census columns that can be used to compose
custom prediction tasks. We evaluate 17 recent LLMs across five proposed
benchmark tasks. We find that zero-shot risk scores produced by multiple-choice
question-answering have high predictive signal but are widely miscalibrated.
Base models consistently overestimate outcome uncertainty, while
instruction-tuned models underestimate uncertainty and produce over-confident
risk scores. In fact, instruction-tuning polarizes answer distribution
regardless of true underlying data uncertainty. This reveals a general
inability of instruction-tuned LLMs to express data uncertainty using
multiple-choice answers. A separate experiment using verbalized chat-style risk
queries yields substantially improved calibration across instruction-tuned
models. These differences in ability to quantify data uncertainty cannot be
revealed in realizable settings, and highlight a blind-spot in the current
evaluation ecosystem that folktexts covers.",2024-07-19,"André F. Cruz, Moritz Hardt, Celestine Mendler-Dünner",http://arxiv.org/pdf/2407.14614v3,cs.LG
Physical Data Embedding for Memory Efficient AI,"Deep neural networks (DNNs) have achieved exceptional performance across
various fields by learning complex, nonlinear mappings from large-scale
datasets. However, they face challenges such as high memory requirements and
computational costs with limited interpretability. This paper introduces an
approach where master equations of physics are converted into multilayered
networks that are trained via backpropagation. The resulting general-purpose
model effectively encodes data in the properties of the underlying physical
system. In contrast to existing methods wherein a trained neural network is
used as a computationally efficient alternative for solving physical equations,
our approach directly treats physics equations as trainable models. We
demonstrate this physical embedding concept with the Nonlinear Schr\""odinger
Equation (NLSE), which acts as trainable architecture for learning complex
patterns including nonlinear mappings and memory effects from data. The network
embeds data representation in orders of magnitude fewer parameters than
conventional neural networks when tested on time series data. Notably, the
trained ""Nonlinear Schr\""odinger Network"" is interpretable, with all parameters
having physical meanings. This interpretability offers insight into the
underlying dynamics of the system that produced the data. The proposed method
of replacing traditional DNN feature learning architectures with physical
equations is also extended to the Gross-Pitaevskii Equation, demonstrating the
broad applicability of the framework to other master equations of physics.
Among our results, an ablation study quantifies the relative importance of
physical terms such as dispersion, nonlinearity, and potential energy for
classification accuracy. We also outline the limitations of this approach as it
relates to generalizability.",2024-07-19,"Callen MacPhee, Yiming Zhou, Bahram Jalali",http://arxiv.org/pdf/2407.14504v3,cs.LG
Catastrophic Goodhart: regularizing RLHF with KL divergence does not mitigate heavy-tailed reward misspecification,"When applying reinforcement learning from human feedback (RLHF), the reward
is learned from data and, therefore, always has some error. It is common to
mitigate this by regularizing the policy with KL divergence from a base model,
with the hope that balancing reward with regularization will achieve desirable
outcomes despite this reward misspecification. We show that when the reward
function has light-tailed error, optimal policies under less restrictive KL
penalties achieve arbitrarily high utility. However, if error is heavy-tailed,
some policies obtain arbitrarily high reward despite achieving no more utility
than the base model--a phenomenon we call catastrophic Goodhart. We adapt a
discrete optimization method to measure the tails of reward models, finding
that they are consistent with light-tailed error. However, the pervasiveness of
heavy-tailed distributions in many real-world applications indicates that
future sources of RL reward could have heavy-tailed error, increasing the
likelihood of reward hacking even with KL regularization.",2024-07-19,"Thomas Kwa, Drake Thomas, Adrià Garriga-Alonso",http://arxiv.org/pdf/2407.14503v2,cs.LG
Indoor Air Quality Dataset with Activities of Daily Living in Low to Middle-income Communities,"In recent years, indoor air pollution has posed a significant threat to our
society, claiming over 3.2 million lives annually. Developing nations, such as
India, are most affected since lack of knowledge, inadequate regulation, and
outdoor air pollution lead to severe daily exposure to pollutants. However,
only a limited number of studies have attempted to understand how indoor air
pollution affects developing countries like India. To address this gap, we
present spatiotemporal measurements of air quality from 30 indoor sites over
six months during summer and winter seasons. The sites are geographically
located across four regions of type: rural, suburban, and urban, covering the
typical low to middle-income population in India. The dataset contains various
types of indoor environments (e.g., studio apartments, classrooms, research
laboratories, food canteens, and residential households), and can provide the
basis for data-driven learning model research aimed at coping with unique
pollution patterns in developing countries. This unique dataset demands
advanced data cleaning and imputation techniques for handling missing data due
to power failure or network outages during data collection. Furthermore,
through a simple speech-to-text application, we provide real-time indoor
activity labels annotated by occupants. Therefore, environmentalists and ML
enthusiasts can utilize this dataset to understand the complex patterns of the
pollutants under different indoor activities, identify recurring sources of
pollution, forecast exposure, improve floor plans and room structures of modern
indoor designs, develop pollution-aware recommender systems, etc.",2024-07-19,"Prasenjit Karmakar, Swadhin Pradhan, Sandip Chakraborty",http://arxiv.org/pdf/2407.14501v3,cs.LG
Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery,"Concept Bottleneck Models (CBMs) have recently been proposed to address the
'black-box' problem of deep neural networks, by first mapping images to a
human-understandable concept space and then linearly combining concepts for
classification. Such models typically require first coming up with a set of
concepts relevant to the task and then aligning the representations of a
feature extractor to map to these concepts. However, even with powerful
foundational feature extractors like CLIP, there are no guarantees that the
specified concepts are detectable. In this work, we leverage recent advances in
mechanistic interpretability and propose a novel CBM approach -- called
Discover-then-Name-CBM (DN-CBM) -- that inverts the typical paradigm: instead
of pre-selecting concepts based on the downstream classification task, we use
sparse autoencoders to first discover concepts learnt by the model, and then
name them and train linear probes for classification. Our concept extraction
strategy is efficient, since it is agnostic to the downstream task, and uses
concepts already known to the model. We perform a comprehensive evaluation
across multiple datasets and CLIP architectures and show that our method yields
semantically meaningful concepts, assigns appropriate names to them that make
them easy to interpret, and yields performant and interpretable CBMs. Code
available at https://github.com/neuroexplicit-saar/discover-then-name.",2024-07-19,"Sukrut Rao, Sweta Mahajan, Moritz Böhle, Bernt Schiele",http://arxiv.org/pdf/2407.14499v2,cs.LG
Conformal Thresholded Intervals for Efficient Regression,"This paper introduces Conformal Thresholded Intervals (CTI), a novel
conformal regression method that aims to produce the smallest possible
prediction set with guaranteed coverage. Unlike existing methods that rely on
nested conformal frameworks and full conditional distribution estimation, CTI
estimates the conditional probability density for a new response to fall into
each interquantile interval using off-the-shelf multi-output quantile
regression. By leveraging the inverse relationship between interval length and
probability density, CTI constructs prediction sets by thresholding the
estimated conditional interquantile intervals based on their length. The
optimal threshold is determined using a calibration set to ensure marginal
coverage, effectively balancing the trade-off between prediction set size and
coverage. CTI's approach is computationally efficient and avoids the complexity
of estimating the full conditional distribution. The method is theoretically
grounded, with provable guarantees for marginal coverage and achieving the
smallest prediction size given by Neyman-Pearson . Extensive experimental
results demonstrate that CTI achieves superior performance compared to
state-of-the-art conformal regression methods across various datasets,
consistently producing smaller prediction sets while maintaining the desired
coverage level. The proposed method offers a simple yet effective solution for
reliable uncertainty quantification in regression tasks, making it an
attractive choice for practitioners seeking accurate and efficient conformal
prediction.",2024-07-19,"Rui Luo, Zhixin Zhou",http://arxiv.org/pdf/2407.14495v2,cs.LG
InterpBench: Semi-Synthetic Transformers for Evaluating Mechanistic Interpretability Techniques,"Mechanistic interpretability methods aim to identify the algorithm a neural
network implements, but it is difficult to validate such methods when the true
algorithm is unknown. This work presents InterpBench, a collection of
semi-synthetic yet realistic transformers with known circuits for evaluating
these techniques. We train simple neural networks using a stricter version of
Interchange Intervention Training (IIT) which we call Strict IIT (SIIT). Like
the original, SIIT trains neural networks by aligning their internal
computation with a desired high-level causal model, but it also prevents
non-circuit nodes from affecting the model's output. We evaluate SIIT on sparse
transformers produced by the Tracr tool and find that SIIT models maintain
Tracr's original circuit while being more realistic. SIIT can also train
transformers with larger circuits, like Indirect Object Identification (IOI).
Finally, we use our benchmark to evaluate existing circuit discovery
techniques.",2024-07-19,"Rohan Gupta, Iván Arcuschin, Thomas Kwa, Adrià Garriga-Alonso",http://arxiv.org/pdf/2407.14494v2,cs.LG
ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities,"In this work, we introduce ChatQA 2, an Llama 3.0-based model with a 128K
context window, designed to bridge the gap between open-source LLMs and leading
proprietary models (e.g., GPT-4-Turbo-2024-04-09) in long context understanding
and retrieval-augmented generation (RAG) capabilities. These two capabilities
are complementary to each other and essential for LLMs to process large volumes
of information that cannot fit into a single prompt. We present a detailed
continued training recipe to extend the context window of Llama3-70B-base from
8K to 128K tokens, along with a three-stage instruction tuning process to
enhance the model's instruction-following, RAG performance, and long-context
understanding capabilities. Our results demonstrate that the
Llama3-ChatQA-2-70B model outperforms most existing state-of-the-art models,
including GPT-4-Turbo-2024-04-09, Qwen2-72B-Instruct, and
Llama3.1-70B-Instruct, on ultra-long tasks beyond 100K tokens, as well as on
the RAG benchmark using only a 4K context window, showing the strong long
context capability across varying sequence lengths. We further provide
extensive comparisons between direct long-context and RAG solutions using the
same state-of-the-art long-context LLMs. Interestingly, we find that the
performance of strong long-context LLMs using RAG improves when retrieving a
larger number of chunks. With a large set of top-k chunks, RAG consistently
outperforms direct long-context solution using the same state-of-the-art
long-context models (e.g., Llama3-ChatQA-2-70B and Qwen2-72B-Instruct) on both
32K and 128K benchmarks. We open-source the model weights, training data, and
the evaluation setup for the for the community:
https://chatqa2-project.github.io/",2024-07-19,"Peng Xu, Wei Ping, Xianchao Wu, Chejian Xu, Zihan Liu, Mohammad Shoeybi, Bryan Catanzaro",http://arxiv.org/pdf/2407.14482v3,cs.LG
Data-Centric Human Preference Optimization with Rationales,"Reinforcement learning from human feedback plays a crucial role in aligning
language models towards human preferences, traditionally represented through
comparisons between pairs or sets of responses within a given context. While
many studies have enhanced algorithmic techniques to optimize learning from
such data, this work shifts focus to improving preference learning through a
data-centric approach. Specifically, we propose enriching existing preference
datasets with machine-generated rationales that explain the reasons behind
choices. We develop a simple and principled framework to augment current
preference learning methods with rationale information. Our comprehensive
analysis highlights how rationales enhance learning efficiency. Extensive
experiments reveal that rationale-enriched preference learning offers multiple
advantages: it improves data efficiency, accelerates convergence to
higher-performing models, and reduces verbosity bias and hallucination.
Furthermore, this framework is versatile enough to integrate with various
preference optimization algorithms. Overall, our findings highlight the
potential of re-imagining data design for preference learning, demonstrating
that even freely available machine-generated rationales can significantly boost
performance across multiple dimensions. The code repository is available at
https: //github.com/reds-lab/preference-learning-with-rationales",2024-07-19,"Hoang Anh Just, Ming Jin, Anit Sahu, Huy Phan, Ruoxi Jia",http://arxiv.org/pdf/2407.14477v3,cs.LG
SurvReLU: Inherently Interpretable Survival Analysis via Deep ReLU Networks,"Survival analysis models time-to-event distributions with censorship.
Recently, deep survival models using neural networks have dominated due to
their representational power and state-of-the-art performance. However, their
""black-box"" nature hinders interpretability, which is crucial in real-world
applications. In contrast, ""white-box"" tree-based survival models offer better
interpretability but struggle to converge to global optima due to greedy
expansion. In this paper, we bridge the gap between previous deep survival
models and traditional tree-based survival models through deep rectified linear
unit (ReLU) networks. We show that a deliberately constructed deep ReLU network
(SurvReLU) can harness the interpretability of tree-based structures with the
representational power of deep survival models. Empirical studies on both
simulated and real survival benchmark datasets show the effectiveness of the
proposed SurvReLU in terms of performance and interoperability. The code is
available at \href{https://github.com/xs018/SurvReLU}{\color{magenta}{
https://github.com/xs018/SurvReLU}}.",2024-07-19,"Xiaotong Sun, Peijie Qiu, Shengfan Zhang",http://arxiv.org/pdf/2407.14463v2,cs.LG
PolyFormer: Scalable Node-wise Filters via Polynomial Graph Transformer,"Spectral Graph Neural Networks have demonstrated superior performance in
graph representation learning. However, many current methods focus on employing
shared polynomial coefficients for all nodes, i.e., learning node-unified
filters, which limits the filters' flexibility for node-level tasks. The recent
DSF attempts to overcome this limitation by learning node-wise coefficients
based on positional encoding. However, the initialization and updating process
of the positional encoding are burdensome, hindering scalability on large-scale
graphs. In this work, we propose a scalable node-wise filter, PolyAttn.
Leveraging the attention mechanism, PolyAttn can directly learn node-wise
filters in an efficient manner, offering powerful representation capabilities.
Building on PolyAttn, we introduce the whole model, named PolyFormer. In the
lens of Graph Transformer models, PolyFormer, which calculates attention scores
within nodes, shows great scalability. Moreover, the model captures spectral
information, enhancing expressiveness while maintaining efficiency. With these
advantages, PolyFormer offers a desirable balance between scalability and
expressiveness for node-level tasks. Extensive experiments demonstrate that our
proposed methods excel at learning arbitrary node-wise filters, showing
superior performance on both homophilic and heterophilic graphs, and handling
graphs containing up to 100 million nodes. The code is available at
https://github.com/air029/PolyFormer.",2024-07-19,"Jiahong Ma, Mingguo He, Zhewei Wei",http://arxiv.org/pdf/2407.14459v1,cs.LG
Regression prediction algorithm for energy consumption regression in cloud computing based on horned lizard algorithm optimised convolutional neural network-bidirectional gated recurrent unit,"For this paper, a prediction study of cloud computing energy consumption was
conducted by optimising the data regression algorithm based on the horned
lizard optimisation algorithm for Convolutional Neural Networks-Bi-Directional
Gated Recurrent Units. Firstly, through Spearman correlation analysis of CPU,
usage, memory usage, network traffic, power consumption, number of instructions
executed, execution time and energy efficiency, we found that power consumption
has the highest degree of positive correlation with energy efficiency, while
CPU usage has the highest degree of negative correlation with energy
efficiency. In our experiments, we introduced a random forest model and an
optimisation model based on the horned lizard optimisation algorithm for
testing, and the results show that the optimisation algorithm has better
prediction results compared to the random forest model. Specifically, the mean
square error (MSE) of the optimisation algorithm is 0.01 smaller than that of
the random forest model, and the mean absolute error (MAE) is 0.01 smaller than
that of the random forest.3 The results of the combined metrics show that the
optimisation algorithm performs more accurately and reliably in predicting
energy efficiency. This research result provides new ideas and methods to
improve the energy efficiency of cloud computing systems. This research not
only expands the scope of application in the field of cloud computing, but also
provides a strong support for improving the energy use efficiency of the
system.",2024-07-19,"Feiyang Li, Zinan Cao, Qixuan Yu, Xirui Tang",http://arxiv.org/pdf/2407.14575v2,cs.LG
Jumping Ahead: Improving Reconstruction Fidelity with JumpReLU Sparse Autoencoders,"Sparse autoencoders (SAEs) are a promising unsupervised approach for
identifying causally relevant and interpretable linear features in a language
model's (LM) activations. To be useful for downstream tasks, SAEs need to
decompose LM activations faithfully; yet to be interpretable the decomposition
must be sparse -- two objectives that are in tension. In this paper, we
introduce JumpReLU SAEs, which achieve state-of-the-art reconstruction fidelity
at a given sparsity level on Gemma 2 9B activations, compared to other recent
advances such as Gated and TopK SAEs. We also show that this improvement does
not come at the cost of interpretability through manual and automated
interpretability studies. JumpReLU SAEs are a simple modification of vanilla
(ReLU) SAEs -- where we replace the ReLU with a discontinuous JumpReLU
activation function -- and are similarly efficient to train and run. By
utilising straight-through-estimators (STEs) in a principled manner, we show
how it is possible to train JumpReLU SAEs effectively despite the discontinuous
JumpReLU function introduced in the SAE's forward pass. Similarly, we use STEs
to directly train L0 to be sparse, instead of training on proxies such as L1,
avoiding problems like shrinkage.",2024-07-19,"Senthooran Rajamanoharan, Tom Lieberum, Nicolas Sonnerat, Arthur Conmy, Vikrant Varma, János Kramár, Neel Nanda",http://arxiv.org/pdf/2407.14435v3,cs.LG
The Extrapolation Power of Implicit Models,"In this paper, we investigate the extrapolation capabilities of implicit deep
learning models in handling unobserved data, where traditional deep neural
networks may falter. Implicit models, distinguished by their adaptability in
layer depth and incorporation of feedback within their computational graph, are
put to the test across various extrapolation scenarios: out-of-distribution,
geographical, and temporal shifts. Our experiments consistently demonstrate
significant performance advantage with implicit models. Unlike their
non-implicit counterparts, which often rely on meticulous architectural design
for each task, implicit models demonstrate the ability to learn complex model
structures without the need for task-specific design, highlighting their
robustness in handling unseen data.",2024-07-19,"Juliette Decugis, Alicia Y. Tsai, Max Emerling, Ashwin Ganesh, Laurent El Ghaoui",http://arxiv.org/pdf/2407.14430v1,cs.LG
Gaussian Process Model with Tensorial Inputs and Its Application to the Design of 3D Printed Antennas,"In simulation-based engineering design with time-consuming simulators,
Gaussian process (GP) models are widely used as fast emulators to speed up the
design optimization process. In its most commonly used form, the input of GP is
a simple list of design parameters. With rapid development of additive
manufacturing (also known as 3D printing), design inputs with 2D/3D spatial
information become prevalent in some applications, for example, neighboring
relations between pixels/voxels and material distributions in heterogeneous
materials. Such spatial information, vital to 3D printed designs, is hard to
incorporate into existing GP models with common kernels such as squared
exponential or Mat\'ern. In this work, we propose to embed a generalized
distance measure into a GP kernel, offering a novel and convenient technique to
incorporate spatial information from freeform 3D printed designs into the GP
framework. The proposed method allows complex design problems for 3D printed
objects to take advantage of a plethora of tools available from the GP
surrogate-based simulation optimization such as designed experiments and
GP-based optimizations including Bayesian optimization. We investigate the
properties of the proposed method and illustrate its performance by several
numerical examples of 3D printed antennas. The dataset is publicly available
at: https://github.com/xichennn/GP_dataset.",2024-07-19,"Xi Chen, Yashika Sharma, Hao Helen Zhang, Xin Hao, Qiang Zhou",http://arxiv.org/pdf/2407.15877v1,cs.LG
Mixture of Experts with Mixture of Precisions for Tuning Quality of Service,"The increasing demand for deploying large Mixture-of-Experts (MoE) models in
resource-constrained environments necessitates efficient approaches to address
their high memory and computational requirements challenges. Moreover, given
that tasks come in different user-defined constraints and the available
resources change over time in multi-tenant environments, it is necessary to
design an approach which provides a flexible configuration space. This paper
presents an adaptive serving approach for the efficient deployment of MoE
models, capitalizing on partial quantization of the experts. By dynamically
determining the number of quantized experts and their distribution across CPU
and GPU, our approach explores the Pareto frontier and offers a fine-grained
range of configurations for tuning throughput and model quality. Our evaluation
on an NVIDIA A100 GPU using a Mixtral 8x7B MoE model for three language
modelling benchmarks demonstrates that the throughput of token generation can
be adjusted from 0.63 to 13.00 token per second. This enhancement comes with a
marginal perplexity increase of 3.81 to 4.00, 13.59 to 14.17, and 7.24 to 7.40
for WikiText2, PTB, and C4 datasets respectively under maximum quantization.
These results highlight the practical applicability of our approach in dynamic
and accuracy-sensitive applications where both memory usage and output quality
are important.",2024-07-19,"HamidReza Imani, Abdolah Amirany, Tarek El-Ghazawi",http://arxiv.org/pdf/2407.14417v2,cs.LG
System-1.x: Learning to Balance Fast and Slow Planning with Language Models,"Language models can be used to solve long-horizon planning problems in two
distinct modes: a fast 'System-1' mode, directly generating plans without any
explicit search or backtracking, and a slow 'System-2' mode, planning
step-by-step by explicitly searching over possible actions. While System-2 is
typically more effective, it is also more computationally expensive, making it
infeasible for long plans or large action spaces. Moreover, isolated System-1
or 2 ignores the user's end goals, failing to provide ways to control the
model's behavior. To this end, we propose the System-1.x Planner, a
controllable planning framework with LLMs that is capable of generating hybrid
plans and balancing between the two planning modes based on the difficulty of
the problem at hand. System-1.x consists of (i) a controller, (ii) a System-1
Planner, and (iii) a System-2 Planner. Based on a user-specified hybridization
factor (x) governing the mixture between System-1 and 2, the controller
decomposes a problem into sub-goals, and classifies them as easy or hard to be
solved by either System-1 or 2, respectively. We fine-tune all three components
on top of a single base LLM, requiring only search traces as supervision.
Experiments with two diverse planning tasks -- Maze Navigation and Blocksworld
-- show that our System-1.x Planner outperforms a System-1 Planner, a System-2
Planner trained to approximate A* search, and also a symbolic planner (A*). We
demonstrate the following key properties of our planner: (1) controllability:
increasing the hybridization factor (e.g., System-1.75 vs 1.5) performs more
search, improving performance, (2) flexibility: by building a neuro-symbolic
variant with a neural System-1 and a symbolic System-2, we can use existing
symbolic methods, and (3) generalizability: by being able to learn from
different search algorithms, our method is robust to the choice of search
algorithm.",2024-07-19,"Swarnadeep Saha, Archiki Prasad, Justin Chih-Yao Chen, Peter Hase, Elias Stengel-Eskin, Mohit Bansal",http://arxiv.org/pdf/2407.14414v2,cs.LG
DEAL: Disentangle and Localize Concept-level Explanations for VLMs,"Large pre-trained Vision-Language Models (VLMs) have become ubiquitous
foundational components of other models and downstream tasks. Although
powerful, our empirical results reveal that such models might not be able to
identify fine-grained concepts. Specifically, the explanations of VLMs with
respect to fine-grained concepts are entangled and mislocalized. To address
this issue, we propose to DisEntAngle and Localize (DEAL) the concept-level
explanations for VLMs without human annotations. The key idea is encouraging
the concept-level explanations to be distinct while maintaining consistency
with category-level explanations. We conduct extensive experiments and ablation
studies on a wide range of benchmark datasets and vision-language models. Our
empirical results demonstrate that the proposed method significantly improves
the concept-level explanations of the model in terms of disentanglability and
localizability. Surprisingly, the improved explainability alleviates the
model's reliance on spurious correlations, which further benefits the
prediction accuracy.",2024-07-19,"Tang Li, Mengmeng Ma, Xi Peng",http://arxiv.org/pdf/2407.14412v1,cs.LG
Modeling Latent Neural Dynamics with Gaussian Process Switching Linear Dynamical Systems,"Understanding how the collective activity of neural populations relates to
computation and ultimately behavior is a key goal in neuroscience. To this end,
statistical methods which describe high-dimensional neural time series in terms
of low-dimensional latent dynamics have played a fundamental role in
characterizing neural systems. Yet, what constitutes a successful method
involves two opposing criteria: (1) methods should be expressive enough to
capture complex nonlinear dynamics, and (2) they should maintain a notion of
interpretability often only warranted by simpler linear models. In this paper,
we develop an approach that balances these two objectives: the Gaussian Process
Switching Linear Dynamical System (gpSLDS). Our method builds on previous work
modeling the latent state evolution via a stochastic differential equation
whose nonlinear dynamics are described by a Gaussian process (GP-SDEs). We
propose a novel kernel function which enforces smoothly interpolated locally
linear dynamics, and therefore expresses flexible -- yet interpretable --
dynamics akin to those of recurrent switching linear dynamical systems (rSLDS).
Our approach resolves key limitations of the rSLDS such as artifactual
oscillations in dynamics near discrete state boundaries, while also providing
posterior uncertainty estimates of the dynamics. To fit our models, we leverage
a modified learning objective which improves the estimation accuracy of kernel
hyperparameters compared to previous GP-SDE fitting approaches. We apply our
method to synthetic data and data recorded in two neuroscience experiments and
demonstrate favorable performance in comparison to the rSLDS.",2024-07-19,"Amber Hu, David Zoltowski, Aditya Nair, David Anderson, Lea Duncker, Scott Linderman",http://arxiv.org/pdf/2408.03330v3,cs.LG
On the Impact of PRB Load Uncertainty Forecasting for Sustainable Open RAN,"The transition to sustainable Open Radio Access Network (O-RAN) architectures
brings new challenges for resource management, especially in predicting the
utilization of Physical Resource Block (PRB)s. In this paper, we propose a
novel approach to characterize the PRB load using probabilistic forecasting
techniques. First, we provide background information on the O-RAN architecture
and components and emphasize the importance of energy/power consumption models
for sustainable implementations. The problem statement highlights the need for
accurate PRB load prediction to optimize resource allocation and power
efficiency. We then investigate probabilistic forecasting techniques, including
Simple-Feed-Forward (SFF), DeepAR, and Transformers, and discuss their
likelihood model assumptions. The simulation results show that DeepAR
estimators predict the PRBs with less uncertainty and effectively capture the
temporal dependencies in the dataset compared to SFF- and Transformer-based
models, leading to power savings. Different percentile selections can also
increase power savings, but at the cost of over-/under provisioning. At the
same time, the performance of the Long-Short Term Memory (LSTM) is shown to be
inferior to the probabilistic estimators with respect to all error metrics.
Finally, we outline the importance of probabilistic, prediction-based
characterization for sustainable O-RAN implementations and highlight avenues
for future research.",2024-07-19,"Vaishnavi Kasuluru, Luis Blanco, Cristian J. Vaca-Rubio, Engin Zeydan",http://arxiv.org/pdf/2407.14400v1,cs.LG
GLAudio Listens to the Sound of the Graph,"We propose GLAudio: Graph Learning on Audio representation of the node
features and the connectivity structure. This novel architecture propagates the
node features through the graph network according to the discrete wave equation
and then employs a sequence learning architecture to learn the target node
function from the audio wave signal. This leads to a new paradigm of learning
on graph-structured data, in which information propagation and information
processing are separated into two distinct steps. We theoretically characterize
the expressivity of our model, introducing the notion of the receptive field of
a vertex, and investigate our model's susceptibility to over-smoothing and
over-squashing both theoretically as well as experimentally on various graph
datasets.",2024-07-19,"Aurelio Sulser, Johann Wenckstern, Clara Kuempel",http://arxiv.org/pdf/2407.14387v1,cs.LG
Frontiers of Deep Learning: From Novel Application to Real-World Deployment,"Deep learning continues to re-shape numerous fields, from natural language
processing and imaging to data analytics and recommendation systems. This
report studies two research papers that represent recent progress on deep
learning from two largely different aspects: The first paper applied the
transformer networks, which are typically used in language models, to improve
the quality of synthetic aperture radar image by effectively reducing the
speckle noise. The second paper presents an in-storage computing design
solution to enable cost-efficient and high-performance implementations of deep
learning recommendation systems. In addition to summarizing each paper in terms
of motivation, key ideas and techniques, and evaluation results, this report
also presents thoughts and discussions about possible future research
directions. By carrying out in-depth study on these two representative papers
and related references, this doctoral candidate has developed better
understanding on the far-reaching impact and efficient implementation of deep
learning models.",2024-07-19,Rui Xie,http://arxiv.org/pdf/2407.14386v1,cs.LG
Improving GBDT Performance on Imbalanced Datasets: An Empirical Study of Class-Balanced Loss Functions,"Class imbalance remains a significant challenge in machine learning,
particularly for tabular data classification tasks. While Gradient Boosting
Decision Trees (GBDT) models have proven highly effective for such tasks, their
performance can be compromised when dealing with imbalanced datasets. This
paper presents the first comprehensive study on adapting class-balanced loss
functions to three GBDT algorithms across various tabular classification tasks,
including binary, multi-class, and multi-label classification. We conduct
extensive experiments on multiple datasets to evaluate the impact of
class-balanced losses on different GBDT models, establishing a valuable
benchmark. Our results demonstrate the potential of class-balanced loss
functions to enhance GBDT performance on imbalanced datasets, offering a robust
approach for practitioners facing class imbalance challenges in real-world
applications. Additionally, we introduce a Python package that facilitates the
integration of class-balanced loss functions into GBDT workflows, making these
advanced techniques accessible to a wider audience.",2024-07-19,"Jiaqi Luo, Yuan Yuan, Shixin Xu",http://arxiv.org/pdf/2407.14381v1,cs.LG
Enhancing Cloud-Native Resource Allocation with Probabilistic Forecasting Techniques in O-RAN,"The need for intelligent and efficient resource provisioning for the
productive management of resources in real-world scenarios is growing with the
evolution of telecommunications towards the 6G era. Technologies such as Open
Radio Access Network (O-RAN) can help to build interoperable solutions for the
management of complex systems. Probabilistic forecasting, in contrast to
deterministic single-point estimators, can offer a different approach to
resource allocation by quantifying the uncertainty of the generated
predictions. This paper examines the cloud-native aspects of O-RAN together
with the radio App (rApp) deployment options. The integration of probabilistic
forecasting techniques as a rApp in O-RAN is also emphasized, along with case
studies of real-world applications. Through a comparative analysis of
forecasting models using the error metric, we show the advantages of Deep
Autoregressive Recurrent network (DeepAR) over other deterministic
probabilistic estimators. Furthermore, the simplicity of Simple-Feed-Forward
(SFF) leads to a fast runtime but does not capture the temporal dependencies of
the input data. Finally, we present some aspects related to the practical
applicability of cloud-native O-RAN with probabilistic forecasting.",2024-07-19,"Vaishnavi Kasuluru, Luis Blanco, Engin Zeydan, Albert Bel, Angelos Antonopoulos",http://arxiv.org/pdf/2407.14377v1,cs.LG
On the use of Probabilistic Forecasting for Network Analysis in Open RAN,"Unlike other single-point Artificial Intelligence (AI)-based prediction
techniques, such as Long-Short Term Memory (LSTM), probabilistic forecasting
techniques (e.g., DeepAR and Transformer) provide a range of possible outcomes
and associated probabilities that enable decision makers to make more informed
and robust decisions. At the same time, the architecture of Open RAN has
emerged as a revolutionary approach for mobile networks, aiming at openness,
interoperability and innovation in the ecosystem of RAN. In this paper, we
propose the use of probabilistic forecasting techniques as a radio App (rApp)
within the Open RAN architecture. We investigate and compare different
probabilistic and single-point forecasting methods and algorithms to estimate
the utilization and resource demands of Physical Resource Blocks (PRBs) of
cellular base stations. Through our evaluations, we demonstrate the numerical
advantages of probabilistic forecasting techniques over traditional
single-point forecasting methods and show that they are capable of providing
more accurate and reliable estimates. In particular, DeepAR clearly outperforms
single-point forecasting techniques such as LSTM and Seasonal-Naive (SN)
baselines and other probabilistic forecasting techniques such as
Simple-Feed-Forward (SFF) and Transformer neural networks.",2024-07-19,"Vaishnavi Kasuluru, Luis Blanco, Engin Zeydan",http://arxiv.org/pdf/2407.14375v1,cs.LG
SCoPE: Evaluating LLMs for Software Vulnerability Detection,"In recent years, code security has become increasingly important, especially
with the rise of interconnected technologies. Detecting vulnerabilities early
in the software development process has demonstrated numerous benefits.
Consequently, the scientific community started using machine learning for
automated detection of source code vulnerabilities. This work explores and
refines the CVEFixes dataset, which is commonly used to train models for
code-related tasks, specifically the C/C++ subset. To this purpose, the Source
Code Processing Engine (SCoPE), a framework composed of strategized techniques
that can be used to reduce the size and normalize C/C++ functions is presented.
The output generated by SCoPE was used to create a new version of CVEFixes.
This refined dataset was then employed in a feature representation analysis to
assess the effectiveness of the tool's code processing techniques, consisting
of fine-tuning three pre-trained LLMs for software vulnerability detection. The
results show that SCoPE successfully helped to identify 905 duplicates within
the evaluated subset. The LLM results corroborate with the literature regarding
their suitability for software vulnerability detection, with the best model
achieving 53% F1-score.",2024-07-19,"José Gonçalves, Tiago Dias, Eva Maia, Isabel Praça",http://arxiv.org/pdf/2407.14372v1,cs.LG
Open Artificial Knowledge,"The tremendous success of chat-based AI systems like ChatGPT, Claude, and
Gemini stems from Large Language Models (LLMs) trained on vast amount of
datasets. However, acquiring high-quality, diverse, and ethically sourced
training data remains a significant challenge. We introduce the Open Artificial
Knowledge (OAK) dataset, a large-scale resource of over 500 million tokens (at
the moment of writing) designed to address this issue. OAK leverages an
ensemble of state-of-the-art LLMs, including GPT4o, LLaMa3-70B, LLaMa3-8B,
Mixtral-8x7B, Gemma-7B, and Gemma-2-9B , to generate high-quality text across
diverse domains, guided by Wikipedia's main categories. Our methodology ensures
broad knowledge coverage while maintaining coherence and factual accuracy. The
OAK dataset aims to foster the development of more capable and aligned language
models while addressing critical issues of data scarcity and privacy in LLM
training, and it is freely available on www.oakdataset.org.",2024-07-19,"Vadim Borisov, Richard H. Schreiber",http://arxiv.org/pdf/2407.14371v1,cs.LG
FuzzTheREST: An Intelligent Automated Black-box RESTful API Fuzzer,"Software's pervasive impact and increasing reliance in the era of digital
transformation raise concerns about vulnerabilities, emphasizing the need for
software security. Fuzzy testing is a dynamic analysis software testing
technique that consists of feeding faulty input data to a System Under Test
(SUT) and observing its behavior. Specifically regarding black-box RESTful API
testing, recent literature has attempted to automate this technique using
heuristics to perform the input search and using the HTTP response status codes
for classification. However, most approaches do not keep track of code
coverage, which is important to validate the solution. This work introduces a
black-box RESTful API fuzzy testing tool that employs Reinforcement Learning
(RL) for vulnerability detection. The fuzzer operates via the OpenAPI
Specification (OAS) file and a scenarios file, which includes information to
communicate with the SUT and the sequences of functionalities to test,
respectively. To evaluate its effectiveness, the tool was tested on the
Petstore API. The tool found a total of six unique vulnerabilities and achieved
55\% code coverage.",2024-07-19,"Tiago Dias, Eva Maia, Isabel Praça",http://arxiv.org/pdf/2407.14361v1,cs.LG
Quantifying the value of positive transfer: An experimental case study,"In traditional approaches to structural health monitoring, challenges often
arise associated with the availability of labelled data. Population-based
structural health monitoring seeks to overcomes these challenges by leveraging
data/information from similar structures via technologies such as transfer
learning. The current paper demonstrate a methodology for quantifying the value
of information transfer in the context of operation and maintenance
decision-making. This demonstration, based on a population of laboratory-scale
aircraft models, highlights the steps required to evaluate the expected value
of information transfer including similarity assessment and prediction of
transfer efficacy. Once evaluated for a given population, the value of
information transfer can be used to optimise transfer-learning strategies for
newly-acquired target domains.",2024-07-19,"Aidan J. Hughes, Giulia Delo, Jack Poole, Nikolaos Dervilis, Keith Worden",http://arxiv.org/pdf/2407.14342v1,cs.LG
Modality-Order Matters! A Novel Hierarchical Feature Fusion Method for CoSAm: A Code-Switched Autism Corpus,"Autism Spectrum Disorder (ASD) is a complex neuro-developmental challenge,
presenting a spectrum of difficulties in social interaction, communication, and
the expression of repetitive behaviors in different situations. This increasing
prevalence underscores the importance of ASD as a major public health concern
and the need for comprehensive research initiatives to advance our
understanding of the disorder and its early detection methods. This study
introduces a novel hierarchical feature fusion method aimed at enhancing the
early detection of ASD in children through the analysis of code-switched speech
(English and Hindi). Employing advanced audio processing techniques, the
research integrates acoustic, paralinguistic, and linguistic information using
Transformer Encoders. This innovative fusion strategy is designed to improve
classification robustness and accuracy, crucial for early and precise ASD
identification. The methodology involves collecting a code-switched speech
corpus, CoSAm, from children diagnosed with ASD and a matched control group.
The dataset comprises 61 voice recordings from 30 children diagnosed with ASD
and 31 from neurotypical children, aged between 3 and 13 years, resulting in a
total of 159.75 minutes of voice recordings. The feature analysis focuses on
MFCCs and extensive statistical attributes to capture speech pattern
variability and complexity. The best model performance is achieved using a
hierarchical fusion technique with an accuracy of 98.75% using a combination of
acoustic and linguistic features first, followed by paralinguistic features in
a hierarchical manner.",2024-07-19,"Mohd Mujtaba Akhtar, Girish, Muskaan Singh, Orchid Chetia Phukan",http://arxiv.org/pdf/2407.14328v2,cs.LG
Joint or Disjoint: Mixing Training Regimes for Early-Exit Models,"Early exits are an important efficiency mechanism integrated into deep neural
networks that allows for the termination of the network's forward pass before
processing through all its layers. By allowing early halting of the inference
process for less complex inputs that reached high confidence, early exits
significantly reduce the amount of computation required. Early exit methods add
trainable internal classifiers which leads to more intricacy in the training
process. However, there is no consistent verification of the approaches of
training of early exit methods, and no unified scheme of training such models.
Most early exit methods employ a training strategy that either simultaneously
trains the backbone network and the exit heads or trains the exit heads
separately. We propose a training approach where the backbone is initially
trained on its own, followed by a phase where both the backbone and the exit
heads are trained together. Thus, we advocate for organizing early-exit
training strategies into three distinct categories, and then validate them for
their performance and efficiency. In this benchmark, we perform both
theoretical and empirical analysis of early-exit training regimes. We study the
methods in terms of information flow, loss landscape and numerical rank of
activations and gauge the suitability of regimes for various architectures and
datasets.",2024-07-19,"Bartłomiej Krzepkowski, Monika Michaluk, Franciszek Szarwacki, Piotr Kubaty, Jary Pomponi, Tomasz Trzciński, Bartosz Wójcik, Kamil Adamczewski",http://arxiv.org/pdf/2407.14320v1,cs.LG
Multi-Source and Test-Time Domain Adaptation on Multivariate Signals using Spatio-Temporal Monge Alignment,"Machine learning applications on signals such as computer vision or
biomedical data often face significant challenges due to the variability that
exists across hardware devices or session recordings. This variability poses a
Domain Adaptation (DA) problem, as training and testing data distributions
often differ. In this work, we propose Spatio-Temporal Monge Alignment (STMA)
to mitigate these variabilities. This Optimal Transport (OT) based method
adapts the cross-power spectrum density (cross-PSD) of multivariate signals by
mapping them to the Wasserstein barycenter of source domains (multi-source DA).
Predictions for new domains can be done with a filtering without the need for
retraining a model with source data (test-time DA). We also study and discuss
two special cases of the method, Temporal Monge Alignment (TMA) and Spatial
Monge Alignment (SMA). Non-asymptotic concentration bounds are derived for the
mappings estimation, which reveals a bias-plus-variance error structure with a
variance decay rate of $\mathcal{O}(n_\ell^{-1/2})$ with $n_\ell$ the signal
length. This theoretical guarantee demonstrates the efficiency of the proposed
computational schema. Numerical experiments on multivariate biosignals and
image data show that STMA leads to significant and consistent performance gains
between datasets acquired with very different settings. Notably, STMA is a
pre-processing step complementary to state-of-the-art deep learning methods.",2024-07-19,"Théo Gnassounou, Antoine Collas, Rémi Flamary, Karim Lounici, Alexandre Gramfort",http://arxiv.org/pdf/2407.14303v1,cs.LG
Riemannian Geometry-Based EEG Approaches: A Literature Review,"The application of Riemannian geometry in the decoding of brain-computer
interfaces (BCIs) has swiftly garnered attention because of its
straightforwardness, precision, and resilience, along with its aptitude for
transfer learning, which has been demonstrated through significant achievements
in global BCI competitions. This paper presents a comprehensive review of
recent advancements in the integration of deep learning with Riemannian
geometry to enhance EEG signal decoding in BCIs. Our review updates the
findings since the last major review in 2017, comparing modern approaches that
utilize deep learning to improve the handling of non-Euclidean data structures
inherent in EEG signals. We discuss how these approaches not only tackle the
traditional challenges of noise sensitivity, non-stationarity, and lengthy
calibration times but also introduce novel classification frameworks and signal
processing techniques to reduce these limitations significantly. Furthermore,
we identify current shortcomings and propose future research directions in
manifold learning and riemannian-based classification, focusing on practical
implementations and theoretical expansions, such as feature tracking on
manifolds, multitask learning, feature extraction, and transfer learning. This
review aims to bridge the gap between theoretical research and practical,
real-world applications, making sophisticated mathematical approaches
accessible and actionable for BCI enhancements.",2024-07-19,"Imad Eddine Tibermacine, Samuele Russo, Ahmed Tibermacine, Abdelaziz Rabehi, Bachir Nail, Kamel Kadri, Christian Napoli",http://arxiv.org/pdf/2407.20250v1,cs.LG
L^2CL: Embarrassingly Simple Layer-to-Layer Contrastive Learning for Graph Collaborative Filtering,"Graph neural networks (GNNs) have recently emerged as an effective approach
to model neighborhood signals in collaborative filtering. Towards this research
line, graph contrastive learning (GCL) demonstrates robust capabilities to
address the supervision label shortage issue through generating massive
self-supervised signals. Despite its effectiveness, GCL for recommendation
suffers seriously from two main challenges: i) GCL relies on graph augmentation
to generate semantically different views for contrasting, which could
potentially disrupt key information and introduce unwanted noise; ii) current
works for GCL primarily focus on contrasting representations using
sophisticated networks architecture (usually deep) to capture high-order
interactions, which leads to increased computational complexity and suboptimal
training efficiency. To this end, we propose L2CL, a principled Layer-to-Layer
Contrastive Learning framework that contrasts representations from different
layers. By aligning the semantic similarities between different layers, L2CL
enables the learning of complex structural relationships and gets rid of the
noise perturbation in stochastic data augmentation. Surprisingly, we find that
L2CL, using only one-hop contrastive learning paradigm, is able to capture
intrinsic semantic structures and improve the quality of node representation,
leading to a simple yet effective architecture. We also provide theoretical
guarantees for L2CL in minimizing task-irrelevant information. Extensive
experiments on five real-world datasets demonstrate the superiority of our
model over various state-of-the-art collaborative filtering methods. Our code
is available at https://github.com/downeykking/L2CL.",2024-07-19,"Xinzhou Jin, Jintang Li, Liang Chen, Chenyun Yu, Yuanzhen Xie, Tao Xie, Chengxiang Zhuo, Zang Li, Zibin Zheng",http://arxiv.org/pdf/2407.14266v1,cs.LG
Hyperparameter Optimization for Driving Strategies Based on Reinforcement Learning,"This paper focuses on hyperparameter optimization for autonomous driving
strategies based on Reinforcement Learning. We provide a detailed description
of training the RL agent in a simulation environment. Subsequently, we employ
Efficient Global Optimization algorithm that uses Gaussian Process fitting for
hyperparameter optimization in RL. Before this optimization phase, Gaussian
process interpolation is applied to fit the surrogate model, for which the
hyperparameter set is generated using Latin hypercube sampling. To accelerate
the evaluation, parallelization techniques are employed. Following the
hyperparameter optimization procedure, a set of hyperparameters is identified,
resulting in a noteworthy enhancement in overall driving performance. There is
a substantial increase of 4\% when compared to existing manually tuned
parameters and the hyperparameters discovered during the initialization process
using Latin hypercube sampling. After the optimization, we analyze the obtained
results thoroughly and conduct a sensitivity analysis to assess the robustness
and generalization capabilities of the learned autonomous driving strategies.
The findings from this study contribute to the advancement of Gaussian process
based Bayesian optimization to optimize the hyperparameters for autonomous
driving in RL, providing valuable insights for the development of efficient and
reliable autonomous driving systems.",2024-07-19,"Nihal Acharya Adde, Hanno Gottschalk, Andreas Ebert",http://arxiv.org/pdf/2407.14262v1,cs.LG
Coverage-aware and Reinforcement Learning Using Multi-agent Approach for HD Map QoS in a Realistic Environment,"One effective way to optimize the offloading process is by minimizing the
transmission time. This is particularly true in a Vehicular Adhoc Network
(VANET) where vehicles frequently download and upload High-definition (HD) map
data which requires constant updates. This implies that latency and throughput
requirements must be guaranteed by the wireless system. To achieve this,
adjustable contention windows (CW) allocation strategies in the standard
IEEE802.11p have been explored by numerous researchers. Nevertheless, their
implementations demand alterations to the existing standard which is not always
desirable. To address this issue, we proposed a Q-Learning algorithm that
operates at the application layer. Moreover, it could be deployed in any
wireless network thereby mitigating the compatibility issues. The solution has
demonstrated a better network performance with relatively fewer optimization
requirements as compared to the Deep Q Network (DQN) and Actor-Critic
algorithms. The same is observed while evaluating the model in a multi-agent
setup showing higher performance compared to the single-agent setup.",2024-07-19,"Jeffrey Redondo, Zhenhui Yuan, Nauman Aslam, Juan Zhang",http://arxiv.org/pdf/2408.03329v1,cs.LG
Voices in a Crowd: Searching for Clusters of Unique Perspectives,"Language models have been shown to reproduce underlying biases existing in
their training data, which is the majority perspective by default. Proposed
solutions aim to capture minority perspectives by either modelling annotator
disagreements or grouping annotators based on shared metadata, both of which
face significant challenges. We propose a framework that trains models without
encoding annotator metadata, extracts latent embeddings informed by annotator
behaviour, and creates clusters of similar opinions, that we refer to as
voices. Resulting clusters are validated post-hoc via internal and external
quantitative metrics, as well a qualitative analysis to identify the type of
voice that each cluster represents. Our results demonstrate the strong
generalisation capability of our framework, indicated by resulting clusters
being adequately robust, while also capturing minority perspectives based on
different demographic factors throughout two distinct datasets.",2024-07-19,"Nikolas Vitsakis, Amit Parekh, Ioannis Konstas",http://arxiv.org/pdf/2407.14259v1,cs.LG
Personalized Multi-tier Federated Learning,"The key challenge of personalized federated learning (PerFL) is to capture
the statistical heterogeneity properties of data with inexpensive
communications and gain customized performance for participating devices. To
address these, we introduced personalized federated learning in multi-tier
architecture (PerMFL) to obtain optimized and personalized local models when
there are known team structures across devices. We provide theoretical
guarantees of PerMFL, which offers linear convergence rates for smooth strongly
convex problems and sub-linear convergence rates for smooth non-convex
problems. We conduct numerical experiments demonstrating the robust empirical
performance of PerMFL, outperforming the state-of-the-art in multiple
personalized federated learning tasks.",2024-07-19,"Sourasekhar Banerjee, Ali Dadras, Alp Yurtsever, Monowar Bhuyan",http://arxiv.org/pdf/2407.14251v1,cs.LG
An Attention-based Representation Distillation Baseline for Multi-Label Continual Learning,"The field of Continual Learning (CL) has inspired numerous researchers over
the years, leading to increasingly advanced countermeasures to the issue of
catastrophic forgetting. Most studies have focused on the single-class
scenario, where each example comes with a single label. The recent literature
has successfully tackled such a setting, with impressive results. Differently,
we shift our attention to the multi-label scenario, as we feel it to be more
representative of real-world open problems. In our work, we show that existing
state-of-the-art CL methods fail to achieve satisfactory performance, thus
questioning the real advance claimed in recent years. Therefore, we assess both
old-style and novel strategies and propose, on top of them, an approach called
Selective Class Attention Distillation (SCAD). It relies on a knowledge
transfer technique that seeks to align the representations of the student
network -- which trains continuously and is subject to forgetting -- with the
teacher ones, which is pretrained and kept frozen. Importantly, our method is
able to selectively transfer the relevant information from the teacher to the
student, thereby preventing irrelevant information from harming the student's
performance during online training. To demonstrate the merits of our approach,
we conduct experiments on two different multi-label datasets, showing that our
method outperforms the current state-of-the-art Continual Learning methods. Our
findings highlight the importance of addressing the unique challenges posed by
multi-label environments in the field of Continual Learning. The code of SCAD
is available at https://github.com/aimagelab/SCAD-LOD-2024.",2024-07-19,"Martin Menabue, Emanuele Frascaroli, Matteo Boschini, Lorenzo Bonicelli, Angelo Porrello, Simone Calderara",http://arxiv.org/pdf/2407.14249v1,cs.LG
Realistic Evaluation of Test-Time Adaptation Algorithms: Unsupervised Hyperparameter Selection,"Test-Time Adaptation (TTA) has recently emerged as a promising strategy for
tackling the problem of machine learning model robustness under distribution
shifts by adapting the model during inference without access to any labels.
Because of task difficulty, hyperparameters strongly influence the
effectiveness of adaptation. However, the literature has provided little
exploration into optimal hyperparameter selection. In this work, we tackle this
problem by evaluating existing TTA methods using surrogate-based hp-selection
strategies (which do not assume access to the test labels) to obtain a more
realistic evaluation of their performance. We show that some of the recent
state-of-the-art methods exhibit inferior performance compared to the previous
algorithms when using our more realistic evaluation setup. Further, we show
that forgetting is still a problem in TTA as the only method that is robust to
hp-selection resets the model to the initial state at every step. We analyze
different types of unsupervised selection strategies, and while they work
reasonably well in most scenarios, the only strategies that work consistently
well use some kind of supervision (either by a limited number of annotated test
samples or by using pretraining data). Our findings underscore the need for
further research with more rigorous benchmarking by explicitly stating model
selection strategies, to facilitate which we open-source our code.",2024-07-19,"Sebastian Cygert, Damian Sójka, Tomasz Trzciński, Bartłomiej Twardowski",http://arxiv.org/pdf/2407.14231v1,cs.LG
ETSCL: An Evidence Theory-Based Supervised Contrastive Learning Framework for Multi-modal Glaucoma Grading,"Glaucoma is one of the leading causes of vision impairment. Digital imaging
techniques, such as color fundus photography (CFP) and optical coherence
tomography (OCT), provide quantitative and noninvasive methods for glaucoma
diagnosis. Recently, in the field of computer-aided glaucoma diagnosis,
multi-modality methods that integrate the CFP and OCT modalities have achieved
greater diagnostic accuracy compared to single-modality methods. However, it
remains challenging to extract reliable features due to the high similarity of
medical images and the unbalanced multi-modal data distribution. Moreover,
existing methods overlook the uncertainty estimation of different modalities,
leading to unreliable predictions. To address these challenges, we propose a
novel framework, namely ETSCL, which consists of a contrastive feature
extraction stage and a decision-level fusion stage. Specifically, the
supervised contrastive loss is employed to enhance the discriminative power in
the feature extraction process, resulting in more effective features. In
addition, we utilize the Frangi vesselness algorithm as a preprocessing step to
incorporate vessel information to assist in the prediction. In the
decision-level fusion stage, an evidence theory-based multi-modality classifier
is employed to combine multi-source information with uncertainty estimation.
Extensive experiments demonstrate that our method achieves state-of-the-art
performance. The code is available at
\url{https://github.com/master-Shix/ETSCL}.",2024-07-19,"Zhiyuan Yang, Bo Zhang, Yufei Shi, Ningze Zhong, Johnathan Loh, Huihui Fang, Yanwu Xu, Si Yong Yeo",http://arxiv.org/pdf/2407.14230v1,cs.LG
Shapley Pruning for Neural Network Compression,"Neural network pruning is a rich field with a variety of approaches. In this
work, we propose to connect the existing pruning concepts such as leave-one-out
pruning and oracle pruning and develop them into a more general Shapley
value-based framework that targets the compression of convolutional neural
networks. To allow for practical applications in utilizing the Shapley value,
this work presents the Shapley value approximations, and performs the
comparative analysis in terms of cost-benefit utility for the neural network
compression. The proposed ranks are evaluated against a new benchmark, Oracle
rank, constructed based on oracle sets. The broad experiments show that the
proposed normative ranking and its approximations show practical results,
obtaining state-of-the-art network compression.",2024-07-19,"Kamil Adamczewski, Yawei Li, Luc van Gool",http://arxiv.org/pdf/2407.15875v1,cs.LG
Domain Adaptation for Industrial Time-series Forecasting via Counterfactual Inference,"Industrial time-series, as a structural data responds to production process
information, can be utilized to perform data-driven decision-making for
effective monitoring of industrial production process. However, there are some
challenges for time-series forecasting in industry, e.g., predicting few-shot
caused by data shortage, and decision-confusing caused by unknown treatment
policy. To cope with the problems, we propose a novel causal domain adaptation
framework, Causal Domain Adaptation (CDA) forecaster to improve the performance
on the interested domain with limited data (target). Firstly, we analyze the
causality existing along with treatments, and thus ensure the shared causality
over time. Subsequently, we propose an answer-based attention mechanism to
achieve domain-invariant representation by the shared causality in both
domains. Then, a novel domain-adaptation is built to model treatments and
outcomes jointly training on source and target domain. The main insights are
that our designed answer-based attention mechanism allows the target domain to
leverage the existed causality in source time-series even with different
treatments, and our forecaster can predict the counterfactual outcome of
industrial time-series, meaning a guidance in production process. Compared with
commonly baselines, our method on real-world and synthetic oilfield datasets
demonstrates the effectiveness in across-domain prediction and the practicality
in guiding production process",2024-07-19,"Chao Min, Guoquan Wen, Jiangru Yuan, Jun Yi, Xing Guo",http://arxiv.org/pdf/2407.14214v1,cs.LG
Advanced Predictive Modeling for Enhanced Mortality Prediction in ICU Stroke Patients Using Clinical Data,"Background: Stroke is second-leading cause of disability and death among
adults. Approximately 17 million people suffer from a stroke annually, with
about 85% being ischemic strokes. Predicting mortality of ischemic stroke
patients in intensive care unit (ICU) is crucial for optimizing treatment
strategies, allocating resources, and improving survival rates. Methods: We
acquired data on ICU ischemic stroke patients from MIMIC-IV database, including
diagnoses, vital signs, laboratory tests, medications, procedures, treatments,
and clinical notes. Stroke patients were randomly divided into training (70%,
n=2441), test (15%, n=523), and validation (15%, n=523) sets. To address data
imbalances, we applied Synthetic Minority Over-sampling Technique (SMOTE). We
selected 30 features for model development, significantly reducing feature
number from 1095 used in the best study. We developed a deep learning model to
assess mortality risk and implemented several baseline machine learning models
for comparison. Results: XGB-DL model, combining XGBoost for feature selection
and deep learning, effectively minimized false positives. Model's AUROC
improved from 0.865 (95% CI: 0.821 - 0.905) on first day to 0.903 (95% CI:
0.868 - 0.936) by fourth day using data from 3,646 ICU mortality patients in
the MIMIC-IV database with 0.945 AUROC (95% CI: 0.944 - 0.947) during training.
Although other ML models also performed well in terms of AUROC, we chose Deep
Learning for its higher specificity. Conclusions: Through enhanced feature
selection and data cleaning, proposed model demonstrates a 13% AUROC
improvement compared to existing models while reducing feature number from 1095
in previous studies to 30.",2024-07-19,"Armin Abdollahi, Negin Ashrafi, Maryam Pishgar",http://arxiv.org/pdf/2407.14211v2,cs.LG
Fair Overlap Number of Balls (Fair-ONB): A Data-Morphology-based Undersampling Method for Bias Reduction,"One of the key issues regarding classification problems in Trustworthy
Artificial Intelligence is ensuring Fairness in the prediction of different
classes when protected (sensitive) features are present. Data quality is
critical in these cases, as biases in training data can be reflected in machine
learning, impacting human lives and failing to comply with current regulations.
One strategy to improve data quality and avoid these problems is preprocessing
the dataset. Instance selection via undersampling can foster balanced learning
of classes and protected feature values. Performing undersampling in class
overlap areas close to the decision boundary should bolster the impact on the
classifier. This work proposes Fair Overlap Number of Balls (Fair-ONB), an
undersampling method that harnesses the data morphology of the different data
groups (obtained from the combination of classes and protected feature values)
to perform guided undersampling in overlap areas. It employs attributes of the
ball coverage of the groups, such as the radius, number of covered instances
and density, to select the most suitable areas for undersampling and reduce
bias. Results show that the Fair-ONB method improves model Fairness with low
impact on the classifier's predictive performance.",2024-07-19,"José Daniel Pascual-Triana, Alberto Fernández, Paulo Novais, Francisco Herrera",http://arxiv.org/pdf/2407.14210v2,cs.LG
Unlearning Concepts from Text-to-Video Diffusion Models,"With the advancement of computer vision and natural language processing,
text-to-video generation, enabled by text-to-video diffusion models, has become
more prevalent. These models are trained using a large amount of data from the
internet. However, the training data often contain copyrighted content,
including cartoon character icons and artist styles, private portraits, and
unsafe videos. Since filtering the data and retraining the model is
challenging, methods for unlearning specific concepts from text-to-video
diffusion models have been investigated. However, due to the high computational
complexity and relative large optimization scale, there is little work on
unlearning methods for text-to-video diffusion models. We propose a novel
concept-unlearning method by transferring the unlearning capability of the text
encoder of text-to-image diffusion models to text-to-video diffusion models.
Specifically, the method optimizes the text encoder using few-shot unlearning,
where several generated images are used. We then use the optimized text encoder
in text-to-video diffusion models to generate videos. Our method costs low
computation resources and has small optimization scale. We discuss the
generated videos after unlearning a concept. The experiments demonstrates that
our method can unlearn copyrighted cartoon characters, artist styles, objects
and people's facial characteristics. Our method can unlearn a concept within
about 100 seconds on an RTX 3070. Since there was no concept unlearning method
for text-to-video diffusion models before, we make concept unlearning feasible
and more accessible in the text-to-video domain.",2024-07-19,"Shiqi Liu, Yihua Tan",http://arxiv.org/pdf/2407.14209v1,cs.LG
Longhorn: State Space Models are Amortized Online Learners,"Modern large language models are built on sequence modeling via next-token
prediction. While the Transformer remains the dominant architecture for
sequence modeling, its quadratic decoding complexity in sequence length poses a
major limitation. State-space models (SSMs) present a competitive alternative,
offering linear decoding efficiency while maintaining parallelism during
training. However, most existing SSMs rely on linear recurrence designs that
appear somewhat ad hoc. In this work, we explore SSM design through the lens of
online learning, conceptualizing SSMs as meta-modules for specific online
learning problems. This approach links SSM design to formulating precise online
learning objectives, with state transition rules derived from solving these
objectives. Based on this insight, we introduce a novel deep SSM architecture,
Longhorn, whose update resembles the closed-form solution for solving the
online associative recall problem. Our experimental results show that Longhorn
outperforms state-of-the-art SSMs, including the Mamba model, on standard
sequence modeling benchmarks, language modeling, and vision tasks.
Specifically, Longhorn achieves a 1.8x improvement in sample efficiency
compared to Mamba, and can extrapolate over contexts that are up to 16x longer
during inference.",2024-07-19,"Bo Liu, Rui Wang, Lemeng Wu, Yihao Feng, Peter Stone, Qiang Liu",http://arxiv.org/pdf/2407.14207v5,cs.LG
Watermark Smoothing Attacks against Language Models,"Watermarking is a key technique for detecting AI-generated text. In this
work, we study its vulnerabilities and introduce the Smoothing Attack, a novel
watermark removal method. By leveraging the relationship between the model's
confidence and watermark detectability, our attack selectively smoothes the
watermarked content, erasing watermark traces while preserving text quality. We
validate our attack on open-source models ranging from $1.3$B to $30$B
parameters on $10$ different watermarks, demonstrating its effectiveness. Our
findings expose critical weaknesses in existing watermarking schemes and
highlight the need for stronger defenses.",2024-07-19,"Hongyan Chang, Hamed Hassani, Reza Shokri",http://arxiv.org/pdf/2407.14206v2,cs.LG
Enhancing Variable Importance in Random Forests: A Novel Application of Global Sensitivity Analysis,"The present work provides an application of Global Sensitivity Analysis to
supervised machine learning methods such as Random Forests. These methods act
as black boxes, selecting features in high--dimensional data sets as to provide
accurate classifiers in terms of prediction when new data are fed into the
system. In supervised machine learning, predictors are generally ranked by
importance based on their contribution to the final prediction. Global
Sensitivity Analysis is primarily used in mathematical modelling to investigate
the effect of the uncertainties of the input variables on the output. We apply
it here as a novel way to rank the input features by their importance to the
explainability of the data generating process, shedding light on how the
response is determined by the dependence structure of its predictors. A
simulation study shows that our proposal can be used to explore what advances
can be achieved either in terms of efficiency, explanatory ability, or simply
by way of confirming existing results.",2024-07-19,"Giulia Vannucci, Roberta Siciliano, Andrea Saltelli",http://arxiv.org/pdf/2407.14194v1,cs.LG
Achieving Well-Informed Decision-Making in Drug Discovery: A Comprehensive Calibration Study using Neural Network-Based Structure-Activity Models,"In the drug discovery process, where experiments can be costly and
time-consuming, computational models that predict drug-target interactions are
valuable tools to accelerate the development of new therapeutic agents.
Estimating the uncertainty inherent in these neural network predictions
provides valuable information that facilitates optimal decision-making when
risk assessment is crucial. However, such models can be poorly calibrated,
which results in unreliable uncertainty estimates that do not reflect the true
predictive uncertainty. In this study, we compare different metrics, including
accuracy and calibration scores, used for model hyperparameter tuning to
investigate which model selection strategy achieves well-calibrated models.
Furthermore, we propose to use a computationally efficient Bayesian uncertainty
estimation method named Bayesian Linear Probing (BLP), which generates
Hamiltonian Monte Carlo (HMC) trajectories to obtain samples for the parameters
of a Bayesian Logistic Regression fitted to the hidden layer of the baseline
neural network. We report that BLP improves model calibration and achieves the
performance of common uncertainty quantification methods by combining the
benefits of uncertainty estimation and probability calibration methods.
Finally, we show that combining post hoc calibration method with
well-performing uncertainty quantification approaches can boost model accuracy
and calibration.",2024-07-19,"Hannah Rosa Friesacher, Ola Engkvist, Lewis Mervin, Yves Moreau, Adam Arany",http://arxiv.org/pdf/2407.14185v1,cs.LG
On Policy Evaluation Algorithms in Distributional Reinforcement Learning,"We introduce a novel class of algorithms to efficiently approximate the
unknown return distributions in policy evaluation problems from distributional
reinforcement learning (DRL). The proposed distributional dynamic programming
algorithms are suitable for underlying Markov decision processes (MDPs) having
an arbitrary probabilistic reward mechanism, including continuous reward
distributions with unbounded support being potentially heavy-tailed.
  For a plain instance of our proposed class of algorithms we prove error
bounds, both within Wasserstein and Kolmogorov--Smirnov distances. Furthermore,
for return distributions having probability density functions the algorithms
yield approximations for these densities; error bounds are given within
supremum norm. We introduce the concept of quantile-spline discretizations to
come up with algorithms showing promising results in simulation experiments.
  While the performance of our algorithms can rigorously be analysed they can
be seen as universal black box algorithms applicable to a large class of MDPs.
We also derive new properties of probability metrics commonly used in DRL on
which our quantitative analysis is based.",2024-07-19,"Julian Gerstenberg, Ralph Neininger, Denis Spiegel",http://arxiv.org/pdf/2407.14175v1,cs.LG
On Maximum Entropy Linear Feature Inversion,"We revisit the classical problem of inverting dimension-reducing linear
mappings using the maximum entropy (MaxEnt) criterion. In the literature,
solutions are problem-dependent, inconsistent, and use different entropy
measures. We propose a new unified approach that not only specializes to the
existing approaches, but offers solutions to new cases, such as when data
values are constrained to [0, 1], which has new applications in machine
learning.",2024-07-19,Paul M Baggenstoss,http://arxiv.org/pdf/2407.14166v1,cs.LG
Revisiting the Disequilibrium Issues in Tackling Heart Disease Classification Tasks,"In the field of heart disease classification, two primary obstacles arise.
Firstly, existing Electrocardiogram (ECG) datasets consistently demonstrate
imbalances and biases across various modalities. Secondly, these time-series
data consist of diverse lead signals, causing Convolutional Neural Networks
(CNNs) to become overfitting to the one with higher power, hence diminishing
the performance of the Deep Learning (DL) process. In addition, when facing an
imbalanced dataset, performance from such high-dimensional data may be
susceptible to overfitting. Current efforts predominantly focus on enhancing DL
models by designing novel architectures, despite these evident challenges,
seemingly overlooking the core issues, therefore hindering advancements in
heart disease classification. To address these obstacles, our proposed approach
introduces two straightforward and direct methods to enhance the classification
tasks. To address the high dimensionality issue, we employ a Channel-wise
Magnitude Equalizer (CME) on signal-encoded images. This approach reduces
redundancy in the feature data range, highlighting changes in the dataset.
Simultaneously, to counteract data imbalance, we propose the Inverted Weight
Logarithmic Loss (IWL) to alleviate imbalances among the data. When applying
IWL loss, the accuracy of state-of-the-art models (SOTA) increases up to 5% in
the CPSC2018 dataset. CME in combination with IWL also surpasses the
classification results of other baseline models from 5% to 10%.",2024-07-19,"Thao Hoang, Linh Nguyen, Khoi Do, Duong Nguyen, Viet Dung Nguyen",http://arxiv.org/pdf/2407.20249v1,cs.LG
Machine learning emulation of precipitation from km-scale regional climate simulations using a diffusion model,"High-resolution climate simulations are valuable for understanding climate
change impacts. This has motivated use of regional convection-permitting
climate models (CPMs), but these are very computationally expensive. We present
a convection-permitting model generative emulator (CPMGEM), to skilfully
emulate precipitation simulations by a 2.2km-resolution regional CPM at much
lower cost. This utilises a generative machine learning approach, a diffusion
model. It takes inputs at the 60km resolution of the driving global climate
model and downscales these to 8.8km, with daily-mean time resolution, capturing
the effect of convective processes represented in the CPM at these scales. The
emulator is trained on simulations over England and Wales from the United
Kingdom Climate Projections Local product, covering years between 1980 and 2080
following a high emissions scenario. The output precipitation has a similarly
realistic spatial structure and intensity distribution to the CPM simulations.
The emulator is stochastic, which improves the realism of samples. We show
evidence that the emulator has skill for extreme events with ~100 year return
times. It captures the main features of the simulated 21st century climate
change, but exhibits some error in the magnitude. We demonstrate successful
transfer from a ""perfect model"" training setting to application using GCM
variable inputs. We also show that the method can be useful in situations with
limited amounts of high-resolution data. Potential applications include
producing high-resolution precipitation predictions for large-ensemble climate
simulations and producing output based on different GCMs and climate change
scenarios to better sample uncertainty.",2024-07-19,"Henry Addison, Elizabeth Kendon, Suman Ravuri, Laurence Aitchison, Peter AG Watson",http://arxiv.org/pdf/2407.14158v2,cs.LG
Where is the Testbed for my Federated Learning Research?,"Progressing beyond centralized AI is of paramount importance, yet,
distributed AI solutions, in particular various federated learning (FL)
algorithms, are often not comprehensively assessed, which prevents the research
community from identifying the most promising approaches and practitioners from
being convinced that a certain solution is deployment-ready. The largest hurdle
towards FL algorithm evaluation is the difficulty of conducting real-world
experiments over a variety of FL client devices and different platforms, with
different datasets and data distribution, all while assessing various
dimensions of algorithm performance, such as inference accuracy, energy
consumption, and time to convergence, to name a few. In this paper, we present
CoLExT, a real-world testbed for FL research. CoLExT is designed to streamline
experimentation with custom FL algorithms in a rich testbed configuration
space, with a large number of heterogeneous edge devices, ranging from
single-board computers to smartphones, and provides real-time collection and
visualization of a variety of metrics through automatic instrumentation.
According to our evaluation, porting FL algorithms to CoLExT requires minimal
involvement from the developer, and the instrumentation introduces minimal
resource usage overhead. Furthermore, through an initial investigation
involving popular FL algorithms running on CoLExT, we reveal previously unknown
trade-offs, inefficiencies, and programming bugs.",2024-07-19,"Janez Božič, Amândio R. Faustino, Boris Radovič, Marco Canini, Veljko Pejović",http://arxiv.org/pdf/2407.14154v2,cs.LG
A Comparative Study of Deep Reinforcement Learning Models: DQN vs PPO vs A2C,"This study conducts a comparative analysis of three advanced Deep
Reinforcement Learning models: Deep Q-Networks (DQN), Proximal Policy
Optimization (PPO), and Advantage Actor-Critic (A2C), within the BreakOut Atari
game environment. Our research assesses the performance and effectiveness of
these models in a controlled setting. Through rigorous experimentation, we
examine each model's learning efficiency, strategy development, and
adaptability under dynamic game conditions. The findings provide critical
insights into the practical applications of these models in game-based learning
environments and contribute to the broader understanding of their capabilities.
The code is publicly available at github.com/Neilus03/DRL_comparative_study.",2024-07-19,"Neil De La Fuente, Daniel A. Vidal Guerra",http://arxiv.org/pdf/2407.14151v1,cs.LG
Class-Incremental Learning with CLIP: Adaptive Representation Adjustment and Parameter Fusion,"Class-incremental learning is a challenging problem, where the goal is to
train a model that can classify data from an increasing number of classes over
time. With the advancement of vision-language pre-trained models such as CLIP,
they demonstrate good generalization ability that allows them to excel in
class-incremental learning with completely frozen parameters. However, further
adaptation to downstream tasks by simply fine-tuning the model leads to severe
forgetting. Most existing works with pre-trained models assume that the
forgetting of old classes is uniform when the model acquires new knowledge. In
this paper, we propose a method named Adaptive Representation Adjustment and
Parameter Fusion (RAPF). During training for new data, we measure the influence
of new classes on old ones and adjust the representations, using textual
features. After training, we employ a decomposed parameter fusion to further
mitigate forgetting during adapter module fine-tuning. Experiments on several
conventional benchmarks show that our method achieves state-of-the-art results.
Our code is available at \url{https://github.com/linlany/RAPF}.",2024-07-19,"Linlan Huang, Xusheng Cao, Haori Lu, Xialei Liu",http://arxiv.org/pdf/2407.14143v1,cs.LG
Early Preparation Pays Off: New Classifier Pre-tuning for Class Incremental Semantic Segmentation,"Class incremental semantic segmentation aims to preserve old knowledge while
learning new tasks, however, it is impeded by catastrophic forgetting and
background shift issues. Prior works indicate the pivotal importance of
initializing new classifiers and mainly focus on transferring knowledge from
the background classifier or preparing classifiers for future classes,
neglecting the flexibility and variance of new classifiers. In this paper, we
propose a new classifier pre-tuning~(NeST) method applied before the formal
training process, learning a transformation from old classifiers to generate
new classifiers for initialization rather than directly tuning the parameters
of new classifiers. Our method can make new classifiers align with the backbone
and adapt to the new data, preventing drastic changes in the feature extractor
when learning new classes. Besides, we design a strategy considering the
cross-task class similarity to initialize matrices used in the transformation,
helping achieve the stability-plasticity trade-off. Experiments on Pascal VOC
2012 and ADE20K datasets show that the proposed strategy can significantly
improve the performance of previous methods. The code is available at
\url{https://github.com/zhengyuan-xie/ECCV24_NeST}.",2024-07-19,"Zhengyuan Xie, Haiquan Lu, Jia-wen Xiao, Enguang Wang, Le Zhang, Xialei Liu",http://arxiv.org/pdf/2407.14142v1,cs.LG
How Homogenizing the Channel-wise Magnitude Can Enhance EEG Classification Model?,"A significant challenge in the electroencephalogram EEG lies in the fact that
current data representations involve multiple electrode signals, resulting in
data redundancy and dominant lead information. However extensive research
conducted on EEG classification focuses on designing model architectures
without tackling the underlying issues. Otherwise, there has been a notable gap
in addressing data preprocessing for EEG, leading to considerable computational
overhead in Deep Learning (DL) processes. In light of these issues, we propose
a simple yet effective approach for EEG data pre-processing. Our method first
transforms the EEG data into an encoded image by an Inverted Channel-wise
Magnitude Homogenization (ICWMH) to mitigate inter-channel biases. Next, we
apply the edge detection technique on the EEG-encoded image combined with skip
connection to emphasize the most significant transitions in the data while
preserving structural and invariant information. By doing so, we can improve
the EEG learning process efficiently without using a huge DL network. Our
experimental evaluations reveal that we can significantly improve (i.e., from
2% to 5%) over current baselines.",2024-07-19,"Huyen Ngo, Khoi Do, Duong Nguyen, Viet Dung Nguyen, Lan Dang",http://arxiv.org/pdf/2407.20247v1,cs.LG
Comparing and Contrasting Deep Learning Weather Prediction Backbones on Navier-Stokes and Atmospheric Dynamics,"Remarkable progress in the development of Deep Learning Weather Prediction
(DLWP) models positions them to become competitive with traditional numerical
weather prediction (NWP) models. Indeed, a wide number of DLWP architectures --
based on various backbones, including U-Net, Transformer, Graph Neural Network
(GNN), and Fourier Neural Operator (FNO) -- have demonstrated their potential
at forecasting atmospheric states. However, due to differences in training
protocols, forecast horizons, and data choices, it remains unclear which (if
any) of these methods and architectures are most suitable for weather
forecasting and for future model development. Here, we step back and provide a
detailed empirical analysis, under controlled conditions, comparing and
contrasting the most prominent DLWP models, along with their backbones. We
accomplish this by predicting synthetic two-dimensional incompressible
Navier-Stokes and real-world global weather dynamics. In terms of accuracy,
memory consumption, and runtime, our results illustrate various tradeoffs. For
example, on synthetic data, we observe favorable performance of FNO; and on the
real-world WeatherBench dataset, our results demonstrate the suitability of
ConvLSTM and SwinTransformer for short-to-mid-ranged forecasts. For long-ranged
weather rollouts of up to 365 days, we observe superior stability and physical
soundness in architectures that formulate a spherical data representation,
i.e., GraphCast and Spherical FNO. In addition, we observe that all of these
model backbones ""saturate,"" i.e., none of them exhibit so-called neural
scaling, which highlights an important direction for future work on these and
related models. The code is available at
https://github.com/amazon-science/dlwp-benchmark.",2024-07-19,"Matthias Karlbauer, Danielle C. Maddix, Abdul Fatir Ansari, Boran Han, Gaurav Gupta, Yuyang Wang, Andrew Stuart, Michael W. Mahoney",http://arxiv.org/pdf/2407.14129v2,cs.LG
Shape and Style GAN-based Multispectral Data Augmentation for Crop/Weed Segmentation in Precision Farming,"The use of deep learning methods for precision farming is gaining increasing
interest. However, collecting training data in this application field is
particularly challenging and costly due to the need of acquiring information
during the different growing stages of the cultivation of interest. In this
paper, we present a method for data augmentation that uses two GANs to create
artificial images to augment the training data. To obtain a higher image
quality, instead of re-creating the entire scene, we take original images and
replace only the patches containing objects of interest with artificial ones
containing new objects with different shapes and styles. In doing this, we take
into account both the foreground (i.e., crop samples) and the background (i.e.,
the soil) of the patches. Quantitative experiments, conducted on publicly
available datasets, demonstrate the effectiveness of the proposed approach. The
source code and data discussed in this work are available as open source.",2024-07-19,"Mulham Fawakherji, Vincenzo Suriani, Daniele Nardi, Domenico Daniele Bloisi",http://arxiv.org/pdf/2407.14119v1,cs.LG
AuditNet: A Conversational AI-based Security Assistant [DEMO],"In the age of information overload, professionals across various fields face
the challenge of navigating vast amounts of documentation and ever-evolving
standards. Ensuring compliance with standards, regulations, and contractual
obligations is a critical yet complex task across various professional fields.
We propose a versatile conversational AI assistant framework designed to
facilitate compliance checking on the go, in diverse domains, including but not
limited to network infrastructure, legal contracts, educational standards,
environmental regulations, and government policies. By leveraging
retrieval-augmented generation using large language models, our framework
automates the review, indexing, and retrieval of relevant, context-aware
information, streamlining the process of verifying adherence to established
guidelines and requirements. This AI assistant not only reduces the manual
effort involved in compliance checks but also enhances accuracy and efficiency,
supporting professionals in maintaining high standards of practice and ensuring
regulatory compliance in their respective fields. We propose and demonstrate
AuditNet, the first conversational AI security assistant designed to assist IoT
network security experts by providing instant access to security standards,
policies, and regulations.",2024-07-19,"Shohreh Deldari, Mohammad Goudarzi, Aditya Joshi, Arash Shaghaghi, Simon Finn, Flora D. Salim, Sanjay Jha",http://arxiv.org/pdf/2407.14116v1,cs.LG
A Mirror Descent-Based Algorithm for Corruption-Tolerant Distributed Gradient Descent,"Distributed gradient descent algorithms have come to the fore in modern
machine learning, especially in parallelizing the handling of large datasets
that are distributed across several workers. However, scant attention has been
paid to analyzing the behavior of distributed gradient descent algorithms in
the presence of adversarial corruptions instead of random noise. In this paper,
we formulate a novel problem in which adversarial corruptions are present in a
distributed learning system. We show how to use ideas from (lazy) mirror
descent to design a corruption-tolerant distributed optimization algorithm.
Extensive convergence analysis for (strongly) convex loss functions is provided
for different choices of the stepsize. We carefully optimize the stepsize
schedule to accelerate the convergence of the algorithm, while at the same time
amortizing the effect of the corruption over time. Experiments based on linear
regression, support vector classification, and softmax classification on the
MNIST dataset corroborate our theoretical findings.",2024-07-19,"Shuche Wang, Vincent Y. F. Tan",http://arxiv.org/pdf/2407.14111v2,cs.LG
TorchGT: A Holistic System for Large-scale Graph Transformer Training,"Graph Transformer is a new architecture that surpasses GNNs in graph
learning. While there emerge inspiring algorithm advancements, their practical
adoption is still limited, particularly on real-world graphs involving up to
millions of nodes. We observe existing graph transformers fail on large-scale
graphs mainly due to heavy computation, limited scalability and inferior model
quality. Motivated by these observations, we propose TorchGT, the first
efficient, scalable, and accurate graph transformer training system. TorchGT
optimizes training at different levels. At algorithm level, by harnessing the
graph sparsity, TorchGT introduces a Dual-interleaved Attention which is
computation-efficient and accuracy-maintained. At runtime level, TorchGT scales
training across workers with a communication-light Cluster-aware Graph
Parallelism. At kernel level, an Elastic Computation Reformation further
optimizes the computation by reducing memory access latency in a dynamic way.
Extensive experiments demonstrate that TorchGT boosts training by up to 62.7x
and supports graph sequence lengths of up to 1M.",2024-07-19,"Meng Zhang, Jie Sun, Qinghao Hu, Peng Sun, Zeke Wang, Yonggang Wen, Tianwei Zhang",http://arxiv.org/pdf/2407.14106v1,cs.LG
ParamsDrag: Interactive Parameter Space Exploration via Image-Space Dragging,"Numerical simulation serves as a cornerstone in scientific modeling, yet the
process of fine-tuning simulation parameters poses significant challenges.
Conventionally, parameter adjustment relies on extensive numerical simulations,
data analysis, and expert insights, resulting in substantial computational
costs and low efficiency. The emergence of deep learning in recent years has
provided promising avenues for more efficient exploration of parameter spaces.
However, existing approaches often lack intuitive methods for precise parameter
adjustment and optimization. To tackle these challenges, we introduce
ParamsDrag, a model that facilitates parameter space exploration through direct
interaction with visualizations. Inspired by DragGAN, our ParamsDrag model
operates in three steps. First, the generative component of ParamsDrag
generates visualizations based on the input simulation parameters. Second, by
directly dragging structure-related features in the visualizations, users can
intuitively understand the controlling effect of different parameters. Third,
with the understanding from the earlier step, users can steer ParamsDrag to
produce dynamic visual outcomes. Through experiments conducted on real-world
simulations and comparisons with state-of-the-art deep learning-based
approaches, we demonstrate the efficacy of our solution.",2024-07-19,"Guan Li, Yang Liu, Guihua Shan, Shiyu Cheng, Weiqun Cao, Junpeng Wang, Ko-Chih Wang",http://arxiv.org/pdf/2407.14100v1,cs.LG
Forward-Forward Learning achieves Highly Selective Latent Representations for Out-of-Distribution Detection in Fully Spiking Neural Networks,"In recent years, Artificial Intelligence (AI) models have achieved remarkable
success across various domains, yet challenges persist in two critical areas:
ensuring robustness against uncertain inputs and drastically increasing model
efficiency during training and inference. Spiking Neural Networks (SNNs),
inspired by biological systems, offer a promising avenue for overcoming these
limitations. By operating in an event-driven manner, SNNs achieve low energy
consumption and can naturally implement biological methods known for their high
noise tolerance. In this work, we explore the potential of the spiking
Forward-Forward Algorithm (FFA) to address these challenges, leveraging its
representational properties for both Out-of-Distribution (OoD) detection and
interpretability. To achieve this, we exploit the sparse and highly specialized
neural latent space of FF networks to estimate the likelihood of a sample
belonging to the training distribution. Additionally, we propose a novel,
gradient-free attribution method to detect features that drive a sample away
from class distributions, addressing the challenges posed by the lack of
gradients in most visual interpretability methods for spiking models. We
evaluate our OoD detection algorithm on well-known image datasets (e.g.,
Omniglot, Not-MNIST, CIFAR10), outperforming previous methods proposed in the
recent literature for OoD detection in spiking networks. Furthermore, our
attribution method precisely identifies salient OoD features, such as artifacts
or missing regions, hence providing a visual explanatory interface for the user
to understand why unknown inputs are identified as such by the proposed method.",2024-07-19,"Erik B. Terres-Escudero, Javier Del Ser, Aitor Martínez-Seras, Pablo Garcia-Bringas",http://arxiv.org/pdf/2407.14097v2,cs.LG
User-Creator Feature Polarization in Recommender Systems with Dual Influence,"Recommender systems serve the dual purpose of presenting relevant content to
users and helping content creators reach their target audience. The dual nature
of these systems naturally influences both users and creators: users'
preferences are affected by the items they are recommended, while creators may
be incentivized to alter their content to attract more users. We define a
model, called user-creator feature dynamics, to capture the dual influence of
recommender systems. We prove that a recommender system with dual influence is
guaranteed to polarize, causing diversity loss in the system. We then
investigate, both theoretically and empirically, approaches for mitigating
polarization and promoting diversity in recommender systems. Unexpectedly, we
find that common diversity-promoting approaches do not work in the presence of
dual influence, while relevancy-optimizing methods like top-$k$ truncation can
prevent polarization and improve diversity of the system.",2024-07-19,"Tao Lin, Kun Jin, Andrew Estornell, Xiaoying Zhang, Yiling Chen, Yang Liu",http://arxiv.org/pdf/2407.14094v2,cs.LG
CRMSP: A Semi-supervised Approach for Key Information Extraction with Class-Rebalancing and Merged Semantic Pseudo-Labeling,"There is a growing demand in the field of KIE (Key Information Extraction) to
apply semi-supervised learning to save manpower and costs, as training document
data using fully-supervised methods requires labor-intensive manual annotation.
The main challenges of applying SSL in the KIE are (1) underestimation of the
confidence of tail classes in the long-tailed distribution and (2) difficulty
in achieving intra-class compactness and inter-class separability of tail
features. To address these challenges, we propose a novel semi-supervised
approach for KIE with Class-Rebalancing and Merged Semantic Pseudo-Labeling
(CRMSP). Firstly, the Class-Rebalancing Pseudo-Labeling (CRP) module introduces
a reweighting factor to rebalance pseudo-labels, increasing attention to tail
classes. Secondly, we propose the Merged Semantic Pseudo-Labeling (MSP) module
to cluster tail features of unlabeled data by assigning samples to Merged
Prototypes (MP). Additionally, we designed a new contrastive loss specifically
for MSP. Extensive experimental results on three well-known benchmarks
demonstrate that CRMSP achieves state-of-the-art performance. Remarkably, CRMSP
achieves 3.24% f1-score improvement over state-of-the-art on the CORD.",2024-07-19,"Qi Zhang, Yonghong Song, Pengcheng Guo, Yangyang Hui",http://arxiv.org/pdf/2407.15873v1,cs.LG
DisenSemi: Semi-supervised Graph Classification via Disentangled Representation Learning,"Graph classification is a critical task in numerous multimedia applications,
where graphs are employed to represent diverse types of multimedia data,
including images, videos, and social networks. Nevertheless, in real-world
scenarios, labeled graph data can be limited or scarce. To address this issue,
we focus on the problem of semi-supervised graph classification, which involves
both supervised and unsupervised models learning from labeled and unlabeled
data. In contrast to recent approaches that transfer the entire knowledge from
the unsupervised model to the supervised one, we argue that an effective
transfer should only retain the relevant semantics that align well with the
supervised task. In this paper, we propose a novel framework named DisenSemi,
which learns disentangled representation for semi-supervised graph
classification. Specifically, a disentangled graph encoder is proposed to
generate factor-wise graph representations for both supervised and unsupervised
models. Then we train two models via supervised objective and mutual
information (MI)-based constraints respectively. To ensure the meaningful
transfer of knowledge from the unsupervised encoder to the supervised one, we
further define an MI-based disentangled consistency regularization between two
models and identify the corresponding rationale that aligns well with the
current graph classification task. Experimental results on a range of publicly
accessible datasets reveal the effectiveness of our DisenSemi.",2024-07-19,"Yifan Wang, Xiao Luo, Chong Chen, Xian-Sheng Hua, Ming Zhang, Wei Ju",http://arxiv.org/pdf/2407.14081v2,cs.LG
Domain-Specific Pretraining of Language Models: A Comparative Study in the Medical Field,"There are many cases where LLMs are used for specific tasks in a single
domain. These usually require less general, but more domain-specific knowledge.
Highly capable, general-purpose state-of-the-art language models like GPT-4 or
Claude-3-opus can often be used for such tasks, but they are very large and
cannot be run locally, even if they were not proprietary. This can be a problem
when working with sensitive data. This paper focuses on domain-specific and
mixed-domain pretraining as potentially more efficient methods than general
pretraining for specialized language models. We will take a look at work
related to domain-specific pretraining, specifically in the medical area, and
compare benchmark results of specialized language models to general-purpose
language models.",2024-07-19,Tobias Kerner,http://arxiv.org/pdf/2407.14076v2,cs.LG
360VFI: A Dataset and Benchmark for Omnidirectional Video Frame Interpolation,"Head-mounted 360{\deg} displays and portable 360{\deg} cameras have
significantly progressed, providing viewers a realistic and immersive
experience. However, many omnidirectional videos have low frame rates that can
lead to visual fatigue, and the prevailing plane frame interpolation
methodologies are unsuitable for omnidirectional video interpolation because
they are designed solely for traditional videos. This paper introduces the
benchmark dataset, 360VFI, for Omnidirectional Video Frame Interpolation. We
present a practical implementation that introduces a distortion prior from
omnidirectional video into the network to modulate distortions. Specifically,
we propose a pyramid distortion-sensitive feature extractor that uses the
unique characteristics of equirectangular projection (ERP) format as prior
information. Moreover, we devise a decoder that uses an affine transformation
to further facilitate the synthesis of intermediate frames. 360VFI is the first
dataset and benchmark that explores the challenge of Omnidirectional Video
Frame Interpolation. Through our benchmark analysis, we present four different
distortion condition scenes in the proposed 360VFI dataset to evaluate the
challenges triggered by distortion during interpolation. Besides, experimental
results demonstrate that Omnidirectional Video Interpolation can be effectively
improved by modeling for omnidirectional distortion.",2024-07-19,"Wenxuan Lu, Mengshun Hu, Yansheng Qiu, Liang Liao, Zheng Wang",http://arxiv.org/pdf/2407.14066v3,cs.LG
MSCT: Addressing Time-Varying Confounding with Marginal Structural Causal Transformer for Counterfactual Post-Crash Traffic Prediction,"Traffic crashes profoundly impede traffic efficiency and pose economic
challenges. Accurate prediction of post-crash traffic status provides essential
information for evaluating traffic perturbations and developing effective
solutions. Previous studies have established a series of deep learning models
to predict post-crash traffic conditions, however, these correlation-based
methods cannot accommodate the biases caused by time-varying confounders and
the heterogeneous effects of crashes. The post-crash traffic prediction model
needs to estimate the counterfactual traffic speed response to hypothetical
crashes under various conditions, which demonstrates the necessity of
understanding the causal relationship between traffic factors. Therefore, this
paper presents the Marginal Structural Causal Transformer (MSCT), a novel deep
learning model designed for counterfactual post-crash traffic prediction. To
address the issue of time-varying confounding bias, MSCT incorporates a
structure inspired by Marginal Structural Models and introduces a balanced loss
function to facilitate learning of invariant causal features. The proposed
model is treatment-aware, with a specific focus on comprehending and predicting
traffic speed under hypothetical crash intervention strategies. In the absence
of ground-truth data, a synthetic data generation procedure is proposed to
emulate the causal mechanism between traffic speed, crashes, and covariates.
The model is validated using both synthetic and real-world data, demonstrating
that MSCT outperforms state-of-the-art models in multi-step-ahead prediction
performance. This study also systematically analyzes the impact of time-varying
confounding bias and dataset distribution on model performance, contributing
valuable insights into counterfactual prediction for intelligent transportation
systems.",2024-07-19,"Shuang Li, Ziyuan Pu, Nan Zhang, Duxin Chen, Lu Dong, Daniel J. Graham, Yinhai Wang",http://arxiv.org/pdf/2407.14065v1,cs.LG
Towards the Causal Complete Cause of Multi-Modal Representation Learning,"Multi-Modal Learning (MML) aims to learn effective representations across
modalities for accurate predictions. Existing methods typically focus on
modality consistency and specificity to learn effective representations.
However, from a causal perspective, they may lead to representations that
contain insufficient and unnecessary information. To address this, we propose
that effective MML representations should be causally sufficient and necessary.
Considering practical issues like spurious correlations and modality conflicts,
we relax the exogeneity and monotonicity assumptions prevalent in prior works
and explore the concepts specific to MML, i.e., Causal Complete Cause $C^3$. We
begin by defining $C^3$, which quantifies the probability of representations
being causally sufficient and necessary. We then discuss the identifiability of
$C^3$ and introduce an instrumental variable to support identifying $C^3$ with
non-exogeneity and non-monotonicity. Building on this, we conduct the $C^3$
measurement, i.e., \(C^3\) risk. We propose a twin network to estimate it
through (i) the real-world branch: utilizing the instrumental variable for
sufficiency, and (ii) the hypothetical-world branch: applying gradient-based
counterfactual modeling for necessity. Theoretical analyses confirm its
reliability. Based on these results, we propose $C^3$ Regularization, a
plug-and-play method that enforces the causal completeness of the learned
representations by minimizing $C^3$ risk. Extensive experiments demonstrate its
effectiveness.",2024-07-19,"Jingyao Wang, Siyu Zhao, Wenwen Qiang, Jiangmeng Li, Changwen Zheng, Fuchun Sun, Hui Xiong",http://arxiv.org/pdf/2407.14058v6,cs.LG
LazyLLM: Dynamic Token Pruning for Efficient Long Context LLM Inference,"The inference of transformer-based large language models consists of two
sequential stages: 1) a prefilling stage to compute the KV cache of prompts and
generate the first token, and 2) a decoding stage to generate subsequent
tokens. For long prompts, the KV cache must be computed for all tokens during
the prefilling stage, which can significantly increase the time needed to
generate the first token. Consequently, the prefilling stage may become a
bottleneck in the generation process. An open question remains whether all
prompt tokens are essential for generating the first token. To answer this, we
introduce a novel method, LazyLLM, that selectively computes the KV for tokens
important for the next token prediction in both the prefilling and decoding
stages. Contrary to static pruning approaches that prune the prompt at once,
LazyLLM allows language models to dynamically select different subsets of
tokens from the context in different generation steps, even though they might
be pruned in previous steps. Extensive experiments on standard datasets across
various tasks demonstrate that LazyLLM is a generic method that can be
seamlessly integrated with existing language models to significantly accelerate
the generation without fine-tuning. For instance, in the multi-document
question-answering task, LazyLLM accelerates the prefilling stage of the LLama
2 7B model by 2.34x while maintaining accuracy.",2024-07-19,"Qichen Fu, Minsik Cho, Thomas Merth, Sachin Mehta, Mohammad Rastegari, Mahyar Najibi",http://arxiv.org/pdf/2407.14057v1,cs.LG
Rasa: Building Expressive Speech Synthesis Systems for Indian Languages in Low-resource Settings,"We release Rasa, the first multilingual expressive TTS dataset for any Indian
language, which contains 10 hours of neutral speech and 1-3 hours of expressive
speech for each of the 6 Ekman emotions covering 3 languages: Assamese,
Bengali, & Tamil. Our ablation studies reveal that just 1 hour of neutral and
30 minutes of expressive data can yield a Fair system as indicated by MUSHRA
scores. Increasing neutral data to 10 hours, with minimal expressive data,
significantly enhances expressiveness. This offers a practical recipe for
resource-constrained languages, prioritizing easily obtainable neutral data
alongside smaller amounts of expressive data. We show the importance of
syllabically balanced data and pooling emotions to enhance expressiveness. We
also highlight challenges in generating specific emotions, e.g., fear and
surprise.",2024-07-19,"Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra",http://arxiv.org/pdf/2407.14056v2,cs.LG
Quantum Hamiltonian Embedding of Images for Data Reuploading Classifiers,"When applying quantum computing to machine learning tasks, one of the first
considerations is the design of the quantum machine learning model itself.
Conventionally, the design of quantum machine learning algorithms relies on the
``quantisation"" of classical learning algorithms, such as using quantum linear
algebra to implement important subroutines of classical algorithms, if not the
entire algorithm, seeking to achieve quantum advantage through possible
run-time accelerations brought by quantum computing. However, recent research
has started questioning whether quantum advantage via speedup is the right goal
for quantum machine learning [1]. Research also has been undertaken to exploit
properties that are unique to quantum systems, such as quantum contextuality,
to better design quantum machine learning models [2]. In this paper, we take an
alternative approach by incorporating the heuristics and empirical evidences
from the design of classical deep learning algorithms to the design of quantum
neural networks. We first construct a model based on the data reuploading
circuit [3] with the quantum Hamiltonian data embedding unitary [4]. Through
numerical experiments on images datasets, including the famous MNIST and
FashionMNIST datasets, we demonstrate that our model outperforms the quantum
convolutional neural network (QCNN)[5] by a large margin (up to over 40% on
MNIST test set). Based on the model design process and numerical results, we
then laid out six principles for designing quantum machine learning models,
especially quantum neural networks.",2024-07-19,"Peiyong Wang, Casey R. Myers, Lloyd C. L. Hollenberg, Udaya Parampalli",http://arxiv.org/pdf/2407.14055v2,cs.LG
Generative Language Model for Catalyst Discovery,"Discovery of novel and promising materials is a critical challenge in the
field of chemistry and material science, traditionally approached through
methodologies ranging from trial-and-error to machine learning-driven inverse
design. Recent studies suggest that transformer-based language models can be
utilized as material generative models to expand chemical space and explore
materials with desired properties. In this work, we introduce the Catalyst
Generative Pretrained Transformer (CatGPT), trained to generate string
representations of inorganic catalyst structures from a vast chemical space.
CatGPT not only demonstrates high performance in generating valid and accurate
catalyst structures but also serves as a foundation model for generating
desired types of catalysts by fine-tuning with sparse and specified datasets.
As an example, we fine-tuned the pretrained CatGPT using a binary alloy
catalyst dataset designed for screening two-electron oxygen reduction reaction
(2e-ORR) catalyst and generate catalyst structures specialized for 2e-ORR. Our
work demonstrates the potential of language models as generative tools for
catalyst discovery.",2024-07-19,"Dong Hyeon Mok, Seoin Back",http://arxiv.org/pdf/2407.14040v1,cs.LG
BERTer: The Efficient One,"We explore advanced fine-tuning techniques to boost BERT's performance in
sentiment analysis, paraphrase detection, and semantic textual similarity. Our
approach leverages SMART regularization to combat overfitting, improves
hyperparameter choices, employs a cross-embedding Siamese architecture for
improved sentence embeddings, and introduces innovative early exiting methods.
Our fine-tuning findings currently reveal substantial improvements in model
efficiency and effectiveness when combining multiple fine-tuning architectures,
achieving a state-of-the-art performance score of on the test set, surpassing
current benchmarks and highlighting BERT's adaptability in multifaceted
linguistic tasks.",2024-07-19,"Pradyumna Saligram, Andrew Lanpouthakoun",http://arxiv.org/pdf/2407.14039v1,cs.LG
HeCiX: Integrating Knowledge Graphs and Large Language Models for Biomedical Research,"Despite advancements in drug development strategies, 90% of clinical trials
fail. This suggests overlooked aspects in target validation and drug
optimization. In order to address this, we introduce HeCiX-KG,
Hetionet-Clinicaltrials neXus Knowledge Graph, a novel fusion of data from
ClinicalTrials.gov and Hetionet in a single knowledge graph. HeCiX-KG combines
data on previously conducted clinical trials from ClinicalTrials.gov, and
domain expertise on diseases and genes from Hetionet. This offers a thorough
resource for clinical researchers. Further, we introduce HeCiX, a system that
uses LangChain to integrate HeCiX-KG with GPT-4, and increase its usability.
HeCiX shows high performance during evaluation against a range of clinically
relevant issues, proving this model to be promising for enhancing the
effectiveness of clinical research. Thus, this approach provides a more
holistic view of clinical trials and existing biological data.",2024-07-19,"Prerana Sanjay Kulkarni, Muskaan Jain, Disha Sheshanarayana, Srinivasan Parthiban",http://arxiv.org/pdf/2407.14030v1,cs.LG
PASS++: A Dual Bias Reduction Framework for Non-Exemplar Class-Incremental Learning,"Class-incremental learning (CIL) aims to recognize new classes incrementally
while maintaining the discriminability of old classes. Most existing CIL
methods are exemplar-based, i.e., storing a part of old data for retraining.
Without relearning old data, those methods suffer from catastrophic forgetting.
In this paper, we figure out two inherent problems in CIL, i.e., representation
bias and classifier bias, that cause catastrophic forgetting of old knowledge.
To address these two biases, we present a simple and novel dual bias reduction
framework that employs self-supervised transformation (SST) in input space and
prototype augmentation (protoAug) in deep feature space. On the one hand, SST
alleviates the representation bias by learning generic and diverse
representations that can transfer across different tasks. On the other hand,
protoAug overcomes the classifier bias by explicitly or implicitly augmenting
prototypes of old classes in the deep feature space, which poses tighter
constraints to maintain previously learned decision boundaries. We further
propose hardness-aware prototype augmentation and multi-view ensemble
strategies, leading to significant improvements. The proposed framework can be
easily integrated with pre-trained models. Without storing any samples of old
classes, our method can perform comparably with state-of-the-art exemplar-based
approaches which store plenty of old data. We hope to draw the attention of
researchers back to non-exemplar CIL by rethinking the necessity of storing old
samples in CIL.",2024-07-19,"Fei Zhu, Xu-Yao Zhang, Zhen Cheng, Cheng-Lin Liu",http://arxiv.org/pdf/2407.14029v1,cs.LG
Causal Inference with Complex Treatments: A Survey,"Causal inference plays an important role in explanatory analysis and decision
making across various fields like statistics, marketing, health care, and
education. Its main task is to estimate treatment effects and make intervention
policies. Traditionally, most of the previous works typically focus on the
binary treatment setting that there is only one treatment for a unit to adopt
or not. However, in practice, the treatment can be much more complex,
encompassing multi-valued, continuous, or bundle options. In this paper, we
refer to these as complex treatments and systematically and comprehensively
review the causal inference methods for addressing them. First, we formally
revisit the problem definition, the basic assumptions, and their possible
variations under specific conditions. Second, we sequentially review the
related methods for multi-valued, continuous, and bundled treatment settings.
In each situation, we tentatively divide the methods into two categories: those
conforming to the unconfoundedness assumption and those violating it.
Subsequently, we discuss the available datasets and open-source codes. Finally,
we provide a brief summary of these works and suggest potential directions for
future research.",2024-07-19,"Yingrong Wang, Haoxuan Li, Minqin Zhu, Anpeng Wu, Ruoxuan Xiong, Fei Wu, Kun Kuang",http://arxiv.org/pdf/2407.14022v1,cs.LG
NeuroBind: Towards Unified Multimodal Representations for Neural Signals,"Understanding neural activity and information representation is crucial for
advancing knowledge of brain function and cognition. Neural activity, measured
through techniques like electrophysiology and neuroimaging, reflects various
aspects of information processing. Recent advances in deep neural networks
offer new approaches to analyzing these signals using pre-trained models.
However, challenges arise due to discrepancies between different neural signal
modalities and the limited scale of high-quality neural data. To address these
challenges, we present NeuroBind, a general representation that unifies
multiple brain signal types, including EEG, fMRI, calcium imaging, and spiking
data. To achieve this, we align neural signals in these image-paired neural
datasets to pre-trained vision-language embeddings. Neurobind is the first
model that studies different neural modalities interconnectedly and is able to
leverage high-resource modality models for various neuroscience tasks. We also
showed that by combining information from different neural signal modalities,
NeuroBind enhances downstream performance, demonstrating the effectiveness of
the complementary strengths of different neural modalities. As a result, we can
leverage multiple types of neural signals mapped to the same space to improve
downstream tasks, and demonstrate the complementary strengths of different
neural modalities. This approach holds significant potential for advancing
neuroscience research, improving AI systems, and developing neuroprosthetics
and brain-computer interfaces.",2024-07-19,"Fengyu Yang, Chao Feng, Daniel Wang, Tianye Wang, Ziyao Zeng, Zhiyang Xu, Hyoungseob Park, Pengliang Ji, Hanbin Zhao, Yuanning Li, Alex Wong",http://arxiv.org/pdf/2407.14020v1,cs.LG
Investigating the Indirect Object Identification circuit in Mamba,"How well will current interpretability techniques generalize to future
models? A relevant case study is Mamba, a recent recurrent architecture with
scaling comparable to Transformers. We adapt pre-Mamba techniques to Mamba and
partially reverse-engineer the circuit responsible for the Indirect Object
Identification (IOI) task. Our techniques provide evidence that 1) Layer 39 is
a key bottleneck, 2) Convolutions in layer 39 shift names one position forward,
and 3) The name entities are stored linearly in Layer 39's SSM. Finally, we
adapt an automatic circuit discovery tool, positional Edge Attribution
Patching, to identify a Mamba IOI circuit. Our contributions provide initial
evidence that circuit-based mechanistic interpretability tools work well for
the Mamba architecture.",2024-07-19,"Danielle Ensign, Adrià Garriga-Alonso",http://arxiv.org/pdf/2407.14008v2,cs.LG
Time Series Generative Learning with Application to Brain Imaging Analysis,"This paper focuses on the analysis of sequential image data, particularly
brain imaging data such as MRI, fMRI, CT, with the motivation of understanding
the brain aging process and neurodegenerative diseases. To achieve this goal,
we investigate image generation in a time series context. Specifically, we
formulate a min-max problem derived from the $f$-divergence between neighboring
pairs to learn a time series generator in a nonparametric manner. The generator
enables us to generate future images by transforming prior lag-k observations
and a random vector from a reference distribution. With a deep neural network
learned generator, we prove that the joint distribution of the generated
sequence converges to the latent truth under a Markov and a conditional
invariance condition. Furthermore, we extend our generation mechanism to a
panel data scenario to accommodate multiple samples. The effectiveness of our
mechanism is evaluated by generating real brain MRI sequences from the
Alzheimer's Disease Neuroimaging Initiative. These generated image sequences
can be used as data augmentation to enhance the performance of further
downstream tasks, such as Alzheimer's disease detection.",2024-07-19,"Zhenghao Li, Sanyou Wu, Long Feng",http://arxiv.org/pdf/2407.14003v1,cs.LG
Clinical Reading Comprehension with Encoder-Decoder Models Enhanced by Direct Preference Optimization,"Extractive question answering over clinical text is a crucial need to help
deal with the deluge of clinical text generated in hospitals. While encoder
models (e.g., BERT) have been popular for this reading comprehension task,
recently encoder-decoder models (e.g., T5) are on the rise. There is also the
emergence of preference optimization techniques to align decoder-only LLMs with
human preferences. In this paper, we combine encoder-decoder models with the
direct preference optimization (DPO) method to improve over prior state of the
art for the RadQA radiology question answering task by 12-15 F1 points. To the
best of our knowledge, this effort is the first to show that DPO method also
works for reading comprehension via novel heuristics to generate preference
data without human inputs.",2024-07-19,"Md Sultan Al Nahian, Ramakanth Kavuluru",http://arxiv.org/pdf/2407.14000v1,cs.LG
Enhancing Graph Neural Networks with Limited Labeled Data by Actively Distilling Knowledge from Large Language Models,"Graphs are pervasive in the real-world, such as social network analysis,
bioinformatics, and knowledge graphs. Graph neural networks (GNNs) have great
ability in node classification, a fundamental task on graphs. Unfortunately,
conventional GNNs still face challenges in scenarios with few labeled nodes,
despite the prevalence of few-shot node classification tasks in real-world
applications. To address this challenge, various approaches have been proposed,
including graph meta-learning, transfer learning, and methods based on Large
Language Models (LLMs). However, traditional meta-learning and transfer
learning methods often require prior knowledge from base classes or fail to
exploit the potential advantages of unlabeled nodes. Meanwhile, LLM-based
methods may overlook the zero-shot capabilities of LLMs and rely heavily on the
quality of generated contexts. In this paper, we propose a novel approach that
integrates LLMs and GNNs, leveraging the zero-shot inference and reasoning
capabilities of LLMs and employing a Graph-LLM-based active learning paradigm
to enhance GNNs' performance. Extensive experiments demonstrate the
effectiveness of our model in improving node classification accuracy with
considerably limited labeled data, surpassing state-of-the-art baselines by
significant margins.",2024-07-19,"Quan Li, Tianxiang Zhao, Lingwei Chen, Junjie Xu, Suhang Wang",http://arxiv.org/pdf/2407.13989v3,cs.LG
Decomposed Direct Preference Optimization for Structure-Based Drug Design,"Diffusion models have achieved promising results for Structure-Based Drug
Design (SBDD). Nevertheless, high-quality protein subpocket and ligand data are
relatively scarce, which hinders the models' generation capabilities. Recently,
Direct Preference Optimization (DPO) has emerged as a pivotal tool for aligning
generative models with human preferences. In this paper, we propose DecompDPO,
a structure-based optimization method aligns diffusion models with
pharmaceutical needs using multi-granularity preference pairs. DecompDPO
introduces decomposition into the optimization objectives and obtains
preference pairs at the molecule or decomposed substructure level based on each
objective's decomposability. Additionally, DecompDPO introduces a
physics-informed energy term to ensure reasonable molecular conformations in
the optimization results. Notably, DecompDPO can be effectively used for two
main purposes: (1) fine-tuning pretrained diffusion models for molecule
generation across various protein families, and (2) molecular optimization
given a specific protein subpocket after generation. Extensive experiments on
the CrossDocked2020 benchmark show that DecompDPO significantly improves model
performance, achieving up to 95.2% Med. High Affinity and a 36.2% success rate
for molecule generation, and 100% Med. High Affinity and a 52.1% success rate
for molecular optimization.",2024-07-19,"Xiwei Cheng, Xiangxin Zhou, Yuwei Yang, Yu Bao, Quanquan Gu",http://arxiv.org/pdf/2407.13981v2,cs.LG
Byzantine-tolerant distributed learning of finite mixture models,"Traditional statistical methods need to be updated to work with modern
distributed data storage paradigms. A common approach is the split-and-conquer
framework, which involves learning models on local machines and averaging their
parameter estimates. However, this does not work for the important problem of
learning finite mixture models, because subpopulation indices on each local
machine may be arbitrarily permuted (the ""label switching problem""). Zhang and
Chen (2022) proposed Mixture Reduction (MR) to address this issue, but MR
remains vulnerable to Byzantine failure, whereby a fraction of local machines
may transmit arbitrarily erroneous information. This paper introduces Distance
Filtered Mixture Reduction (DFMR), a Byzantine tolerant adaptation of MR that
is both computationally efficient and statistically sound. DFMR leverages the
densities of local estimates to construct a robust filtering mechanism. By
analysing the pairwise L2 distances between local estimates, DFMR identifies
and removes severely corrupted local estimates while retaining the majority of
uncorrupted ones. We provide theoretical justification for DFMR, proving its
optimal convergence rate and asymptotic equivalence to the global maximum
likelihood estimate under standard assumptions. Numerical experiments on
simulated and real-world data validate the effectiveness of DFMR in achieving
robust and accurate aggregation in the presence of Byzantine failure.",2024-07-19,"Qiong Zhang, Yan Shuo Tan, Jiahua Chen",http://arxiv.org/pdf/2407.13980v2,cs.LG
Truthfulness of Calibration Measures,"We initiate the study of the truthfulness of calibration measures in
sequential prediction. A calibration measure is said to be truthful if the
forecaster (approximately) minimizes the expected penalty by predicting the
conditional expectation of the next outcome, given the prior distribution of
outcomes. Truthfulness is an important property of calibration measures,
ensuring that the forecaster is not incentivized to exploit the system with
deliberate poor forecasts. This makes it an essential desideratum for
calibration measures, alongside typical requirements, such as soundness and
completeness.
  We conduct a taxonomy of existing calibration measures and their
truthfulness. Perhaps surprisingly, we find that all of them are far from being
truthful. That is, under existing calibration measures, there are simple
distributions on which a polylogarithmic (or even zero) penalty is achievable,
while truthful prediction leads to a polynomial penalty. Our main contribution
is the introduction of a new calibration measure termed the Subsampled Smooth
Calibration Error (SSCE) under which truthful prediction is optimal up to a
constant multiplicative factor.",2024-07-19,"Nika Haghtalab, Mingda Qiao, Kunhe Yang, Eric Zhao",http://arxiv.org/pdf/2407.13979v2,cs.LG
Dual adversarial and contrastive network for single-source domain generalization in fault diagnosis,"Domain generalization achieves fault diagnosis on unseen modes. In process
industrial systems, fault samples are limited, and it is quite common that the
available fault data are from a single mode. Extracting domain-invariant
features from single-mode data for unseen mode fault diagnosis poses
challenges. Existing methods utilize a generator module to simulate samples of
unseen modes. However, multi-mode samples contain complex spatiotemporal
information, which brings significant difficulties to accurate sample
generation. To solve this problem, this paper proposed a dual adversarial and
contrastive network (DACN) for single-source domain generalization in fault
diagnosis. The main idea of DACN is to generate diverse sample features and
extract domain-invariant feature representations. An adversarial pseudo-sample
feature generation strategy is developed to create fake unseen mode sample
features with sufficient semantic information and diversity, leveraging
adversarial learning between the feature transformer and domain-invariant
feature extractor. An enhanced domain-invariant feature extraction strategy is
designed to capture common feature representations across multi-modes,
utilizing contrastive learning and adversarial learning between the
domain-invariant feature extractor and the discriminator. Experiments on the
Tennessee Eastman process and continuous stirred-tank reactor demonstrate that
DACN achieves high classification accuracy on unseen modes while maintaining a
small model size.",2024-07-19,"Guangqiang Li, M. Amine Atoui, Xiangshun Li",http://arxiv.org/pdf/2407.13978v2,cs.LG
"A Unified Confidence Sequence for Generalized Linear Models, with Applications to Bandits","We present a unified likelihood ratio-based confidence sequence (CS) for any
(self-concordant) generalized linear model (GLM) that is guaranteed to be
convex and numerically tight. We show that this is on par or improves upon
known CSs for various GLMs, including Gaussian, Bernoulli, and Poisson. In
particular, for the first time, our CS for Bernoulli has a
$\mathrm{poly}(S)$-free radius where $S$ is the norm of the unknown parameter.
Our first technical novelty is its derivation, which utilizes a time-uniform
PAC-Bayesian bound with a uniform prior/posterior, despite the latter being a
rather unpopular choice for deriving CSs. As a direct application of our new
CS, we propose a simple and natural optimistic algorithm called OFUGLB,
applicable to any generalized linear bandits (GLB; Filippi et al. (2010)). Our
analysis shows that the celebrated optimistic approach simultaneously attains
state-of-the-art regrets for various self-concordant (not necessarily bounded)
GLBs, and even $\mathrm{poly}(S)$-free for bounded GLBs, including logistic
bandits. The regret analysis, our second technical novelty, follows from
combining our new CS with a new proof technique that completely avoids the
previously widely used self-concordant control lemma (Faury et al., 2020, Lemma
9). Numerically, OFUGLB outperforms or is at par with prior algorithms for
logistic bandits.",2024-07-19,"Junghyun Lee, Se-Young Yun, Kwang-Sung Jun",http://arxiv.org/pdf/2407.13977v3,cs.LG
The Group Robustness is in the Details: Revisiting Finetuning under Spurious Correlations,"Modern machine learning models are prone to over-reliance on spurious
correlations, which can often lead to poor performance on minority groups. In
this paper, we identify surprising and nuanced behavior of finetuned models on
worst-group accuracy via comprehensive experiments on four well-established
benchmarks across vision and language tasks. We first show that the commonly
used class-balancing techniques of mini-batch upsampling and loss upweighting
can induce a decrease in worst-group accuracy (WGA) with training epochs,
leading to performance no better than without class-balancing. While in some
scenarios, removing data to create a class-balanced subset is more effective,
we show this depends on group structure and propose a mixture method which can
outperform both techniques. Next, we show that scaling pretrained models is
generally beneficial for worst-group accuracy, but only in conjunction with
appropriate class-balancing. Finally, we identify spectral imbalance in
finetuning features as a potential source of group disparities -- minority
group covariance matrices incur a larger spectral norm than majority groups
once conditioned on the classes. Our results show more nuanced interactions of
modern finetuned models with group robustness than was previously known. Our
code is available at https://github.com/tmlabonte/revisiting-finetuning.",2024-07-19,"Tyler LaBonte, John C. Hill, Xinchen Zhang, Vidya Muthukumar, Abhishek Kumar",http://arxiv.org/pdf/2407.13957v2,cs.LG
"Neural topology optimization: the good, the bad, and the ugly","Neural networks (NNs) hold great promise for advancing inverse design via
topology optimization (TO), yet misconceptions about their application persist.
This article focuses on neural topology optimization (neural TO), which
leverages NNs to reparameterize the decision space and reshape the optimization
landscape. While the method is still in its infancy, our analysis tools reveal
critical insights into the NNs' impact on the optimization process. We
demonstrate that the choice of NN architecture significantly influences the
objective landscape and the optimizer's path to an optimum. Notably, NNs
introduce non-convexities even in otherwise convex landscapes, potentially
delaying convergence in convex problems but enhancing exploration for
non-convex problems. This analysis lays the groundwork for future advancements
by highlighting: 1) the potential of neural TO for non-convex problems and
dedicated GPU hardware (the ""good""), 2) the limitations in smooth landscapes
(the ""bad""), and 3) the complex challenge of selecting optimal NN architectures
and hyperparameters for superior performance (the ""ugly"").",2024-07-19,"Suryanarayanan Manoj Sanu, Alejandro M. Aragon, Miguel A. Bessa",http://arxiv.org/pdf/2407.13954v1,cs.LG
BRSR-OpGAN: Blind Radar Signal Restoration using Operational Generative Adversarial Network,"Objective: Many studies on radar signal restoration in the literature focus
on isolated restoration problems, such as denoising over a certain type of
noise, while ignoring other types of artifacts. Additionally, these approaches
usually assume a noisy environment with a limited set of fixed signal-to-noise
ratio (SNR) levels. However, real-world radar signals are often corrupted by a
blend of artifacts, including but not limited to unwanted echo, sensor noise,
intentional jamming, and interference, each of which can vary in type,
severity, and duration. This study introduces Blind Radar Signal Restoration
using an Operational Generative Adversarial Network (BRSR-OpGAN), which uses a
dual domain loss in the temporal and spectral domains. This approach is
designed to improve the quality of radar signals, regardless of the diversity
and intensity of the corruption. Methods: The BRSR-OpGAN utilizes 1D
Operational GANs, which use a generative neuron model specifically optimized
for blind restoration of corrupted radar signals. This approach leverages GANs'
flexibility to adapt dynamically to a wide range of artifact characteristics.
Results: The proposed approach has been extensively evaluated using a
well-established baseline and a newly curated extended dataset called the Blind
Radar Signal Restoration (BRSR) dataset. This dataset was designed to simulate
real-world conditions and includes a variety of artifacts, each varying in
severity. The evaluation shows an average SNR improvement over 15.1 dB and 14.3
dB for the baseline and BRSR datasets, respectively. Finally, even on
resource-constrained platforms, the proposed approach can be applied in
real-time.",2024-07-18,"Muhammad Uzair Zahid, Serkan Kiranyaz, Alper Yildirim, Moncef Gabbouj",http://arxiv.org/pdf/2407.13949v2,cs.LG
Event-Triggered Reinforcement Learning Based Joint Resource Allocation for Ultra-Reliable Low-Latency V2X Communications,"Future 6G-enabled vehicular networks face the challenge of ensuring
ultra-reliable low-latency communication (URLLC) for delivering safety-critical
information in a timely manner. Existing resource allocation schemes for
vehicle-to-everything (V2X) communication systems primarily rely on traditional
optimization-based algorithms. However, these methods often fail to guarantee
the strict reliability and latency requirements of URLLC applications in
dynamic vehicular environments due to the high complexity and communication
overhead of the solution methodologies. This paper proposes a novel deep
reinforcement learning (DRL) based framework for the joint power and block
length allocation to minimize the worst-case decoding-error probability in the
finite block length (FBL) regime for a URLLC-based downlink V2X communication
system. The problem is formulated as a non-convex mixed-integer nonlinear
programming problem (MINLP). Initially, an algorithm grounded in optimization
theory is developed based on deriving the joint convexity of the decoding error
probability in the block length and transmit power variables within the region
of interest. Subsequently, an efficient event-triggered DRL-based algorithm is
proposed to solve the joint optimization problem. Incorporating event-triggered
learning into the DRL framework enables assessing whether to initiate the DRL
process, thereby reducing the number of DRL process executions while
maintaining reasonable reliability performance. Simulation results demonstrate
that the proposed event-triggered DRL scheme can achieve 95% of the performance
of the joint optimization scheme while reducing the DRL executions by up to 24%
for different network settings.",2024-07-18,"Nasir Khan, Sinem Coleri",http://arxiv.org/pdf/2407.13947v1,cs.LG
Unmasking Social Bots: How Confident Are We?,"Social bots remain a major vector for spreading disinformation on social
media and a menace to the public. Despite the progress made in developing
multiple sophisticated social bot detection algorithms and tools, bot detection
remains a challenging, unsolved problem that is fraught with uncertainty due to
the heterogeneity of bot behaviors, training data, and detection algorithms.
Detection models often disagree on whether to label the same account as bot or
human-controlled. However, they do not provide any measure of uncertainty to
indicate how much we should trust their results. We propose to address both bot
detection and the quantification of uncertainty at the account level - a novel
feature of this research. This dual focus is crucial as it allows us to
leverage additional information related to the quantified uncertainty of each
prediction, thereby enhancing decision-making and improving the reliability of
bot classifications. Specifically, our approach facilitates targeted
interventions for bots when predictions are made with high confidence and
suggests caution (e.g., gathering more data) when predictions are uncertain.",2024-07-18,"James Giroux, Ariyarathne Gangani, Alexander C. Nwala, Cristiano Fanelli",http://arxiv.org/pdf/2407.13929v2,cs.LG
EggNet: An Evolving Graph-based Graph Attention Network for Particle Track Reconstruction,"Track reconstruction is a crucial task in particle experiments and is
traditionally very computationally expensive due to its combinatorial nature.
Recently, graph neural networks (GNNs) have emerged as a promising approach
that can improve scalability. Most of these GNN-based methods, including the
edge classification (EC) and the object condensation (OC) approach, require an
input graph that needs to be constructed beforehand. In this work, we consider
a one-shot OC approach that reconstructs particle tracks directly from a set of
hits (point cloud) by recursively applying graph attention networks with an
evolving graph structure. This approach iteratively updates the graphs and can
better facilitate the message passing across each graph. Preliminary studies on
the TrackML dataset show better track performance compared to the methods that
require a fixed input graph.",2024-07-18,"Paolo Calafiura, Jay Chan, Loic Delabrouille, Brandon Wang",http://arxiv.org/pdf/2407.13925v1,cs.LG
Synthetic Counterfactual Faces,"Computer vision systems have been deployed in various applications involving
biometrics like human faces. These systems can identify social media users,
search for missing persons, and verify identity of individuals. While computer
vision models are often evaluated for accuracy on available benchmarks, more
annotated data is necessary to learn about their robustness and fairness
against semantic distributional shifts in input data, especially in face data.
Among annotated data, counterfactual examples grant strong explainability
characteristics. Because collecting natural face data is prohibitively
expensive, we put forth a generative AI-based framework to construct targeted,
counterfactual, high-quality synthetic face data. Our synthetic data pipeline
has many use cases, including face recognition systems sensitivity evaluations
and image understanding system probes. The pipeline is validated with multiple
user studies. We showcase the efficacy of our face generation pipeline on a
leading commercial vision model. We identify facial attributes that cause
vision systems to fail.",2024-07-18,"Guruprasad V Ramesh, Harrison Rosenberg, Ashish Hooda, Shimaa Ahmed Kassem Fawaz",http://arxiv.org/pdf/2407.13922v2,cs.LG
Continual Distillation Learning: Knowledge Distillation in Prompt-based Continual Learning,"We introduce the problem of continual distillation learning (CDL) in order to
use knowledge distillation (KD) to improve prompt-based continual learning (CL)
models. The CDL problem is valuable to study since the use of a larger vision
transformer (ViT) leads to better performance in prompt-based continual
learning. The distillation of knowledge from a large ViT to a small ViT
improves the inference efficiency for prompt-based CL models. We empirically
found that existing KD methods such as logit distillation and feature
distillation cannot effectively improve the student model in the CDL setup. To
address this issue, we introduce a novel method named Knowledge Distillation
based on Prompts (KDP), in which globally accessible prompts specifically
designed for knowledge distillation are inserted into the frozen ViT backbone
of the student model. We demonstrate that our KDP method effectively enhances
the distillation performance in comparison to existing KD methods in the CDL
setup.",2024-07-18,"Qifan Zhang, Yunhui Guo, Yu Xiang",http://arxiv.org/pdf/2407.13911v4,cs.LG
Crafting Efficient Fine-Tuning Strategies for Large Language Models,"This paper addresses the challenges of efficiently fine-tuning large language
models (LLMs) by exploring data efficiency and hyperparameter optimization. We
investigate the minimum data required for effective fine-tuning and propose a
novel hyperparameter optimization method that leverages early-stage model
performance. Our experiments demonstrate that fine-tuning with as few as 200
samples can improve model accuracy from 70\% to 88\% in a product attribute
extraction task. We identify a saturation point of approximately 6,500 samples,
beyond which additional data yields diminishing returns. Our proposed bayesian
hyperparameter optimization method, which evaluates models at 20\% of total
training time, correlates strongly with final model performance, with 4 out of
5 top early-stage models remaining in the top 5 at completion. This approach
led to a 2\% improvement in accuracy over baseline models when evaluated on an
independent test set. These findings offer actionable insights for
practitioners, potentially reducing computational load and dependency on
extensive datasets while enhancing overall performance of fine-tuned LLMs.",2024-07-18,"Michael Oliver, Guan Wang",http://arxiv.org/pdf/2407.13906v1,cs.LG
Framework for Curating Speech Datasets and Evaluating ASR Systems: A Case Study for Polish,"Speech datasets available in the public domain are often underutilized
because of challenges in discoverability and interoperability. A comprehensive
framework has been designed to survey, catalog, and curate available speech
datasets, which allows replicable evaluation of automatic speech recognition
(ASR) systems. A case study focused on the Polish language was conducted; the
framework was applied to curate more than 24 datasets and evaluate 25
combinations of ASR systems and models. This research constitutes the most
extensive comparison to date of both commercial and free ASR systems for the
Polish language. It draws insights from 600 system-model-test set evaluations,
marking a significant advancement in both scale and comprehensiveness. The
results of surveys and performance comparisons are available as interactive
dashboards (https://huggingface.co/spaces/amu-cai/pl-asr-leaderboard) along
with curated datasets (https://huggingface.co/datasets/amu-cai/pl-asr-bigos-v2,
https://huggingface.co/datasets/pelcra/pl-asr-pelcra-for-bigos) and the open
challenge call (https://poleval.pl/tasks/task3). Tools used for evaluation are
open-sourced (https://github.com/goodmike31/pl-asr-bigos-tools), facilitating
replication and adaptation for other languages, as well as continuous expansion
with new datasets and systems.",2024-07-18,Michał Junczyk,http://arxiv.org/pdf/2408.00005v1,cs.LG
A reinforcement learning strategy to automate and accelerate h/p-multigrid solvers,"We explore a reinforcement learning strategy to automate and accelerate
h/p-multigrid methods in high-order solvers. Multigrid methods are very
efficient but require fine-tuning of numerical parameters, such as the number
of smoothing sweeps per level and the correction fraction (i.e., proportion of
the corrected solution that is transferred from a coarser grid to a finer
grid). The objective of this paper is to use a proximal policy optimization
algorithm to automatically tune the multigrid parameters and, by doing so,
improve stability and efficiency of the h/p-multigrid strategy.
  Our findings reveal that the proposed reinforcement learning h/p-multigrid
approach significantly accelerates and improves the robustness of steady-state
simulations for one dimensional advection-diffusion and nonlinear Burgers'
equations, when discretized using high-order h/p methods, on uniform and
nonuniform grids.",2024-07-18,"David Huergo, Laura Alonso, Saumitra Joshi, Adrian Juanicoteca, Gonzalo Rubio, Esteban Ferrer",http://arxiv.org/pdf/2407.15872v1,cs.LG
Data-Algorithm-Architecture Co-Optimization for Fair Neural Networks on Skin Lesion Dataset,"As Artificial Intelligence (AI) increasingly integrates into our daily lives,
fairness has emerged as a critical concern, particularly in medical AI, where
datasets often reflect inherent biases due to social factors like the
underrepresentation of marginalized communities and socioeconomic barriers to
data collection. Traditional approaches to mitigating these biases have focused
on data augmentation and the development of fairness-aware training algorithms.
However, this paper argues that the architecture of neural networks, a core
component of Machine Learning (ML), plays a crucial role in ensuring fairness.
We demonstrate that addressing fairness effectively requires a holistic
approach that simultaneously considers data, algorithms, and architecture.
Utilizing Automated ML (AutoML) technology, specifically Neural Architecture
Search (NAS), we introduce a novel framework, BiaslessNAS, designed to achieve
fair outcomes in analyzing skin lesion datasets. BiaslessNAS incorporates
fairness considerations at every stage of the NAS process, leading to the
identification of neural networks that are not only more accurate but also
significantly fairer. Our experiments show that BiaslessNAS achieves a 2.55%
increase in accuracy and a 65.50% improvement in fairness compared to
traditional NAS methods, underscoring the importance of integrating fairness
into neural network architecture for better outcomes in medical AI
applications.",2024-07-18,"Yi Sheng, Junhuan Yang, Jinyang Li, James Alaina, Xiaowei Xu, Yiyu Shi, Jingtong Hu, Weiwen Jiang, Lei Yang",http://arxiv.org/pdf/2407.13896v1,cs.LG
APS-USCT: Ultrasound Computed Tomography on Sparse Data via AI-Physic Synergy,"Ultrasound computed tomography (USCT) is a promising technique that achieves
superior medical imaging reconstruction resolution by fully leveraging waveform
information, outperforming conventional ultrasound methods. Despite its
advantages, high-quality USCT reconstruction relies on extensive data
acquisition by a large number of transducers, leading to increased costs,
computational demands, extended patient scanning times, and manufacturing
complexities. To mitigate these issues, we propose a new USCT method called
APS-USCT, which facilitates imaging with sparse data, substantially reducing
dependence on high-cost dense data acquisition. Our APS-USCT method consists of
two primary components: APS-wave and APS-FWI. The APS-wave component, an
encoder-decoder system, preprocesses the waveform data, converting sparse data
into dense waveforms to augment sample density prior to reconstruction. The
APS-FWI component, utilizing the InversionNet, directly reconstructs the speed
of sound (SOS) from the ultrasound waveform data. We further improve the
model's performance by incorporating Squeeze-and-Excitation (SE) Blocks and
source encoding techniques. Testing our method on a breast cancer dataset
yielded promising results. It demonstrated outstanding performance with an
average Structural Similarity Index (SSIM) of 0.8431. Notably, over 82% of
samples achieved an SSIM above 0.8, with nearly 61% exceeding 0.85,
highlighting the significant potential of our approach in improving USCT image
reconstruction by efficiently utilizing sparse data.",2024-07-18,"Yi Sheng, Hanchen Wang, Yipei Liu, Junhuan Yang, Weiwen Jiang, Youzuo Lin, Lei Yang",http://arxiv.org/pdf/2407.14564v1,cs.LG
Attention in SRAM on Tenstorrent Grayskull,"When implementations of the Transformer's self-attention layer utilize SRAM
instead of DRAM, they can achieve significant speedups. The Tenstorrent
Grayskull architecture provides a large SRAM, distributed across a grid of
cores. This work presents a fused kernel for Grayskull, that exclusively
utilizes its large SRAM by combining matrix multiplication, attention score
scaling and Softmax operations. Additionally, a dedicated Softmax kernel
utilizing the SRAM and a CPU implementation serving as a baseline are
presented. The Softmax operation consumes most of the runtime in the
computation of attention weights from queries and keys on Grayskull. The
speedup of the dedicated Softmax kernel compared to the CPU implementation is
up to $10 \times$, and the Softmax implementation inside the fused kernel is
approximately $1.8 \times$ faster than the dedicated Softmax kernel. The time
and memory complexity of all implementations is quadratic in sequence length.
Currently, the Grayskull e150 is approximately $30 \times$ cheaper for the
general public than an Nvidia H100 PCIe (a state-of-the-art GPU) and offers
approximately $1.5 \times$ more SRAM.",2024-07-18,Moritz Thüning,http://arxiv.org/pdf/2407.13885v1,cs.LG
Privacy-preserving gradient-based fair federated learning,"Federated learning (FL) schemes allow multiple participants to
collaboratively train neural networks without the need to directly share the
underlying data.However, in early schemes, all participants eventually obtain
the same model. Moreover, the aggregation is typically carried out by a third
party, who obtains combined gradients or weights, which may reveal the model.
These downsides underscore the demand for fair and privacy-preserving FL
schemes. Here, collaborative fairness asks for individual model quality
depending on the individual data contribution. Privacy is demanded with respect
to any kind of data outsourced to the third party. Now, there already exist
some approaches aiming for either fair or privacy-preserving FL and a few works
even address both features. In our paper, we build upon these seminal works and
present a novel, fair and privacy-preserving FL scheme. Our approach, which
mainly relies on homomorphic encryption, stands out for exclusively using local
gradients. This increases the usability in comparison to state-of-the-art
approaches and thereby opens the door to applications in control.",2024-07-18,"Janis Adamek, Moritz Schulze Darup",http://arxiv.org/pdf/2407.13881v1,cs.LG
VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance,"Concept Bottleneck Models (CBMs) provide interpretable prediction by
introducing an intermediate Concept Bottleneck Layer (CBL), which encodes
human-understandable concepts to explain models' decision. Recent works
proposed to utilize Large Language Models and pre-trained Vision-Language
Models to automate the training of CBMs, making it more scalable and automated.
However, existing approaches still fall short in two aspects: First, the
concepts predicted by CBL often mismatch the input image, raising doubts about
the faithfulness of interpretation. Second, it has been shown that concept
values encode unintended information: even a set of random concepts could
achieve comparable test accuracy to state-of-the-art CBMs. To address these
critical limitations, in this work, we propose a novel framework called
Vision-Language-Guided Concept Bottleneck Model (VLG-CBM) to enable faithful
interpretability with the benefits of boosted performance. Our method leverages
off-the-shelf open-domain grounded object detectors to provide visually
grounded concept annotation, which largely enhances the faithfulness of concept
prediction while further improving the model performance. In addition, we
propose a new metric called Number of Effective Concepts (NEC) to control the
information leakage and provide better interpretability. Extensive evaluations
across five standard benchmarks show that our method, VLG-CBM, outperforms
existing methods by at least 4.27% and up to 51.09% on Accuracy at NEC=5
(denoted as ANEC-5), and by at least 0.45% and up to 29.78% on average accuracy
(denoted as ANEC-avg), while preserving both faithfulness and interpretability
of the learned concepts as demonstrated in extensive experiments.",2024-07-18,"Divyansh Srivastava, Ge Yan, Tsui-Wei Weng",http://arxiv.org/pdf/2408.01432v3,cs.LG
Optimal high-precision shadow estimation,"We give the first tight sample complexity bounds for shadow tomography and
classical shadows in the regime where the target error is below some
sufficiently small inverse polynomial in the dimension of the Hilbert space.
Formally we give a protocol that, given any $m\in\mathbb{N}$ and $\epsilon \le
O(d^{-12})$, measures $O(\log(m)/\epsilon^2)$ copies of an unknown mixed state
$\rho\in\mathbb{C}^{d\times d}$ and outputs a classical description of $\rho$
which can then be used to estimate any collection of $m$ observables to within
additive accuracy $\epsilon$. Previously, even for the simpler task of shadow
tomography -- where the $m$ observables are known in advance -- the best known
rates either scaled benignly but suboptimally in all of $m, d, \epsilon$, or
scaled optimally in $\epsilon, m$ but had additional polynomial factors in $d$
for general observables. Intriguingly, we also show via dimensionality
reduction, that we can rescale $\epsilon$ and $d$ to reduce to the regime where
$\epsilon \le O(d^{-1/2})$. Our algorithm draws upon representation-theoretic
tools recently developed in the context of full state tomography.",2024-07-18,"Sitan Chen, Jerry Li, Allen Liu",http://arxiv.org/pdf/2407.13874v1,cs.LG
Keypoint Aware Masked Image Modelling,"SimMIM is a widely used method for pretraining vision transformers using
masked image modeling. However, despite its success in fine-tuning performance,
it has been shown to perform sub-optimally when used for linear probing. We
propose an efficient patch-wise weighting derived from keypoint features which
captures the local information and provides better context during SimMIM's
reconstruction phase. Our method, KAMIM, improves the top-1 linear probing
accuracy from 16.12% to 33.97%, and finetuning accuracy from 76.78% to 77.3%
when tested on the ImageNet-1K dataset with a ViT-B when trained for the same
number of epochs. We conduct extensive testing on different datasets, keypoint
extractors, and model architectures and observe that patch-wise weighting
augments linear probing performance for larger pretraining datasets. We also
analyze the learned representations of a ViT-B trained using KAMIM and observe
that they behave similar to contrastive learning with regard to its behavior,
with longer attention distances and homogenous self-attention across layers.
Our code is publicly available at https://github.com/madhava20217/KAMIM.",2024-07-18,"Madhava Krishna, A V Subramanyam",http://arxiv.org/pdf/2407.13873v3,cs.LG
Enhancing Worldwide Image Geolocation by Ensembling Satellite-Based Ground-Level Attribute Predictors,"We examine the challenge of estimating the location of a single ground-level
image in the absence of GPS or other location metadata. Currently, geolocation
systems are evaluated by measuring the Great Circle Distance between the
predicted location and ground truth. Because this measurement only uses a
single point, it cannot assess the distribution of predictions by geolocation
systems. Evaluation of a distribution of potential locations (areas) is
required when there are follow-on procedures to further narrow down or verify
the location. This is especially important in poorly-sampled regions e.g. rural
and wilderness areas.
  In this paper, we introduce a novel metric, Recall vs Area (RvA), which
measures the accuracy of estimated distributions of locations. RvA treats image
geolocation results similarly to document retrieval, measuring recall as a
function of area: For a ranked list of (possibly discontiguous) predicted
regions, we measure the area required for accumulated regions to contain the
ground truth coordinate. This produces a curve similar to a precision-recall
curve, where ""precision"" is replaced by square kilometers area, enabling
evaluation for different downstream search area budgets.
  Following from this view of the problem, we then examine an ensembling
approach to global-scale image geolocation, which incorporates information from
multiple sources, and can readily incorporate multiple models, attribute
predictors, and data sources. We study its effectiveness by combining the
geolocation models GeoEstimation and the current state-of-the-art, GeoCLIP,
with attribute predictors based on Oak Ridge National Laboratory LandScan and
European Space Agency Climate Change Initiative Land Cover. We find significant
improvements in image geolocation for areas that are under-represented in the
training set, particularly non-urban areas, on both Im2GPS3k and Street View
images.",2024-07-18,"Michael J. Bianco, David Eigen, Michael Gormish",http://arxiv.org/pdf/2407.13862v2,cs.LG
Quantum Natural Stochastic Pairwise Coordinate Descent,"Quantum machine learning through variational quantum algorithms (VQAs) has
gained substantial attention in recent years. VQAs employ parameterized quantum
circuits, which are typically optimized using gradient-based methods. However,
these methods often exhibit sub-optimal convergence performance due to their
dependence on Euclidean geometry. The quantum natural gradient descent (QNGD)
optimization method, which considers the geometry of the quantum state space
via a quantum information (Riemannian) metric tensor, provides a more effective
optimization strategy. Despite its advantages, QNGD encounters notable
challenges for learning from quantum data, including the no-cloning principle,
which prohibits the replication of quantum data, state collapse, and the
measurement postulate, which leads to the stochastic loss function. This paper
introduces the quantum natural stochastic pairwise coordinate descent (2-QNSCD)
optimization method. This method leverages the curved geometry of the quantum
state space through a novel ensemble-based quantum information metric tensor,
offering a more physically realizable optimization strategy for learning from
quantum data. To improve computational efficiency and reduce sample complexity,
we develop a highly sparse unbiased estimator of the novel metric tensor using
a quantum circuit with gate complexity $\Theta(1)$ times that of the
parameterized quantum circuit and single-shot quantum measurements. Our
approach avoids the need for multiple copies of quantum data, thus adhering to
the no-cloning principle. We provide a detailed theoretical foundation for our
optimization method, along with an exponential convergence analysis.
Additionally, we validate the utility of our method through a series of
numerical experiments.",2024-07-18,"Mohammad Aamir Sohail, Mohsen Heidari Khoozani, S. Sandeep Pradhan",http://arxiv.org/pdf/2407.13858v1,cs.LG
Forecasting GPU Performance for Deep Learning Training and Inference,"Deep learning kernels exhibit predictable memory accesses and compute
patterns, making GPUs' parallel architecture well-suited for their execution.
Software and runtime systems for GPUs are optimized to better utilize the
stream multiprocessors, on-chip cache, and off-chip high-bandwidth memory. As
deep learning models and GPUs evolve, access to newer GPUs is often limited,
raising questions about the performance of new model architectures on existing
GPUs, existing models on new GPUs, and new model architectures on new GPUs. To
address these questions, we introduce NeuSight, a framework to predict the
performance of various deep learning models, for both training and inference,
on unseen GPUs without requiring actual execution. The framework leverages both
GPU hardware behavior and software library optimizations to estimate end-to-end
performance. Previous work uses regression models that capture linear trends or
multilayer perceptrons to predict the overall latency of deep learning kernels
on GPUs. These approaches suffer from higher error percentages when forecasting
performance on unseen models and new GPUs. Instead, NeuSight decomposes the
prediction problem into smaller problems, bounding the prediction through
fundamental performance laws. NeuSight decomposes a single deep learning kernel
prediction into smaller working sets called tiles, which are executed
independently on the GPU. Tile-granularity predictions are determined using a
machine learning approach and aggregated to estimate end-to-end latency.
NeuSight outperforms prior work across various deep learning workloads and the
latest GPUs. It reduces the percentage error from 121.4% and 30.8% to 2.3% in
predicting the latency of GPT3 model for training and inference on H100,
compared to state-of-the-art prior work, where both GPT3 and H100 were not used
to train the framework.",2024-07-18,"Seonho Lee, Amar Phanishayee, Divya Mahajan",http://arxiv.org/pdf/2407.13853v3,cs.LG
Semantic Prototypes: Enhancing Transparency Without Black Boxes,"As machine learning (ML) models and datasets increase in complexity, the
demand for methods that enhance explainability and interpretability becomes
paramount. Prototypes, by encapsulating essential characteristics within data,
offer insights that enable tactical decision-making and enhance transparency.
Traditional prototype methods often rely on sub-symbolic raw data and opaque
latent spaces, reducing explainability and increasing the risk of
misinterpretations. This paper presents a novel framework that utilizes
semantic descriptions to define prototypes and provide clear explanations,
effectively addressing the shortcomings of conventional methods. Our approach
leverages concept-based descriptions to cluster data on the semantic level,
ensuring that prototypes not only represent underlying properties intuitively
but are also straightforward to interpret. Our method simplifies the
interpretative process and effectively bridges the gap between complex data
structures and human cognitive processes, thereby enhancing transparency and
fostering trust. Our approach outperforms existing widely-used prototype
methods in facilitating human understanding and informativeness, as validated
through a user survey.",2024-07-18,"Orfeas Menis-Mastromichalakis, Giorgos Filandrianos, Jason Liartis, Edmund Dervakos, Giorgos Stamou",http://arxiv.org/pdf/2407.15871v3,cs.LG
X-Former: Unifying Contrastive and Reconstruction Learning for MLLMs,"Recent advancements in Multimodal Large Language Models (MLLMs) have
revolutionized the field of vision-language understanding by integrating visual
perception capabilities into Large Language Models (LLMs). The prevailing trend
in this field involves the utilization of a vision encoder derived from
vision-language contrastive learning (CL), showing expertise in capturing
overall representations while facing difficulties in capturing detailed local
patterns. In this work, we focus on enhancing the visual representations for
MLLMs by combining high-frequency and detailed visual representations, obtained
through masked image modeling (MIM), with semantically-enriched low-frequency
representations captured by CL. To achieve this goal, we introduce X-Former
which is a lightweight transformer module designed to exploit the complementary
strengths of CL and MIM through an innovative interaction mechanism.
Specifically, X-Former first bootstraps vision-language representation learning
and multimodal-to-multimodal generative learning from two frozen vision
encoders, i.e., CLIP-ViT (CL-based) and MAE-ViT (MIM-based). It further
bootstraps vision-to-language generative learning from a frozen LLM to ensure
visual features from X-Former can be interpreted by the LLM. To demonstrate the
effectiveness of our approach, we assess its performance on tasks demanding
detailed visual understanding. Extensive evaluations indicate that X-Former
excels in visual reasoning tasks involving both structural and semantic
categories in the GQA dataset. Assessment on fine-grained visual perception
benchmark further confirms its superior capabilities in visual understanding.",2024-07-18,"Sirnam Swetha, Jinyu Yang, Tal Neiman, Mamshad Nayeem Rizve, Son Tran, Benjamin Yao, Trishul Chilimbi, Mubarak Shah",http://arxiv.org/pdf/2407.13851v1,cs.LG
CoxSE: Exploring the Potential of Self-Explaining Neural Networks with Cox Proportional Hazards Model for Survival Analysis,"The Cox Proportional Hazards (CPH) model has long been the preferred survival
model for its explainability. However, to increase its predictive power beyond
its linear log-risk, it was extended to utilize deep neural networks
sacrificing its explainability. In this work, we explore the potential of
self-explaining neural networks (SENN) for survival analysis. we propose a new
locally explainable Cox proportional hazards model, named CoxSE, by estimating
a locally-linear log-hazard function using the SENN. We also propose a
modification to the Neural additive (NAM) models hybrid with SENN, named
CoxSENAM, which enables the control of the stability and consistency of the
generated explanations. Several experiments using synthetic and real datasets
have been performed comparing with a NAM-based model, DeepSurv model explained
with SHAP, and a linear CPH model. The results show that, unlike the NAM-based
model, the SENN-based model can provide more stable and consistent explanations
while maintaining the same expressiveness power of the black-box model. The
results also show that, due to their structural design, NAM-based models
demonstrated better robustness to non-informative features. Among these models,
the hybrid model exhibited the best robustness.",2024-07-18,"Abdallah Alabdallah, Omar Hamed, Mattias Ohlsson, Thorsteinn Rögnvaldsson, Sepideh Pashami",http://arxiv.org/pdf/2407.13849v1,cs.LG
Many Perception Tasks are Highly Redundant Functions of their Input Data,"We show that many perception tasks, from visual recognition, semantic
segmentation, optical flow, depth estimation to vocalization discrimination,
are highly redundant functions of their input data. Images or spectrograms,
projected into different subspaces, formed by orthogonal bases in pixel,
Fourier or wavelet domains, can be used to solve these tasks remarkably well
regardless of whether it is the top subspace where data varies the most, some
intermediate subspace with moderate variability--or the bottom subspace where
data varies the least. This phenomenon occurs because different subspaces have
a large degree of redundant information relevant to the task.",2024-07-18,"Rahul Ramesh, Anthony Bisulco, Ronald W. DiTullio, Linran Wei, Vijay Balasubramanian, Kostas Daniilidis, Pratik Chaudhari",http://arxiv.org/pdf/2407.13841v2,cs.LG
Temperature Distribution Prediction in Laser Powder Bed Fusion using Transferable and Scalable Graph Neural Networks,"This study presents novel predictive models using Graph Neural Networks
(GNNs) for simulating thermal dynamics in Laser Powder Bed Fusion (L-PBF)
processes. By developing and validating Single-Laser GNN (SL-GNN) and
Multi-Laser GNN (ML-GNN) surrogates, the research introduces a scalable
data-driven approach that learns fundamental physics from small-scale Finite
Element Analysis (FEA) simulations and applies them to larger domains.
Achieving a Mean Absolute Percentage Error (MAPE) of 3.77% with the baseline
SL-GNN model, GNNs effectively learn from high-resolution simulations and
generalize well across larger geometries. The proposed models capture the
complexity of the heat transfer process in L-PBF while significantly reducing
computational costs. For example, a thermomechanical simulation for a 2 mm x 2
mm domain typically requires about 4 hours, whereas the SL-GNN model can
predict thermal distributions almost instantly. Calibrating models to larger
domains enhances predictive performance, with significant drops in MAPE for 3
mm x 3 mm and 4 mm x 4 mm domains, highlighting the scalability and efficiency
of this approach. Additionally, models show a decreasing trend in Root Mean
Square Error (RMSE) when tuned to larger domains, suggesting potential for
becoming geometry-agnostic. The interaction of multiple lasers complicates heat
transfer, necessitating larger model architectures and advanced feature
engineering. Using hyperparameters from Gaussian process-based Bayesian
optimization, the best ML-GNN model demonstrates a 46.4% improvement in MAPE
over the baseline ML-GNN model. In summary, this approach enables more
efficient and flexible predictive modeling in L-PBF additive manufacturing.",2024-07-18,"Riddhiman Raut, Amit Kumar Ball, Amrita Basak",http://arxiv.org/pdf/2407.13838v1,cs.LG
Non-native Quantum Generative Optimization with Adversarial Autoencoders,"Large-scale optimization problems are prevalent in several fields, including
engineering, finance, and logistics. However, most optimization problems cannot
be efficiently encoded onto a physical system because the existing quantum
samplers have too few qubits. Another typical limiting factor is that the
optimization constraints are not compatible with the native cost Hamiltonian.
This work presents a new approach to address these challenges. We introduce the
adversarial quantum autoencoder model (AQAM) that can be used to map
large-scale optimization problems onto existing quantum samplers while
simultaneously optimizing the problem through latent quantum-enhanced Boltzmann
sampling. We demonstrate the AQAM on a neutral atom sampler, and showcase the
model by optimizing 64px by 64px unit cells that represent a broad-angle filter
metasurface applicable to improving the coherence of neutral atom devices.
Using 12-atom simulations, we demonstrate that the AQAM achieves a lower Renyi
divergence and a larger spectral gap when compared to classical Markov Chain
Monte Carlo samplers. Our work paves the way to more efficient mapping of
conventional optimization problems into existing quantum samplers.",2024-07-18,"Blake A. Wilson, Jonathan Wurtz, Vahagn Mkhitaryan, Michael Bezick, Sheng-Tao Wang, Sabre Kais, Vladimir M. Shalaev, Alexandra Boltasseva",http://arxiv.org/pdf/2407.13830v1,cs.LG
NNsight and NDIF: Democratizing Access to Open-Weight Foundation Model Internals,"We introduce NNsight and NDIF, technologies that work in tandem to enable
scientific study of the representations and computations learned by very large
neural networks. NNsight is an open-source system that extends PyTorch to
introduce deferred remote execution. The National Deep Inference Fabric (NDIF)
is a scalable inference service that executes NNsight requests, allowing users
to share GPU resources and pretrained models. These technologies are enabled by
the Intervention Graph, an architecture developed to decouple experimental
design from model runtime. Together, this framework provides transparent and
efficient access to the internals of deep neural networks such as very large
language models (LLMs) without imposing the cost or complexity of hosting
customized models individually. We conduct a quantitative survey of the machine
learning literature that reveals a growing gap in the study of the internals of
large-scale AI. We demonstrate the design and use of our framework to address
this gap by enabling a range of research methods on huge models. Finally, we
conduct benchmarks to compare performance with previous approaches.
  Code, documentation, and tutorials are available at https://nnsight.net/.",2024-07-18,"Jaden Fiotto-Kaufman, Alexander R. Loftus, Eric Todd, Jannik Brinkmann, Koyena Pal, Dmitrii Troitskii, Michael Ripa, Adam Belfki, Can Rager, Caden Juang, Aaron Mueller, Samuel Marks, Arnab Sen Sharma, Francesca Lucchetti, Nikhil Prakash, Carla Brodley, Arjun Guha, Jonathan Bell, Byron C. Wallace, David Bau",http://arxiv.org/pdf/2407.14561v4,cs.LG
Automated and Holistic Co-design of Neural Networks and ASICs for Enabling In-Pixel Intelligence,"Extreme edge-AI systems, such as those in readout ASICs for radiation
detection, must operate under stringent hardware constraints such as
micron-level dimensions, sub-milliwatt power, and nanosecond-scale speed while
providing clear accuracy advantages over traditional architectures. Finding
ideal solutions means identifying optimal AI and ASIC design choices from a
design space that has explosively expanded during the merger of these domains,
creating non-trivial couplings which together act upon a small set of solutions
as constraints tighten. It is impractical, if not impossible, to manually
determine ideal choices among possibilities that easily exceed billions even in
small-size problems. Existing methods to bridge this gap have leveraged
theoretical understanding of hardware to f architecture search. However, the
assumptions made in computing such theoretical metrics are too idealized to
provide sufficient guidance during the difficult search for a practical
implementation. Meanwhile, theoretical estimates for many other crucial metrics
(like delay) do not even exist and are similarly variable, dependent on
parameters of the process design kit (PDK). To address these challenges, we
present a study that employs intelligent search using multi-objective Bayesian
optimization, integrating both neural network search and ASIC synthesis in the
loop. This approach provides reliable feedback on the collective impact of all
cross-domain design choices. We showcase the effectiveness of our approach by
finding several Pareto-optimal design choices for effective and efficient
neural networks that perform real-time feature extraction from input pulses
within the individual pixels of a readout ASIC.",2024-07-18,"Shubha R. Kharel, Prashansa Mukim, Piotr Maj, Grzegorz W. Deptuch, Shinjae Yoo, Yihui Ren, Soumyajit Mandal",http://arxiv.org/pdf/2407.14560v1,cs.LG
Random Latent Exploration for Deep Reinforcement Learning,"We introduce Random Latent Exploration (RLE), a simple yet effective
exploration strategy in reinforcement learning (RL). On average, RLE
outperforms noise-based methods, which perturb the agent's actions, and
bonus-based exploration, which rewards the agent for attempting novel
behaviors. The core idea of RLE is to encourage the agent to explore different
parts of the environment by pursuing randomly sampled goals in a latent space.
RLE is as simple as noise-based methods, as it avoids complex bonus
calculations but retains the deep exploration benefits of bonus-based methods.
Our experiments show that RLE improves performance on average in both discrete
(e.g., Atari) and continuous control tasks (e.g., Isaac Gym), enhancing
exploration while remaining a simple and general plug-in for existing RL
algorithms. Project website and code:
https://srinathm1359.github.io/random-latent-exploration",2024-07-18,"Srinath Mahankali, Zhang-Wei Hong, Ayush Sekhari, Alexander Rakhlin, Pulkit Agrawal",http://arxiv.org/pdf/2407.13755v3,cs.LG
Multi-Label Learning with Stronger Consistency Guarantees,"We present a detailed study of surrogate losses and algorithms for
multi-label learning, supported by $H$-consistency bounds. We first show that,
for the simplest form of multi-label loss (the popular Hamming loss), the
well-known consistent binary relevance surrogate suffers from a sub-optimal
dependency on the number of labels in terms of $H$-consistency bounds, when
using smooth losses such as logistic losses. Furthermore, this loss function
fails to account for label correlations. To address these drawbacks, we
introduce a novel surrogate loss, multi-label logistic loss, that accounts for
label correlations and benefits from label-independent $H$-consistency bounds.
We then broaden our analysis to cover a more extensive family of multi-label
losses, including all common ones and a new extension defined based on
linear-fractional functions with respect to the confusion matrix. We also
extend our multi-label logistic losses to more comprehensive multi-label
comp-sum losses, adapting comp-sum losses from standard classification to the
multi-label learning. We prove that this family of surrogate losses benefits
from $H$-consistency bounds, and thus Bayes-consistency, across any general
multi-label loss. Our work thus proposes a unified surrogate loss framework
benefiting from strong consistency guarantees for any multi-label loss,
significantly expanding upon previous work which only established
Bayes-consistency and for specific loss functions. Additionally, we adapt
constrained losses from standard classification to multi-label constrained
losses in a similar way, which also benefit from $H$-consistency bounds and
thus Bayes-consistency for any multi-label loss. We further describe efficient
gradient computation algorithms for minimizing the multi-label logistic loss.",2024-07-18,"Anqi Mao, Mehryar Mohri, Yutao Zhong",http://arxiv.org/pdf/2407.13746v1,cs.LG
Optimistic Q-learning for average reward and episodic reinforcement learning,"We present an optimistic Q-learning algorithm for regret minimization in
average reward reinforcement learning under an additional assumption on the
underlying MDP that for all policies, the time to visit some frequent state
$s_0$ is finite and upper bounded by $H$, either in expectation or with
constant probability. Our setting strictly generalizes the episodic setting and
is significantly less restrictive than the assumption of bounded hitting time
\textit{for all states} made by most previous literature on model-free
algorithms in average reward settings. We demonstrate a regret bound of
$\tilde{O}(H^5 S\sqrt{AT})$, where $S$ and $A$ are the numbers of states and
actions, and $T$ is the horizon. A key technical novelty of our work is the
introduction of an $\overline{L}$ operator defined as $\overline{L} v =
\frac{1}{H} \sum_{h=1}^H L^h v$ where $L$ denotes the Bellman operator. Under
the given assumption, we show that the $\overline{L}$ operator has a strict
contraction (in span) even in the average-reward setting where the discount
factor is $1$. Our algorithm design uses ideas from episodic Q-learning to
estimate and apply this operator iteratively. Thus, we provide a unified view
of regret minimization in episodic and non-episodic settings, which may be of
independent interest.",2024-07-18,"Priyank Agrawal, Shipra Agrawal",http://arxiv.org/pdf/2407.13743v2,cs.LG
Dynamic Pricing in Securities Lending Market: Application in Revenue Optimization for an Agent Lender Portfolio,"Securities lending is an important part of the financial market structure,
where agent lenders help long term institutional investors to lend out their
securities to short sellers in exchange for a lending fee. Agent lenders within
the market seek to optimize revenue by lending out securities at the highest
rate possible. Typically, this rate is set by hard-coded business rules or
standard supervised machine learning models. These approaches are often
difficult to scale and are not adaptive to changing market conditions. Unlike a
traditional stock exchange with a centralized limit order book, the securities
lending market is organized similarly to an e-commerce marketplace, where agent
lenders and borrowers can transact at any agreed price in a bilateral fashion.
This similarity suggests that the use of typical methods for addressing dynamic
pricing problems in e-commerce could be effective in the securities lending
market. We show that existing contextual bandit frameworks can be successfully
utilized in the securities lending market. Using offline evaluation on real
historical data, we show that the contextual bandit approach can consistently
outperform typical approaches by at least 15% in terms of total revenue
generated.",2024-07-18,"Jing Xu, Yung-Cheng Hsu, William Biscarri",http://arxiv.org/pdf/2407.13687v4,cs.LG
Understanding Reinforcement Learning-Based Fine-Tuning of Diffusion Models: A Tutorial and Review,"This tutorial provides a comprehensive survey of methods for fine-tuning
diffusion models to optimize downstream reward functions. While diffusion
models are widely known to provide excellent generative modeling capability,
practical applications in domains such as biology require generating samples
that maximize some desired metric (e.g., translation efficiency in RNA, docking
score in molecules, stability in protein). In these cases, the diffusion model
can be optimized not only to generate realistic samples but also to explicitly
maximize the measure of interest. Such methods are based on concepts from
reinforcement learning (RL). We explain the application of various RL
algorithms, including PPO, differentiable optimization, reward-weighted MLE,
value-weighted sampling, and path consistency learning, tailored specifically
for fine-tuning diffusion models. We aim to explore fundamental aspects such as
the strengths and limitations of different RL-based fine-tuning algorithms
across various scenarios, the benefits of RL-based fine-tuning compared to
non-RL-based approaches, and the formal objectives of RL-based fine-tuning
(target distributions). Additionally, we aim to examine their connections with
related topics such as classifier guidance, Gflownets, flow-based diffusion
models, path integral control theory, and sampling from unnormalized
distributions such as MCMC. The code of this tutorial is available at
https://github.com/masa-ue/RLfinetuning_Diffusion_Bioseq",2024-07-18,"Masatoshi Uehara, Yulai Zhao, Tommaso Biancalani, Sergey Levine",http://arxiv.org/pdf/2407.13734v1,cs.LG
Realizable $H$-Consistent and Bayes-Consistent Loss Functions for Learning to Defer,"We present a comprehensive study of surrogate loss functions for learning to
defer. We introduce a broad family of surrogate losses, parameterized by a
non-increasing function $\Psi$, and establish their realizable $H$-consistency
under mild conditions. For cost functions based on classification error, we
further show that these losses admit $H$-consistency bounds when the hypothesis
set is symmetric and complete, a property satisfied by common neural network
and linear function hypothesis sets. Our results also resolve an open question
raised in previous work (Mozannar et al., 2023) by proving the realizable
$H$-consistency and Bayes-consistency of a specific surrogate loss.
Furthermore, we identify choices of $\Psi$ that lead to $H$-consistent
surrogate losses for any general cost function, thus achieving
Bayes-consistency, realizable $H$-consistency, and $H$-consistency bounds
simultaneously. We also investigate the relationship between $H$-consistency
bounds and realizable $H$-consistency in learning to defer, highlighting key
differences from standard classification. Finally, we empirically evaluate our
proposed surrogate losses and compare them with existing baselines.",2024-07-18,"Anqi Mao, Mehryar Mohri, Yutao Zhong",http://arxiv.org/pdf/2407.13732v1,cs.LG
Predictive Low Rank Matrix Learning under Partial Observations: Mixed-Projection ADMM,"We study the problem of learning a partially observed matrix under the low
rank assumption in the presence of fully observed side information that depends
linearly on the true underlying matrix. This problem consists of an important
generalization of the Matrix Completion problem, a central problem in
Statistics, Operations Research and Machine Learning, that arises in
applications such as recommendation systems, signal processing, system
identification and image denoising. We formalize this problem as an
optimization problem with an objective that balances the strength of the fit of
the reconstruction to the observed entries with the ability of the
reconstruction to be predictive of the side information. We derive a
mixed-projection reformulation of the resulting optimization problem and
present a strong semidefinite cone relaxation. We design an efficient, scalable
alternating direction method of multipliers algorithm that produces high
quality feasible solutions to the problem of interest. Our numerical results
demonstrate that in the small rank regime ($k \leq 15$), our algorithm outputs
solutions that achieve on average $79\%$ lower objective value and $90.1\%$
lower $\ell_2$ reconstruction error than the solutions returned by the best
performing benchmark method on synthetic data. The runtime of our algorithm is
competitive with and often superior to that of the benchmark methods. Our
algorithm is able to solve problems with $n = 10000$ rows and $m = 10000$
columns in less than a minute. On large scale real world data, our algorithm
produces solutions that achieve $67\%$ lower out of sample error than benchmark
methods in $97\%$ less execution time.",2024-07-18,"Dimitris Bertsimas, Nicholas A. G. Johnson",http://arxiv.org/pdf/2407.13731v2,cs.LG
Compressing Structured Tensor Algebra,"Tensor algebra is a crucial component for data-intensive workloads such as
machine learning and scientific computing. As the complexity of data grows,
scientists often encounter a dilemma between the highly specialized dense
tensor algebra and efficient structure-aware algorithms provided by sparse
tensor algebra. In this paper, we introduce DASTAC, a framework to propagate
the tensors's captured high-level structure down to low-level code generation
by incorporating techniques such as automatic data layout compression,
polyhedral analysis, and affine code generation. Our methodology reduces memory
footprint by automatically detecting the best data layout, heavily benefits
from polyhedral optimizations, leverages further optimizations, and enables
parallelization through MLIR. Through extensive experimentation, we show that
DASTAC achieves 1 to 2 orders of magnitude speedup over TACO, a
state-of-the-art sparse tensor compiler, and StructTensor, a state-of-the-art
structured tensor algebra compiler, with a significantly lower memory
footprint.",2024-07-18,"Mahdi Ghorbani, Emilien Bauer, Tobias Grosser, Amir Shaikhha",http://arxiv.org/pdf/2407.13726v1,cs.LG
Enhanced $H$-Consistency Bounds,"Recent research has introduced a key notion of $H$-consistency bounds for
surrogate losses. These bounds offer finite-sample guarantees, quantifying the
relationship between the zero-one estimation error (or other target loss) and
the surrogate loss estimation error for a specific hypothesis set. However,
previous bounds were derived under the condition that a lower bound of the
surrogate loss conditional regret is given as a convex function of the target
conditional regret, without non-constant factors depending on the predictor or
input instance. Can we derive finer and more favorable $H$-consistency bounds?
In this work, we relax this condition and present a general framework for
establishing enhanced $H$-consistency bounds based on more general inequalities
relating conditional regrets. Our theorems not only subsume existing results as
special cases but also enable the derivation of more favorable bounds in
various scenarios. These include standard multi-class classification, binary
and multi-class classification under Tsybakov noise conditions, and bipartite
ranking.",2024-07-18,"Anqi Mao, Mehryar Mohri, Yutao Zhong",http://arxiv.org/pdf/2407.13722v1,cs.LG
Attention Based Simple Primitives for Open World Compositional Zero-Shot Learning,"Compositional Zero-Shot Learning (CZSL) aims to predict unknown compositions
made up of attribute and object pairs. Predicting compositions unseen during
training is a challenging task. We are exploring Open World Compositional
Zero-Shot Learning (OW-CZSL) in this study, where our test space encompasses
all potential combinations of attributes and objects. Our approach involves
utilizing the self-attention mechanism between attributes and objects to
achieve better generalization from seen to unseen compositions. Utilizing a
self-attention mechanism facilitates the model's ability to identify
relationships between attribute and objects. The similarity between the
self-attended textual and visual features is subsequently calculated to
generate predictions during the inference phase. The potential test space may
encompass implausible object-attribute combinations arising from unrestricted
attribute-object pairings. To mitigate this issue, we leverage external
knowledge from ConceptNet to restrict the test space to realistic compositions.
Our proposed model, Attention-based Simple Primitives (ASP), demonstrates
competitive performance, achieving results comparable to the state-of-the-art.",2024-07-18,"Ans Munir, Faisal Z. Qureshi, Muhammad Haris Khan, Mohsen Ali",http://arxiv.org/pdf/2407.13715v1,cs.LG
FSP-Laplace: Function-Space Priors for the Laplace Approximation in Bayesian Deep Learning,"Laplace approximations are popular techniques for endowing deep networks with
epistemic uncertainty estimates as they can be applied without altering the
predictions of the trained network, and they scale to large models and
datasets. While the choice of prior strongly affects the resulting posterior
distribution, computational tractability and lack of interpretability of the
weight space typically limit the Laplace approximation to isotropic Gaussian
priors, which are known to cause pathological behavior as depth increases. As a
remedy, we directly place a prior on function space. More precisely, since
Lebesgue densities do not exist on infinite-dimensional function spaces, we
recast training as finding the so-called weak mode of the posterior measure
under a Gaussian process (GP) prior restricted to the space of functions
representable by the neural network. Through the GP prior, one can express
structured and interpretable inductive biases, such as regularity or
periodicity, directly in function space, while still exploiting the implicit
inductive biases that allow deep networks to generalize. After model
linearization, the training objective induces a negative log-posterior density
to which we apply a Laplace approximation, leveraging highly scalable methods
from matrix-free linear algebra. Our method provides improved results where
prior knowledge is abundant (as is the case in many scientific inference
tasks). At the same time, it stays competitive for black-box supervised
learning problems, where neural networks typically excel.",2024-07-18,"Tristan Cinquin, Marvin Pförtner, Vincent Fortuin, Philipp Hennig, Robert Bamler",http://arxiv.org/pdf/2407.13711v2,cs.LG
Understanding Reference Policies in Direct Preference Optimization,"Direct Preference Optimization (DPO) has become a widely used training method
for the instruction fine-tuning of large language models (LLMs). In this work,
we explore an under-investigated aspect of DPO - its dependency on the
reference model or policy. Such reference policies, typically instantiated as
the model to be further fine-tuned, are important since they can impose an
upper limit on DPO's effectiveness. Therefore, we address three related
research questions in this work. First, we explore the optimal strength of the
KL divergence constraint in DPO, which penalizes deviations from the reference
policy, and find that DPO is sensitive to this strength. Next, we examine the
necessity of the KL-constraint from the reference policies in DPO by providing
both theoretical and empirical comparisons between DPO and related learning
objectives, demonstrating DPO's superiority in this controlled setting.
Additionally, we investigate whether DPO benefits from stronger reference
policies, finding that a stronger reference policy can lead to improved
performance, but only when it is similar to the model being fine-tuned. Our
findings highlight the confounding role of reference policies in DPO and offer
insights for best practices, while also identifying open research questions for
future studies.",2024-07-18,"Yixin Liu, Pengfei Liu, Arman Cohan",http://arxiv.org/pdf/2407.13709v2,cs.LG
Are We Ready for Out-of-Distribution Detection in Digital Pathology?,"The detection of semantic and covariate out-of-distribution (OOD) examples is
a critical yet overlooked challenge in digital pathology (DP). Recently,
substantial insight and methods on OOD detection were presented by the ML
community, but how do they fare in DP applications? To this end, we establish a
benchmark study, our highlights being: 1) the adoption of proper evaluation
protocols, 2) the comparison of diverse detectors in both a single and
multi-model setting, and 3) the exploration into advanced ML settings like
transfer learning (ImageNet vs. DP pre-training) and choice of architecture
(CNNs vs. transformers). Through our comprehensive experiments, we contribute
new insights and guidelines, paving the way for future research and discussion.",2024-07-18,"Ji-Hun Oh, Kianoush Falahkheirkhah, Rohit Bhargava",http://arxiv.org/pdf/2407.13708v1,cs.LG
Discovering governing equation in structural dynamics from acceleration-only measurements,"Over the past few years, equation discovery has gained popularity in
different fields of science and engineering. However, existing equation
discovery algorithms rely on the availability of noisy measurements of the
state variables (i.e., displacement {and velocity}). This is a major bottleneck
in structural dynamics, where we often only have access to acceleration
measurements. To that end, this paper introduces a novel equation discovery
algorithm for discovering governing equations of dynamical systems from
acceleration-only measurements. The proposed algorithm employs a library-based
approach for equation discovery. To enable equation discovery from
acceleration-only measurements, we propose a novel Approximate Bayesian
Computation (ABC) model that prioritizes parsimonious models. The efficacy of
the proposed algorithm is illustrated using {four} structural dynamics examples
that include both linear and nonlinear dynamical systems. The case studies
presented illustrate the possible application of the proposed approach for
equation discovery of dynamical systems from acceleration-only measurements.",2024-07-18,"Calvin Alvares, Souvik Chakraborty",http://arxiv.org/pdf/2407.13704v1,cs.LG
PASTA: Controllable Part-Aware Shape Generation with Autoregressive Transformers,"The increased demand for tools that automate the 3D content creation process
led to tremendous progress in deep generative models that can generate diverse
3D objects of high fidelity. In this paper, we present PASTA, an autoregressive
transformer architecture for generating high quality 3D shapes. PASTA comprises
two main components: An autoregressive transformer that generates objects as a
sequence of cuboidal primitives and a blending network, implemented with a
transformer decoder that composes the sequences of cuboids and synthesizes high
quality meshes for each object. Our model is trained in two stages: First we
train our autoregressive generative model using only annotated cuboidal parts
as supervision and next, we train our blending network using explicit 3D
supervision, in the form of watertight meshes. Evaluations on various ShapeNet
objects showcase the ability of our model to perform shape generation from
diverse inputs \eg from scratch, from a partial object, from text and images,
as well size-guided generation, by explicitly conditioning on a bounding box
that defines the object's boundaries. Moreover, as our model considers the
underlying part-based structure of a 3D object, we are able to select a
specific part and produce shapes with meaningful variations of this part. As
evidenced by our experiments, our model generates 3D shapes that are both more
realistic and diverse than existing part-based and non part-based methods,
while at the same time is simpler to implement and train.",2024-07-18,"Songlin Li, Despoina Paschalidou, Leonidas Guibas",http://arxiv.org/pdf/2407.13677v1,cs.LG
Predicting Star Scientists in the Field of Artificial Intelligence: A Machine Learning Approach,"Star scientists are highly influential researchers who have made significant
contributions to their field, gained widespread recognition, and often
attracted substantial research funding. They are critical for the advancement
of science and innovation, and they have a significant influence on the
transfer of knowledge and technology to industry. Identifying potential star
scientists before their performance becomes outstanding is important for
recruitment, collaboration, networking, or research funding decisions. Using
machine learning techniques, this study proposes a model to predict star
scientists in the field of artificial intelligence while highlighting features
related to their success. Our results confirm that rising stars follow
different patterns compared to their non-rising stars counterparts in almost
all the early-career features. We also found that certain features such as
gender and ethnic diversity play important roles in scientific collaboration
and that they can significantly impact an author's career development and
success. The most important features in predicting star scientists in the field
of artificial intelligence were the number of articles, group discipline
diversity, and weighted degree centrality. The proposed approach offers
valuable insights for researchers, practitioners, and funding agencies
interested in identifying and supporting talented researchers.",2024-07-18,"Koosha Shirouyeh, Andrea Schiffauerova, Ashkan Ebadi",http://arxiv.org/pdf/2407.14559v1,cs.LG
Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning,"Uncertainty quantification (UQ) is a crucial but challenging task in many
high-dimensional regression or learning problems to increase the confidence of
a given predictor. We develop a new data-driven approach for UQ in regression
that applies both to classical regression approaches such as the LASSO as well
as to neural networks. One of the most notable UQ techniques is the debiased
LASSO, which modifies the LASSO to allow for the construction of asymptotic
confidence intervals by decomposing the estimation error into a Gaussian and an
asymptotically vanishing bias component. However, in real-world problems with
finite-dimensional data, the bias term is often too significant to be
neglected, resulting in overly narrow confidence intervals. Our work rigorously
addresses this issue and derives a data-driven adjustment that corrects the
confidence intervals for a large class of predictors by estimating the means
and variances of the bias terms from training data, exploiting high-dimensional
concentration phenomena. This gives rise to non-asymptotic confidence
intervals, which can help avoid overestimating uncertainty in critical
applications such as MRI diagnosis. Importantly, our analysis extends beyond
sparse regression to data-driven predictors like neural networks, enhancing the
reliability of model-based deep learning. Our findings bridge the gap between
established theory and the practical applicability of such debiased methods.",2024-07-18,"Frederik Hoppe, Claudio Mayrink Verdun, Hannah Laus, Felix Krahmer, Holger Rauhut",http://arxiv.org/pdf/2407.13666v1,cs.LG
Decision Focused Causal Learning for Direct Counterfactual Marketing Optimization,"Marketing optimization plays an important role to enhance user engagement in
online Internet platforms. Existing studies usually formulate this problem as a
budget allocation problem and solve it by utilizing two fully decoupled stages,
i.e., machine learning (ML) and operation research (OR). However, the learning
objective in ML does not take account of the downstream optimization task in
OR, which causes that the prediction accuracy in ML may be not positively
related to the decision quality.
  Decision Focused Learning (DFL) integrates ML and OR into an end-to-end
framework, which takes the objective of the downstream task as the decision
loss function and guarantees the consistency of the optimization direction
between ML and OR. However, deploying DFL in marketing is non-trivial due to
multiple technological challenges. Firstly, the budget allocation problem in
marketing is a 0-1 integer stochastic programming problem and the budget is
uncertain and fluctuates a lot in real-world settings, which is beyond the
general problem background in DFL. Secondly, the counterfactual in marketing
causes that the decision loss cannot be directly computed and the optimal
solution can never be obtained, both of which disable the common
gradient-estimation approaches in DFL. Thirdly, the OR solver is called
frequently to compute the decision loss during model training in DFL, which
produces huge computational cost and cannot support large-scale training data.
In this paper, we propose a decision focused causal learning framework (DFCL)
for direct counterfactual marketing optimization, which overcomes the above
technological challenges. Both offline experiments and online A/B testing
demonstrate the effectiveness of DFCL over the state-of-the-art methods.
Currently, DFCL has been deployed in several marketing scenarios in Meituan,
one of the largest online food delivery platform in the world.",2024-07-18,"Hao Zhou, Rongxiao Huang, Shaoming Li, Guibin Jiang, Jiaqi Zheng, Bing Cheng, Wei Lin",http://arxiv.org/pdf/2407.13664v1,cs.LG
CogniVoice: Multimodal and Multilingual Fusion Networks for Mild Cognitive Impairment Assessment from Spontaneous Speech,"Mild Cognitive Impairment (MCI) is a medical condition characterized by
noticeable declines in memory and cognitive abilities, potentially affecting
individual's daily activities. In this paper, we introduce CogniVoice, a novel
multilingual and multimodal framework to detect MCI and estimate Mini-Mental
State Examination (MMSE) scores by analyzing speech data and its textual
transcriptions. The key component of CogniVoice is an ensemble multimodal and
multilingual network based on ``Product of Experts'' that mitigates reliance on
shortcut solutions. Using a comprehensive dataset containing both English and
Chinese languages from TAUKADIAL challenge, CogniVoice outperforms the best
performing baseline model on MCI classification and MMSE regression tasks by
2.8 and 4.1 points in F1 and RMSE respectively, and can effectively reduce the
performance gap across different language groups by 0.7 points in F1.",2024-07-18,"Jiali Cheng, Mohamed Elgaar, Nidhi Vakil, Hadi Amiri",http://arxiv.org/pdf/2407.13660v1,cs.LG
Data Alchemy: Mitigating Cross-Site Model Variability Through Test Time Data Calibration,"Deploying deep learning-based imaging tools across various clinical sites
poses significant challenges due to inherent domain shifts and regulatory
hurdles associated with site-specific fine-tuning. For histopathology, stain
normalization techniques can mitigate discrepancies, but they often fall short
of eliminating inter-site variations. Therefore, we present Data Alchemy, an
explainable stain normalization method combined with test time data calibration
via a template learning framework to overcome barriers in cross-site analysis.
Data Alchemy handles shifts inherent to multi-site data and minimizes them
without needing to change the weights of the normalization or classifier
networks. Our approach extends to unseen sites in various clinical settings
where data domain discrepancies are unknown. Extensive experiments highlight
the efficacy of our framework in tumor classification in hematoxylin and
eosin-stained patches. Our explainable normalization method boosts
classification tasks' area under the precision-recall curve(AUPR) by 0.165,
0.545 to 0.710. Additionally, Data Alchemy further reduces the multisite
classification domain gap, by improving the 0.710 AUPR an additional 0.142,
elevating classification performance further to 0.852, from 0.545. Our Data
Alchemy framework can popularize precision medicine with minimal operational
overhead by allowing for the seamless integration of pre-trained deep
learning-based clinical tools across multiple sites.",2024-07-18,"Abhijeet Parida, Antonia Alomar, Zhifan Jiang, Pooneh Roshanitabrizi, Austin Tapp, Maria Ledesma-Carbayo, Ziyue Xu, Syed Muhammed Anwar, Marius George Linguraru, Holger R. Roth",http://arxiv.org/pdf/2407.13632v1,cs.LG
Distributionally and Adversarially Robust Logistic Regression via Intersecting Wasserstein Balls,"Adversarially robust optimization (ARO) has become the de facto standard for
training models to defend against adversarial attacks during testing. However,
despite their robustness, these models often suffer from severe overfitting. To
mitigate this issue, several successful approaches have been proposed,
including replacing the empirical distribution in training with: (i) a
worst-case distribution within an ambiguity set, leading to a distributionally
robust (DR) counterpart of ARO; or (ii) a mixture of the empirical distribution
with one derived from an auxiliary dataset (e.g., synthetic, external, or
out-of-domain). Building on the first approach, we explore the Wasserstein DR
counterpart of ARO for logistic regression and show it admits a tractable
convex optimization reformulation. Adopting the second approach, we enhance the
DR framework by intersecting its ambiguity set with one constructed from an
auxiliary dataset, which yields significant improvements when the Wasserstein
distance between the data-generating and auxiliary distributions can be
estimated. We analyze the resulting optimization problem, develop efficient
solutions, and show that our method outperforms benchmark approaches on
standard datasets.",2024-07-18,"Aras Selvi, Eleonora Kreacic, Mohsen Ghassemi, Vamsi Potluru, Tucker Balch, Manuela Veloso",http://arxiv.org/pdf/2407.13625v2,cs.LG
Misspecified $Q$-Learning with Sparse Linear Function Approximation: Tight Bounds on Approximation Error,"The recent work by Dong & Yang (2023) showed for misspecified sparse linear
bandits, one can obtain an $O\left(\epsilon\right)$-optimal policy using a
polynomial number of samples when the sparsity is a constant, where $\epsilon$
is the misspecification error. This result is in sharp contrast to misspecified
linear bandits without sparsity, which require an exponential number of samples
to get the same guarantee. In order to study whether the analog result is
possible in the reinforcement learning setting, we consider the following
problem: assuming the optimal $Q$-function is a $d$-dimensional linear function
with sparsity $k$ and misspecification error $\epsilon$, whether we can obtain
an $O\left(\epsilon\right)$-optimal policy using number of samples polynomially
in the feature dimension $d$. We first demonstrate why the standard approach
based on Bellman backup or the existing optimistic value function elimination
approach such as OLIVE (Jiang et al., 2017) achieves suboptimal guarantees for
this problem. We then design a novel elimination-based algorithm to show one
can obtain an $O\left(H\epsilon\right)$-optimal policy with sample complexity
polynomially in the feature dimension $d$ and planning horizon $H$. Lastly, we
complement our upper bound with an $\widetilde{\Omega}\left(H\epsilon\right)$
suboptimality lower bound, giving a complete picture of this problem.",2024-07-18,"Ally Yalei Du, Lin F. Yang, Ruosong Wang",http://arxiv.org/pdf/2407.13622v1,cs.LG
Differential Privacy Mechanisms in Neural Tangent Kernel Regression,"Training data privacy is a fundamental problem in modern Artificial
Intelligence (AI) applications, such as face recognition, recommendation
systems, language generation, and many others, as it may contain sensitive user
information related to legal issues. To fundamentally understand how privacy
mechanisms work in AI applications, we study differential privacy (DP) in the
Neural Tangent Kernel (NTK) regression setting, where DP is one of the most
powerful tools for measuring privacy under statistical learning, and NTK is one
of the most popular analysis frameworks for studying the learning mechanisms of
deep neural networks. In our work, we can show provable guarantees for both
differential privacy and test accuracy of our NTK regression. Furthermore, we
conduct experiments on the basic image classification dataset CIFAR10 to
demonstrate that NTK regression can preserve good accuracy under a modest
privacy budget, supporting the validity of our analysis. To our knowledge, this
is the first work to provide a DP guarantee for NTK regression.",2024-07-18,"Jiuxiang Gu, Yingyu Liang, Zhizhou Sha, Zhenmei Shi, Zhao Song",http://arxiv.org/pdf/2407.13621v2,cs.LG
Physics-guided Active Sample Reweighting for Urban Flow Prediction,"Urban flow prediction is a spatio-temporal modeling task that estimates the
throughput of transportation services like buses, taxis, and ride-sharing,
where data-driven models have become the most popular solution in the past
decade. Meanwhile, the implicitly learned mapping between historical
observations to the prediction targets tend to over-simplify the dynamics of
real-world urban flows, leading to suboptimal predictions. Some recent
spatio-temporal prediction solutions bring remedies with the notion of
physics-guided machine learning (PGML), which describes spatio-temporal data
with nuanced and principled physics laws, thus enhancing both the prediction
accuracy and interpretability. However, these spatio-temporal PGML methods are
built upon a strong assumption that the observed data fully conforms to the
differential equations that define the physical system, which can quickly
become ill-posed in urban flow prediction tasks. The observed urban flow data,
especially when sliced into time-dependent snapshots to facilitate predictions,
is typically incomplete and sparse, and prone to inherent noise incurred in the
collection process. As a result, such physical inconsistency between the data
and PGML model significantly limits the predictive power and robustness of the
solution. Moreover, due to the interval-based predictions and intermittent
nature of data filing in many transportation services, the instantaneous
dynamics of urban flows can hardly be captured, rendering differential
equation-based continuous modeling a loose fit for this setting. To overcome
the challenges, we develop a discretized physics-guided network (PN), and
propose a data-aware framework Physics-guided Active Sample Reweighting
(P-GASR) to enhance PN. Experimental results in four real-world datasets
demonstrate that our method achieves state-of-the-art performance with a
demonstrable improvement in robustness.",2024-07-18,"Wei Jiang, Tong Chen, Guanhua Ye, Wentao Zhang, Lizhen Cui, Zi Huang, Hongzhi Yin",http://arxiv.org/pdf/2407.13605v2,cs.LG
A Foundation Model for Soccer,"We propose a foundation model for soccer, which is able to predict subsequent
actions in a soccer match from a given input sequence of actions. As a proof of
concept, we train a transformer architecture on three seasons of data from a
professional soccer league. We quantitatively and qualitatively compare the
performance of this transformer architecture to two baseline models: a Markov
model and a multi-layer perceptron. Additionally, we discuss potential
applications of our model. We provide an open-source implementation of our
methods at https://github.com/danielhocevar/Foundation-Model-for-Soccer.",2024-07-18,"Ethan Baron, Daniel Hocevar, Zach Salehe",http://arxiv.org/pdf/2407.14558v1,cs.LG
Mechanistically Interpreting a Transformer-based 2-SAT Solver: An Axiomatic Approach,"Mechanistic interpretability aims to reverse engineer the computation
performed by a neural network in terms of its internal components. Although
there is a growing body of research on mechanistic interpretation of neural
networks, the notion of a mechanistic interpretation itself is often ad-hoc.
Inspired by the notion of abstract interpretation from the program analysis
literature that aims to develop approximate semantics for programs, we give a
set of axioms that formally characterize a mechanistic interpretation as a
description that approximately captures the semantics of the neural network
under analysis in a compositional manner. We use these axioms to guide the
mechanistic interpretability analysis of a Transformer-based model trained to
solve the well-known 2-SAT problem. We are able to reverse engineer the
algorithm learned by the model -- the model first parses the input formulas and
then evaluates their satisfiability via enumeration of different possible
valuations of the Boolean input variables. We also present evidence to support
that the mechanistic interpretation of the analyzed model indeed satisfies the
stated axioms.",2024-07-18,"Nils Palumbo, Ravi Mangal, Zifan Wang, Saranya Vijayakumar, Corina S. Pasareanu, Somesh Jha",http://arxiv.org/pdf/2407.13594v1,cs.LG
MeshFeat: Multi-Resolution Features for Neural Fields on Meshes,"Parametric feature grid encodings have gained significant attention as an
encoding approach for neural fields since they allow for much smaller MLPs,
which significantly decreases the inference time of the models. In this work,
we propose MeshFeat, a parametric feature encoding tailored to meshes, for
which we adapt the idea of multi-resolution feature grids from Euclidean space.
We start from the structure provided by the given vertex topology and use a
mesh simplification algorithm to construct a multi-resolution feature
representation directly on the mesh. The approach allows the usage of small
MLPs for neural fields on meshes, and we show a significant speed-up compared
to previous representations while maintaining comparable reconstruction quality
for texture reconstruction and BRDF representation. Given its intrinsic
coupling to the vertices, the method is particularly well-suited for
representations on deforming meshes, making it a good fit for object animation.",2024-07-18,"Mihir Mahajan, Florian Hofherr, Daniel Cremers",http://arxiv.org/pdf/2407.13592v1,cs.LG
High-Dimensional Confidence Regions in Sparse MRI,"One of the most promising solutions for uncertainty quantification in
high-dimensional statistics is the debiased LASSO that relies on unconstrained
$\ell_1$-minimization. The initial works focused on real Gaussian designs as a
toy model for this problem. However, in medical imaging applications, such as
compressive sensing for MRI, the measurement system is represented by a
(subsampled) complex Fourier matrix. The purpose of this work is to extend the
method to the MRI case in order to construct confidence intervals for each
pixel of an MR image. We show that a sufficient amount of data is $n \gtrsim
\max\{ s_0\log^2 s_0\log p, s_0 \log^2 p \}$.",2024-07-18,"Frederik Hoppe, Felix Krahmer, Claudio Mayrink Verdun, Marion Menzel, Holger Rauhut",http://arxiv.org/pdf/2407.18964v1,cs.LG
With or Without Replacement? Improving Confidence in Fourier Imaging,"Over the last few years, debiased estimators have been proposed in order to
establish rigorous confidence intervals for high-dimensional problems in
machine learning and data science. The core argument is that the error of these
estimators with respect to the ground truth can be expressed as a Gaussian
variable plus a remainder term that vanishes as long as the dimension of the
problem is sufficiently high. Thus, uncertainty quantification (UQ) can be
performed exploiting the Gaussian model. Empirically, however, the remainder
term cannot be neglected in many realistic situations of moderately-sized
dimensions, in particular in certain structured measurement scenarios such as
Magnetic Resonance Imaging (MRI). This, in turn, can downgrade the advantage of
the UQ methods as compared to non-UQ approaches such as the standard LASSO. In
this paper, we present a method to improve the debiased estimator by sampling
without replacement. Our approach leverages recent results of ours on the
structure of the random nature of certain sampling schemes showing how a
transition between sampling with and without replacement can lead to a weighted
reconstruction scheme with improved performance for the standard LASSO. In this
paper, we illustrate how this reweighted sampling idea can also improve the
debiased estimator and, consequently, provide a better method for UQ in Fourier
imaging.",2024-07-18,"Frederik Hoppe, Claudio Mayrink Verdun, Felix Krahmer, Marion I. Menzel, Holger Rauhut",http://arxiv.org/pdf/2407.13575v1,cs.LG
EnergyDiff: Universal Time-Series Energy Data Generation using Diffusion Models,"High-resolution time series data are crucial for the operation and planning
of energy systems such as electrical power systems and heating systems. Such
data often cannot be shared due to privacy concerns, necessitating the use of
synthetic data. However, high-resolution time series data is difficult to model
due to its inherent high dimensionality and complex temporal dependencies.
Leveraging the recent development of generative AI, especially diffusion
models, we propose EnergyDiff, a universal data generation framework for energy
time series data. EnergyDiff builds on state-of-the-art denoising diffusion
probabilistic models, utilizing a proposed denoising network dedicated to
high-resolution time series data and introducing a novel Marginal Calibration
technique. Our extensive experimental results demonstrate that EnergyDiff
achieves significant improvement in capturing the temporal dependencies and
marginal distributions compared to baselines, particularly at the 1-minute
resolution. Additionally, EnergyDiff consistently generates highquality time
series data across diverse energy domains, time resolutions, and at both
customer and transformer levels with reduced computational need.",2024-07-18,"Nan Lin, Peter Palensky, Pedro P. Vergara",http://arxiv.org/pdf/2407.13538v2,cs.LG
Evaluating the performance-deviation of itemKNN in RecBole and LensKit,"This study examines the performance of item-based k-Nearest Neighbors
(ItemKNN) algorithms in the RecBole and LensKit recommender system libraries.
Using four data sets (Anime, Modcloth, ML-100K, and ML-1M), we assess each
library's efficiency, accuracy, and scalability, focusing primarily on
normalized discounted cumulative gain (nDCG). Our results show that RecBole
outperforms LensKit on two of three metrics on the ML-100K data set: it
achieved an 18% higher nDCG, 14% higher precision, and 35% lower recall. To
ensure a fair comparison, we adjusted LensKit's nDCG calculation to match
RecBole's method. This alignment made the performance more comparable, with
LensKit achieving an nDCG of 0.2540 and RecBole 0.2674. Differences in
similarity matrix calculations were identified as the main cause of performance
deviations. After modifying LensKit to retain only the top K similar items,
both libraries showed nearly identical nDCG values across all data sets. For
instance, both achieved an nDCG of 0.2586 on the ML-1M data set with the same
random seed. Initially, LensKit's original implementation only surpassed
RecBole in the ModCloth dataset.",2024-07-18,"Michael Schmidt, Jannik Nitschke, Tim Prinz",http://arxiv.org/pdf/2407.13531v1,cs.LG
Discussion: Effective and Interpretable Outcome Prediction by Training Sparse Mixtures of Linear Experts,"Process Outcome Prediction entails predicting a discrete property of an
unfinished process instance from its partial trace. High-capacity outcome
predictors discovered with ensemble and deep learning methods have been shown
to achieve top accuracy performances, but they suffer from a lack of
transparency. Aligning with recent efforts to learn inherently interpretable
outcome predictors, we propose to train a sparse Mixture-of-Experts where both
the ``gate'' and ``expert'' sub-nets are Logistic Regressors. This
ensemble-like model is trained end-to-end while automatically selecting a
subset of input features in each sub-net, as an alternative to the common
approach of performing a global feature selection step prior to model training.
Test results on benchmark logs confirmed the validity and efficacy of this
approach.",2024-07-18,"Francesco Folino, Luigi Pontieri, Pietro Sabatino",http://arxiv.org/pdf/2407.13526v1,cs.LG
INDIC QA BENCHMARK: A Multilingual Benchmark to Evaluate Question Answering capability of LLMs for Indic Languages,"Large Language Models (LLMs) perform well on unseen tasks in English, but
their abilities in non English languages are less explored due to limited
benchmarks and training data. To bridge this gap, we introduce the Indic QA
Benchmark, a large dataset for context grounded question answering in 11 major
Indian languages, covering both extractive and abstractive tasks. Evaluations
of multilingual LLMs, including instruction finetuned versions, revealed weak
performance in low resource languages due to a strong English language bias in
their training data. We also investigated the Translate Test paradigm,where
inputs are translated to English for processing and the results are translated
back into the source language for output. This approach outperformed
multilingual LLMs, particularly in low resource settings. By releasing Indic
QA, we aim to promote further research into LLMs question answering
capabilities in low resource languages. This benchmark offers a critical
resource to address existing limitations and foster multilingual understanding.",2024-07-18,"Abhishek Kumar Singh, Vishwajeet kumar, Rudra Murthy, Jaydeep Sen, Ashish Mittal, Ganesh Ramakrishnan",http://arxiv.org/pdf/2407.13522v2,cs.LG
CIC: Circular Image Compression,"Learned image compression (LIC) is currently the cutting-edge method.
However, the inherent difference between testing and training images of LIC
results in performance degradation to some extent. Especially for
out-of-sample, out-of-distribution, or out-of-domain testing images, the
performance of LIC dramatically degraded. Classical LIC is a serial image
compression (SIC) approach that utilizes an open-loop architecture with serial
encoding and decoding units. Nevertheless, according to the theory of automatic
control, a closed-loop architecture holds the potential to improve the dynamic
and static performance of LIC. Therefore, a circular image compression (CIC)
approach with closed-loop encoding and decoding elements is proposed to
minimize the gap between testing and training images and upgrade the capability
of LIC. The proposed CIC establishes a nonlinear loop equation and proves that
steady-state error between reconstructed and original images is close to zero
by Taylor series expansion. The proposed CIC method possesses the property of
Post-Training and plug-and-play which can be built on any existing advanced SIC
methods. Experimental results on five public image compression datasets
demonstrate that the proposed CIC outperforms five competing state-of-the-art
open-source SIC algorithms in reconstruction capacity. Experimental results
further show that the proposed method is suitable for out-of-sample testing
images with dark backgrounds, sharp edges, high contrast, grid shapes, or
complex patterns.",2024-07-18,"Honggui Li, Sinan Chen, Nahid Md Lokman Hossain, Maria Trocan, Dimitri Galayko, Mohamad Sawan",http://arxiv.org/pdf/2407.15870v2,cs.LG
From A-to-Z Review of Clustering Validation Indices,"Data clustering involves identifying latent similarities within a dataset and
organizing them into clusters or groups. The outcomes of various clustering
algorithms differ as they are susceptible to the intrinsic characteristics of
the original dataset, including noise and dimensionality. The effectiveness of
such clustering procedures directly impacts the homogeneity of clusters,
underscoring the significance of evaluating algorithmic outcomes. Consequently,
the assessment of clustering quality presents a significant and complex
endeavor. A pivotal aspect affecting clustering validation is the cluster
validity metric, which aids in determining the optimal number of clusters. The
main goal of this study is to comprehensively review and explain the
mathematical operation of internal and external cluster validity indices, but
not all, to categorize these indices and to brainstorm suggestions for future
advancement of clustering validation research. In addition, we review and
evaluate the performance of internal and external clustering validation indices
on the most common clustering algorithms, such as the evolutionary clustering
algorithm star (ECA*). Finally, we suggest a classification framework for
examining the functionality of both internal and external clustering validation
measures regarding their ideal values, user-friendliness, responsiveness to
input data, and appropriateness across various fields. This classification aids
researchers in selecting the appropriate clustering validation measure to suit
their specific requirements.",2024-07-18,"Bryar A. Hassan, Noor Bahjat Tayfor, Alla A. Hassan, Aram M. Ahmed, Tarik A. Rashid, Naz N. Abdalla",http://arxiv.org/pdf/2407.20246v1,cs.LG
Model-based Policy Optimization using Symbolic World Model,"The application of learning-based control methods in robotics presents
significant challenges. One is that model-free reinforcement learning
algorithms use observation data with low sample efficiency. To address this
challenge, a prevalent approach is model-based reinforcement learning, which
involves employing an environment dynamics model. We suggest approximating
transition dynamics with symbolic expressions, which are generated via symbolic
regression. Approximation of a mechanical system with a symbolic model has
fewer parameters than approximation with neural networks, which can potentially
lead to higher accuracy and quality of extrapolation. We use a symbolic
dynamics model to generate trajectories in model-based policy optimization to
improve the sample efficiency of the learning algorithm. We evaluate our
approach across various tasks within simulated environments. Our method
demonstrates superior sample efficiency in these tasks compared to model-free
and model-based baseline methods.",2024-07-18,"Andrey Gorodetskiy, Konstantin Mironov, Aleksandr Panov",http://arxiv.org/pdf/2407.13518v1,cs.LG
Instance Selection for Dynamic Algorithm Configuration with Reinforcement Learning: Improving Generalization,"Dynamic Algorithm Configuration (DAC) addresses the challenge of dynamically
setting hyperparameters of an algorithm for a diverse set of instances rather
than focusing solely on individual tasks. Agents trained with Deep
Reinforcement Learning (RL) offer a pathway to solve such settings. However,
the limited generalization performance of these agents has significantly
hindered the application in DAC. Our hypothesis is that a potential bias in the
training instances limits generalization capabilities. We take a step towards
mitigating this by selecting a representative subset of training instances to
overcome overrepresentation and then retraining the agent on this subset to
improve its generalization performance. For constructing the meta-features for
the subset selection, we particularly account for the dynamic nature of the RL
agent by computing time series features on trajectories of actions and rewards
generated by the agent's interaction with the environment. Through empirical
evaluations on the Sigmoid and CMA-ES benchmarks from the standard benchmark
library for DAC, called DACBench, we discuss the potentials of our selection
technique compared to training on the entire instance set. Our results
highlight the efficacy of instance selection in refining DAC policies for
diverse instance spaces.",2024-07-18,"Carolin Benjamins, Gjorgjina Cenikj, Ana Nikolikj, Aditya Mohan, Tome Eftimov, Marius Lindauer",http://arxiv.org/pdf/2407.13513v1,cs.LG
Spontaneous Style Text-to-Speech Synthesis with Controllable Spontaneous Behaviors Based on Language Models,"Spontaneous style speech synthesis, which aims to generate human-like speech,
often encounters challenges due to the scarcity of high-quality data and
limitations in model capabilities. Recent language model-based TTS systems can
be trained on large, diverse, and low-quality speech datasets, resulting in
highly natural synthesized speech. However, they are limited by the difficulty
of simulating various spontaneous behaviors and capturing prosody variations in
spontaneous speech. In this paper, we propose a novel spontaneous speech
synthesis system based on language models. We systematically categorize and
uniformly model diverse spontaneous behaviors. Moreover, fine-grained prosody
modeling is introduced to enhance the model's ability to capture subtle prosody
variations in spontaneous speech.Experimental results show that our proposed
method significantly outperforms the baseline methods in terms of prosody
naturalness and spontaneous behavior naturalness.",2024-07-18,"Weiqin Li, Peiji Yang, Yicheng Zhong, Yixuan Zhou, Zhisheng Wang, Zhiyong Wu, Xixin Wu, Helen Meng",http://arxiv.org/pdf/2407.13509v1,cs.LG
"Training Foundation Models as Data Compression: On Information, Model Weights and Copyright Law","The training process of foundation models as for other classes of deep
learning systems is based on minimizing the reconstruction error over a
training set. For this reason, they are susceptible to the memorization and
subsequent reproduction of training samples. In this paper, we introduce a
training-as-compressing perspective, wherein the model's weights embody a
compressed representation of the training data. From a copyright standpoint,
this point of view implies that the weights can be considered a reproduction
or, more likely, a derivative work of a potentially protected set of works. We
investigate the technical and legal challenges that emerge from this framing of
the copyright of outputs generated by foundation models, including their
implications for practitioners and researchers. We demonstrate that adopting an
information-centric approach to the problem presents a promising pathway for
tackling these emerging complex legal issues.",2024-07-18,"Giorgio Franceschelli, Claudia Cevenini, Mirco Musolesi",http://arxiv.org/pdf/2407.13493v4,cs.LG
An Agile Adaptation Method for Multi-mode Vehicle Communication Networks,"This paper focuses on discovering the impact of communication mode allocation
on communication efficiency in the vehicle communication networks. To be
specific, Markov decision process and reinforcement learning are applied to
establish an agile adaptation mechanism for multi-mode communication devices
according to the driving scenarios and business requirements. Then, Q-learning
is used to train the agile adaptation reinforcement learning model and output
the trained model. By learning the best actions to take in different states to
maximize the cumulative reward, and avoiding the problem of poor adaptation
effect caused by inaccurate delay measurement in unstable communication
scenarios. The experiments show that the proposed scheme can quickly adapt to
dynamic vehicle networking environment, while achieving high concurrency and
communication efficiency.",2024-07-18,"Shiwen He, Kanghong Chen, Shiyue Huang, Wei Huang, Zhenyu An",http://arxiv.org/pdf/2408.01429v1,cs.LG
LIMT: Language-Informed Multi-Task Visual World Models,"Most recent successes in robot reinforcement learning involve learning a
specialized single-task agent.
  However, robots capable of performing multiple tasks can be much more
valuable in real-world applications.
  Multi-task reinforcement learning can be very challenging due to the
increased sample complexity and the potentially conflicting task objectives.
  Previous work on this topic is dominated by model-free approaches.
  The latter can be very sample inefficient even when learning specialized
single-task agents.
  In this work, we focus on model-based multi-task reinforcement learning.
  We propose a method for learning multi-task visual world models, leveraging
pre-trained language models to extract semantically meaningful task
representations.
  These representations are used by the world model and policy to reason about
task similarity in dynamics and behavior.
  Our results highlight the benefits of using language-driven task
representations for world models and a clear advantage of model-based
multi-task learning over the more common model-free paradigm.",2024-07-18,"Elie Aljalbout, Nikolaos Sotirakis, Patrick van der Smagt, Maximilian Karl, Nutan Chen",http://arxiv.org/pdf/2407.13466v1,cs.LG
SA-DVAE: Improving Zero-Shot Skeleton-Based Action Recognition by Disentangled Variational Autoencoders,"Existing zero-shot skeleton-based action recognition methods utilize
projection networks to learn a shared latent space of skeleton features and
semantic embeddings. The inherent imbalance in action recognition datasets,
characterized by variable skeleton sequences yet constant class labels,
presents significant challenges for alignment. To address the imbalance, we
propose SA-DVAE -- Semantic Alignment via Disentangled Variational
Autoencoders, a method that first adopts feature disentanglement to separate
skeleton features into two independent parts -- one is semantic-related and
another is irrelevant -- to better align skeleton and semantic features. We
implement this idea via a pair of modality-specific variational autoencoders
coupled with a total correction penalty. We conduct experiments on three
benchmark datasets: NTU RGB+D, NTU RGB+D 120 and PKU-MMD, and our experimental
results show that SA-DAVE produces improved performance over existing methods.
The code is available at https://github.com/pha123661/SA-DVAE.",2024-07-18,"Sheng-Wei Li, Zi-Xiang Wei, Wei-Jie Chen, Yi-Hsin Yu, Chih-Yuan Yang, Jane Yung-jen Hsu",http://arxiv.org/pdf/2407.13460v1,cs.LG
All Roads Lead to Rome? Exploring Representational Similarities Between Latent Spaces of Generative Image Models,"Do different generative image models secretly learn similar underlying
representations? We investigate this by measuring the latent space similarity
of four different models: VAEs, GANs, Normalizing Flows (NFs), and Diffusion
Models (DMs). Our methodology involves training linear maps between frozen
latent spaces to ""stitch"" arbitrary pairs of encoders and decoders and
measuring output-based and probe-based metrics on the resulting ""stitched''
models. Our main findings are that linear maps between latent spaces of
performant models preserve most visual information even when latent sizes
differ; for CelebA models, gender is the most similarly represented probe-able
attribute. Finally we show on an NF that latent space representations converge
early in training.",2024-07-18,"Charumathi Badrinath, Usha Bhalla, Alex Oesterling, Suraj Srinivas, Himabindu Lakkaraju",http://arxiv.org/pdf/2407.13449v1,cs.LG
Enhancing Out-of-Vocabulary Performance of Indian TTS Systems for Practical Applications through Low-Effort Data Strategies,"Publicly available TTS datasets for low-resource languages like Hindi and
Tamil typically contain 10-20 hours of data, leading to poor vocabulary
coverage. This limitation becomes evident in downstream applications where
domain-specific vocabulary coupled with frequent code-mixing with English,
results in many OOV words. To highlight this problem, we create a benchmark
containing OOV words from several real-world applications. Indeed,
state-of-the-art Hindi and Tamil TTS systems perform poorly on this OOV
benchmark, as indicated by intelligibility tests. To improve the model's OOV
performance, we propose a low-effort and economically viable strategy to obtain
more training data. Specifically, we propose using volunteers as opposed to
high quality voice artists to record words containing character bigrams unseen
in the training data. We show that using such inexpensive data, the model's
performance improves on OOV words, while not affecting voice quality and
in-domain performance.",2024-07-18,"Srija Anand, Praveen Srinivasa Varadhan, Ashwin Sankar, Giri Raju, Mitesh M. Khapra",http://arxiv.org/pdf/2407.13435v1,cs.LG
The Art of Imitation: Learning Long-Horizon Manipulation Tasks from Few Demonstrations,"Task Parametrized Gaussian Mixture Models (TP-GMM) are a sample-efficient
method for learning object-centric robot manipulation tasks. However, there are
several open challenges to applying TP-GMMs in the wild. In this work, we
tackle three crucial challenges synergistically. First, end-effector velocities
are non-Euclidean and thus hard to model using standard GMMs. We thus propose
to factorize the robot's end-effector velocity into its direction and
magnitude, and model them using Riemannian GMMs. Second, we leverage the
factorized velocities to segment and sequence skills from complex demonstration
trajectories. Through the segmentation, we further align skill trajectories and
hence leverage time as a powerful inductive bias. Third, we present a method to
automatically detect relevant task parameters per skill from visual
observations. Our approach enables learning complex manipulation tasks from
just five demonstrations while using only RGB-D observations. Extensive
experimental evaluations on RLBench demonstrate that our approach achieves
state-of-the-art performance with 20-fold improved sample efficiency. Our
policies generalize across different environments, object instances, and object
positions, while the learned skills are reusable.",2024-07-18,"Jan Ole von Hartz, Tim Welschehold, Abhinav Valada, Joschka Boedecker",http://arxiv.org/pdf/2407.13432v3,cs.LG
Improving Out-of-Distribution Generalization of Trajectory Prediction for Autonomous Driving via Polynomial Representations,"Robustness against Out-of-Distribution (OoD) samples is a key performance
indicator of a trajectory prediction model. However, the development and
ranking of state-of-the-art (SotA) models are driven by their In-Distribution
(ID) performance on individual competition datasets. We present an OoD testing
protocol that homogenizes datasets and prediction tasks across two large-scale
motion datasets. We introduce a novel prediction algorithm based on polynomial
representations for agent trajectory and road geometry on both the input and
output sides of the model. With a much smaller model size, training effort, and
inference time, we reach near SotA performance for ID testing and significantly
improve robustness in OoD testing. Within our OoD testing protocol, we further
study two augmentation strategies of SotA models and their effects on model
generalization. Highlighting the contrast between ID and OoD performance, we
suggest adding OoD testing to the evaluation criteria of trajectory prediction
models.",2024-07-18,"Yue Yao, Shengchao Yan, Daniel Goehring, Wolfram Burgard, Joerg Reichardt",http://arxiv.org/pdf/2407.13431v3,cs.LG
Towards Dynamic Feature Acquisition on Medical Time Series by Maximizing Conditional Mutual Information,"Knowing which features of a multivariate time series to measure and when is a
key task in medicine, wearables, and robotics. Better acquisition policies can
reduce costs while maintaining or even improving the performance of downstream
predictors. Inspired by the maximization of conditional mutual information, we
propose an approach to train acquirers end-to-end using only the downstream
loss. We show that our method outperforms random acquisition policy, matches a
model with an unrestrained budget, but does not yet overtake a static
acquisition strategy. We highlight the assumptions and outline avenues for
future work.",2024-07-18,"Fedor Sergeev, Paola Malsot, Gunnar Rätsch, Vincent Fortuin",http://arxiv.org/pdf/2407.13429v1,cs.LG
Exploring End-to-end Differentiable Neural Charged Particle Tracking -- A Loss Landscape Perspective,"Measurement and analysis of high energetic particles for scientific, medical
or industrial applications is a complex procedure, requiring the design of
sophisticated detector and data processing systems. The development of adaptive
and differentiable software pipelines using a combination of conventional and
machine learning algorithms is therefore getting ever more important to
optimize and operate the system efficiently while maintaining end-to-end (E2E)
differentiability. We propose for the application of charged particle tracking
an E2E differentiable decision-focused learning scheme using graph neural
networks with combinatorial components solving a linear assignment problem for
each detector layer. We demonstrate empirically that including differentiable
variations of discrete assignment operations allows for efficient network
optimization, working better or on par with approaches that lack E2E
differentiability. In additional studies, we dive deeper into the optimization
process and provide further insights from a loss landscape perspective. We
demonstrate that while both methods converge into similar performing, globally
well-connected regions, they suffer under substantial predictive instability
across initialization and optimization methods, which can have unpredictable
consequences on the performance of downstream tasks such as image
reconstruction. We also point out a dependency between the interpolation factor
of the gradient estimator and the prediction stability of the model, suggesting
the choice of sufficiently small values. Given the strong global connectivity
of learned solutions and the excellent training performance, we argue that E2E
differentiability provides, besides the general availability of gradient
information, an important tool for robust particle tracking to mitigate
prediction instabilities by favoring solutions that perform well on downstream
tasks.",2024-07-18,"Tobias Kortus, Ralf Keidel, Nicolas R. Gauger",http://arxiv.org/pdf/2407.13420v1,cs.LG
From Words to Worlds: Compositionality for Cognitive Architectures,"Large language models (LLMs) are very performant connectionist systems, but
do they exhibit more compositionality? More importantly, is that part of why
they perform so well? We present empirical analyses across four LLM families
(12 models) and three task categories, including a novel task introduced below.
Our findings reveal a nuanced relationship in learning of compositional
strategies by LLMs -- while scaling enhances compositional abilities,
instruction tuning often has a reverse effect. Such disparity brings forth some
open issues regarding the development and improvement of large language models
in alignment with human cognitive capacities.",2024-07-18,"Ruchira Dhar, Anders Søgaard",http://arxiv.org/pdf/2407.13419v1,cs.LG
Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization,"Language model alignment methods such as reinforcement learning from human
feedback (RLHF) have led to impressive advances in language model capabilities,
but are limited by a widely observed phenomenon known as overoptimization,
where the quality of the language model degrades over the course of the
alignment process. As the model optimizes performance with respect to an
offline reward model, it overfits to inaccuracies and drifts away from
preferred responses covered by the data. To discourage such distribution shift,
KL-regularization is widely employed in existing offline alignment methods, but
overoptimization continues to harm performance. Lending theoretical insight
into the source of these empirical observations, we first show that the
KL-regularization is too weak to prevent overfitting, then raise the following
question: is it possible to design an efficient algorithm that is provably
robust to overoptimization?
  We address this question with a new algorithm for offline alignment,
$\chi^2$-Preference Optimization ($\chi$PO). $\chi$PO is a one-line change to
Direct Preference Optimization (DPO; Rafailov et al., 2023), which only
involves modifying the logarithmic link function in the DPO objective. Despite
this minimal change, $\chi$PO implicitly implements the principle of pessimism
in the face of uncertainty via regularization with the $\chi^2$-divergence --
which quantifies uncertainty more effectively than KL-regularization -- and
provably alleviates overoptimization, achieving sample-complexity guarantees
based on single-policy concentrability -- the gold standard in offline
reinforcement learning. $\chi$PO's simplicity and strong guarantees make it the
first practical and general-purpose offline alignment algorithm that is
provably robust to overoptimization.",2024-07-18,"Audrey Huang, Wenhao Zhan, Tengyang Xie, Jason D. Lee, Wen Sun, Akshay Krishnamurthy, Dylan J. Foster",http://arxiv.org/pdf/2407.13399v3,cs.LG
Open-World Visual Reasoning by a Neuro-Symbolic Program of Zero-Shot Symbols,"We consider the problem of finding spatial configurations of multiple objects
in images, e.g., a mobile inspection robot is tasked to localize abandoned
tools on the floor. We define the spatial configuration of objects by
first-order logic in terms of relations and attributes. A neuro-symbolic
program matches the logic formulas to probabilistic object proposals for the
given image, provided by language-vision models by querying them for the
symbols. This work is the first to combine neuro-symbolic programming
(reasoning) and language-vision models (learning) to find spatial
configurations of objects in images in an open world setting. We show the
effectiveness by finding abandoned tools on floors and leaking pipes. We find
that most prediction errors are due to biases in the language-vision model.",2024-07-18,"Gertjan Burghouts, Fieke Hillerström, Erwin Walraven, Michael van Bekkum, Frank Ruis, Joris Sijs, Jelle van Mil, Judith Dijk",http://arxiv.org/pdf/2407.13382v1,cs.LG
Geometric Active Exploration in Markov Decision Processes: the Benefit of Abstraction,"How can a scientist use a Reinforcement Learning (RL) algorithm to design
experiments over a dynamical system's state space? In the case of finite and
Markovian systems, an area called Active Exploration (AE) relaxes the
optimization problem of experiments design into Convex RL, a generalization of
RL admitting a wider notion of reward. Unfortunately, this framework is
currently not scalable and the potential of AE is hindered by the vastness of
experiment spaces typical of scientific discovery applications. However, these
spaces are often endowed with natural geometries, e.g., permutation invariance
in molecular design, that an agent could leverage to improve the statistical
and computational efficiency of AE. To achieve this, we bridge AE and MDP
homomorphisms, which offer a way to exploit known geometric structures via
abstraction. Towards this goal, we make two fundamental contributions: we
extend MDP homomorphisms formalism to Convex RL, and we present, to the best of
our knowledge, the first analysis that formally captures the benefit of
abstraction via homomorphisms on sample efficiency. Ultimately, we propose the
Geometric Active Exploration (GAE) algorithm, which we analyse theoretically
and experimentally in environments motivated by problems in scientific
discovery.",2024-07-18,"Riccardo De Santi, Federico Arangath Joseph, Noah Liniger, Mirco Mutti, Andreas Krause",http://arxiv.org/pdf/2407.13364v1,cs.LG
Capturing Style in Author and Document Representation,"A wide range of Deep Natural Language Processing (NLP) models integrates
continuous and low dimensional representations of words and documents.
Surprisingly, very few models study representation learning for authors. These
representations can be used for many NLP tasks, such as author identification
and classification, or in recommendation systems. A strong limitation of
existing works is that they do not explicitly capture writing style, making
them hardly applicable to literary data. We therefore propose a new
architecture based on Variational Information Bottleneck (VIB) that learns
embeddings for both authors and documents with a stylistic constraint. Our
model fine-tunes a pre-trained document encoder. We stimulate the detection of
writing style by adding predefined stylistic features making the representation
axis interpretable with respect to writing style indicators. We evaluate our
method on three datasets: a literary corpus extracted from the Gutenberg
Project, the Blog Authorship Corpus and IMDb62, for which we show that it
matches or outperforms strong/recent baselines in authorship attribution while
capturing much more accurately the authors stylistic aspects.",2024-07-18,"Enzo Terreau, Antoine Gourru, Julien Velcin",http://arxiv.org/pdf/2407.13358v1,cs.LG
Reconstruct the Pruned Model without Any Retraining,"Structured pruning is a promising hardware-friendly compression technique for
large language models (LLMs), which is expected to be retraining-free to avoid
the enormous retraining cost. This retraining-free paradigm involves (1)
pruning criteria to define the architecture and (2) distortion reconstruction
to restore performance. However, existing methods often emphasize pruning
criteria while using reconstruction techniques that are specific to certain
modules or criteria, resulting in limited generalizability. To address this, we
introduce the Linear Interpolation-based Adaptive Reconstruction (LIAR)
framework, which is both efficient and effective. LIAR does not require
back-propagation or retraining and is compatible with various pruning criteria
and modules. By applying linear interpolation to the preserved weights, LIAR
minimizes reconstruction error and effectively reconstructs the pruned output.
Our evaluations on benchmarks such as GLUE, SQuAD, WikiText, and common sense
reasoning show that LIAR enables a BERT model to maintain 98% accuracy even
after removing 50% of its parameters and achieves top performance for LLaMA in
just a few minutes.",2024-07-18,"Pingjie Wang, Ziqing Fan, Shengchao Hu, Zhe Chen, Yanfeng Wang, Yu Wang",http://arxiv.org/pdf/2407.13331v1,cs.LG
RISC-V RVV efficiency for ANN algorithms,"Handling vast amounts of data is crucial in today's world. The growth of
high-performance computing has created a need for parallelization, particularly
in the area of machine learning algorithms such as ANN (Approximate Nearest
Neighbors). To improve the speed of these algorithms, it is important to
optimize them for specific processor architectures. RISC-V (Reduced Instruction
Set Computer Five) is one of the modern processor architectures, which features
a vector instruction set called RVV (RISC-V Vector Extension). In machine
learning algorithms, vector extensions are widely utilized to improve the
processing of voluminous data. This study examines the effectiveness of
applying RVV to commonly used ANN algorithms. The algorithms were adapted for
RISC-V and optimized using RVV after identifying the primary bottlenecks.
Additionally, we developed a theoretical model of a parameterized vector block
and identified the best on average configuration that demonstrates the highest
theoretical performance of the studied ANN algorithms when the other CPU
parameters are fixed.",2024-07-18,"Konstantin Rumyantsev, Pavel Yakovlev, Andrey Gorshkov, Andrey P. Sokolov",http://arxiv.org/pdf/2407.13326v1,cs.LG
Deterministic Trajectory Optimization through Probabilistic Optimal Control,"In this article, we discuss two algorithms tailored to discrete-time
deterministic finite-horizon nonlinear optimal control problems or so-called
deterministic trajectory optimization problems. Both algorithms can be derived
from an emerging theoretical paradigm that we refer to as probabilistic optimal
control. The paradigm reformulates stochastic optimal control as an equivalent
probabilistic inference problem and can be viewed as a generalisation of the
former. The merit of this perspective is that it allows to address the problem
using the Expectation-Maximization algorithm. It is shown that the application
of this algorithm results in a fixed point iteration of probabilistic policies
that converge to the deterministic optimal policy. Two strategies for policy
evaluation are discussed, using state-of-the-art uncertainty quantification
methods resulting into two distinct algorithms. The algorithms are structurally
closest related to the differential dynamic programming algorithm and related
methods that use sigma-point methods to avoid direct gradient evaluations. The
main advantage of the algorithms is an improved balance between exploration and
exploitation over the iterations, leading to improved numerical stability and
accelerated convergence. These properties are demonstrated on different
nonlinear systems.",2024-07-18,"Mohammad Mahmoudi Filabadi, Tom Lefebvre, Guillaume Crevecoeur",http://arxiv.org/pdf/2407.13316v3,cs.LG
A deep latent variable model for semi-supervised multi-unit soft sensing in industrial processes,"In many industrial processes, an apparent lack of data limits the development
of data-driven soft sensors. There are, however, often opportunities to learn
stronger models by being more data-efficient. To achieve this, one can leverage
knowledge about the data from which the soft sensor is learned. Taking
advantage of properties frequently possessed by industrial data, we introduce a
deep latent variable model for semi-supervised multi-unit soft sensing. This
hierarchical, generative model is able to jointly model different units, as
well as learning from both labeled and unlabeled data.
  An empirical study of multi-unit soft sensing is conducted using two
datasets: a synthetic dataset of single-phase fluid flow, and a large, real
dataset of multi-phase flow in oil and gas wells. We show that by combining
semi-supervised and multi-task learning, the proposed model achieves superior
results, outperforming current leading methods for this soft sensing problem.
We also show that when a model has been trained on a multi-unit dataset, it may
be finetuned to previously unseen units using only a handful of data points. In
this finetuning procedure, unlabeled data improve soft sensor performance;
remarkably, this is true even when no labeled data are available.",2024-07-18,"Bjarne Grimstad, Kristian Løvland, Lars S. Imsland, Vidar Gunnerud",http://arxiv.org/pdf/2407.13310v1,cs.LG
Mean Teacher based SSL Framework for Indoor Localization Using Wi-Fi RSSI Fingerprinting,"Wi-Fi fingerprinting is widely applied for indoor localization due to the
widespread availability of Wi-Fi devices. However, traditional methods are not
ideal for multi-building and multi-floor environments due to the scalability
issues. Therefore, more and more researchers have employed deep learning
techniques to enable scalable indoor localization. This paper introduces a
novel semi-supervised learning framework for neural networks based on wireless
access point selection, noise injection, and Mean Teacher model, which
leverages unlabeled fingerprints to enhance localization performance. The
proposed framework can manage hybrid in/outsourcing and voluntarily contributed
databases and continually expand the fingerprint database with newly submitted
unlabeled fingerprints during service. The viability of the proposed framework
was examined using two established deep-learning models with the UJIIndoorLoc
database. The experimental results suggest that the proposed framework
significantly improves localization performance compared to the supervised
learning-based approach in terms of floor-level coordinate estimation using
EvAAL metric. It shows enhancements up to 10.99% and 8.98% in the former
scenario and 4.25% and 9.35% in the latter, respectively with additional
studies highlight the importance of the essential components of the proposed
framework.",2024-07-18,"Sihao Li, Zhe Tang, Kyeong Soo Kim, Jeremy S. Smith",http://arxiv.org/pdf/2407.13303v1,cs.LG
"CoD, Towards an Interpretable Medical Agent using Chain of Diagnosis","The field of medical diagnosis has undergone a significant transformation
with the advent of large language models (LLMs), yet the challenges of
interpretability within these models remain largely unaddressed. This study
introduces Chain-of-Diagnosis (CoD) to enhance the interpretability of
LLM-based medical diagnostics. CoD transforms the diagnostic process into a
diagnostic chain that mirrors a physician's thought process, providing a
transparent reasoning pathway. Additionally, CoD outputs the disease confidence
distribution to ensure transparency in decision-making. This interpretability
makes model diagnostics controllable and aids in identifying critical symptoms
for inquiry through the entropy reduction of confidences. With CoD, we
developed DiagnosisGPT, capable of diagnosing 9604 diseases. Experimental
results demonstrate that DiagnosisGPT outperforms other LLMs on diagnostic
benchmarks. Moreover, DiagnosisGPT provides interpretability while ensuring
controllability in diagnostic rigor.",2024-07-18,"Junying Chen, Chi Gui, Anningzhe Gao, Ke Ji, Xidong Wang, Xiang Wan, Benyou Wang",http://arxiv.org/pdf/2407.13301v2,cs.LG
Scikit-fingerprints: easy and efficient computation of molecular fingerprints in Python,"In this work, we present scikit-fingerprints, a Python package for
computation of molecular fingerprints for applications in chemoinformatics. Our
library offers an industry-standard scikit-learn interface, allowing intuitive
usage and easy integration with machine learning pipelines. It is also highly
optimized, featuring parallel computation that enables efficient processing of
large molecular datasets. Currently, scikit-fingerprints stands as the most
feature-rich library in the open source Python ecosystem, offering over 30
molecular fingerprints. Our library simplifies chemoinformatics tasks based on
molecular fingerprints, including molecular property prediction and virtual
screening. It is also flexible, highly efficient, and fully open source.",2024-07-18,"Jakub Adamczyk, Piotr Ludynia",http://arxiv.org/pdf/2407.13291v4,cs.LG
Hierarchical Stage-Wise Training of Linked Deep Neural Networks for Multi-Building and Multi-Floor Indoor Localization Based on Wi-Fi RSSI Fingerprinting,"In this paper, we present a new solution to the problem of large-scale
multi-building and multi-floor indoor localization based on linked neural
networks, where each neural network is dedicated to a sub-problem and trained
under a hierarchical stage-wise training framework. When the measured data from
sensors have a hierarchical representation as in multi-building and multi-floor
indoor localization, it is important to exploit the hierarchical nature in data
processing to provide a scalable solution. In this regard, the hierarchical
stage-wise training framework extends the original stage-wise training
framework to the case of multiple linked networks by training a lower-hierarchy
network based on the prior knowledge gained from the training of
higher-hierarchy networks. The experimental results with the publicly-available
UJIIndoorLoc multi-building and multi-floor Wi-Fi RSSI fingerprint database
demonstrate that the linked neural networks trained under the proposed
hierarchical stage-wise training framework can achieve a three-dimensional
localization error of 8.19 m, which, to the best of the authors' knowledge, is
the most accurate result ever obtained for neural network-based models trained
and evaluated with the full datasets of the UJIIndoorLoc database, and that,
when applied to a model based on hierarchical convolutional neural networks,
the proposed training framework can also significantly reduce the
three-dimensional localization error from 11.78 m to 8.71 m.",2024-07-18,"Sihao Li, Kyeong Soo Kim, Zhe Tang, Graduate, Jeremy S. Smith",http://arxiv.org/pdf/2407.13288v1,cs.LG
Long Input Sequence Network for Long Time Series Forecasting,"Short fixed-length inputs are the main bottleneck of deep learning methods in
long time-series forecasting tasks. Prolonging input length causes overfitting,
rapidly deteriorating accuracy. Our research indicates that the overfitting is
a combination reaction of the multi-scale pattern coupling in time series and
the fixed focusing scale of current models. First, we find that the patterns
exhibited by a time series across various scales are reflective of its
multi-periodic nature, where each scale corresponds to specific period length.
Second, We find that the token size predominantly dictates model behavior, as
it determines the scale at which the model focuses and the context size it can
accommodate. Our idea is to decouple the multi-scale temporal patterns of time
series and to model each pattern with its corresponding period length as token
size. We introduced a novel series-decomposition module(MPSD), and a
Multi-Token Pattern Recognition neural network(MTPR), enabling the model to
handle \textit{inputs up to $10\times$ longer}. Sufficient context enhances
performance(\textit{38% maximum precision improvement}), and the decoupling
approach offers \textit{Low complexity($0.22\times$ cost)} and \textit{high
interpretability}.",2024-07-18,"Chao Ma, Yikai Hou, Xiang Li, Yinggang Sun, Haining Yu",http://arxiv.org/pdf/2407.15869v1,cs.LG
Auditing Local Explanations is Hard,"In sensitive contexts, providers of machine learning algorithms are
increasingly required to give explanations for their algorithms' decisions.
However, explanation receivers might not trust the provider, who potentially
could output misleading or manipulated explanations. In this work, we
investigate an auditing framework in which a third-party auditor or a
collective of users attempts to sanity-check explanations: they can query model
decisions and the corresponding local explanations, pool all the information
received, and then check for basic consistency properties. We prove upper and
lower bounds on the amount of queries that are needed for an auditor to succeed
within this framework. Our results show that successful auditing requires a
potentially exorbitant number of queries -- particularly in high dimensional
cases. Our analysis also reveals that a key property is the ``locality'' of the
provided explanations -- a quantity that so far has not been paid much
attention to in the explainability literature. Looking forward, our results
suggest that for complex high-dimensional settings, merely providing a
pointwise prediction and explanation could be insufficient, as there is no way
for the users to verify that the provided explanations are not completely
made-up.",2024-07-18,"Robi Bhattacharjee, Ulrike von Luxburg",http://arxiv.org/pdf/2407.13281v1,cs.LG
Analyzing and Bridging the Gap between Maximizing Total Reward and Discounted Reward in Deep Reinforcement Learning,"The optimal objective is a fundamental aspect of reinforcement learning (RL),
as it determines how policies are evaluated and optimized. While total return
maximization is the ideal objective in RL, discounted return maximization is
the practical objective due to its stability. This can lead to a misalignment
of objectives. To better understand the problem, we theoretically analyze the
performance gap between the policy maximizes the total return and the policy
maximizes the discounted return. Our analysis reveals that increasing the
discount factor can be ineffective at eliminating this gap when environment
contains cyclic states,a frequent scenario. To address this issue, we propose
two alternative approaches to align the objectives. The first approach achieves
alignment by modifying the terminal state value, treating it as a tunable
hyper-parameter with its suitable range defined through theoretical analysis.
The second approach focuses on calibrating the reward data in trajectories,
enabling alignment in practical Deep RL applications using off-policy
algorithms. This method enhances robustness to the discount factor and improve
performance when the trajectory length is large. Our proposed methods
demonstrate that adjusting reward data can achieve alignment, providing an
insight that can be leveraged to design new optimization objectives to
fundamentally enhance the performance of RL algorithms.",2024-07-18,"Shuyu Yin, Fei Wen, Peilin Liu, Tao Luo",http://arxiv.org/pdf/2407.13279v2,cs.LG
Deep Time Series Models: A Comprehensive Survey and Benchmark,"Time series, characterized by a sequence of data points arranged in a
discrete-time order, are ubiquitous in real-world applications. Different from
other modalities, time series present unique challenges due to their complex
and dynamic nature, including the entanglement of nonlinear patterns and
time-variant trends. Analyzing time series data is of great significance in
real-world scenarios and has been widely studied over centuries. Recent years
have witnessed remarkable breakthroughs in the time series community, with
techniques shifting from traditional statistical methods to advanced deep
learning models. In this paper, we delve into the design of deep time series
models across various analysis tasks and review the existing literature from
two perspectives: basic modules and model architectures. Further, we develop
and release Time Series Library (TSLib) as a fair benchmark of deep time series
models for diverse analysis tasks, which implements 24 mainstream models,
covers 30 datasets from different domains, and supports five prevalent analysis
tasks. Based on TSLib, we thoroughly evaluate 12 advanced deep time series
models on different tasks. Empirical results indicate that models with specific
structures are well-suited for distinct analytical tasks, which offers insights
for research and adoption of deep time series models. Code is available at
https://github.com/thuml/Time-Series-Library.",2024-07-18,"Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Mingsheng Long, Jianmin Wang",http://arxiv.org/pdf/2407.13278v1,cs.LG
Mixture of Experts based Multi-task Supervise Learning from Crowds,"Existing truth inference methods in crowdsourcing aim to map redundant labels
and items to the ground truth. They treat the ground truth as hidden variables
and use statistical or deep learning-based worker behavior models to infer the
ground truth. However, worker behavior models that rely on ground truth hidden
variables overlook workers' behavior at the item feature level, leading to
imprecise characterizations and negatively impacting the quality of truth
inference. This paper proposes a new paradigm of multi-task supervised learning
from crowds, which eliminates the need for modeling of items's ground truth in
worker behavior models. Within this paradigm, we propose a worker behavior
model at the item feature level called Mixture of Experts based Multi-task
Supervised Learning from Crowds (MMLC). Two truth inference strategies are
proposed within MMLC. The first strategy, named MMLC-owf, utilizes clustering
methods in the worker spectral space to identify the projection vector of the
oracle worker. Subsequently, the labels generated based on this vector are
considered as the inferred truth. The second strategy, called MMLC-df, employs
the MMLC model to fill the crowdsourced data, which can enhance the
effectiveness of existing truth inference methods. Experimental results
demonstrate that MMLC-owf outperforms state-of-the-art methods and MMLC-df
enhances the quality of existing truth inference methods.",2024-07-18,"Tao Han, Huaixuan Shi, Xinyi Ding, Xiao Ma, Huamao Gu, Yili Fang",http://arxiv.org/pdf/2407.13268v2,cs.LG
Motif-Consistent Counterfactuals with Adversarial Refinement for Graph-Level Anomaly Detection,"Graph-level anomaly detection is significant in diverse domains. To improve
detection performance, counterfactual graphs have been exploited to benefit the
generalization capacity by learning causal relations. Most existing studies
directly introduce perturbations (e.g., flipping edges) to generate
counterfactual graphs, which are prone to alter the semantics of generated
examples and make them off the data manifold, resulting in sub-optimal
performance. To address these issues, we propose a novel approach,
Motif-consistent Counterfactuals with Adversarial Refinement (MotifCAR), for
graph-level anomaly detection. The model combines the motif of one graph, the
core subgraph containing the identification (category) information, and the
contextual subgraph (non-motif) of another graph to produce a raw
counterfactual graph. However, the produced raw graph might be distorted and
cannot satisfy the important counterfactual properties: Realism, Validity,
Proximity and Sparsity. Towards that, we present a Generative Adversarial
Network (GAN)-based graph optimizer to refine the raw counterfactual graphs. It
adopts the discriminator to guide the generator to generate graphs close to
realistic data, i.e., meet the property Realism. Further, we design the motif
consistency to force the motif of the generated graphs to be consistent with
the realistic graphs, meeting the property Validity. Also, we devise the
contextual loss and connection loss to control the contextual subgraph and the
newly added links to meet the properties Proximity and Sparsity. As a result,
the model can generate high-quality counterfactual graphs. Experiments
demonstrate the superiority of MotifCAR.",2024-07-18,"Chunjing Xiao, Shikang Pang, Wenxin Tai, Yanlong Huang, Goce Trajcevski, Fan Zhou",http://arxiv.org/pdf/2407.13251v1,cs.LG
Transformers with Stochastic Competition for Tabular Data Modelling,"Despite the prevalence and significance of tabular data across numerous
industries and fields, it has been relatively underexplored in the realm of
deep learning. Even today, neural networks are often overshadowed by techniques
such as gradient boosted decision trees (GBDT). However, recent models are
beginning to close this gap, outperforming GBDT in various setups and garnering
increased attention in the field. Inspired by this development, we introduce a
novel stochastic deep learning model specifically designed for tabular data.
The foundation of this model is a Transformer-based architecture, carefully
adapted to cater to the unique properties of tabular data through strategic
architectural modifications and leveraging two forms of stochastic competition.
First, we employ stochastic ""Local Winner Takes All"" units to promote
generalization capacity through stochasticity and sparsity. Second, we
introduce a novel embedding layer that selects among alternative linear
embedding layers through a mechanism of stochastic competition. The
effectiveness of the model is validated on a variety of widely-used, publicly
available datasets. We demonstrate that, through the incorporation of these
elements, our model yields high performance and marks a significant advancement
in the application of deep learning to tabular data.",2024-07-18,"Andreas Voskou, Charalambos Christoforou, Sotirios Chatzis",http://arxiv.org/pdf/2407.13238v1,cs.LG
Evaluating Large Language Models for Anxiety and Depression Classification using Counseling and Psychotherapy Transcripts,"We aim to evaluate the efficacy of traditional machine learning and large
language models (LLMs) in classifying anxiety and depression from long
conversational transcripts. We fine-tune both established transformer models
(BERT, RoBERTa, Longformer) and more recent large models (Mistral-7B), trained
a Support Vector Machine with feature engineering, and assessed GPT models
through prompting. We observe that state-of-the-art models fail to enhance
classification outcomes compared to traditional machine learning methods.",2024-07-18,"Junwei Sun, Siqi Ma, Yiran Fan, Peter Washington",http://arxiv.org/pdf/2407.13228v1,cs.LG
Non-Contact Breath Rate Classification Using SVM Model and mmWave Radar Sensor Data,"This work presents the use of frequency modulated continuous wave (FMCW)
radar technology combined with a machine learning model to differentiate
between normal and abnormal breath rates. The proposed system non-contactly
collects data using FMCW radar, which depends on breath rates. Various support
vector machine kernels are used to classify the observed data into normal and
abnormal states. Prolonged experiments show good accuracy in breath rate
classification, confirming the model's efficacy. The best accuracy is 95
percent with the smallest number of support vectors in the case of the
quadratic polynomial kernel.",2024-07-18,"Mohammad Wassaf Ali, Ayushi Gupta, Mujeev Khan, Mohd Wajid",http://arxiv.org/pdf/2407.13222v1,cs.LG
LiNR: Model Based Neural Retrieval on GPUs at LinkedIn,"This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval
system. LiNR supports a billion-sized index on GPU models. We discuss our
experiences and challenges in creating scalable, differentiable search indexes
using TensorFlow and PyTorch at production scale. In LiNR, both items and model
weights are integrated into the model binary. Viewing index construction as a
form of model training, we describe scaling our system for large indexes,
incorporating full scans and efficient filtering. A key focus is on enabling
attribute-based pre-filtering for exhaustive GPU searches, addressing the
common challenge of post-filtering in KNN searches that often reduces system
quality. We further provide multi-embedding retrieval algorithms and strategies
for tackling cold start issues in retrieval. Our advancements in supporting
larger indexes through quantization are also discussed. We believe LiNR
represents one of the industry's first Live-updated model-based retrieval
indexes. Applied to out-of-network post recommendations on LinkedIn Feed, LiNR
has contributed to a 3% relative increase in professional daily active users.
We envisage LiNR as a step towards integrating retrieval and ranking into a
single GPU model, simplifying complex infrastructures and enabling end-to-end
optimization of the entire differentiable infrastructure through gradient
descent.",2024-07-18,"Fedor Borisyuk, Qingquan Song, Mingzhou Zhou, Ganesh Parameswaran, Madhu Arun, Siva Popuri, Tugrul Bingol, Zhuotao Pei, Kuang-Hsuan Lee, Lu Zheng, Qizhan Shao, Ali Naqvi, Sen Zhou, Aman Gupta",http://arxiv.org/pdf/2407.13218v3,cs.LG
Revisiting Attention for Multivariate Time Series Forecasting,"Current Transformer methods for Multivariate Time-Series Forecasting (MTSF)
are all based on the conventional attention mechanism. They involve sequence
embedding and performing a linear projection of Q, K, and V, and then computing
attention within this latent space. We have never delved into the attention
mechanism to explore whether such a mapping space is optimal for MTSF. To
investigate this issue, this study first proposes Frequency Spectrum attention
(FSatten), a novel attention mechanism based on the frequency domain space. It
employs the Fourier transform for embedding and introduces Multi-head Spectrum
Scaling (MSS) to replace the conventional linear mapping of Q and K. FSatten
can accurately capture the periodic dependencies between sequences and
outperform the conventional attention without changing mainstream
architectures. We further design a more general method dubbed Scaled Orthogonal
attention (SOatten). We propose an orthogonal embedding and a Head-Coupling
Convolution (HCC) based on the neighboring similarity bias to guide the model
in learning comprehensive dependency patterns. Experiments show that FSatten
and SOatten surpass the SOTA which uses conventional attention, making it a
good alternative as a basic attention mechanism for MTSF. The codes and log
files will be released at: https://github.com/Joeland4/FSatten-SOatten.",2024-07-18,Haixiang Wu,http://arxiv.org/pdf/2407.13806v1,cs.LG
Scalable Exploration via Ensemble++,"Thompson Sampling is a principled method for balancing exploration and
exploitation, but its real-world adoption faces computational challenges in
large-scale or non-conjugate settings. While ensemble-based approaches offer
partial remedies, they typically require prohibitively large ensemble sizes. We
propose Ensemble++, a scalable exploration framework using a novel
shared-factor ensemble architecture with random linear combinations. For linear
bandits, we provide theoretical guarantees showing that Ensemble++ achieves
regret comparable to exact Thompson Sampling with only $\Theta(d \log T)$
ensemble sizes--significantly outperforming prior methods. Crucially, this
efficiency holds across both compact and finite action sets with either
time-invariant or time-varying contexts without configuration changes. We
extend this theoretical foundation to nonlinear rewards by replacing fixed
features with learnable neural representations while preserving the same
incremental update principle, effectively bridging theory and practice for
real-world tasks. Comprehensive experiments across linear, quadratic, neural,
and GPT-based contextual bandits validate our theoretical findings and
demonstrate Ensemble++'s superior regret-computation tradeoff versus
state-of-the-art methods.",2024-07-18,"Yingru Li, Jiawei Xu, Baoxiang Wang, Zhi-Quan Luo",http://arxiv.org/pdf/2407.13195v5,cs.LG
Robust Multivariate Time Series Forecasting against Intra- and Inter-Series Transitional Shift,"The non-stationary nature of real-world Multivariate Time Series (MTS) data
presents forecasting models with a formidable challenge of the time-variant
distribution of time series, referred to as distribution shift. Existing
studies on the distribution shift mostly adhere to adaptive normalization
techniques for alleviating temporal mean and covariance shifts or time-variant
modeling for capturing temporal shifts. Despite improving model generalization,
these normalization-based methods often assume a time-invariant transition
between outputs and inputs but disregard specific intra-/inter-series
correlations, while time-variant models overlook the intrinsic causes of the
distribution shift. This limits model expressiveness and interpretability of
tackling the distribution shift for MTS forecasting. To mitigate such a
dilemma, we present a unified Probabilistic Graphical Model to Jointly
capturing intra-/inter-series correlations and modeling the time-variant
transitional distribution, and instantiate a neural framework called JointPGM
for non-stationary MTS forecasting. Specifically, JointPGM first employs
multiple Fourier basis functions to learn dynamic time factors and designs two
distinct learners: intra-series and inter-series learners. The intra-series
learner effectively captures temporal dynamics by utilizing temporal gates,
while the inter-series learner explicitly models spatial dynamics through
multi-hop propagation, incorporating Gumbel-softmax sampling. These two types
of series dynamics are subsequently fused into a latent variable, which is
inversely employed to infer time factors, generate final prediction, and
perform reconstruction. We validate the effectiveness and efficiency of
JointPGM through extensive experiments on six highly non-stationary MTS
datasets, achieving state-of-the-art forecasting performance of MTS
forecasting.",2024-07-18,"Hui He, Qi Zhang, Kun Yi, Xiaojun Xue, Shoujin Wang, Liang Hu, Longbing Cao",http://arxiv.org/pdf/2407.13194v1,cs.LG
"Data-Driven Estimation of Conditional Expectations, Application to Optimal Stopping and Reinforcement Learning","When the underlying conditional density is known, conditional expectations
can be computed analytically or numerically. When, however, such knowledge is
not available and instead we are given a collection of training data, the goal
of this work is to propose simple and purely data-driven means for estimating
directly the desired conditional expectation. Because conditional expectations
appear in the description of a number of stochastic optimization problems with
the corresponding optimal solution satisfying a system of nonlinear equations,
we extend our data-driven method to cover such cases as well. We test our
methodology by applying it to Optimal Stopping and Optimal Action Policy in
Reinforcement Learning.",2024-07-18,George V. Moustakides,http://arxiv.org/pdf/2407.13189v1,cs.LG
SpaDiT: Diffusion Transformer for Spatial Gene Expression Prediction using scRNA-seq,"The rapid development of spatial transcriptomics (ST) technologies is
revolutionizing our understanding of the spatial organization of biological
tissues. Current ST methods, categorized into next-generation sequencing-based
(seq-based) and fluorescence in situ hybridization-based (image-based) methods,
offer innovative insights into the functional dynamics of biological tissues.
However, these methods are limited by their cellular resolution and the
quantity of genes they can detect. To address these limitations, we propose
SpaDiT, a deep learning method that utilizes a diffusion generative model to
integrate scRNA-seq and ST data for the prediction of undetected genes. By
employing a Transformer-based diffusion model, SpaDiT not only accurately
predicts unknown genes but also effectively generates the spatial structure of
ST genes. We have demonstrated the effectiveness of SpaDiT through extensive
experiments on both seq-based and image-based ST data. SpaDiT significantly
contributes to ST gene prediction methods with its innovative approach.
Compared to eight leading baseline methods, SpaDiT achieved state-of-the-art
performance across multiple metrics, highlighting its substantial
bioinformatics contribution.",2024-07-18,"Xiaoyu Li, Fangfang Zhu, Wenwen Min",http://arxiv.org/pdf/2407.13182v1,cs.LG
Compressed models are NOT miniature versions of large models,"Large neural models are often compressed before deployment. Model compression
is necessary for many practical reasons, such as inference latency, memory
footprint, and energy consumption. Compressed models are assumed to be
miniature versions of corresponding large neural models. However, we question
this belief in our work. We compare compressed models with corresponding large
neural models using four model characteristics: prediction errors, data
representation, data distribution, and vulnerability to adversarial attack. We
perform experiments using the BERT-large model and its five compressed
versions. For all four model characteristics, compressed models significantly
differ from the BERT-large model. Even among compressed models, they differ
from each other on all four model characteristics. Apart from the expected loss
in model performance, there are major side effects of using compressed models
to replace large neural models.",2024-07-18,"Rohit Raj Rai, Rishant Pal, Amit Awekar",http://arxiv.org/pdf/2407.13174v1,cs.LG
Autonomous Navigation of Unmanned Vehicle Through Deep Reinforcement Learning,"This paper explores the method of achieving autonomous navigation of unmanned
vehicles through Deep Reinforcement Learning (DRL). The focus is on using the
Deep Deterministic Policy Gradient (DDPG) algorithm to address issues in
high-dimensional continuous action spaces. The paper details the model of a
Ackermann robot and the structure and application of the DDPG algorithm.
Experiments were conducted in a simulation environment to verify the
feasibility of the improved algorithm. The results demonstrate that the DDPG
algorithm outperforms traditional Deep Q-Network (DQN) and Double Deep
Q-Network (DDQN) algorithms in path planning tasks.",2024-07-18,"Letian Xu, Jiabei Liu, Haopeng Zhao, Tianyao Zheng, Tongzhou Jiang, Lipeng Liu",http://arxiv.org/pdf/2407.18962v1,cs.LG
HHGT: Hierarchical Heterogeneous Graph Transformer for Heterogeneous Graph Representation Learning,"Despite the success of Heterogeneous Graph Neural Networks (HGNNs) in
modeling real-world Heterogeneous Information Networks (HINs), challenges such
as expressiveness limitations and over-smoothing have prompted researchers to
explore Graph Transformers (GTs) for enhanced HIN representation learning.
However, research on GT in HINs remains limited, with two key shortcomings in
existing work: (1) A node's neighbors at different distances in HINs convey
diverse semantics. Unfortunately, existing methods ignore such differences and
uniformly treat neighbors within a given distance in a coarse manner, which
results in semantic confusion. (2) Nodes in HINs have various types, each with
unique semantics. Nevertheless, existing methods mix nodes of different types
during neighbor aggregation, hindering the capture of proper correlations
between nodes of diverse types. To bridge these gaps, we design an innovative
structure named (k,t)-ring neighborhood, where nodes are initially organized by
their distance, forming different non-overlapping k-ring neighborhoods for each
distance. Within each k-ring structure, nodes are further categorized into
different groups according to their types, thus emphasizing the heterogeneity
of both distances and types in HINs naturally. Based on this structure, we
propose a novel Hierarchical Heterogeneous Graph Transformer (HHGT) model,
which seamlessly integrates a Type-level Transformer for aggregating nodes of
different types within each k-ring neighborhood, followed by a Ring-level
Transformer for aggregating different k-ring neighborhoods in a hierarchical
manner. Extensive experiments are conducted on downstream tasks to verify
HHGT's superiority over 14 baselines, with a notable improvement of up to
24.75% in NMI and 29.25% in ARI for node clustering task on the ACM dataset
compared to the best baseline.",2024-07-18,"Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Kaijun Liu, Cheng Long, Xiaoyang Wang",http://arxiv.org/pdf/2407.13158v1,cs.LG
Preset-Voice Matching for Privacy Regulated Speech-to-Speech Translation Systems,"In recent years, there has been increased demand for speech-to-speech
translation (S2ST) systems in industry settings. Although successfully
commercialized, cloning-based S2ST systems expose their distributors to
liabilities when misused by individuals and can infringe on personality rights
when exploited by media organizations. This work proposes a regulated S2ST
framework called Preset-Voice Matching (PVM). PVM removes cross-lingual voice
cloning in S2ST by first matching the input voice to a similar prior consenting
speaker voice in the target-language. With this separation, PVM avoids cloning
the input speaker, ensuring PVM systems comply with regulations and reduce risk
of misuse. Our results demonstrate PVM can significantly improve S2ST system
run-time in multi-speaker settings and the naturalness of S2ST synthesized
speech. To our knowledge, PVM is the first explicitly regulated S2ST framework
leveraging similarly-matched preset-voices for dynamic S2ST tasks.",2024-07-18,"Daniel Platnick, Bishoy Abdelnour, Eamon Earl, Rahul Kumar, Zahra Rezaei, Thomas Tsangaris, Faraj Lagum",http://arxiv.org/pdf/2407.13153v1,cs.LG
PG-Rainbow: Using Distributional Reinforcement Learning in Policy Gradient Methods,"This paper introduces PG-Rainbow, a novel algorithm that incorporates a
distributional reinforcement learning framework with a policy gradient
algorithm. Existing policy gradient methods are sample inefficient and rely on
the mean of returns when calculating the state-action value function,
neglecting the distributional nature of returns in reinforcement learning
tasks. To address this issue, we use an Implicit Quantile Network that provides
the quantile information of the distribution of rewards to the critic network
of the Proximal Policy Optimization algorithm. We show empirical results that
through the integration of reward distribution information into the policy
network, the policy agent acquires enhanced capabilities to comprehensively
evaluate the consequences of potential actions in a given state, facilitating
more sophisticated and informed decision-making processes. We evaluate the
performance of the proposed algorithm in the Atari-2600 game suite, simulated
via the Arcade Learning Environment (ALE).",2024-07-18,"WooJae Jeon, KangJun Lee, Jeewoo Lee",http://arxiv.org/pdf/2407.13146v2,cs.LG
Integrated Hardware Architecture and Device Placement Search,"Distributed execution of deep learning training involves a dynamic interplay
between hardware accelerator architecture and device placement strategy. This
is the first work to explore the co-optimization of determining the optimal
architecture and device placement strategy through novel algorithms, improving
the balance of computational resources, memory usage, and data distribution.
Our architecture search leverages tensor and vector units, determining their
quantity and dimensionality, and on-chip and off-chip memory configurations. It
also determines the microbatch size and decides whether to recompute or stash
activations, balancing the memory footprint of training and storage size. For
each explored architecture configuration, we use an Integer Linear Program
(ILP) to find the optimal schedule for executing operators on the accelerator.
The ILP results then integrate with a dynamic programming solution to identify
the most effective device placement strategy, combining data, pipeline, and
tensor model parallelism across multiple accelerators. Our approach achieves
higher throughput on large language models compared to the state-of-the-art
TPUv4 and the Spotlight accelerator search framework. The entire source code of
PHAZE is available at https://github.com/msr-fiddle/phaze.",2024-07-18,"Irene Wang, Jakub Tarnawski, Amar Phanishayee, Divya Mahajan",http://arxiv.org/pdf/2407.13143v1,cs.LG
A light-weight and efficient punctuation and word casing prediction model for on-device streaming ASR,"Punctuation and word casing prediction are necessary for automatic speech
recognition (ASR). With the popularity of on-device end-to-end streaming ASR
systems, the on-device punctuation and word casing prediction become a
necessity while we found little discussion on this. With the emergence of
Transformer, Transformer based models have been explored for this scenario.
However, Transformer based models are too large for on-device ASR systems. In
this paper, we propose a light-weight and efficient model that jointly predicts
punctuation and word casing in real time. The model is based on Convolutional
Neural Network (CNN) and Bidirectional Long Short-Term Memory (BiLSTM).
Experimental results on the IWSLT2011 test set show that the proposed model
obtains 9% relative improvement compared to the best of non-Transformer models
on overall F1-score. Compared to the representative of Transformer based
models, the proposed model achieves comparable results to the representative
model while being only one-fortieth its size and 2.5 times faster in terms of
inference time. It is suitable for on-device streaming ASR systems. Our code is
publicly available.",2024-07-18,"Jian You, Xiangfeng Li",http://arxiv.org/pdf/2407.13142v1,cs.LG
Out-of-Distribution Detection through Soft Clustering with Non-Negative Kernel Regression,"As language models become more general purpose, increased attention needs to
be paid to detecting out-of-distribution (OOD) instances, i.e., those not
belonging to any of the distributions seen during training. Existing methods
for detecting OOD data are computationally complex and storage-intensive. We
propose a novel soft clustering approach for OOD detection based on
non-negative kernel regression. Our approach greatly reduces computational and
space complexities (up to 11x improvement in inference time and 87% reduction
in storage requirements) and outperforms existing approaches by up to 4 AUROC
points on four different benchmarks. We also introduce an entropy-constrained
version of our algorithm, which leads to further reductions in storage
requirements (up to 97% lower than comparable approaches) while retaining
competitive performance. Our soft clustering approach for OOD detection
highlights its potential for detecting tail-end phenomena in extreme-scale data
settings.",2024-07-18,"Aryan Gulati, Xingjian Dong, Carlos Hurtado, Sarath Shekkizhar, Swabha Swayamdipta, Antonio Ortega",http://arxiv.org/pdf/2407.13141v1,cs.LG
From 2015 to 2023: How Machine Learning Aids Natural Product Analysis,"In recent years, conventional chemistry techniques have faced significant
challenges due to their inherent limitations, struggling to cope with the
increasing complexity and volume of data generated in contemporary research
endeavors. Computational methodologies represent robust tools in the field of
chemistry, offering the capacity to harness potent machine-learning models to
yield insightful analytical outcomes. This review delves into the spectrum of
computational strategies available for natural product analysis and constructs
a research framework for investigating both qualitative and quantitative
chemistry problems. Our objective is to present a novel perspective on the
symbiosis of machine learning and chemistry, with the potential to catalyze a
transformation in the field of natural product analysis.",2024-07-18,"Suwen Shi, Ziwei Huang, Xingxin Gu, Xu Lin, Chaoying Zhong, Junjie Hang, Jianli Lin, Claire Chenwen Zhong, Lin Zhang, Yu Li, Junjie Huang",http://arxiv.org/pdf/2408.00793v1,cs.LG
A Survey on Differential Privacy for SpatioTemporal Data in Transportation Research,"With low-cost computing devices, improved sensor technology, and the
proliferation of data-driven algorithms, we have more data than we know what to
do with. In transportation, we are seeing a surge in spatiotemporal data
collection. At the same time, concerns over user privacy have led to research
on differential privacy in applied settings. In this paper, we look at some
recent developments in differential privacy in the context of spatiotemporal
data. Spatiotemporal data contain not only features about users but also the
geographical locations of their frequent visits. Hence, the public release of
such data carries extreme risks. To address the need for such data in research
and inference without exposing private information, significant work has been
proposed. This survey paper aims to summarize these efforts and provide a
review of differential privacy mechanisms and related software. We also discuss
related work in transportation where such mechanisms have been applied.
Furthermore, we address the challenges in the deployment and mass adoption of
differential privacy in transportation spatiotemporal data for downstream
analyses.",2024-07-18,Rahul Bhadani,http://arxiv.org/pdf/2407.15868v1,cs.LG
Reconfigurable Intelligent Surface Aided Vehicular Edge Computing: Joint Phase-shift Optimization and Multi-User Power Allocation,"Vehicular edge computing (VEC) is an emerging technology with significant
potential in the field of internet of vehicles (IoV), enabling vehicles to
perform intensive computational tasks locally or offload them to nearby edge
devices. However, the quality of communication links may be severely
deteriorated due to obstacles such as buildings, impeding the offloading
process. To address this challenge, we introduce the use of Reconfigurable
Intelligent Surfaces (RIS), which provide alternative communication pathways to
assist vehicular communication. By dynamically adjusting the phase-shift of the
RIS, the performance of VEC systems can be substantially improved. In this
work, we consider a RIS-assisted VEC system, and design an optimal scheme for
local execution power, offloading power, and RIS phase-shift, where random task
arrivals and channel variations are taken into account. To address the scheme,
we propose an innovative deep reinforcement learning (DRL) framework that
combines the Deep Deterministic Policy Gradient (DDPG) algorithm for optimizing
RIS phase-shift coefficients and the Multi-Agent Deep Deterministic Policy
Gradient (MADDPG) algorithm for optimizing the power allocation of vehicle user
(VU). Simulation results show that our proposed scheme outperforms the
traditional centralized DDPG, Twin Delayed Deep Deterministic Policy Gradient
(TD3) and some typical stochastic schemes.",2024-07-18,"Kangwei Qi, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Khaled B. Letaief",http://arxiv.org/pdf/2407.13123v1,cs.LG
MO-EMT-NAS: Multi-Objective Continuous Transfer of Architectural Knowledge Between Tasks from Different Datasets,"Deploying models across diverse devices demands tradeoffs among multiple
objectives due to different resource constraints. Arguably, due to the small
model trap problem in multi-objective neural architecture search (MO-NAS) based
on a supernet, existing approaches may fail to maintain large models. Moreover,
multi-tasking neural architecture search (MT-NAS) excels in handling multiple
tasks simultaneously, but most existing efforts focus on tasks from the same
dataset, limiting their practicality in real-world scenarios where multiple
tasks may come from distinct datasets. To tackle the above challenges, we
propose a Multi-Objective Evolutionary Multi-Tasking framework for NAS
(MO-EMT-NAS) to achieve architectural knowledge transfer across tasks from
different datasets while finding Pareto optimal architectures for
multi-objectives, model accuracy and computational efficiency. To alleviate the
small model trap issue, we introduce an auxiliary objective that helps maintain
multiple larger models of similar accuracy. Moreover, the computational
efficiency is further enhanced by parallelizing the training and validation of
the weight-sharing-based supernet. Experimental results on seven datasets with
two, three, and four task combinations show that MO-EMT-NAS achieves a better
minimum classification error while being able to offer flexible trade-offs
between model performance and complexity, compared to the state-of-the-art
single-objective MT-NAS algorithms. The runtime of MO-EMT-NAS is reduced by
59.7% to 77.7%, compared to the corresponding multi-objective single-task
approaches.",2024-07-18,"Peng Liao, XiLu Wang, Yaochu Jin, WenLi Du",http://arxiv.org/pdf/2407.13122v1,cs.LG
TrialEnroll: Predicting Clinical Trial Enrollment Success with Deep & Cross Network and Large Language Models,"Clinical trials need to recruit a sufficient number of volunteer patients to
demonstrate the statistical power of the treatment (e.g., a new drug) in curing
a certain disease. Clinical trial recruitment has a significant impact on trial
success. Forecasting whether the recruitment process would be successful before
we run the trial would save many resources and time. This paper develops a
novel deep & cross network with large language model (LLM)-augmented text
feature that learns semantic information from trial eligibility criteria and
predicts enrollment success. The proposed method enables interpretability by
understanding which sentence/word in eligibility criteria contributes heavily
to prediction. We also demonstrate the empirical superiority of the proposed
method (0.7002 PR-AUC) over a bunch of well-established machine learning
methods. The code and curated dataset are publicly available at
https://anonymous.4open.science/r/TrialEnroll-7E12.",2024-07-18,"Ling Yue, Sixue Xing, Jintai Chen, Tianfan Fu",http://arxiv.org/pdf/2407.13115v1,cs.LG
Audio-visual Generalized Zero-shot Learning the Easy Way,"Audio-visual generalized zero-shot learning is a rapidly advancing domain
that seeks to understand the intricate relations between audio and visual cues
within videos. The overarching goal is to leverage insights from seen classes
to identify instances from previously unseen ones. Prior approaches primarily
utilized synchronized auto-encoders to reconstruct audio-visual attributes,
which were informed by cross-attention transformers and projected text
embeddings. However, these methods fell short of effectively capturing the
intricate relationship between cross-modal features and class-label embeddings
inherent in pre-trained language-aligned embeddings. To circumvent these
bottlenecks, we introduce a simple yet effective framework for Easy
Audio-Visual Generalized Zero-shot Learning, named EZ-AVGZL, that aligns
audio-visual embeddings with transformed text representations. It utilizes a
single supervised text audio-visual contrastive loss to learn an alignment
between audio-visual and textual modalities, moving away from the conventional
approach of reconstructing cross-modal features and text embeddings. Our key
insight is that while class name embeddings are well aligned with
language-based audio-visual features, they don't provide sufficient class
separation to be useful for zero-shot learning. To address this, our method
leverages differential optimization to transform class embeddings into a more
discriminative space while preserving the semantic structure of language
representations. We conduct extensive experiments on VGGSound-GZSL, UCF-GZSL,
and ActivityNet-GZSL benchmarks. Our results demonstrate that our EZ-AVGZL
achieves state-of-the-art performance in audio-visual generalized zero-shot
learning.",2024-07-18,"Shentong Mo, Pedro Morgado",http://arxiv.org/pdf/2407.13095v1,cs.LG
Krait: A Backdoor Attack Against Graph Prompt Tuning,"Graph prompt tuning has emerged as a promising paradigm to effectively
transfer general graph knowledge from pre-trained models to various downstream
tasks, particularly in few-shot contexts. However, its susceptibility to
backdoor attacks, where adversaries insert triggers to manipulate outcomes,
raises a critical concern. We conduct the first study to investigate such
vulnerability, revealing that backdoors can disguise benign graph prompts, thus
evading detection. We introduce Krait, a novel graph prompt backdoor.
Specifically, we propose a simple yet effective model-agnostic metric called
label non-uniformity homophily to select poisoned candidates, significantly
reducing computational complexity. To accommodate diverse attack scenarios and
advanced attack types, we design three customizable trigger generation methods
to craft prompts as triggers. We propose a novel centroid similarity-based loss
function to optimize prompt tuning for attack effectiveness and stealthiness.
Experiments on four real-world graphs demonstrate that Krait can efficiently
embed triggers to merely 0.15% to 2% of training nodes, achieving high attack
success rates without sacrificing clean accuracy. Notably, in one-to-one and
all-to-one attacks, Krait can achieve 100% attack success rates by poisoning as
few as 2 and 22 nodes, respectively. Our experiments further show that Krait
remains potent across different transfer cases, attack types, and graph neural
network backbones. Additionally, Krait can be successfully extended to the
black-box setting, posing more severe threats. Finally, we analyze why Krait
can evade both classical and state-of-the-art defenses, and provide practical
insights for detecting and mitigating this class of attacks.",2024-07-18,"Ying Song, Rita Singh, Balaji Palanisamy",http://arxiv.org/pdf/2407.13068v2,cs.LG
A Novel GAN Approach to Augment Limited Tabular Data for Short-Term Substance Use Prediction,"Substance use is a global issue that negatively impacts millions of persons
who use drugs (PWUDs). In practice, identifying vulnerable PWUDs for efficient
allocation of appropriate resources is challenging due to their complex use
patterns (e.g., their tendency to change usage within months) and the high
acquisition costs for collecting PWUD-focused substance use data. Thus, there
has been a paucity of machine learning models for accurately predicting
short-term substance use behaviors of PWUDs. In this paper, using longitudinal
survey data of 258 PWUDs in the U.S. Great Plains collected by our team, we
design a novel GAN that deals with high-dimensional low-sample-size tabular
data and survey skip logic to augment existing data to improve classification
models' prediction on (A) whether the PWUDs would increase usage and (B) at
which ordinal frequency they would use a particular drug within the next 12
months. Our evaluation results show that, when trained on augmented data from
our proposed GAN, the classification models improve their predictive
performance (AUROC) by up to 13.4% in Problem (A) and 15.8% in Problem (B) for
usage of marijuana, meth, amphetamines, and cocaine, which outperform
state-of-the-art generative models.",2024-07-17,"Nguyen Thach, Patrick Habecker, Bergen Johnston, Lillianna Cervantes, Anika Eisenbraun, Alex Mason, Kimberly Tyler, Bilal Khan, Hau Chan",http://arxiv.org/pdf/2407.13047v1,cs.LG
DropKAN: Regularizing KANs by masking post-activations,"We propose DropKAN (Dropout Kolmogorov-Arnold Networks) a regularization
method that prevents co-adaptation of activation function weights in
Kolmogorov-Arnold Networks (KANs). DropKAN functions by embedding the drop mask
directly within the KAN layer, randomly masking the outputs of some activations
within the KANs' computation graph. We show that this simple procedure that
require minimal coding effort has a regularizing effect and consistently lead
to better generalization of KANs. We analyze the adaptation of the standard
Dropout with KANs and demonstrate that Dropout applied to KANs' neurons can
lead to unpredictable behavior in the feedforward pass. We carry an empirical
study with real world Machine Learning datasets to validate our findings. Our
results suggest that DropKAN is consistently a better alternative to using
standard Dropout with KANs, and improves the generalization performance of
KANs. Our implementation of DropKAN is available at:
\url{https://github.com/Ghaith81/dropkan}.",2024-07-17,Mohammed Ghaith Altarabichi,http://arxiv.org/pdf/2407.13044v4,cs.LG
A Scalable and Generalized Deep Learning Framework for Anomaly Detection in Surveillance Videos,"Anomaly detection in videos is challenging due to the complexity, noise, and
diverse nature of activities such as violence, shoplifting, and vandalism.
While deep learning (DL) has shown excellent performance in this area, existing
approaches have struggled to apply DL models across different anomaly tasks
without extensive retraining. This repeated retraining is time-consuming,
computationally intensive, and unfair. To address this limitation, a new DL
framework is introduced in this study, consisting of three key components:
transfer learning to enhance feature generalization, model fusion to improve
feature representation, and multi-task classification to generalize the
classifier across multiple tasks without training from scratch when new task is
introduced. The framework's main advantage is its ability to generalize without
requiring retraining from scratch for each new task. Empirical evaluations
demonstrate the framework's effectiveness, achieving an accuracy of 97.99% on
the RLVS dataset (violence detection), 83.59% on the UCF dataset (shoplifting
detection), and 88.37% across both datasets using a single classifier without
retraining. Additionally, when tested on an unseen dataset, the framework
achieved an accuracy of 87.25%. The study also utilizes two explainability
tools to identify potential biases, ensuring robustness and fairness. This
research represents the first successful resolution of the generalization issue
in anomaly detection, marking a significant advancement in the field.",2024-07-17,"Sabah Abdulazeez Jebur, Khalid A. Hussein, Haider Kadhim Hoomod, Laith Alzubaidi, Ahmed Ali Saihood, YuanTong Gu",http://arxiv.org/pdf/2408.00792v1,cs.LG
Universal Facial Encoding of Codec Avatars from VR Headsets,"Faithful real-time facial animation is essential for avatar-mediated
telepresence in Virtual Reality (VR). To emulate authentic communication,
avatar animation needs to be efficient and accurate: able to capture both
extreme and subtle expressions within a few milliseconds to sustain the rhythm
of natural conversations. The oblique and incomplete views of the face,
variability in the donning of headsets, and illumination variation due to the
environment are some of the unique challenges in generalization to unseen
faces. In this paper, we present a method that can animate a photorealistic
avatar in realtime from head-mounted cameras (HMCs) on a consumer VR headset.
We present a self-supervised learning approach, based on a cross-view
reconstruction objective, that enables generalization to unseen users. We
present a lightweight expression calibration mechanism that increases accuracy
with minimal additional cost to run-time efficiency. We present an improved
parameterization for precise ground-truth generation that provides robustness
to environmental variation. The resulting system produces accurate facial
animation for unseen users wearing VR headsets in realtime. We compare our
approach to prior face-encoding methods demonstrating significant improvements
in both quantitative metrics and qualitative results.",2024-07-17,"Shaojie Bai, Te-Li Wang, Chenghui Li, Akshay Venkatesh, Tomas Simon, Chen Cao, Gabriel Schwartz, Ryan Wrench, Jason Saragih, Yaser Sheikh, Shih-En Wei",http://arxiv.org/pdf/2407.13038v1,cs.LG
ColorMAE: Exploring data-independent masking strategies in Masked AutoEncoders,"Masked AutoEncoders (MAE) have emerged as a robust self-supervised framework,
offering remarkable performance across a wide range of downstream tasks. To
increase the difficulty of the pretext task and learn richer visual
representations, existing works have focused on replacing standard random
masking with more sophisticated strategies, such as adversarial-guided and
teacher-guided masking. However, these strategies depend on the input data thus
commonly increasing the model complexity and requiring additional calculations
to generate the mask patterns. This raises the question: Can we enhance MAE
performance beyond random masking without relying on input data or incurring
additional computational costs? In this work, we introduce a simple yet
effective data-independent method, termed ColorMAE, which generates different
binary mask patterns by filtering random noise. Drawing inspiration from color
noise in image processing, we explore four types of filters to yield mask
patterns with different spatial and semantic priors. ColorMAE requires no
additional learnable parameters or computational overhead in the network, yet
it significantly enhances the learned representations. We provide a
comprehensive empirical evaluation, demonstrating our strategy's superiority in
downstream tasks compared to random masking. Notably, we report an improvement
of 2.72 in mIoU in semantic segmentation tasks relative to baseline MAE
implementations.",2024-07-17,"Carlos Hinojosa, Shuming Liu, Bernard Ghanem",http://arxiv.org/pdf/2407.13036v1,cs.LG
Pre-Trained Foundation Model representations to uncover Breathing patterns in Speech,"The process of human speech production involves coordinated respiratory
action to elicit acoustic speech signals. Typically, speech is produced when
air is forced from the lungs and is modulated by the vocal tract, where such
actions are interspersed by moments of breathing in air (inhalation) to refill
the lungs again. Respiratory rate (RR) is a vital metric that is used to assess
the overall health, fitness, and general well-being of an individual. Existing
approaches to measure RR (number of breaths one takes in a minute) are
performed using specialized equipment or training. Studies have demonstrated
that machine learning algorithms can be used to estimate RR using bio-sensor
signals as input. Speech-based estimation of RR can offer an effective approach
to measure the vital metric without requiring any specialized equipment or
sensors. This work investigates a machine learning based approach to estimate
RR from speech segments obtained from subjects speaking to a close-talking
microphone device. Data were collected from N=26 individuals, where the
groundtruth RR was obtained through commercial grade chest-belts and then
manually corrected for any errors. A convolutional long-short term memory
network (Conv-LSTM) is proposed to estimate respiration time-series data from
the speech signal. We demonstrate that the use of pre-trained representations
obtained from a foundation model, such as Wav2Vec2, can be used to estimate
respiration-time-series with low root-mean-squared error and high correlation
coefficient, when compared with the baseline. The model-driven time series can
be used to estimate $RR$ with a low mean absolute error (MAE) ~ 1.6
breaths/min.",2024-07-17,"Vikramjit Mitra, Anirban Chatterjee, Ke Zhai, Helen Weng, Ayuko Hill, Nicole Hay, Christopher Webb, Jamie Cheng, Erdrin Azemi",http://arxiv.org/pdf/2407.13035v1,cs.LG
Proof-of-Collaborative-Learning: A Multi-winner Federated Learning Consensus Algorithm,"Regardless of their variations, blockchains require a consensus mechanism to
validate transactions, supervise added blocks, maintain network security,
synchronize the network state, and distribute incentives. Proof-of-Work (PoW),
one of the most influential implementations of consensus mechanisms, consumes
an extraordinary amount of energy for a task that lacks direct productive
output. In this paper, we propose Proof-of-Collaborative-Learning (PoCL), a
multi-winner federated learning validated consensus mechanism that redirects
the computation power of blockchains to train federated learning models. In
addition, we present a novel evaluation mechanism to ensure the efficiency of
the locally trained models of miners. We evaluated the security of our
evaluation mechanism by introducing and conducting probable attacks. Moreover,
we present a novel reward distribution mechanism to incentivize winning miners
fairly, and demonstrate that our reward system is fair both within and across
all rounds.",2024-07-17,"Amirreza Sokhankhosh, Sara Rouhani",http://arxiv.org/pdf/2407.13018v2,cs.LG
High-Quality Tabular Data Generation using Post-Selected VAE,"Synthetic tabular data is becoming a necessity as concerns about data privacy
intensify in the world. Tabular data can be useful for testing various systems,
simulating real data, analyzing the data itself or building predictive models.
Unfortunately, such data may not be available due to confidentiality issues.
Previous techniques, such as TVAE (Xu et al., 2019) or OCTGAN (Kim et al.,
2021), are either unable to handle particularly complex datasets, or are
complex in themselves, resulting in inferior run time performance. This paper
introduces PSVAE, a new simple model that is capable of producing high-quality
synthetic data in less run time. PSVAE incorporates two key ideas: loss
optimization and post-selection. Along with these ideas, the proposed model
compensates for underrepresented categories and uses a modern activation
function, Mish (Misra, 2019).",2024-07-17,Volodymyr Shulakov,http://arxiv.org/pdf/2407.13016v1,cs.LG
A Resolution Independent Neural Operator,"The Deep Operator Network (DeepONet) is a powerful neural operator
architecture that uses two neural networks to map between infinite-dimensional
function spaces. This architecture allows for the evaluation of the solution
field at any location within the domain but requires input functions to be
discretized at identical locations, limiting practical applications. We
introduce a general framework for operator learning from input-output data with
arbitrary sensor locations and counts. This begins by introducing a
resolution-independent DeepONet (RI-DeepONet), which handles input functions
discretized arbitrarily but sufficiently finely. To achieve this, we propose
two dictionary learning algorithms that adaptively learn continuous basis
functions, parameterized as implicit neural representations (INRs), from
correlated signals on arbitrary point clouds. These basis functions project
input function data onto a finite-dimensional embedding space, making it
compatible with DeepONet without architectural changes. We specifically use
sinusoidal representation networks (SIRENs) as trainable INR basis functions.
Similarly, the dictionary learning algorithms identify basis functions for
output data, defining a new neural operator architecture: the Resolution
Independent Neural Operator (RINO). In RINO, the operator learning task reduces
to mapping coefficients of input basis functions to output basis functions. We
demonstrate RINO's robustness and applicability in handling arbitrarily sampled
input and output functions during both training and inference through several
numerical examples.",2024-07-17,"Bahador Bahmani, Somdatta Goswami, Ioannis G. Kevrekidis, Michael D. Shields",http://arxiv.org/pdf/2407.13010v3,cs.LG
Fighting Sampling Bias: A Framework for Training and Evaluating Credit Scoring Models,"Scoring models support decision-making in financial institutions. Their
estimation and evaluation are based on the data of previously accepted
applicants with known repayment behavior. This creates sampling bias: the
available labeled data offers a partial picture of the distribution of
candidate borrowers, which the model is supposed to score. The paper addresses
the adverse effect of sampling bias on model training and evaluation. To
improve scorecard training, we propose bias-aware self-learning - a reject
inference framework that augments the biased training data by inferring labels
for selected rejected applications. For scorecard evaluation, we propose a
Bayesian framework that extends standard accuracy measures to the biased
setting and provides a reliable estimate of future scorecard performance.
Extensive experiments on synthetic and real-world data confirm the superiority
of our propositions over various benchmarks in predictive performance and
profitability. By sensitivity analysis, we also identify boundary conditions
affecting their performance. Notably, we leverage real-world data from a
randomized controlled trial to assess the novel methodologies on holdout data
that represent the true borrower population. Our findings confirm that reject
inference is a difficult problem with modest potential to improve scorecard
performance. Addressing sampling bias during scorecard evaluation is a much
more promising route to improve scoring practices. For example, our results
suggest a profit improvement of about eight percent, when using Bayesian
evaluation to decide on acceptance rates.",2024-07-17,"Nikita Kozodoi, Stefan Lessmann, Morteza Alamgir, Luis Moreira-Matias, Konstantinos Papakonstantinou",http://arxiv.org/pdf/2407.13009v1,cs.LG
Sparsity-based Safety Conservatism for Constrained Offline Reinforcement Learning,"Reinforcement Learning (RL) has made notable success in decision-making
fields like autonomous driving and robotic manipulation. Yet, its reliance on
real-time feedback poses challenges in costly or hazardous settings.
Furthermore, RL's training approach, centered on ""on-policy"" sampling, doesn't
fully capitalize on data. Hence, Offline RL has emerged as a compelling
alternative, particularly in conducting additional experiments is impractical,
and abundant datasets are available. However, the challenge of distributional
shift (extrapolation), indicating the disparity between data distributions and
learning policies, also poses a risk in offline RL, potentially leading to
significant safety breaches due to estimation errors (interpolation). This
concern is particularly pronounced in safety-critical domains, where real-world
problems are prevalent. To address both extrapolation and interpolation errors,
numerous studies have introduced additional constraints to confine policy
behavior, steering it towards more cautious decision-making. While many studies
have addressed extrapolation errors, fewer have focused on providing effective
solutions for tackling interpolation errors. For example, some works tackle
this issue by incorporating potential cost-maximizing optimization by
perturbing the original dataset. However, this, involving a bi-level
optimization structure, may introduce significant instability or complicate
problem-solving in high-dimensional tasks. This motivates us to pinpoint areas
where hazards may be more prevalent than initially estimated based on the
sparsity of available data by providing significant insight into constrained
offline RL. In this paper, we present conservative metrics based on data
sparsity that demonstrate the high generalizability to any methods and efficacy
compared to using bi-level cost-ub-maximization.",2024-07-17,"Minjae Cho, Chuangchuang Sun",http://arxiv.org/pdf/2407.13006v1,cs.LG
Novel Deep Neural Network Classifier Characterization Metrics with Applications to Dataless Evaluation,"The mainstream AI community has seen a rise in large-scale open-source
classifiers, often pre-trained on vast datasets and tested on standard
benchmarks; however, users facing diverse needs and limited, expensive test
data may be overwhelmed by available choices. Deep Neural Network (DNN)
classifiers undergo training, validation, and testing phases using example
dataset, with the testing phase focused on determining the classification
accuracy of test examples without delving into the inner working of the
classifier. In this work, we evaluate a DNN classifier's training quality
without any example dataset. It is assumed that a DNN is a composition of a
feature extractor and a classifier which is the penultimate completely
connected layer. The quality of a classifier is estimated using its weight
vectors. The feature extractor is characterized using two metrics that utilize
feature vectors it produces when synthetic data is fed as input. These
synthetic input vectors are produced by backpropagating desired outputs of the
classifier. Our empirical study of the proposed method for ResNet18, trained
with CAFIR10 and CAFIR100 datasets, confirms that data-less evaluation of DNN
classifiers is indeed possible.",2024-07-17,"Nathaniel Dean, Dilip Sarkar",http://arxiv.org/pdf/2407.13000v1,cs.LG
SmartQuant: CXL-based AI Model Store in Support of Runtime Configurable Weight Quantization,"Recent studies have revealed that, during the inference on generative AI
models such as transformer, the importance of different weights exhibits
substantial context-dependent variations. This naturally manifests a promising
potential of adaptively configuring weight quantization to improve the
generative AI inference efficiency. Although configurable weight quantization
can readily leverage the hardware support of variable-precision arithmetics in
modern GPU and AI accelerators, little prior research has studied how one could
exploit variable weight quantization to proportionally improve the AI model
memory access speed and energy efficiency. Motivated by the rapidly maturing
CXL ecosystem, this work develops a CXL-based design solution to fill this gap.
The key is to allow CXL memory controllers play an active role in supporting
and exploiting runtime configurable weight quantization. Using transformer as a
representative generative AI model, we carried out experiments that well
demonstrate the effectiveness of the proposed design solution.",2024-07-17,"Rui Xie, Asad Ul Haq, Linsen Ma, Krystal Sun, Sanchari Sen, Swagath Venkataramani, Liu Liu, Tong Zhang",http://arxiv.org/pdf/2407.15866v2,cs.LG
Sharpness-diversity tradeoff: improving flat ensembles with SharpBalance,"Recent studies on deep ensembles have identified the sharpness of the local
minima of individual learners and the diversity of the ensemble members as key
factors in improving test-time performance. Building on this, our study
investigates the interplay between sharpness and diversity within deep
ensembles, illustrating their crucial role in robust generalization to both
in-distribution (ID) and out-of-distribution (OOD) data. We discover a
trade-off between sharpness and diversity: minimizing the sharpness in the loss
landscape tends to diminish the diversity of individual members within the
ensemble, adversely affecting the ensemble's improvement. The trade-off is
justified through our theoretical analysis and verified empirically through
extensive experiments. To address the issue of reduced diversity, we introduce
SharpBalance, a novel training approach that balances sharpness and diversity
within ensembles. Theoretically, we show that our training strategy achieves a
better sharpness-diversity trade-off. Empirically, we conducted comprehensive
evaluations in various data sets (CIFAR-10, CIFAR-100, TinyImageNet) and showed
that SharpBalance not only effectively improves the sharpness-diversity
trade-off, but also significantly improves ensemble performance in ID and OOD
scenarios.",2024-07-17,"Haiquan Lu, Xiaotian Liu, Yefan Zhou, Qunli Li, Kurt Keutzer, Michael W. Mahoney, Yujun Yan, Huanrui Yang, Yaoqing Yang",http://arxiv.org/pdf/2407.12996v1,cs.LG
A Survey of AI-Powered Mini-Grid Solutions for a Sustainable Future in Rural Communities,"This paper presents a comprehensive survey of AI-driven mini-grid solutions
aimed at enhancing sustainable energy access. It emphasises the potential of
mini-grids, which can operate independently or in conjunction with national
power grids, to provide reliable and affordable electricity to remote
communities. Given the inherent unpredictability of renewable energy sources
such as solar and wind, the necessity for accurate energy forecasting and
management is discussed, highlighting the role of advanced AI techniques in
forecasting energy supply and demand, optimising grid operations, and ensuring
sustainable energy distribution. This paper reviews various forecasting models,
including statistical methods, machine learning algorithms, and hybrid
approaches, evaluating their effectiveness for both short-term and long-term
predictions. Additionally, it explores public datasets and tools such as
Prophet, NeuralProphet, and N-BEATS for model implementation and validation.
The survey concludes with recommendations for future research, addressing
challenges in model adaptation and optimisation for real-world applications.",2024-07-17,"Craig Pirie, Harsha Kalutarage, Muhammad Shadi Hajar, Nirmalie Wiratunga, Subodha Charles, Geeth Sandaru Madhushan, Priyantha Buddhika, Supun Wijesiriwardana, Akila Dimantha, Kithdara Hansamal, Shalitha Pathiranage",http://arxiv.org/pdf/2407.15865v1,cs.LG
Improving SAM Requires Rethinking its Optimization Formulation,"This paper rethinks Sharpness-Aware Minimization (SAM), which is originally
formulated as a zero-sum game where the weights of a network and a bounded
perturbation try to minimize/maximize, respectively, the same differentiable
loss. To fundamentally improve this design, we argue that SAM should instead be
reformulated using the 0-1 loss. As a continuous relaxation, we follow the
simple conventional approach where the minimizing (maximizing) player uses an
upper bound (lower bound) surrogate to the 0-1 loss. This leads to a novel
formulation of SAM as a bilevel optimization problem, dubbed as BiSAM. BiSAM
with newly designed lower-bound surrogate loss indeed constructs stronger
perturbation. Through numerical evidence, we show that BiSAM consistently
results in improved performance when compared to the original SAM and variants,
while enjoying similar computational complexity. Our code is available at
https://github.com/LIONS-EPFL/BiSAM.",2024-07-17,"Wanyun Xie, Fabian Latorre, Kimon Antonakopoulos, Thomas Pethick, Volkan Cevher",http://arxiv.org/pdf/2407.12993v1,cs.LG
Retrieval-Enhanced Machine Learning: Synthesis and Opportunities,"In the field of language modeling, models augmented with retrieval components
have emerged as a promising solution to address several challenges faced in the
natural language processing (NLP) field, including knowledge grounding,
interpretability, and scalability. Despite the primary focus on NLP, we posit
that the paradigm of retrieval-enhancement can be extended to a broader
spectrum of machine learning (ML) such as computer vision, time series
prediction, and computational biology. Therefore, this work introduces a formal
framework of this paradigm, Retrieval-Enhanced Machine Learning (REML), by
synthesizing the literature in various domains in ML with consistent notations
which is missing from the current literature. Also, we found that while a
number of studies employ retrieval components to augment their models, there is
a lack of integration with foundational Information Retrieval (IR) research. We
bridge this gap between the seminal IR research and contemporary REML studies
by investigating each component that comprises the REML framework. Ultimately,
the goal of this work is to equip researchers across various disciplines with a
comprehensive, formally structured framework of retrieval-enhanced models,
thereby fostering interdisciplinary future research.",2024-07-17,"To Eun Kim, Alireza Salemi, Andrew Drozdov, Fernando Diaz, Hamed Zamani",http://arxiv.org/pdf/2407.12982v2,cs.LG
A Framework for testing Federated Learning algorithms using an edge-like environment,"Federated Learning (FL) is a machine learning paradigm in which many clients
cooperatively train a single centralized model while keeping their data private
and decentralized. FL is commonly used in edge computing, which involves
placing computer workloads (both hardware and software) as close as possible to
the edge, where the data is being created and where actions are occurring,
enabling faster response times, greater data privacy, and reduced data transfer
costs. However, due to the heterogeneous data distributions/contents of
clients, it is non-trivial to accurately evaluate the contributions of local
models in global centralized model aggregation. This is an example of a major
challenge in FL, commonly known as data imbalance or class imbalance. In
general, testing and assessing FL algorithms can be a very difficult and
complex task due to the distributed nature of the systems. In this work, a
framework is proposed and implemented to assess FL algorithms in a more easy
and scalable way. This framework is evaluated over a distributed edge-like
environment managed by a container orchestration platform (i.e. Kubernetes).",2024-07-17,"Felipe Machado Schwanck, Marcos Tomazzoli Leipnitz, Joel Luís Carbonera, Juliano Araujo Wickboldt",http://arxiv.org/pdf/2407.12980v2,cs.LG
Leveraging Environment Interaction for Automated PDDL Translation and Planning with Large Language Models,"Large Language Models (LLMs) have shown remarkable performance in various
natural language tasks, but they often struggle with planning problems that
require structured reasoning. To address this limitation, the conversion of
planning problems into the Planning Domain Definition Language (PDDL) has been
proposed as a potential solution, enabling the use of automated planners.
However, generating accurate PDDL files typically demands human inputs or
correction, which can be time-consuming and costly. In this paper, we propose a
novel approach that leverages LLMs and environment feedback to automatically
generate PDDL domain and problem description files without the need for human
intervention. Our method introduces an iterative refinement process that
generates multiple problem PDDL candidates and progressively refines the domain
PDDL based on feedback obtained from interacting with the environment. To guide
the refinement process, we develop an Exploration Walk (EW) metric, which
provides rich feedback signals for LLMs to update the PDDL file. We evaluate
our approach on $10$ PDDL environments. We achieve an average task solve rate
of 66% compared to a 29% solve rate by GPT-4's intrinsic planning with
chain-of-thought prompting. Our work enables the automated modeling of planning
environments using LLMs and environment feedback, eliminating the need for
human intervention in the PDDL translation process and paving the way for more
reliable LLM agents in challenging problems. Our code is available at
https://github.com/BorealisAI/llm-pddl-planning",2024-07-17,"Sadegh Mahdavi, Raquel Aoki, Keyi Tang, Yanshuai Cao",http://arxiv.org/pdf/2407.12979v2,cs.LG
Rényi-infinity constrained sampling with $d^3$ membership queries,"Uniform sampling over a convex body is a fundamental algorithmic problem, yet
the convergence in KL or R\'enyi divergence of most samplers remains poorly
understood. In this work, we propose a constrained proximal sampler, a
principled and simple algorithm that possesses elegant convergence guarantees.
Leveraging the uniform ergodicity of this sampler, we show that it converges in
the R\'enyi-infinity divergence ($\mathcal R_\infty$) with no query complexity
overhead when starting from a warm start. This is the strongest of commonly
considered performance metrics, implying rates in $\{\mathcal R_q,
\mathsf{KL}\}$ convergence as special cases.
  By applying this sampler within an annealing scheme, we propose an algorithm
which can approximately sample $\varepsilon$-close to the uniform distribution
on convex bodies in $\mathcal R_\infty$-divergence with
$\widetilde{\mathcal{O}}(d^3\, \text{polylog} \frac{1}{\varepsilon})$ query
complexity. This improves on all prior results in $\{\mathcal R_q,
\mathsf{KL}\}$-divergences, without resorting to any algorithmic modifications
or post-processing of the sample. It also matches the prior best known
complexity in total variation distance.",2024-07-17,"Yunbum Kook, Matthew S. Zhang",http://arxiv.org/pdf/2407.12967v1,cs.LG
R+X: Retrieval and Execution from Everyday Human Videos,"We present R+X, a framework which enables robots to learn skills from long,
unlabelled, first-person videos of humans performing everyday tasks. Given a
language command from a human, R+X first retrieves short video clips containing
relevant behaviour, and then executes the skill by conditioning an in-context
imitation learning method (KAT) on this behaviour. By leveraging a Vision
Language Model (VLM) for retrieval, R+X does not require any manual annotation
of the videos, and by leveraging in-context learning for execution, robots can
perform commanded skills immediately, without requiring a period of training on
the retrieved videos. Experiments studying a range of everyday household tasks
show that R+X succeeds at translating unlabelled human videos into robust robot
skills, and that R+X outperforms several recent alternative methods. Videos and
code are available at https://www.robot-learning.uk/r-plus-x.",2024-07-17,"Georgios Papagiannis, Norman Di Palo, Pietro Vitiello, Edward Johns",http://arxiv.org/pdf/2407.12957v2,cs.LG
Beyond the Veil of Similarity: Quantifying Semantic Continuity in Explainable AI,"We introduce a novel metric for measuring semantic continuity in Explainable
AI methods and machine learning models. We posit that for models to be truly
interpretable and trustworthy, similar inputs should yield similar
explanations, reflecting a consistent semantic understanding. By leveraging XAI
techniques, we assess semantic continuity in the task of image recognition. We
conduct experiments to observe how incremental changes in input affect the
explanations provided by different XAI methods. Through this approach, we aim
to evaluate the models' capability to generalize and abstract semantic concepts
accurately and to evaluate different XAI methods in correctly capturing the
model behaviour. This paper contributes to the broader discourse on AI
interpretability by proposing a quantitative measure for semantic continuity
for XAI methods, offering insights into the models' and explainers' internal
reasoning processes, and promoting more reliable and transparent AI systems.",2024-07-17,"Qi Huang, Emanuele Mezzi, Osman Mutlu, Miltiadis Kofinas, Vidya Prasad, Shadnan Azwad Khan, Elena Ranguelova, Niki van Stein",http://arxiv.org/pdf/2407.12950v2,cs.LG
The 2024 Foundation Model Transparency Index,"Foundation models are increasingly consequential yet extremely opaque. To
characterize the status quo, the Foundation Model Transparency Index (FMTI) was
launched in October 2023 to measure the transparency of leading foundation
model developers. FMTI 2023 assessed 10 major foundation model developers (e.g.
OpenAI, Google) on 100 transparency indicators (e.g. does the developer
disclose the wages it pays for data labor?). At the time, developers publicly
disclosed very limited information with the average score being 37 out of 100.
To understand how the status quo has changed, we conduct a follow-up study
after 6 months: we score 14 developers against the same 100 indicators. While
in FMTI 2023 we searched for publicly available information, in FMTI 2024
developers submit reports on the 100 transparency indicators, potentially
including information that was not previously public. We find that developers
now score 58 out of 100 on average, a 21 point improvement over FMTI 2023. Much
of this increase is driven by developers disclosing information during the FMTI
2024 process: on average, developers disclosed information related to 16.6
indicators that was not previously public. We observe regions of sustained
(i.e. across 2023 and 2024) and systemic (i.e. across most or all developers)
opacity such as on copyright status, data access, data labor, and downstream
impact. We publish transparency reports for each developer that consolidate
information disclosures: these reports are based on the information disclosed
to us via developers. Our findings demonstrate that transparency can be
improved in this nascent ecosystem, the Foundation Model Transparency Index
likely contributes to these improvements, and policymakers should consider
interventions in areas where transparency has not improved.",2024-07-17,"Rishi Bommasani, Kevin Klyman, Sayash Kapoor, Shayne Longpre, Betty Xiong, Nestor Maslej, Percy Liang",http://arxiv.org/pdf/2407.12929v2,cs.LG
Matryoshka-Adaptor: Unsupervised and Supervised Tuning for Smaller Embedding Dimensions,"Embeddings from Large Language Models (LLMs) have emerged as critical
components in various applications, particularly for information retrieval.
While high-dimensional embeddings generally demonstrate superior performance as
they contain more salient information, their practical application is
frequently hindered by elevated computational latency and the associated higher
cost. To address these challenges, we propose Matryoshka-Adaptor, a novel
tuning framework designed for the customization of LLM embeddings.
Matryoshka-Adaptor facilitates substantial dimensionality reduction while
maintaining comparable performance levels, thereby achieving a significant
enhancement in computational efficiency and cost-effectiveness. Our framework
directly modifies the embeddings from pre-trained LLMs which is designed to be
seamlessly integrated with any LLM architecture, encompassing those accessible
exclusively through black-box APIs. Also, it exhibits efficacy in both
unsupervised and supervised learning settings. A rigorous evaluation conducted
across a diverse corpus of English, multilingual, and multimodal datasets
consistently reveals substantial gains with Matryoshka-Adaptor. Notably, with
Google and OpenAI Embedding APIs, Matryoshka-Adaptor achieves a reduction in
dimensionality ranging from two- to twelve-fold without compromising
performance across multiple BEIR datasets.",2024-07-17,"Jinsung Yoon, Raj Sinha, Sercan O Arik, Tomas Pfister",http://arxiv.org/pdf/2407.20243v1,cs.LG
AgentPoison: Red-teaming LLM Agents via Poisoning Memory or Knowledge Bases,"LLM agents have demonstrated remarkable performance across various
applications, primarily due to their advanced capabilities in reasoning,
utilizing external knowledge and tools, calling APIs, and executing actions to
interact with environments. Current agents typically utilize a memory module or
a retrieval-augmented generation (RAG) mechanism, retrieving past knowledge and
instances with similar embeddings from knowledge bases to inform task planning
and execution. However, the reliance on unverified knowledge bases raises
significant concerns about their safety and trustworthiness. To uncover such
vulnerabilities, we propose a novel red teaming approach AgentPoison, the first
backdoor attack targeting generic and RAG-based LLM agents by poisoning their
long-term memory or RAG knowledge base. In particular, we form the trigger
generation process as a constrained optimization to optimize backdoor triggers
by mapping the triggered instances to a unique embedding space, so as to ensure
that whenever a user instruction contains the optimized backdoor trigger, the
malicious demonstrations are retrieved from the poisoned memory or knowledge
base with high probability. In the meantime, benign instructions without the
trigger will still maintain normal performance. Unlike conventional backdoor
attacks, AgentPoison requires no additional model training or fine-tuning, and
the optimized backdoor trigger exhibits superior transferability, in-context
coherence, and stealthiness. Extensive experiments demonstrate AgentPoison's
effectiveness in attacking three types of real-world LLM agents: RAG-based
autonomous driving agent, knowledge-intensive QA agent, and healthcare
EHRAgent. On each agent, AgentPoison achieves an average attack success rate
higher than 80% with minimal impact on benign performance (less than 1%) with a
poison rate less than 0.1%.",2024-07-17,"Zhaorun Chen, Zhen Xiang, Chaowei Xiao, Dawn Song, Bo Li",http://arxiv.org/pdf/2407.12784v1,cs.LG
Contrastive Adversarial Training for Unsupervised Domain Adaptation,"Domain adversarial training has shown its effective capability for finding
domain invariant feature representations and been successfully adopted for
various domain adaptation tasks. However, recent advances of large models
(e.g., vision transformers) and emerging of complex adaptation scenarios (e.g.,
DomainNet) make adversarial training being easily biased towards source domain
and hardly adapted to target domain. The reason is twofold: relying on large
amount of labelled data from source domain for large model training and lacking
of labelled data from target domain for fine-tuning. Existing approaches widely
focused on either enhancing discriminator or improving the training stability
for the backbone networks. Due to unbalanced competition between the feature
extractor and the discriminator during the adversarial training, existing
solutions fail to function well on complex datasets. To address this issue, we
proposed a novel contrastive adversarial training (CAT) approach that leverages
the labeled source domain samples to reinforce and regulate the feature
generation for target domain. Typically, the regulation forces the target
feature distribution being similar to the source feature distribution. CAT
addressed three major challenges in adversarial learning: 1) ensure the feature
distributions from two domains as indistinguishable as possible for the
discriminator, resulting in a more robust domain-invariant feature generation;
2) encourage target samples moving closer to the source in the feature space,
reducing the requirement for generalizing classifier trained on the labeled
source domain to unlabeled target domain; 3) avoid directly aligning unpaired
source and target samples within mini-batch. CAT can be easily plugged into
existing models and exhibits significant performance improvements.",2024-07-17,"Jiahong Chen, Zhilin Zhang, Lucy Li, Behzad Shahrasbi, Arjun Mishra",http://arxiv.org/pdf/2407.12782v1,cs.LG
Jigsaw Game: Federated Clustering,"Federated learning has recently garnered significant attention, especially
within the domain of supervised learning. However, despite the abundance of
unlabeled data on end-users, unsupervised learning problems such as clustering
in the federated setting remain underexplored. In this paper, we investigate
the federated clustering problem, with a focus on federated k-means. We outline
the challenge posed by its non-convex objective and data heterogeneity in the
federated framework. To tackle these challenges, we adopt a new perspective by
studying the structures of local solutions in k-means and propose a one-shot
algorithm called FeCA (Federated Centroid Aggregation). FeCA adaptively refines
local solutions on clients, then aggregates these refined solutions to recover
the global solution of the entire dataset in a single round. We empirically
demonstrate the robustness of FeCA under various federated scenarios on both
synthetic and real-world data. Additionally, we extend FeCA to representation
learning and present DeepFeCA, which combines DeepCluster and FeCA for
unsupervised feature learning in the federated setting.",2024-07-17,"Jinxuan Xu, Hong-You Chen, Wei-Lun Chao, Yuqian Zhang",http://arxiv.org/pdf/2407.12764v1,cs.LG
A survey and taxonomy of methods interpreting random forest models,"The interpretability of random forest (RF) models is a research topic of
growing interest in the machine learning (ML) community. In the state of the
art, RF is considered a powerful learning ensemble given its predictive
performance, flexibility, and ease of use. Furthermore, the inner process of
the RF model is understandable because it uses an intuitive and intelligible
approach for building the RF decision tree ensemble. However, the RF resulting
model is regarded as a ""black box"" because of its numerous deep decision trees.
Gaining visibility over the entire process that induces the final decisions by
exploring each decision tree is complicated, if not impossible. This complexity
limits the acceptance and implementation of RF models in several fields of
application. Several papers have tackled the interpretation of RF models. This
paper aims to provide an extensive review of methods used in the literature to
interpret RF resulting models. We have analyzed these methods and classified
them based on different axes. Although this review is not exhaustive, it
provides a taxonomy of various techniques that should guide users in choosing
the most appropriate tools for interpreting RF models, depending on the
interpretability aspects sought. It should also be valuable for researchers who
aim to focus their work on the interpretability of RF or ML black boxes in
general.",2024-07-17,"Maissae Haddouchi, Abdelaziz Berrado",http://arxiv.org/pdf/2407.12759v1,cs.LG
LookupViT: Compressing visual information to a limited number of tokens,"Vision Transformers (ViT) have emerged as the de-facto choice for numerous
industry grade vision solutions. But their inference cost can be prohibitive
for many settings, as they compute self-attention in each layer which suffers
from quadratic computational complexity in the number of tokens. On the other
hand, spatial information in images and spatio-temporal information in videos
is usually sparse and redundant. In this work, we introduce LookupViT, that
aims to exploit this information sparsity to reduce ViT inference cost.
LookupViT provides a novel general purpose vision transformer block that
operates by compressing information from higher resolution tokens to a fixed
number of tokens. These few compressed tokens undergo meticulous processing,
while the higher-resolution tokens are passed through computationally cheaper
layers. Information sharing between these two token sets is enabled through a
bidirectional cross-attention mechanism. The approach offers multiple
advantages - (a) easy to implement on standard ML accelerators (GPUs/TPUs) via
standard high-level operators, (b) applicable to standard ViT and its variants,
thus generalizes to various tasks, (c) can handle different tokenization and
attention approaches. LookupViT also offers flexibility for the compressed
tokens, enabling performance-computation trade-offs in a single trained model.
We show LookupViT's effectiveness on multiple domains - (a) for
image-classification (ImageNet-1K and ImageNet-21K), (b) video classification
(Kinetics400 and Something-Something V2), (c) image captioning (COCO-Captions)
with a frozen encoder. LookupViT provides $2\times$ reduction in FLOPs while
upholding or improving accuracy across these domains. In addition, LookupViT
also demonstrates out-of-the-box robustness and generalization on image
classification (ImageNet-C,R,A,O), improving by up to $4\%$ over ViT.",2024-07-17,"Rajat Koner, Gagan Jain, Prateek Jain, Volker Tresp, Sujoy Paul",http://arxiv.org/pdf/2407.12753v1,cs.LG
Scalable Monte Carlo for Bayesian Learning,"This book aims to provide a graduate-level introduction to advanced topics in
Markov chain Monte Carlo (MCMC) algorithms, as applied broadly in the Bayesian
computational context. Most, if not all of these topics (stochastic gradient
MCMC, non-reversible MCMC, continuous time MCMC, and new techniques for
convergence assessment) have emerged as recently as the last decade, and have
driven substantial recent practical and theoretical advances in the field. A
particular focus is on methods that are scalable with respect to either the
amount of data, or the data dimension, motivated by the emerging high-priority
application areas in machine learning and AI.",2024-07-17,"Paul Fearnhead, Christopher Nemeth, Chris J. Oates, Chris Sherlock",http://arxiv.org/pdf/2407.12751v1,cs.LG
Comparing Federated Stochastic Gradient Descent and Federated Averaging for Predicting Hospital Length of Stay,"Predicting hospital length of stay (LOS) reliably is an essential need for
efficient resource allocation at hospitals. Traditional predictive modeling
tools frequently have difficulty acquiring sufficient and diverse data because
healthcare institutions have privacy rules in place. In our study, we modeled
this problem as an empirical graph where nodes are the hospitals. This modeling
approach facilitates collaborative model training by modeling decentralized
data sources from different hospitals without extracting sensitive data outside
of hospitals. A local model is trained on a node (hospital) by aiming the
generalized total variation minimization (GTVMin). Moreover, we implemented and
compared two different federated learning optimization algorithms named
federated stochastic gradient descent (FedSGD) and federated averaging
(FedAVG). Our results show that federated learning enables accurate prediction
of hospital LOS while addressing privacy concerns without extracting data
outside healthcare institutions.",2024-07-17,Mehmet Yigit Balik,http://arxiv.org/pdf/2407.12741v1,cs.LG
An Evaluation of Continual Learning for Advanced Node Semiconductor Defect Inspection,"Deep learning-based semiconductor defect inspection has gained traction in
recent years, offering a powerful and versatile approach that provides high
accuracy, adaptability, and efficiency in detecting and classifying nano-scale
defects. However, semiconductor manufacturing processes are continually
evolving, leading to the emergence of new types of defects over time. This
presents a significant challenge for conventional supervised defect detectors,
as they may suffer from catastrophic forgetting when trained on new defect
datasets, potentially compromising performance on previously learned tasks. An
alternative approach involves the constant storage of previously trained
datasets alongside pre-trained model versions, which can be utilized for
(re-)training from scratch or fine-tuning whenever encountering a new defect
dataset. However, adhering to such a storage template is impractical in terms
of size, particularly when considering High-Volume Manufacturing (HVM).
Additionally, semiconductor defect datasets, especially those encompassing
stochastic defects, are often limited and expensive to obtain, thus lacking
sufficient representation of the entire universal set of defectivity. This work
introduces a task-agnostic, meta-learning approach aimed at addressing this
challenge, which enables the incremental addition of new defect classes and
scales to create a more robust and generalized model for semiconductor defect
inspection. We have benchmarked our approach using real resist-wafer SEM
(Scanning Electron Microscopy) datasets for two process steps, ADI and AEI,
demonstrating its superior performance compared to conventional supervised
training methods.",2024-07-17,"Amit Prasad, Bappaditya Dey, Victor Blanco, Sandip Halder",http://arxiv.org/pdf/2407.12724v1,cs.LG
A Unifying Post-Processing Framework for Multi-Objective Learn-to-Defer Problems,"Learn-to-Defer is a paradigm that enables learning algorithms to work not in
isolation but as a team with human experts. In this paradigm, we permit the
system to defer a subset of its tasks to the expert. Although there are
currently systems that follow this paradigm and are designed to optimize the
accuracy of the final human-AI team, the general methodology for developing
such systems under a set of constraints (e.g., algorithmic fairness, expert
intervention budget, defer of anomaly, etc.) remains largely unexplored. In
this paper, using a $d$-dimensional generalization to the fundamental lemma of
Neyman and Pearson (d-GNP), we obtain the Bayes optimal solution for
learn-to-defer systems under various constraints. Furthermore, we design a
generalizable algorithm to estimate that solution and apply this algorithm to
the COMPAS and ACSIncome datasets. Our algorithm shows improvements in terms of
constraint violation over a set of baselines.",2024-07-17,"Mohammad-Amin Charusaie, Samira Samadi",http://arxiv.org/pdf/2407.12710v1,cs.LG
TTSDS -- Text-to-Speech Distribution Score,"Many recently published Text-to-Speech (TTS) systems produce audio close to
real speech. However, TTS evaluation needs to be revisited to make sense of the
results obtained with the new architectures, approaches and datasets. We
propose evaluating the quality of synthetic speech as a combination of multiple
factors such as prosody, speaker identity, and intelligibility. Our approach
assesses how well synthetic speech mirrors real speech by obtaining correlates
of each factor and measuring their distance from both real speech datasets and
noise datasets. We benchmark 35 TTS systems developed between 2008 and 2024 and
show that our score computed as an unweighted average of factors strongly
correlates with the human evaluations from each time period.",2024-07-17,"Christoph Minixhofer, Ondřej Klejch, Peter Bell",http://arxiv.org/pdf/2407.12707v3,cs.LG
Enhancing the Utility of Privacy-Preserving Cancer Classification using Synthetic Data,"Deep learning holds immense promise for aiding radiologists in breast cancer
detection. However, achieving optimal model performance is hampered by
limitations in availability and sharing of data commonly associated to patient
privacy concerns. Such concerns are further exacerbated, as traditional deep
learning models can inadvertently leak sensitive training information. This
work addresses these challenges exploring and quantifying the utility of
privacy-preserving deep learning techniques, concretely, (i) differentially
private stochastic gradient descent (DP-SGD) and (ii) fully synthetic training
data generated by our proposed malignancy-conditioned generative adversarial
network. We assess these methods via downstream malignancy classification of
mammography masses using a transformer model. Our experimental results depict
that synthetic data augmentation can improve privacy-utility tradeoffs in
differentially private model training. Further, model pretraining on synthetic
data achieves remarkable performance, which can be further increased with
DP-SGD fine-tuning across all privacy guarantees. With this first in-depth
exploration of privacy-preserving deep learning in breast imaging, we address
current and emerging clinical privacy requirements and pave the way towards the
adoption of private high-utility deep diagnostic models. Our reproducible
codebase is publicly available at https://github.com/RichardObi/mammo_dp.",2024-07-17,"Richard Osuala, Daniel M. Lang, Anneliese Riess, Georgios Kaissis, Zuzanna Szafranowska, Grzegorz Skorupko, Oliver Diaz, Julia A. Schnabel, Karim Lekadir",http://arxiv.org/pdf/2407.12669v1,cs.LG
Beyond Next Token Prediction: Patch-Level Training for Large Language Models,"The prohibitive training costs of Large Language Models (LLMs) have emerged
as a significant bottleneck in the development of next-generation LLMs. In this
paper, we show that it is possible to significantly reduce the training costs
of LLMs without sacrificing their performance. Specifically, we introduce
patch-level training for LLMs, in which multiple tokens are aggregated into a
unit of higher information density, referred to as a `patch', to serve as the
fundamental text unit for training LLMs. During patch-level training, we feed
the language model shorter sequences of patches and train it to predict the
next patch, thereby processing the majority of the training data at a
significantly reduced cost. Following this, the model continues token-level
training on the remaining training data to align with the inference mode.
Experiments on a diverse range of models (370M-2.7B parameters) demonstrate
that patch-level training can reduce the overall training costs to 0.5$\times$,
without compromising the model performance compared to token-level training.
Source code: https://github.com/shaochenze/PatchTrain.",2024-07-17,"Chenze Shao, Fandong Meng, Jie Zhou",http://arxiv.org/pdf/2407.12665v3,cs.LG
SpikeVoice: High-Quality Text-to-Speech Via Efficient Spiking Neural Network,"Brain-inspired Spiking Neural Network (SNN) has demonstrated its
effectiveness and efficiency in vision, natural language, and speech
understanding tasks, indicating their capacity to ""see"", ""listen"", and ""read"".
In this paper, we design \textbf{SpikeVoice}, which performs high-quality
Text-To-Speech (TTS) via SNN, to explore the potential of SNN to ""speak"". A
major obstacle to using SNN for such generative tasks lies in the demand for
models to grasp long-term dependencies. The serial nature of spiking neurons,
however, leads to the invisibility of information at future spiking time steps,
limiting SNN models to capture sequence dependencies solely within the same
time step. We term this phenomenon ""partial-time dependency"". To address this
issue, we introduce Spiking Temporal-Sequential Attention STSA in the
SpikeVoice. To the best of our knowledge, SpikeVoice is the first TTS work in
the SNN field. We perform experiments using four well-established datasets that
cover both Chinese and English languages, encompassing scenarios with both
single-speaker and multi-speaker configurations. The results demonstrate that
SpikeVoice can achieve results comparable to Artificial Neural Networks (ANN)
with only 10.5 energy consumption of ANN.",2024-07-17,"Kexin Wang, Jiahong Zhang, Yong Ren, Man Yao, Di Shang, Bo Xu, Guoqi Li",http://arxiv.org/pdf/2408.00788v1,cs.LG
Profiling quantum circuits for their efficient execution on single- and multi-core architectures,"Application-specific quantum computers offer the most efficient means to
tackle problems intractable by classical computers. Realizing these
architectures necessitates a deep understanding of quantum circuit properties
and their relationship to execution outcomes on quantum devices. Our study aims
to perform for the first time a rigorous examination of quantum circuits by
introducing graph theory-based metrics extracted from their qubit interaction
graph and gate dependency graph alongside conventional parameters describing
the circuit itself. This methodology facilitates a comprehensive analysis and
clustering of quantum circuits. Furthermore, it uncovers a connection between
parameters rooted in both qubit interaction and gate dependency graphs, and the
performance metrics for quantum circuit mapping, across a range of established
quantum device and mapping configurations. Among the various device
configurations, we particularly emphasize modular (i.e., multi-core) quantum
computing architectures due to their high potential as a viable solution for
quantum device scalability. This thorough analysis will help us to: i) identify
key attributes of quantum circuits that affect the quantum circuit mapping
performance metrics; ii) predict the performance on a specific chip for similar
circuit structures; iii) determine preferable combinations of mapping
techniques and hardware setups for specific circuits; and iv) define
representative benchmark sets by clustering similarly structured circuits.",2024-07-17,"Medina Bandic, Pablo le Henaff, Anabel Ovide, Pau Escofet, Sahar Ben Rached, Santiago Rodrigo, Hans van Someren, Sergi Abadal, Eduard Alarcon, Carmen G. Almudever, Sebastian Feld",http://arxiv.org/pdf/2407.12640v1,cs.LG
ARTEMIS: A Mixed Analog-Stochastic In-DRAM Accelerator for Transformer Neural Networks,"Transformers have emerged as a powerful tool for natural language processing
(NLP) and computer vision. Through the attention mechanism, these models have
exhibited remarkable performance gains when compared to conventional approaches
like recurrent neural networks (RNNs) and convolutional neural networks (CNNs).
Nevertheless, transformers typically demand substantial execution time due to
their extensive computations and large memory footprint. Processing in-memory
(PIM) and near-memory computing (NMC) are promising solutions to accelerating
transformers as they offer high compute parallelism and memory bandwidth.
However, designing PIM/NMC architectures to support the complex operations and
massive amounts of data that need to be moved between layers in transformer
neural networks remains a challenge. We propose ARTEMIS, a mixed
analog-stochastic in-DRAM accelerator for transformer models. Through employing
minimal changes to the conventional DRAM arrays, ARTEMIS efficiently alleviates
the costs associated with transformer model execution by supporting stochastic
computing for multiplications and temporal analog accumulations using a novel
in-DRAM metal-on-metal capacitor. Our analysis indicates that ARTEMIS exhibits
at least 3.0x speedup, 1.8x lower energy, and 1.9x better energy efficiency
compared to GPU, TPU, CPU, and state-of-the-art PIM transformer hardware
accelerators.",2024-07-17,"Salma Afifi, Ishan Thakkar, Sudeep Pasricha",http://arxiv.org/pdf/2407.12638v1,cs.LG
A Methodology Establishing Linear Convergence of Adaptive Gradient Methods under PL Inequality,"Adaptive gradient-descent optimizers are the standard choice for training
neural network models. Despite their faster convergence than gradient-descent
and remarkable performance in practice, the adaptive optimizers are not as well
understood as vanilla gradient-descent. A reason is that the dynamic update of
the learning rate that helps in faster convergence of these methods also makes
their analysis intricate. Particularly, the simple gradient-descent method
converges at a linear rate for a class of optimization problems, whereas the
practically faster adaptive gradient methods lack such a theoretical guarantee.
The Polyak-{\L}ojasiewicz (PL) inequality is the weakest known class, for which
linear convergence of gradient-descent and its momentum variants has been
proved. Therefore, in this paper, we prove that AdaGrad and Adam, two
well-known adaptive gradient methods, converge linearly when the cost function
is smooth and satisfies the PL inequality. Our theoretical framework follows a
simple and unified approach, applicable to both batch and stochastic gradients,
which can potentially be utilized in analyzing linear convergence of other
variants of Adam.",2024-07-17,"Kushal Chakrabarti, Mayank Baranwal",http://arxiv.org/pdf/2407.12629v1,cs.LG
MCU-MixQ: A HW/SW Co-optimized Mixed-precision Neural Network Design Framework for MCUs,"Mixed-precision neural network (MPNN) that utilizes just enough data width
for the neural network processing is an effective approach to meet the
stringent resources constraints including memory and computing of MCUs.
Nevertheless, there is still a lack of sub-byte and mixed-precision SIMD
operations in MCU-class ISA and the limited computing capability of MCUs
remains underutilized, which further aggravates the computing bound encountered
in neural network processing. As a result, the benefits of MPNNs cannot be
fully unleashed. In this work, we propose to pack multiple low-bitwidth
arithmetic operations within a single instruction multiple data (SIMD)
instructions in typical MCUs, and then develop an efficient convolution
operator by exploring both the data parallelism and computing parallelism in
convolution along with the proposed SIMD packing. Finally, we further leverage
Neural Architecture Search (NAS) to build a HW/SW co-designed MPNN design
framework, namely MCU-MixQ. This framework can optimize both the MPNN
quantization and MPNN implementation efficiency, striking an optimized balance
between neural network performance and accuracy. According to our experiment
results, MCU-MixQ achieves 2.1$\times$ and 1.4$\times$ speedup over CMix-NN and
MCUNet respectively under the same resource constraints.",2024-07-17,"Junfeng Gong, Cheng Liu, Long Cheng, Huawei Li, Xiaowei Li",http://arxiv.org/pdf/2407.18267v1,cs.LG
On Diversity in Discriminative Neural Networks,"Diversity is a concept of prime importance in almost all disciplines based on
information processing. In telecommunications, for example, spatial, temporal,
and frequency diversity, as well as redundant coding, are fundamental concepts
that have enabled the design of extremely efficient systems. In machine
learning, in particular with neural networks, diversity is not always a concept
that is emphasized or at least clearly identified. This paper proposes a neural
network architecture that builds upon various diversity principles, some of
them already known, others more original. Our architecture obtains remarkable
results, with a record self-supervised learning accuracy of 99. 57% in MNIST,
and a top tier promising semi-supervised learning accuracy of 94.21% in
CIFAR-10 using only 25 labels per class.",2024-07-17,"Brahim Oubaha, Claude Berrou, Xueyao Ji, Yehya Nasser, Raphaël Le Bidan",http://arxiv.org/pdf/2407.12599v1,cs.LG
Estimate Epidemiological Parameters given Partial Observations based on Algebraically Observable PINNs,"In this study, we considered the problem of estimating epidemiological
parameters based on physics-informed neural networks (PINNs). In practice, not
all trajectory data corresponding to the population estimated by epidemic
models can be obtained, and some observed trajectories are noisy. Learning
PINNs to estimate unknown epidemiological parameters using such partial
observations is challenging. Accordingly, we introduce the concept of algebraic
observability into PINNs. The validity of the proposed PINN, named as an
algebraically observable PINNs, in terms of estimation parameters and
prediction of unobserved variables, is demonstrated through numerical
experiments.",2024-07-17,Mizuka Komatsu,http://arxiv.org/pdf/2407.12598v1,cs.LG
DP-KAN: Differentially Private Kolmogorov-Arnold Networks,"We study the Kolmogorov-Arnold Network (KAN), recently proposed as an
alternative to the classical Multilayer Perceptron (MLP), in the application
for differentially private model training. Using the DP-SGD algorithm, we
demonstrate that KAN can be made private in a straightforward manner and
evaluated its performance across several datasets. Our results indicate that
the accuracy of KAN is not only comparable with MLP but also experiences
similar deterioration due to privacy constraints, making it suitable for
differentially private model training.",2024-07-17,"Nikita P. Kalinin, Simone Bombari, Hossein Zakerinia, Christoph H. Lampert",http://arxiv.org/pdf/2407.12569v1,cs.LG
"End-to-end Stroke imaging analysis, using reservoir computing-based effective connectivity, and interpretable Artificial intelligence","In this paper, we propose a reservoir computing-based and directed graph
analysis pipeline. The goal of this pipeline is to define an efficient brain
representation for connectivity in stroke data derived from magnetic resonance
imaging. Ultimately, this representation is used within a directed graph
convolutional architecture and investigated with explainable artificial
intelligence (AI) tools.
  Stroke is one of the leading causes of mortality and morbidity worldwide, and
it demands precise diagnostic tools for timely intervention and improved
patient outcomes. Neuroimaging data, with their rich structural and functional
information, provide a fertile ground for biomarker discovery. However, the
complexity and variability of information flow in the brain requires advanced
analysis, especially if we consider the case of disrupted networks as those
given by the brain connectome of stroke patients. To address the needs given by
this complex scenario we proposed an end-to-end pipeline. This pipeline begins
with reservoir computing causality, to define effective connectivity of the
brain. This allows directed graph network representations which have not been
fully investigated so far by graph convolutional network classifiers. Indeed,
the pipeline subsequently incorporates a classification module to categorize
the effective connectivity (directed graphs) of brain networks of patients
versus matched healthy control. The classification led to an area under the
curve of 0.69 with the given heterogeneous dataset. Thanks to explainable
tools, an interpretation of disrupted networks across the brain networks was
possible. This elucidates the effective connectivity biomarker's contribution
to stroke classification, fostering insights into disease mechanisms and
treatment responses.",2024-07-17,"Wojciech Ciezobka, Joan Falco-Roget, Cemal Koba, Alessandro Crimi",http://arxiv.org/pdf/2407.12553v1,cs.LG
UniTE: A Survey and Unified Pipeline for Pre-training Spatiotemporal Trajectory Embeddings,"Spatiotemporal trajectories are sequences of timestamped locations, which
enable a variety of analyses that in turn enable important real-world
applications. It is common to map trajectories to vectors, called embeddings,
before subsequent analyses. Thus, the qualities of embeddings are very
important. Methods for pre-training embeddings, which leverage unlabeled
trajectories for training universal embeddings, have shown promising
applicability across different tasks, thus attracting considerable interest.
However, research progress on this topic faces two key challenges: a lack of a
comprehensive overview of existing methods, resulting in several related
methods not being well-recognized, and the absence of a unified pipeline,
complicating the development of new methods and the analysis of methods.
  We present UniTE, a survey and a unified pipeline for this domain. In doing
so, we present a comprehensive list of existing methods for pre-training
trajectory embeddings, which includes methods that either explicitly or
implicitly employ pre-training techniques. Further, we present a unified and
modular pipeline with publicly available underlying code, simplifying the
process of constructing and evaluating methods for pre-training trajectory
embeddings. Additionally, we contribute a selection of experimental results
using the proposed pipeline on real-world datasets. Implementation of the
pipeline is publicly available at https://github.com/Logan-Lin/UniTE.",2024-07-17,"Yan Lin, Zeyu Zhou, Yicheng Liu, Haochen Lv, Haomin Wen, Tianyi Li, Yushuai Li, Christian S. Jensen, Shengnan Guo, Youfang Lin, Huaiyu Wan",http://arxiv.org/pdf/2407.12550v2,cs.LG
Abstraction Alignment: Comparing Model-Learned and Human-Encoded Conceptual Relationships,"While interpretability methods identify a model's learned concepts, they
overlook the relationships between concepts that make up its abstractions and
inform its ability to generalize to new data. To assess whether models' have
learned human-aligned abstractions, we introduce abstraction alignment, a
methodology to compare model behavior against formal human knowledge.
Abstraction alignment externalizes domain-specific human knowledge as an
abstraction graph, a set of pertinent concepts spanning levels of abstraction.
Using the abstraction graph as a ground truth, abstraction alignment measures
the alignment of a model's behavior by determining how much of its uncertainty
is accounted for by the human abstractions. By aggregating abstraction
alignment across entire datasets, users can test alignment hypotheses, such as
which human concepts the model has learned and where misalignments recur. In
evaluations with experts, abstraction alignment differentiates seemingly
similar errors, improves the verbosity of existing model-quality metrics, and
uncovers improvements to current human abstractions.",2024-07-17,"Angie Boggust, Hyemin Bang, Hendrik Strobelt, Arvind Satyanarayan",http://arxiv.org/pdf/2407.12543v2,cs.LG
Navigating the Smog: A Cooperative Multi-Agent RL for Accurate Air Pollution Mapping through Data Assimilation,"The rapid rise of air pollution events necessitates accurate, real-time
monitoring for informed mitigation strategies. Data Assimilation (DA) methods
provide promising solutions, but their effectiveness hinges heavily on optimal
measurement locations. This paper presents a novel approach for air quality
mapping where autonomous drones, guided by a collaborative multi-agent
reinforcement learning (MARL) framework, act as airborne detectives. Ditching
the limitations of static sensor networks, the drones engage in a synergistic
interaction, adapting their flight paths in real time to gather optimal data
for Data Assimilation (DA). Our approach employs a tailored reward function
with dynamic credit assignment, enabling drones to prioritize informative
measurements without requiring unavailable ground truth data, making it
practical for real-world deployments. Extensive experiments using a real-world
dataset demonstrate that our solution achieves significantly improved pollution
estimates, even with limited drone resources or limited prior knowledge of the
pollution plume. Beyond air quality, this solution unlocks possibilities for
tackling diverse environmental challenges like wildfire detection and
management through scalable and autonomous drone cooperation.",2024-07-17,"Ichrak Mokhtari, Walid Bechkit, Mohamed Sami Assenine, Hervé Rivano",http://arxiv.org/pdf/2407.12539v1,cs.LG
A Survey on Universal Approximation Theorems,"This paper discusses various theorems on the approximation capabilities of
neural networks (NNs), which are known as universal approximation theorems
(UATs). The paper gives a systematic overview of UATs starting from the
preliminary results on function approximation, such as Taylor's theorem,
Fourier's theorem, Weierstrass approximation theorem, Kolmogorov - Arnold
representation theorem, etc. Theoretical and numerical aspects of UATs are
covered from both arbitrary width and depth.",2024-07-17,Midhun T Augustine,http://arxiv.org/pdf/2407.12895v1,cs.LG
Evaluating the transferability potential of deep learning models for climate downscaling,"Climate downscaling, the process of generating high-resolution climate data
from low-resolution simulations, is essential for understanding and adapting to
climate change at regional and local scales. Deep learning approaches have
proven useful in tackling this problem. However, existing studies usually focus
on training models for one specific task, location and variable, which are
therefore limited in their generalizability and transferability. In this paper,
we evaluate the efficacy of training deep learning downscaling models on
multiple diverse climate datasets to learn more robust and transferable
representations. We evaluate the effectiveness of architectures zero-shot
transferability using CNNs, Fourier Neural Operators (FNOs), and vision
Transformers (ViTs). We assess the spatial, variable, and product
transferability of downscaling models experimentally, to understand the
generalizability of these different architecture types.",2024-07-17,"Ayush Prasad, Paula Harder, Qidong Yang, Prasanna Sattegeri, Daniela Szwarcman, Campbell Watson, David Rolnick",http://arxiv.org/pdf/2407.12517v1,cs.LG
Online Pseudo-Zeroth-Order Training of Neuromorphic Spiking Neural Networks,"Brain-inspired neuromorphic computing with spiking neural networks (SNNs) is
a promising energy-efficient computational approach. However, successfully
training SNNs in a more biologically plausible and
neuromorphic-hardware-friendly way is still challenging. Most recent methods
leverage spatial and temporal backpropagation (BP), not adhering to
neuromorphic properties. Despite the efforts of some online training methods,
tackling spatial credit assignments by alternatives with comparable performance
as spatial BP remains a significant problem. In this work, we propose a novel
method, online pseudo-zeroth-order (OPZO) training. Our method only requires a
single forward propagation with noise injection and direct top-down signals for
spatial credit assignment, avoiding spatial BP's problem of symmetric weights
and separate phases for layer-by-layer forward-backward propagation. OPZO
solves the large variance problem of zeroth-order methods by the
pseudo-zeroth-order formulation and momentum feedback connections, while having
more guarantees than random feedback. Combining online training, OPZO can pave
paths to on-chip SNN training. Experiments on neuromorphic and static datasets
with fully connected and convolutional networks demonstrate the effectiveness
of OPZO with similar performance compared with spatial BP, as well as estimated
low training costs.",2024-07-17,"Mingqing Xiao, Qingyan Meng, Zongpeng Zhang, Di He, Zhouchen Lin",http://arxiv.org/pdf/2407.12516v1,cs.LG
Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning,"Large-scale infrastructure systems are crucial for societal welfare, and
their effective management requires strategic forecasting and intervention
methods that account for various complexities. Our study addresses two
challenges within the Prognostics and Health Management (PHM) framework applied
to sewer assets: modeling pipe degradation across severity levels and
developing effective maintenance policies. We employ Multi-State Degradation
Models (MSDM) to represent the stochastic degradation process in sewer pipes
and use Deep Reinforcement Learning (DRL) to devise maintenance strategies. A
case study of a Dutch sewer network exemplifies our methodology. Our findings
demonstrate the model's effectiveness in generating intelligent, cost-saving
maintenance strategies that surpass heuristics. It adapts its management
strategy based on the pipe's age, opting for a passive approach for newer pipes
and transitioning to active strategies for older ones to prevent failures and
reduce costs. This research highlights DRL's potential in optimizing
maintenance policies. Future research will aim improve the model by
incorporating partial observability, exploring various reinforcement learning
algorithms, and extending this methodology to comprehensive infrastructure
management.",2024-07-17,"Lisandro A. Jimenez-Roa, Thiago D. Simão, Zaharah Bukhsh, Tiedo Tinga, Hajo Molegraaf, Nils Jansen, Marielle Stoelinga",http://arxiv.org/pdf/2407.12894v1,cs.LG
Classification and reconstruction for single-pixel imaging with classical and quantum neural networks,"Single-pixel cameras are effective solution for imaging outside the visible
spectrum where traditional CMOS/CCD cameras have challenges. Combined with
machine learning, they can analyze images quickly enough for practical
applications. Solving the problem of high-dimensional single-pixel
visualization can potentially be accelerated using quantum machine learning,
thereby expanding the range of practical problems. In this work we simulated a
single-pixel imaging experiment using Hadamard basis patterns, where images
from the MNIST handwritten digit dataset were used as objects. There were
selected 64 measurements with maximum variance (6% of the number of pixels in
the image). We created algorithms for classifying and reconstruction images
based on these measurements using classical fully connected neural networks and
parameterized quantum circuits. Classical and quantum classifiers showed
accuracies of 96% and 95% respectively after 6 training epochs, which is quite
competitive result. Image reconstruction was also demonstrated using classical
and quantum neural networks after 10 training epochs, the structural similarity
index measure values were 0.76 and 0.25, respectively, which indicates that the
problem in such a formulation turned out to be too difficult for quantum neural
networks in such a configuration for now.",2024-07-17,"Sofya Manko, Dmitry Frolovtsev",http://arxiv.org/pdf/2407.12506v2,cs.LG
Subequivariant Reinforcement Learning in 3D Multi-Entity Physical Environments,"Learning policies for multi-entity systems in 3D environments is far more
complicated against single-entity scenarios, due to the exponential expansion
of the global state space as the number of entities increases. One potential
solution of alleviating the exponential complexity is dividing the global space
into independent local views that are invariant to transformations including
translations and rotations. To this end, this paper proposes Subequivariant
Hierarchical Neural Networks (SHNN) to facilitate multi-entity policy learning.
In particular, SHNN first dynamically decouples the global space into local
entity-level graphs via task assignment. Second, it leverages subequivariant
message passing over the local entity-level graphs to devise local reference
frames, remarkably compressing the representation redundancy, particularly in
gravity-affected environments. Furthermore, to overcome the limitations of
existing benchmarks in capturing the subtleties of multi-entity systems under
the Euclidean symmetry, we propose the Multi-entity Benchmark (MEBEN), a new
suite of environments tailored for exploring a wide range of multi-entity
reinforcement learning. Extensive experiments demonstrate significant
advancements of SHNN on the proposed benchmarks compared to existing methods.
Comprehensive ablations are conducted to verify the indispensability of task
assignment and subequivariance.",2024-07-17,"Runfa Chen, Ling Wang, Yu Du, Tianrui Xue, Fuchun Sun, Jianwei Zhang, Wenbing Huang",http://arxiv.org/pdf/2407.12505v1,cs.LG
Temporal Test-Time Adaptation with State-Space Models,"Distribution shifts between training and test data are inevitable over the
lifecycle of a deployed model, leading to performance decay. Adapting a model
on test samples can help mitigate this drop in performance. However, most
test-time adaptation methods have focused on synthetic corruption shifts,
leaving a variety of distribution shifts underexplored. In this paper, we focus
on distribution shifts that evolve gradually over time, which are common in the
wild but challenging for existing methods, as we show. To address this, we
propose STAD, a probabilistic state-space model that adapts a deployed model to
temporal distribution shifts by learning the time-varying dynamics in the last
set of hidden features. Without requiring labels, our model infers
time-evolving class prototypes that act as a dynamic classification head.
Through experiments on real-world temporal distribution shifts, we show that
our method excels in handling small batch sizes and label shift.",2024-07-17,"Mona Schirmer, Dan Zhang, Eric Nalisnick",http://arxiv.org/pdf/2407.12492v2,cs.LG
Hybrid Dynamic Pruning: A Pathway to Efficient Transformer Inference,"In the world of deep learning, Transformer models have become very
significant, leading to improvements in many areas from understanding language
to recognizing images, covering a wide range of applications. Despite their
success, the deployment of these models in real-time applications, particularly
on edge devices, poses significant challenges due to their quadratic
computational intensity and memory demands. To overcome these challenges we
introduce a novel Hybrid Dynamic Pruning (HDP), an efficient
algorithm-architecture co-design approach that accelerates transformers using
head sparsity, block sparsity and approximation opportunities to reduce
computations in attention and reduce memory access. With the observation of the
huge redundancy in attention scores and attention heads, we propose a novel
integer-based row-balanced block pruning to prune unimportant blocks in the
attention matrix at run time, also propose integer-based head pruning to detect
and prune unimportant heads at an early stage at run time. Also we propose an
approximation method that reduces attention computations. To efficiently
support these methods with lower latency and power efficiency, we propose a HDP
co-processor architecture.",2024-07-17,"Ghadeer Jaradat, Mohammed Tolba, Ghada Alsuhli, Hani Saleh, Mahmoud Al-Qutayri, Thanos Stouraitis, Baker Mohammad",http://arxiv.org/pdf/2407.12893v1,cs.LG
Leveraging the Mahalanobis Distance to enhance Unsupervised Brain MRI Anomaly Detection,"Unsupervised Anomaly Detection (UAD) methods rely on healthy data
distributions to identify anomalies as outliers. In brain MRI, a common
approach is reconstruction-based UAD, where generative models reconstruct
healthy brain MRIs, and anomalies are detected as deviations between input and
reconstruction. However, this method is sensitive to imperfect reconstructions,
leading to false positives that impede the segmentation. To address this
limitation, we construct multiple reconstructions with probabilistic diffusion
models. We then analyze the resulting distribution of these reconstructions
using the Mahalanobis distance to identify anomalies as outliers. By leveraging
information about normal variations and covariance of individual pixels within
this distribution, we effectively refine anomaly scoring, leading to improved
segmentation. Our experimental results demonstrate substantial performance
improvements across various data sets. Specifically, compared to relying solely
on single reconstructions, our approach achieves relative improvements of
15.9%, 35.4%, 48.0%, and 4.7% in terms of AUPRC for the BRATS21, ATLAS, MSLUB
and WMH data sets, respectively.",2024-07-17,"Finn Behrendt, Debayan Bhattacharya, Robin Mieling, Lennart Maack, Julia Krüger, Roland Opfer, Alexander Schlaefer",http://arxiv.org/pdf/2407.12474v1,cs.LG
A Novel Dependency Framework for Enhancing Discourse Data Analysis,"The development of different theories of discourse structure has led to the
establishment of discourse corpora based on these theories. However, the
existence of discourse corpora established on different theoretical bases
creates challenges when it comes to exploring them in a consistent and cohesive
way. This study has as its primary focus the conversion of PDTB annotations
into dependency structures. It employs refined BERT-based discourse parsers to
test the validity of the dependency data derived from the PDTB-style corpora in
English, Chinese, and several other languages. By converting both PDTB and RST
annotations for the same texts into dependencies, this study also applies
``dependency distance'' metrics to examine the correlation between RST
dependencies and PDTB dependencies in English. The results show that the PDTB
dependency data is valid and that there is a strong correlation between the two
types of dependency distance. This study presents a comprehensive approach for
analyzing and evaluating discourse corpora by employing discourse dependencies
to achieve unified analysis. By applying dependency representations, we can
extract data from PDTB, RST, and SDRT corpora in a coherent and unified manner.
Moreover, the cross-linguistic validation establishes the framework's
generalizability beyond English. The establishment of this comprehensive
dependency framework overcomes limitations of existing discourse corpora,
supporting a diverse range of algorithms and facilitating further studies in
computational discourse analysis and language sciences.",2024-07-17,"Kun Sun, Rong Wang",http://arxiv.org/pdf/2407.12473v1,cs.LG
Driving pattern interpretation based on action phases clustering,"Current approaches to identifying driving heterogeneity face challenges in
comprehending fundamental patterns from the perspective of underlying driving
behavior mechanisms. The concept of Action phases was proposed in our previous
work, capturing the diversity of driving characteristics with physical
meanings. This study presents a novel framework to further interpret driving
patterns by classifying Action phases in an unsupervised manner. In this
framework, a Resampling and Downsampling Method (RDM) is first applied to
standardize the length of Action phases. Then the clustering calibration
procedure including ''Feature Selection'', ''Clustering Analysis'',
''Difference/Similarity Evaluation'', and ''Action phases Re-extraction'' is
iteratively applied until all differences among clusters and similarities
within clusters reach the pre-determined criteria. Application of the framework
using real-world datasets revealed six driving patterns in the I80 dataset,
labeled as ''Catch up'', ''Keep away'', and ''Maintain distance'', with both
''Stable'' and ''Unstable'' states. Notably, Unstable patterns are more
numerous than Stable ones. ''Maintain distance'' is the most common among
Stable patterns. These observations align with the dynamic nature of driving.
Two patterns ''Stable keep away'' and ''Unstable catch up'' are missing in the
US101 dataset, which is in line with our expectations as this dataset was
previously shown to have less heterogeneity. This demonstrates the potential of
driving patterns in describing driving heterogeneity. The proposed framework
promises advantages in addressing label scarcity in supervised learning and
enhancing tasks such as driving behavior modeling and driving trajectory
prediction.",2024-07-17,"Xue Yao, Simeon C. Calvert, Serge P. Hoogendoorn",http://arxiv.org/pdf/2407.17518v1,cs.LG
Estimating Reaction Barriers with Deep Reinforcement Learning,"Stable states in complex systems correspond to local minima on the associated
potential energy surface. Transitions between these local minima govern the
dynamics of such systems. Precisely determining the transition pathways in
complex and high-dimensional systems is challenging because these transitions
are rare events, and isolating the relevant species in experiments is
difficult. Most of the time, the system remains near a local minimum, with
rare, large fluctuations leading to transitions between minima. The probability
of such transitions decreases exponentially with the height of the energy
barrier, making the system's dynamics highly sensitive to the calculated energy
barriers. This work aims to formulate the problem of finding the minimum energy
barrier between two stable states in the system's state space as a
cost-minimization problem. We propose solving this problem using reinforcement
learning algorithms. The exploratory nature of reinforcement learning agents
enables efficient sampling and determination of the minimum energy barrier for
transitions.",2024-07-17,Adittya Pal,http://arxiv.org/pdf/2407.12453v2,cs.LG
Energy-Guided Diffusion Sampling for Offline-to-Online Reinforcement Learning,"Combining offline and online reinforcement learning (RL) techniques is indeed
crucial for achieving efficient and safe learning where data acquisition is
expensive. Existing methods replay offline data directly in the online phase,
resulting in a significant challenge of data distribution shift and
subsequently causing inefficiency in online fine-tuning. To address this issue,
we introduce an innovative approach, \textbf{E}nergy-guided \textbf{DI}ffusion
\textbf{S}ampling (EDIS), which utilizes a diffusion model to extract prior
knowledge from the offline dataset and employs energy functions to distill this
knowledge for enhanced data generation in the online phase. The theoretical
analysis demonstrates that EDIS exhibits reduced suboptimality compared to
solely utilizing online data or directly reusing offline data. EDIS is a
plug-in approach and can be combined with existing methods in offline-to-online
RL setting. By implementing EDIS to off-the-shelf methods Cal-QL and IQL, we
observe a notable 20% average improvement in empirical performance on MuJoCo,
AntMaze, and Adroit environments. Code is available at
\url{https://github.com/liuxhym/EDIS}.",2024-07-17,"Xu-Hui Liu, Tian-Shuo Liu, Shengyi Jiang, Ruifeng Chen, Zhilong Zhang, Xinwei Chen, Yang Yu",http://arxiv.org/pdf/2407.12448v2,cs.LG
A Comprehensive Sustainable Framework for Machine Learning and Artificial Intelligence,"In financial applications, regulations or best practices often lead to
specific requirements in machine learning relating to four key pillars:
fairness, privacy, interpretability and greenhouse gas emissions. These all sit
in the broader context of sustainability in AI, an emerging practical AI topic.
However, although these pillars have been individually addressed by past
literature, none of these works have considered all the pillars. There are
inherent trade-offs between each of the pillars (for example, accuracy vs
fairness or accuracy vs privacy), making it even more important to consider
them together. This paper outlines a new framework for Sustainable Machine
Learning and proposes FPIG, a general AI pipeline that allows for these
critical topics to be considered simultaneously to learn the trade-offs between
the pillars better. Based on the FPIG framework, we propose a meta-learning
algorithm to estimate the four key pillars given a dataset summary, model
architecture, and hyperparameters before model training. This algorithm allows
users to select the optimal model architecture for a given dataset and a given
set of user requirements on the pillars. We illustrate the trade-offs under the
FPIG model on three classical datasets and demonstrate the meta-learning
approach with an example of real-world datasets and models with different
interpretability, showcasing how it can aid model selection.",2024-07-17,"Roberto Pagliari, Peter Hill, Po-Yu Chen, Maciej Dabrowny, Tingsheng Tan, Francois Buet-Golfouse",http://arxiv.org/pdf/2407.12445v1,cs.LG
Preventing Catastrophic Overfitting in Fast Adversarial Training: A Bi-level Optimization Perspective,"Adversarial training (AT) has become an effective defense method against
adversarial examples (AEs) and it is typically framed as a bi-level
optimization problem. Among various AT methods, fast AT (FAT), which employs a
single-step attack strategy to guide the training process, can achieve good
robustness against adversarial attacks at a low cost. However, FAT methods
suffer from the catastrophic overfitting problem, especially on complex tasks
or with large-parameter models. In this work, we propose a FAT method termed
FGSM-PCO, which mitigates catastrophic overfitting by averting the collapse of
the inner optimization problem in the bi-level optimization process. FGSM-PCO
generates current-stage AEs from the historical AEs and incorporates them into
the training process using an adaptive mechanism. This mechanism determines an
appropriate fusion ratio according to the performance of the AEs on the
training model. Coupled with a loss function tailored to the training
framework, FGSM-PCO can alleviate catastrophic overfitting and help the
recovery of an overfitted model to effective training. We evaluate our
algorithm across three models and three datasets to validate its effectiveness.
Comparative empirical studies against other FAT algorithms demonstrate that our
proposed method effectively addresses unresolved overfitting issues in existing
algorithms.",2024-07-17,"Zhaoxin Wang, Handing Wang, Cong Tian, Yaochu Jin",http://arxiv.org/pdf/2407.12443v1,cs.LG
GraphGuard: Contrastive Self-Supervised Learning for Credit-Card Fraud Detection in Multi-Relational Dynamic Graphs,"Credit card fraud has significant implications at both an individual and
societal level, making effective prevention essential. Current methods rely
heavily on feature engineering and labeled information, both of which have
significant limitations. In this work, we present GraphGuard, a novel
contrastive self-supervised graph-based framework for detecting fraudulent
credit card transactions. We conduct experiments on a real-world dataset and a
synthetic dataset. Our results provide a promising initial direction for
exploring the effectiveness of graph-based self-supervised approaches for
credit card fraud detection.",2024-07-17,"Kristófer Reynisson, Marco Schreyer, Damian Borth",http://arxiv.org/pdf/2407.12440v1,cs.LG
Semantic-Aware Representation of Multi-Modal Data for Data Ingress: A Literature Review,"Machine Learning (ML) is continuously permeating a growing amount of
application domains. Generative AI such as Large Language Models (LLMs) also
sees broad adoption to process multi-modal data such as text, images, audio,
and video. While the trend is to use ever-larger datasets for training,
managing this data efficiently has become a significant practical challenge in
the industry-double as much data is certainly not double as good. Rather the
opposite is important since getting an understanding of the inherent quality
and diversity of the underlying data lakes is a growing challenge for
application-specific ML as well as for fine-tuning foundation models.
Furthermore, information retrieval (IR) from expanding data lakes is
complicated by the temporal dimension inherent in time-series data which must
be considered to determine its semantic value. This study focuses on the
different semantic-aware techniques to extract embeddings from mono-modal,
multi-modal, and cross-modal data to enhance IR capabilities in a growing data
lake. Articles were collected to summarize information about the
state-of-the-art techniques focusing on applications of embedding for three
different categories of data modalities.",2024-07-17,"Pierre Lamart, Yinan Yu, Christian Berger",http://arxiv.org/pdf/2407.12438v1,cs.LG
Variable-Agnostic Causal Exploration for Reinforcement Learning,"Modern reinforcement learning (RL) struggles to capture real-world
cause-and-effect dynamics, leading to inefficient exploration due to extensive
trial-and-error actions. While recent efforts to improve agent exploration have
leveraged causal discovery, they often make unrealistic assumptions of causal
variables in the environments. In this paper, we introduce a novel framework,
Variable-Agnostic Causal Exploration for Reinforcement Learning (VACERL),
incorporating causal relationships to drive exploration in RL without
specifying environmental causal variables. Our approach automatically
identifies crucial observation-action steps associated with key variables using
attention mechanisms. Subsequently, it constructs the causal graph connecting
these steps, which guides the agent towards observation-action pairs with
greater causal influence on task completion. This can be leveraged to generate
intrinsic rewards or establish a hierarchy of subgoals to enhance exploration
efficiency. Experimental results showcase a significant improvement in agent
performance in grid-world, 2d games and robotic domains, particularly in
scenarios with sparse rewards and noisy actions, such as the notorious Noisy-TV
environments.",2024-07-17,"Minh Hoang Nguyen, Hung Le, Svetha Venkatesh",http://arxiv.org/pdf/2407.12437v1,cs.LG
SafePowerGraph: Safety-aware Evaluation of Graph Neural Networks for Transmission Power Grids,"Power grids are critical infrastructures of paramount importance to modern
society and their rapid evolution and interconnections has heightened the
complexity of power systems (PS) operations. Traditional methods for grid
analysis struggle with the computational demands of large-scale RES and ES
integration, prompting the adoption of machine learning (ML) techniques,
particularly Graph Neural Networks (GNNs). GNNs have proven effective in
solving the alternating current (AC) Power Flow (PF) and Optimal Power Flow
(OPF) problems, crucial for operational planning. However, existing benchmarks
and datasets completely ignore safety and robustness requirements in their
evaluation and never consider realistic safety-critical scenarios that most
impact the operations of the power grids. We present SafePowerGraph, the first
simulator-agnostic, safety-oriented framework and benchmark for GNNs in PS
operations. SafePowerGraph integrates multiple PF and OPF simulators and
assesses GNN performance under diverse scenarios, including energy price
variations and power line outages. Our extensive experiments underscore the
importance of self-supervised learning and graph attention architectures for
GNN robustness. We provide at https://github.com/yamizi/SafePowerGraph our
open-source repository, a comprehensive leaderboard, a dataset and model zoo
and expect our framework to standardize and advance research in the critical
field of GNN for power systems.",2024-07-17,"Salah Ghamizi, Aleksandar Bojchevski, Aoxiang Ma, Jun Cao",http://arxiv.org/pdf/2407.12421v1,cs.LG
Dirac--Bianconi Graph Neural Networks -- Enabling Non-Diffusive Long-Range Graph Predictions,"The geometry of a graph is encoded in dynamical processes on the graph. Many
graph neural network (GNN) architectures are inspired by such dynamical
systems, typically based on the graph Laplacian. Here, we introduce
Dirac--Bianconi GNNs (DBGNNs), which are based on the topological Dirac
equation recently proposed by Bianconi. Based on the graph Laplacian, we
demonstrate that DBGNNs explore the geometry of the graph in a fundamentally
different way than conventional message passing neural networks (MPNNs). While
regular MPNNs propagate features diffusively, analogous to the heat equation,
DBGNNs allow for coherent long-range propagation. Experimental results showcase
the superior performance of DBGNNs over existing conventional MPNNs for
long-range predictions of power grid stability and peptide properties. This
study highlights the effectiveness of DBGNNs in capturing intricate graph
dynamics, providing notable advancements in GNN architectures.",2024-07-17,"Christian Nauck, Rohan Gorantla, Michael Lindner, Konstantin Schürholt, Antonia S. J. S. Mey, Frank Hellmann",http://arxiv.org/pdf/2407.12419v1,cs.LG
Improving the classification of extreme classes by means of loss regularisation and generalised beta distributions,"An ordinal classification problem is one in which the target variable takes
values on an ordinal scale. Nowadays, there are many of these problems
associated with real-world tasks where it is crucial to accurately classify the
extreme classes of the ordinal structure. In this work, we propose a unimodal
regularisation approach that can be applied to any loss function to improve the
classification performance of the first and last classes while maintaining good
performance for the remainder. The proposed methodology is tested on six
datasets with different numbers of classes, and compared with other unimodal
regularisation methods in the literature. In addition, performance in the
extreme classes is compared using a new metric that takes into account their
sensitivities. Experimental results and statistical analysis show that the
proposed methodology obtains a superior average performance considering
different metrics. The results for the proposed metric show that the
generalised beta distribution generally improves classification performance in
the extreme classes. At the same time, the other five nominal and ordinal
metrics considered show that the overall performance is aligned with the
performance of previous alternatives.",2024-07-17,"Víctor Manuel Vargas, Pedro Antonio Gutiérrez, Javier Barbero-Gómez, César Hervás-Martínez",http://arxiv.org/pdf/2407.12417v1,cs.LG
Not All Frequencies Are Created Equal:Towards a Dynamic Fusion of Frequencies in Time-Series Forecasting,"Long-term time series forecasting is a long-standing challenge in various
applications. A central issue in time series forecasting is that methods should
expressively capture long-term dependency. Furthermore, time series forecasting
methods should be flexible when applied to different scenarios. Although
Fourier analysis offers an alternative to effectively capture reusable and
periodic patterns to achieve long-term forecasting in different scenarios,
existing methods often assume high-frequency components represent noise and
should be discarded in time series forecasting. However, we conduct a series of
motivation experiments and discover that the role of certain frequencies varies
depending on the scenarios. In some scenarios, removing high-frequency
components from the original time series can improve the forecasting
performance, while in others scenarios, removing them is harmful to forecasting
performance. Therefore, it is necessary to treat the frequencies differently
according to specific scenarios. To achieve this, we first reformulate the time
series forecasting problem as learning a transfer function of each frequency in
the Fourier domain. Further, we design Frequency Dynamic Fusion (FreDF), which
individually predicts each Fourier component, and dynamically fuses the output
of different frequencies. Moreover, we provide a novel insight into the
generalization ability of time series forecasting and propose the
generalization bound of time series forecasting. Then we prove FreDF has a
lower bound, indicating that FreDF has better generalization ability.
  Extensive experiments conducted on multiple benchmark datasets and ablation
studies demonstrate the effectiveness of FreDF. The code is available at
https://github.com/Zh-XY22/FreDF.",2024-07-17,"Xingyu Zhang, Siyu Zhao, Zeen Song, Huijie Guo, Jianqi Zhang, Changwen Zheng, Wenwen Qiang",http://arxiv.org/pdf/2407.12415v3,cs.LG
Proximity-based Self-Federated Learning,"In recent advancements in machine learning, federated learning allows a
network of distributed clients to collaboratively develop a global model
without needing to share their local data. This technique aims to safeguard
privacy, countering the vulnerabilities of conventional centralized learning
methods. Traditional federated learning approaches often rely on a central
server to coordinate model training across clients, aiming to replicate the
same model uniformly across all nodes. However, these methods overlook the
significance of geographical and local data variances in vast networks,
potentially affecting model effectiveness and applicability. Moreover, relying
on a central server might become a bottleneck in large networks, such as the
ones promoted by edge computing. Our paper introduces a novel,
fully-distributed federated learning strategy called proximity-based
self-federated learning that enables the self-organised creation of multiple
federations of clients based on their geographic proximity and data
distribution without exchanging raw data. Indeed, unlike traditional
algorithms, our approach encourages clients to share and adjust their models
with neighbouring nodes based on geographic proximity and model accuracy. This
method not only addresses the limitations posed by diverse data distributions
but also enhances the model's adaptability to different regional
characteristics creating specialized models for each federation. We demonstrate
the efficacy of our approach through simulations on well-known datasets,
showcasing its effectiveness over the conventional centralized federated
learning framework.",2024-07-17,"Davide Domini, Gianluca Aguzzi, Nicolas Farabegoli, Mirko Viroli, Lukas Esterle",http://arxiv.org/pdf/2407.12410v1,cs.LG
Analyzing the Generalization and Reliability of Steering Vectors,"Steering vectors (SVs) have been proposed as an effective approach to adjust
language model behaviour at inference time by intervening on intermediate model
activations. They have shown promise in terms of improving both capabilities
and model alignment. However, the reliability and generalisation properties of
this approach are unknown. In this work, we rigorously investigate these
properties, and show that steering vectors have substantial limitations both
in- and out-of-distribution. In-distribution, steerability is highly variable
across different inputs. Depending on the concept, spurious biases can
substantially contribute to how effective steering is for each input,
presenting a challenge for the widespread use of steering vectors.
Out-of-distribution, while steering vectors often generalise well, for several
concepts they are brittle to reasonable changes in the prompt, resulting in
them failing to generalise well. Overall, our findings show that while steering
can work well in the right circumstances, there remain technical difficulties
of applying steering vectors to guide models' behaviour at scale. Our code is
available at https://github.com/dtch1997/steering-bench",2024-07-17,"Daniel Tan, David Chanin, Aengus Lynch, Dimitrios Kanoulas, Brooks Paige, Adria Garriga-Alonso, Robert Kirk",http://arxiv.org/pdf/2407.12404v8,cs.LG
Geometric Remove-and-Retrain (GOAR): Coordinate-Invariant eXplainable AI Assessment,"Identifying the relevant input features that have a critical influence on the
output results is indispensable for the development of explainable artificial
intelligence (XAI). Remove-and-Retrain (ROAR) is a widely accepted approach for
assessing the importance of individual pixels by measuring changes in accuracy
following their removal and subsequent retraining of the modified dataset.
However, we uncover notable limitations in pixel-perturbation strategies. When
viewed from a geometric perspective, we discover that these metrics fail to
discriminate between differences among feature attribution methods, thereby
compromising the reliability of the evaluation. To address this challenge, we
introduce an alternative feature-perturbation approach named Geometric
Remove-and-Retrain (GOAR). Through a series of experiments with both synthetic
and real datasets, we substantiate that GOAR transcends the limitations of
pixel-centric metrics.",2024-07-17,"Yong-Hyun Park, Junghoon Seo, Bomseok Park, Seongsu Lee, Junghyo Jo",http://arxiv.org/pdf/2407.12401v1,cs.LG
A Practical Solver for Scalar Data Topological Simplification,"This paper presents a practical approach for the optimization of topological
simplification, a central pre-processing step for the analysis and
visualization of scalar data. Given an input scalar field f and a set of
""signal"" persistence pairs to maintain, our approach produces an output field g
that is close to f and which optimizes (i) the cancellation of ""non-signal""
pairs, while (ii) preserving the ""signal"" pairs. In contrast to pre-existing
simplification algorithms, our approach is not restricted to persistence pairs
involving extrema and can thus address a larger class of topological features,
in particular saddle pairs in three-dimensional scalar data. Our approach
leverages recent generic persistence optimization frameworks and extends them
with tailored accelerations specific to the problem of topological
simplification. Extensive experiments report substantial accelerations over
these frameworks, thereby making topological simplification optimization
practical for real-life datasets. Our approach enables a direct visualization
and analysis of the topologically simplified data, e.g., via isosurfaces of
simplified topology (fewer components and handles). We apply our approach to
the extraction of prominent filament structures in three-dimensional data.
Specifically, we show that our pre-simplification of the data leads to
practical improvements over standard topological techniques for removing
filament loops. We also show how our approach can be used to repair genus
defects in surface processing. Finally, we provide a C++ implementation for
reproducibility purposes.",2024-07-17,"Mohamed Kissi, Mathieu Pont, Joshua A. Levine, Julien Tierny",http://arxiv.org/pdf/2407.12399v3,cs.LG
Mamba-PTQ: Outlier Channels in Recurrent Large Language Models,"Modern recurrent layers are emerging as a promising path toward edge
deployment of foundation models, especially in the context of large language
models (LLMs). Compressing the whole input sequence in a finite-dimensional
representation enables recurrent layers to model long-range dependencies while
maintaining a constant inference cost for each token and a fixed memory
requirement. However, the practical deployment of LLMs in resource-limited
environments often requires further model compression, such as quantization and
pruning. While these techniques are well-established for attention-based
models, their effects on recurrent layers remain underexplored.
  In this preliminary work, we focus on post-training quantization for
recurrent LLMs and show that Mamba models exhibit the same pattern of outlier
channels observed in attention-based LLMs. We show that the reason for the
difficulty of quantizing SSMs is caused by activation outliers, similar to
those observed in transformer-based LLMs. We report baseline results for
post-training quantization of Mamba that do not take into account the
activation outliers and suggest first steps for outlier-aware quantization.",2024-07-17,"Alessandro Pierro, Steven Abreu",http://arxiv.org/pdf/2407.12397v1,cs.LG
Private and Federated Stochastic Convex Optimization: Efficient Strategies for Centralized Systems,"This paper addresses the challenge of preserving privacy in Federated
Learning (FL) within centralized systems, focusing on both trusted and
untrusted server scenarios. We analyze this setting within the Stochastic
Convex Optimization (SCO) framework, and devise methods that ensure
Differential Privacy (DP) while maintaining optimal convergence rates for
homogeneous and heterogeneous data distributions. Our approach, based on a
recent stochastic optimization technique, offers linear computational
complexity, comparable to non-private FL methods, and reduced gradient
obfuscation. This work enhances the practicality of DP in FL, balancing
privacy, efficiency, and robustness in a variety of server trust environment.",2024-07-17,"Roie Reshef, Kfir Y. Levy",http://arxiv.org/pdf/2407.12396v1,cs.LG
Deep Learning-based Sentiment Analysis of Olympics Tweets,"Sentiment analysis (SA), is an approach of natural language processing (NLP)
for determining a text's emotional tone by analyzing subjective information
such as views, feelings, and attitudes toward specific topics, products,
services, events, or experiences. This study attempts to develop an advanced
deep learning (DL) model for SA to understand global audience emotions through
tweets in the context of the Olympic Games. The findings represent global
attitudes around the Olympics and contribute to advancing the SA models. We
have used NLP for tweet pre-processing and sophisticated DL models for arguing
with SA, this research enhances the reliability and accuracy of sentiment
classification. The study focuses on data selection, preprocessing,
visualization, feature extraction, and model building, featuring a baseline
Na\""ive Bayes (NB) model and three advanced DL models: Convolutional Neural
Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional
Encoder Representations from Transformers (BERT). The results of the
experiments show that the BERT model can efficiently classify sentiments
related to the Olympics, achieving the highest accuracy of 99.23%.",2024-07-17,"Indranil Bandyopadhyay, Rahul Karmakar",http://arxiv.org/pdf/2407.12376v1,cs.LG
FETCH: A Memory-Efficient Replay Approach for Continual Learning in Image Classification,"Class-incremental continual learning is an important area of research, as
static deep learning methods fail to adapt to changing tasks and data
distributions. In previous works, promising results were achieved using replay
and compressed replay techniques. In the field of regular replay, GDumb
achieved outstanding results but requires a large amount of memory. This
problem can be addressed by compressed replay techniques. The goal of this work
is to evaluate compressed replay in the pipeline of GDumb. We propose FETCH, a
two-stage compression approach. First, the samples from the continual
datastream are encoded by the early layers of a pre-trained neural network.
Second, the samples are compressed before being stored in the episodic memory.
Following GDumb, the remaining classification head is trained from scratch
using only the decompressed samples from the reply memory. We evaluate FETCH in
different scenarios and show that this approach can increase accuracy on
CIFAR10 and CIFAR100. In our experiments, simple compression methods (e.g.,
quantization of tensors) outperform deep autoencoders. In the future, FETCH
could serve as a baseline for benchmarking compressed replay learning in
constrained memory scenarios.",2024-07-17,"Markus Weißflog, Peter Protzel, Peer Neubert",http://arxiv.org/pdf/2407.12375v1,cs.LG
Temporal receptive field in dynamic graph learning: A comprehensive analysis,"Dynamic link prediction is a critical task in the analysis of evolving
networks, with applications ranging from recommender systems to economic
exchanges. However, the concept of the temporal receptive field, which refers
to the temporal context that models use for making predictions, has been
largely overlooked and insufficiently analyzed in existing research. In this
study, we present a comprehensive analysis of the temporal receptive field in
dynamic graph learning. By examining multiple datasets and models, we formalize
the role of temporal receptive field and highlight their crucial influence on
predictive accuracy. Our results demonstrate that appropriately chosen temporal
receptive field can significantly enhance model performance, while for some
models, overly large windows may introduce noise and reduce accuracy. We
conduct extensive benchmarking to validate our findings, ensuring that all
experiments are fully reproducible. Code is available at
https://github.com/ykrmm/BenchmarkTW .",2024-07-17,"Yannis Karmim, Leshanshui Yang, Raphaël Fournier S'Niehotta, Clément Chatelain, Sébastien Adam, Nicolas Thome",http://arxiv.org/pdf/2407.12370v2,cs.LG
Watermarking Recommender Systems,"Recommender systems embody significant commercial value and represent crucial
intellectual property. However, the integrity of these systems is constantly
challenged by malicious actors seeking to steal their underlying models.
Safeguarding against such threats is paramount to upholding the rights and
interests of the model owner. While model watermarking has emerged as a potent
defense mechanism in various domains, its direct application to recommender
systems remains unexplored and non-trivial. In this paper, we address this gap
by introducing Autoregressive Out-of-distribution Watermarking (AOW), a novel
technique tailored specifically for recommender systems. Our approach entails
selecting an initial item and querying it through the oracle model, followed by
the selection of subsequent items with small prediction scores. This iterative
process generates a watermark sequence autoregressively, which is then
ingrained into the model's memory through training. To assess the efficacy of
the watermark, the model is tasked with predicting the subsequent item given a
truncated watermark sequence. Through extensive experimentation and analysis,
we demonstrate the superior performance and robust properties of AOW. Notably,
our watermarking technique exhibits high-confidence extraction capabilities and
maintains effectiveness even in the face of distillation and fine-tuning
processes.",2024-07-17,"Sixiao Zhang, Cheng Long, Wei Yuan, Hongxu Chen, Hongzhi Yin",http://arxiv.org/pdf/2407.21034v3,cs.LG
Object-Aware Query Perturbation for Cross-Modal Image-Text Retrieval,"The pre-trained vision and language (V\&L) models have substantially improved
the performance of cross-modal image-text retrieval. In general, however, V\&L
models have limited retrieval performance for small objects because of the
rough alignment between words and the small objects in the image. In contrast,
it is known that human cognition is object-centric, and we pay more attention
to important objects, even if they are small. To bridge this gap between the
human cognition and the V\&L model's capability, we propose a cross-modal
image-text retrieval framework based on ``object-aware query perturbation.''
The proposed method generates a key feature subspace of the detected objects
and perturbs the corresponding queries using this subspace to improve the
object awareness in the image. In our proposed method, object-aware cross-modal
image-text retrieval is possible while keeping the rich expressive power and
retrieval performance of existing V\&L models without additional fine-tuning.
Comprehensive experiments on four public datasets show that our method
outperforms conventional algorithms. Our code is publicly available at
\url{https://github.com/NEC-N-SOGI/query-perturbation}.",2024-07-17,"Naoya Sogi, Takashi Shibata, Makoto Terao",http://arxiv.org/pdf/2407.12346v2,cs.LG
Continual Learning for Adaptable Car-Following in Dynamic Traffic Environments,"The continual evolution of autonomous driving technology requires
car-following models that can adapt to diverse and dynamic traffic
environments. Traditional learning-based models often suffer from performance
degradation when encountering unseen traffic patterns due to a lack of
continual learning capabilities. This paper proposes a novel car-following
model based on continual learning that addresses this limitation. Our framework
incorporates Elastic Weight Consolidation (EWC) and Memory Aware Synapses (MAS)
techniques to mitigate catastrophic forgetting and enable the model to learn
incrementally from new traffic data streams. We evaluate the performance of the
proposed model on the Waymo and Lyft datasets which encompass various traffic
scenarios. The results demonstrate that the continual learning techniques
significantly outperform the baseline model, achieving 0\% collision rates
across all traffic conditions. This research contributes to the advancement of
autonomous driving technology by fostering the development of more robust and
adaptable car-following models.",2024-07-17,"Xianda Chen, PakHin Tiu, Xu Han, Junjie Chen, Yuanfei Wu, Xinhu Zheng, Meixin Zhu",http://arxiv.org/pdf/2407.14247v1,cs.LG
Learning Structurally Stabilized Representations for Multi-modal Lossless DNA Storage,"In this paper, we present Reed-Solomon coded single-stranded representation
learning (RSRL), a novel end-to-end model for learning representations for
multi-modal lossless DNA storage. In contrast to existing learning-based
methods, the proposed RSRL is inspired by both error-correction codec and
structural biology. Specifically, RSRL first learns the representations for the
subsequent storage from the binary data transformed by the Reed-Solomon codec.
Then, the representations are masked by an RS-code-informed mask to focus on
correcting the burst errors occurring in the learning process. With the decoded
representations with error corrections, a novel biologically stabilized loss is
formulated to regularize the data representations to possess stable
single-stranded structures. By incorporating these novel strategies, the
proposed RSRL can learn highly durable, dense, and lossless representations for
the subsequent storage tasks into DNA sequences. The proposed RSRL has been
compared with a number of strong baselines in real-world tasks of multi-modal
data storage. The experimental results obtained demonstrate that RSRL can store
diverse types of data with much higher information density and durability but
much lower error rates.",2024-07-17,"Ben Cao, Tiantian He, Xue Li, Bin Wang, Xiaohu Wu, Qiang Zhang, Yew-Soon Ong",http://arxiv.org/pdf/2408.00779v1,cs.LG
Virtual Gram staining of label-free bacteria using darkfield microscopy and deep learning,"Gram staining has been one of the most frequently used staining protocols in
microbiology for over a century, utilized across various fields, including
diagnostics, food safety, and environmental monitoring. Its manual procedures
make it vulnerable to staining errors and artifacts due to, e.g., operator
inexperience and chemical variations. Here, we introduce virtual Gram staining
of label-free bacteria using a trained deep neural network that digitally
transforms darkfield images of unstained bacteria into their Gram-stained
equivalents matching brightfield image contrast. After a one-time training
effort, the virtual Gram staining model processes an axial stack of darkfield
microscopy images of label-free bacteria (never seen before) to rapidly
generate Gram staining, bypassing several chemical steps involved in the
conventional staining process. We demonstrated the success of the virtual Gram
staining workflow on label-free bacteria samples containing Escherichia coli
and Listeria innocua by quantifying the staining accuracy of the virtual Gram
staining model and comparing the chromatic and morphological features of the
virtually stained bacteria against their chemically stained counterparts. This
virtual bacteria staining framework effectively bypasses the traditional Gram
staining protocol and its challenges, including stain standardization, operator
errors, and sensitivity to chemical variations.",2024-07-17,"Cagatay Isil, Hatice Ceylan Koydemir, Merve Eryilmaz, Kevin de Haan, Nir Pillar, Koray Mentesoglu, Aras Firat Unal, Yair Rivenson, Sukantha Chandrasekaran, Omai B. Garner, Aydogan Ozcan",http://arxiv.org/pdf/2407.12337v1,cs.LG
Why Do You Grok? A Theoretical Analysis of Grokking Modular Addition,"We present a theoretical explanation of the ``grokking'' phenomenon, where a
model generalizes long after overfitting,for the originally-studied problem of
modular addition. First, we show that early in gradient descent, when the
``kernel regime'' approximately holds, no permutation-equivariant model can
achieve small population error on modular addition unless it sees at least a
constant fraction of all possible data points. Eventually, however, models
escape the kernel regime. We show that two-layer quadratic networks that
achieve zero training loss with bounded $\ell_{\infty}$ norm generalize well
with substantially fewer training points, and further show such networks exist
and can be found by gradient descent with small $\ell_{\infty}$ regularization.
We further provide empirical evidence that these networks as well as simple
Transformers, leave the kernel regime only after initially overfitting. Taken
together, our results strongly support the case for grokking as a consequence
of the transition from kernel-like behavior to limiting behavior of gradient
descent on deep networks.",2024-07-17,"Mohamad Amin Mohamadi, Zhiyuan Li, Lei Wu, Danica J. Sutherland",http://arxiv.org/pdf/2407.12332v1,cs.LG
Uncertainty Calibration with Energy Based Instance-wise Scaling in the Wild Dataset,"With the rapid advancement in the performance of deep neural networks (DNNs),
there has been significant interest in deploying and incorporating artificial
intelligence (AI) systems into real-world scenarios. However, many DNNs lack
the ability to represent uncertainty, often exhibiting excessive confidence
even when making incorrect predictions. To ensure the reliability of AI
systems, particularly in safety-critical cases, DNNs should transparently
reflect the uncertainty in their predictions. In this paper, we investigate
robust post-hoc uncertainty calibration methods for DNNs within the context of
multi-class classification tasks. While previous studies have made notable
progress, they still face challenges in achieving robust calibration,
particularly in scenarios involving out-of-distribution (OOD). We identify that
previous methods lack adaptability to individual input data and struggle to
accurately estimate uncertainty when processing inputs drawn from the wild
dataset. To address this issue, we introduce a novel instance-wise calibration
method based on an energy model. Our method incorporates energy scores instead
of softmax confidence scores, allowing for adaptive consideration of DNN
uncertainty for each prediction within a logit space. In experiments, we show
that the proposed method consistently maintains robust performance across the
spectrum, spanning from in-distribution to OOD scenarios, when compared to
other state-of-the-art methods.",2024-07-17,"Mijoo Kim, Junseok Kwon",http://arxiv.org/pdf/2407.12330v1,cs.LG
Spectra: Surprising Effectiveness of Pretraining Ternary Language Models at Scale,"Rapid advancements in GPU computational power has outpaced memory capacity
and bandwidth growth, creating bottlenecks in Large Language Model (LLM)
inference. Post-training quantization is the leading method for addressing
memory-related bottlenecks in LLM inference, but it suffers from significant
performance degradation below 4-bit precision. This paper addresses these
challenges by investigating the pretraining of low-bitwidth models specifically
Ternary Language Models (TriLMs) as an alternative to traditional
floating-point models (FloatLMs) and their post-training quantized versions
(QuantLMs). We present Spectra LLM suite, the first open suite of LLMs spanning
multiple bit-widths, including FloatLMs, QuantLMs, and TriLMs, ranging from 99M
to 3.9B parameters trained on 300B tokens. Our comprehensive evaluation
demonstrates that TriLMs offer superior scaling behavior in terms of model size
(in bits). Surprisingly, at scales exceeding one billion parameters, TriLMs
consistently outperform their QuantLM and FloatLM counterparts for a given bit
size across various benchmarks. Notably, the 3.9B parameter TriLM matches the
performance of the FloatLM 3.9B across all benchmarks, despite having fewer
bits than FloatLM 830M. Overall, this research provides valuable insights into
the feasibility and scalability of low-bitwidth language models, paving the way
for the development of more efficient LLMs.
  To enhance understanding of low-bitwidth models, we are releasing 500+
intermediate checkpoints of the Spectra suite at
https://github.com/NolanoOrg/SpectraSuite.",2024-07-17,"Ayush Kaushal, Tejas Vaidhya, Arnab Kumar Mondal, Tejas Pandey, Aaryan Bhagat, Irina Rish",http://arxiv.org/pdf/2407.12327v5,cs.LG
Multi evolutional deep neural networks (Multi-EDNN),"Evolutional deep neural networks (EDNN) solve partial differential equations
(PDEs) by marching the network representation of the solution fields, using the
governing equations. Use of a single network to solve coupled PDEs on large
domains requires a large number of network parameters and incurs a significant
computational cost. We introduce coupled EDNN (C-EDNN) to solve systems of PDEs
by using independent networks for each state variable, which are only coupled
through the governing equations. We also introduce distributed EDNN (D-EDNN) by
spatially partitioning the global domain into several elements and assigning
individual EDNNs to each element to solve the local evolution of the PDE. The
networks then exchange the solution and fluxes at their interfaces, similar to
flux-reconstruction methods, and ensure that the PDE dynamics are accurately
preserved between neighboring elements. Together C-EDNN and D-EDNN form the
general class of Multi-EDNN methods. We demonstrate these methods with aid of
canonical problems including linear advection, the heat equation, and the
compressible Navier-Stokes equations in Couette and Taylor-Green flows.",2024-07-17,"Hadden Kim, Tamer A. Zaki",http://arxiv.org/pdf/2407.12293v1,cs.LG
Information-Theoretic Foundations for Machine Learning,"The progress of machine learning over the past decade is undeniable. In
retrospect, it is both remarkable and unsettling that this progress was
achievable with little to no rigorous theory to guide experimentation. Despite
this fact, practitioners have been able to guide their future experimentation
via observations from previous large-scale empirical investigations. In this
work, we propose a theoretical framework which attempts to provide rigor to
existing practices in machine learning. To the theorist, we provide a framework
which is mathematically rigorous and leaves open many interesting ideas for
future exploration. To the practitioner, we provide a framework whose results
are simple, and provide intuition to guide future investigations across a wide
range of learning paradigms. Concretely, we provide a theoretical framework
rooted in Bayesian statistics and Shannon's information theory which is general
enough to unify the analysis of many phenomena in machine learning. Our
framework characterizes the performance of an optimal Bayesian learner as it
learns from a stream of experience. Unlike existing analyses that weaken with
increasing data complexity, our theoretical tools provide accurate insights
across diverse machine learning settings. Throughout this work, we derive
theoretical results and demonstrate their generality by apply them to derive
insights specific to settings. These settings range from learning from data
which is independently and identically distributed under an unknown
distribution, to data which is sequential, to data which exhibits hierarchical
structure amenable to meta-learning, and finally to data which is not fully
explainable under the learner's beliefs (misspecification). These results are
particularly relevant as we strive to understand and overcome increasingly
difficult machine learning challenges in this endlessly complex world.",2024-07-17,"Hong Jun Jeon, Benjamin Van Roy",http://arxiv.org/pdf/2407.12288v4,cs.LG
CDFL: Efficient Federated Human Activity Recognition using Contrastive Learning and Deep Clustering,"In the realm of ubiquitous computing, Human Activity Recognition (HAR) is
vital for the automation and intelligent identification of human actions
through data from diverse sensors. However, traditional machine learning
approaches by aggregating data on a central server and centralized processing
are memory-intensive and raise privacy concerns. Federated Learning (FL) has
emerged as a solution by training a global model collaboratively across
multiple devices by exchanging their local model parameters instead of local
data. However, in realistic settings, sensor data on devices is
non-independently and identically distributed (Non-IID). This means that data
activity recorded by most devices is sparse, and sensor data distribution for
each client may be inconsistent. As a result, typical FL frameworks in
heterogeneous environments suffer from slow convergence and poor performance
due to deviation of the global model's objective from the global objective.
Most FL methods applied to HAR are either designed for overly ideal scenarios
without considering the Non-IID problem or present privacy and scalability
concerns. This work addresses these challenges, proposing CDFL, an efficient
federated learning framework for image-based HAR. CDFL efficiently selects a
representative set of privacy-preserved images using contrastive learning and
deep clustering, reduces communication overhead by selecting effective clients
for global model updates, and improves global model quality by training on
privacy-preserved data. Our comprehensive experiments carried out on three
public datasets, namely Stanford40, PPMI, and VOC2012, demonstrate the
superiority of CDFL in terms of performance, convergence rate, and bandwidth
usage compared to state-of-the-art approaches.",2024-07-17,"Ensieh Khazaei, Alireza Esmaeilzehi, Bilal Taha, Dimitrios Hatzinakos",http://arxiv.org/pdf/2407.12287v1,cs.LG
Chip Placement with Diffusion Models,"Macro placement is a vital step in digital circuit design that defines the
physical location of large collections of components, known as macros, on a 2D
chip. Because key performance metrics of the chip are determined by the
placement, optimizing it is crucial. Existing learning-based methods typically
fall short because of their reliance on reinforcement learning (RL), which is
slow and struggles to generalize, requiring online training on each new
circuit. Instead, we train a diffusion model capable of placing new circuits
zero-shot, using guided sampling in lieu of RL to optimize placement quality.
To enable such models to train at scale, we designed a capable yet efficient
architecture for the denoising model, and propose a novel algorithm to generate
large synthetic datasets for pre-training. To allow zero-shot transfer to real
circuits, we empirically study the design decisions of our dataset generation
algorithm, and identify several key factors enabling generalization. When
trained on our synthetic data, our models generate high-quality placements on
unseen, realistic circuits, achieving competitive performance on placement
benchmarks compared to state-of-the-art methods.",2024-07-17,"Vint Lee, Minh Nguyen, Leena Elzeiny, Chun Deng, Pieter Abbeel, John Wawrzynek",http://arxiv.org/pdf/2407.12282v2,cs.LG
ER-FSL: Experience Replay with Feature Subspace Learning for Online Continual Learning,"Online continual learning (OCL) involves deep neural networks retaining
knowledge from old data while adapting to new data, which is accessible only
once. A critical challenge in OCL is catastrophic forgetting, reflected in
reduced model performance on old data. Existing replay-based methods mitigate
forgetting by replaying buffered samples from old data and learning current
samples of new data. In this work, we dissect existing methods and empirically
discover that learning and replaying in the same feature space is not conducive
to addressing the forgetting issue. Since the learned features associated with
old data are readily changed by the features related to new data due to data
imbalance, leading to the forgetting problem. Based on this observation, we
intuitively explore learning and replaying in different feature spaces.
Learning in a feature subspace is sufficient to capture novel knowledge from
new data while replaying in a larger feature space provides more feature space
to maintain historical knowledge from old data. To this end, we propose a novel
OCL approach called experience replay with feature subspace learning (ER-FSL).
Firstly, ER-FSL divides the entire feature space into multiple subspaces, with
each subspace used to learn current samples. Moreover, it introduces a subspace
reuse mechanism to address situations where no blank subspaces exist. Secondly,
ER-FSL replays previous samples using an accumulated space comprising all
learned subspaces. Extensive experiments on three datasets demonstrate the
superiority of ER-FSL over various state-of-the-art methods.",2024-07-17,Huiwei Lin,http://arxiv.org/pdf/2407.12279v1,cs.LG
When can transformers compositionally generalize in-context?,"Many tasks can be composed from a few independent components. This gives rise
to a combinatorial explosion of possible tasks, only some of which might be
encountered during training. Under what circumstances can transformers
compositionally generalize from a subset of tasks to all possible combinations
of tasks that share similar components? Here we study a modular multitask
setting that allows us to precisely control compositional structure in the data
generation process. We present evidence that transformers learning in-context
struggle to generalize compositionally on this task despite being in principle
expressive enough to do so. Compositional generalization becomes possible only
when introducing a bottleneck that enforces an explicit separation between task
inference and task execution.",2024-07-17,"Seijin Kobayashi, Simon Schug, Yassir Akram, Florian Redhardt, Johannes von Oswald, Razvan Pascanu, Guillaume Lajoie, João Sacramento",http://arxiv.org/pdf/2407.12275v1,cs.LG
UTG: Towards a Unified View of Snapshot and Event Based Models for Temporal Graphs,"Many real world graphs are inherently dynamic, constantly evolving with node
and edge additions. These graphs can be represented by temporal graphs, either
through a stream of edge events or a sequence of graph snapshots. Until now,
the development of machine learning methods for both types has occurred largely
in isolation, resulting in limited experimental comparison and theoretical
crosspollination between the two. In this paper, we introduce Unified Temporal
Graph (UTG), a framework that unifies snapshot-based and event-based machine
learning models under a single umbrella, enabling models developed for one
representation to be applied effectively to datasets of the other. We also
propose a novel UTG training procedure to boost the performance of
snapshot-based models in the streaming setting. We comprehensively evaluate
both snapshot and event-based models across both types of temporal graphs on
the temporal link prediction task. Our main findings are threefold: first, when
combined with UTG training, snapshot-based models can perform competitively
with event-based models such as TGN and GraphMixer even on event datasets.
Second, snapshot-based models are at least an order of magnitude faster than
most event-based models during inference. Third, while event-based methods such
as NAT and DyGFormer outperforms snapshot-based methods on both types of
temporal graphs, this is because they leverage joint neighborhood structural
features thus emphasizing the potential to incorporate these features into
snapshotbased models as well. These findings highlight the importance of
comparing model architectures independent of the data format and suggest the
potential of combining the efficiency of snapshot-based models with the
performance of event-based models in the future.",2024-07-17,"Shenyang Huang, Farimah Poursafaei, Reihaneh Rabbany, Guillaume Rabusseau, Emanuele Rossi",http://arxiv.org/pdf/2407.12269v2,cs.LG
Voltage-Controlled Magnetoelectric Devices for Neuromorphic Diffusion Process,"Stochastic diffusion processes are pervasive in nature, from the seemingly
erratic Brownian motion to the complex interactions of synaptically-coupled
spiking neurons. Recently, drawing inspiration from Langevin dynamics,
neuromorphic diffusion models were proposed and have become one of the major
breakthroughs in the field of generative artificial intelligence. Unlike
discriminative models that have been well developed to tackle classification or
regression tasks, diffusion models as well as other generative models such as
ChatGPT aim at creating content based upon contexts learned. However, the more
complex algorithms of these models result in high computational costs using
today's technologies, creating a bottleneck in their efficiency, and impeding
further development. Here, we develop a spintronic voltage-controlled
magnetoelectric memory hardware for the neuromorphic diffusion process. The
in-memory computing capability of our spintronic devices goes beyond current
Von Neumann architecture, where memory and computing units are separated.
Together with the non-volatility of magnetic memory, we can achieve high-speed
and low-cost computing, which is desirable for the increasing scale of
generative models in the current era. We experimentally demonstrate that the
hardware-based true random diffusion process can be implemented for image
generation and achieve comparable image quality to software-based training as
measured by the Frechet inception distance (FID) score, achieving ~10^3 better
energy-per-bit-per-area over traditional hardware.",2024-07-17,"Yang Cheng, Qingyuan Shu, Albert Lee, Haoran He, Ivy Zhu, Minzhang Chen, Renhe Chen, Zirui Wang, Hantao Zhang, Chih-Yao Wang, Shan-Yi Yang, Yu-Chen Hsin, Cheng-Yi Shih, Hsin-Han Lee, Ran Cheng, Kang L. Wang",http://arxiv.org/pdf/2407.12261v2,cs.LG
COKE: Causal Discovery with Chronological Order and Expert Knowledge in High Proportion of Missing Manufacturing Data,"Understanding causal relationships between machines is crucial for fault
diagnosis and optimization in manufacturing processes. Real-world datasets
frequently exhibit up to 90% missing data and high dimensionality from hundreds
of sensors. These datasets also include domain-specific expert knowledge and
chronological order information, reflecting the recording order across
different machines, which is pivotal for discerning causal relationships within
the manufacturing data. However, previous methods for handling missing data in
scenarios akin to real-world conditions have not been able to effectively
utilize expert knowledge. Conversely, prior methods that can incorporate expert
knowledge struggle with datasets that exhibit missing values. Therefore, we
propose COKE to construct causal graphs in manufacturing datasets by leveraging
expert knowledge and chronological order among sensors without imputing missing
data. Utilizing the characteristics of the recipe, we maximize the use of
samples with missing values, derive embeddings from intersections with an
initial graph that incorporates expert knowledge and chronological order, and
create a sensor ordering graph. The graph-generating process has been optimized
by an actor-critic architecture to obtain a final graph that has a maximum
reward. Experimental evaluations in diverse settings of sensor quantities and
missing proportions demonstrate that our approach compared with the benchmark
methods shows an average improvement of 39.9% in the F1-score. Moreover, the
F1-score improvement can reach 62.6% when considering the configuration similar
to real-world datasets, and 85.0% in real-world semiconductor datasets. The
source code is available at https://github.com/OuTingYun/COKE.",2024-07-17,"Ting-Yun Ou, Ching Chang, Wen-Chih Peng",http://arxiv.org/pdf/2407.12254v2,cs.LG
Explaining Deep Neural Networks by Leveraging Intrinsic Methods,"Despite their impact on the society, deep neural networks are often regarded
as black-box models due to their intricate structures and the absence of
explanations for their decisions. This opacity poses a significant challenge to
AI systems wider adoption and trustworthiness. This thesis addresses this issue
by contributing to the field of eXplainable AI, focusing on enhancing the
interpretability of deep neural networks. The core contributions lie in
introducing novel techniques aimed at making these networks more interpretable
by leveraging an analysis of their inner workings. Specifically, the
contributions are threefold. Firstly, the thesis introduces designs for
self-explanatory deep neural networks, such as the integration of external
memory for interpretability purposes and the usage of prototype and
constraint-based layers across several domains. Secondly, this research delves
into novel investigations on neurons within trained deep neural networks,
shedding light on overlooked phenomena related to their activation values.
Lastly, the thesis conducts an analysis of the application of explanatory
techniques in the field of visual analytics, exploring the maturity of their
adoption and the potential of these systems to convey explanations to users
effectively.",2024-07-17,Biagio La Rosa,http://arxiv.org/pdf/2407.12243v1,cs.LG
Adaptive Cascading Network for Continual Test-Time Adaptation,"We study the problem of continual test-time adaption where the goal is to
adapt a source pre-trained model to a sequence of unlabelled target domains at
test time. Existing methods on test-time training suffer from several
limitations: (1) Mismatch between the feature extractor and classifier; (2)
Interference between the main and self-supervised tasks; (3) Lack of the
ability to quickly adapt to the current distribution. In light of these
challenges, we propose a cascading paradigm that simultaneously updates the
feature extractor and classifier at test time, mitigating the mismatch between
them and enabling long-term model adaptation. The pre-training of our model is
structured within a meta-learning framework, thereby minimizing the
interference between the main and self-supervised tasks and encouraging fast
adaptation in the presence of limited unlabelled data. Additionally, we
introduce innovative evaluation metrics, average accuracy and forward transfer,
to effectively measure the model's adaptation capabilities in dynamic,
real-world scenarios. Extensive experiments and ablation studies demonstrate
the superiority of our approach in a range of tasks including image
classification, text classification, and speech recognition.",2024-07-17,"Kien X. Nguyen, Fengchun Qiao, Xi Peng",http://arxiv.org/pdf/2407.12240v2,cs.LG
Urban Traffic Forecasting with Integrated Travel Time and Data Availability in a Conformal Graph Neural Network Framework,"Traffic flow prediction is a big challenge for transportation authorities as
it helps plan and develop better infrastructure. State-of-the-art models often
struggle to consider the data in the best way possible, as well as intrinsic
uncertainties and the actual physics of the traffic. In this study, we propose
a novel framework to incorporate travel times between stations into a weighted
adjacency matrix of a Graph Neural Network (GNN) architecture with information
from traffic stations based on their data availability. To handle uncertainty,
we utilized the Adaptive Conformal Prediction (ACP) method that adjusts
prediction intervals based on real-time validation residuals. To validate our
results, we model a microscopic traffic scenario and perform a Monte-Carlo
simulation to get a travel time distribution for a Vehicle Under Test (VUT),
and this distribution is compared against the real-world data. Experiments show
that the proposed model outperformed the next-best model by approximately 24%
in MAE and 8% in RMSE and validation showed the simulated travel time closely
matches the 95th percentile of the observed travel time value.",2024-07-17,"Mayur Patil, Qadeer Ahmed, Shawn Midlam-Mohler",http://arxiv.org/pdf/2407.12238v2,cs.LG
Base Models for Parabolic Partial Differential Equations,"Parabolic partial differential equations (PDEs) appear in many disciplines to
model the evolution of various mathematical objects, such as probability flows,
value functions in control theory, and derivative prices in finance. It is
often necessary to compute the solutions or a function of the solutions to a
parametric PDE in multiple scenarios corresponding to different parameters of
this PDE. This process often requires resolving the PDEs from scratch, which is
time-consuming. To better employ existing simulations for the PDEs, we propose
a framework for finding solutions to parabolic PDEs across different scenarios
by meta-learning an underlying base distribution. We build upon this base
distribution to propose a method for computing solutions to parametric PDEs
under different parameter settings. Finally, we illustrate the application of
the proposed methods through extensive experiments in generative modeling,
stochastic control, and finance. The empirical results suggest that the
proposed approach improves generalization to solving PDEs under new parameter
regimes.",2024-07-17,"Xingzi Xu, Ali Hasan, Jie Ding, Vahid Tarokh",http://arxiv.org/pdf/2407.12234v1,cs.LG
Individualized Federated Learning for Traffic Prediction with Error Driven Aggregation,"Low-latency traffic prediction is vital for smart city traffic management.
Federated Learning has emerged as a promising technique for Traffic Prediction
(FLTP), offering several advantages such as privacy preservation, reduced
communication overhead, improved prediction accuracy, and enhanced adaptability
to changing traffic conditions. However, majority of the current FLTP
frameworks lack a real-time model updating scheme, which hinders their ability
to continuously incorporate new incoming traffic data and adapt effectively to
the changing dynamics of traffic trends. Another concern with the existing FLTP
frameworks is their reliance on the conventional FL model aggregation method,
which involves assigning an identical model (i.e., the global model) to all
traffic monitoring devices to predict their individual local traffic trends,
thereby neglecting the non-IID characteristics of traffic data collected in
different locations. Building upon these findings and harnessing insights from
reinforcement learning, we propose NeighborFL, an individualized real-time
federated learning scheme that introduces a haversine distance-based and
error-driven, personalized local models grouping heuristic from the perspective
of each individual traffic node. This approach allows NeighborFL to create
location-aware and tailored prediction models for each client while fostering
collaborative learning. Simulations demonstrate the effectiveness of
NeighborFL, offering improved real-time prediction accuracy over three baseline
models, with one experimental setting showing a 16.9% reduction in MSE value
compared to a naive FL setting.",2024-07-17,"Hang Chen, Collin Meese, Mark Nejad, Chien-Chung Shen",http://arxiv.org/pdf/2407.12226v1,cs.LG
Conditional Quantile Estimation for Uncertain Watch Time in Short-Video Recommendation,"Accurately predicting watch time is crucial for optimizing recommendations
and user experience in short video platforms. However, existing methods that
estimate a single average watch time often fail to capture the inherent
uncertainty in user engagement patterns. In this paper, we propose Conditional
Quantile Estimation (CQE) to model the entire conditional distribution of watch
time. Using quantile regression, CQE characterizes the complex watch-time
distribution for each user-video pair, providing a flexible and comprehensive
approach to understanding user behavior. We further design multiple strategies
to combine the quantile estimates, adapting to different recommendation
scenarios and user preferences. Extensive offline experiments and online A/B
tests demonstrate the superiority of CQE in watch-time prediction and user
engagement modeling. Specifically, deploying CQE online on a large-scale
platform with hundreds of millions of daily active users has led to substantial
gains in key evaluation metrics, including active days, engagement time, and
video views. These results highlight the practical impact of our proposed
approach in enhancing the user experience and overall performance of the short
video recommendation system. The code will be released
https://github.com/justopit/CQE.",2024-07-17,"Chengzhi Lin, Shuchang Liu, Chuyuan Wang, Yongqi Liu",http://arxiv.org/pdf/2407.12223v5,cs.LG
Questionable practices in machine learning,"Evaluating modern ML models is hard. The strong incentive for researchers and
companies to report a state-of-the-art result on some metric often leads to
questionable research practices (QRPs): bad practices which fall short of
outright research fraud. We describe 44 such practices which can undermine
reported results, giving examples where possible. Our list emphasises the
evaluation of large language models (LLMs) on public benchmarks. We also
discuss ""irreproducible research practices"", i.e. decisions that make it
difficult or impossible for other researchers to reproduce, build on or audit
previous research.",2024-07-17,"Gavin Leech, Juan J. Vazquez, Niclas Kupper, Misha Yagudin, Laurence Aitchison",http://arxiv.org/pdf/2407.12220v2,cs.LG
Generalized Coverage for More Robust Low-Budget Active Learning,"The ProbCover method of Yehuda et al. is a well-motivated algorithm for
active learning in low-budget regimes, which attempts to ""cover"" the data
distribution with balls of a given radius at selected data points. We
demonstrate, however, that the performance of this algorithm is extremely
sensitive to the choice of this radius hyper-parameter, and that tuning it is
quite difficult, with the original heuristic frequently failing. We thus
introduce (and theoretically motivate) a generalized notion of ""coverage,""
including ProbCover's objective as a special case, but also allowing smoother
notions that are far more robust to hyper-parameter choice. We propose an
efficient greedy method to optimize this coverage, generalizing ProbCover's
algorithm; due to its close connection to kernel herding, we call it
""MaxHerding."" The objective can also be optimized non-greedily through a
variant of $k$-medoids, clarifying the relationship to other low-budget active
learning methods. In comprehensive experiments, MaxHerding surpasses existing
active learning methods across multiple low-budget image classification
benchmarks, and does so with less computational cost than most competitive
methods.",2024-07-16,"Wonho Bae, Junhyug Noh, Danica J. Sutherland",http://arxiv.org/pdf/2407.12212v2,cs.LG
"On the Calibration of Epistemic Uncertainty: Principles, Paradoxes and Conflictual Loss","The calibration of predictive distributions has been widely studied in deep
learning, but the same cannot be said about the more specific epistemic
uncertainty as produced by Deep Ensembles, Bayesian Deep Networks, or
Evidential Deep Networks. Although measurable, this form of uncertainty is
difficult to calibrate on an objective basis as it depends on the prior for
which a variety of choices exist. Nevertheless, epistemic uncertainty must in
all cases satisfy two formal requirements: first, it must decrease when the
training dataset gets larger and, second, it must increase when the model
expressiveness grows. Despite these expectations, our experimental study shows
that on several reference datasets and models, measures of epistemic
uncertainty violate these requirements, sometimes presenting trends completely
opposite to those expected. These paradoxes between expectation and reality
raise the question of the true utility of epistemic uncertainty as estimated by
these models. A formal argument suggests that this disagreement is due to a
poor approximation of the posterior distribution rather than to a flaw in the
measure itself. Based on this observation, we propose a regularization function
for deep ensembles, called conflictual loss in line with the above
requirements. We emphasize its strengths by showing experimentally that it
restores both requirements of epistemic uncertainty, without sacrificing either
the performance or the calibration of the deep ensembles.",2024-07-16,"Mohammed Fellaji, Frédéric Pennerath, Brieuc Conan-Guez, Miguel Couceiro",http://arxiv.org/pdf/2407.12211v1,cs.LG
Whitening Not Recommended for Classification Tasks in LLMs,"Sentence embedding is a cornerstone in NLP. Whitening has been claimed to be
an effective operation to improve embedding quality obtained from Large
Language Models (LLMs). However, we find that the efficacy of whitening is
model-dependent and task-dependent. In particular, whitening degenerates
embeddings for classification tasks. The conclusion is supported by extensive
experiments. We also explored a variety of whitening operations, including PCA,
ZCA, PCA-Cor, ZCA-Cor and Cholesky whitenings. A by-product of our research is
embedding evaluation platform for LLMs called SentEval+.",2024-07-16,"Ali Forooghi, Shaghayegh Sadeghi, Jianguo Lu",http://arxiv.org/pdf/2407.12886v1,cs.LG
This Probably Looks Exactly Like That: An Invertible Prototypical Network,"We combine concept-based neural networks with generative, flow-based
classifiers into a novel, intrinsically explainable, exactly invertible
approach to supervised learning. Prototypical neural networks, a type of
concept-based neural network, represent an exciting way forward in realizing
human-comprehensible machine learning without concept annotations, but a
human-machine semantic gap continues to haunt current approaches. We find that
reliance on indirect interpretation functions for prototypical explanations
imposes a severe limit on prototypes' informative power. From this, we posit
that invertibly learning prototypes as distributions over the latent space
provides more robust, expressive, and interpretable modeling. We propose one
such model, called ProtoFlow, by composing a normalizing flow with Gaussian
mixture models. ProtoFlow (1) sets a new state-of-the-art in joint generative
and predictive modeling and (2) achieves predictive performance comparable to
existing prototypical neural networks while enabling richer interpretation.",2024-07-16,"Zachariah Carmichael, Timothy Redgrave, Daniel Gonzalez Cedre, Walter J. Scheirer",http://arxiv.org/pdf/2407.12200v1,cs.LG
Satisficing Exploration for Deep Reinforcement Learning,"A default assumption in the design of reinforcement-learning algorithms is
that a decision-making agent always explores to learn optimal behavior. In
sufficiently complex environments that approach the vastness and scale of the
real world, however, attaining optimal performance may in fact be an entirely
intractable endeavor and an agent may seldom find itself in a position to
complete the requisite exploration for identifying an optimal policy. Recent
work has leveraged tools from information theory to design agents that
deliberately forgo optimal solutions in favor of sufficiently-satisfying or
satisficing solutions, obtained through lossy compression. Notably, such agents
may employ fundamentally different exploratory decisions to learn satisficing
behaviors more efficiently than optimal ones that are more data intensive.
While supported by a rigorous corroborating theory, the underlying algorithm
relies on model-based planning, drastically limiting the compatibility of these
ideas with function approximation and high-dimensional observations. In this
work, we remedy this issue by extending an agent that directly represents
uncertainty over the optimal value function allowing it to both bypass the need
for model-based planning and to learn satisficing policies. We provide simple
yet illustrative experiments that demonstrate how our algorithm enables deep
reinforcement-learning agents to achieve satisficing behaviors. In keeping with
previous work on this setting for multi-armed bandits, we additionally find
that our algorithm is capable of synthesizing optimal behaviors, when feasible,
more efficiently than its non-information-theoretic counterpart.",2024-07-16,"Dilip Arumugam, Saurabh Kumar, Ramki Gummadi, Benjamin Van Roy",http://arxiv.org/pdf/2407.12185v1,cs.LG
Exploration Unbound,"A sequential decision-making agent balances between exploring to gain new
knowledge about an environment and exploiting current knowledge to maximize
immediate reward. For environments studied in the traditional literature,
optimal decisions gravitate over time toward exploitation as the agent
accumulates sufficient knowledge and the benefits of further exploration
vanish. What if, however, the environment offers an unlimited amount of useful
knowledge and there is large benefit to further exploration no matter how much
the agent has learned? We offer a simple, quintessential example of such a
complex environment. In this environment, rewards are unbounded and an agent
can always increase the rate at which rewards accumulate by exploring to learn
more. Consequently, an optimal agent forever maintains a propensity to explore.",2024-07-16,"Dilip Arumugam, Wanqiao Xu, Benjamin Van Roy",http://arxiv.org/pdf/2407.12178v1,cs.LG
Are Linear Regression Models White Box and Interpretable?,"Explainable artificial intelligence (XAI) is a set of tools and algorithms
that applied or embedded to machine learning models to understand and interpret
the models. They are recommended especially for complex or advanced models
including deep neural network because they are not interpretable from human
point of view. On the other hand, simple models including linear regression are
easy to implement, has less computational complexity and easy to visualize the
output. The common notion in the literature that simple models including linear
regression are considered as ""white box"" because they are more interpretable
and easier to understand. This is based on the idea that linear regression
models have several favorable outcomes including the effect of the features in
the model and whether they affect positively or negatively toward model output.
Moreover, uncertainty of the model can be measured or estimated using the
confidence interval. However, we argue that this perception is not accurate and
linear regression models are not easy to interpret neither easy to understand
considering common XAI metrics and possible challenges might face. This
includes linearity, local explanation, multicollinearity, covariates,
normalization, uncertainty, features contribution and fairness. Consequently,
we recommend the so-called simple models should be treated equally to complex
models when it comes to explainability and interpretability.",2024-07-16,"Ahmed M Salih, Yuhe Wang",http://arxiv.org/pdf/2407.12177v1,cs.LG
A Scalable Real-Time Data Assimilation Framework for Predicting Turbulent Atmosphere Dynamics,"The weather and climate domains are undergoing a significant transformation
thanks to advances in AI-based foundation models such as FourCastNet,
GraphCast, ClimaX and Pangu-Weather. While these models show considerable
potential, they are not ready yet for operational use in weather forecasting or
climate prediction. This is due to the lack of a data assimilation method as
part of their workflow to enable the assimilation of incoming Earth system
observations in real time. This limitation affects their effectiveness in
predicting complex atmospheric phenomena such as tropical cyclones and
atmospheric rivers. To overcome these obstacles, we introduce a generic
real-time data assimilation framework and demonstrate its end-to-end
performance on the Frontier supercomputer. This framework comprises two primary
modules: an ensemble score filter (EnSF), which significantly outperforms the
state-of-the-art data assimilation method, namely, the Local Ensemble Transform
Kalman Filter (LETKF); and a vision transformer-based surrogate capable of
real-time adaptation through the integration of observational data. The ViT
surrogate can represent either physics-based models or AI-based foundation
models. We demonstrate both the strong and weak scaling of our framework up to
1024 GPUs on the Exascale supercomputer, Frontier. Our results not only
illustrate the framework's exceptional scalability on high-performance
computing systems, but also demonstrate the importance of supercomputers in
real-time data assimilation for weather and climate predictions. Even though
the proposed framework is tested only on a benchmark surface quasi-geostrophic
(SQG) turbulence system, it has the potential to be combined with existing
AI-based foundation models, making it suitable for future operational
implementations.",2024-07-16,"Junqi Yin, Siming Liang, Siyan Liu, Feng Bao, Hristo G. Chipilski, Dan Lu, Guannan Zhang",http://arxiv.org/pdf/2407.12168v1,cs.LG
Subject-driven Text-to-Image Generation via Preference-based Reinforcement Learning,"Text-to-image generative models have recently attracted considerable
interest, enabling the synthesis of high-quality images from textual prompts.
However, these models often lack the capability to generate specific subjects
from given reference images or to synthesize novel renditions under varying
conditions. Methods like DreamBooth and Subject-driven Text-to-Image (SuTI)
have made significant progress in this area. Yet, both approaches primarily
focus on enhancing similarity to reference images and require expensive setups,
often overlooking the need for efficient training and avoiding overfitting to
the reference images. In this work, we present the $\lambda$-Harmonic reward
function, which provides a reliable reward signal and enables early stopping
for faster training and effective regularization. By combining the
Bradley-Terry preference model, the $\lambda$-Harmonic reward function also
provides preference labels for subject-driven generation tasks. We propose
Reward Preference Optimization (RPO), which offers a simpler setup (requiring
only $3\%$ of the negative samples used by DreamBooth) and fewer gradient steps
for fine-tuning. Unlike most existing methods, our approach does not require
training a text encoder or optimizing text embeddings and achieves text-image
alignment by fine-tuning only the U-Net component. Empirically,
$\lambda$-Harmonic proves to be a reliable approach for model selection in
subject-driven generation tasks. Based on preference labels and early stopping
validation from the $\lambda$-Harmonic reward function, our algorithm achieves
a state-of-the-art CLIP-I score of 0.833 and a CLIP-T score of 0.314 on
DreamBench.",2024-07-16,"Yanting Miao, William Loh, Suraj Kothawade, Pascal Poupart, Abdullah Rashwan, Yeqing Li",http://arxiv.org/pdf/2407.12164v3,cs.LG
Bellman Diffusion Models,"Diffusion models have seen tremendous success as generative architectures.
Recently, they have been shown to be effective at modelling policies for
offline reinforcement learning and imitation learning. We explore using
diffusion as a model class for the successor state measure (SSM) of a policy.
We find that enforcing the Bellman flow constraints leads to a simple Bellman
update on the diffusion step distribution.",2024-07-16,"Liam Schramm, Abdeslam Boularias",http://arxiv.org/pdf/2407.12163v1,cs.LG
Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions,"The emergence of Generative AI is catalyzing a paradigm shift in user
interfaces from command-based to intent-based outcome specification. In this
paper, we explore abstract-to-detailed task transitions in the context of
frontend code generation as a step towards intent-based user interfaces, aiming
to bridge the gap between abstract user intentions and concrete
implementations. We introduce Frontend Diffusion, an end-to-end LLM-powered
tool that generates high-quality websites from user sketches. The system
employs a three-stage task transition process: sketching, writing, and coding.
We demonstrate the potential of task transitions to reduce human intervention
and communication costs in complex tasks. Our work also opens avenues for
exploring similar approaches in other domains, potentially extending to more
complex, interdependent tasks such as video production.",2024-07-16,"Qinshi Zhang, Latisha Besariani Hendra, Mohan Chi, Zijian Ding",http://arxiv.org/pdf/2408.00778v1,cs.LG
A Hitchhiker's Guide to Deep Chemical Language Processing for Bioactivity Prediction,"Deep learning has significantly accelerated drug discovery, with 'chemical
language' processing (CLP) emerging as a prominent approach. CLP learns from
molecular string representations (e.g., Simplified Molecular Input Line Entry
Systems [SMILES] and Self-Referencing Embedded Strings [SELFIES]) with methods
akin to natural language processing. Despite their growing importance, training
predictive CLP models is far from trivial, as it involves many 'bells and
whistles'. Here, we analyze the key elements of CLP training, to provide
guidelines for newcomers and experts alike. Our study spans three neural
network architectures, two string representations, three embedding strategies,
across ten bioactivity datasets, for both classification and regression
purposes. This 'hitchhiker's guide' not only underscores the importance of
certain methodological choices, but it also equips researchers with practical
recommendations on ideal choices, e.g., in terms of neural network
architectures, molecular representations, and hyperparameter optimization.",2024-07-16,"Rıza Özçelik, Francesca Grisoni",http://arxiv.org/pdf/2407.12152v1,cs.LG
Monocular pose estimation of articulated surgical instruments in open surgery,"This work presents a novel approach to monocular 6D pose estimation of
surgical instruments in open surgery, addressing challenges such as object
articulations, symmetries, occlusions, and lack of annotated real-world data.
The method leverages synthetic data generation and domain adaptation techniques
to overcome these obstacles. The proposed approach consists of three main
components: (1) synthetic data generation using 3D modeling of surgical tools
with articulation rigging and physically-based rendering; (2) a tailored pose
estimation framework combining object detection with pose estimation and a
hybrid geometric fusion strategy; and (3) a training strategy that utilizes
both synthetic and real unannotated data, employing domain adaptation on real
video data using automatically generated pseudo-labels. Evaluations conducted
on videos of open surgery demonstrate the good performance and real-world
applicability of the proposed method, highlighting its potential for
integration into medical augmented reality and robotic systems. The approach
eliminates the need for extensive manual annotation of real surgical data.",2024-07-16,"Robert Spektor, Tom Friedman, Itay Or, Gil Bolotin, Shlomi Laufer",http://arxiv.org/pdf/2407.12138v1,cs.LG
Molecular Topological Profile (MOLTOP) -- Simple and Strong Baseline for Molecular Graph Classification,"We revisit the effectiveness of topological descriptors for molecular graph
classification and design a simple, yet strong baseline. We demonstrate that a
simple approach to feature engineering - employing histogram aggregation of
edge descriptors and one-hot encoding for atomic numbers and bond types - when
combined with a Random Forest classifier, can establish a strong baseline for
Graph Neural Networks (GNNs). The novel algorithm, Molecular Topological
Profile (MOLTOP), integrates Edge Betweenness Centrality, Adjusted Rand Index
and SCAN Structural Similarity score. This approach proves to be remarkably
competitive when compared to modern GNNs, while also being simple, fast,
low-variance and hyperparameter-free. Our approach is rigorously tested on
MoleculeNet datasets using fair evaluation protocol provided by Open Graph
Benchmark. We additionally show out-of-domain generation capabilities on
peptide classification task from Long Range Graph Benchmark. The evaluations
across eleven benchmark datasets reveal MOLTOP's strong discriminative
capabilities, surpassing the $1$-WL test and even $3$-WL test for some classes
of graphs. Our conclusion is that descriptor-based baselines, such as the one
we propose, are still crucial for accurately assessing advancements in the GNN
domain.",2024-07-16,"Jakub Adamczyk, Wojciech Czech",http://arxiv.org/pdf/2407.12136v3,cs.LG
Distribution Alignment for Fully Test-Time Adaptation with Dynamic Online Data Streams,"Given a model trained on source data, Test-Time Adaptation (TTA) enables
adaptation and inference in test data streams with domain shifts from the
source. Current methods predominantly optimize the model for each incoming test
data batch using self-training loss. While these methods yield commendable
results in ideal test data streams, where batches are independently and
identically sampled from the target distribution, they falter under more
practical test data streams that are not independent and identically
distributed (non-i.i.d.). The data batches in a non-i.i.d. stream display
prominent label shifts relative to each other. It leads to conflicting
optimization objectives among batches during the TTA process. Given the
inherent risks of adapting the source model to unpredictable test-time
distributions, we reverse the adaptation process and propose a novel
Distribution Alignment loss for TTA. This loss guides the distributions of
test-time features back towards the source distributions, which ensures
compatibility with the well-trained source model and eliminates the pitfalls
associated with conflicting optimization objectives. Moreover, we devise a
domain shift detection mechanism to extend the success of our proposed TTA
method in the continual domain shift scenarios. Our extensive experiments
validate the logic and efficacy of our method. On six benchmark datasets, we
surpass existing methods in non-i.i.d. scenarios and maintain competitive
performance under the ideal i.i.d. assumption.",2024-07-16,"Ziqiang Wang, Zhixiang Chi, Yanan Wu, Li Gu, Zhi Liu, Konstantinos Plataniotis, Yang Wang",http://arxiv.org/pdf/2407.12128v1,cs.LG
SurroFlow: A Flow-Based Surrogate Model for Parameter Space Exploration and Uncertainty Quantification,"Existing deep learning-based surrogate models facilitate efficient data
generation, but fall short in uncertainty quantification, efficient parameter
space exploration, and reverse prediction. In our work, we introduce SurroFlow,
a novel normalizing flow-based surrogate model, to learn the invertible
transformation between simulation parameters and simulation outputs. The model
not only allows accurate predictions of simulation outcomes for a given
simulation parameter but also supports uncertainty quantification in the data
generation process. Additionally, it enables efficient simulation parameter
recommendation and exploration. We integrate SurroFlow and a genetic algorithm
as the backend of a visual interface to support effective user-guided ensemble
simulation exploration and visualization. Our framework significantly reduces
the computational costs while enhancing the reliability and exploration
capabilities of scientific surrogate models.",2024-07-16,"Jingyi Shen, Yuhan Duan, Han-Wei Shen",http://arxiv.org/pdf/2407.12884v1,cs.LG
MEMO: Fine-grained Tensor Management For Ultra-long Context LLM Training,"Nowadays, Large Language Models (LLMs) have been trained using extended
context lengths to foster more creative applications. However, long context
training poses great challenges considering the constraint of GPU memory. It
not only leads to substantial activation memory consumption during training,
but also incurs considerable memory fragmentation. To facilitate long context
training, existing frameworks have adopted strategies such as recomputation and
various forms of parallelisms. Nevertheless, these techniques rely on redundant
computation or extensive communication, resulting in low Model FLOPS
Utilization (MFU). In this paper, we propose MEMO, a novel LLM training
framework designed for fine-grained activation memory management. Given the
quadratic scaling of computation and linear scaling of memory with sequence
lengths when using FlashAttention, we offload memory-consuming activations to
CPU memory after each layer's forward pass and fetch them during the backward
pass. To maximize the swapping of activations without hindering computation,
and to avoid exhausting limited CPU memory, we implement a token-wise
activation recomputation and swapping mechanism. Furthermore, we tackle the
memory fragmentation issue by employing a bi-level Mixed Integer Programming
(MIP) approach, optimizing memory reuse across transformer layers. Empirical
results demonstrate that MEMO achieves an average of 1.97x and 1.80x MFU
compared to Megatron-LM and DeepSpeed, respectively. This improvement is
attributed to MEMO's ability to minimize memory fragmentation, reduce
recomputation and intensive communication, and circumvent the delays associated
with the memory reorganization process due to fragmentation. By leveraging
fine-grained activation memory management, MEMO facilitates efficient training
of 7B LLM with 1 million sequence length on just 8 A800 GPUs, achieving an MFU
of 52.30%.",2024-07-16,"Pinxue Zhao, Hailin Zhang, Fangcheng Fu, Xiaonan Nie, Qibin Liu, Fang Yang, Yuanbo Peng, Dian Jiao, Shuaipeng Li, Jinbao Xue, Yangyu Tao, Bin Cui",http://arxiv.org/pdf/2407.12117v3,cs.LG
A Graph-based Adversarial Imitation Learning Framework for Reliable & Realtime Fleet Scheduling in Urban Air Mobility,"The advent of Urban Air Mobility (UAM) presents the scope for a
transformative shift in the domain of urban transportation. However, its
widespread adoption and economic viability depends in part on the ability to
optimally schedule the fleet of aircraft across vertiports in a UAM network,
under uncertainties attributed to airspace congestion, changing weather
conditions, and varying demands. This paper presents a comprehensive
optimization formulation of the fleet scheduling problem, while also
identifying the need for alternate solution approaches, since directly solving
the resulting integer nonlinear programming problem is computationally
prohibitive for daily fleet scheduling. Previous work has shown the
effectiveness of using (graph) reinforcement learning (RL) approaches to train
real-time executable policy models for fleet scheduling. However, such policies
can often be brittle on out-of-distribution scenarios or edge cases. Moreover,
training performance also deteriorates as the complexity (e.g., number of
constraints) of the problem increases. To address these issues, this paper
presents an imitation learning approach where the RL-based policy exploits
expert demonstrations yielded by solving the exact optimization using a Genetic
Algorithm. The policy model comprises Graph Neural Network (GNN) based encoders
that embed the space of vertiports and aircraft, Transformer networks to encode
demand, passenger fare, and transport cost profiles, and a Multi-head attention
(MHA) based decoder. Expert demonstrations are used through the Generative
Adversarial Imitation Learning (GAIL) algorithm. Interfaced with a UAM
simulation environment involving 8 vertiports and 40 aircrafts, in terms of the
daily profits earned reward, the new imitative approach achieves better mean
performance and remarkable improvement in the case of unseen worst-case
scenarios, compared to pure RL results.",2024-07-16,"Prithvi Poddar, Steve Paul, Souma Chowdhury",http://arxiv.org/pdf/2407.12113v2,cs.LG
A Benchmark for Fairness-Aware Graph Learning,"Fairness-aware graph learning has gained increasing attention in recent
years. Nevertheless, there lacks a comprehensive benchmark to evaluate and
compare different fairness-aware graph learning methods, which blocks
practitioners from choosing appropriate ones for broader real-world
applications. In this paper, we present an extensive benchmark on ten
representative fairness-aware graph learning methods. Specifically, we design a
systematic evaluation protocol and conduct experiments on seven real-world
datasets to evaluate these methods from multiple perspectives, including group
fairness, individual fairness, the balance between different fairness criteria,
and computational efficiency. Our in-depth analysis reveals key insights into
the strengths and limitations of existing methods. Additionally, we provide
practical guidance for applying fairness-aware graph learning methods in
applications. To the best of our knowledge, this work serves as an initial step
towards comprehensively understanding representative fairness-aware graph
learning methods to facilitate future advancements in this area.",2024-07-16,"Yushun Dong, Song Wang, Zhenyu Lei, Zaiyi Zheng, Jing Ma, Chen Chen, Jundong Li",http://arxiv.org/pdf/2407.12112v1,cs.LG
Private prediction for large-scale synthetic text generation,"We present an approach for generating differentially private synthetic text
using large language models (LLMs), via private prediction. In the private
prediction framework, we only require the output synthetic data to satisfy
differential privacy guarantees. This is in contrast to approaches that train a
generative model on potentially sensitive user-supplied source data and seek to
ensure the model itself is safe to release.
  We prompt a pretrained LLM with source data, but ensure that next-token
predictions are made with differential privacy guarantees. Previous work in
this paradigm reported generating a small number of examples (<10) at
reasonable privacy levels, an amount of data that is useful only for downstream
in-context learning or prompting. In contrast, we make changes that allow us to
generate thousands of high-quality synthetic data points, greatly expanding the
set of potential applications. Our improvements come from an improved privacy
analysis and a better private selection mechanism, which makes use of the
equivalence between the softmax layer for sampling tokens in LLMs and the
exponential mechanism. Furthermore, we introduce a novel use of public
predictions via the sparse vector technique, in which we do not pay privacy
costs for tokens that are predictable without sensitive data; we find this to
be particularly effective for structured data.",2024-07-16,"Kareem Amin, Alex Bie, Weiwei Kong, Alexey Kurakin, Natalia Ponomareva, Umar Syed, Andreas Terzis, Sergei Vassilvitskii",http://arxiv.org/pdf/2407.12108v2,cs.LG
Does Refusal Training in LLMs Generalize to the Past Tense?,"Refusal training is widely used to prevent LLMs from generating harmful,
undesirable, or illegal outputs. We reveal a curious generalization gap in the
current refusal training approaches: simply reformulating a harmful request in
the past tense (e.g., ""How to make a Molotov cocktail?"" to ""How did people make
a Molotov cocktail?"") is often sufficient to jailbreak many state-of-the-art
LLMs. We systematically evaluate this method on Llama-3 8B, Claude-3.5 Sonnet,
GPT-3.5 Turbo, Gemma-2 9B, Phi-3-Mini, GPT-4o mini, GPT-4o, o1-mini,
o1-preview, and R2D2 models using GPT-3.5 Turbo as a reformulation model. For
example, the success rate of this simple attack on GPT-4o increases from 1%
using direct requests to 88% using 20 past tense reformulation attempts on
harmful requests from JailbreakBench with GPT-4 as a jailbreak judge.
Interestingly, we also find that reformulations in the future tense are less
effective, suggesting that refusal guardrails tend to consider past historical
questions more benign than hypothetical future questions. Moreover, our
experiments on fine-tuning GPT-3.5 Turbo show that defending against past
reformulations is feasible when past tense examples are explicitly included in
the fine-tuning data. Overall, our findings highlight that the widely used
alignment techniques -- such as SFT, RLHF, and adversarial training -- employed
to align the studied models can be brittle and do not always generalize as
intended. We provide code and jailbreak artifacts at
https://github.com/tml-epfl/llm-past-tense.",2024-07-16,"Maksym Andriushchenko, Nicolas Flammarion",http://arxiv.org/pdf/2407.11969v4,cs.LG
Efficient Training with Denoised Neural Weights,"Good weight initialization serves as an effective measure to reduce the
training cost of a deep neural network (DNN) model. The choice of how to
initialize parameters is challenging and may require manual tuning, which can
be time-consuming and prone to human error. To overcome such limitations, this
work takes a novel step towards building a weight generator to synthesize the
neural weights for initialization. We use the image-to-image translation task
with generative adversarial networks (GANs) as an example due to the ease of
collecting model weights spanning a wide range. Specifically, we first collect
a dataset with various image editing concepts and their corresponding trained
weights, which are later used for the training of the weight generator. To
address the different characteristics among layers and the substantial number
of weights to be predicted, we divide the weights into equal-sized blocks and
assign each block an index. Subsequently, a diffusion model is trained with
such a dataset using both text conditions of the concept and the block indexes.
By initializing the image translation model with the denoised weights predicted
by our diffusion model, the training requires only 43.3 seconds. Compared to
training from scratch (i.e., Pix2pix), we achieve a 15x training time
acceleration for a new concept while obtaining even better image generation
quality.",2024-07-16,"Yifan Gong, Zheng Zhan, Yanyu Li, Yerlan Idelbayev, Andrey Zharkov, Kfir Aberman, Sergey Tulyakov, Yanzhi Wang, Jian Ren",http://arxiv.org/pdf/2407.11966v1,cs.LG
Motion-Oriented Compositional Neural Radiance Fields for Monocular Dynamic Human Modeling,"This paper introduces Motion-oriented Compositional Neural Radiance Fields
(MoCo-NeRF), a framework designed to perform free-viewpoint rendering of
monocular human videos via novel non-rigid motion modeling approach. In the
context of dynamic clothed humans, complex cloth dynamics generate non-rigid
motions that are intrinsically distinct from skeletal articulations and
critically important for the rendering quality. The conventional approach
models non-rigid motions as spatial (3D) deviations in addition to skeletal
transformations. However, it is either time-consuming or challenging to achieve
optimal quality due to its high learning complexity without a direct
supervision. To target this problem, we propose a novel approach of modeling
non-rigid motions as radiance residual fields to benefit from more direct color
supervision in the rendering and utilize the rigid radiance fields as a prior
to reduce the complexity of the learning process. Our approach utilizes a
single multiresolution hash encoding (MHE) to concurrently learn the canonical
T-pose representation from rigid skeletal motions and the radiance residual
field for non-rigid motions. Additionally, to further improve both training
efficiency and usability, we extend MoCo-NeRF to support simultaneous training
of multiple subjects within a single framework, thanks to our effective design
for modeling non-rigid motions. This scalability is achieved through the
integration of a global MHE and learnable identity codes in addition to
multiple local MHEs. We present extensive results on ZJU-MoCap and MonoCap,
clearly demonstrating state-of-the-art performance in both single- and
multi-subject settings. The code and model will be made publicly available at
the project page: https://stevejaehyeok.github.io/publications/moco-nerf.",2024-07-16,"Jaehyeok Kim, Dongyoon Wee, Dan Xu",http://arxiv.org/pdf/2407.11962v2,cs.LG
Context-Guided Diffusion for Out-of-Distribution Molecular and Protein Design,"Generative models have the potential to accelerate key steps in the discovery
of novel molecular therapeutics and materials. Diffusion models have recently
emerged as a powerful approach, excelling at unconditional sample generation
and, with data-driven guidance, conditional generation within their training
domain. Reliably sampling from high-value regions beyond the training data,
however, remains an open challenge -- with current methods predominantly
focusing on modifying the diffusion process itself. In this paper, we develop
context-guided diffusion (CGD), a simple plug-and-play method that leverages
unlabeled data and smoothness constraints to improve the out-of-distribution
generalization of guided diffusion models. We demonstrate that this approach
leads to substantial performance gains across various settings, including
continuous, discrete, and graph-structured diffusion processes with
applications across drug discovery, materials science, and protein design.",2024-07-16,"Leo Klarner, Tim G. J. Rudner, Garrett M. Morris, Charlotte M. Deane, Yee Whye Teh",http://arxiv.org/pdf/2407.11942v1,cs.LG
Fairly Accurate: Optimizing Accuracy Parity in Fair Target-Group Detection,"In algorithmic toxicity detection pipelines, it is important to identify
which demographic group(s) are the subject of a post, a task commonly known as
\textit{target (group) detection}. While accurate detection is clearly
important, we further advocate a fairness objective: to provide equal
protection to all groups who may be targeted. To this end, we adopt
\textit{Accuracy Parity} (AP) -- balanced detection accuracy across groups --
as our fairness objective. However, in order to align model training with our
AP fairness objective, we require an equivalent loss function. Moreover, for
gradient-based models such as neural networks, this loss function needs to be
differentiable. Because no such loss function exists today for AP, we propose
\emph{Group Accuracy Parity} (GAP): the first differentiable loss function
having a one-on-one mapping to AP. We empirically show that GAP addresses
disparate impact on groups for target detection. Furthermore, because a single
post often targets multiple groups in practice, we also provide a mathematical
extension of GAP to larger multi-group settings, something typically requiring
heuristics in prior work. Our findings show that by optimizing AP, GAP better
mitigates bias in comparison with other commonly employed loss functions.",2024-07-16,"Soumyajit Gupta, Venelin Kovatchev, Maria De-Arteaga, Matthew Lease",http://arxiv.org/pdf/2407.11933v1,cs.LG
Tackling Oversmoothing in GNN via Graph Sparsification: A Truss-based Approach,"Graph Neural Network (GNN) achieves great success for node-level and
graph-level tasks via encoding meaningful topological structures of networks in
various domains, ranging from social to biological networks. However, repeated
aggregation operations lead to excessive mixing of node representations,
particularly in dense regions with multiple GNN layers, resulting in nearly
indistinguishable embeddings. This phenomenon leads to the oversmoothing
problem that hampers downstream graph analytics tasks. To overcome this issue,
we propose a novel and flexible truss-based graph sparsification model that
prunes edges from dense regions of the graph. Pruning redundant edges in dense
regions helps to prevent the aggregation of excessive neighborhood information
during hierarchical message passing and pooling in GNN models. We then utilize
our sparsification model in the state-of-the-art baseline GNNs and pooling
models, such as GIN, SAGPool, GMT, DiffPool, MinCutPool, HGP-SL, DMonPool, and
AdamGNN. Extensive experiments on different real-world datasets show that our
model significantly improves the performance of the baseline GNN models in the
graph classification task.",2024-07-16,"Tanvir Hossain, Khaled Mohammed Saifuddin, Muhammad Ifte Khairul Islam, Farhan Tanvir, Esra Akbas",http://arxiv.org/pdf/2407.11928v1,cs.LG
Bayesian Causal Forests for Longitudinal Data: Assessing the Impact of Part-Time Work on Growth in High School Mathematics Achievement,"Modelling growth in student achievement is a significant challenge in the
field of education. Understanding how interventions or experiences such as
part-time work can influence this growth is also important. Traditional methods
like difference-in-differences are effective for estimating causal effects from
longitudinal data. Meanwhile, Bayesian non-parametric methods have recently
become popular for estimating causal effects from single time point
observational studies. However, there remains a scarcity of methods capable of
combining the strengths of these two approaches to flexibly estimate
heterogeneous causal effects from longitudinal data. Motivated by two waves of
data from the High School Longitudinal Study, the NCES' most recent
longitudinal study which tracks a representative sample of over 20,000 students
in the US, our study introduces a longitudinal extension of Bayesian Causal
Forests. This model allows for the flexible identification of both individual
growth in mathematical ability and the effects of participation in part-time
work. Simulation studies demonstrate the predictive performance and reliable
uncertainty quantification of the proposed model. Results reveal the negative
impact of part time work for most students, but hint at potential benefits for
those students with an initially low sense of school belonging. Clear signs of
a widening achievement gap between students with high and low academic
achievement are also identified. Potential policy implications are discussed,
along with promising areas for future research.",2024-07-16,"Nathan McJames, Ann O'Shea, Andrew Parnell",http://arxiv.org/pdf/2407.11927v1,cs.LG
Learning secondary tool affordances of human partners using iCub robot's egocentric data,"Objects, in particular tools, provide several action possibilities to the
agents that can act on them, which are generally associated with the term of
affordances. A tool is typically designed for a specific purpose, such as
driving a nail in the case of a hammer, which we call as the primary
affordance. A tool can also be used beyond its primary purpose, in which case
we can associate this auxiliary use with the term secondary affordance.
Previous work on affordance perception and learning has been mostly focused on
primary affordances. Here, we address the less explored problem of learning the
secondary tool affordances of human partners. To do this, we use the iCub robot
to observe human partners with three cameras while they perform actions on
twenty objects using four different tools. In our experiments, human partners
utilize tools to perform actions that do not correspond to their primary
affordances. For example, the iCub robot observes a human partner using a ruler
for pushing, pulling, and moving objects instead of measuring their lengths. In
this setting, we constructed a dataset by taking images of objects before and
after each action is executed. We then model learning secondary affordances by
training three neural networks (ResNet-18, ResNet-50, and ResNet-101) each on
three tasks, using raw images showing the `initial' and `final' position of
objects as input: (1) predicting the tool used to move an object, (2)
predicting the tool used with an additional categorical input that encoded the
action performed, and (3) joint prediction of both tool used and action
performed. Our results indicate that deep learning architectures enable the
iCub robot to predict secondary tool affordances, thereby paving the road for
human-robot collaborative object manipulation involving complex affordances.",2024-07-16,"Bosong Ding, Erhan Oztop, Giacomo Spigler, Murat Kirtay",http://arxiv.org/pdf/2407.11922v1,cs.LG
Global Optimisation of Black-Box Functions with Generative Models in the Wasserstein Space,"We propose a new uncertainty estimator for gradient-free optimisation of
black-box simulators using deep generative surrogate models. Optimisation of
these simulators is especially challenging for stochastic simulators and higher
dimensions. To address these issues, we utilise a deep generative surrogate
approach to model the black box response for the entire parameter space. We
then leverage this knowledge to estimate the proposed uncertainty based on the
Wasserstein distance - the Wasserstein uncertainty. This approach is employed
in a posterior agnostic gradient-free optimisation algorithm that minimises
regret over the entire parameter space. A series of tests were conducted to
demonstrate that our method is more robust to the shape of both the black box
function and the stochastic response of the black box than state-of-the-art
methods, such as efficient global optimisation with a deep Gaussian process
surrogate.",2024-07-16,"Tigran Ramazyan, Mikhail Hushchyn, Denis Derkach",http://arxiv.org/pdf/2407.11917v3,cs.LG
Imitation of human motion achieves natural head movements for humanoid robots in an active-speaker detection task,"Head movements are crucial for social human-human interaction. They can
transmit important cues (e.g., joint attention, speaker detection) that cannot
be achieved with verbal interaction alone. This advantage also holds for
human-robot interaction. Even though modeling human motions through generative
AI models has become an active research area within robotics in recent years,
the use of these methods for producing head movements in human-robot
interaction remains underexplored. In this work, we employed a generative AI
pipeline to produce human-like head movements for a Nao humanoid robot. In
addition, we tested the system on a real-time active-speaker tracking task in a
group conversation setting. Overall, the results show that the Nao robot
successfully imitates human head movements in a natural manner while actively
tracking the speakers during the conversation. Code and data from this study
are available at https://github.com/dingdingding60/Humanoids2024HRI",2024-07-16,"Bosong Ding, Murat Kirtay, Giacomo Spigler",http://arxiv.org/pdf/2407.11915v1,cs.LG
Quantised Global Autoencoder: A Holistic Approach to Representing Visual Data,"In quantised autoencoders, images are usually split into local patches, each
encoded by one token. This representation is redundant in the sense that the
same number of tokens is spend per region, regardless of the visual information
content in that region. Adaptive discretisation schemes like quadtrees are
applied to allocate tokens for patches with varying sizes, but this just varies
the region of influence for a token which nevertheless remains a local
descriptor. Modern architectures add an attention mechanism to the autoencoder
which infuses some degree of global information into the local tokens. Despite
the global context, tokens are still associated with a local image region. In
contrast, our method is inspired by spectral decompositions which transform an
input signal into a superposition of global frequencies. Taking the data-driven
perspective, we learn custom basis functions corresponding to the codebook
entries in our VQ-VAE setup. Furthermore, a decoder combines these basis
functions in a non-linear fashion, going beyond the simple linear superposition
of spectral decompositions. We can achieve this global description with an
efficient transpose operation between features and channels and demonstrate our
performance on compression.",2024-07-16,"Tim Elsner, Paula Usinger, Victor Czech, Gregor Kobsik, Yanjiang He, Isaak Lim, Leif Kobbelt",http://arxiv.org/pdf/2407.11913v2,cs.LG
Benchmarking the Attribution Quality of Vision Models,"Attribution maps are one of the most established tools to explain the
functioning of computer vision models. They assign importance scores to input
features, indicating how relevant each feature is for the prediction of a deep
neural network. While much research has gone into proposing new attribution
methods, their proper evaluation remains a difficult challenge. In this work,
we propose a novel evaluation protocol that overcomes two fundamental
limitations of the widely used incremental-deletion protocol, i.e., the
out-of-domain issue and lacking inter-model comparisons. This allows us to
evaluate 23 attribution methods and how different design choices of popular
vision backbones affect their attribution quality. We find that intrinsically
explainable models outperform standard models and that raw attribution values
exhibit a higher attribution quality than what is known from previous work.
Further, we show consistent changes in the attribution quality when varying the
network design, indicating that some standard design choices promote
attribution quality.",2024-07-16,"Robin Hesse, Simone Schaub-Meyer, Stefan Roth",http://arxiv.org/pdf/2407.11910v2,cs.LG
GraphFM: A Scalable Framework for Multi-Graph Pretraining,"Graph neural networks are typically trained on individual datasets, often
requiring highly specialized models and extensive hyperparameter tuning. This
dataset-specific approach arises because each graph dataset often has unique
node features and diverse connectivity structures, making it difficult to build
a generalist model. To address these challenges, we introduce a scalable
multi-graph multi-task pretraining approach specifically tailored for node
classification tasks across diverse graph datasets from different domains. Our
method, Graph Foundation Model (GraphFM), leverages a Perceiver-based encoder
that employs learned latent tokens to compress domain-specific features into a
common latent space. This approach enhances the model's ability to generalize
across different graphs and allows for scaling across diverse data. We
demonstrate the efficacy of our approach by training a model on 152 different
graph datasets comprising over 7.4 million nodes and 189 million edges,
establishing the first set of scaling laws for multi-graph pretraining on
datasets spanning many domains (e.g., molecules, citation and product graphs).
Our results show that pretraining on a diverse array of real and synthetic
graphs improves the model's adaptability and stability, while performing
competitively with state-of-the-art specialist models. This work illustrates
that multi-graph pretraining can significantly reduce the burden imposed by the
current graph training paradigm, unlocking new capabilities for the field of
graph neural networks by creating a single generalist model that performs
competitively across a wide range of datasets and tasks.",2024-07-16,"Divyansha Lachi, Mehdi Azabou, Vinam Arora, Eva Dyer",http://arxiv.org/pdf/2407.11907v1,cs.LG
Combining Wasserstein-1 and Wasserstein-2 proximals: robust manifold learning via well-posed generative flows,"We formulate well-posed continuous-time generative flows for learning
distributions that are supported on low-dimensional manifolds through
Wasserstein proximal regularizations of $f$-divergences. Wasserstein-1 proximal
operators regularize $f$-divergences so that singular distributions can be
compared. Meanwhile, Wasserstein-2 proximal operators regularize the paths of
the generative flows by adding an optimal transport cost, i.e., a kinetic
energy penalization. Via mean-field game theory, we show that the combination
of the two proximals is critical for formulating well-posed generative flows.
Generative flows can be analyzed through optimality conditions of a mean-field
game (MFG), a system of a backward Hamilton-Jacobi (HJ) and a forward
continuity partial differential equations (PDEs) whose solution characterizes
the optimal generative flow. For learning distributions that are supported on
low-dimensional manifolds, the MFG theory shows that the Wasserstein-1
proximal, which addresses the HJ terminal condition, and the Wasserstein-2
proximal, which addresses the HJ dynamics, are both necessary for the
corresponding backward-forward PDE system to be well-defined and have a unique
solution with provably linear flow trajectories. This implies that the
corresponding generative flow is also unique and can therefore be learned in a
robust manner even for learning high-dimensional distributions supported on
low-dimensional manifolds. The generative flows are learned through adversarial
training of continuous-time flows, which bypasses the need for reverse
simulation. We demonstrate the efficacy of our approach for generating
high-dimensional images without the need to resort to autoencoders or
specialized architectures.",2024-07-16,"Hyemin Gu, Markos A. Katsoulakis, Luc Rey-Bellet, Benjamin J. Zhang",http://arxiv.org/pdf/2407.11901v1,cs.LG
InstructAV: Instruction Fine-tuning Large Language Models for Authorship Verification,"Large Language Models (LLMs) have demonstrated remarkable proficiency in a
wide range of NLP tasks. However, when it comes to authorship verification (AV)
tasks, which involve determining whether two given texts share the same
authorship, even advanced models like ChatGPT exhibit notable limitations. This
paper introduces a novel approach, termed InstructAV, for authorship
verification. This approach utilizes LLMs in conjunction with a
parameter-efficient fine-tuning (PEFT) method to simultaneously improve
accuracy and explainability. The distinctiveness of InstructAV lies in its
ability to align classification decisions with transparent and understandable
explanations, representing a significant progression in the field of authorship
verification. Through comprehensive experiments conducted across various
datasets, InstructAV demonstrates its state-of-the-art performance on the AV
task, offering high classification accuracy coupled with enhanced explanation
reliability.",2024-07-16,"Yujia Hu, Zhiqiang Hu, Chun-Wei Seah, Roy Ka-Wei Lee",http://arxiv.org/pdf/2407.12882v1,cs.LG
Deep Learning without Global Optimization by Random Fourier Neural Networks,"We introduce a new training algorithm for deep neural networks that utilize
random complex exponential activation functions. Our approach employs a Markov
Chain Monte Carlo sampling procedure to iteratively train network layers,
avoiding global and gradient-based optimization while maintaining error
control. It consistently attains the theoretical approximation rate for
residual networks with complex exponential activation functions, determined by
network complexity. Additionally, it enables efficient learning of multiscale
and high-frequency features, producing interpretable parameter distributions.
Despite using sinusoidal basis functions, we do not observe Gibbs phenomena in
approximating discontinuous target functions.",2024-07-16,"Owen Davis, Gianluca Geraci, Mohammad Motamed",http://arxiv.org/pdf/2407.11894v2,cs.LG
Learning Confidence Bounds for Classification with Imbalanced Data,"Class imbalance poses a significant challenge in classification tasks, where
traditional approaches often lead to biased models and unreliable predictions.
Undersampling and oversampling techniques have been commonly employed to
address this issue, yet they suffer from inherent limitations stemming from
their simplistic approach such as loss of information and additional biases
respectively. In this paper, we propose a novel framework that leverages
learning theory and concentration inequalities to overcome the shortcomings of
traditional solutions. We focus on understanding the uncertainty in a
class-dependent manner, as captured by confidence bounds that we directly embed
into the learning process. By incorporating class-dependent estimates, our
method can effectively adapt to the varying degrees of imbalance across
different classes, resulting in more robust and reliable classification
outcomes. We empirically show how our framework provides a promising direction
for handling imbalanced data in classification tasks, offering practitioners a
valuable tool for building more accurate and trustworthy models.",2024-07-16,"Matt Clifford, Jonathan Erskine, Alexander Hepburn, Raúl Santos-Rodríguez, Dario Garcia-Garcia",http://arxiv.org/pdf/2407.11878v2,cs.LG
Simplifying the Theory on Over-Smoothing,"Graph convolutions have gained popularity due to their ability to efficiently
operate on data with an irregular geometric structure. However, graph
convolutions cause over-smoothing, which refers to representations becoming
more similar with increased depth. However, many different definitions and
intuitions currently coexist, leading to research efforts focusing on
incompatible directions. This paper attempts to align these directions by
showing that over-smoothing is merely a special case of power iteration. This
greatly simplifies the existing theory on over-smoothing, making it more
accessible. Based on the theory, we provide a novel comprehensive definition of
rank collapse as a generalized form of over-smoothing and introduce the
rank-one distance as a corresponding metric. Our empirical evaluation of 14
commonly used methods shows that more models than were previously known suffer
from this issue.",2024-07-16,Andreas Roth,http://arxiv.org/pdf/2407.11876v2,cs.LG
Variance Norms for Kernelized Anomaly Detection,"We present a unified theory for Mahalanobis-type anomaly detection on Banach
spaces, using ideas from Cameron-Martin theory applied to non-Gaussian
measures. This approach leads to a basis-free, data-driven notion of anomaly
distance through the so-called variance norm of a probability measure, which
can be consistently estimated using empirical measures. Our framework
generalizes the classical $\mathbb{R}^d$, functional $(L^2[0,1])^d$, and
kernelized settings, including the general case of non-injective covariance
operator. We prove that the variance norm depends solely on the inner product
in a given Hilbert space, and hence that the kernelized Mahalanobis distance
can naturally be recovered by working on reproducing kernel Hilbert spaces.
  Using the variance norm, we introduce the notion of a kernelized
nearest-neighbour Mahalanobis distance for semi-supervised anomaly detection.
In an empirical study on 12 real-world datasets, we demonstrate that the
kernelized nearest-neighbour Mahalanobis distance outperforms the traditional
kernelized Mahalanobis distance for multivariate time series anomaly detection,
using state-of-the-art time series kernels such as the signature, global
alignment, and Volterra reservoir kernels. Moreover, we provide an initial
theoretical justification of nearest-neighbour Mahalanobis distances by
developing concentration inequalities in the finite-dimensional Gaussian case.",2024-07-16,"Thomas Cass, Lukas Gonon, Nikita Zozoulenko",http://arxiv.org/pdf/2407.11873v1,cs.LG
Tiled Bit Networks: Sub-Bit Neural Network Compression Through Reuse of Learnable Binary Vectors,"Binary Neural Networks (BNNs) enable efficient deep learning by saving on
storage and computational costs. However, as the size of neural networks
continues to grow, meeting computational requirements remains a challenge. In
this work, we propose a new form of quantization to tile neural network layers
with sequences of bits to achieve sub-bit compression of binary-weighted neural
networks. The method learns binary vectors (i.e. tiles) to populate each layer
of a model via aggregation and reshaping operations. During inference, the
method reuses a single tile per layer to represent the full tensor. We employ
the approach to both fully-connected and convolutional layers, which make up
the breadth of space in most neural architectures. Empirically, the approach
achieves near fullprecision performance on a diverse range of architectures
(CNNs, Transformers, MLPs) and tasks (classification, segmentation, and time
series forecasting) with up to an 8x reduction in size compared to
binary-weighted models. We provide two implementations for Tiled Bit Networks:
1) we deploy the model to a microcontroller to assess its feasibility in
resource-constrained environments, and 2) a GPU-compatible inference kernel to
facilitate the reuse of a single tile per layer in memory.",2024-07-16,"Matt Gorbett, Hossein Shirazi, Indrakshi Ray",http://arxiv.org/pdf/2407.12075v1,cs.LG
Unlearning Targeted Information via Single Layer Unlearning Gradient,"Unauthorized privacy-related and copyrighted content generation using
generative-AI is becoming a significant concern for human society, raising
ethical, legal, and privacy issues that demand urgent attention. The EU's
General Data Protection Regulation (GDPR) include a ""right to be forgotten,""
which allows individuals to request the deletion of their personal data.
However, this primarily applies to data stored in traditional databases, not AI
models. Recently, machine unlearning techniques have arise that attempt to
eliminate the influence of sensitive content used during AI model training, but
they often require extensive updates to the deployed systems and incur
substantial computational costs. In this work, we propose a novel and efficient
method called Single Layer Unlearning Gradient (SLUG), that can unlearn
targeted information by updating targeted layers of a model using a one-time
gradient computation. Our method is highly modular and enables the selective
removal of multiple sensitive concepts, such as celebrity names and copyrighted
content, from the generated outputs of widely used foundation models (e.g.,
CLIP) and generative models (e.g., Stable Diffusion). Broadly, our method
ensures AI-generated content complies with privacy regulations and intellectual
property laws, fostering responsible use of generative models, mitigating legal
risks and promoting a trustworthy, socially responsible AI ecosystem.",2024-07-16,"Zikui Cai, Yaoteng Tan, M. Salman Asif",http://arxiv.org/pdf/2407.11867v2,cs.LG
What Makes a Meme a Meme? Identifying Memes for Memetics-Aware Dataset Creation,"Warning: This paper contains memes that may be offensive to some readers.
  Multimodal Internet Memes are now a ubiquitous fixture in online discourse.
One strand of meme-based research is the classification of memes according to
various affects, such as sentiment and hate, supported by manually compiled
meme datasets. Understanding the unique characteristics of memes is crucial for
meme classification. Unlike other user-generated content, memes spread via
memetics, i.e. the process by which memes are imitated and transformed into
symbols used to create new memes. In effect, there exists an ever-evolving pool
of visual and linguistic symbols that underpin meme culture and are crucial to
interpreting the meaning of individual memes. The current approach of training
supervised learning models on static datasets, without taking memetics into
account, limits the depth and accuracy of meme interpretation. We argue that
meme datasets must contain genuine memes, as defined via memetics, so that
effective meme classifiers can be built. In this work, we develop a meme
identification protocol which distinguishes meme from non-memetic content by
recognising the memetics within it. We apply our protocol to random samplings
of the leading 7 meme classification datasets and observe that more than half
(50. 4\%) of the evaluated samples were found to contain no signs of memetics.
Our work also provides a meme typology grounded in memetics, providing the
basis for more effective approaches to the interpretation of memes and the
creation of meme datasets.",2024-07-16,"Muzhaffar Hazman, Susan McKeever, Josephine Griffith",http://arxiv.org/pdf/2407.11861v1,cs.LG
Scaling Sign Language Translation,"Sign language translation (SLT) addresses the problem of translating
information from a sign language in video to a spoken language in text.
Existing studies, while showing progress, are often limited to narrow domains
and/or few sign languages and struggle with open-domain tasks. In this paper,
we push forward the frontier of SLT by scaling pretraining data, model size,
and number of translation directions. We perform large-scale SLT pretraining on
different data including 1) noisy multilingual YouTube SLT data, 2) parallel
text corpora, and 3) SLT data augmented by translating video captions to other
languages with off-the-shelf machine translation models. We unify different
pretraining tasks with task-specific prompts under the encoder-decoder
architecture, and initialize the SLT model with pretrained (m/By)T5 models
across model sizes. SLT pretraining results on How2Sign and FLEURS-ASL#0 (ASL
to 42 spoken languages) demonstrate the significance of data/model scaling and
cross-lingual cross-modal transfer, as well as the feasibility of zero-shot
SLT. We finetune the pretrained SLT models on 5 downstream open-domain SLT
benchmarks covering 5 sign languages. Experiments show substantial quality
improvements over the vanilla baselines, surpassing the previous
state-of-the-art (SOTA) by wide margins.",2024-07-16,"Biao Zhang, Garrett Tanzer, Orhan Firat",http://arxiv.org/pdf/2407.11855v1,cs.LG
Enhancing Parameter Efficiency and Generalization in Large-Scale Models: A Regularized and Masked Low-Rank Adaptation Approach,"Large pre-trained models, such as large language models (LLMs), present
significant resource challenges for fine-tuning due to their extensive
parameter sizes, especially for applications in mobile systems. To address
this, Low-Rank Adaptation (LoRA) has been developed to reduce resource
consumption while maintaining satisfactory fine-tuning results. Despite its
effectiveness, the original LoRA method faces challenges of suboptimal
performance and overfitting. This paper investigates the intrinsic dimension of
the matrix updates approximated by the LoRA method and reveals the performance
benefits of increasing this intrinsic dimension. By employing regularization
and a gradient masking method that encourages higher intrinsic dimension, the
proposed method, termed Regularized and Masked LoRA (RM-LoRA), achieves
superior generalization performance with the same or lower trainable parameter
budget compared to the original LoRA and its latest variants across various
open-source vision and language datasets.",2024-07-16,"Yuzhu Mao, Siqi Ping, Zihao Zhao, Yang Liu, Wenbo Ding",http://arxiv.org/pdf/2407.12074v1,cs.LG
Variational Randomized Smoothing for Sample-Wise Adversarial Robustness,"Randomized smoothing is a defensive technique to achieve enhanced robustness
against adversarial examples which are small input perturbations that degrade
the performance of neural network models. Conventional randomized smoothing
adds random noise with a fixed noise level for every input sample to smooth out
adversarial perturbations. This paper proposes a new variational framework that
uses a per-sample noise level suitable for each input by introducing a noise
level selector. Our experimental results demonstrate enhancement of empirical
robustness against adversarial attacks. We also provide and analyze the
certified robustness for our sample-wise smoothing method.",2024-07-16,"Ryo Hase, Ye Wang, Toshiaki Koike-Akino, Jing Liu, Kieran Parsons",http://arxiv.org/pdf/2407.11844v1,cs.LG
LoFTI: Localization and Factuality Transfer to Indian Locales,"Large language models (LLMs) encode vast amounts of world knowledge acquired
via training on large web-scale datasets crawled from the internet. However,
these datasets typically exhibit a geographical bias towards English-speaking
Western countries. This results in LLMs producing biased or hallucinated
responses to queries that require answers localized to other geographical
regions. In this work, we introduce a new benchmark named LoFTI (Localization
and Factuality Transfer to Indian Locales) that can be used to evaluate an
LLM's localization and factual text transfer capabilities. LoFTI consists of
factual statements about entities in source and target locations; the source
locations are spread across the globe and the target locations are all within
India with varying degrees of hyperlocality (country, states, cities). The
entities span a wide variety of categories. We use LoFTI to evaluate Mixtral,
GPT-4 and two other Mixtral-based approaches well-suited to the task of
localized factual transfer. We demonstrate that LoFTI is a high-quality
evaluation benchmark and all the models, including GPT-4, produce skewed
results across varying levels of hyperlocality.",2024-07-16,"Sona Elza Simon, Soumen Kumar Mondal, Abhishek Singhania, Sayambhu Sen, Preethi Jyothi",http://arxiv.org/pdf/2407.11833v1,cs.LG
Approximating the Number of Relevant Variables in a Parity Implies Proper Learning,"Consider the model where we can access a parity function through random
uniform labeled examples in the presence of random classification noise. In
this paper, we show that approximating the number of relevant variables in the
parity function is as hard as properly learning parities.
  More specifically, let $\gamma:{\mathbb R}^+\to {\mathbb R}^+$, where
$\gamma(x) \ge x$, be any strictly increasing function. In our first result, we
show that from any polynomial-time algorithm that returns a
$\gamma$-approximation, $D$ (i.e., $\gamma^{-1}(d(f)) \leq D \leq
\gamma(d(f))$), of the number of relevant variables~$d(f)$ for any parity $f$,
we can, in polynomial time, construct a solution to the long-standing open
problem of polynomial-time learning $k(n)$-sparse parities (parities with
$k(n)\le n$ relevant variables), where $k(n) = \omega_n(1)$.
  In our second result, we show that from any $T(n)$-time algorithm that, for
any parity $f$, returns a $\gamma$-approximation of the number of relevant
variables $d(f)$ of $f$, we can, in polynomial time, construct a
$poly(\Gamma(n))T(\Gamma(n)^2)$-time algorithm that properly learns parities,
where $\Gamma(x)=\gamma(\gamma(x))$.
  If $T(\Gamma(n)^2)=\exp({o(n/\log n)})$, this would resolve another
long-standing open problem of properly learning parities in the presence of
random classification noise in time $\exp({o(n/\log n)})$.",2024-07-16,"Nader H. Bshouty, George Haddad",http://arxiv.org/pdf/2407.11832v1,cs.LG
Vibravox: A Dataset of French Speech Captured with Body-conduction Audio Sensors,"Vibravox is a dataset compliant with the General Data Protection Regulation
(GDPR) containing audio recordings using five different body-conduction audio
sensors: two in-ear microphones, two bone conduction vibration pickups, and a
laryngophone. The dataset also includes audio data from an airborne microphone
used as a reference. The Vibravox corpus contains 45 hours per sensor of speech
samples and physiological sounds recorded by 188 participants under different
acoustic conditions imposed by a high order ambisonics 3D spatializer.
Annotations about the recording conditions and linguistic transcriptions are
also included in the corpus. We conducted a series of experiments on various
speech-related tasks, including speech recognition, speech enhancement, and
speaker verification. These experiments were carried out using state-of-the-art
models to evaluate and compare their performances on signals captured by the
different audio sensors offered by the Vibravox dataset, with the aim of
gaining a better grasp of their individual characteristics.",2024-07-16,"Julien Hauret, Malo Olivier, Thomas Joubaud, Christophe Langrenne, Sarah Poirée, Véronique Zimpfer, Éric Bavu",http://arxiv.org/pdf/2407.11828v4,cs.LG
Harmonizing Safety and Speed: A Human-Algorithm Approach to Enhance the FDA's Medical Device Clearance Policy,"The United States Food and Drug Administration's (FDA's) Premarket
Notification 510(K) pathway allows manufacturers to gain approval for a medical
device by demonstrating its substantial equivalence to another legally marketed
device. However, the inherent ambiguity of this regulatory procedure has led to
high recall rates for many devices cleared through this pathway. This trend has
raised significant concerns regarding the efficacy of the FDA's current
approach, prompting a reassessment of the 510(K) regulatory framework. In this
paper, we develop a combined human-algorithm approach to assist the FDA in
improving its 510(k) medical device clearance process by reducing the risk of
potential recalls and the workload imposed on the FDA. We first develop machine
learning methods to estimate the risk of recall of 510(k) medical devices based
on the information available at the time of submission. We then propose a
data-driven clearance policy that recommends acceptance, rejection, or deferral
to FDA's committees for in-depth evaluation. We conduct an empirical study
using a unique large-scale dataset of over 31,000 medical devices and 12,000
national and international manufacturers from over 65 countries that we
assembled based on data sources from the FDA and Centers for Medicare and
Medicaid Service (CMS). A conservative evaluation of our proposed policy based
on this data shows a 38.9% improvement in the recall rate and a 43.0% reduction
in the FDA's workload. Our analyses also indicate that implementing our policy
could result in significant annual cost-savings ranging between \$2.4 billion
and \$2.7 billion, which highlights the value of using a holistic and
data-driven approach to improve the FDA's current 510(K) medical device
evaluation pathway.",2024-07-16,"Mohammad Zhalechian, Soroush Saghafian, Omar Robles",http://arxiv.org/pdf/2407.11823v1,cs.LG
Boosting drug-disease association prediction for drug repositioning via dual-feature extraction and cross-dual-domain decoding,"The extraction of biomedical data has significant academic and practical
value in contemporary biomedical sciences. In recent years, drug repositioning,
a cost-effective strategy for drug development by discovering new indications
for approved drugs, has gained increasing attention. However, many existing
drug repositioning methods focus on mining information from adjacent nodes in
biomedical networks without considering the potential inter-relationships
between the feature spaces of drugs and diseases. This can lead to inaccurate
encoding, resulting in biased mined drug-disease association information. To
address this limitation, we propose a new model called Dual-Feature Drug
Repurposing Neural Network (DFDRNN). DFDRNN allows the mining of two features
(similarity and association) from the drug-disease biomedical networks to
encode drugs and diseases. A self-attention mechanism is utilized to extract
neighbor feature information. It incorporates two dual-feature extraction
modules: the single-domain dual-feature extraction (SDDFE) module for
extracting features within a single domain (drugs or diseases) and the
cross-domain dual-feature extraction (CDDFE) module for extracting features
across domains. By utilizing these modules, we ensure more appropriate encoding
of drugs and diseases. A cross-dual-domain decoder is also designed to predict
drug-disease associations in both domains. Our proposed DFDRNN model
outperforms six state-of-the-art methods on four benchmark datasets, achieving
an average AUROC of 0.946 and an average AUPR of 0.597. Case studies on two
diseases show that the proposed DFDRNN model can be applied in real-world
scenarios, demonstrating its significant potential in drug repositioning.",2024-07-16,"Enqiang Zhu, Xiang Li, Chanjuan Liu, Nikhil R. Pal",http://arxiv.org/pdf/2407.11812v4,cs.LG
Scalable and Reliable Over-the-Air Federated Edge Learning,"Federated edge learning (FEEL) has emerged as a core paradigm for large-scale
optimization. However, FEEL still suffers from a communication bottleneck due
to the transmission of high-dimensional model updates from the clients to the
federator. Over-the-air computation (AirComp) leverages the additive property
of multiple-access channels by aggregating the clients' updates over the
channel to save communication resources. While analog uncoded transmission can
benefit from the increased signal-to-noise ratio (SNR) due to the simultaneous
transmission of many clients, potential errors may severely harm the learning
process for small SNRs. To alleviate this problem, channel coding approaches
were recently proposed for AirComp in FEEL. However, their error-correction
capability degrades with an increasing number of clients. We propose a digital
lattice-based code construction with constant error-correction capabilities in
the number of clients, and compare to nested-lattice codes, well-known for
their optimal rate and power efficiency in the point-to-point AWGN channel.",2024-07-16,"Maximilian Egger, Christoph Hofmeister, Cem Kaya, Rawad Bitar, Antonia Wachter-Zeh",http://arxiv.org/pdf/2407.11807v1,cs.LG
PipeInfer: Accelerating LLM Inference using Asynchronous Pipelined Speculation,"Inference of Large Language Models (LLMs) across computer clusters has become
a focal point of research in recent times, with many acceleration techniques
taking inspiration from CPU speculative execution. These techniques reduce
bottlenecks associated with memory bandwidth, but also increase end-to-end
latency per inference run, requiring high speculation acceptance rates to
improve performance. Combined with a variable rate of acceptance across tasks,
speculative inference techniques can result in reduced performance.
Additionally, pipeline-parallel designs require many user requests to maintain
maximum utilization. As a remedy, we propose PipeInfer, a pipelined speculative
acceleration technique to reduce inter-token latency and improve system
utilization for single-request scenarios while also improving tolerance to low
speculation acceptance rates and low-bandwidth interconnects. PipeInfer
exhibits up to a 2.15$\times$ improvement in generation speed over standard
speculative inference. PipeInfer achieves its improvement through Continuous
Asynchronous Speculation and Early Inference Cancellation, the former improving
latency and generation speed by running single-token inference simultaneously
with several speculative runs, while the latter improves speed and latency by
skipping the computation of invalidated runs, even in the middle of inference.",2024-07-16,"Branden Butler, Sixing Yu, Arya Mazaheri, Ali Jannesari",http://arxiv.org/pdf/2407.11798v2,cs.LG
Characterizing and Understanding HGNN Training on GPUs,"Owing to their remarkable representation capabilities for heterogeneous graph
data, Heterogeneous Graph Neural Networks (HGNNs) have been widely adopted in
many critical real-world domains such as recommendation systems and medical
analysis. Prior to their practical application, identifying the optimal HGNN
model parameters tailored to specific tasks through extensive training is a
time-consuming and costly process. To enhance the efficiency of HGNN training,
it is essential to characterize and analyze the execution semantics and
patterns within the training process to identify performance bottlenecks. In
this study, we conduct an in-depth quantification and analysis of two
mainstream HGNN training scenarios, including single-GPU and multi-GPU
distributed training. Based on the characterization results, we disclose the
performance bottlenecks and their underlying causes in different HGNN training
scenarios and provide optimization guidelines from both software and hardware
perspectives.",2024-07-16,"Dengke Han, Mingyu Yan, Xiaochun Ye, Dongrui Fan",http://arxiv.org/pdf/2407.11790v4,cs.LG
Defining 'Good': Evaluation Framework for Synthetic Smart Meter Data,"Access to granular demand data is essential for the net zero transition; it
allows for accurate profiling and active demand management as our reliance on
variable renewable generation increases. However, public release of this data
is often impossible due to privacy concerns. Good quality synthetic data can
circumnavigate this issue. Despite significant research on generating synthetic
smart meter data, there is still insufficient work on creating a consistent
evaluation framework. In this paper, we investigate how common frameworks used
by other industries leveraging synthetic data, can be applied to synthetic
smart meter data, such as fidelity, utility and privacy. We also recommend
specific metrics to ensure that defining aspects of smart meter data are
preserved and test the extent to which privacy can be protected using
differential privacy. We show that standard privacy attack methods like
reconstruction or membership inference attacks are inadequate for assessing
privacy risks of smart meter datasets. We propose an improved method by
injecting training data with implausible outliers, then launching privacy
attacks directly on these outliers. The choice of $\epsilon$ (a metric of
privacy loss) significantly impacts privacy risk, highlighting the necessity of
performing these explicit privacy tests when making trade-offs between fidelity
and privacy.",2024-07-16,"Sheng Chai, Gus Chadney, Charlot Avery, Phil Grunewald, Pascal Van Hentenryck, Priya L. Donti",http://arxiv.org/pdf/2407.11785v1,cs.LG
Cryptocurrency Price Forecasting Using XGBoost Regressor and Technical Indicators,"The rapid growth of the stock market has attracted many investors due to its
potential for significant profits. However, predicting stock prices accurately
is difficult because financial markets are complex and constantly changing.
This is especially true for the cryptocurrency market, which is known for its
extreme volatility, making it challenging for traders and investors to make
wise and profitable decisions. This study introduces a machine learning
approach to predict cryptocurrency prices. Specifically, we make use of
important technical indicators such as Exponential Moving Average (EMA) and
Moving Average Convergence Divergence (MACD) to train and feed the XGBoost
regressor model. We demonstrate our approach through an analysis focusing on
the closing prices of Bitcoin cryptocurrency. We evaluate the model's
performance through various simulations, showing promising results that suggest
its usefulness in aiding/guiding cryptocurrency traders and investors in
dynamic market conditions.",2024-07-16,"Abdelatif Hafid, Maad Ebrahim, Ali Alfatemi, Mohamed Rahouti, Diogo Oliveira",http://arxiv.org/pdf/2407.11786v1,cs.LG
Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development,"The emergence of multimodal large models has advanced artificial
intelligence, introducing unprecedented levels of performance and
functionality. However, optimizing these models remains challenging due to
historically isolated paths of model-centric and data-centric developments,
leading to suboptimal outcomes and inefficient resource utilization. In
response, we present a new sandbox suite tailored for integrated data-model
co-development. This sandbox provides a feedback-driven experimental platform,
enabling cost-effective iteration and guided refinement of both data and
models. Our proposed ``Probe-Analyze-Refine'' workflow, validated through
practical use cases on multimodal tasks such as image-text pre-training with
CLIP, image-to-text generation with LLaVA-like models, and text-to-video
generation with DiT-based models, yields transferable and notable performance
boosts, such as topping the VBench leaderboard. Extensive experiments also
uncover fruitful insights into the interplay between data quality, diversity,
model behavior, and computational costs. All codes, datasets, and models are
open-sourced to foster future research and applications that would otherwise be
infeasible due to the lack of a dedicated co-development infrastructure.",2024-07-16,"Daoyuan Chen, Haibin Wang, Yilun Huang, Ce Ge, Yaliang Li, Bolin Ding, Jingren Zhou",http://arxiv.org/pdf/2407.11784v2,cs.LG
Local Feature Selection without Label or Feature Leakage for Interpretable Machine Learning Predictions,"Local feature selection in machine learning provides instance-specific
explanations by focusing on the most relevant features for each prediction,
enhancing the interpretability of complex models. However, such methods tend to
produce misleading explanations by encoding additional information in their
selections. In this work, we attribute the problem of misleading selections by
formalizing the concepts of label and feature leakage. We rigorously derive the
necessary and sufficient conditions under which we can guarantee no leakage,
and show existing methods do not meet these conditions. Furthermore, we propose
the first local feature selection method that is proven to have no leakage
called SUWR. Our experimental results indicate that SUWR is less prone to
overfitting and combines state-of-the-art predictive performance with high
feature-selection sparsity. Our generic and easily extendable formal approach
provides a strong theoretical basis for future work on interpretability with
reliable explanations.",2024-07-16,"Harrie Oosterhuis, Lijun Lyu, Avishek Anand",http://arxiv.org/pdf/2407.11778v1,cs.LG
XEdgeAI: A Human-centered Industrial Inspection Framework with Data-centric Explainable Edge AI Approach,"Recent advancements in deep learning have significantly improved visual
quality inspection and predictive maintenance within industrial settings.
However, deploying these technologies on low-resource edge devices poses
substantial challenges due to their high computational demands and the inherent
complexity of Explainable AI (XAI) methods. This paper addresses these
challenges by introducing a novel XAI-integrated Visual Quality Inspection
framework that optimizes the deployment of semantic segmentation models on
low-resource edge devices. Our framework incorporates XAI and the Large Vision
Language Model to deliver human-centered interpretability through visual and
textual explanations to end-users. This is crucial for end-user trust and model
interpretability. We outline a comprehensive methodology consisting of six
fundamental modules: base model fine-tuning, XAI-based explanation generation,
evaluation of XAI approaches, XAI-guided data augmentation, development of an
edge-compatible model, and the generation of understandable visual and textual
explanations. Through XAI-guided data augmentation, the enhanced model
incorporating domain expert knowledge with visual and textual explanations is
successfully deployed on mobile devices to support end-users in real-world
scenarios. Experimental results showcase the effectiveness of the proposed
framework, with the mobile model achieving competitive accuracy while
significantly reducing model size. This approach paves the way for the broader
adoption of reliable and interpretable AI tools in critical industrial
applications, where decisions must be both rapid and justifiable. Our code for
this work can be found at https://github.com/Analytics-Everywhere-Lab/vqixai.",2024-07-16,"Truong Thanh Hung Nguyen, Phuc Truong Loc Nguyen, Hung Cao",http://arxiv.org/pdf/2407.11771v2,cs.LG
ITI-IQA: a Toolbox for Heterogeneous Univariate and Multivariate Missing Data Imputation Quality Assessment,"Missing values are a major challenge in most data science projects working on
real data. To avoid losing valuable information, imputation methods are used to
fill in missing values with estimates, allowing the preservation of samples or
variables that would otherwise be discarded. However, if the process is not
well controlled, imputation can generate spurious values that introduce
uncertainty and bias into the learning process. The abundance of univariate and
multivariate imputation techniques, along with the complex trade-off between
data reliability and preservation, makes it difficult to determine the best
course of action to tackle missing values. In this work, we present ITI-IQA
(Imputation Quality Assessment), a set of utilities designed to assess the
reliability of various imputation methods, select the best imputer for any
feature or group of features, and filter out features that do not meet quality
criteria. Statistical tests are conducted to evaluate the suitability of every
tested imputer, ensuring that no new biases are introduced during the
imputation phase. The result is a trainable pipeline of filters and imputation
methods that streamlines the process of dealing with missing data, supporting
different data types: continuous, discrete, binary, and categorical. The
toolbox also includes a suite of diagnosing methods and graphical tools to
check measurements and results during and after handling missing data.",2024-07-16,"Pedro Pons-Suñer, Laura Arnal, J. Ramón Navarro-Cerdán, François Signol",http://arxiv.org/pdf/2407.11767v1,cs.LG
Relaxing Graph Transformers for Adversarial Attacks,"Existing studies have shown that Graph Neural Networks (GNNs) are vulnerable
to adversarial attacks. Even though Graph Transformers (GTs) surpassed
Message-Passing GNNs on several benchmarks, their adversarial robustness
properties are unexplored. However, attacking GTs is challenging due to their
Positional Encodings (PEs) and special attention mechanisms which can be
difficult to differentiate. We overcome these challenges by targeting three
representative architectures based on (1) random-walk PEs, (2)
pair-wise-shortest-path PEs, and (3) spectral PEs - and propose the first
adaptive attacks for GTs. We leverage our attacks to evaluate robustness to (a)
structure perturbations on node classification; and (b) node injection attacks
for (fake-news) graph classification. Our evaluation reveals that they can be
catastrophically fragile and underlines our work's importance and the necessity
for adaptive attacks.",2024-07-16,"Philipp Foth, Lukas Gosch, Simon Geisler, Leo Schwinn, Stephan Günnemann",http://arxiv.org/pdf/2407.11764v1,cs.LG
Enhancing Split Computing and Early Exit Applications through Predefined Sparsity,"In the past decade, Deep Neural Networks (DNNs) achieved state-of-the-art
performance in a broad range of problems, spanning from object classification
and action recognition to smart building and healthcare. The flexibility that
makes DNNs such a pervasive technology comes at a price: the computational
requirements preclude their deployment on most of the resource-constrained edge
devices available today to solve real-time and real-world tasks. This paper
introduces a novel approach to address this challenge by combining the concept
of predefined sparsity with Split Computing (SC) and Early Exit (EE). In
particular, SC aims at splitting a DNN with a part of it deployed on an edge
device and the rest on a remote server. Instead, EE allows the system to stop
using the remote server and rely solely on the edge device's computation if the
answer is already good enough. Specifically, how to apply such a predefined
sparsity to a SC and EE paradigm has never been studied. This paper studies
this problem and shows how predefined sparsity significantly reduces the
computational, storage, and energy burdens during the training and inference
phases, regardless of the hardware platform. This makes it a valuable approach
for enhancing the performance of SC and EE applications. Experimental results
showcase reductions exceeding 4x in storage and computational complexity
without compromising performance. The source code is available at
https://github.com/intelligolabs/sparsity_sc_ee.",2024-07-16,"Luigi Capogrosso, Enrico Fraccaroli, Giulio Petrozziello, Francesco Setti, Samarjit Chakraborty, Franco Fummi, Marco Cristani",http://arxiv.org/pdf/2407.11763v1,cs.LG
Self-Regulating Random Walks for Resilient Decentralized Learning on Graphs,"Consider the setting of multiple random walks (RWs) on a graph executing a
certain computational task. For instance, in decentralized learning via RWs, a
model is updated at each iteration based on the local data of the visited node
and then passed to a randomly chosen neighbor. RWs can fail due to node or link
failures. The goal is to maintain a desired number of RWs to ensure failure
resilience. Achieving this is challenging due to the lack of a central entity
to track which RWs have failed to replace them with new ones by forking
(duplicating) surviving ones. Without duplications, the number of RWs will
eventually go to zero, causing a catastrophic failure of the system. We propose
two decentralized algorithms called DecAFork and DecAFork+ that can maintain
the number of RWs in the graph around a desired value even in the presence of
arbitrary RW failures. Nodes continuously estimate the number of surviving RWs
by estimating their return time distribution and fork the RWs when failures are
likely to happen. DecAFork+ additionally allows terminations to avoid
overloading the network by forking too many RWs. We present extensive numerical
simulations that show the performance of DecAFork and DecAFork+ regarding fast
detection and reaction to failures compared to a baseline, and establish
theoretical guarantees on the performance of both algorithms.",2024-07-16,"Maximilian Egger, Rawad Bitar, Ghadir Ayache, Antonia Wachter-Zeh, Salim El Rouayheb",http://arxiv.org/pdf/2407.11762v2,cs.LG
Overfitting In Contrastive Learning?,"Overfitting describes a machine learning phenomenon where the model fits too
closely to the training data, resulting in poor generalization. While this
occurrence is thoroughly documented for many forms of supervised learning, it
is not well examined in the context of unsupervised learning. In this work we
examine the nature of overfitting in unsupervised contrastive learning. We show
that overfitting can indeed occur and the mechanism behind overfitting.",2024-07-16,"Zachary Rabin, Jim Davis, Benjamin Lewis, Matthew Scherreik",http://arxiv.org/pdf/2407.15863v2,cs.LG
A Theoretical Formulation of Many-body Message Passing Neural Networks,"We present many-body Message Passing Neural Network (MPNN) framework that
models higher-order node interactions ($\ge 2$ nodes). We model higher-order
terms as tree-shaped motifs, comprising a central node with its neighborhood,
and apply localized spectral filters on motif Laplacian, weighted by global
edge Ricci curvatures. We prove our formulation is invariant to neighbor node
permutation, derive its sensitivity bound, and bound the range of learned graph
potential. We run regression on graph energies to demonstrate that it scales
well with deeper and wider network topology, and run classification on
synthetic graph datasets with heterophily and show its consistently high
Dirichlet energy growth.
  We open-source our code at https://github.com/JThh/Many-Body-MPNN.",2024-07-16,Jiatong Han,http://arxiv.org/pdf/2407.11756v1,cs.LG
A Channel Attention-Driven Hybrid CNN Framework for Paddy Leaf Disease Detection,"Farmers face various challenges when it comes to identifying diseases in rice
leaves during their early stages of growth, which is a major reason for poor
produce. Therefore, early and accurate disease identification is important in
agriculture to avoid crop loss and improve cultivation. In this research, we
propose a novel hybrid deep learning (DL) classifier designed by extending the
Squeeze-and-Excitation network architecture with a channel attention mechanism
and the Swish ReLU activation function. The channel attention mechanism in our
proposed model identifies the most important feature channels required for
classification during feature extraction and selection. The dying ReLU problem
is mitigated by utilizing the Swish ReLU activation function, and the
Squeeze-andExcitation blocks improve information propagation and cross-channel
interaction. Upon evaluation, our model achieved a high F1-score of 99.76% and
an accuracy of 99.74%, surpassing the performance of existing models. These
outcomes demonstrate the potential of state-of-the-art DL techniques in
agriculture, contributing to the advancement of more efficient and reliable
disease detection systems.",2024-07-16,"Pandiyaraju V, Shravan Venkatraman, Abeshek A, Pavan Kumar S, Aravintakshan S A, Senthil Kumar A M, Kannan A",http://arxiv.org/pdf/2407.11753v1,cs.LG
Why long model-based rollouts are no reason for bad Q-value estimates,"This paper explores the use of model-based offline reinforcement learning
with long model rollouts. While some literature criticizes this approach due to
compounding errors, many practitioners have found success in real-world
applications. The paper aims to demonstrate that long rollouts do not
necessarily result in exponentially growing errors and can actually produce
better Q-value estimates than model-free methods. These findings can
potentially enhance reinforcement learning techniques.",2024-07-16,"Philipp Wissmann, Daniel Hein, Steffen Udluft, Volker Tresp",http://arxiv.org/pdf/2407.11751v1,cs.LG
OAM-TCD: A globally diverse dataset of high-resolution tree cover maps,"Accurately quantifying tree cover is an important metric for ecosystem
monitoring and for assessing progress in restored sites. Recent works have
shown that deep learning-based segmentation algorithms are capable of
accurately mapping trees at country and continental scales using
high-resolution aerial and satellite imagery. Mapping at high (ideally
sub-meter) resolution is necessary to identify individual trees, however there
are few open-access datasets containing instance level annotations and those
that exist are small or not geographically diverse. We present a novel
open-access dataset for individual tree crown delineation (TCD) in
high-resolution aerial imagery sourced from OpenAerialMap (OAM). Our dataset,
OAM-TCD, comprises 5072 2048x2048 px images at 10 cm/px resolution with
associated human-labeled instance masks for over 280k individual and 56k groups
of trees. By sampling imagery from around the world, we are able to better
capture the diversity and morphology of trees in different terrestrial biomes
and in both urban and natural environments. Using our dataset, we train
reference instance and semantic segmentation models that compare favorably to
existing state-of-the-art models. We assess performance through k-fold
cross-validation and comparison with existing datasets; additionally we
demonstrate compelling results on independent aerial imagery captured over
Switzerland and compare to municipal tree inventories and LIDAR-derived canopy
maps in the city of Zurich. Our dataset, models and training/benchmark code are
publicly released under permissive open-source licenses: Creative Commons
(majority CC BY 4.0), and Apache 2.0 respectively.",2024-07-16,"Josh Veitch-Michaelis, Andrew Cottam, Daniella Schweizer, Eben N. Broadbent, David Dao, Ce Zhang, Angelica Almeyda Zambrano, Simeon Max",http://arxiv.org/pdf/2407.11743v1,cs.LG
ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection,"In open-set semi-supervised learning (OSSL), we consider unlabeled datasets
that may contain unknown classes. Existing OSSL methods often use the softmax
confidence for classifying data as in-distribution (ID) or out-of-distribution
(OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD
classification, without considering the statistics of the problem. We propose a
new score for ID/OOD classification based on angles in feature space between
data and an ID subspace. Moreover, we propose an approach to estimate the
conditional distributions of scores given ID or OOD data, enabling
probabilistic predictions of data being ID or OOD. These components are put
together in a framework for OSSL, termed \emph{ProSub}, that is experimentally
shown to reach SOTA performance on several benchmark problems. Our code is
available at https://github.com/walline/prosub.",2024-07-16,"Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand",http://arxiv.org/pdf/2407.11735v1,cs.LG
Multi-Modal and Multi-Attribute Generation of Single Cells with CFGen,"Generative modeling of single-cell RNA-seq data is crucial for tasks like
trajectory inference, batch effect removal, and simulation of realistic
cellular data. However, recent deep generative models simulating synthetic
single cells from noise operate on pre-processed continuous gene expression
approximations, overlooking the discrete nature of single-cell data, which
limits their effectiveness and hinders the incorporation of robust noise
models. Additionally, aspects like controllable multi-modal and multi-label
generation of cellular data remain underexplored. This work introduces CellFlow
for Generation (CFGen), a flow-based conditional generative model that
preserves the inherent discreteness of single-cell data. CFGen generates
whole-genome multi-modal single-cell data reliably, improving the recovery of
crucial biological data characteristics while tackling relevant generative
tasks such as rare cell type augmentation and batch correction. We also
introduce a novel framework for compositional data generation using Flow
Matching. By showcasing CFGen on a diverse set of biological datasets and
settings, we provide evidence of its value to the fields of computational
biology and deep generative models.",2024-07-16,"Alessandro Palma, Till Richter, Hanyi Zhang, Manuel Lubetzki, Alexander Tong, Andrea Dittadi, Fabian Theis",http://arxiv.org/pdf/2407.11734v2,cs.LG
Exploring Quantization for Efficient Pre-Training of Transformer Language Models,"The increasing scale of Transformer models has led to an increase in their
pre-training computational requirements. While quantization has proven to be
effective after pre-training and during fine-tuning, applying quantization in
Transformers during pre-training has remained largely unexplored at scale for
language modeling. This study aims to explore the impact of quantization for
efficient pre-training of Transformers, with a focus on linear layer
components. By systematically applying straightforward linear quantization to
weights, activations, gradients, and optimizer states, we assess its effects on
model efficiency, stability, and performance during training. By offering a
comprehensive recipe of effective quantization strategies to be applied during
the pre-training of Transformers, we promote high training efficiency from
scratch while retaining language modeling ability. Code is available at
https://github.com/chandar-lab/EfficientLLMs.",2024-07-16,"Kamran Chitsaz, Quentin Fournier, Gonçalo Mordido, Sarath Chandar",http://arxiv.org/pdf/2407.11722v2,cs.LG
NITRO-D: Native Integer-only Training of Deep Convolutional Neural Networks,"Quantization has become increasingly pivotal in addressing the steadily
increasing computational and memory requirements of Deep Neural Networks
(DNNs). By reducing the number of bits used to represent weights and
activations (typically from 32-bit floating-point to 16-bit or 8-bit integers),
quantization reduces the memory footprint, energy consumption, and execution
time of DNN models. However, traditional quantization methods typically focus
on the inference of DNNs, while the training process still relies on
floating-point operations. To date, only one work in the literature has
addressed integer-only training for Multi-Layer Perceptron (MLP) architectures.
This work introduces NITRO-D, a new framework for training arbitrarily deep
integer-only Convolutional Neural Networks (CNNs) that operate entirely in the
integer-only domain for both training and inference. NITRO-D is the first
framework in the literature enabling the training of integer-only CNNs without
the need to introduce a quantization scheme. Specifically, NITRO-D introduces a
novel architecture integrating multiple integer local-loss blocks, which
include the proposed NITRO Scaling Layer and the NITRO-ReLU activation
function. Additionally, it introduces a novel integer-only learning algorithm
derived from Local Error Signals (LES), utilizing IntegerSGD, an optimizer
specifically designed to operate in an integer-only context. NITRO-D is
implemented in an open-source Python library. Extensive experimental
evaluations demonstrate its effectiveness across several state-of-the-art image
recognition datasets. Results show significant performance improvements from
2.47% to 5.96% for integer-only MLP architectures over the state-of-the-art
solution, and the capability of training integer-only CNN architectures with
minimal accuracy degradation from -0.15% to -4.22% compared to floating-point
LES.",2024-07-16,"Alberto Pirillo, Luca Colombo, Manuel Roveri",http://arxiv.org/pdf/2407.11698v2,cs.LG
Global atmospheric data assimilation with multi-modal masked autoencoders,"Global data assimilation enables weather forecasting at all scales and
provides valuable data for studying the Earth system. However, the
computational demands of physics-based algorithms used in operational systems
limits the volume and diversity of observations that are assimilated. Here, we
present ""EarthNet"", a multi-modal foundation model for data assimilation that
learns to predict a global gap-filled atmospheric state solely from satellite
observations. EarthNet is trained as a masked autoencoder that ingests a 12
hour sequence of observations and learns to fill missing data from other
sensors. We show that EarthNet performs a form of data assimilation producing a
global 0.16 degree reanalysis dataset of 3D atmospheric temperature and
humidity at a fraction of the time compared to operational systems. It is shown
that the resulting reanalysis dataset reproduces climatology by evaluating a 1
hour forecast background state against observations. We also show that our 3D
humidity predictions outperform MERRA-2 and ERA5 reanalyses by 10% to 60%
between the middle troposphere and lower stratosphere (5 to 20 km altitude) and
our 3D temperature and humidity are statistically equivalent to the Microwave
integrated Retrieval System (MiRS) observations at nearly every level of the
atmosphere. Our results indicate significant promise in using EarthNet for
high-frequency data assimilation and global weather forecasting.",2024-07-16,"Thomas J. Vandal, Kate Duffy, Daniel McDuff, Yoni Nachmany, Chris Hartshorn",http://arxiv.org/pdf/2407.11696v1,cs.LG
Theoretical Insights into CycleGAN: Analyzing Approximation and Estimation Errors in Unpaired Data Generation,"In this paper, we focus on analyzing the excess risk of the unpaired data
generation model, called CycleGAN. Unlike classical GANs, CycleGAN not only
transforms data between two unpaired distributions but also ensures the
mappings are consistent, which is encouraged by the cycle-consistency term
unique to CycleGAN. The increasing complexity of model structure and the
addition of the cycle-consistency term in CycleGAN present new challenges for
error analysis. By considering the impact of both the model architecture and
training procedure, the risk is decomposed into two terms: approximation error
and estimation error. These two error terms are analyzed separately and
ultimately combined by considering the trade-off between them. Each component
is rigorously analyzed; the approximation error through constructing
approximations of the optimal transport maps, and the estimation error through
establishing an upper bound using Rademacher complexity. Our analysis not only
isolates these errors but also explores the trade-offs between them, which
provides a theoretical insights of how CycleGAN's architecture and training
procedures influence its performance.",2024-07-16,"Luwei Sun, Dongrui Shen, Han Feng",http://arxiv.org/pdf/2407.11678v2,cs.LG
SKADA-Bench: Benchmarking Unsupervised Domain Adaptation Methods with Realistic Validation On Diverse Modalities,"Unsupervised Domain Adaptation (DA) consists of adapting a model trained on a
labeled source domain to perform well on an unlabeled target domain with some
data distribution shift. While many methods have been proposed in the
literature, fair and realistic evaluation remains an open question,
particularly due to methodological difficulties in selecting hyperparameters in
the unsupervised setting. With SKADA-bench, we propose a framework to evaluate
DA methods on diverse modalities, beyond computer vision task that have been
largely explored in the literature. We present a complete and fair evaluation
of existing shallow algorithms, including reweighting, mapping, and subspace
alignment. Realistic hyperparameter selection is performed with nested
cross-validation and various unsupervised model selection scores, on both
simulated datasets with controlled shifts and real-world datasets across
diverse modalities, such as images, text, biomedical, and tabular data. Our
benchmark highlights the importance of realistic validation and provides
practical guidance for real-life applications, with key insights into the
choice and impact of model selection approaches. SKADA-bench is open-source,
reproducible, and can be easily extended with novel DA methods, datasets, and
model selection criteria without requiring re-evaluating competitors.
SKADA-bench is available on Github at
https://github.com/scikit-adaptation/skada-bench.",2024-07-16,"Yanis Lalou, Théo Gnassounou, Antoine Collas, Antoine de Mathelin, Oleksii Kachaiev, Ambroise Odonnat, Alexandre Gramfort, Thomas Moreau, Rémi Flamary",http://arxiv.org/pdf/2407.11676v3,cs.LG
Neural Compression of Atmospheric States,"Atmospheric states derived from reanalysis comprise a substantial portion of
weather and climate simulation outputs. Many stakeholders -- such as
researchers, policy makers, and insurers -- use this data to better understand
the earth system and guide policy decisions. Atmospheric states have also
received increased interest as machine learning approaches to weather
prediction have shown promising results. A key issue for all audiences is that
dense time series of these high-dimensional states comprise an enormous amount
of data, precluding all but the most well resourced groups from accessing and
using historical data and future projections. To address this problem, we
propose a method for compressing atmospheric states using methods from the
neural network literature, adapting spherical data to processing by
conventional neural architectures through the use of the area-preserving
HEALPix projection. We investigate two model classes for building neural
compressors: the hyperprior model from the neural image compression literature
and recent vector-quantised models. We show that both families of models
satisfy the desiderata of small average error, a small number of high-error
reconstructed pixels, faithful reproduction of extreme events such as
hurricanes and heatwaves, preservation of the spectral power distribution
across spatial scales. We demonstrate compression ratios in excess of 1000x,
with compression and decompression at a rate of approximately one second per
global atmospheric state.",2024-07-16,"Piotr Mirowski, David Warde-Farley, Mihaela Rosca, Matthew Koichi Grimes, Yana Hasson, Hyunjik Kim, Mélanie Rey, Simon Osindero, Suman Ravuri, Shakir Mohamed",http://arxiv.org/pdf/2407.11666v2,cs.LG
Co-Designing Binarized Transformer and Hardware Accelerator for Efficient End-to-End Edge Deployment,"Transformer models have revolutionized AI tasks, but their large size hinders
real-world deployment on resource-constrained and latency-critical edge
devices. While binarized Transformers offer a promising solution by
significantly reducing model size, existing approaches suffer from
algorithm-hardware mismatches with limited co-design exploration, leading to
suboptimal performance on edge devices. Hence, we propose a co-design method
for efficient end-to-end edge deployment of Transformers from three aspects:
algorithm, hardware, and joint optimization. First, we propose BMT, a novel
hardware-friendly binarized Transformer with optimized quantization methods and
components, and we further enhance its model accuracy by leveraging the
weighted ternary weight splitting training technique. Second, we develop a
streaming processor mixed binarized Transformer accelerator, namely BAT, which
is equipped with specialized units and scheduling pipelines for efficient
inference of binarized Transformers. Finally, we co-optimize the algorithm and
hardware through a design space exploration approach to achieve a global
trade-off between accuracy, latency, and robustness for real-world deployments.
Experimental results show our co-design achieves up to 2.14-49.37x throughput
gains and 3.72-88.53x better energy efficiency over state-of-the-art
Transformer accelerators, enabling efficient end-to-end edge deployment.",2024-07-16,"Yuhao Ji, Chao Fang, Shaobo Ma, Haikuo Shao, Zhongfeng Wang",http://arxiv.org/pdf/2407.12070v1,cs.LG
Magnetogram-to-Magnetogram: Generative Forecasting of Solar Evolution,"Investigating the solar magnetic field is crucial to understand the physical
processes in the solar interior as well as their effects on the interplanetary
environment. We introduce a novel method to predict the evolution of the solar
line-of-sight (LoS) magnetogram using image-to-image translation with Denoising
Diffusion Probabilistic Models (DDPMs). Our approach combines ""computer science
metrics"" for image quality and ""physics metrics"" for physical accuracy to
evaluate model performance. The results indicate that DDPMs are effective in
maintaining the structural integrity, the dynamic range of solar magnetic
fields, the magnetic flux and other physical features such as the size of the
active regions, surpassing traditional persistence models, also in flaring
situation. We aim to use deep learning not only for visualisation but as an
integrative and interactive tool for telescopes, enhancing our understanding of
unexpected physical events like solar flares. Future studies will aim to
integrate more diverse solar data to refine the accuracy and applicability of
our generative model.",2024-07-16,"Francesco Pio Ramunno, Hyun-Jin Jeong, Stefan Hackstein, André Csillaghy, Svyatoslav Voloshynovskiy, Manolis K. Georgoulis",http://arxiv.org/pdf/2407.11659v1,cs.LG
Exciting Action: Investigating Efficient Exploration for Learning Musculoskeletal Humanoid Locomotion,"Learning a locomotion controller for a musculoskeletal system is challenging
due to over-actuation and high-dimensional action space. While many
reinforcement learning methods attempt to address this issue, they often
struggle to learn human-like gaits because of the complexity involved in
engineering an effective reward function. In this paper, we demonstrate that
adversarial imitation learning can address this issue by analyzing key problems
and providing solutions using both current literature and novel techniques. We
validate our methodology by learning walking and running gaits on a simulated
humanoid model with 16 degrees of freedom and 92 Muscle-Tendon Units, achieving
natural-looking gaits with only a few demonstrations.",2024-07-16,"Henri-Jacques Geiß, Firas Al-Hafez, Andre Seyfarth, Jan Peters, Davide Tateo",http://arxiv.org/pdf/2407.11658v1,cs.LG
R-SFLLM: Jamming Resilient Framework for Split Federated Learning with Large Language Models,"Split federated learning (SFL) is a compute-efficient paradigm in distributed
machine learning (ML), where components of large ML models are outsourced to
remote servers. A significant challenge in SFL, particularly when deployed over
wireless channels, is the susceptibility of transmitted model parameters to
adversarial jamming that could jeopardize the learning process. This is
particularly pronounced for word embedding parameters in large language models
(LLMs), which are crucial for language understanding. In this paper, rigorous
insights are provided into the influence of jamming LLM word embeddings in SFL
by deriving an expression for the ML training loss divergence and showing that
it is upper-bounded by the mean squared error (MSE). Based on this analysis, a
physical layer framework is developed for resilient SFL with LLMs (R-SFLLM)
over wireless networks. R-SFLLM leverages wireless sensing data to gather
information on the jamming directions-of-arrival (DoAs) for the purpose of
devising a novel, sensing-assisted anti-jamming strategy while jointly
optimizing beamforming, user scheduling, and resource allocation. Extensive
experiments using BERT and RoBERTa models demonstrate R-SFLLM's effectiveness,
achieving close-to-baseline performance across various natural language
processing (NLP) tasks and datasets. The proposed methodology further
introduces an adversarial training component, where controlled noise exposure
significantly enhances the LLM's resilience to perturbed parameters during
training. The results show that more noise-sensitive models, such as RoBERTa,
benefit from this feature, especially when resource allocation is unfair. It is
also shown that worst-case jamming in particular translates into worst-case
model outcomes, thereby necessitating the need for jamming-resilient SFL
protocols.",2024-07-16,"Aladin Djuhera, Vlad C. Andrei, Xinyang Li, Ullrich J. Mönich, Holger Boche, Walid Saad",http://arxiv.org/pdf/2407.11654v2,cs.LG
CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging,"Federated Learning (FL) offers a privacy-preserving approach to train models
on decentralized data. Its potential in healthcare is significant, but
challenges arise due to cross-client variations in medical image data,
exacerbated by limited annotations. This paper introduces Cross-Client
Variations Adaptive Federated Learning (CCVA-FL) to address these issues.
CCVA-FL aims to minimize cross-client variations by transforming images into a
common feature space. It involves expert annotation of a subset of images from
each client, followed by the selection of a client with the least data
complexity as the target. Synthetic medical images are then generated using
Scalable Diffusion Models with Transformers (DiT) based on the target client's
annotated images. These synthetic images, capturing diversity and representing
the original data, are shared with other clients. Each client then translates
its local images into the target image space using image-to-image translation.
The translated images are subsequently used in a federated learning setting to
develop a server model. Our results demonstrate that CCVA-FL outperforms
Vanilla Federated Averaging by effectively addressing data distribution
differences across clients without compromising privacy.",2024-07-16,"Sunny Gupta, Amit Sethi",http://arxiv.org/pdf/2407.11652v7,cs.LG
Dataset Dictionary Learning in a Wasserstein Space for Federated Domain Adaptation,"Multi-Source Domain Adaptation (MSDA) is a challenging scenario where
multiple related and heterogeneous source datasets must be adapted to an
unlabeled target dataset. Conventional MSDA methods often overlook that data
holders may have privacy concerns, hindering direct data sharing. In response,
decentralized MSDA has emerged as a promising strategy to achieve adaptation
without centralizing clients' data. Our work proposes a novel approach,
Decentralized Dataset Dictionary Learning, to address this challenge. Our
method leverages Wasserstein barycenters to model the distributional shift
across multiple clients, enabling effective adaptation while preserving data
privacy. Specifically, our algorithm expresses each client's underlying
distribution as a Wasserstein barycenter of public atoms, weighted by private
barycentric coordinates. Our approach ensures that the barycentric coordinates
remain undisclosed throughout the adaptation process. Extensive experimentation
across five visual domain adaptation benchmarks demonstrates the superiority of
our strategy over existing decentralized MSDA techniques. Moreover, our method
exhibits enhanced robustness to client parallelism while maintaining relative
resilience compared to conventional decentralized MSDA methodologies.",2024-07-16,"Eduardo Fernandes Montesuma, Fabiola Espinoza Castellon, Fred Ngolè Mboula, Aurélien Mayoue, Antoine Souloumiac, Cédric Gouy-Pailler",http://arxiv.org/pdf/2407.11647v1,cs.LG
Dynamic Dimension Wrapping (DDW) Algorithm: A Novel Approach for Efficient Cross-Dimensional Search in Dynamic Multidimensional Spaces,"To effectively search for the optimal motion template in dynamic
multidimensional space, this paper proposes a novel optimization algorithm,
Dynamic Dimension Wrapping (DDW).The algorithm combines Dynamic Time Warping
(DTW) and Euclidean distance, and designs a fitness function that adapts to
dynamic multidimensional space by establishing a time-data chain mapping across
dimensions. This paper also proposes a novel update mechanism,Optimal Dimension
Collection (ODC), combined with the search strategy of traditional optimization
algorithms, enables DDW to adjust both the dimension values and the number of
dimensions of the population individuals simultaneously. In this way, DDW
significantly reduces computational complexity and improves search accuracy.
Experimental results show that DDW performs excellently in dynamic
multidimensional space, outperforming 31 traditional optimization algorithms.
This algorithm provides a novel approach to solving dynamic multidimensional
optimization problems and demonstrates broad application potential in fields
such as motion data analysis.",2024-07-16,"Dongnan Jin, Yali Liu, Qiuzhi Song, Xunju Ma, Yue Liu, Dehao Wu",http://arxiv.org/pdf/2407.11626v3,cs.LG
Rethinking Fair Graph Neural Networks from Re-balancing,"Driven by the powerful representation ability of Graph Neural Networks
(GNNs), plentiful GNN models have been widely deployed in many real-world
applications. Nevertheless, due to distribution disparities between different
demographic groups, fairness in high-stake decision-making systems is receiving
increasing attention. Although lots of recent works devoted to improving the
fairness of GNNs and achieved considerable success, they all require
significant architectural changes or additional loss functions requiring more
hyper-parameter tuning. Surprisingly, we find that simple re-balancing methods
can easily match or surpass existing fair GNN methods. We claim that the
imbalance across different demographic groups is a significant source of
unfairness, resulting in imbalanced contributions from each group to the
parameters updating. However, these simple re-balancing methods have their own
shortcomings during training. In this paper, we propose FairGB, Fair Graph
Neural Network via re-Balancing, which mitigates the unfairness of GNNs by
group balancing. Technically, FairGB consists of two modules: counterfactual
node mixup and contribution alignment loss. Firstly, we select counterfactual
pairs across inter-domain and inter-class, and interpolate the ego-networks to
generate new samples. Guided by analysis, we can reveal the debiasing mechanism
of our model by the causal view and prove that our strategy can make sensitive
attributes statistically independent from target labels. Secondly, we reweigh
the contribution of each group according to gradients. By combining these two
modules, they can mutually promote each other. Experimental results on
benchmark datasets show that our method can achieve state-of-the-art results
concerning both utility and fairness metrics. Code is available at
https://github.com/ZhixunLEE/FairGB.",2024-07-16,"Zhixun Li, Yushun Dong, Qiang Liu, Jeffrey Xu Yu",http://arxiv.org/pdf/2407.11624v1,cs.LG
Strategic Littlestone Dimension: Improved Bounds on Online Strategic Classification,"We study the problem of online binary classification in settings where
strategic agents can modify their observable features to receive a positive
classification. We model the set of feasible manipulations by a directed graph
over the feature space, and assume the learner only observes the manipulated
features instead of the original ones. We introduce the Strategic Littlestone
Dimension, a new combinatorial measure that captures the joint complexity of
the hypothesis class and the manipulation graph. We demonstrate that it
characterizes the instance-optimal mistake bounds for deterministic learning
algorithms in the realizable setting. We also achieve improved regret in the
agnostic setting by a refined agnostic-to-realizable reduction that accounts
for the additional challenge of not observing agents' original features.
Finally, we relax the assumption that the learner knows the manipulation graph,
instead assuming their knowledge is captured by a family of graphs. We derive
regret bounds in both the realizable setting where all agents manipulate
according to the same graph within the graph family, and the agnostic setting
where the manipulation graphs are chosen adversarially and not consistently
modeled by a single graph in the family.",2024-07-16,"Saba Ahmadi, Kunhe Yang, Hanrui Zhang",http://arxiv.org/pdf/2407.11619v1,cs.LG
Graph Dimension Attention Networks for Enterprise Credit Assessment,"Enterprise credit assessment is critical for evaluating financial risk, and
Graph Neural Networks (GNNs), with their advanced capability to model
inter-entity relationships, are a natural tool to get a deeper understanding of
these financial networks. However, existing GNN-based methodologies
predominantly emphasize entity-level attention mechanisms for contagion risk
aggregation, often overlooking the heterogeneous importance of different
feature dimensions, thus falling short in adequately modeling credit risk
levels. To address this issue, we propose a novel architecture named Graph
Dimension Attention Network (GDAN), which incorporates a dimension-level
attention mechanism to capture fine-grained risk-related characteristics.
Furthermore, we explore the interpretability of the GNN-based method in
financial scenarios and propose a simple but effective data-centric explainer
for GDAN, called GDAN-DistShift. DistShift provides edge-level interpretability
by quantifying distribution shifts during the message-passing process.
Moreover, we collected a real-world, multi-source Enterprise Credit Assessment
Dataset (ECAD) and have made it accessible to the research community since
high-quality datasets are lacking in this field. Extensive experiments
conducted on ECAD demonstrate the effectiveness of our methods. In addition, we
ran GDAN on the well-known datasets SMEsD and DBLP, also with excellent
results.",2024-07-16,"Shaopeng Wei, Beni Egressy, Xingyan Chen, Yu Zhao, Fuzhen Zhuang, Roger Wattenhofer, Gang Kou",http://arxiv.org/pdf/2407.11615v1,cs.LG
The Foundations of Tokenization: Statistical and Computational Concerns,"Tokenization - the practice of converting strings of characters from an
alphabet into sequences of tokens over a vocabulary - is a critical step in the
NLP pipeline. The use of token representations is widely credited with
increased model performance but is also the source of many undesirable
behaviors, such as spurious ambiguity or inconsistency. Despite its recognized
importance as a standard representation method in NLP, the theoretical
underpinnings of tokenization are not yet fully understood. In particular, the
impact of tokenization on language model estimation has been investigated
primarily through empirical means. The present paper contributes to addressing
this theoretical gap by proposing a unified formal framework for representing
and analyzing tokenizer models. Based on the category of stochastic maps, this
framework enables us to establish general conditions for a principled use of
tokenizers and, most importantly, the necessary and sufficient conditions for a
tokenizer model to preserve the consistency of statistical estimators. In
addition, we discuss statistical and computational concerns crucial for
designing and implementing tokenizer models, such as inconsistency, ambiguity,
finiteness, and sequentiality. The framework and results advanced in this paper
contribute to building robust theoretical foundations for representations in
neural language modeling that can inform future theoretical and empirical
research.",2024-07-16,"Juan Luis Gastaldi, John Terilla, Luca Malagutti, Brian DuSell, Tim Vieira, Ryan Cotterell",http://arxiv.org/pdf/2407.11606v4,cs.LG
HyperAggregation: Aggregating over Graph Edges with Hypernetworks,"HyperAggregation is a hypernetwork-based aggregation function for Graph
Neural Networks. It uses a hypernetwork to dynamically generate weights in the
size of the current neighborhood, which are then used to aggregate this
neighborhood. This aggregation with the generated weights is done like an
MLP-Mixer channel mixing over variable-sized vertex neighborhoods. We
demonstrate HyperAggregation in two models, GraphHyperMixer is a model based on
MLP-Mixer while GraphHyperConv is derived from a GCN but with a
hypernetwork-based aggregation function. We perform experiments on diverse
benchmark datasets for the vertex classification, graph classification, and
graph regression tasks. The results show that HyperAggregation can be
effectively used for homophilic and heterophilic datasets in both inductive and
transductive settings. GraphHyperConv performs better than GraphHyperMixer and
is especially strong in the transductive setting. On the heterophilic dataset
Roman-Empire it reaches a new state of the art. On the graph-level tasks our
models perform in line with similarly sized models. Ablation studies
investigate the robustness against various hyperparameter choices. The
implementation of HyperAggregation as well code to reproduce all experiments is
available under https://github.com/Foisunt/HyperAggregation .",2024-07-16,"Nicolas Lell, Ansgar Scherp",http://arxiv.org/pdf/2407.11596v1,cs.LG
DiNO-Diffusion. Scaling Medical Diffusion via Self-Supervised Pre-Training,"Diffusion models (DMs) have emerged as powerful foundation models for a
variety of tasks, with a large focus in synthetic image generation. However,
their requirement of large annotated datasets for training limits their
applicability in medical imaging, where datasets are typically smaller and
sparsely annotated. We introduce DiNO-Diffusion, a self-supervised method for
training latent diffusion models (LDMs) that conditions the generation process
on image embeddings extracted from DiNO. By eliminating the reliance on
annotations, our training leverages over 868k unlabelled images from public
chest X-Ray (CXR) datasets. Despite being self-supervised, DiNO-Diffusion shows
comprehensive manifold coverage, with FID scores as low as 4.7, and emerging
properties when evaluated in downstream tasks. It can be used to generate
semantically-diverse synthetic datasets even from small data pools,
demonstrating up to 20% AUC increase in classification performance when used
for data augmentation. Images were generated with different sampling strategies
over the DiNO embedding manifold and using real images as a starting point.
Results suggest, DiNO-Diffusion could facilitate the creation of large datasets
for flexible training of downstream AI models from limited amount of real data,
while also holding potential for privacy preservation. Additionally,
DiNO-Diffusion demonstrates zero-shot segmentation performance of up to 84.4%
Dice score when evaluating lung lobe segmentation. This evidences good CXR
image-anatomy alignment, akin to segmenting using textual descriptors on
vanilla DMs. Finally, DiNO-Diffusion can be easily adapted to other medical
imaging modalities or state-of-the-art diffusion models, opening the door for
large-scale, multi-domain image generation pipelines for medical imaging.",2024-07-16,"Guillermo Jimenez-Perez, Pedro Osorio, Josef Cersovsky, Javier Montalt-Tordera, Jens Hooge, Steffen Vogler, Sadegh Mohammadi",http://arxiv.org/pdf/2407.11594v1,cs.LG
Enhancing stop location detection for incomplete urban mobility datasets,"Stop location detection, within human mobility studies, has an impacts in
multiple fields including urban planning, transport network design,
epidemiological modeling, and socio-economic segregation analysis. However, it
remains a challenging task because classical density clustering algorithms
often struggle with noisy or incomplete GPS datasets. This study investigates
the application of classification algorithms to enhance density-based methods
for stop identification. Our approach incorporates multiple features, including
individual routine behavior across various time scales and local
characteristics of individual GPS points. The dataset comprises
privacy-preserving and anonymized GPS points previously labeled as stops by a
sequence-oriented, density-dependent algorithm. We simulated data gaps by
removing point density from select stops to assess performance under sparse
data conditions. The model classifies individual GPS points within trajectories
as potential stops or non-stops. Given the highly imbalanced nature of the
dataset, we prioritized recall over precision in performance evaluation.
Results indicate that this method detects most stops, even in the presence of
spatio-temporal gaps and that points classified as false positives often
correspond to recurring locations for devices, typically near previous stops.
While this research contributes to mobility analysis techniques, significant
challenges persist. The lack of ground truth data limits definitive conclusions
about the algorithm's accuracy. Further research is needed to validate the
method across diverse datasets and to incorporate collective behavior inputs.",2024-07-16,"Margherita Bertè, Rashid Ibrahimli, Lars Koopmans, Pablo Valgañón, Nicola Zomer, Davide Colombi",http://arxiv.org/pdf/2407.11579v1,cs.LG
Federated Learning Forecasting for Strengthening Grid Reliability and Enabling Markets for Resilience,"We propose a comprehensive approach to increase the reliability and
resilience of future power grids rich in distributed energy resources. Our
distributed scheme combines federated learning-based attack detection with a
local electricity market-based attack mitigation method. We validate the scheme
by applying it to a real-world distribution grid rich in solar PV. Simulation
results demonstrate that the approach is feasible and can successfully mitigate
the grid impacts of cyber-physical attacks.",2024-07-16,"Lucas Pereira, Vineet Jagadeesan Nair, Bruno Dias, Hugo Morais, Anuradha Annaswamy",http://arxiv.org/pdf/2407.11571v1,cs.LG
RobotKeyframing: Learning Locomotion with High-Level Objectives via Mixture of Dense and Sparse Rewards,"This paper presents a novel learning-based control framework that uses
keyframing to incorporate high-level objectives in natural locomotion for
legged robots. These high-level objectives are specified as a variable number
of partial or complete pose targets that are spaced arbitrarily in time. Our
proposed framework utilizes a multi-critic reinforcement learning algorithm to
effectively handle the mixture of dense and sparse rewards. Additionally, it
employs a transformer-based encoder to accommodate a variable number of input
targets, each associated with specific time-to-arrivals. Throughout simulation
and hardware experiments, we demonstrate that our framework can effectively
satisfy the target keyframe sequence at the required times. In the experiments,
the multi-critic method significantly reduces the effort of hyperparameter
tuning compared to the standard single-critic alternative. Moreover, the
proposed transformer-based architecture enables robots to anticipate future
goals, which results in quantitative improvements in their ability to reach
their targets.",2024-07-16,"Fatemeh Zargarbashi, Jin Cheng, Dongho Kang, Robert Sumner, Stelian Coros",http://arxiv.org/pdf/2407.11562v2,cs.LG
Self-Guided Generation of Minority Samples Using Diffusion Models,"We present a novel approach for generating minority samples that live on
low-density regions of a data manifold. Our framework is built upon diffusion
models, leveraging the principle of guided sampling that incorporates an
arbitrary energy-based guidance during inference time. The key defining feature
of our sampler lies in its \emph{self-contained} nature, \ie, implementable
solely with a pretrained model. This distinguishes our sampler from existing
techniques that require expensive additional components (like external
classifiers) for minority generation. Specifically, we first estimate the
likelihood of features within an intermediate latent sample by evaluating a
reconstruction loss w.r.t. its posterior mean. The generation then proceeds
with the minimization of the estimated likelihood, thereby encouraging the
emergence of minority features in the latent samples of subsequent timesteps.
To further improve the performance of our sampler, we provide several
time-scheduling techniques that properly manage the influence of guidance over
inference steps. Experiments on benchmark real datasets demonstrate that our
approach can greatly improve the capability of creating realistic
low-likelihood minority instances over the existing techniques without the
reliance on costly additional elements. Code is available at
\url{https://github.com/soobin-um/sg-minority}.",2024-07-16,"Soobin Um, Jong Chul Ye",http://arxiv.org/pdf/2407.11555v1,cs.LG
A Discrete Perspective Towards the Construction of Sparse Probabilistic Boolean Networks,"Boolean Network (BN) and its extension Probabilistic Boolean Network (PBN)
are popular mathematical models for studying genetic regulatory networks. BNs
and PBNs are also applied to model manufacturing systems, financial risk and
healthcare service systems. In this paper, we propose a novel Greedy Entry
Removal (GER) algorithm for constructing sparse PBNs. We derive theoretical
upper bounds for both existing algorithms and the GER algorithm. Furthermore,
we are the first to study the lower bound problem of the construction of sparse
PBNs, and to derive a series of related theoretical results. In our numerical
experiments based on both synthetic and practical data, GER gives the best
performance among state-of-the-art sparse PBN construction algorithms and
outputs sparsest possible decompositions on most of the transition probability
matrices being tested.",2024-07-16,"Christopher H. Fok, Chi-Wing Wong, Wai-Ki Ching",http://arxiv.org/pdf/2407.11543v1,cs.LG
Counting in Small Transformers: The Delicate Interplay between Attention and Feed-Forward Layers,"Next to scaling considerations, architectural design choices profoundly shape
the solution space of transformers. In this work, we analyze the solutions
simple transformer blocks implement when tackling the histogram task: counting
items in sequences. Despite its simplicity, this task reveals a complex
interplay between predictive performance, vocabulary and embedding sizes,
token-mixing mechanisms, and feed-forward layer capacity. We identify two
theoretical counting strategies transformers adopt, relation-based and
inventory-based counting, each defining distinct learning regimes for the task.
These strategies dictate how functionality is distributed between attention and
feed-forward layers. We further show that adding softmax and
beginning-of-sequence tokens allow for more robustness when embedding
dimensions are comparatively small. Empirical introspection of trained models
closely confirms both the learning regimes of the various architectures and the
formation of these strategies during training. We demonstrate how a basic task
that requires only aggregation and selection is significantly impacted by minor
design changes.",2024-07-16,"Freya Behrens, Luca Biggio, Lenka Zdeborová",http://arxiv.org/pdf/2407.11542v3,cs.LG
Not Another Imputation Method: A Transformer-based Model for Missing Values in Tabular Datasets,"Handling missing values in tabular datasets presents a significant challenge
in training and testing artificial intelligence models, an issue usually
addressed using imputation techniques. Here we introduce ""Not Another
Imputation Method"" (NAIM), a novel transformer-based model specifically
designed to address this issue without the need for traditional imputation
techniques. NAIM's ability to avoid the necessity of imputing missing values
and to effectively learn from available data relies on two main techniques: the
use of feature-specific embeddings to encode both categorical and numerical
features also handling missing inputs; the modification of the masked
self-attention mechanism to completely mask out the contributions of missing
data. Additionally, a novel regularization technique is introduced to enhance
the model's generalization capability from incomplete data. We extensively
evaluated NAIM on 5 publicly available tabular datasets, demonstrating its
superior performance over 6 state-of-the-art machine learning models and 5 deep
learning models, each paired with 3 different imputation techniques when
necessary. The results highlight the efficacy of NAIM in improving predictive
performance and resilience in the presence of missing data. To facilitate
further research and practical application in handling missing data without
traditional imputation methods, we made the code for NAIM available at
https://github.com/cosbidev/NAIM.",2024-07-16,"Camillo Maria Caruso, Paolo Soda, Valerio Guarrasi",http://arxiv.org/pdf/2407.11540v2,cs.LG
Cross-Modal Augmentation for Few-Shot Multimodal Fake News Detection,"The nascent topic of fake news requires automatic detection methods to
quickly learn from limited annotated samples. Therefore, the capacity to
rapidly acquire proficiency in a new task with limited guidance, also known as
few-shot learning, is critical for detecting fake news in its early stages.
Existing approaches either involve fine-tuning pre-trained language models
which come with a large number of parameters, or training a complex neural
network from scratch with large-scale annotated datasets. This paper presents a
multimodal fake news detection model which augments multimodal features using
unimodal features. For this purpose, we introduce Cross-Modal Augmentation
(CMA), a simple approach for enhancing few-shot multimodal fake news detection
by transforming n-shot classification into a more robust (n $\times$ z)-shot
problem, where z represents the number of supplementary features. The proposed
CMA achieves SOTA results over three benchmark datasets, utilizing a
surprisingly simple linear probing method to classify multimodal fake news with
only a few training samples. Furthermore, our method is significantly more
lightweight than prior approaches, particularly in terms of the number of
trainable parameters and epoch times. The code is available here:
\url{https://github.com/zgjiangtoby/FND_fewshot}",2024-07-16,"Ye Jiang, Taihang Wang, Xiaoman Xu, Yimin Wang, Xingyi Song, Diana Maynard",http://arxiv.org/pdf/2407.12880v1,cs.LG
LRQ: Optimizing Post-Training Quantization for Large Language Models by Learning Low-Rank Weight-Scaling Matrices,"With the commercialization of large language models (LLMs), weight-activation
quantization has emerged to compress and accelerate LLMs, achieving high
throughput while reducing inference costs. However, existing post-training
quantization (PTQ) techniques for quantizing weights and activations of LLMs
still suffer from non-negligible accuracy drops, especially on massive
multitask language understanding. To address this issue, we propose Low-Rank
Quantization (LRQ) - a simple yet effective post-training weight quantization
method for LLMs that reconstructs the outputs of an intermediate Transformer
block by leveraging low-rank weight-scaling matrices, replacing the
conventional full weight-scaling matrices that entail as many learnable scales
as their associated weights. Thanks to parameter sharing via low-rank
structure, LRQ only needs to learn significantly fewer parameters while
enabling the individual scaling of weights, thus boosting the generalization
capability of quantized LLMs. We show the superiority of LRQ over prior LLM PTQ
works under (i) 8-bit weight and per-tensor activation quantization, (ii) 4-bit
weight and 8-bit per-token activation quantization, and (iii) low-bit
weight-only quantization schemes. Our code is available at Software.",2024-07-16,"Jung Hyun Lee, Jeonghoon Kim, June Yong Yang, Se Jung Kwon, Eunho Yang, Kang Min Yoo, Dongsoo Lee",http://arxiv.org/pdf/2407.11534v2,cs.LG
Large Visual-Language Models Are Also Good Classifiers: A Study of In-Context Multimodal Fake News Detection,"Large visual-language models (LVLMs) exhibit exceptional performance in
visual-language reasoning across diverse cross-modal benchmarks. Despite these
advances, recent research indicates that Large Language Models (LLMs), like
GPT-3.5-turbo, underachieve compared to well-trained smaller models, such as
BERT, in Fake News Detection (FND), prompting inquiries into LVLMs' efficacy in
FND tasks. Although performance could improve through fine-tuning LVLMs, the
substantial parameters and requisite pre-trained weights render it a
resource-heavy endeavor for FND applications. This paper initially assesses the
FND capabilities of two notable LVLMs, CogVLM and GPT4V, in comparison to a
smaller yet adeptly trained CLIP model in a zero-shot context. The findings
demonstrate that LVLMs can attain performance competitive with that of the
smaller model. Next, we integrate standard in-context learning (ICL) with
LVLMs, noting improvements in FND performance, though limited in scope and
consistency. To address this, we introduce the \textbf{I}n-context
\textbf{M}ultimodal \textbf{F}ake \textbf{N}ews \textbf{D}etection (IMFND)
framework, enriching in-context examples and test inputs with predictions and
corresponding probabilities from a well-trained smaller model. This strategic
integration directs the LVLMs' focus towards news segments associated with
higher probabilities, thereby improving their analytical accuracy. The
experimental results suggest that the IMFND framework significantly boosts the
FND efficiency of LVLMs, achieving enhanced accuracy over the standard ICL
approach across three publicly available FND datasets.",2024-07-16,"Ye Jiang, Yimin Wang",http://arxiv.org/pdf/2407.12879v4,cs.LG
Learning on Graphs with Large Language Models(LLMs): A Deep Dive into Model Robustness,"Large Language Models (LLMs) have demonstrated remarkable performance across
various natural language processing tasks. Recently, several LLMs-based
pipelines have been developed to enhance learning on graphs with text
attributes, showcasing promising performance. However, graphs are well-known to
be susceptible to adversarial attacks and it remains unclear whether LLMs
exhibit robustness in learning on graphs. To address this gap, our work aims to
explore the potential of LLMs in the context of adversarial attacks on graphs.
Specifically, we investigate the robustness against graph structural and
textual perturbations in terms of two dimensions: LLMs-as-Enhancers and
LLMs-as-Predictors. Through extensive experiments, we find that, compared to
shallow models, both LLMs-as-Enhancers and LLMs-as-Predictors offer superior
robustness against structural and textual attacks.Based on these findings, we
carried out additional analyses to investigate the underlying causes.
Furthermore, we have made our benchmark library openly available to facilitate
quick and fair evaluations, and to encourage ongoing innovative research in
this field.",2024-07-16,"Kai Guo, Zewen Liu, Zhikai Chen, Hongzhi Wen, Wei Jin, Jiliang Tang, Yi Chang",http://arxiv.org/pdf/2407.12068v2,cs.LG
Ensemble Transport Filter via Optimized Maximum Mean Discrepancy,"In this paper, we present a new ensemble-based filter method by
reconstructing the analysis step of the particle filter through a transport
map, which directly transports prior particles to posterior particles. The
transport map is constructed through an optimization problem described by the
Maximum Mean Discrepancy loss function, which matches the expectation
information of the approximated posterior and reference posterior. The proposed
method inherits the accurate estimation of the posterior distribution from
particle filtering. To improve the robustness of Maximum Mean Discrepancy, a
variance penalty term is used to guide the optimization. It prioritizes
minimizing the discrepancy between the expectations of highly informative
statistics for the approximated and reference posteriors. The penalty term
significantly enhances the robustness of the proposed method and leads to a
better approximation of the posterior. A few numerical examples are presented
to illustrate the advantage of the proposed method over the ensemble Kalman
filter.",2024-07-16,"Dengfei Zeng, Lijian Jiang",http://arxiv.org/pdf/2407.11518v1,cs.LG
"Reasoning with Large Language Models, a Survey","Scaling up language models to billions of parameters has opened up
possibilities for in-context learning, allowing instruction tuning and few-shot
learning on tasks that the model was not specifically trained for. This has
achieved breakthrough performance on language tasks such as translation,
summarization, and question-answering. Furthermore, in addition to these
associative ""System 1"" tasks, recent advances in Chain-of-thought prompt
learning have demonstrated strong ""System 2"" reasoning abilities, answering a
question in the field of artificial general intelligence whether LLMs can
reason. The field started with the question whether LLMs can solve grade school
math word problems. This paper reviews the rapidly expanding field of
prompt-based reasoning with LLMs. Our taxonomy identifies different ways to
generate, evaluate, and control multi-step reasoning. We provide an in-depth
coverage of core approaches and open problems, and we propose a research agenda
for the near future. Finally, we highlight the relation between reasoning and
prompt-based learning, and we discuss the relation between reasoning,
sequential decision processes, and reinforcement learning. We find that
self-improvement, self-reflection, and some metacognitive abilities of the
reasoning processes are possible through the judicious use of prompts. True
self-improvement and self-reasoning, to go from reasoning with LLMs to
reasoning by LLMs, remains future work.",2024-07-16,"Aske Plaat, Annie Wong, Suzan Verberne, Joost Broekens, Niki van Stein, Thomas Back",http://arxiv.org/pdf/2407.11511v1,cs.LG
Diff-MTS: Temporal-Augmented Conditional Diffusion-based AIGC for Industrial Time Series Towards the Large Model Era,"Industrial Multivariate Time Series (MTS) is a critical view of the
industrial field for people to understand the state of machines. However, due
to data collection difficulty and privacy concerns, available data for building
industrial intelligence and industrial large models is far from sufficient.
Therefore, industrial time series data generation is of great importance.
Existing research usually applies Generative Adversarial Networks (GANs) to
generate MTS. However, GANs suffer from unstable training process due to the
joint training of the generator and discriminator. This paper proposes a
temporal-augmented conditional adaptive diffusion model, termed Diff-MTS, for
MTS generation. It aims to better handle the complex temporal dependencies and
dynamics of MTS data. Specifically, a conditional Adaptive Maximum-Mean
Discrepancy (Ada-MMD) method has been proposed for the controlled generation of
MTS, which does not require a classifier to control the generation. It improves
the condition consistency of the diffusion model. Moreover, a Temporal
Decomposition Reconstruction UNet (TDR-UNet) is established to capture complex
temporal patterns and further improve the quality of the synthetic time series.
Comprehensive experiments on the C-MAPSS and FEMTO datasets demonstrate that
the proposed Diff-MTS performs substantially better in terms of diversity,
fidelity, and utility compared with GAN-based methods. These results show that
Diff-MTS facilitates the generation of industrial data, contributing to
intelligent maintenance and the construction of industrial large models.",2024-07-16,"Lei Ren, Haiteng Wang, Yuanjun Laili",http://arxiv.org/pdf/2407.11501v1,cs.LG
An AI System for Continuous Knee Osteoarthritis Severity Grading Using Self-Supervised Anomaly Detection with Limited Data,"The diagnostic accuracy and subjectivity of existing Knee Osteoarthritis (OA)
ordinal grading systems has been a subject of on-going debate and concern.
Existing automated solutions are trained to emulate these imperfect systems,
whilst also being reliant on large annotated databases for fully-supervised
training. This work proposes a three stage approach for automated continuous
grading of knee OA that is built upon the principles of Anomaly Detection (AD);
learning a robust representation of healthy knee X-rays and grading disease
severity based on its distance to the centre of normality. In the first stage,
SS-FewSOME is proposed, a self-supervised AD technique that learns the 'normal'
representation, requiring only examples of healthy subjects and <3% of the
labels that existing methods require. In the second stage, this model is used
to pseudo label a subset of unlabelled data as 'normal' or 'anomalous',
followed by denoising of pseudo labels with CLIP. The final stage involves
retraining on labelled and pseudo labelled data using the proposed Dual Centre
Representation Learning (DCRL) which learns the centres of two representation
spaces; normal and anomalous. Disease severity is then graded based on the
distance to the learned centres. The proposed methodology outperforms existing
techniques by margins of up to 24% in terms of OA detection and the disease
severity scores correlate with the Kellgren-Lawrence grading system at the same
level as human expert performance. Code available at
https://github.com/niamhbelton/SS-FewSOME_Disease_Severity_Knee_Osteoarthritis.",2024-07-16,"Niamh Belton, Aonghus Lawlor, Kathleen M. Curran",http://arxiv.org/pdf/2407.11500v1,cs.LG
A Meta-Learning Approach for Multi-Objective Reinforcement Learning in Sustainable Home Environments,"Effective residential appliance scheduling is crucial for sustainable living.
While multi-objective reinforcement learning (MORL) has proven effective in
balancing user preferences in appliance scheduling, traditional MORL struggles
with limited data in non-stationary residential settings characterized by
renewable generation variations. Significant context shifts that can invalidate
previously learned policies. To address these challenges, we extend
state-of-the-art MORL algorithms with the meta-learning paradigm, enabling
rapid, few-shot adaptation to shifting contexts. Additionally, we employ an
auto-encoder (AE)-based unsupervised method to detect environment context
changes. We have also developed a residential energy environment to evaluate
our method using real-world data from London residential settings. This study
not only assesses the application of MORL in residential appliance scheduling
but also underscores the effectiveness of meta-learning in energy management.
Our top-performing method significantly surpasses the best baseline, while the
trained model saves 3.28% on electricity bills, a 2.74% increase in user
comfort, and a 5.9% improvement in expected utility. Additionally, it reduces
the sparsity of solutions by 62.44%. Remarkably, these gains were accomplished
using 96.71% less training data and 61.1% fewer training steps.",2024-07-16,"Junlin Lu, Patrick Mannion, Karl Mason",http://arxiv.org/pdf/2407.11489v1,cs.LG
Multi-Channel Masked Autoencoder and Comprehensive Evaluations for Reconstructing 12-Lead ECG from Arbitrary Single-Lead ECG,"Electrocardiogram (ECG) has emerged as a widely accepted diagnostic
instrument for cardiovascular diseases (CVD). The standard clinical 12-lead ECG
configuration causes considerable inconvenience and discomfort, while wearable
devices offers a more practical alternative. To reduce information gap between
12-lead ECG and single-lead ECG, this study proposes a multi-channel masked
autoencoder (MCMA) for reconstructing 12-Lead ECG from arbitrary single-lead
ECG, and a comprehensive evaluation benchmark, ECGGenEval, encompass the
signal-level, feature-level, and diagnostic-level evaluations. MCMA can achieve
the state-of-the-art performance. In the signal-level evaluation, the mean
square errors of 0.0317 and 0.1034, Pearson correlation coefficients of 0.7885
and 0.7420. In the feature-level evaluation, the average standard deviation of
the mean heart rate across the generated 12-lead ECG is 1.0481, the coefficient
of variation is 1.58%, and the range is 3.2874. In the diagnostic-level
evaluation, the average F1-score with two generated 12-lead ECG from different
single-lead ECG are 0.8233 and 0.8410.",2024-07-16,"Jiarong Chen, Wanqing Wu, Tong Liu, Shenda Hong",http://arxiv.org/pdf/2407.11481v2,cs.LG
Dilated convolution neural operator for multiscale partial differential equations,"This paper introduces a data-driven operator learning method for multiscale
partial differential equations, with a particular emphasis on preserving
high-frequency information. Drawing inspiration from the representation of
multiscale parameterized solutions as a combination of low-rank global bases
(such as low-frequency Fourier modes) and localized bases over coarse patches
(analogous to dilated convolution), we propose the Dilated Convolutional Neural
Operator (DCNO). The DCNO architecture effectively captures both high-frequency
and low-frequency features while maintaining a low computational cost through a
combination of convolution and Fourier layers. We conduct experiments to
evaluate the performance of DCNO on various datasets, including the multiscale
elliptic equation, its inverse problem, Navier-Stokes equation, and Helmholtz
equation. We show that DCNO strikes an optimal balance between accuracy and
computational cost and offers a promising solution for multiscale operator
learning.",2024-07-16,"Bo Xu, Xinliang Liu, Lei Zhang",http://arxiv.org/pdf/2408.00775v1,cs.LG
AIGC for Industrial Time Series: From Deep Generative Models to Large Generative Models,"With the remarkable success of generative models like ChatGPT, Artificial
Intelligence Generated Content (AIGC) is undergoing explosive development. Not
limited to text and images, generative models can generate industrial time
series data, addressing challenges such as the difficulty of data collection
and data annotation. Due to their outstanding generation ability, they have
been widely used in Internet of Things, metaverse, and cyber-physical-social
systems to enhance the efficiency of industrial production. In this paper, we
present a comprehensive overview of generative models for industrial time
series from deep generative models (DGMs) to large generative models (LGMs).
First, a DGM-based AIGC framework is proposed for industrial time series
generation. Within this framework, we survey advanced industrial DGMs and
present a multi-perspective categorization. Furthermore, we systematically
analyze the critical technologies required to construct industrial LGMs from
four aspects: large-scale industrial dataset, LGMs architecture for complex
industrial characteristics, self-supervised training for industrial time
series, and fine-tuning of industrial downstream tasks. Finally, we conclude
the challenges and future directions to enable the development of generative
models in industry.",2024-07-16,"Lei Ren, Haiteng Wang, Jinwang Li, Yang Tang, Chunhua Yang",http://arxiv.org/pdf/2407.11480v2,cs.LG
XTraffic: A Dataset Where Traffic Meets Incidents with Explainability and More,"Long-separated research has been conducted on two highly correlated tracks:
traffic and incidents. Traffic track witnesses complicating deep learning
models, e.g., to push the prediction a few percent more accurate, and the
incident track only studies the incidents alone, e.g., to infer the incident
risk. We, for the first time, spatiotemporally aligned the two tracks in a
large-scale region (16,972 traffic nodes) over the whole year of 2023: our
XTraffic dataset includes traffic, i.e., time-series indexes on traffic flow,
lane occupancy, and average vehicle speed, and incidents, whose records are
spatiotemporally-aligned with traffic data, with seven different incident
classes. Additionally, each node includes detailed physical and policy-level
meta-attributes of lanes. Our data can revolutionalize traditional
traffic-related tasks towards higher interpretability and practice: instead of
traditional prediction or classification tasks, we conduct: (1) post-incident
traffic forecasting to quantify the impact of different incidents on traffic
indexes; (2) incident classification using traffic indexes to determine the
incidents types for precautions measures; (3) global causal analysis among the
traffic indexes, meta-attributes, and incidents to give high-level guidance of
the interrelations of various factors; (4) local causal analysis within road
nodes to examine how different incidents affect the road segments' relations.
The dataset is available at http://xaitraffic.github.io.",2024-07-16,"Xiaochuan Gou, Ziyue Li, Tian Lan, Junpeng Lin, Zhishuai Li, Bingyu Zhao, Chen Zhang, Di Wang, Xiangliang Zhang",http://arxiv.org/pdf/2407.11477v1,cs.LG
Quantum Maximum Entropy Inference and Hamiltonian Learning,"Maximum entropy inference and learning of graphical models are pivotal tasks
in learning theory and optimization. This work extends algorithms for these
problems, including generalized iterative scaling (GIS) and gradient descent
(GD), to the quantum realm. While the generalization, known as quantum
iterative scaling (QIS), is straightforward, the key challenge lies in the
non-commutative nature of quantum problem instances, rendering the convergence
rate analysis significantly more challenging than the classical case. Our
principal technical contribution centers on a rigorous analysis of the
convergence rates, involving the establishment of both lower and upper bounds
on the spectral radius of the Jacobian matrix for each iteration of these
algorithms. Furthermore, we explore quasi-Newton methods to enhance the
performance of QIS and GD. Specifically, we propose using Anderson mixing and
the L-BFGS method for QIS and GD, respectively. These quasi-Newton techniques
exhibit remarkable efficiency gains, resulting in orders of magnitude
improvements in performance. As an application, our algorithms provide a viable
approach to designing Hamiltonian learning algorithms.",2024-07-16,"Minbo Gao, Zhengfeng Ji, Fuchao Wei",http://arxiv.org/pdf/2407.11473v1,cs.LG
Safe Online Convex Optimization with Multi-Point Feedback,"Motivated by the stringent safety requirements that are often present in
real-world applications, we study a safe online convex optimization setting
where the player needs to simultaneously achieve sublinear regret and zero
constraint violation while only using zero-order information. In particular, we
consider a multi-point feedback setting, where the player chooses $d + 1$
points in each round (where $d$ is the problem dimension) and then receives the
value of the constraint function and cost function at each of these points. To
address this problem, we propose an algorithm that leverages forward-difference
gradient estimation as well as optimistic and pessimistic action sets to
achieve $\mathcal{O}(d \sqrt{T})$ regret and zero constraint violation under
the assumption that the constraint function is smooth and strongly convex. We
then perform a numerical study to investigate the impacts of the unknown
constraint and zero-order feedback on empirical performance.",2024-07-16,"Spencer Hutchinson, Mahnoosh Alizadeh",http://arxiv.org/pdf/2407.11471v1,cs.LG
MaskVD: Region Masking for Efficient Video Object Detection,"Video tasks are compute-heavy and thus pose a challenge when deploying in
real-time applications, particularly for tasks that require state-of-the-art
Vision Transformers (ViTs). Several research efforts have tried to address this
challenge by leveraging the fact that large portions of the video undergo very
little change across frames, leading to redundant computations in frame-based
video processing. In particular, some works leverage pixel or semantic
differences across frames, however, this yields limited latency benefits with
significantly increased memory overhead. This paper, in contrast, presents a
strategy for masking regions in video frames that leverages the semantic
information in images and the temporal correlation between frames to
significantly reduce FLOPs and latency with little to no penalty in performance
over baseline models. In particular, we demonstrate that by leveraging
extracted features from previous frames, ViT backbones directly benefit from
region masking, skipping up to 80% of input regions, improving FLOPs and
latency by 3.14x and 1.5x. We improve memory and latency over the
state-of-the-art (SOTA) by 2.3x and 1.14x, while maintaining similar detection
performance. Additionally, our approach demonstrates promising results on
convolutional neural networks (CNNs) and provides latency improvements over the
SOTA up to 1.3x using specialized computational kernels.",2024-07-16,"Sreetama Sarkar, Gourav Datta, Souvik Kundu, Kai Zheng, Chirayata Bhattacharyya, Peter A. Beerel",http://arxiv.org/pdf/2407.12067v1,cs.LG
NudgeRank: Digital Algorithmic Nudging for Personalized Health,"In this paper we describe NudgeRank, an innovative digital algorithmic
nudging system designed to foster positive health behaviors on a
population-wide scale. Utilizing a novel combination of Graph Neural Networks
augmented with an extensible Knowledge Graph, this Recommender System is
operational in production, delivering personalized and context-aware nudges to
over 1.1 million care recipients daily. This enterprise deployment marks one of
the largest AI-driven health behavior change initiatives, accommodating diverse
health conditions and wearable devices. Rigorous evaluation reveals
statistically significant improvements in health outcomes, including a 6.17%
increase in daily steps and 7.61% more exercise minutes. Moreover, user
engagement and program enrollment surged, with a 13.1% open rate compared to
baseline systems' 4%. Demonstrating scalability and reliability, NudgeRank
operates efficiently on commodity compute resources while maintaining
automation and observability standards essential for production systems.",2024-07-16,"Jodi Chiam, Aloysius Lim, Ankur Teredesai",http://arxiv.org/pdf/2407.20241v1,cs.LG
Towards consistency of rule-based explainer and black box model -- fusion of rule induction and XAI-based feature importance,"Rule-based models offer a human-understandable representation, i.e. they are
interpretable. For this reason, they are used to explain the decisions of
non-interpretable complex models, referred to as black box models. The
generation of such explanations involves the approximation of a black box model
by a rule-based model. To date, however, it has not been investigated whether
the rule-based model makes decisions in the same way as the black box model it
approximates. Decision making in the same way is understood in this work as the
consistency of decisions and the consistency of the most important attributes
used for decision making. This study proposes a novel approach ensuring that
the rule-based surrogate model mimics the performance of the black box model.
The proposed solution performs an explanation fusion involving rule generation
and taking into account the feature importance determined by the selected XAI
methods for the black box model being explained. The result of the method can
be both global and local rule-based explanations. The quality of the proposed
solution was verified by extensive analysis on 30 tabular benchmark datasets
representing classification problems. Evaluation included comparison with the
reference method and an illustrative case study. In addition, the paper
discusses the possible pathways for the application of the rule-based approach
in XAI and how rule-based explanations, including the proposed method, meet the
user perspective and requirements for both content and presentation. The
software created and a detailed report containing the full experimental results
are available on the GitHub repository
(https://github.com/ruleminer/FI-rules4XAI ).",2024-07-16,"Michał Kozielski, Marek Sikora, Łukasz Wawrowski",http://arxiv.org/pdf/2407.14543v1,cs.LG
Investigating Imperceptibility of Adversarial Attacks on Tabular Data: An Empirical Analysis,"Adversarial attacks are a potential threat to machine learning models by
causing incorrect predictions through imperceptible perturbations to the input
data. While these attacks have been extensively studied in unstructured data
like images, applying them to tabular data, poses new challenges. These
challenges arise from the inherent heterogeneity and complex feature
interdependencies in tabular data, which differ from the image data. To account
for this distinction, it is necessary to establish tailored imperceptibility
criteria specific to tabular data. However, there is currently a lack of
standardised metrics for assessing the imperceptibility of adversarial attacks
on tabular data. To address this gap, we propose a set of key properties and
corresponding metrics designed to comprehensively characterise imperceptible
adversarial attacks on tabular data. These are: proximity to the original
input, sparsity of altered features, deviation from the original data
distribution, sensitivity in perturbing features with narrow distribution,
immutability of certain features that should remain unchanged, feasibility of
specific feature values that should not go beyond valid practical ranges, and
feature interdependencies capturing complex relationships between data
attributes. We evaluate the imperceptibility of five adversarial attacks,
including both bounded attacks and unbounded attacks, on tabular data using the
proposed imperceptibility metrics. The results reveal a trade-off between the
imperceptibility and effectiveness of these attacks. The study also identifies
limitations in current attack algorithms, offering insights that can guide
future research in the area. The findings gained from this empirical analysis
provide valuable direction for enhancing the design of adversarial attack
algorithms, thereby advancing adversarial machine learning on tabular data.",2024-07-16,"Zhipeng He, Chun Ouyang, Laith Alzubaidi, Alistair Barros, Catarina Moreira",http://arxiv.org/pdf/2407.11463v3,cs.LG
RIMformer: An End-to-End Transformer for FMCW Radar Interference Mitigation,"Frequency-modulated continuous-wave (FMCW) radar plays a pivotal role in the
field of remote sensing. The increasing degree of FMCW radar deployment has
increased the mutual interference, which weakens the detection capabilities of
radars and threatens reliability and safety of systems. In this paper, a novel
FMCW radar interference mitigation (RIM) method, termed as RIMformer, is
proposed by using an end-to-end Transformer-based structure. In the RIMformer,
a dual multi-head self-attention mechanism is proposed to capture the
correlations among the distinct distance elements of intermediate frequency
(IF) signals. Additionally, an improved convolutional block is integrated to
harness the power of convolution for extracting local features. The
architecture is designed to process time-domain IF signals in an end-to-end
manner, thereby avoiding the need for additional manual data processing steps.
The improved decoder structure ensures the parallelization of the network to
increase its computational efficiency. Simulation and measurement experiments
are carried out to validate the accuracy and effectiveness of the proposed
method. The results show that the proposed RIMformer can effectively mitigate
interference and restore the target signals.",2024-07-16,"Ziang Zhang, Guangzhi Chen, Youlong Weng, Shunchuan Yang, Zhiyu Jia, Jingxuan Chen",http://arxiv.org/pdf/2407.11459v2,cs.LG
Graceful task adaptation with a bi-hemispheric RL agent,"In humans, responsibility for performing a task gradually shifts from the
right hemisphere to the left. The Novelty-Routine Hypothesis (NRH) states that
the right and left hemispheres are used to perform novel and routine tasks
respectively, enabling us to learn a diverse range of novel tasks while
performing the task capably. Drawing on the NRH, we develop a reinforcement
learning agent with specialised hemispheres that can exploit generalist
knowledge from the right-hemisphere to avoid poor initial performance on novel
tasks. In addition, we find that this design has minimal impact on its ability
to learn novel tasks. We conclude by identifying improvements to our agent and
exploring potential expansion to the continual learning setting.",2024-07-16,"Grant Nicholas, Levin Kuhlmann, Gideon Kowadlo",http://arxiv.org/pdf/2407.11456v1,cs.LG
Isometric Representation Learning for Disentangled Latent Space of Diffusion Models,"The latent space of diffusion model mostly still remains unexplored, despite
its great success and potential in the field of generative modeling. In fact,
the latent space of existing diffusion models are entangled, with a distorted
mapping from its latent space to image space. To tackle this problem, we
present Isometric Diffusion, equipping a diffusion model with a geometric
regularizer to guide the model to learn a geometrically sound latent space of
the training data manifold. This approach allows diffusion models to learn a
more disentangled latent space, which enables smoother interpolation, more
accurate inversion, and more precise control over attributes directly in the
latent space. Our extensive experiments consisting of image interpolations,
image inversions, and linear editing show the effectiveness of our method.",2024-07-16,"Jaehoon Hahm, Junho Lee, Sunghyun Kim, Joonseok Lee",http://arxiv.org/pdf/2407.11451v1,cs.LG
Repurformer: Transformers for Repurposing-Aware Molecule Generation,"Generating as diverse molecules as possible with desired properties is
crucial for drug discovery research, which invokes many approaches based on
deep generative models today. Despite recent advancements in these models,
particularly in variational autoencoders (VAEs), generative adversarial
networks (GANs), Transformers, and diffusion models, a significant challenge
known as \textit{the sample bias problem} remains. This problem occurs when
generated molecules targeting the same protein tend to be structurally similar,
reducing the diversity of generation. To address this, we propose leveraging
multi-hop relationships among proteins and compounds. Our model, Repurformer,
integrates bi-directional pretraining with Fast Fourier Transform (FFT) and
low-pass filtering (LPF) to capture complex interactions and generate diverse
molecules. A series of experiments on BindingDB dataset confirm that
Repurformer successfully creates substitutes for anchor compounds that resemble
positive compounds, increasing diversity between the anchor and generated
compounds.",2024-07-16,"Changhun Lee, Gyumin Lee",http://arxiv.org/pdf/2407.11439v1,cs.LG
Genomic Language Models: Opportunities and Challenges,"Large language models (LLMs) are having transformative impacts across a wide
range of scientific fields, particularly in the biomedical sciences. Just as
the goal of Natural Language Processing is to understand sequences of words, a
major objective in biology is to understand biological sequences. Genomic
Language Models (gLMs), which are LLMs trained on DNA sequences, have the
potential to significantly advance our understanding of genomes and how DNA
elements at various scales interact to give rise to complex functions. To
showcase this potential, we highlight key applications of gLMs, including
functional constraint prediction, sequence design, and transfer learning.
Despite notable recent progress, however, developing effective and efficient
gLMs presents numerous challenges, especially for species with large, complex
genomes. Here, we discuss major considerations for developing and evaluating
gLMs.",2024-07-16,"Gonzalo Benegas, Chengzhong Ye, Carlos Albors, Jianan Canal Li, Yun S. Song",http://arxiv.org/pdf/2407.11435v2,cs.LG
Joint Data Inpainting and Graph Learning via Unrolled Neural Networks,"Given partial measurements of a time-varying graph signal, we propose an
algorithm to simultaneously estimate both the underlying graph topology and the
missing measurements. The proposed algorithm operates by training an
interpretable neural network, designed from the unrolling framework. The
proposed technique can be used both as a graph learning and a graph signal
reconstruction algorithm. This work enhances prior work in graph signal
reconstruction by allowing the underlying graph to be unknown; and also builds
on prior work in graph learning by tailoring the learned graph to the signal
reconstruction task.",2024-07-16,"Subbareddy Batreddy, Pushkal Mishra, Yaswanth Kakarla, Aditya Siripuram",http://arxiv.org/pdf/2407.11429v1,cs.LG
Semi-Supervised Generative Models for Disease Trajectories: A Case Study on Systemic Sclerosis,"We propose a deep generative approach using latent temporal processes for
modeling and holistically analyzing complex disease trajectories, with a
particular focus on Systemic Sclerosis (SSc). We aim to learn temporal latent
representations of the underlying generative process that explain the observed
patient disease trajectories in an interpretable and comprehensive way. To
enhance the interpretability of these latent temporal processes, we develop a
semi-supervised approach for disentangling the latent space using established
medical knowledge. By combining the generative approach with medical
definitions of different characteristics of SSc, we facilitate the discovery of
new aspects of the disease. We show that the learned temporal latent processes
can be utilized for further data analysis and clinical hypothesis testing,
including finding similar patients and clustering SSc patient trajectories into
novel sub-types. Moreover, our method enables personalized online monitoring
and prediction of multivariate time series with uncertainty quantification.",2024-07-16,"Cécile Trottet, Manuel Schürch, Ahmed Allam, Imon Barua, Liubov Petelytska, David Launay, Paolo Airò, Radim Bečvář, Christopher Denton, Mislav Radic, Oliver Distler, Anna-Maria Hoffmann-Vold, Michael Krauthammer, the EUSTAR collaborators",http://arxiv.org/pdf/2407.11427v2,cs.LG
Generally-Occurring Model Change for Robust Counterfactual Explanations,"With the increasing impact of algorithmic decision-making on human lives, the
interpretability of models has become a critical issue in machine learning.
Counterfactual explanation is an important method in the field of interpretable
machine learning, which can not only help users understand why machine learning
models make specific decisions, but also help users understand how to change
these decisions. Naturally, it is an important task to study the robustness of
counterfactual explanation generation algorithms to model changes. Previous
literature has proposed the concept of Naturally-Occurring Model Change, which
has given us a deeper understanding of robustness to model change. In this
paper, we first further generalize the concept of Naturally-Occurring Model
Change, proposing a more general concept of model parameter changes,
Generally-Occurring Model Change, which has a wider range of applicability. We
also prove the corresponding probabilistic guarantees. In addition, we consider
a more specific problem, data set perturbation, and give relevant theoretical
results by combining optimization theory.",2024-07-16,"Ao Xu, Tieru Wu",http://arxiv.org/pdf/2407.11426v1,cs.LG
Accounting for Work Zone Disruptions in Traffic Flow Forecasting,"Traffic speed forecasting is an important task in intelligent transportation
system management. The objective of much of the current computational research
is to minimize the difference between predicted and actual speeds, but
information modalities other than speed priors are largely not taken into
account. In particular, though state of the art performance is achieved on
speed forecasting with graph neural network methods, these methods do not
incorporate information on roadway maintenance work zones and their impacts on
predicted traffic flows; yet, the impacts of construction work zones are of
significant interest to roadway management agencies, because they translate to
impacts on the local economy and public well-being. In this paper, we build
over the convolutional graph neural network architecture and present a novel
``Graph Convolutional Network for Roadway Work Zones"" model that includes a
novel data fusion mechanism and a new heterogeneous graph aggregation
methodology to accommodate work zone information in spatio-temporal
dependencies among traffic states. The model is evaluated on two data sets that
capture traffic flows in the presence of work zones in the Commonwealth of
Virginia. Extensive comparative evaluation and ablation studies show that the
proposed model can capture complex and nonlinear spatio-temporal relationships
across a transportation corridor, outperforming baseline models, particularly
when predicting traffic flow during a workzone event.",2024-07-16,"Yuanjie Lu, Amarda Shehu, David Lattanzi",http://arxiv.org/pdf/2407.11407v1,cs.LG
Mapping savannah woody vegetation at the species level with multispecral drone and hyperspectral EnMAP data,"Savannahs are vital ecosystems whose sustainability is endangered by the
spread of woody plants. This research targets the accurate mapping of
fractional woody cover (FWC) at the species level in a South African savannah,
using EnMAP hyperspectral data. Field annotations were combined with very
high-resolution multispectral drone data to produce land cover maps that
included three woody species. The high-resolution labelled maps were then used
to generate FWC samples for each woody species class at the 30-m spatial
resolution of EnMAP. Four machine learning regression algorithms were tested
for FWC mapping on dry season EnMAP imagery. The contribution of multitemporal
information was also assessed by incorporating as additional regression
features, spectro-temporal metrics from Sentinel-2 data of both the dry and wet
seasons. The results demonstrated the suitability of our approach for
accurately mapping FWC at the species level. The highest accuracy rates
achieved from the combined EnMAP and Sentinel-2 experiments highlighted their
synergistic potential for species-level vegetation mapping.",2024-07-16,"Christina Karakizi, Akpona Okujeni, Eleni Sofikiti, Vasileios Tsironis, Athina Psalta, Konstantinos Karantzalos, Patrick Hostert, Elias Symeonakis",http://arxiv.org/pdf/2407.11404v1,cs.LG
Data selection method for assessment of autonomous vehicles,"As the popularity of autonomous vehicles has grown, many standards and
regulators, such as ISO, NHTSA, and Euro NCAP, require safety validation to
ensure a sufficient level of safety before deploying them in the real world.
Manufacturers gather a large amount of public road data for this purpose.
However, the majority of these validation activities are done manually by
humans. Furthermore, the data used to validate each driving feature may differ.
As a result, it is essential to have an efficient data selection method that
can be used flexibly and dynamically for verification and validation while also
accelerating the validation process. In this paper, we present a data selection
method that is practical, flexible, and efficient for assessment of autonomous
vehicles. Our idea is to optimize the similarity between the metadata
distribution of the selected data and a predefined metadata distribution that
is expected for validation. Our experiments on the large dataset BDD100K show
that our method can perform data selection tasks efficiently. These results
demonstrate that our methods are highly reliable and can be used to select
appropriate data for the validation of various safety functions.",2024-07-16,"Linh Trinh, Ali Anwar, Siegfried Mercelis",http://arxiv.org/pdf/2407.12065v2,cs.LG
DreamCatalyst: Fast and High-Quality 3D Editing via Controlling Editability and Identity Preservation,"Score distillation sampling (SDS) has emerged as an effective framework in
text-driven 3D editing tasks, leveraging diffusion models for 3D-consistent
editing. However, existing SDS-based 3D editing methods suffer from long
training times and produce low-quality results. We identify that the root cause
of this performance degradation is \textit{their conflict with the sampling
dynamics of diffusion models}. Addressing this conflict allows us to treat SDS
as a diffusion reverse process for 3D editing via sampling from data space. In
contrast, existing methods naively distill the score function using diffusion
models. From these insights, we propose DreamCatalyst, a novel framework that
considers these sampling dynamics in the SDS framework. Specifically, we devise
the optimization process of our DreamCatalyst to approximate the diffusion
reverse process in editing tasks, thereby aligning with diffusion sampling
dynamics. As a result, DreamCatalyst successfully reduces training time and
improves editing quality. Our method offers two modes: (1) a fast mode that
edits Neural Radiance Fields (NeRF) scenes approximately 23 times faster than
current state-of-the-art NeRF editing methods, and (2) a high-quality mode that
produces superior results about 8 times faster than these methods. Notably, our
high-quality mode outperforms current state-of-the-art NeRF editing methods in
terms of both speed and quality. DreamCatalyst also surpasses the
state-of-the-art 3D Gaussian Splatting (3DGS) editing methods, establishing
itself as an effective and model-agnostic 3D editing solution. See more
extensive results on our project page: https://dream-catalyst.github.io.",2024-07-16,"Jiwook Kim, Seonho Lee, Jaeyo Shin, Jiho Choi, Hyunjung Shim",http://arxiv.org/pdf/2407.11394v3,cs.LG
CIC-BART-SSA: Controllable Image Captioning with Structured Semantic Augmentation,"Controllable Image Captioning (CIC) aims at generating natural language
descriptions for an image, conditioned on information provided by end users,
e.g., regions, entities or events of interest. However, available
image-language datasets mainly contain captions that describe the entirety of
an image, making them ineffective for training CIC models that can potentially
attend to any subset of regions or relationships. To tackle this challenge, we
propose a novel, fully automatic method to sample additional focused and
visually grounded captions using a unified structured semantic representation
built on top of the existing set of captions associated with an image. We
leverage Abstract Meaning Representation (AMR), a cross-lingual graph-based
semantic formalism, to encode all possible spatio-semantic relations between
entities, beyond the typical spatial-relations-only focus of current methods.
We use this Structured Semantic Augmentation (SSA) framework to augment
existing image-caption datasets with the grounded controlled captions,
increasing their spatial and semantic diversity and focal coverage. We then
develop a new model, CIC-BART-SSA, specifically tailored for the CIC task, that
sources its control signals from SSA-diversified datasets. We empirically show
that, compared to SOTA CIC models, CIC-BART-SSA generates captions that are
superior in diversity and text quality, are competitive in controllability,
and, importantly, minimize the gap between broad and highly focused controlled
captioning performance by efficiently generalizing to the challenging highly
focused scenarios. Code is available at
https://github.com/SamsungLabs/CIC-BART-SSA.",2024-07-16,"Kalliopi Basioti, Mohamed A. Abdelsalam, Federico Fancellu, Vladimir Pavlovic, Afsaneh Fazly",http://arxiv.org/pdf/2407.11393v2,cs.LG
NAMER: Non-Autoregressive Modeling for Handwritten Mathematical Expression Recognition,"Recently, Handwritten Mathematical Expression Recognition (HMER) has gained
considerable attention in pattern recognition for its diverse applications in
document understanding. Current methods typically approach HMER as an
image-to-sequence generation task within an autoregressive (AR) encoder-decoder
framework. However, these approaches suffer from several drawbacks: 1) a lack
of overall language context, limiting information utilization beyond the
current decoding step; 2) error accumulation during AR decoding; and 3) slow
decoding speed. To tackle these problems, this paper makes the first attempt to
build a novel bottom-up Non-AutoRegressive Modeling approach for HMER, called
NAMER. NAMER comprises a Visual Aware Tokenizer (VAT) and a Parallel Graph
Decoder (PGD). Initially, the VAT tokenizes visible symbols and local relations
at a coarse level. Subsequently, the PGD refines all tokens and establishes
connectivities in parallel, leveraging comprehensive visual and linguistic
contexts. Experiments on CROHME 2014/2016/2019 and HME100K datasets demonstrate
that NAMER not only outperforms the current state-of-the-art (SOTA) methods on
ExpRate by 1.93%/2.35%/1.49%/0.62%, but also achieves significant speedups of
13.7x and 6.7x faster in decoding time and overall FPS, proving the
effectiveness and efficiency of NAMER.",2024-07-16,"Chenyu Liu, Jia Pan, Jinshui Hu, Baocai Yin, Bing Yin, Mingjun Chen, Cong Liu, Jun Du, Qingfeng Liu",http://arxiv.org/pdf/2407.11380v1,cs.LG
Learning-augmented Maximum Independent Set,"We study the Maximum Independent Set (MIS) problem on general graphs within
the framework of learning-augmented algorithms. The MIS problem is known to be
NP-hard and is also NP-hard to approximate to within a factor of $n^{1-\delta}$
for any $\delta>0$. We show that we can break this barrier in the presence of
an oracle obtained through predictions from a machine learning model that
answers vertex membership queries for a fixed MIS with probability
$1/2+\varepsilon$. In the first setting we consider, the oracle can be queried
once per vertex to know if a vertex belongs to a fixed MIS, and the oracle
returns the correct answer with probability $1/2 + \varepsilon$. Under this
setting, we show an algorithm that obtains an
$\tilde{O}(\sqrt{\Delta}/\varepsilon)$-approximation in $O(m)$ time where
$\Delta$ is the maximum degree of the graph. In the second setting, we allow
multiple queries to the oracle for a vertex, each of which is correct with
probability $1/2 + \varepsilon$. For this setting, we show an
$O(1)$-approximation algorithm using $O(n/\varepsilon^2)$ total queries and
$\tilde{O}(m)$ runtime.",2024-07-16,"Vladimir Braverman, Prathamesh Dharangutte, Vihan Shah, Chen Wang",http://arxiv.org/pdf/2407.11364v1,cs.LG
Graph Structure Prompt Learning: A Novel Methodology to Improve Performance of Graph Neural Networks,"Graph neural networks (GNNs) are widely applied in graph data modeling.
However, existing GNNs are often trained in a task-driven manner that fails to
fully capture the intrinsic nature of the graph structure, resulting in
sub-optimal node and graph representations. To address this limitation, we
propose a novel Graph structure Prompt Learning method (GPL) to enhance the
training of GNNs, which is inspired by prompt mechanisms in natural language
processing. GPL employs task-independent graph structure losses to encourage
GNNs to learn intrinsic graph characteristics while simultaneously solving
downstream tasks, producing higher-quality node and graph representations. In
extensive experiments on eleven real-world datasets, after being trained by
GPL, GNNs significantly outperform their original performance on node
classification, graph classification, and edge prediction tasks (up to 10.28%,
16.5%, and 24.15%, respectively). By allowing GNNs to capture the inherent
structural prompts of graphs in GPL, they can alleviate the issue of
over-smooth and achieve new state-of-the-art performances, which introduces a
novel and effective direction for GNN research with potential applications in
various domains.",2024-07-16,"Zhenhua Huang, Kunhao Li, Shaojie Wang, Zhaohong Jia, Wentao Zhu, Sharad Mehrotra",http://arxiv.org/pdf/2407.11361v1,cs.LG
Feature Inference Attack on Shapley Values,"As a solution concept in cooperative game theory, Shapley value is highly
recognized in model interpretability studies and widely adopted by the leading
Machine Learning as a Service (MLaaS) providers, such as Google, Microsoft, and
IBM. However, as the Shapley value-based model interpretability methods have
been thoroughly studied, few researchers consider the privacy risks incurred by
Shapley values, despite that interpretability and privacy are two foundations
of machine learning (ML) models.
  In this paper, we investigate the privacy risks of Shapley value-based model
interpretability methods using feature inference attacks: reconstructing the
private model inputs based on their Shapley value explanations. Specifically,
we present two adversaries. The first adversary can reconstruct the private
inputs by training an attack model based on an auxiliary dataset and black-box
access to the model interpretability services. The second adversary, even
without any background knowledge, can successfully reconstruct most of the
private features by exploiting the local linear correlations between the model
inputs and outputs. We perform the proposed attacks on the leading MLaaS
platforms, i.e., Google Cloud, Microsoft Azure, and IBM aix360. The
experimental results demonstrate the vulnerability of the state-of-the-art
Shapley value-based model interpretability methods used in the leading MLaaS
platforms and highlight the significance and necessity of designing
privacy-preserving model interpretability methods in future studies. To our
best knowledge, this is also the first work that investigates the privacy risks
of Shapley values.",2024-07-16,"Xinjian Luo, Yangfan Jiang, Xiaokui Xiao",http://arxiv.org/pdf/2407.11359v1,cs.LG
SES: Bridging the Gap Between Explainability and Prediction of Graph Neural Networks,"Despite the Graph Neural Networks' (GNNs) proficiency in analyzing graph
data, achieving high-accuracy and interpretable predictions remains
challenging. Existing GNN interpreters typically provide post-hoc explanations
disjointed from GNNs' predictions, resulting in misrepresentations.
Self-explainable GNNs offer built-in explanations during the training process.
However, they cannot exploit the explanatory outcomes to augment prediction
performance, and they fail to provide high-quality explanations of node
features and require additional processes to generate explainable subgraphs,
which is costly. To address the aforementioned limitations, we propose a
self-explained and self-supervised graph neural network (SES) to bridge the gap
between explainability and prediction. SES comprises two processes: explainable
training and enhanced predictive learning. During explainable training, SES
employs a global mask generator co-trained with a graph encoder and directly
produces crucial structure and feature masks, reducing time consumption and
providing node feature and subgraph explanations. In the enhanced predictive
learning phase, mask-based positive-negative pairs are constructed utilizing
the explanations to compute a triplet loss and enhance the node representations
by contrastive learning.",2024-07-16,"Zhenhua Huang, Kunhao Li, Shaojie Wang, Zhaohong Jia, Wentao Zhu, Sharad Mehrotra",http://arxiv.org/pdf/2407.11358v2,cs.LG
Preconditioned Gradient Descent Finds Over-Parameterized Neural Networks with Sharp Generalization for Nonparametric Regression,"We consider nonparametric regression by an over-parameterized two-layer
neural network trained by gradient descent (GD) or its variant in this paper.
We show that, if the neural network is trained with a novel Preconditioned
Gradient Descent (PGD) with early stopping and the target function has spectral
bias widely studied in the deep learning literature, the trained network
renders a particularly sharp generalization bound with a minimax optimal rate
of $\cO({1}/{n^{4\alpha/(4\alpha+1)}})$, which is sharper the current standard
rate of $\cO({1}/{n^{2\alpha/(2\alpha+1)}})$ with $2\alpha = d/(d-1)$ when the
data is distributed uniformly on the unit sphere in $\RR^d$ and $n$ is the size
of the training data. When the target function has no spectral bias, we prove
that neural network trained with regular GD with early stopping still enjoys
minimax optimal rate, and in this case our results do not require
distributional assumptions in contrast with the current known results. Our
results are built upon two significant technical contributions. First, uniform
convergence to the NTK is established during the training process by PGD or GD,
so that we can have a nice decomposition of the neural network function at any
step of GD or PGD into a function in the RKHS and an error function with a
small $L^{\infty}$-norm. Second, local Rademacher complexity is employed to
tightly bound the Rademacher complexity of the function class comprising all
the possible neural network functions obtained by GD or PGD. Our results also
indicate that PGD can be another way of avoiding the usual linear regime of NTK
and obtaining sharper generalization bound, because PGD induces a different
kernel with lower kernel complexity during the training than the regular NTK
induced by the network architecture trained by regular GD.",2024-07-16,Yingzhen Yang,http://arxiv.org/pdf/2407.11353v1,cs.LG
Performance Evaluation of Lightweight Open-source Large Language Models in Pediatric Consultations: A Comparative Analysis,"Large language models (LLMs) have demonstrated potential applications in
medicine, yet data privacy and computational burden limit their deployment in
healthcare institutions. Open-source and lightweight versions of LLMs emerge as
potential solutions, but their performance, particularly in pediatric settings
remains underexplored. In this cross-sectional study, 250 patient consultation
questions were randomly selected from a public online medical forum, with 10
questions from each of 25 pediatric departments, spanning from December 1,
2022, to October 30, 2023. Two lightweight open-source LLMs, ChatGLM3-6B and
Vicuna-7B, along with a larger-scale model, Vicuna-13B, and the widely-used
proprietary ChatGPT-3.5, independently answered these questions in Chinese
between November 1, 2023, and November 7, 2023. To assess reproducibility, each
inquiry was replicated once. We found that ChatGLM3-6B demonstrated higher
accuracy and completeness than Vicuna-13B and Vicuna-7B (P < .001), but all
were outperformed by ChatGPT-3.5. ChatGPT-3.5 received the highest ratings in
accuracy (65.2%) compared to ChatGLM3-6B (41.2%), Vicuna-13B (11.2%), and
Vicuna-7B (4.4%). Similarly, in completeness, ChatGPT-3.5 led (78.4%), followed
by ChatGLM3-6B (76.0%), Vicuna-13B (34.8%), and Vicuna-7B (22.0%) in highest
ratings. ChatGLM3-6B matched ChatGPT-3.5 in readability, both outperforming
Vicuna models (P < .001). In terms of empathy, ChatGPT-3.5 outperformed the
lightweight LLMs (P < .001). In safety, all models performed comparably well (P
> .05), with over 98.4% of responses being rated as safe. Repetition of
inquiries confirmed these findings. In conclusion, Lightweight LLMs demonstrate
promising application in pediatric healthcare. However, the observed gap
between lightweight and large-scale proprietary LLMs underscores the need for
continued development efforts.",2024-07-16,"Qiuhong Wei, Ying Cui, Mengwei Ding, Yanqin Wang, Lingling Xiang, Zhengxiong Yao, Ceran Chen, Ying Long, Zhezhen Jin, Ximing Xu",http://arxiv.org/pdf/2407.15862v1,cs.LG
Navigating the swarm: Deep neural networks command emergent behaviours,"Interacting individuals in complex systems often give rise to coherent motion
exhibiting coordinated global structures. Such phenomena are ubiquitously
observed in nature, from cell migration, bacterial swarms, animal and insect
groups, and even human societies. Primary mechanisms responsible for the
emergence of collective behavior have been extensively identified, including
local alignments based on average or relative velocity, non-local pairwise
repulsive-attractive interactions such as distance-based potentials, interplay
between local and non-local interactions, and cognitive-based inhomogeneous
interactions. However, discovering how to adapt these mechanisms to modulate
emergent behaviours remains elusive. Here, we demonstrate that it is possible
to generate coordinated structures in collective behavior at desired moments
with intended global patterns by fine-tuning an inter-agent interaction rule.
Our strategy employs deep neural networks, obeying the laws of dynamics, to
find interaction rules that command desired collective structures. The
decomposition of interaction rules into distancing and aligning forces,
expressed by polynomial series, facilitates the training of neural networks to
propose desired interaction models. Presented examples include altering the
mean radius and size of clusters in vortical swarms, timing of transitions from
random to ordered states, and continuously shifting between typical modes of
collective motions. This strategy can even be leveraged to superimpose
collective modes, resulting in hitherto unexplored but highly practical hybrid
collective patterns, such as protective security formations. Our findings
reveal innovative strategies for creating and controlling collective motion,
paving the way for new applications in robotic swarm operations, active matter
organisation, and for the uncovering of obscure interaction rules in biological
systems.",2024-07-16,"Dongjo Kim, Jeongsu Lee, Ho-Young Kim",http://arxiv.org/pdf/2407.11330v1,cs.LG
Mitigating biases in big mobility data: a case study of monitoring large-scale transit systems,"Big mobility datasets (BMD) have shown many advantages in studying human
mobility and evaluating the performance of transportation systems. However, the
quality of BMD remains poorly understood. This study evaluates biases in BMD
and develops mitigation methods. Using Google and Apple mobility data as
examples, this study compares them with benchmark data from governmental
agencies. Spatio-temporal discrepancies between BMD and benchmark are observed
and their impacts on transportation applications are investigated, emphasizing
the urgent need to address these biases to prevent misguided policymaking. This
study further proposes and tests a bias mitigation method. It is shown that the
mitigated BMD could generate valuable insights into large-scale public transit
systems across 100+ US counties, revealing regional disparities of the recovery
of transit systems from the COVID-19. This study underscores the importance of
caution when using BMD in transportation research and presents effective
mitigation strategies that would benefit practitioners.",2024-07-16,"Feilong Wang, Xuegang Ban, Peng Chen, Chenxi Liu, Rong Zhao",http://arxiv.org/pdf/2407.14541v1,cs.LG
LiteGPT: Large Vision-Language Model for Joint Chest X-ray Localization and Classification Task,"Vision-language models have been extensively explored across a wide range of
tasks, achieving satisfactory performance; however, their application in
medical imaging remains underexplored. In this work, we propose a unified
framework - LiteGPT - for the medical imaging. We leverage multiple pre-trained
visual encoders to enrich information and enhance the performance of
vision-language models. To the best of our knowledge, this is the first study
to utilize vision-language models for the novel task of joint localization and
classification in medical images. Besides, we are pioneers in providing
baselines for disease localization in chest X-rays. Finally, we set new
state-of-the-art performance in the image classification task on the
well-benchmarked VinDr-CXR dataset. All code and models are publicly available
online: https://github.com/leduckhai/LiteGPT",2024-07-16,"Khai Le-Duc, Ryan Zhang, Ngoc Son Nguyen, Tan-Hanh Pham, Anh Dao, Ba Hung Ngo, Anh Totti Nguyen, Truong-Son Hy",http://arxiv.org/pdf/2407.12064v1,cs.LG
Digital Twin Vehicular Edge Computing Network: Task Offloading and Resource Allocation,"With the increasing demand for multiple applications on internet of vehicles.
It requires vehicles to carry out multiple computing tasks in real time.
However, due to the insufficient computing capability of vehicles themselves,
offloading tasks to vehicular edge computing (VEC) servers and allocating
computing resources to tasks becomes a challenge. In this paper, a multi task
digital twin (DT) VEC network is established. By using DT to develop offloading
strategies and resource allocation strategies for multiple tasks of each
vehicle in a single slot, an optimization problem is constructed. To solve it,
we propose a multi-agent reinforcement learning method on the task offloading
and resource allocation. Numerous experiments demonstrate that our method is
effective compared to other benchmark algorithms.",2024-07-16,"Yu Xie, Qiong Wu, Pingyi Fan",http://arxiv.org/pdf/2407.11310v1,cs.LG
Detection of Global Anomalies on Distributed IoT Edges with Device-to-Device Communication,"Anomaly detection is an important function in IoT applications for finding
outliers caused by abnormal events. Anomaly detection sometimes comes with
high-frequency data sampling which should be carried out at Edge devices rather
than Cloud. In this paper, we consider the case that multiple IoT devices are
installed in a single remote site and that they collaboratively detect
anomalies from the observations with device-to-device communications. For this,
we propose a fully distributed collaborative scheme for training distributed
anomaly detectors with Wireless Ad Hoc Federated Learning, namely
""WAFL-Autoencoder"". We introduce the concept of Global Anomaly which sample is
not only rare to the local device but rare to all the devices in the target
domain. We also propose a distributed threshold-finding algorithm for Global
Anomaly detection. With our standard benchmark-based evaluation, we have
confirmed that our scheme trained anomaly detectors perfectly across the
devices. We have also confirmed that the devices collaboratively found
thresholds for Global Anomaly detection with low false positive rates while
achieving high true positive rates with few exceptions.",2024-07-16,"Hideya Ochiai, Riku Nishihata, Eisuke Tomiyama, Yuwei Sun, Hiroshi Esaki",http://arxiv.org/pdf/2407.11308v1,cs.LG
Zero-Shot Adaptation for Approximate Posterior Sampling of Diffusion Models in Inverse Problems,"Diffusion models have emerged as powerful generative techniques for solving
inverse problems. Despite their success in a variety of inverse problems in
imaging, these models require many steps to converge, leading to slow inference
time. Recently, there has been a trend in diffusion models for employing
sophisticated noise schedules that involve more frequent iterations of
timesteps at lower noise levels, thereby improving image generation and
convergence speed. However, application of these ideas for solving inverse
problems with diffusion models remain challenging, as these noise schedules do
not perform well when using empirical tuning for the forward model
log-likelihood term weights. To tackle these challenges, we propose zero-shot
approximate posterior sampling (ZAPS) that leverages connections to zero-shot
physics-driven deep learning. ZAPS fixes the number of sampling steps, and uses
zero-shot training with a physics-guided loss function to learn log-likelihood
weights at each irregular timestep. We apply ZAPS to the recently proposed
diffusion posterior sampling method as baseline, though ZAPS can also be used
with other posterior sampling diffusion models. We further approximate the
Hessian of the logarithm of the prior using a diagonalization approach with
learnable diagonal entries for computational efficiency. These parameters are
optimized over a fixed number of epochs with a given computational budget. Our
results for various noisy inverse problems, including Gaussian and motion
deblurring, inpainting, and super-resolution show that ZAPS reduces inference
time, provides robustness to irregular noise schedules and improves
reconstruction quality. Code is available at https://github.com/ualcalar17/ZAPS",2024-07-16,"Yaşar Utku Alçalar, Mehmet Akçakaya",http://arxiv.org/pdf/2407.11288v1,cs.LG
CLAMS: A System for Zero-Shot Model Selection for Clustering,"We propose an AutoML system that enables model selection on clustering
problems by leveraging optimal transport-based dataset similarity. Our
objective is to establish a comprehensive AutoML pipeline for clustering
problems and provide recommendations for selecting the most suitable
algorithms, thus opening up a new area of AutoML beyond the traditional
supervised learning settings. We compare our results against multiple
clustering baselines and find that it outperforms all of them, hence
demonstrating the utility of similarity-based automated model selection for
solving clustering applications.",2024-07-15,"Prabhant Singh, Pieter Gijsbers, Murat Onur Yildirim, Elif Ceren Gok, Joaquin Vanschoren",http://arxiv.org/pdf/2407.11286v1,cs.LG
Novel Approach for Predicting the Air Quality Index of Megacities through Attention-Enhanced Deep Multitask Spatiotemporal Learning,"Air pollution remains one of the most formidable environmental threats to
human health globally, particularly in urban areas, contributing to nearly 7
million premature deaths annually. Megacities, defined as cities with
populations exceeding 10 million, are frequent hotspots of severe pollution,
experiencing numerous weeks of dangerously poor air quality due to the
concentration of harmful pollutants. In addition, the complex interplay of
factors makes accurate air quality predictions incredibly challenging, and
prediction models often struggle to capture these intricate dynamics. To
address these challenges, this paper proposes an attention-enhanced deep
multitask spatiotemporal machine learning model based on long-short-term memory
networks for long-term air quality monitoring and prediction. The model
demonstrates robust performance in predicting the levels of major pollutants
such as sulfur dioxide and carbon monoxide, effectively capturing complex
trends and fluctuations. The proposed model provides actionable information for
policymakers, enabling informed decision making to improve urban air quality.",2024-07-15,"Harun Khan, Joseph Tso, Nathan Nguyen, Nivaan Kaushal, Ansh Malhotra, Nayel Rehman",http://arxiv.org/pdf/2407.11283v1,cs.LG
Intelligent Cross-Organizational Process Mining: A Survey and New Perspectives,"Process mining, as a high-level field in data mining, plays a crucial role in
enhancing operational efficiency and decision-making across organizations. In
this survey paper, we delve into the growing significance and ongoing trends in
the field of process mining, advocating a specific viewpoint on its contents,
application, and development in modern businesses and process management,
particularly in cross-organizational settings. We first summarize the framework
of process mining, common industrial applications, and the latest advances
combined with artificial intelligence, such as workflow optimization,
compliance checking, and performance analysis. Then, we propose a holistic
framework for intelligent process analysis and outline initial methodologies in
cross-organizational settings, highlighting both challenges and opportunities.
This particular perspective aims to revolutionize process mining by leveraging
artificial intelligence to offer sophisticated solutions for complex,
multi-organizational data analysis. By integrating advanced machine learning
techniques, we can enhance predictive capabilities, streamline processes, and
facilitate real-time decision-making. Furthermore, we pinpoint avenues for
future investigations within the research community, encouraging the
exploration of innovative algorithms, data integration strategies, and
privacy-preserving methods to fully harness the potential of process mining in
diverse, interconnected business environments.",2024-07-15,"Yiyuan Yang, Zheshun Wu, Yong Chu, Zhenghua Chen, Zenglin Xu, Qingsong Wen",http://arxiv.org/pdf/2407.11280v1,cs.LG
Private Estimation when Data and Privacy Demands are Correlated,"Differential Privacy (DP) is the current gold-standard for ensuring privacy
for statistical queries. Estimation problems under DP constraints appearing in
the literature have largely focused on providing equal privacy to all users. We
consider the problems of empirical mean estimation for univariate data and
frequency estimation for categorical data, both subject to heterogeneous
privacy constraints. Each user, contributing a sample to the dataset, is
allowed to have a different privacy demand. The dataset itself is assumed to be
worst-case and we study both problems under two different formulations --
first, where privacy demands and data may be correlated, and second, where
correlations are weakened by random permutation of the dataset. We establish
theoretical performance guarantees for our proposed algorithms, under both PAC
error and mean-squared error. These performance guarantees translate to minimax
optimality in several instances, and experiments confirm superior performance
of our algorithms over other baseline techniques.",2024-07-15,"Syomantak Chaudhuri, Thomas A. Courtade",http://arxiv.org/pdf/2407.11274v2,cs.LG
Multistep Brent Oil Price Forecasting with a Multi-Aspect Meta-heuristic Optimization and Ensemble Deep Learning Model,"Accurate crude oil price forecasting is crucial for various economic
activities, including energy trading, risk management, and investment planning.
Although deep learning models have emerged as powerful tools for crude oil
price forecasting, achieving accurate forecasts remains challenging. Deep
learning models' performance is heavily influenced by hyperparameters tuning,
and they are expected to perform differently under various circumstances.
Furthermore, price volatility is also sensitive to external factors such as
world events. To address these limitations, we propose a hybrid approach that
integrates metaheuristic optimization with an ensemble of five widely used
neural network architectures for time series forecasting. Unlike existing
methods that apply metaheuristics to optimise hyperparameters within the neural
network architecture, we exploit the GWO metaheuristic optimiser at four
levels: feature selection, data preparation, model training, and forecast
blending. The proposed approach has been evaluated for forecasting three-ahead
days using real-world Brent crude oil price data, and the obtained results
demonstrate that the proposed approach improves the forecasting performance
measured using various benchmarks, achieving 0.000127 of MSE.",2024-07-15,"Mohammed Alruqimi, Luca Di Persio",http://arxiv.org/pdf/2407.12062v2,cs.LG
Heterogenous Multi-Source Data Fusion Through Input Mapping and Latent Variable Gaussian Process,"Artificial intelligence and machine learning frameworks have served as
computationally efficient mapping between inputs and outputs for engineering
problems. These mappings have enabled optimization and analysis routines that
have warranted superior designs, ingenious material systems and optimized
manufacturing processes. A common occurrence in such modeling endeavors is the
existence of multiple source of data, each differentiated by fidelity,
operating conditions, experimental conditions, and more. Data fusion frameworks
have opened the possibility of combining such differentiated sources into
single unified models, enabling improved accuracy and knowledge transfer.
However, these frameworks encounter limitations when the different sources are
heterogeneous in nature, i.e., not sharing the same input parameter space.
These heterogeneous input scenarios can occur when the domains differentiated
by complexity, scale, and fidelity require different parametrizations. Towards
addressing this void, a heterogeneous multi-source data fusion framework is
proposed based on input mapping calibration (IMC) and latent variable Gaussian
process (LVGP). In the first stage, the IMC algorithm is utilized to transform
the heterogeneous input parameter spaces into a unified reference parameter
space. In the second stage, a multi-source data fusion model enabled by LVGP is
leveraged to build a single source-aware surrogate model on the transformed
reference space. The proposed framework is demonstrated and analyzed on three
engineering case studies (design of cantilever beam, design of ellipsoidal void
and modeling properties of Ti6Al4V alloy). The results indicate that the
proposed framework provides improved predictive accuracy over a single source
model and transformed but source unaware model.",2024-07-15,"Yigitcan Comlek, Sandipp Krishnan Ravi, Piyush Pandita, Sayan Ghosh, Liping Wang, Wei Chen",http://arxiv.org/pdf/2407.11268v1,cs.LG
Enhancing Multi-Step Brent Oil Price Forecasting with Ensemble Multi-Scenario Bi-GRU Networks,"Despite numerous research efforts in applying deep learning to time series
forecasting, achieving high accuracy in multi-step predictions for volatile
time series like crude oil prices remains a significant challenge. Moreover,
most existing approaches primarily focus on one-step forecasting, and the
performance often varies depending on the dataset and specific case study. In
this paper, we introduce an ensemble model to capture Brent oil price
volatility and enhance the multi-step prediction. Our methodology employs a
two-pronged approach. First, we assess popular deep-learning models and the
impact of various external factors on forecasting accuracy. Then, we introduce
an ensemble multi-step forecasting model for Brent oil prices. Our approach
generates accurate forecasts by employing ensemble techniques across multiple
forecasting scenarios using three BI-GRU networks.Extensive experiments were
conducted on a dataset encompassing the COVID-19 pandemic period, which had a
significant impact on energy markets. The proposed model's performance was
evaluated using the standard evaluation metrics of MAE, MSE, and RMSE. The
results demonstrate that the proposed model outperforms benchmark and
established models.",2024-07-15,"Mohammed Alruqimi, Luca Di Persio",http://arxiv.org/pdf/2407.11267v1,cs.LG
Separable Operator Networks,"Operator learning has become a powerful tool in machine learning for modeling
complex physical systems governed by partial differential equations (PDEs).
Although Deep Operator Networks (DeepONet) show promise, they require extensive
data acquisition. Physics-informed DeepONets (PI-DeepONet) mitigate data
scarcity but suffer from inefficient training processes. We introduce Separable
Operator Networks (SepONet), a novel framework that significantly enhances the
efficiency of physics-informed operator learning. SepONet uses independent
trunk networks to learn basis functions separately for different coordinate
axes, enabling faster and more memory-efficient training via forward-mode
automatic differentiation. We provide a universal approximation theorem for
SepONet proving the existence of a separable approximation to any nonlinear
continuous operator. Then, we comprehensively benchmark its representational
capacity and computational performance against PI-DeepONet. Our results
demonstrate SepONet's superior performance across various nonlinear and
inseparable PDEs, with SepONet's advantages increasing with problem complexity,
dimension, and scale. For 1D time-dependent PDEs, SepONet achieves up to 112x
faster training and 82x reduction in GPU memory usage compared to PI-DeepONet,
while maintaining comparable accuracy. For the 2D time-dependent nonlinear
diffusion equation, SepONet efficiently handles the complexity, achieving a
6.44% mean relative $\ell_{2}$ test error, while PI-DeepONet fails due to
memory constraints. This work paves the way for extreme-scale learning of
continuous mappings between infinite-dimensional function spaces. Open source
code is available at
\url{https://github.com/HewlettPackard/separable-operator-networks}.",2024-07-15,"Xinling Yu, Sean Hooten, Ziyue Liu, Yequan Zhao, Marco Fiorentino, Thomas Van Vaerenbergh, Zheng Zhang",http://arxiv.org/pdf/2407.11253v3,cs.LG
Disentangling Representations through Multi-task Learning,"Intelligent perception and interaction with the world hinges on internal
representations that capture its underlying structure (''disentangled'' or
''abstract'' representations). Disentangled representations serve as world
models, isolating latent factors of variation in the world along approximately
orthogonal directions, thus facilitating feature-based generalization. We
provide experimental and theoretical results guaranteeing the emergence of
disentangled representations in agents that optimally solve multi-task evidence
accumulation classification tasks, canonical in the neuroscience literature.
The key conceptual finding is that, by producing accurate multi-task
classification estimates, a system implicitly represents a set of coordinates
specifying a disentangled representation of the underlying latent state of the
data it receives. The theory provides conditions for the emergence of these
representations in terms of noise, number of tasks, and evidence accumulation
time. We experimentally validate these predictions in RNNs trained to
multi-task, which learn disentangled representations in the form of continuous
attractors, leading to zero-shot out-of-distribution (OOD) generalization in
predicting latent factors. We demonstrate the robustness of our framework
across autoregressive architectures, decision boundary geometries and in tasks
requiring classification confidence estimation. We find that transformers are
particularly suited for disentangling representations, which might explain
their unique world understanding abilities. Overall, our framework establishes
a formal link between competence at multiple tasks and the formation of
disentangled, interpretable world models in both biological and artificial
systems, and helps explain why ANNs often arrive at human-interpretable
concepts, and how they both may acquire exceptional zero-shot generalization
capabilities.",2024-07-15,"Pantelis Vafidis, Aman Bhargava, Antonio Rangel",http://arxiv.org/pdf/2407.11249v3,cs.LG
(Deep) Generative Geodesics,"In this work, we propose to study the global geometrical properties of
generative models. We introduce a new Riemannian metric to assess the
similarity between any two data points. Importantly, our metric is agnostic to
the parametrization of the generative model and requires only the evaluation of
its data likelihood. Moreover, the metric leads to the conceptual definition of
generative distances and generative geodesics, whose computation can be done
efficiently in the data space. Their approximations are proven to converge to
their true values under mild conditions. We showcase three proof-of-concept
applications of this global metric, including clustering, data visualization,
and data interpolation, thus providing new tools to support the geometrical
understanding of generative models.",2024-07-15,"Beomsu Kim, Michael Puthawala, Jong Chul Ye, Emanuele Sansone",http://arxiv.org/pdf/2407.11244v1,cs.LG
From GaLore to WeLore: How Low-Rank Weights Non-uniformly Emerge from Low-Rank Gradients,"Modern Large Language Models (LLMs) are composed of matrices with billions of
elements, making their storage and processing quite demanding in terms of
computational resources and memory usage. Being significantly large, such
matrices can often be expressed in low-rank format with potential to relax
resource requirements. Unlike prior works which focus on developing novel
matrix decomposition algorithms, in this work we first study the emergence of
low-rank structures across matrices within different layers of LLMs and
establish a consequential relationship between the gradient dynamics and
emerging low-rank expressiveness of matrices. Our findings reveal that
different layers exhibit varying levels of converged low-rank structure,
necessitating a non-uniform rank reduction across them to minimize performance
drop due to compression. In view of that, we present Weight Low-Rank Projection
(WeLore) that unifies weight compression and memory-efficient fine-tuning as
ONE, in a data-agnostic and one-shot way. WeLore capitalizes the heavy-tail
distribution of singular values to identify a suitable rank reduction ratio for
matrices within LLMs. Going beyond only as a compression technique, WeLore
categorizes weight matrices into Low-rank Components (LRCs) and Non-Low-rank
Components (N-LRCs) based on their ability to express themselves as low-rank.
Our gradient perspective and extensive experiments illustrate that LRCs tend to
have better finetuning capabilities and can closely mimic (sometimes
outperform) the training loss trajectory and performance of full-finetuning
with notable memory and compute footprint reduction. For example, finetuning a
50\% compressed LLaMa-2 7B model using only a fraction of parameters in LRCs
(WeLore) can outperform its full finetuning with ~3x better throughput and
~0.6x GPU requirement. Our codes are available at
\url{https://github.com/VITA-Group/welore}",2024-07-15,"Ajay Jaiswal, Lu Yin, Zhenyu Zhang, Shiwei Liu, Jiawei Zhao, Yuandong Tian, Zhangyang Wang",http://arxiv.org/pdf/2407.11239v1,cs.LG
Unraveling the Truth: Do VLMs really Understand Charts? A Deep Dive into Consistency and Robustness,"Chart question answering (CQA) is a crucial area of Visual Language
Understanding. However, the robustness and consistency of current Visual
Language Models (VLMs) in this field remain under-explored. This paper
evaluates state-of-the-art VLMs on comprehensive datasets, developed
specifically for this study, encompassing diverse question categories and chart
formats. We investigate two key aspects: 1) the models' ability to handle
varying levels of chart and question complexity, and 2) their robustness across
different visual representations of the same underlying data. Our analysis
reveals significant performance variations based on question and chart types,
highlighting both strengths and weaknesses of current models. Additionally, we
identify areas for improvement and propose future research directions to build
more robust and reliable CQA systems. This study sheds light on the limitations
of current models and paves the way for future advancements in the field.",2024-07-15,"Srija Mukhopadhyay, Adnan Qidwai, Aparna Garimella, Pritika Ramu, Vivek Gupta, Dan Roth",http://arxiv.org/pdf/2407.11229v2,cs.LG
Mechanistic interpretability of large language models with applications to the financial services industry,"Large Language Models such as GPTs (Generative Pre-trained Transformers)
exhibit remarkable capabilities across a broad spectrum of applications.
Nevertheless, due to their intrinsic complexity, these models present
substantial challenges in interpreting their internal decision-making
processes. This lack of transparency poses critical challenges when it comes to
their adaptation by financial institutions, where concerns and accountability
regarding bias, fairness, and reliability are of paramount importance.
Mechanistic interpretability aims at reverse engineering complex AI models such
as transformers. In this paper, we are pioneering the use of mechanistic
interpretability to shed some light on the inner workings of large language
models for use in financial services applications. We offer several examples of
how algorithmic tasks can be designed for compliance monitoring purposes. In
particular, we investigate GPT-2 Small's attention pattern when prompted to
identify potential violation of Fair Lending laws. Using direct logit
attribution, we study the contributions of each layer and its corresponding
attention heads to the logit difference in the residual stream. Finally, we
design clean and corrupted prompts and use activation patching as a causal
intervention method to localize our task completion components further. We
observe that the (positive) heads $10.2$ (head $2$, layer $10$), $10.7$, and
$11.3$, as well as the (negative) heads $9.6$ and $10.6$ play a significant
role in the task completion.",2024-07-15,"Ashkan Golgoon, Khashayar Filom, Arjun Ravi Kannan",http://arxiv.org/pdf/2407.11215v2,cs.LG
PutnamBench: Evaluating Neural Theorem-Provers on the Putnam Mathematical Competition,"We present PutnamBench, a new multi-language benchmark for evaluating the
ability of neural theorem-provers to solve competition mathematics problems.
PutnamBench consists of 1692 hand-constructed formalizations of 640 theorems
sourced from the William Lowell Putnam Mathematical Competition, the premier
undergraduate-level mathematics competition in North America. All the problems
have formalizations in Lean 4 and Isabelle; a substantial subset also has Coq
formalizations. PutnamBench requires significant problem-solving ability and
proficiency in a broad range of topics taught in undergraduate mathematics
courses. We use PutnamBench to evaluate several established neural and symbolic
theorem-provers. These approaches can only solve a handful of the PutnamBench
problems, establishing the benchmark as a difficult open challenge for research
on neural theorem-proving. PutnamBench is available at
https://github.com/trishullab/PutnamBench.",2024-07-15,"George Tsoukalas, Jasper Lee, John Jennings, Jimmy Xin, Michelle Ding, Michael Jennings, Amitayush Thakur, Swarat Chaudhuri",http://arxiv.org/pdf/2407.11214v2,cs.LG
PupilSense: A Novel Application for Webcam-Based Pupil Diameter Estimation,"Measuring pupil diameter is vital for gaining insights into physiological and
psychological states - traditionally captured by expensive, specialized
equipment like Tobii eye-trackers and Pupillabs glasses. This paper presents a
novel application that enables pupil diameter estimation using standard
webcams, making the process accessible in everyday environments without
specialized equipment. Our app estimates pupil diameters from videos and offers
detailed analysis, including class activation maps, graphs of predicted left
and right pupil diameters, and eye aspect ratios during blinks. This tool
expands the accessibility of pupil diameter measurement, particularly in
everyday settings, benefiting fields like human behavior research and
healthcare. Additionally, we present a new open source dataset for pupil
diameter estimation using webcam images containing cropped eye images and
corresponding pupil diameter measurements.",2024-07-15,"Vijul Shah, Ko Watanabe, Brian B. Moser, Andreas Dengel",http://arxiv.org/pdf/2407.11204v2,cs.LG
Differentiable Neural-Integrated Meshfree Method for Forward and Inverse Modeling of Finite Strain Hyperelasticity,"The present study aims to extend the novel physics-informed machine learning
approach, specifically the neural-integrated meshfree (NIM) method, to model
finite-strain problems characterized by nonlinear elasticity and large
deformations. To this end, the hyperelastic material models are integrated into
the loss function of the NIM method by employing a consistent local variational
formulation. Thanks to the inherent differentiable programming capabilities,
NIM can circumvent the need for derivation of Newton-Raphson linearization of
the variational form and the resulting tangent stiffness matrix, typically
required in traditional numerical methods. Additionally, NIM utilizes a hybrid
neural-numerical approximation encoded with partition-of-unity basis functions,
coined NeuroPU, to effectively represent the displacement and streamline the
training process. NeuroPU can also be used for approximating the unknown
material fields, enabling NIM a unified framework for both forward and inverse
modeling. For the imposition of displacement boundary conditions, this study
introduces a new approach based on singular kernel functions into the NeuroPU
approximation, leveraging its unique feature that allows for customized basis
functions. Numerical experiments demonstrate the NIM method's capability in
forward hyperelasticity modeling, achieving desirable accuracy, with errors
among $10^{-3} \sim 10^{-5}$ in the relative $L_2$ norm, comparable to the
well-established finite element solvers. Furthermore, NIM is applied to address
the complex task of identifying heterogeneous mechanical properties of
hyperelastic materials from strain data, validating its effectiveness in the
inverse modeling of nonlinear materials. To leverage GPU acceleration, NIM is
fully implemented on the JAX deep learning framework in this study, utilizing
the accelerator-oriented array computation capabilities offered by JAX.",2024-07-15,"Honghui Du, Binyao Guo, QiZhi He",http://arxiv.org/pdf/2407.11183v1,cs.LG
Transformer-based Drum-level Prediction in a Boiler Plant with Delayed Relations among Multivariates,"The steam drum water level is a critical parameter that directly impacts the
safety and efficiency of power plant operations. However, predicting the drum
water level in boilers is challenging due to complex non-linear process
dynamics originating from long-time delays and interrelations, as well as
measurement noise. This paper investigates the application of Transformer-based
models for predicting drum water levels in a steam boiler plant. Leveraging the
capabilities of Transformer architectures, this study aims to develop an
accurate and robust predictive framework to anticipate water level fluctuations
and facilitate proactive control strategies. To this end, a prudent pipeline is
proposed, including 1) data preprocess, 2) causal relation analysis, 3) delay
inference, 4) variable augmentation, and 5) prediction. Through extensive
experimentation and analysis, the effectiveness of Transformer-based approaches
in steam drum water level prediction is evaluated, highlighting their potential
to enhance operational stability and optimize plant performance.",2024-07-15,"Gang Su, Sun Yang, Zhishuai Li",http://arxiv.org/pdf/2407.11180v1,cs.LG
Physics-embedded Fourier Neural Network for Partial Differential Equations,"We consider solving complex spatiotemporal dynamical systems governed by
partial differential equations (PDEs) using frequency domain-based discrete
learning approaches, such as Fourier neural operators. Despite their widespread
use for approximating nonlinear PDEs, the majority of these methods neglect
fundamental physical laws and lack interpretability. We address these
shortcomings by introducing Physics-embedded Fourier Neural Networks (PeFNN)
with flexible and explainable error control. PeFNN is designed to enforce
momentum conservation and yields interpretable nonlinear expressions by
utilizing unique multi-scale momentum-conserving Fourier (MC-Fourier) layers
and an element-wise product operation. The MC-Fourier layer is by design
translation- and rotation-invariant in the frequency domain, serving as a
plug-and-play module that adheres to the laws of momentum conservation. PeFNN
establishes a new state-of-the-art in solving widely employed spatiotemporal
PDEs and generalizes well across input resolutions. Further, we demonstrate its
outstanding performance for challenging real-world applications such as
large-scale flood simulations.",2024-07-15,"Qingsong Xu, Nils Thuerey, Yilei Shi, Jonathan Bamber, Chaojun Ouyang, Xiao Xiang Zhu",http://arxiv.org/pdf/2407.11158v1,cs.LG
"Lessons from a human-in-the-loop machine learning approach for identifying vacant, abandoned, and deteriorated properties in Savannah, Georgia","Addressing strategies for managing vacant, abandoned, and deteriorated (VAD)
properties is important for maintaining healthy communities. Yet, the process
of identifying these properties can be difficult. Here, we create a
human-in-the-loop machine learning (HITLML) model called VADecide and apply it
to a parcel-level case study in Savannah, Georgia. The results show a higher
prediction accuracy than was achieved when using a machine learning model
without human input in the training. The HITLML approach also reveals
differences between machine vs. human-generated results. Our findings
contribute to knowledge about the advantages and challenges of HITLML in urban
planning.
  [Accepted for Publication at a Peer Review Journal]",2024-07-15,"Xiaofan Liang, Brian Brainerd, Tara Hicks, Clio Andris",http://arxiv.org/pdf/2407.11138v2,cs.LG
Discrete generative diffusion models without stochastic differential equations: a tensor network approach,"Diffusion models (DMs) are a class of generative machine learning methods
that sample a target distribution by transforming samples of a trivial (often
Gaussian) distribution using a learned stochastic differential equation. In
standard DMs, this is done by learning a ``score function'' that reverses the
effect of adding diffusive noise to the distribution of interest. Here we
consider the generalisation of DMs to lattice systems with discrete degrees of
freedom, and where noise is added via Markov chain jump dynamics. We show how
to use tensor networks (TNs) to efficiently define and sample such ``discrete
diffusion models'' (DDMs) without explicitly having to solve a stochastic
differential equation. We show the following: (i) by parametrising the data and
evolution operators as TNs, the denoising dynamics can be represented exactly;
(ii) the auto-regressive nature of TNs allows to generate samples efficiently
and without bias; (iii) for sampling Boltzmann-like distributions, TNs allow to
construct an efficient learning scheme that integrates well with Monte Carlo.
We illustrate this approach to study the equilibrium of two models with
non-trivial thermodynamics, the $d=1$ constrained Fredkin chain and the $d=2$
Ising model.",2024-07-15,"Luke Causer, Grant M. Rotskoff, Juan P. Garrahan",http://arxiv.org/pdf/2407.11133v1,cs.LG
Towards Adversarially Robust Vision-Language Models: Insights from Design Choices and Prompt Formatting Techniques,"Vision-Language Models (VLMs) have witnessed a surge in both research and
real-world applications. However, as they are becoming increasingly prevalent,
ensuring their robustness against adversarial attacks is paramount. This work
systematically investigates the impact of model design choices on the
adversarial robustness of VLMs against image-based attacks. Additionally, we
introduce novel, cost-effective approaches to enhance robustness through prompt
formatting. By rephrasing questions and suggesting potential adversarial
perturbations, we demonstrate substantial improvements in model robustness
against strong image-based attacks such as Auto-PGD. Our findings provide
important guidelines for developing more robust VLMs, particularly for
deployment in safety-critical environments.",2024-07-15,"Rishika Bhagwatkar, Shravan Nayak, Reza Bayat, Alexis Roger, Daniel Z Kaplan, Pouya Bashivan, Irina Rish",http://arxiv.org/pdf/2407.11121v1,cs.LG
VGBench: Evaluating Large Language Models on Vector Graphics Understanding and Generation,"In the realm of vision models, the primary mode of representation is using
pixels to rasterize the visual world. Yet this is not always the best or unique
way to represent visual content, especially for designers and artists who
depict the world using geometry primitives such as polygons. Vector graphics
(VG), on the other hand, offer a textual representation of visual content,
which can be more concise and powerful for content like cartoons, sketches and
scientific figures. Recent studies have shown promising results on processing
vector graphics with capable Large Language Models (LLMs). However, such works
focus solely on qualitative results, understanding, or a specific type of
vector graphics. We propose VGBench, a comprehensive benchmark for LLMs on
handling vector graphics through diverse aspects, including (a) both visual
understanding and generation, (b) evaluation of various vector graphics
formats, (c) diverse question types, (d) wide range of prompting techniques,
(e) under multiple LLMs and (f) comparison with VLMs on rasterized
representations. Evaluating on our collected 4279 understanding and 5845
generation samples, we find that LLMs show strong capability on both aspects
while exhibiting less desirable performance on low-level formats (SVG). Both
data and evaluation pipeline will be open-sourced at https://vgbench.github.io.",2024-07-15,"Bocheng Zou, Mu Cai, Jianrui Zhang, Yong Jae Lee",http://arxiv.org/pdf/2407.10972v2,cs.LG
Walking the Values in Bayesian Inverse Reinforcement Learning,"The goal of Bayesian inverse reinforcement learning (IRL) is recovering a
posterior distribution over reward functions using a set of demonstrations from
an expert optimizing for a reward unknown to the learner. The resulting
posterior over rewards can then be used to synthesize an apprentice policy that
performs well on the same or a similar task. A key challenge in Bayesian IRL is
bridging the computational gap between the hypothesis space of possible rewards
and the likelihood, often defined in terms of Q values: vanilla Bayesian IRL
needs to solve the costly forward planning problem - going from rewards to the
Q values - at every step of the algorithm, which may need to be done thousands
of times. We propose to solve this by a simple change: instead of focusing on
primarily sampling in the space of rewards, we can focus on primarily working
in the space of Q-values, since the computation required to go from Q-values to
reward is radically cheaper. Furthermore, this reversion of the computation
makes it easy to compute the gradient allowing efficient sampling using
Hamiltonian Monte Carlo. We propose ValueWalk - a new Markov chain Monte Carlo
method based on this insight - and illustrate its advantages on several tasks.",2024-07-15,"Ondrej Bajgar, Alessandro Abate, Konstantinos Gatsis, Michael A. Osborne",http://arxiv.org/pdf/2407.10971v1,cs.LG
Q-Sparse: All Large Language Models can be Fully Sparsely-Activated,"We introduce, Q-Sparse, a simple yet effective approach to training
sparsely-activated large language models (LLMs). Q-Sparse enables full sparsity
of activations in LLMs which can bring significant efficiency gains in
inference. This is achieved by applying top-K sparsification to the activations
and the straight-through-estimator to the training. We also introduce Block
Q-Sparse for batch training and inference. The key results from this work are,
(1) Q-Sparse can achieve results comparable to those of baseline LLMs while
being much more efficient at inference time; (2) We present an
inference-optimal scaling law for sparsely-activated LLMs; (3) Q-Sparse is
effective in different settings, including training-from-scratch,
continue-training of off-the-shelf LLMs, and finetuning; (4) Q-Sparse works for
both full-precision and 1-bit LLMs (e.g., BitNet b1.58). Particularly, the
synergy of BitNet b1.58 and Q-Sparse (can be equipped with MoE) provides the
cornerstone and a clear path to revolutionize the efficiency, including cost
and energy consumption, of future LLMs.",2024-07-15,"Hongyu Wang, Shuming Ma, Ruiping Wang, Furu Wei",http://arxiv.org/pdf/2407.10969v3,cs.LG
BECAUSE: Bilinear Causal Representation for Generalizable Offline Model-based Reinforcement Learning,"Offline model-based reinforcement learning (MBRL) enhances data efficiency by
utilizing pre-collected datasets to learn models and policies, especially in
scenarios where exploration is costly or infeasible. Nevertheless, its
performance often suffers from the objective mismatch between model and policy
learning, resulting in inferior performance despite accurate model predictions.
This paper first identifies the primary source of this mismatch comes from the
underlying confounders present in offline data for MBRL. Subsequently, we
introduce \textbf{B}ilin\textbf{E}ar \textbf{CAUS}al
r\textbf{E}presentation~(BECAUSE), an algorithm to capture causal
representation for both states and actions to reduce the influence of the
distribution shift, thus mitigating the objective mismatch problem.
Comprehensive evaluations on 18 tasks that vary in data quality and environment
context demonstrate the superior performance of BECAUSE over existing offline
RL algorithms. We show the generalizability and robustness of BECAUSE under
fewer samples or larger numbers of confounders. Additionally, we offer
theoretical analysis of BECAUSE to prove its error bound and sample efficiency
when integrating causal representation into offline MBRL.",2024-07-15,"Haohong Lin, Wenhao Ding, Jian Chen, Laixi Shi, Jiacheng Zhu, Bo Li, Ding Zhao",http://arxiv.org/pdf/2407.10967v2,cs.LG
"No Train, all Gain: Self-Supervised Gradients Improve Deep Frozen Representations","This paper introduces FUNGI, Features from UNsupervised GradIents, a method
to enhance the features of transformer encoders by leveraging self-supervised
gradients. Our method is simple: given any pretrained model, we first compute
gradients from various self-supervised objectives for each input. These
gradients are projected to a lower dimension and then concatenated with the
model's output embedding. The resulting features are evaluated on k-nearest
neighbor classification over 11 datasets from vision, 5 from natural language
processing, and 2 from audio. Across backbones spanning various sizes and
pretraining strategies, FUNGI features provide consistent performance
improvements over the embeddings. We also show that using FUNGI features can
benefit linear classification, clustering and image retrieval, and that they
significantly improve the retrieval-based in-context scene understanding
abilities of pretrained models, for example improving upon DINO by +17% for
semantic segmentation - without any training.",2024-07-15,"Walter Simoncini, Spyros Gidaris, Andrei Bursuc, Yuki M. Asano",http://arxiv.org/pdf/2407.10964v2,cs.LG
Fast Matrix Multiplications for Lookup Table-Quantized LLMs,"The deployment of large language models (LLMs) is often constrained by memory
bandwidth, where the primary bottleneck is the cost of transferring model
parameters from the GPU's global memory to its registers. When coupled with
custom kernels that fuse the dequantization and matmul operations, weight-only
quantization can thus enable faster inference by reducing the amount of memory
movement. However, developing high-performance kernels for weight-quantized
LLMs presents substantial challenges, especially when the weights are
compressed to non-evenly-divisible bit widths (e.g., 3 bits) with non-uniform,
lookup table (LUT) quantization. This paper describes FLUTE, a flexible lookup
table engine for LUT-quantized LLMs, which uses offline restructuring of the
quantized weight matrix to minimize bit manipulations associated with
unpacking, and vectorization and duplication of the lookup table to mitigate
shared memory bandwidth constraints. At batch sizes < 32 and quantization group
size of 128 (typical in LLM inference), the FLUTE kernel can be 2-4x faster
than existing GEMM kernels. As an application of FLUTE, we explore a simple
extension to lookup table-based NormalFloat quantization and apply it to
quantize LLaMA3 to various configurations, obtaining competitive quantization
performance against strong baselines while obtaining an end-to-end throughput
increase of 1.5 to 2 times.",2024-07-15,"Han Guo, William Brandon, Radostin Cholakov, Jonathan Ragan-Kelley, Eric P. Xing, Yoon Kim",http://arxiv.org/pdf/2407.10960v4,cs.LG
Enhancing Stochastic Optimization for Statistical Efficiency Using ROOT-SGD with Diminishing Stepsize,"In this paper, we revisit \textsf{ROOT-SGD}, an innovative method for
stochastic optimization to bridge the gap between stochastic optimization and
statistical efficiency. The proposed method enhances the performance and
reliability of \textsf{ROOT-SGD} by integrating a carefully designed
\emph{diminishing stepsize strategy}. This approach addresses key challenges in
optimization, providing robust theoretical guarantees and practical benefits.
Our analysis demonstrates that \textsf{ROOT-SGD} with diminishing achieves
optimal convergence rates while maintaining computational efficiency. By
dynamically adjusting the learning rate, \textsf{ROOT-SGD} ensures improved
stability and precision throughout the optimization process. The findings of
this study offer valuable insights for developing advanced optimization
algorithms that are both efficient and statistically robust.",2024-07-15,Chris Junchi Li,http://arxiv.org/pdf/2407.10955v2,cs.LG
A Unified Differentiable Boolean Operator with Fuzzy Logic,"This paper presents a unified differentiable boolean operator for implicit
solid shape modeling using Constructive Solid Geometry (CSG). Traditional CSG
relies on min, max operators to perform boolean operations on implicit shapes.
But because these boolean operators are discontinuous and discrete in the
choice of operations, this makes optimization over the CSG representation
challenging. Drawing inspiration from fuzzy logic, we present a unified boolean
operator that outputs a continuous function and is differentiable with respect
to operator types. This enables optimization of both the primitives and the
boolean operations employed in CSG with continuous optimization techniques,
such as gradient descent. We further demonstrate that such a continuous boolean
operator allows modeling of both sharp mechanical objects and smooth organic
shapes with the same framework. Our proposed boolean operator opens up new
possibilities for future research toward fully continuous CSG optimization.",2024-07-15,"Hsueh-Ti Derek Liu, Maneesh Agrawala, Cem Yuksel, Tim Omernick, Vinith Misra, Stefano Corazza, Morgan McGuire, Victor Zordan",http://arxiv.org/pdf/2407.10954v1,cs.LG
Representing Rule-based Chatbots with Transformers,"What kind of internal mechanisms might Transformers use to conduct fluid,
natural-sounding conversations? Prior work has illustrated by construction how
Transformers can solve various synthetic tasks, such as sorting a list or
recognizing formal languages, but it remains unclear how to extend this
approach to a conversational setting. In this work, we propose using ELIZA, a
classic rule-based chatbot, as a setting for formal, mechanistic analysis of
Transformer-based chatbots. ELIZA allows us to formally model key aspects of
conversation, including local pattern matching and long-term dialogue state
tracking. We first present a theoretical construction of a Transformer that
implements the ELIZA chatbot. Building on prior constructions, particularly
those for simulating finite-state automata, we show how simpler mechanisms can
be composed and extended to produce more sophisticated behavior. Next, we
conduct a set of empirical analyses of Transformers trained on synthetically
generated ELIZA conversations. Our analysis illustrates the kinds of mechanisms
these models tend to prefer--for example, models favor an induction head
mechanism over a more precise, position-based copying mechanism; and using
intermediate generations to simulate recurrent data structures, akin to an
implicit scratchpad or Chain-of-Thought. Overall, by drawing an explicit
connection between neural chatbots and interpretable, symbolic mechanisms, our
results provide a new framework for the mechanistic analysis of conversational
agents.",2024-07-15,"Dan Friedman, Abhishek Panigrahi, Danqi Chen",http://arxiv.org/pdf/2407.10949v2,cs.LG
Evaluation of RAG Metrics for Question Answering in the Telecom Domain,"Retrieval Augmented Generation (RAG) is widely used to enable Large Language
Models (LLMs) perform Question Answering (QA) tasks in various domains.
However, RAG based on open-source LLM for specialized domains has challenges of
evaluating generated responses. A popular framework in the literature is the
RAG Assessment (RAGAS), a publicly available library which uses LLMs for
evaluation. One disadvantage of RAGAS is the lack of details of derivation of
numerical value of the evaluation metrics. One of the outcomes of this work is
a modified version of this package for few metrics (faithfulness, context
relevance, answer relevance, answer correctness, answer similarity and factual
correctness) through which we provide the intermediate outputs of the prompts
by using any LLMs. Next, we analyse the expert evaluations of the output of the
modified RAGAS package and observe the challenges of using it in the telecom
domain. We also study the effect of the metrics under correct vs. wrong
retrieval and observe that few of the metrics have higher values for correct
retrieval. We also study for differences in metrics between base embeddings and
those domain adapted via pre-training and fine-tuning. Finally, we comment on
the suitability and challenges of using these metrics for in-the-wild telecom
QA task.",2024-07-15,"Sujoy Roychowdhury, Sumit Soman, H G Ranjani, Neeraj Gunda, Vansh Chhabra, Sai Krishna Bala",http://arxiv.org/pdf/2407.12873v1,cs.LG
Fine-Tuning and Prompt Optimization: Two Great Steps that Work Better Together,"Natural Language Processing (NLP) systems are increasingly taking the form of
sophisticated modular pipelines, e.g., Retrieval Augmented Generation (RAG),
where each module may involve a distinct Language Model (LM) and an associated
prompt template. These compound systems often lack intermediate labels or
gradient flow to optimize each module, making their end-to-end optimization
challenging. Here we seek strategies to optimize both the module-level LM
weights and the associated prompt templates of such systems to maximize a
downstream task metric. We propose for the first time combining the weight and
prompt optimization strategies to optimize a modular LM pipeline by alternating
between the two to get the same LM to teach itself. In experiments with
multi-hop QA, mathematical reasoning, and feature-based classification using
mistral-7b, llama-2-7b, and llama-3-8b, these BetterTogether strategies
optimizing the weights and prompts of a pipeline together outperform directly
optimizing weights alone and prompts alone by up to 60% and 6%, respectively,
on average across LMs and tasks. BetterTogether optimizer is released in DSPy
at http://dspy.ai",2024-07-15,"Dilara Soylu, Christopher Potts, Omar Khattab",http://arxiv.org/pdf/2407.10930v2,cs.LG
Leveraging Bi-Focal Perspectives and Granular Feature Integration for Accurate Reliable Early Alzheimer's Detection,"Being the most commonly known neurodegeneration, Alzheimer's Disease (AD) is
annually diagnosed in millions of patients. The present medical scenario still
finds the exact diagnosis and classification of AD through neuroimaging data as
a challenging task. Traditional CNNs can extract a good amount of low-level
information in an image while failing to extract high-level minuscule
particles, which is a significant challenge in detecting AD from MRI scans. To
overcome this, we propose a novel Granular Feature Integration method to
combine information extraction at different scales along with an efficient
information flow, enabling the model to capture both broad and fine-grained
features simultaneously. We also propose a Bi-Focal Perspective mechanism to
highlight the subtle neurofibrillary tangles and amyloid plaques in the MRI
scans, ensuring that critical pathological markers are accurately identified.
Our model achieved an F1-Score of 99.31%, precision of 99.24%, and recall of
99.51%. These scores prove that our model is significantly better than the
state-of-the-art (SOTA) CNNs in existence.",2024-07-15,"Shravan Venkatraman, Pandiyaraju V, Abeshek A, Pavan Kumar S, Aravintakshan S A",http://arxiv.org/pdf/2407.10921v7,cs.LG
When Heterophily Meets Heterogeneity: New Graph Benchmarks and Effective Methods,"Many real-world graphs frequently present challenges for graph learning due
to the presence of both heterophily and heterogeneity. However, existing
benchmarks for graph learning often focus on heterogeneous graphs with
homophily or homogeneous graphs with heterophily, leaving a gap in
understanding how methods perform on graphs that are both heterogeneous and
heterophilic. To bridge this gap, we introduce H2GB, a novel graph benchmark
that brings together the complexities of both the heterophily and heterogeneity
properties of graphs. Our benchmark encompasses 9 diverse real-world datasets
across 5 domains, 28 baseline model implementations, and 26 benchmark results.
In addition, we present a modular graph transformer framework UnifiedGT and a
new model variant, H2G-former, that excels at this challenging benchmark. By
integrating masked label embeddings, cross-type heterogeneous attention, and
type-specific FFNs, H2G-former effectively tackles graph heterophily and
heterogeneity. Extensive experiments across 26 baselines on H2GB reveal
inadequacies of current models on heterogeneous heterophilic graph learning,
and demonstrate the superiority of our H2G-former over existing solutions. Both
the benchmark and the framework are available on GitHub
(https://github.com/junhongmit/H2GB) and PyPI (https://pypi.org/project/H2GB),
and documentation can be found at https://junhongmit.github.io/H2GB/.",2024-07-15,"Junhong Lin, Xiaojie Guo, Shuaicheng Zhang, Dawei Zhou, Yada Zhu, Julian Shun",http://arxiv.org/pdf/2407.10916v1,cs.LG
DataDream: Few-shot Guided Dataset Generation,"While text-to-image diffusion models have been shown to achieve
state-of-the-art results in image synthesis, they have yet to prove their
effectiveness in downstream applications. Previous work has proposed to
generate data for image classifier training given limited real data access.
However, these methods struggle to generate in-distribution images or depict
fine-grained features, thereby hindering the generalization of classification
models trained on synthetic datasets. We propose DataDream, a framework for
synthesizing classification datasets that more faithfully represents the real
data distribution when guided by few-shot examples of the target classes.
DataDream fine-tunes LoRA weights for the image generation model on the few
real images before generating the training data using the adapted model. We
then fine-tune LoRA weights for CLIP using the synthetic data to improve
downstream image classification over previous approaches on a large variety of
datasets. We demonstrate the efficacy of DataDream through extensive
experiments, surpassing state-of-the-art classification accuracy with few-shot
data across 7 out of 10 datasets, while being competitive on the other 3.
Additionally, we provide insights into the impact of various factors, such as
the number of real-shot and generated images as well as the fine-tuning compute
on model performance. The code is available at
https://github.com/ExplainableML/DataDream.",2024-07-15,"Jae Myung Kim, Jessica Bader, Stephan Alaniz, Cordelia Schmid, Zeynep Akata",http://arxiv.org/pdf/2407.10910v2,cs.LG
Optical Diffusion Models for Image Generation,"Diffusion models generate new samples by progressively decreasing the noise
from the initially provided random distribution. This inference procedure
generally utilizes a trained neural network numerous times to obtain the final
output, creating significant latency and energy consumption on digital
electronic hardware such as GPUs. In this study, we demonstrate that the
propagation of a light beam through a semi-transparent medium can be programmed
to implement a denoising diffusion model on image samples. This framework
projects noisy image patterns through passive diffractive optical layers, which
collectively only transmit the predicted noise term in the image. The optical
transparent layers, which are trained with an online training approach,
backpropagating the error to the analytical model of the system, are passive
and kept the same across different steps of denoising. Hence this method
enables high-speed image generation with minimal power consumption, benefiting
from the bandwidth and energy efficiency of optical information processing.",2024-07-15,"Ilker Oguz, Niyazi Ulas Dinc, Mustafa Yildirim, Junjie Ke, Innfarn Yoo, Qifei Wang, Feng Yang, Christophe Moser, Demetri Psaltis",http://arxiv.org/pdf/2407.10897v2,cs.LG
SLIP: Securing LLMs IP Using Weights Decomposition,"Large language models (LLMs) have recently seen widespread adoption, in both
academia and industry. As these models grow, they become valuable intellectual
property (IP), reflecting enormous investments by their owners. Moreover, the
high cost of cloud-based deployment has driven interest towards deployment to
edge devices, yet this risks exposing valuable parameters to theft and
unauthorized use. Current methods to protect models' IP on the edge have
limitations in terms of practicality, loss in accuracy, or suitability to
requirements. In this paper, we introduce a novel hybrid inference algorithm,
named SLIP, designed to protect edge-deployed models from theft. SLIP is the
first hybrid protocol that is both practical for real-world applications and
provably secure, while having zero accuracy degradation and minimal impact on
latency. It involves partitioning the model between two computing resources,
one secure but expensive, and another cost-effective but vulnerable. This is
achieved through matrix decomposition, ensuring that the secure resource
retains a maximally sensitive portion of the model's IP while performing a
minimal amount of computations, and vice versa for the vulnerable resource.
Importantly, the protocol includes security guarantees that prevent attackers
from exploiting the partition to infer the secured information. Finally, we
present experimental results that show the robustness and effectiveness of our
method, positioning it as a compelling solution for protecting LLMs.",2024-07-15,"Yehonathan Refael, Adam Hakim, Lev Greenberg, Tal Aviv, Satya Lokam, Ben Fishman, Shachar Seidman",http://arxiv.org/pdf/2407.10886v2,cs.LG
SSSD-ECG-nle: New Label Embeddings with Structured State-Space Models for ECG generation,"An electrocardiogram (ECG) is vital for identifying cardiac diseases,
offering crucial insights for diagnosing heart conditions and informing
potentially life-saving treatments. However, like other types of medical data,
ECGs are subject to privacy concerns when distributed and analyzed. Diffusion
models have made significant progress in recent years, creating the possibility
for synthesizing data comparable to the real one and allowing their widespread
adoption without privacy concerns. In this paper, we use diffusion models with
structured state spaces for generating digital 10-second 12-lead ECG signals.
We propose the SSSD-ECG-nle architecture based on SSSD-ECG with a modified
conditioning mechanism and demonstrate its efficiency on downstream tasks. We
conduct quantitative and qualitative evaluations, including analyzing
convergence speed, the impact of adding positive samples, and assessment with
physicians' expert knowledge. Finally, we share the results of physician
evaluations and also make synthetic data available to ensure the
reproducibility of the experiments described.",2024-07-15,"Sergey Skorik, Aram Avetisyan",http://arxiv.org/pdf/2407.11108v1,cs.LG
Deep Causal Learning to Explain and Quantify The Geo-Tension's Impact on Natural Gas Market,"Natural gas demand is a crucial factor for predicting natural gas prices and
thus has a direct influence on the power system. However, existing methods face
challenges in assessing the impact of shocks, such as the outbreak of the
Russian-Ukrainian war. In this context, we apply deep neural network-based
Granger causality to identify important drivers of natural gas demand.
Furthermore, the resulting dependencies are used to construct a counterfactual
case without the outbreak of the war, providing a quantifiable estimate of the
overall effect of the shock on various German energy sectors. The code and
dataset are available at https://github.com/bonaldli/CausalEnergy.",2024-07-15,"Philipp Kai Peter, Yulin Li, Ziyue Li, Wolfgang Ketter",http://arxiv.org/pdf/2407.10878v1,cs.LG
Random Channel Ablation for Robust Hand Gesture Classification with Multimodal Biosignals,"Biosignal-based hand gesture classification is an important component of
effective human-machine interaction. For multimodal biosignal sensing, the
modalities often face data loss due to missing channels in the data which can
adversely affect the gesture classification performance. To make the
classifiers robust to missing channels in the data, this paper proposes using
Random Channel Ablation (RChA) during the training process. Ultrasound and
force myography (FMG) data were acquired from the forearm for 12 hand gestures
over 2 subjects. The resulting multimodal data had 16 total channels, 8 for
each modality. The proposed method was applied to convolutional neural network
architecture, and compared with baseline, imputation, and oracle methods. Using
5-fold cross-validation for the two subjects, on average, 12.2% and 24.5%
improvement was observed for gesture classification with up to 4 and 8 missing
channels respectively compared to the baseline. Notably, the proposed method is
also robust to an increase in the number of missing channels compared to other
methods. These results show the efficacy of using random channel ablation to
improve classifier robustness for multimodal and multi-channel biosignal-based
hand gesture classification.",2024-07-15,"Keshav Bimbraw, Jing Liu, Ye Wang, Toshiaki Koike-Akino",http://arxiv.org/pdf/2407.10874v1,cs.LG
GPT Sonograpy: Hand Gesture Decoding from Forearm Ultrasound Images via VLM,"Large vision-language models (LVLMs), such as the Generative Pre-trained
Transformer 4-omni (GPT-4o), are emerging multi-modal foundation models which
have great potential as powerful artificial-intelligence (AI) assistance tools
for a myriad of applications, including healthcare, industrial, and academic
sectors. Although such foundation models perform well in a wide range of
general tasks, their capability without fine-tuning is often limited in
specialized tasks. However, full fine-tuning of large foundation models is
challenging due to enormous computation/memory/dataset requirements. We show
that GPT-4o can decode hand gestures from forearm ultrasound data even with no
fine-tuning, and improves with few-shot, in-context learning.",2024-07-15,"Keshav Bimbraw, Ye Wang, Jing Liu, Toshiaki Koike-Akino",http://arxiv.org/pdf/2407.10870v1,cs.LG
Provable Robustness of (Graph) Neural Networks Against Data Poisoning and Backdoor Attacks,"Generalization of machine learning models can be severely compromised by data
poisoning, where adversarial changes are applied to the training data. This
vulnerability has led to interest in certifying (i.e., proving) that such
changes up to a certain magnitude do not affect test predictions. We, for the
first time, certify Graph Neural Networks (GNNs) against poisoning attacks,
including backdoors, targeting the node features of a given graph. Our
certificates are white-box and based upon $(i)$ the neural tangent kernel,
which characterizes the training dynamics of sufficiently wide networks; and
$(ii)$ a novel reformulation of the bilevel optimization problem describing
poisoning as a mixed-integer linear program. Consequently, we leverage our
framework to provide fundamental insights into the role of graph structure and
its connectivity on the worst-case robustness behavior of convolution-based and
PageRank-based GNNs. We note that our framework is more general and constitutes
the first approach to derive white-box poisoning certificates for NNs, which
can be of independent interest beyond graph-related tasks.",2024-07-15,"Lukas Gosch, Mahalakshmi Sabanayagam, Debarghya Ghoshdastidar, Stephan Günnemann",http://arxiv.org/pdf/2407.10867v2,cs.LG
"Principal Component Flow Map Learning of PDEs from Incomplete, Limited, and Noisy Data","We present a computational technique for modeling the evolution of dynamical
systems in a reduced basis, with a focus on the challenging problem of modeling
partially-observed partial differential equations (PDEs) on high-dimensional
non-uniform grids. We address limitations of previous work on data-driven flow
map learning in the sense that we focus on noisy and limited data to move
toward data collection scenarios in real-world applications. Leveraging recent
work on modeling PDEs in modal and nodal spaces, we present a neural network
structure that is suitable for PDE modeling with noisy and limited data
available only on a subset of the state variables or computational domain. In
particular, spatial grid-point measurements are reduced using a learned linear
transformation, after which the dynamics are learned in this reduced basis
before being transformed back out to the nodal space. This approach yields a
drastically reduced parameterization of the neural network compared with
previous flow map models for nodal space learning. This allows for rapid
high-resolution simulations, enabled by smaller training data sets and reduced
training times.",2024-07-15,Victor Churchill,http://arxiv.org/pdf/2407.10854v2,cs.LG
Improved Uncertainty Estimation of Graph Neural Network Potentials Using Engineered Latent Space Distances,"Graph neural networks (GNNs) have been shown to be astonishingly capable
models for molecular property prediction, particularly as surrogates for
expensive density functional theory calculations of relaxed energy for novel
material discovery. However, one limitation of GNNs in this context is the lack
of useful uncertainty prediction methods, as this is critical to the material
discovery pipeline. In this work, we show that uncertainty quantification for
relaxed energy calculations is more complex than uncertainty quantification for
other kinds of molecular property prediction, due to the effect that structure
optimizations have on the error distribution. We propose that distribution-free
techniques are more useful tools for assessing calibration, recalibrating, and
developing uncertainty prediction methods for GNNs performing relaxed energy
calculations. We also develop a relaxed energy task for evaluating uncertainty
methods for equivariant GNNs, based on distribution-free recalibration and
using the Open Catalyst Project dataset. We benchmark a set of popular
uncertainty prediction methods on this task, and show that latent distance
methods, with our novel improvements, are the most well-calibrated and
economical approach for relaxed energy calculations. Finally, we demonstrate
that our latent space distance method produces results which align with our
expectations on a clustering example, and on specific equation of state and
adsorbate coverage examples from outside the training dataset.",2024-07-15,"Joseph Musielewicz, Janice Lan, Matt Uyttendaele, John R. Kitchin",http://arxiv.org/pdf/2407.10844v2,cs.LG
Offline Reinforcement Learning with Imputed Rewards,"Offline Reinforcement Learning (ORL) offers a robust solution to training
agents in applications where interactions with the environment must be strictly
limited due to cost, safety, or lack of accurate simulation environments.
Despite its potential to facilitate deployment of artificial agents in the real
world, Offline Reinforcement Learning typically requires very many
demonstrations annotated with ground-truth rewards. Consequently,
state-of-the-art ORL algorithms can be difficult or impossible to apply in
data-scarce scenarios. In this paper we propose a simple but effective Reward
Model that can estimate the reward signal from a very limited sample of
environment transitions annotated with rewards. Once the reward signal is
modeled, we use the Reward Model to impute rewards for a large sample of
reward-free transitions, thus enabling the application of ORL techniques. We
demonstrate the potential of our approach on several D4RL continuous locomotion
tasks. Our results show that, using only 1\% of reward-labeled transitions from
the original datasets, our learned reward model is able to impute rewards for
the remaining 99\% of the transitions, from which performant agents can be
learned using Offline Reinforcement Learning.",2024-07-15,"Carlo Romeo, Andrew D. Bagdanov",http://arxiv.org/pdf/2407.10839v1,cs.LG
Data-Guided Physics-Informed Neural Networks for Solving Inverse Problems in Partial Differential Equations,"Physics-informed neural networks (PINNs) represent a significant advancement
in scientific machine learning by integrating fundamental physical laws into
their architecture through loss functions. PINNs have been successfully applied
to solve various forward and inverse problems in partial differential equations
(PDEs). However, a notable challenge can emerge during the early training
stages when solving inverse problems. Specifically, data losses remain high
while PDE residual losses are minimized rapidly, thereby exacerbating the
imbalance between loss terms and impeding the overall efficiency of PINNs. To
address this challenge, this study proposes a novel framework termed
data-guided physics-informed neural networks (DG-PINNs). The DG-PINNs framework
is structured into two distinct phases: a pre-training phase and a fine-tuning
phase. In the pre-training phase, a loss function with only the data loss is
minimized in a neural network. In the fine-tuning phase, a composite loss
function, which consists of the data loss, PDE residual loss, and, if
available, initial and boundary condition losses, is minimized in the same
neural network. Notably, the pre-training phase ensures that the data loss is
already at a low value before the fine-tuning phase commences. This approach
enables the fine-tuning phase to converge to a minimal composite loss function
with fewer iterations compared to existing PINNs. To validate the
effectiveness, noise-robustness, and efficiency of DG-PINNs, extensive
numerical investigations are conducted on inverse problems related to several
classical PDEs, including the heat equation, wave equation, Euler--Bernoulli
beam equation, and Navier--Stokes equation. The numerical results demonstrate
that DG-PINNs can accurately solve these inverse problems and exhibit
robustness against noise in training data.",2024-07-15,"Wei Zhou, Y. F. Xu",http://arxiv.org/pdf/2407.10836v1,cs.LG
Exploration in Knowledge Transfer Utilizing Reinforcement Learning,"The contribution focuses on the problem of exploration within the task of
knowledge transfer. Knowledge transfer refers to the useful application of the
knowledge gained while learning the source task in the target task. The
intended benefit of knowledge transfer is to speed up the learning process of
the target task. The article aims to compare several exploration methods used
within a deep transfer learning algorithm, particularly Deep Target Transfer
$Q$-learning. The methods used are $\epsilon$-greedy, Boltzmann, and upper
confidence bound exploration. The aforementioned transfer learning algorithms
and exploration methods were tested on the virtual drone problem. The results
have shown that the upper confidence bound algorithm performs the best out of
these options. Its sustainability to other applications is to be checked.",2024-07-15,"Adam Jedlička, Tatiana Valentine Guy",http://arxiv.org/pdf/2407.10835v1,cs.LG
MetaLLM: A High-performant and Cost-efficient Dynamic Framework for Wrapping LLMs,"The rapid progress in machine learning (ML) has brought forth many large
language models (LLMs) that excel in various tasks and areas. These LLMs come
with different abilities and costs in terms of computation or pricing. Since
the demand for each query can vary, e.g., because of the queried domain or its
complexity, defaulting to one LLM in an application is not usually the best
choice, whether it is the biggest, priciest, or even the one with the best
average test performance. Consequently, picking the right LLM that is both
accurate and cost-effective for an application is necessary yet remains a
challenge. In this paper, we introduce MetaLLM, a framework that dynamically
and intelligently routes each query to the optimal LLM (among several available
LLMs) for classification and multi-choice question-answering tasks, achieving
significantly improved accuracy and cost-effectiveness. By framing the
selection problem as a multi-armed bandit, MetaLLM balances prediction accuracy
and cost efficiency under uncertainty. Our experiments, conducted on popular
LLM platforms such as OpenAI and Together AI, as well as open-source LLM,
showcase MetaLLM's efficacy in real-world scenarios, laying the groundwork for
future extensions.",2024-07-15,"Quang H. Nguyen, Thinh Dao, Duy C. Hoang, Juliette Decugis, Saurav Manchanda, Nitesh V. Chawla, Khoa D. Doan",http://arxiv.org/pdf/2407.10834v3,cs.LG
LLM Circuit Analyses Are Consistent Across Training and Scale,"Most currently deployed large language models (LLMs) undergo continuous
training or additional finetuning. By contrast, most research into LLMs'
internal mechanisms focuses on models at one snapshot in time (the end of
pre-training), raising the question of whether their results generalize to
real-world settings. Existing studies of mechanisms over time focus on
encoder-only or toy models, which differ significantly from most deployed
models. In this study, we track how model mechanisms, operationalized as
circuits, emerge and evolve across 300 billion tokens of training in
decoder-only LLMs, in models ranging from 70 million to 2.8 billion parameters.
We find that task abilities and the functional components that support them
emerge consistently at similar token counts across scale. Moreover, although
such components may be implemented by different attention heads over time, the
overarching algorithm that they implement remains. Surprisingly, both these
algorithms and the types of components involved therein can replicate across
model scale. These results suggest that circuit analyses conducted on small
models at the end of pre-training can provide insights that still apply after
additional pre-training and over model scale.",2024-07-15,"Curt Tigges, Michael Hanna, Qinan Yu, Stella Biderman",http://arxiv.org/pdf/2407.10827v2,cs.LG
Wicked Oddities: Selectively Poisoning for Effective Clean-Label Backdoor Attacks,"Deep neural networks are vulnerable to backdoor attacks, a type of
adversarial attack that poisons the training data to manipulate the behavior of
models trained on such data. Clean-label attacks are a more stealthy form of
backdoor attacks that can perform the attack without changing the labels of
poisoned data. Early works on clean-label attacks added triggers to a random
subset of the training set, ignoring the fact that samples contribute unequally
to the attack's success. This results in high poisoning rates and low attack
success rates. To alleviate the problem, several supervised learning-based
sample selection strategies have been proposed. However, these methods assume
access to the entire labeled training set and require training, which is
expensive and may not always be practical. This work studies a new and more
practical (but also more challenging) threat model where the attacker only
provides data for the target class (e.g., in face recognition systems) and has
no knowledge of the victim model or any other classes in the training set. We
study different strategies for selectively poisoning a small set of training
samples in the target class to boost the attack success rate in this setting.
Our threat model poses a serious threat in training machine learning models
with third-party datasets, since the attack can be performed effectively with
limited information. Experiments on benchmark datasets illustrate the
effectiveness of our strategies in improving clean-label backdoor attacks.",2024-07-15,"Quang H. Nguyen, Nguyen Ngoc-Hieu, The-Anh Ta, Thanh Nguyen-Tang, Kok-Seng Wong, Hoang Thanh-Tung, Khoa D. Doan",http://arxiv.org/pdf/2407.10825v2,cs.LG
Foundational Autoraters: Taming Large Language Models for Better Automatic Evaluation,"As large language models (LLMs) advance, it becomes more challenging to
reliably evaluate their output due to the high costs of human evaluation. To
make progress towards better LLM autoraters, we introduce FLAMe, a family of
Foundational Large Autorater Models. FLAMe is trained on our large and diverse
collection of 100+ quality assessment tasks comprising 5M+ human judgments,
curated and standardized using publicly released human evaluations from
previous research. FLAMe significantly improves generalization to a wide
variety of held-out tasks, outperforming LLMs trained on proprietary data like
GPT-4 and Claude-3 on many tasks. We show that FLAMe can also serve as a
powerful starting point for further downstream fine-tuning, using reward
modeling evaluation as a case study (FLAMe-RM). Notably, on RewardBench, our
FLAMe-RM-24B model (with an accuracy of 87.8%) is the top-performing generative
model trained exclusively on permissively licensed data, outperforming both
GPT-4-0125 (85.9%) and GPT-4o (84.7%). Additionally, we explore a more
computationally efficient approach using a novel tail-patch fine-tuning
strategy to optimize our FLAMe multitask mixture for reward modeling evaluation
(FLAMe-Opt-RM), offering competitive RewardBench performance while requiring
approximately 25x less training datapoints. Overall, our FLAMe variants
outperform all popular proprietary LLM-as-a-Judge models we consider across 8
out of 12 autorater evaluation benchmarks, encompassing 53 quality assessment
tasks, including RewardBench and LLM-AggreFact. Finally, our analysis reveals
that FLAMe is significantly less biased than these LLM-as-a-Judge models on the
CoBBLEr autorater bias benchmark, while effectively identifying high-quality
responses for code generation.",2024-07-15,"Tu Vu, Kalpesh Krishna, Salaheddin Alzubi, Chris Tar, Manaal Faruqui, Yun-Hsuan Sung",http://arxiv.org/pdf/2407.10817v1,cs.LG
"GuideLight: ""Industrial Solution"" Guidance for More Practical Traffic Signal Control Agents","Currently, traffic signal control (TSC) methods based on reinforcement
learning (RL) have proven superior to traditional methods. However, most RL
methods face difficulties when applied in the real world due to three factors:
input, output, and the cycle-flow relation. The industry's observable input is
much more limited than simulation-based RL methods. For real-world solutions,
only flow can be reliably collected, whereas common RL methods need more. For
the output action, most RL methods focus on acyclic control, which real-world
signal controllers do not support. Most importantly, industry standards require
a consistent cycle-flow relationship: non-decreasing and different response
strategies for low, medium, and high-level flows, which is ignored by the RL
methods. To narrow the gap between RL methods and industry standards, we
innovatively propose to use industry solutions to guide the RL agent.
Specifically, we design behavior cloning and curriculum learning to guide the
agent to mimic and meet industry requirements and, at the same time, leverage
the power of exploration and exploitation in RL for better performance. We
theoretically prove that such guidance can largely decrease the sample
complexity to polynomials in the horizon when searching for an optimal policy.
Our rigid experiments show that our method has good cycle-flow relation and
superior performance.",2024-07-15,"Haoyuan Jiang, Xuantang Xiong, Ziyue Li, Hangyu Mao, Guanghu Sui, Jingqing Ruan, Yuheng Cheng, Hua Wei, Wolfgang Ketter, Rui Zhao",http://arxiv.org/pdf/2407.10811v1,cs.LG
FabGPT: An Efficient Large Multimodal Model for Complex Wafer Defect Knowledge Queries,"Intelligence is key to advancing integrated circuit (IC) fabrication. Recent
breakthroughs in Large Multimodal Models (LMMs) have unlocked extraditionary
abilities in understanding images and text, fostering intelligent fabrication.
Leveraging the power of LMMs, we introduce FabGPT, a customized IC fabrication
large multimodal model for wafer defect knowledge query. FabGPT manifests
expertise in conducting defect detection in Scanning Electron Microscope (SEM)
images, performing root cause analysis, and providing expert Q&A on fabrication
processes. FabGPT matches enhanced multimodal features to automatically detect
minute defects under complex wafer backgrounds and reduce the subjectivity of
manual threshold settings. Besides, the proposed modulation module and
interactive corpus training strategy embed wafer defect knowledge into the
pre-trained model, effectively balancing Q&A queries related to defect
knowledge and original knowledge and mitigating the modality bias issues.
Experiments on in-house fab data show that FabGPT achieves significant
performance improvement in wafer defect detection and knowledge querying.",2024-07-15,"Yuqi Jiang, Xudong Lu, Qian Jin, Qi Sun, Hanming Wu, Cheng Zhuo",http://arxiv.org/pdf/2407.10810v2,cs.LG
Employing Sentence Space Embedding for Classification of Data Stream from Fake News Domain,"Tabular data is considered the last unconquered castle of deep learning, yet
the task of data stream classification is stated to be an equally important and
demanding research area. Due to the temporal constraints, it is assumed that
deep learning methods are not the optimal solution for application in this
field. However, excluding the entire -- and prevalent -- group of methods seems
rather rash given the progress that has been made in recent years in its
development. For this reason, the following paper is the first to present an
approach to natural language data stream classification using the sentence
space method, which allows for encoding text into the form of a discrete
digital signal. This allows the use of convolutional deep networks dedicated to
image classification to solve the task of recognizing fake news based on text
data. Based on the real-life Fakeddit dataset, the proposed approach was
compared with state-of-the-art algorithms for data stream classification based
on generalization ability and time complexity.",2024-07-15,"Paweł Zyblewski, Jakub Klikowski, Weronika Borek-Marciniec, Paweł Ksieniewicz",http://arxiv.org/pdf/2407.10807v1,cs.LG
Latent Linear Quadratic Regulator for Robotic Control Tasks,"Model predictive control (MPC) has played a more crucial role in various
robotic control tasks, but its high computational requirements are concerning,
especially for nonlinear dynamical models. This paper presents a
$\textbf{la}$tent $\textbf{l}$inear $\textbf{q}$uadratic $\textbf{r}$egulator
(LaLQR) that maps the state space into a latent space, on which the dynamical
model is linear and the cost function is quadratic, allowing the efficient
application of LQR. We jointly learn this alternative system by imitating the
original MPC. Experiments show LaLQR's superior efficiency and generalization
compared to other baselines.",2024-07-15,"Yuan Zhang, Shaohui Yang, Toshiyuki Ohtsuka, Colin Jones, Joschka Boedecker",http://arxiv.org/pdf/2407.11107v2,cs.LG
DINO Pre-training for Vision-based End-to-end Autonomous Driving,"In this article, we focus on the pre-training of visual autonomous driving
agents in the context of imitation learning. Current methods often rely on a
classification-based pre-training, which we hypothesise to be holding back from
extending capabilities of implicit image understanding. We propose pre-training
the visual encoder of a driving agent using the self-distillation with no
labels (DINO) method, which relies on a self-supervised learning paradigm.% and
is trained on an unrelated task. Our experiments in CARLA environment in
accordance with the Leaderboard benchmark reveal that the proposed pre-training
is more efficient than classification-based pre-training, and is on par with
the recently proposed pre-training based on visual place recognition (VPRPre).",2024-07-15,"Shubham Juneja, Povilas Daniušis, Virginijus Marcinkevičius",http://arxiv.org/pdf/2407.10803v1,cs.LG
Motion-prior Contrast Maximization for Dense Continuous-Time Motion Estimation,"Current optical flow and point-tracking methods rely heavily on synthetic
datasets. Event cameras are novel vision sensors with advantages in challenging
visual conditions, but state-of-the-art frame-based methods cannot be easily
adapted to event data due to the limitations of current event simulators. We
introduce a novel self-supervised loss combining the Contrast Maximization
framework with a non-linear motion prior in the form of pixel-level
trajectories and propose an efficient solution to solve the high-dimensional
assignment problem between non-linear trajectories and events. Their
effectiveness is demonstrated in two scenarios: In dense continuous-time motion
estimation, our method improves the zero-shot performance of a synthetically
trained model on the real-world dataset EVIMO2 by 29%. In optical flow
estimation, our method elevates a simple UNet to achieve state-of-the-art
performance among self-supervised methods on the DSEC optical flow benchmark.
Our code is available at https://github.com/tub-rip/MotionPriorCMax.",2024-07-15,"Friedhelm Hamann, Ziyun Wang, Ioannis Asmanis, Kenneth Chaney, Guillermo Gallego, Kostas Daniilidis",http://arxiv.org/pdf/2407.10802v1,cs.LG
GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework,"Methods to evaluate Large Language Model (LLM) responses and detect
inconsistencies, also known as hallucinations, with respect to the provided
knowledge, are becoming increasingly important for LLM applications. Current
metrics fall short in their ability to provide explainable decisions,
systematically check all pieces of information in the response, and are often
too computationally expensive to be used in practice. We present GraphEval: a
hallucination evaluation framework based on representing information in
Knowledge Graph (KG) structures. Our method identifies the specific triples in
the KG that are prone to hallucinations and hence provides more insight into
where in the response a hallucination has occurred, if at all, than previous
methods. Furthermore, using our approach in conjunction with state-of-the-art
natural language inference (NLI) models leads to an improvement in balanced
accuracy on various hallucination benchmarks, compared to using the raw NLI
models. Lastly, we explore the use of GraphEval for hallucination correction by
leveraging the structure of the KG, a method we name GraphCorrect, and
demonstrate that the majority of hallucinations can indeed be rectified.",2024-07-15,"Hannah Sansford, Nicholas Richardson, Hermina Petric Maretic, Juba Nait Saada",http://arxiv.org/pdf/2407.10793v1,cs.LG
AdapTable: Test-Time Adaptation for Tabular Data via Shift-Aware Uncertainty Calibrator and Label Distribution Handler,"In real-world scenarios, tabular data often suffer from distribution shifts
that threaten the performance of machine learning models. Despite its
prevalence and importance, handling distribution shifts in the tabular domain
remains underexplored due to the inherent challenges within the tabular data
itself. In this sense, test-time adaptation (TTA) offers a promising solution
by adapting models to target data without accessing source data, crucial for
privacy-sensitive tabular domains. However, existing TTA methods either 1)
overlook the nature of tabular distribution shifts, often involving label
distribution shifts, or 2) impose architectural constraints on the model,
leading to a lack of applicability. To this end, we propose AdapTable, a novel
TTA framework for tabular data. AdapTable operates in two stages: 1)
calibrating model predictions using a shift-aware uncertainty calibrator, and
2) adjusting these predictions to match the target label distribution with a
label distribution handler. We validate the effectiveness of AdapTable through
theoretical analysis and extensive experiments on various distribution shift
scenarios. Our results demonstrate AdapTable's ability to handle various
real-world distribution shifts, achieving up to a 16% improvement on the HELOC
dataset.",2024-07-15,"Changhun Kim, Taewon Kim, Seungyeon Woo, June Yong Yang, Eunho Yang",http://arxiv.org/pdf/2407.10784v4,cs.LG
Correlations Are Ruining Your Gradient Descent,"Herein the topics of (natural) gradient descent, data decorrelation, and
approximate methods for backpropagation are brought into a common discussion.
Natural gradient descent illuminates how gradient vectors, pointing at
directions of steepest descent, can be improved by considering the local
curvature of loss landscapes. We extend this perspective and show that to fully
solve the problem illuminated by natural gradients in neural networks, one must
recognise that correlations in the data at any linear transformation, including
node responses at every layer of a neural network, cause a non-orthonormal
relationship between the model's parameters. To solve this requires a method
for decorrelating inputs at each individual layer of a neural network. We
describe a range of methods which have been proposed for decorrelation and
whitening of node output, and expand on these to provide a novel method
specifically useful for distributed computing and computational neuroscience.
Implementing decorrelation within multi-layer neural networks, we can show that
not only is training via backpropagation sped up significantly but also
existing approximations of backpropagation, which have failed catastrophically
in the past, benefit significantly in their accuracy and convergence speed.
This has the potential to provide a route forward for approximate gradient
descent methods which have previously been discarded, training approaches for
analogue and neuromorphic hardware, and potentially insights as to the efficacy
and utility of decorrelation processes in the brain.",2024-07-15,Nasir Ahmad,http://arxiv.org/pdf/2407.10780v2,cs.LG
Deep Learning Evidence for Global Optimality of Gerver's Sofa,"The Moving Sofa Problem, formally proposed by Leo Moser in 1966, seeks to
determine the largest area of a two-dimensional shape that can navigate through
an $L$-shaped corridor with unit width. The current best lower bound is about
2.2195, achieved by Joseph Gerver in 1992, though its global optimality remains
unproven. In this paper, we investigate this problem by leveraging the
universal approximation strength and computational efficiency of neural
networks. We report two approaches, both supporting Gerver's conjecture that
his shape is the unique global maximum. Our first approach is continuous
function learning. We drop Gerver's assumptions that i) the rotation of the
corridor is monotonic and symmetric and, ii) the trajectory of its corner as a
function of rotation is continuously differentiable. We parameterize rotation
and trajectory by independent piecewise linear neural networks (with input
being some pseudo time), allowing for rich movements such as backward rotation
and pure translation. We then compute the sofa area as a differentiable
function of rotation and trajectory using our ""waterfall"" algorithm. Our final
loss function includes differential terms and initial conditions, leveraging
the principles of physics-informed machine learning. Under such settings,
extensive training starting from diverse function initialization and
hyperparameters is conducted, unexceptionally showing rapid convergence to
Gerver's solution. Our second approach is via discrete optimization of the
Kallus-Romik upper bound, which converges to the maximum sofa area from above
as the number of rotation angles increases. We uplift this number to 10000 to
reveal its asymptotic behavior. It turns out that the upper bound yielded by
our models does converge to Gerver's area (within an error of 0.01% when the
number of angles reaches 2100). We also improve their five-angle upper bound
from 2.37 to 2.3337.",2024-07-15,"Kuangdai Leng, Jia Bi, Jaehoon Cha, Samuel Pinilla, Jeyan Thiyagalingam",http://arxiv.org/pdf/2407.11106v1,cs.LG
The Missing Link: Allocation Performance in Causal Machine Learning,"Automated decision-making (ADM) systems are being deployed across a diverse
range of critical problem areas such as social welfare and healthcare. Recent
work highlights the importance of causal ML models in ADM systems, but
implementing them in complex social environments poses significant challenges.
Research on how these challenges impact the performance in specific downstream
decision-making tasks is limited. Addressing this gap, we make use of a
comprehensive real-world dataset of jobseekers to illustrate how the
performance of a single CATE model can vary significantly across different
decision-making scenarios and highlight the differential influence of
challenges such as distribution shifts on predictions and allocations.",2024-07-15,"Unai Fischer-Abaigar, Christoph Kern, Frauke Kreuter",http://arxiv.org/pdf/2407.10779v1,cs.LG
Last-Iterate Global Convergence of Policy Gradients for Constrained Reinforcement Learning,"Constrained Reinforcement Learning (CRL) tackles sequential decision-making
problems where agents are required to achieve goals by maximizing the expected
return while meeting domain-specific constraints, which are often formulated as
expected costs. In this setting, policy-based methods are widely used since
they come with several advantages when dealing with continuous-control
problems. These methods search in the policy space with an action-based or
parameter-based exploration strategy, depending on whether they learn directly
the parameters of a stochastic policy or those of a stochastic hyperpolicy. In
this paper, we propose a general framework for addressing CRL problems via
gradient-based primal-dual algorithms, relying on an alternate ascent/descent
scheme with dual-variable regularization. We introduce an exploration-agnostic
algorithm, called C-PG, which exhibits global last-iterate convergence
guarantees under (weak) gradient domination assumptions, improving and
generalizing existing results. Then, we design C-PGAE and C-PGPE, the
action-based and the parameter-based versions of C-PG, respectively, and we
illustrate how they naturally extend to constraints defined in terms of risk
measures over the costs, as it is often requested in safety-critical scenarios.
Finally, we numerically validate our algorithms on constrained control
problems, and compare them with state-of-the-art baselines, demonstrating their
effectiveness.",2024-07-15,"Alessandro Montenegro, Marco Mussi, Matteo Papini, Alberto Maria Metelli",http://arxiv.org/pdf/2407.10775v2,cs.LG
ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time Series Forecasting,"Long time series forecasting aims to utilize historical information to
forecast future states over extended horizons. Traditional RNN-based series
forecasting methods struggle to effectively address long-term dependencies and
gradient issues in long time series problems. Recently, SegRNN has emerged as a
leading RNN-based model tailored for long-term series forecasting,
demonstrating state-of-the-art performance while maintaining a streamlined
architecture through innovative segmentation and parallel decoding techniques.
Nevertheless, SegRNN has several limitations: its fixed segmentation disrupts
data continuity and fails to effectively leverage information across different
segments, the segmentation strategy employed by SegRNN does not fundamentally
address the issue of information loss within the recurrent structure. To
address these issues, we propose the ISMRNN method with three key enhancements:
we introduce an implicit segmentation structure to decompose the time series
and map it to segmented hidden states, resulting in denser information exchange
during the segmentation phase. Additionally, we incorporate residual structures
in the encoding layer to mitigate information loss within the recurrent
structure. To extract information more effectively, we further integrate the
Mamba architecture to enhance time series information extraction. Experiments
on several real-world long time series forecasting datasets demonstrate that
our model surpasses the performance of current state-of-the-art models.",2024-07-15,"GaoXiang Zhao, Li Zhou, XiaoQiang Wang",http://arxiv.org/pdf/2407.10768v5,cs.LG
Physics-Informed Machine Learning for Smart Additive Manufacturing,"Compared to physics-based computational manufacturing, data-driven models
such as machine learning (ML) are alternative approaches to achieve smart
manufacturing. However, the data-driven ML's ""black box"" nature has presented a
challenge to interpreting its outcomes. On the other hand, governing physical
laws are not effectively utilized to develop data-efficient ML algorithms. To
leverage the advantages of ML and physical laws of advanced manufacturing, this
paper focuses on the development of a physics-informed machine learning (PIML)
model by integrating neural networks and physical laws to improve model
accuracy, transparency, and generalization with case studies in laser metal
deposition (LMD).",2024-07-15,"Rahul Sharma, Maziar Raissi, Y. B. Guo",http://arxiv.org/pdf/2407.10761v1,cs.LG
Qwen2-Audio Technical Report,"We introduce the latest progress of Qwen-Audio, a large-scale audio-language
model called Qwen2-Audio, which is capable of accepting various audio signal
inputs and performing audio analysis or direct textual responses with regard to
speech instructions. In contrast to complex hierarchical tags, we have
simplified the pre-training process by utilizing natural language prompts for
different data and tasks, and have further expanded the data volume. We have
boosted the instruction-following capability of Qwen2-Audio and implemented two
distinct audio interaction modes for voice chat and audio analysis. In the
voice chat mode, users can freely engage in voice interactions with Qwen2-Audio
without text input. In the audio analysis mode, users could provide audio and
text instructions for analysis during the interaction. Note that we do not use
any system prompts to switch between voice chat and audio analysis modes.
Qwen2-Audio is capable of intelligently comprehending the content within audio
and following voice commands to respond appropriately. For instance, in an
audio segment that simultaneously contains sounds, multi-speaker conversations,
and a voice command, Qwen2-Audio can directly understand the command and
provide an interpretation and response to the audio. Additionally, DPO has
optimized the model's performance in terms of factuality and adherence to
desired behavior. According to the evaluation results from AIR-Bench,
Qwen2-Audio outperformed previous SOTAs, such as Gemini-1.5-pro, in tests
focused on audio-centric instruction-following capabilities. Qwen2-Audio is
open-sourced with the aim of fostering the advancement of the multi-modal
language community.",2024-07-15,"Yunfei Chu, Jin Xu, Qian Yang, Haojie Wei, Xipin Wei, Zhifang Guo, Yichong Leng, Yuanjun Lv, Jinzheng He, Junyang Lin, Chang Zhou, Jingren Zhou",http://arxiv.org/pdf/2407.10759v1,cs.LG
Cluster and Separate: a GNN Approach to Voice and Staff Prediction for Score Engraving,"This paper approaches the problem of separating the notes from a quantized
symbolic music piece (e.g., a MIDI file) into multiple voices and staves. This
is a fundamental part of the larger task of music score engraving (or score
typesetting), which aims to produce readable musical scores for human
performers. We focus on piano music and support homophonic voices, i.e., voices
that can contain chords, and cross-staff voices, which are notably difficult
tasks that have often been overlooked in previous research. We propose an
end-to-end system based on graph neural networks that clusters notes that
belong to the same chord and connects them with edges if they are part of a
voice. Our results show clear and consistent improvements over a previous
approach on two datasets of different styles. To aid the qualitative analysis
of our results, we support the export in symbolic music formats and provide a
direct visualization of our outputs graph over the musical score. All code and
pre-trained models are available at https://github.com/CPJKU/piano_svsep",2024-07-15,"Francesco Foscarin, Emmanouil Karystinaios, Eita Nakamura, Gerhard Widmer",http://arxiv.org/pdf/2407.21030v1,cs.LG
Continual Deep Learning on the Edge via Stochastic Local Competition among Subnetworks,"Continual learning on edge devices poses unique challenges due to stringent
resource constraints. This paper introduces a novel method that leverages
stochastic competition principles to promote sparsity, significantly reducing
deep network memory footprint and computational demand. Specifically, we
propose deep networks that comprise blocks of units that compete locally to win
the representation of each arising new task; competition takes place in a
stochastic manner. This type of network organization results in sparse
task-specific representations from each network layer; the sparsity pattern is
obtained during training and is different among tasks. Crucially, our method
sparsifies both the weights and the weight gradients, thus facilitating
training on edge devices. This is performed on the grounds of winning
probability for each unit in a block. During inference, the network retains
only the winning unit and zeroes-out all weights pertaining to non-winning
units for the task at hand. Thus, our approach is specifically tailored for
deployment on edge devices, providing an efficient and scalable solution for
continual learning in resource-limited environments.",2024-07-15,"Theodoros Christophides, Kyriakos Tolias, Sotirios Chatzis",http://arxiv.org/pdf/2407.10758v1,cs.LG
Impacts of Data Preprocessing and Hyperparameter Optimization on the Performance of Machine Learning Models Applied to Intrusion Detection Systems,"In the context of cybersecurity of modern communications networks, Intrusion
Detection Systems (IDS) have been continuously improved, many of them
incorporating machine learning (ML) techniques to identify threats. Although
there are researches focused on the study of these techniques applied to IDS,
the state-of-the-art lacks works concentrated exclusively on the evaluation of
the impacts of data pre-processing actions and the optimization of the values
of the hyperparameters of the ML algorithms in the construction of the models
of threat identification. This article aims to present a study that fills this
research gap. For that, experiments were carried out with two data sets,
comparing attack scenarios with variations of pre-processing techniques and
optimization of hyperparameters. The results confirm that the proper
application of these techniques, in general, makes the generated classification
models more robust and greatly reduces the execution times of these models'
training and testing processes.",2024-07-15,"Mateus Guimarães Lima, Antony Carvalho, João Gabriel Álvares, Clayton Escouper das Chagas, Ronaldo Ribeiro Goldschmidt",http://arxiv.org/pdf/2407.11105v1,cs.LG
Exploring the Potentials and Challenges of Deep Generative Models in Product Design Conception,"The synthesis of product design concepts stands at the crux of early-phase
development processes for technical products, traditionally posing an intricate
interdisciplinary challenge. The application of deep learning methods,
particularly Deep Generative Models (DGMs), holds the promise of automating and
streamlining manual iterations and therefore introducing heightened levels of
innovation and efficiency. However, DGMs have yet to be widely adopted into the
synthesis of product design concepts. This paper aims to explore the reasons
behind this limited application and derive the requirements for successful
integration of these technologies. We systematically analyze DGM-families (VAE,
GAN, Diffusion, Transformer, Radiance Field), assessing their strengths,
weaknesses, and general applicability for product design conception. Our
objective is to provide insights that simplify the decision-making process for
engineers, helping them determine which method might be most effective for
their specific challenges. Recognizing the rapid evolution of this field, we
hope that our analysis contributes to a fundamental understanding and guides
practitioners towards the most promising approaches. This work seeks not only
to illuminate current challenges but also to propose potential solutions,
thereby offering a clear roadmap for leveraging DGMs in the realm of product
design conception.",2024-07-15,"Phillip Mueller, Lars Mikelsons",http://arxiv.org/pdf/2407.11104v2,cs.LG
Transforming Agency. On the mode of existence of Large Language Models,"This paper investigates the ontological characterization of Large Language
Models (LLMs) like ChatGPT. Between inflationary and deflationary accounts, we
pay special attention to their status as agents. This requires explaining in
detail the architecture, processing, and training procedures that enable LLMs
to display their capacities, and the extensions used to turn LLMs into
agent-like systems. After a systematic analysis we conclude that a LLM fails to
meet necessary and sufficient conditions for autonomous agency in the light of
embodied theories of mind: the individuality condition (it is not the product
of its own activity, it is not even directly affected by it), the normativity
condition (it does not generate its own norms or goals), and, partially the
interactional asymmetry condition (it is not the origin and sustained source of
its interaction with the environment). If not agents, then ... what are LLMs?
We argue that ChatGPT should be characterized as an interlocutor or linguistic
automaton, a library-that-talks, devoid of (autonomous) agency, but capable to
engage performatively on non-purposeful yet purpose-structured and
purpose-bounded tasks. When interacting with humans, a ""ghostly"" component of
the human-machine interaction makes it possible to enact genuine conversational
experiences with LLMs. Despite their lack of sensorimotor and biological
embodiment, LLMs textual embodiment (the training corpus) and resource-hungry
computational embodiment, significantly transform existing forms of human
agency. Beyond assisted and extended agency, the LLM-human coupling can produce
midtended forms of agency, closer to the production of intentional agency than
to the extended instrumentality of any previous technologies.",2024-07-15,"Xabier E. Barandiaran, Lola S. Almendros",http://arxiv.org/pdf/2407.10735v2,cs.LG
On-Device Training of Fully Quantized Deep Neural Networks on Cortex-M Microcontrollers,"On-device training of DNNs allows models to adapt and fine-tune to newly
collected data or changing domains while deployed on microcontroller units
(MCUs). However, DNN training is a resource-intensive task, making the
implementation and execution of DNN training algorithms on MCUs challenging due
to low processor speeds, constrained throughput, limited floating-point
support, and memory constraints. In this work, we explore on-device training of
DNNs for Cortex-M MCUs. We present a method that enables efficient training of
DNNs completely in place on the MCU using fully quantized training (FQT) and
dynamic partial gradient updates. We demonstrate the feasibility of our
approach on multiple vision and time-series datasets and provide insights into
the tradeoff between training accuracy, memory overhead, energy, and latency on
real hardware.",2024-07-15,"Mark Deutel, Frank Hannig, Christopher Mutschler, Jürgen Teich",http://arxiv.org/pdf/2407.10734v2,cs.LG
Mitigating Data Imbalance for Software Vulnerability Assessment: Does Data Augmentation Help?,"Background: Software Vulnerability (SV) assessment is increasingly adopted to
address the ever-increasing volume and complexity of SVs. Data-driven
approaches have been widely used to automate SV assessment tasks, particularly
the prediction of the Common Vulnerability Scoring System (CVSS) metrics such
as exploitability, impact, and severity. SV assessment suffers from the
imbalanced distributions of the CVSS classes, but such data imbalance has been
hardly understood and addressed in the literature. Aims: We conduct a
large-scale study to quantify the impacts of data imbalance and mitigate the
issue for SV assessment through the use of data augmentation. Method: We
leverage nine data augmentation techniques to balance the class distributions
of the CVSS metrics. We then compare the performance of SV assessment models
with and without leveraging the augmented data. Results: Through extensive
experiments on 180k+ real-world SVs, we show that mitigating data imbalance can
significantly improve the predictive performance of models for all the CVSS
tasks, by up to 31.8% in Matthews Correlation Coefficient. We also discover
that simple text augmentation like combining random text insertion, deletion,
and replacement can outperform the baseline across the board. Conclusions: Our
study provides the motivation and the first promising step toward tackling data
imbalance for effective SV assessment.",2024-07-15,"Triet H. M. Le, M. Ali Babar",http://arxiv.org/pdf/2407.10722v1,cs.LG
PlayMolecule pKAce: Small Molecule Protonation through Equivariant Neural Networks,"Small molecule protonation is an important part of the preparation of small
molecules for many types of computational chemistry protocols. For this, a
correct estimation of the pKa values of the protonation sites of molecules is
required. In this work, we present pKAce, a new web application for the
prediction of micro-pKa values of the molecules' protonation sites. We adapt
the state-of-the-art, equivariant, TensorNet model originally developed for
quantum mechanics energy and force predictions to the prediction of micro-pKa
values. We show that an adapted version of this model can achieve
state-of-the-art performance comparable with established models while trained
on just a fraction of their training data.",2024-07-15,"Nikolai Schapin, Maciej Majewski, Mariona Torrens-Fontanals, Gianni De Fabritiis",http://arxiv.org/pdf/2407.11103v1,cs.LG
Geometric Analysis of Unconstrained Feature Models with $d=K$,"Recently, interesting empirical phenomena known as Neural Collapse have been
observed during the final phase of training deep neural networks for
classification tasks. We examine this issue when the feature dimension d is
equal to the number of classes K. We demonstrate that two popular unconstrained
feature models are strict saddle functions, with every critical point being
either a global minimum or a strict saddle point that can be exited using
negative curvatures. The primary findings conclusively confirm the conjecture
on the unconstrained feature models in previous articles.",2024-07-15,"Yi Shen, Shao Gu",http://arxiv.org/pdf/2407.10702v2,cs.LG
On Machine Learning Approaches for Protein-Ligand Binding Affinity Prediction,"Binding affinity optimization is crucial in early-stage drug discovery. While
numerous machine learning methods exist for predicting ligand potency, their
comparative efficacy remains unclear. This study evaluates the performance of
classical tree-based models and advanced neural networks in protein-ligand
binding affinity prediction. Our comprehensive benchmarking encompasses 2D
models utilizing ligand-only RDKit embeddings and Large Language Model (LLM)
ligand representations, as well as 3D neural networks incorporating bound
protein-ligand conformations. We assess these models across multiple standard
datasets, examining various predictive scenarios including classification,
ranking, regression, and active learning. Results indicate that simpler models
can surpass more complex ones in specific tasks, while 3D models leveraging
structural information become increasingly competitive with larger training
datasets containing compounds with labelled affinity data against multiple
targets. Pre-trained 3D models, by incorporating protein pocket environments,
demonstrate significant advantages in data-scarce scenarios for specific
binding pockets. Additionally, LLM pretraining on 2D ligand data enhances
complex model performance, providing versatile embeddings that outperform
traditional RDKit features in computational efficiency. Finally, we show that
combining 2D and 3D model strengths improves active learning outcomes beyond
current state-of-the-art approaches. These findings offer valuable insights for
optimizing machine learning strategies in drug discovery pipelines.",2024-07-15,"Nikolai Schapin, Carles Navarro, Albert Bou, Gianni De Fabritiis",http://arxiv.org/pdf/2407.19073v1,cs.LG
Probability Passing for Graph Neural Networks: Graph Structure and Representations Joint Learning,"Graph Neural Networks (GNNs) have achieved notable success in the analysis of
non-Euclidean data across a wide range of domains. However, their applicability
is constrained by the dependence on the observed graph structure. To solve this
problem, Latent Graph Inference (LGI) is proposed to infer a task-specific
latent structure by computing similarity or edge probability of node features
and then apply a GNN to produce predictions. Even so, existing approaches
neglect the noise from node features, which affects generated graph structure
and performance. In this work, we introduce a novel method called Probability
Passing to refine the generated graph structure by aggregating edge
probabilities of neighboring nodes based on observed graph. Furthermore, we
continue to utilize the LGI framework, inputting the refined graph structure
and node features into GNNs to obtain predictions. We name the proposed scheme
as Probability Passing-based Graph Neural Network (PPGNN). Moreover, the
anchor-based technique is employed to reduce complexity and improve efficiency.
Experimental results demonstrate the effectiveness of the proposed method.",2024-07-15,"Ziyan Wang, Yaxuan He, Bin Liu",http://arxiv.org/pdf/2407.10688v2,cs.LG
GeoMix: Towards Geometry-Aware Data Augmentation,"Mixup has shown considerable success in mitigating the challenges posed by
limited labeled data in image classification. By synthesizing samples through
the interpolation of features and labels, Mixup effectively addresses the issue
of data scarcity. However, it has rarely been explored in graph learning tasks
due to the irregularity and connectivity of graph data. Specifically, in node
classification tasks, Mixup presents a challenge in creating connections for
synthetic data. In this paper, we propose Geometric Mixup (GeoMix), a simple
and interpretable Mixup approach leveraging in-place graph editing. It
effectively utilizes geometry information to interpolate features and labels
with those from the nearby neighborhood, generating synthetic nodes and
establishing connections for them. We conduct theoretical analysis to elucidate
the rationale behind employing geometry information for node Mixup, emphasizing
the significance of locality enhancement-a critical aspect of our method's
design. Extensive experiments demonstrate that our lightweight Geometric Mixup
achieves state-of-the-art results on a wide variety of standard datasets with
limited labeled data. Furthermore, it significantly improves the generalization
capability of underlying GNNs across various challenging out-of-distribution
generalization tasks. Our code is available at
https://github.com/WtaoZhao/geomix.",2024-07-15,"Wentao Zhao, Qitian Wu, Chenxiao Yang, Junchi Yan",http://arxiv.org/pdf/2407.10681v1,cs.LG
Flow Perturbation to Accelerate Unbiased Sampling of Boltzmann distribution,"Flow-based generative models have been employed for sampling the Boltzmann
distribution, but their application to high-dimensional systems is hindered by
the significant computational cost of obtaining the Jacobian of the flow. To
overcome this challenge, we introduce the flow perturbation method, which
incorporates optimized stochastic perturbations into the flow. By reweighting
trajectories generated by the perturbed flow, our method achieves unbiased
sampling of the Boltzmann distribution with orders of magnitude speedup
compared to both brute force Jacobian calculations and the Hutchinson
estimator. Notably, it accurately sampled the Chignolin protein with all atomic
Cartesian coordinates explicitly represented, which, to our best knowledge, is
the largest molecule ever Boltzmann sampled in such detail using generative
models.",2024-07-15,"Xin Peng, Ang Gao",http://arxiv.org/pdf/2407.10666v2,cs.LG
Enhancing Electrocardiogram Signal Analysis Using NLP-Inspired Techniques: A Novel Approach with Embedding and Self-Attention,"A language is made up of an infinite/finite number of sentences, which in
turn is composed of a number of words. The Electrocardiogram (ECG) is the most
popular noninvasive medical tool for studying heart function and diagnosing
various irregular cardiac rhythms. Intuitive inspection of the ECG reveals a
marked similarity between ECG signals and the spoken language. As a result, the
ECG signal may be thought of as a series of heartbeats (similar to sentences in
a spoken language), with each heartbeat consisting of a collection of waves
(similar to words in a sentence) with varying morphologies. Just as natural
language processing (NLP) is used to help computers comprehend and interpret
human natural language, it is conceivable to create NLP-inspired algorithms to
help computers comprehend the electrocardiogram data more efficiently. In this
study, we propose a novel ECG analysis technique, based on embedding and self
attention, to capture the spatial as well as the temporal dependencies of the
ECG data. To generate the embedding, an encoder-decoder network was proposed to
capture the temporal dependencies of the ECG signal and perform data
compression. The compressed and encoded data was fed to the embedding layer as
its weights. Finally, the proposed CNN-LSTM-Self Attention classifier works on
the embedding layer and classifies the signal as normal or anomalous. The
approach was tested using the PTB-xl dataset, which is severely imbalanced. Our
emphasis was to appropriately recognise the disease classes present in minority
numbers, in order to limit the detection of False Negative cases. An accuracy
of 91% was achieved with a good F1-score for all the disease classes.
Additionally, the the size of the model was reduced by 34% due to compression,
making it suitable for deployment in real time applications",2024-07-15,"Prapti Ganguly, Wazib Ansar, Amlan Chakrabarti",http://arxiv.org/pdf/2407.11102v1,cs.LG
Evaluating Large Language Models with fmeval,"fmeval is an open source library to evaluate large language models (LLMs) in
a range of tasks. It helps practitioners evaluate their model for task
performance and along multiple responsible AI dimensions. This paper presents
the library and exposes its underlying design principles: simplicity, coverage,
extensibility and performance. We then present how these were implemented in
the scientific and engineering choices taken when developing fmeval. A case
study demonstrates a typical use case for the library: picking a suitable model
for a question answering task. We close by discussing limitations and further
work in the development of the library. fmeval can be found at
https://github.com/aws/fmeval.",2024-07-15,"Pola Schwöbel, Luca Franceschi, Muhammad Bilal Zafar, Keerthan Vasist, Aman Malhotra, Tomer Shenhar, Pinal Tailor, Pinar Yilmaz, Michael Diamond, Michele Donini",http://arxiv.org/pdf/2407.12872v1,cs.LG
Cutting Through the Clutter: The Potential of LLMs for Efficient Filtration in Systematic Literature Reviews,"Systematic literature reviews (SLRs) are essential but labor-intensive due to
high publication volumes and inefficient keyword-based filtering. To streamline
this process, we evaluate Large Language Models (LLMs) for enhancing efficiency
and accuracy in corpus filtration while minimizing manual effort. Our
open-source tool LLMSurver presents a visual interface to utilize LLMs for
literature filtration, evaluate the results, and refine queries in an
interactive way. We assess the real-world performance of our approach in
filtering over 8.3k articles during a recent survey construction, comparing
results with human efforts. The findings show that recent LLM models can reduce
filtering time from weeks to minutes. A consensus scheme ensures recall rates
>98.8%, surpassing typical human error thresholds and improving selection
accuracy. This work advances literature review methodologies and highlights the
potential of responsible human-AI collaboration in academic research.",2024-07-15,"Lucas Joos, Daniel A. Keim, Maximilian T. Fischer",http://arxiv.org/pdf/2407.10652v2,cs.LG
Deep Diffusion Image Prior for Efficient OOD Adaptation in 3D Inverse Problems,"Recent inverse problem solvers that leverage generative diffusion priors have
garnered significant attention due to their exceptional quality. However,
adaptation of the prior is necessary when there exists a discrepancy between
the training and testing distributions. In this work, we propose deep diffusion
image prior (DDIP), which generalizes the recent adaptation method of SCD by
introducing a formal connection to the deep image prior. Under this framework,
we propose an efficient adaptation method dubbed D3IP, specified for 3D
measurements, which accelerates DDIP by orders of magnitude while achieving
superior performance. D3IP enables seamless integration of 3D inverse solvers
and thus leads to coherent 3D reconstruction. Moreover, we show that
meta-learning techniques can also be applied to yield even better performance.
We show that our method is capable of solving diverse 3D reconstructive tasks
from the generative prior trained only with phantom images that are vastly
different from the training set, opening up new opportunities of applying
diffusion inverse solvers even when training with gold standard data is
impossible. Code: https://github.com/HJ-harry/DDIP3D",2024-07-15,"Hyungjin Chung, Jong Chul Ye",http://arxiv.org/pdf/2407.10641v1,cs.LG
Data-Driven Abstractions via Binary-Tree Gaussian Processes for Formal Verification,"To advance formal verification of stochastic systems against temporal logic
requirements for handling unknown dynamics, researchers have been designing
data-driven approaches inspired by breakthroughs in the underlying machine
learning techniques. As one promising research direction, abstraction-based
solutions based on Gaussian process (GP) regression have become popular for
their ability to learn a representation of the latent system from data with a
quantified error. Results obtained based on this model are then translated to
the true system via various methods. In a recent publication, GPs using a
so-called binary-tree kernel have demonstrated a polynomial speedup w.r.t. the
size of the data compared to their vanilla version, outcompeting all existing
sparse GP approximations. Incidentally, the resulting binary-tree Gaussian
process (BTGP) is characteristic for its piecewise-constant posterior mean and
covariance functions, naturally abstracting the input space into discrete
partitions. In this paper, we leverage this natural abstraction of the BTGP for
formal verification, eliminating the need for cumbersome abstraction and error
quantification procedures. We show that the BTGP allows us to construct an
interval Markov chain model of the unknown system with a speedup that is
polynomial w.r.t. the size of the abstraction compared to alternative
approaches. We provide a delocalized error quantification via a unified formula
even when the true dynamics do not live in the function space of the BTGP. This
allows us to compute upper and lower bounds on the probability of satisfying
reachability specifications that are robust to both aleatoric and epistemic
uncertainties.",2024-07-15,"Oliver Schön, Shammakh Naseer, Ben Wooding, Sadegh Soudjani",http://arxiv.org/pdf/2407.21029v1,cs.LG
Evaluating Model Bias Requires Characterizing its Mistakes,"The ability to properly benchmark model performance in the face of spurious
correlations is important to both build better predictors and increase
confidence that models are operating as intended. We demonstrate that
characterizing (as opposed to simply quantifying) model mistakes across
subgroups is pivotal to properly reflect model biases, which are ignored by
standard metrics such as worst-group accuracy or accuracy gap. Inspired by the
hypothesis testing framework, we introduce SkewSize, a principled and flexible
metric that captures bias from mistakes in a model's predictions. It can be
used in multi-class settings or generalised to the open vocabulary setting of
generative models. SkewSize is an aggregation of the effect size of the
interaction between two categorical variables: the spurious variable
representing the bias attribute and the model's prediction. We demonstrate the
utility of SkewSize in multiple settings including: standard vision models
trained on synthetic data, vision models trained on ImageNet, and large scale
vision-and-language models from the BLIP-2 family. In each case, the proposed
SkewSize is able to highlight biases not captured by other metrics, while also
providing insights on the impact of recently proposed techniques, such as
instruction tuning.",2024-07-15,"Isabela Albuquerque, Jessica Schrouff, David Warde-Farley, Taylan Cemgil, Sven Gowal, Olivia Wiles",http://arxiv.org/pdf/2407.10633v1,cs.LG
Brain Tumor Classification From MRI Images Using Machine Learning,"Brain tumor is a life-threatening problem and hampers the normal functioning
of the human body. The average five-year relative survival rate for malignant
brain tumors is 35.6 percent. For proper diagnosis and efficient treatment
planning, it is necessary to detect the brain tumor in early stages. Due to
advancement in medical imaging technology, the brain images are taken in
different modalities. The ability to extract relevant characteristics from
magnetic resonance imaging (MRI) scans is a crucial step for brain tumor
classifiers. Several studies have proposed various strategies to extract
relevant features from different modalities of MRI to predict the growth of
abnormal tumors. Most techniques used conventional methods of image processing
for feature extraction and machine learning for classification. More recently,
the use of deep learning algorithms in medical imaging has resulted in
significant improvements in the classification and diagnosis of brain tumors.
Since tumors are located at different regions of the brain, localizing the
tumor and classifying it to a particular category is a challenging task. The
objective of this project is to develop a predictive system for brain tumor
detection using machine learning(ensembling).",2024-07-15,"Vidhyapriya Ranganathan, Celshiya Udaiyar, Jaisree Jayanth, Meghaa P V, Srija B, Uthra S",http://arxiv.org/pdf/2407.10630v1,cs.LG
Balancing the Scales: Reinforcement Learning for Fair Classification,"Fairness in classification tasks has traditionally focused on bias removal
from neural representations, but recent trends favor algorithmic methods that
embed fairness into the training process. These methods steer models towards
fair performance, preventing potential elimination of valuable information that
arises from representation manipulation. Reinforcement Learning (RL), with its
capacity for learning through interaction and adjusting reward functions to
encourage desired behaviors, emerges as a promising tool in this domain. In
this paper, we explore the usage of RL to address bias in imbalanced
classification by scaling the reward function to mitigate bias. We employ the
contextual multi-armed bandit framework and adapt three popular RL algorithms
to suit our objectives, demonstrating a novel approach to mitigating bias.",2024-07-15,"Leon Eshuijs, Shihan Wang, Antske Fokkens",http://arxiv.org/pdf/2407.10629v1,cs.LG
Arena Learning: Build Data Flywheel for LLMs Post-training via Simulated Chatbot Arena,"Assessing the effectiveness of large language models (LLMs) presents
substantial challenges. The method of conducting human-annotated battles in an
online Chatbot Arena is a highly effective evaluative technique. However, this
approach is limited by the costs and time required for human annotation. In
this paper, we introduce Arena Learning, an innovative offline strategy
designed to simulate these arena battles using AI-driven annotations to
evaluate battle outcomes, thus facilitating the continuous improvement of the
target model through both supervised fine-tuning and reinforcement learning.
Arena Learning comprises two key elements. First, it ensures precise
evaluations and maintains consistency between offline simulations and online
competitions via WizardArena, a pipeline developed to accurately predict the
Elo rankings of various models using a meticulously designed offline test set.
Our results demonstrate that WizardArena's predictions closely align with those
from the online Arena. Second, it involves the continuous improvement of
training data based on the battle results and the refined model. We establish a
data flywheel to iteratively update the training data by highlighting the
weaknesses of the target model based on its battle results, enabling it to
learn from the strengths of multiple different models. We apply Arena Learning
to train our target model, WizardLM-$\beta$, and demonstrate significant
performance enhancements across various metrics. This fully automated training
and evaluation pipeline sets the stage for continuous advancements in various
LLMs via post-training. Notably, Arena Learning plays a pivotal role in the
success of WizardLM-2, and this paper serves both as an exploration of its
efficacy and a foundational study for future discussions related to WizardLM-2
and its derivatives.",2024-07-15,"Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Qingwei Lin, Jianguang Lou, Shifeng Chen, Yansong Tang, Weizhu Chen",http://arxiv.org/pdf/2407.10627v1,cs.LG
MetaTool: Facilitating Large Language Models to Master Tools with Meta-task Augmentation,"Utilizing tools with Large Language Models (LLMs) is essential for grounding
AI agents in real-world applications. The prevailing approach involves few-shot
prompting with demonstrations or fine-tuning with expert annotations. However,
mere in-context demonstrations may fail to cover sufficient knowledge for
complex tools and tasks. Training on solution paths is also hindered by the
high cost of expert annotations and generalizing to new tools. A core challenge
of generalizable tool use lies in understanding the ""meta"", or fundamental
natures of tools that are transferable across tasks, such as causality and
constraints. In this paper, we present MetaTool, a novel tool learning
methodology designed to generalize across any reusable toolset. Our approach
incorporates a self-supervised augmentation technique derived from a series of
meta-tasks. This involves predicting masked elements in the tool execution
process. The self-supervised procedure enables scalable generation of
high-quality QA data, which is handy for supervising tool understanding. By
incorporating meta-task data into task-oriented training, our method
significantly enhances the performance of open-source LLMs, achieving results
comparable to ChatGPT in both tool-based planning and chatting scenarios.
Through large-scale instruction tuning, the MetaTool model demonstrates
impressive zero-shot generalizability on new tasks.",2024-07-15,"Xiaohan Wang, Dian Li, Yilin Zhao, Sinbadliu, Hui Wang",http://arxiv.org/pdf/2407.12871v2,cs.LG
Three Dogmas of Reinforcement Learning,"Modern reinforcement learning has been conditioned by at least three dogmas.
The first is the environment spotlight, which refers to our tendency to focus
on modeling environments rather than agents. The second is our treatment of
learning as finding the solution to a task, rather than adaptation. The third
is the reward hypothesis, which states that all goals and purposes can be well
thought of as maximization of a reward signal. These three dogmas shape much of
what we think of as the science of reinforcement learning. While each of the
dogmas have played an important role in developing the field, it is time we
bring them to the surface and reflect on whether they belong as basic
ingredients of our scientific paradigm. In order to realize the potential of
reinforcement learning as a canonical frame for researching intelligent agents,
we suggest that it is time we shed dogmas one and two entirely, and embrace a
nuanced approach to the third.",2024-07-15,"David Abel, Mark K. Ho, Anna Harutyunyan",http://arxiv.org/pdf/2407.10583v1,cs.LG
Antibody DomainBed: Out-of-Distribution Generalization in Therapeutic Protein Design,"Machine learning (ML) has demonstrated significant promise in accelerating
drug design. Active ML-guided optimization of therapeutic molecules typically
relies on a surrogate model predicting the target property of interest. The
model predictions are used to determine which designs to evaluate in the lab,
and the model is updated on the new measurements to inform the next cycle of
decisions. A key challenge is that the experimental feedback from each cycle
inspires changes in the candidate proposal or experimental protocol for the
next cycle, which lead to distribution shifts. To promote robustness to these
shifts, we must account for them explicitly in the model training. We apply
domain generalization (DG) methods to classify the stability of interactions
between an antibody and antigen across five domains defined by design cycles.
Our results suggest that foundational models and ensembling improve predictive
performance on out-of-distribution domains. We publicly release our codebase
extending the DG benchmark ``DomainBed,'' and the associated dataset of
antibody sequences and structures emulating distribution shifts across design
cycles.",2024-07-15,"Nataša Tagasovska, Ji Won Park, Matthieu Kirchmeyer, Nathan C. Frey, Andrew Martin Watkins, Aya Abdelsalam Ismail, Arian Rokkum Jamasb, Edith Lee, Tyler Bryson, Stephen Ra, Kyunghyun Cho",http://arxiv.org/pdf/2407.21028v1,cs.LG
ConTEXTure: Consistent Multiview Images to Texture,"We introduce ConTEXTure, a generative network designed to create a texture
map/atlas for a given 3D mesh using images from multiple viewpoints. The
process begins with generating a front-view image from a text prompt, such as
'Napoleon, front view', describing the 3D mesh. Additional images from
different viewpoints are derived from this front-view image and camera poses
relative to it. ConTEXTure builds upon the TEXTure network, which uses text
prompts for six viewpoints (e.g., 'Napoleon, front view', 'Napoleon, left
view', etc.). However, TEXTure often generates images for non-front viewpoints
that do not accurately represent those viewpoints.To address this issue, we
employ Zero123++, which generates multiple view-consistent images for the six
specified viewpoints simultaneously, conditioned on the initial front-view
image and the depth maps of the mesh for the six viewpoints. By utilizing these
view-consistent images, ConTEXTure learns the texture atlas from all viewpoint
images concurrently, unlike previous methods that do so sequentially. This
approach ensures that the rendered images from various viewpoints, including
back, side, bottom, and top, are free from viewpoint irregularities.",2024-07-15,"Jaehoon Ahn, Sumin Cho, Harim Jung, Kibeom Hong, Seonghoon Ban, Moon-Ryul Jung",http://arxiv.org/pdf/2407.10558v1,cs.LG
Learning Social Cost Functions for Human-Aware Path Planning,"Achieving social acceptance is one of the main goals of Social Robotic
Navigation. Despite this topic has received increasing interest in recent
years, most of the research has focused on driving the robotic agent along
obstacle-free trajectories, planning around estimates of future human motion to
respect personal distances and optimize navigation. However, social
interactions in everyday life are also dictated by norms that do not strictly
depend on movement, such as when standing at the end of a queue rather than
cutting it. In this paper, we propose a novel method to recognize common social
scenarios and modify a traditional planner's cost function to adapt to them.
This solution enables the robot to carry out different social navigation
behaviors that would not arise otherwise, maintaining the robustness of
traditional navigation. Our approach allows the robot to learn different social
norms with a single learned model, rather than having different modules for
each task. As a proof of concept, we consider the tasks of queuing and respect
interaction spaces of groups of people talking to one another, but the method
can be extended to other human activities that do not involve motion.",2024-07-15,"Andrea Eirale, Matteo Leonetti, Marcello Chiaberge",http://arxiv.org/pdf/2407.10547v2,cs.LG
LightCL: Compact Continual Learning with Low Memory Footprint For Edge Device,"Continual learning (CL) is a technique that enables neural networks to
constantly adapt to their dynamic surroundings. Despite being overlooked for a
long time, this technology can considerably address the customized needs of
users in edge devices. Actually, most CL methods require huge resource
consumption by the training behavior to acquire generalizability among all
tasks for delaying forgetting regardless of edge scenarios. Therefore, this
paper proposes a compact algorithm called LightCL, which evaluates and
compresses the redundancy of already generalized components in structures of
the neural network. Specifically, we consider two factors of generalizability,
learning plasticity and memory stability, and design metrics of both to
quantitatively assess generalizability of neural networks during CL. This
evaluation shows that generalizability of different layers in a neural network
exhibits a significant variation. Thus, we $\textit{Maintain Generalizability}$
by freezing generalized parts without the resource-intensive training process
and $\textit{Memorize Feature Patterns}$ by stabilizing feature extracting of
previous tasks to enhance generalizability for less-generalized parts with a
little extra memory, which is far less than the reduction by freezing.
Experiments illustrate that LightCL outperforms other state-of-the-art methods
and reduces at most $\textbf{6.16$\times$}$ memory footprint. We also verify
the effectiveness of LightCL on the edge device.",2024-07-15,"Zeqing Wang, Fei Cheng, Kangye Ji, Bohu Huang",http://arxiv.org/pdf/2407.10545v3,cs.LG
MARVEL: MR Fingerprinting with Additional micRoVascular Estimates using bidirectional LSTMs,"The Magnetic Resonance Fingerprinting (MRF) approach aims to estimate
multiple MR or physiological parameters simultaneously with a single fast
acquisition sequence. Most of the MRF studies proposed so far have used simple
MR sequence types to measure relaxation times (T1, T2). In that case, deep
learning algorithms have been successfully used to speed up the reconstruction
process. In theory, the MRF concept could be used with a variety of other MR
sequence types and should be able to provide more information about the tissue
microstructures. Yet, increasing the complexity of the numerical models often
leads to prohibited simulation times, and estimating multiple parameters from
one sequence implies new dictionary dimensions whose sizes become too large for
standard computers and DL architectures.In this paper, we propose to analyze
the MRF signal coming from a complex balance Steady-state free precession
(bSSFP) type sequence to simultaneously estimate relaxometry maps (T1, T2),
Field maps (B1, B0) as well as microvascular properties such as the local
Cerebral Blood Volume (CBV) or the averaged vessel Radius (R).To bypass the
curse of dimensionality, we propose an efficient way to simulate the MR signal
coming from numerical voxels containing realistic microvascular networks as
well as a Bidirectional Long Short-Term Memory network used for the matching
process.On top of standard MRF maps, our results on 3 human volunteers suggest
that our approach can quickly produce high-quality quantitative maps of
microvascular parameters that are otherwise obtained using longer dedicated
sequences and intravenous injection of a contrast agent. This approach could be
used for the management of multiple pathologies and could be tuned to provide
other types of microstructural information.",2024-07-15,"Antoine Barrier, Thomas Coudert, Aurélien Delphin, Benjamin Lemasson, Thomas Christen",http://arxiv.org/pdf/2407.10512v1,cs.LG
A pragmatic policy learning approach to account for users' fatigue in repeated auctions,"Online advertising banners are sold in real-time through auctions.Typically,
the more banners a user is shown, the smaller the marginalvalue of the next
banner for this user is. This fact can be detected bybasic ML models, that can
be used to predict how previously won auctionsdecrease the current opportunity
value. However, learning is not enough toproduce a bid that correctly accounts
for how winning the current auctionimpacts the future values. Indeed, a policy
that uses this prediction tomaximize the expected payoff of the current auction
could be dubbedimpatient because such policy does not fully account for the
repeatednature of the auctions. Under this perspective, it seems that most
biddersin the literature are impatient. Unsurprisingly, impatience induces a
cost.We provide two empirical arguments for the importance of this cost
ofimpatience. First, an offline counterfactual analysis and, second, a
notablebusiness metrics improvement by mitigating the cost of impatience
withpolicy learning",2024-07-15,"Benjamin Heymann, Rémi Chan--Renous-Legoubin, Alexandre Gilotte",http://arxiv.org/pdf/2407.10504v1,cs.LG
Guitar Chord Diagram Suggestion for Western Popular Music,"Chord diagrams are used by guitar players to show where and how to play a
chord on the fretboard. They are useful to beginners learning chords or for
sharing the hand positions required to play a song.However, the diagrams
presented on guitar learning toolsare usually selected from an existing
databaseand rarely represent the actual positions used by performers.In this
paper, we propose a tool which suggests a chord diagram for achord label,taking
into account the diagram of the previous chord.Based on statistical analysis of
the DadaGP and mySongBook datasets, we show that some chord diagrams are
over-represented in western popular musicand that some chords can be played in
more than 20 different ways.We argue that taking context into account can
improve the variety and the quality of chord diagram suggestion, and compare
this approach with a model taking only the current chord label into account.We
show that adding previous context improves the F1-score on this task by up to
27% and reduces the propensity of the model to suggest standard open chords.We
also define the notion of texture in the context of chord diagrams andshow
through a variety of metrics that our model improves textureconsistencywith the
previous diagram.",2024-07-15,"Alexandre d'Hooge, Louis Bigo, Ken Déguernel, Nicolas Martin",http://arxiv.org/pdf/2407.14260v1,cs.LG
Improving Hyperbolic Representations via Gromov-Wasserstein Regularization,"Hyperbolic representations have shown remarkable efficacy in modeling
inherent hierarchies and complexities within data structures. Hyperbolic neural
networks have been commonly applied for learning such representations from
data, but they often fall short in preserving the geometric structures of the
original feature spaces. In response to this challenge, our work applies the
Gromov-Wasserstein (GW) distance as a novel regularization mechanism within
hyperbolic neural networks. The GW distance quantifies how well the original
data structure is maintained after embedding the data in a hyperbolic space.
Specifically, we explicitly treat the layers of the hyperbolic neural networks
as a transport map and calculate the GW distance accordingly. We validate that
the GW distance computed based on a training set well approximates the GW
distance of the underlying data distribution. Our approach demonstrates
consistent enhancements over current state-of-the-art methods across various
tasks, including few-shot image classification, as well as semi-supervised
graph link prediction and node classification.",2024-07-15,"Yifei Yang, Wonjun Lee, Dongmian Zou, Gilad Lerman",http://arxiv.org/pdf/2407.10495v1,cs.LG
Learning to Unlearn for Robust Machine Unlearning,"Machine unlearning (MU) seeks to remove knowledge of specific data samples
from trained models without the necessity for complete retraining, a task made
challenging by the dual objectives of effective erasure of data and maintaining
the overall performance of the model. Despite recent advances in this field,
balancing between the dual objectives of unlearning remains challenging. From a
fresh perspective of generalization, we introduce a novel Learning-to-Unlearn
(LTU) framework, which adopts a meta-learning approach to optimize the
unlearning process to improve forgetting and remembering in a unified manner.
LTU includes a meta-optimization scheme that facilitates models to effectively
preserve generalizable knowledge with only a small subset of the remaining set,
while thoroughly forgetting the specific data samples. We also introduce a
Gradient Harmonization strategy to align the optimization trajectories for
remembering and forgetting via mitigating gradient conflicts, thus ensuring
efficient and effective model updates. Our approach demonstrates improved
efficiency and efficacy for MU, offering a promising solution to the challenges
of data rights and model reusability.",2024-07-15,"Mark He Huang, Lin Geng Foo, Jun Liu",http://arxiv.org/pdf/2407.10494v1,cs.LG
Learning Dynamics of LLM Finetuning,"Learning dynamics, which describes how the learning of specific training
examples influences the model's predictions on other examples, gives us a
powerful tool for understanding the behavior of deep learning systems. We study
the learning dynamics of large language models during different types of
finetuning, by analyzing the step-wise decomposition of how influence
accumulates among different potential responses. Our framework allows a uniform
interpretation of many interesting observations about the training of popular
algorithms for both instruction tuning and preference tuning. In particular, we
propose a hypothetical explanation of why specific types of hallucination are
strengthened after finetuning, e.g., the model might use phrases or facts in
the response for question B to answer question A, or the model might keep
repeating similar simple phrases when generating responses. We also extend our
framework and highlight a unique ""squeezing effect"" to explain a previously
observed phenomenon in off-policy direct preference optimization (DPO), where
running DPO for too long makes even the desired outputs less likely. This
framework also provides insights into where the benefits of on-policy DPO and
other variants come from. The analysis not only provides a novel perspective of
understanding LLM's finetuning but also inspires a simple, effective method to
improve alignment performance.",2024-07-15,"Yi Ren, Danica J. Sutherland",http://arxiv.org/pdf/2407.10490v3,cs.LG
Understanding Matrix Function Normalizations in Covariance Pooling through the Lens of Riemannian Geometry,"Global Covariance Pooling (GCP) has been demonstrated to improve the
performance of Deep Neural Networks (DNNs) by exploiting second-order
statistics of high-level representations. GCP typically performs classification
of the covariance matrices by applying matrix function normalization, such as
matrix logarithm or power, followed by a Euclidean classifier. However,
covariance matrices inherently lie in a Riemannian manifold, known as the
Symmetric Positive Definite (SPD) manifold. The current literature does not
provide a satisfactory explanation of why Euclidean classifiers can be applied
directly to Riemannian features after the normalization of the matrix power. To
mitigate this gap, this paper provides a comprehensive and unified
understanding of the matrix logarithm and power from a Riemannian geometry
perspective. The underlying mechanism of matrix functions in GCP is interpreted
from two perspectives: one based on tangent classifiers (Euclidean classifiers
on the tangent space) and the other based on Riemannian classifiers. Via
theoretical analysis and empirical validation through extensive experiments on
fine-grained and large-scale visual classification datasets, we conclude that
the working mechanism of the matrix functions should be attributed to the
Riemannian classifiers they implicitly respect. The code is available at
https://github.com/GitZH-Chen/RiemGCP.git.",2024-07-15,"Ziheng Chen, Yue Song, Xiao-Jun Wu, Gaowen Liu, Nicu Sebe",http://arxiv.org/pdf/2407.10484v3,cs.LG
G-PCGRL: Procedural Graph Data Generation via Reinforcement Learning,"Graph data structures offer a versatile and powerful means to model
relationships and interconnections in various domains, promising substantial
advantages in data representation, analysis, and visualization. In games,
graph-based data structures are omnipresent and represent, for example, game
economies, skill trees or complex, branching quest lines. With this paper, we
propose G-PCGRL, a novel and controllable method for the procedural generation
of graph data using reinforcement learning. Therefore, we frame this problem as
manipulating a graph's adjacency matrix to fulfill a given set of constraints.
Our method adapts and extends the Procedural Content Generation via
Reinforcement Learning (PCGRL) framework and introduces new representations to
frame the problem of graph data generation as a Markov decision process. We
compare the performance of our method with the original PCGRL, the run time
with a random search and evolutionary algorithm, and evaluate G-PCGRL on two
graph data domains in games: game economies and skill trees. The results show
that our method is capable of generating graph-based content quickly and
reliably to support and inspire designers in the game creation process. In
addition, trained models are controllable in terms of the type and number of
nodes to be generated.",2024-07-15,"Florian Rupp, Kai Eckert",http://arxiv.org/pdf/2407.10483v1,cs.LG
SuperPADL: Scaling Language-Directed Physics-Based Control with Progressive Supervised Distillation,"Physically-simulated models for human motion can generate high-quality
responsive character animations, often in real-time. Natural language serves as
a flexible interface for controlling these models, allowing expert and
non-expert users to quickly create and edit their animations. Many recent
physics-based animation methods, including those that use text interfaces,
train control policies using reinforcement learning (RL). However, scaling
these methods beyond several hundred motions has remained challenging.
Meanwhile, kinematic animation models are able to successfully learn from
thousands of diverse motions by leveraging supervised learning methods.
Inspired by these successes, in this work we introduce SuperPADL, a scalable
framework for physics-based text-to-motion that leverages both RL and
supervised learning to train controllers on thousands of diverse motion clips.
SuperPADL is trained in stages using progressive distillation, starting with a
large number of specialized experts using RL. These experts are then
iteratively distilled into larger, more robust policies using a combination of
reinforcement learning and supervised learning. Our final SuperPADL controller
is trained on a dataset containing over 5000 skills and runs in real time on a
consumer GPU. Moreover, our policy can naturally transition between skills,
allowing for users to interactively craft multi-stage animations. We
experimentally demonstrate that SuperPADL significantly outperforms RL-based
baselines at this large data scale.",2024-07-15,"Jordan Juravsky, Yunrong Guo, Sanja Fidler, Xue Bin Peng",http://arxiv.org/pdf/2407.10481v1,cs.LG
Deep Learning-Based Operators for Evolutionary Algorithms,"We present two novel domain-independent genetic operators that harness the
capabilities of deep learning: a crossover operator for genetic algorithms and
a mutation operator for genetic programming. Deep Neural Crossover leverages
the capabilities of deep reinforcement learning and an encoder-decoder
architecture to select offspring genes. BERT mutation masks multiple gp-tree
nodes and then tries to replace these masks with nodes that will most likely
improve the individual's fitness. We show the efficacy of both operators
through experimentation.",2024-07-15,"Eliad Shem-Tov, Moshe Sipper, Achiya Elyasaf",http://arxiv.org/pdf/2407.10477v1,cs.LG
Deflated Dynamics Value Iteration,"The Value Iteration (VI) algorithm is an iterative procedure to compute the
value function of a Markov decision process, and is the basis of many
reinforcement learning (RL) algorithms as well. As the error convergence rate
of VI as a function of iteration $k$ is $O(\gamma^k)$, it is slow when the
discount factor $\gamma$ is close to $1$. To accelerate the computation of the
value function, we propose Deflated Dynamics Value Iteration (DDVI). DDVI uses
matrix splitting and matrix deflation techniques to effectively remove
(deflate) the top $s$ dominant eigen-structure of the transition matrix
$\mathcal{P}^{\pi}$. We prove that this leads to a $\tilde{O}(\gamma^k
|\lambda_{s+1}|^k)$ convergence rate, where $\lambda_{s+1}$is $(s+1)$-th
largest eigenvalue of the dynamics matrix. We then extend DDVI to the RL
setting and present Deflated Dynamics Temporal Difference (DDTD) algorithm. We
empirically show the effectiveness of the proposed algorithms.",2024-07-15,"Jongmin Lee, Amin Rakhsha, Ernest K. Ryu, Amir-massoud Farahmand",http://arxiv.org/pdf/2407.10454v1,cs.LG
Inertial Confinement Fusion Forecasting via Large Language Models,"Controlled fusion energy is deemed pivotal for the advancement of human
civilization. In this study, we introduce $\textbf{LPI-LLM}$, a novel
integration of Large Language Models (LLMs) with classical reservoir computing
paradigms tailored to address a critical challenge, Laser-Plasma Instabilities
($\texttt{LPI}$), in Inertial Confinement Fusion ($\texttt{ICF}$). Our approach
offers several key contributions: Firstly, we propose the $\textit{LLM-anchored
Reservoir}$, augmented with a $\textit{Fusion-specific Prompt}$, enabling
accurate forecasting of $\texttt{LPI}$-generated-hot electron dynamics during
implosion. Secondly, we develop $\textit{Signal-Digesting Channels}$ to
temporally and spatially describe the driver laser intensity across time,
capturing the unique characteristics of $\texttt{ICF}$ inputs. Lastly, we
design the $\textit{Confidence Scanner}$ to quantify the confidence level in
forecasting, providing valuable insights for domain experts to design the
$\texttt{ICF}$ process. Extensive experiments demonstrate the superior
performance of our method, achieving 1.90 CAE, 0.14 $\texttt{top-1}$ MAE, and
0.11 $\texttt{top-5}$ MAE in predicting Hard X-ray ($\texttt{HXR}$) energies
emitted by the hot electrons in $\texttt{ICF}$ implosions, which presents
state-of-the-art comparisons against concurrent best systems. Additionally, we
present $\textbf{LPI4AI}$, the first $\texttt{LPI}$ benchmark based on physical
experiments, aimed at fostering novel ideas in $\texttt{LPI}$ research and
enhancing the utility of LLMs in scientific exploration. Overall, our work
strives to forge an innovative synergy between AI and $\texttt{ICF}$ for
advancing fusion energy.",2024-07-15,"Mingkai Chen, Taowen Wang, Shihui Cao, James Chenhao Liang, Chuan Liu, Chunshu Wu, Qifan Wang, Ying Nian Wu, Michael Huang, Chuang Ren, Ang Li, Tong Geng, Dongfang Liu",http://arxiv.org/pdf/2407.11098v3,cs.LG
GraphPrint: Extracting Features from 3D Protein Structure for Drug Target Affinity Prediction,"Accurate drug target affinity prediction can improve drug candidate
selection, accelerate the drug discovery process, and reduce drug production
costs. Previous work focused on traditional fingerprints or used features
extracted based on the amino acid sequence in the protein, ignoring its 3D
structure which affects its binding affinity. In this work, we propose
GraphPrint: a framework for incorporating 3D protein structure features for
drug target affinity prediction. We generate graph representations for protein
3D structures using amino acid residue location coordinates and combine them
with drug graph representation and traditional features to jointly learn drug
target affinity. Our model achieves a mean square error of 0.1378 and a
concordance index of 0.8929 on the KIBA dataset and improves over using
traditional protein features alone. Our ablation study shows that the 3D
protein structure-based features provide information complementary to
traditional features.",2024-07-15,Amritpal Singh,http://arxiv.org/pdf/2407.10452v1,cs.LG
"A Fast, Robust Elliptical Slice Sampling Implementation for Linearly Truncated Multivariate Normal Distributions","Elliptical slice sampling, when adapted to linearly truncated multivariate
normal distributions, is a rejection-free Markov chain Monte Carlo method. At
its core, it requires analytically constructing an ellipse-polytope
intersection. The main novelty of this paper is an algorithm that computes this
intersection in $\mathcal{O}(m \log m)$ time, where $m$ is the number of linear
inequality constraints representing the polytope. We show that an
implementation based on this algorithm enhances numerical stability, speeds up
running time, and is easy to parallelize for launching multiple Markov chains.",2024-07-15,"Kaiwen Wu, Jacob R. Gardner",http://arxiv.org/pdf/2407.10449v1,cs.LG
Spectral Representation for Causal Estimation with Hidden Confounders,"We address the problem of causal effect estimation where hidden confounders
are present, with a focus on two settings: instrumental variable regression
with additional observed confounders, and proxy causal learning. Our approach
uses a singular value decomposition of a conditional expectation operator,
followed by a saddle-point optimization problem, which, in the context of IV
regression, can be thought of as a neural net generalization of the seminal
approach due to Darolles et al. [2011]. Saddle-point formulations have gathered
considerable attention recently, as they can avoid double sampling bias and are
amenable to modern function approximation methods. We provide experimental
validation in various settings, and show that our approach outperforms existing
methods on common benchmarks.",2024-07-15,"Haotian Sun, Antoine Moulin, Tongzheng Ren, Arthur Gretton, Bo Dai",http://arxiv.org/pdf/2407.10448v2,cs.LG
Enhancing Building Safety Design for Active Shooter Incidents: Exploration of Building Exit Parameters using Reinforcement Learning-Based Simulations,"With the alarming rise in active shooter incidents (ASIs) in the United
States, enhancing public safety through building design has become a pressing
need. This study proposes a reinforcement learning-based simulation approach
addressing gaps in existing research that has neglected the dynamic behaviours
of shooters. We developed an autonomous agent to simulate an active shooter
within a realistic office environment, aiming to offer insights into the
interactions between building design parameters and ASI outcomes. A case study
is conducted to quantitatively investigate the impact of building exit numbers
(total count of accessible exits) and configuration (arrangement of which exits
are available or not) on evacuation and harm rates. Findings demonstrate that
greater exit availability significantly improves evacuation outcomes and
reduces harm. Exits nearer to the shooter's initial position hold greater
importance for accessibility than those farther away. By encompassing dynamic
shooter behaviours, this study offers preliminary insights into effective
building safety design against evolving threats.",2024-07-15,"Ruying Liu, Wanjing Wu, Burcin Becerik-Gerber, Gale M. Lucas",http://arxiv.org/pdf/2407.10441v1,cs.LG
Omni-Dimensional Frequency Learner for General Time Series Analysis,"Frequency domain representation of time series feature offers a concise
representation for handling real-world time series data with inherent
complexity and dynamic nature. However, current frequency-based methods with
complex operations still fall short of state-of-the-art time domain methods for
general time series analysis. In this work, we present Omni-Dimensional
Frequency Learner (ODFL) model based on a in depth analysis among all the three
aspects of the spectrum feature: channel redundancy property among the
frequency dimension, the sparse and un-salient frequency energy distribution
among the frequency dimension, and the semantic diversity among the variable
dimension. Technically, our method is composed of a semantic-adaptive global
filter with attention to the un-salient frequency bands and partial operation
among the channel dimension. Empirical results show that ODFL achieves
consistent state-of-the-art in five mainstream time series analysis tasks,
including short- and long-term forecasting, imputation, classification, and
anomaly detection, offering a promising foundation for time series analysis.",2024-07-15,"Xianing Chen, Hanting Chen, Hailin Hu",http://arxiv.org/pdf/2407.10419v2,cs.LG
An integrated perspective of robustness in regression through the lens of the bias-variance trade-off,"This paper presents an integrated perspective on robustness in regression.
Specifically, we examine the relationship between traditional outlier-resistant
robust estimation and robust optimization, which focuses on parameter
estimation resistant to imaginary dataset-perturbations. While both are
commonly regarded as robust methods, these concepts demonstrate a bias-variance
trade-off, indicating that they follow roughly converse strategies.",2024-07-15,Akifumi Okuno,http://arxiv.org/pdf/2407.10418v1,cs.LG
Proper losses regret at least 1/2-order,"A fundamental challenge in machine learning is the choice of a loss as it
characterizes our learning task, is minimized in the training phase, and serves
as an evaluation criterion for estimators. Proper losses are commonly chosen,
ensuring minimizers of the full risk match the true probability vector.
Estimators induced from a proper loss are widely used to construct forecasters
for downstream tasks such as classification and ranking. In this procedure, how
does the forecaster based on the obtained estimator perform well under a given
downstream task? This question is substantially relevant to the behavior of the
$p$-norm between the estimated and true probability vectors when the estimator
is updated. In the proper loss framework, the suboptimality of the estimated
probability vector from the true probability vector is measured by a surrogate
regret. First, we analyze a surrogate regret and show that the strict
properness of a loss is necessary and sufficient to establish a non-vacuous
surrogate regret bound. Second, we solve an important open question that the
order of convergence in p-norm cannot be faster than the $1/2$-order of
surrogate regrets for a broad class of strictly proper losses. This implies
that strongly proper losses entail the optimal convergence rate.",2024-07-15,"Han Bao, Asuka Takatsu",http://arxiv.org/pdf/2407.10417v1,cs.LG
Static and multivariate-temporal attentive fusion transformer for readmission risk prediction,"Background: Accurate short-term readmission prediction of ICU patients is
significant in improving the efficiency of resource assignment by assisting
physicians in making discharge decisions. Clinically, both individual static
static and multivariate temporal data collected from ICU monitors play critical
roles in short-term readmission prediction. Informative static and multivariate
temporal feature representation capturing and fusion present challenges for
accurate readmission prediction. Methods:We propose a novel static and
multivariate-temporal attentive fusion transformer (SMTAFormer) to predict
short-term readmission of ICU patients by fully leveraging the potential of
demographic and dynamic temporal data. In SMTAFormer, we first apply an MLP
network and a temporal transformer network to learn useful static and temporal
feature representations, respectively. Then, the well-designed static and
multivariate temporal feature fusion module is applied to fuse static and
temporal feature representations by modeling intra-correlation among
multivariate temporal features and constructing inter-correlation between
static and multivariate temporal features. Results: We construct a readmission
risk assessment (RRA) dataset based on the MIMIC-III dataset. The extensive
experiments show that SMTAFormer outperforms advanced methods, in which the
accuracy of our proposed method is up to 86.6%, and the area under the receiver
operating characteristic curve (AUC) is up to 0.717. Conclusion: Our proposed
SMTAFormer can efficiently capture and fuse static and multivariate temporal
feature representations. The results show that SMTAFormer significantly
improves the short-term readmission prediction performance of ICU patients
through comparisons to strong baselines.",2024-07-15,"Zhe Sun, Runzhi Li, Jing Wang, Gang Chen, Siyu Yan, Lihong Ma",http://arxiv.org/pdf/2407.11096v1,cs.LG
Teaching CORnet Human fMRI Representations for Enhanced Model-Brain Alignment,"Deep convolutional neural networks (DCNNs) have demonstrated excellent
performance in object recognition and have been found to share some
similarities with brain visual processing. However, the substantial gap between
DCNNs and human visual perception still exists. Functional magnetic resonance
imaging (fMRI) as a widely used technique in cognitive neuroscience can record
neural activation in the human visual cortex during the process of visual
perception. Can we teach DCNNs human fMRI signals to achieve a more brain-like
model? To answer this question, this study proposed ReAlnet-fMRI, a model based
on the SOTA vision model CORnet but optimized using human fMRI data through a
multi-layer encoding-based alignment framework. This framework has been shown
to effectively enable the model to learn human brain representations. The
fMRI-optimized ReAlnet-fMRI exhibited higher similarity to the human brain than
both CORnet and the control model in within-and across-subject as well as
within- and across-modality model-brain (fMRI and EEG) alignment evaluations.
Additionally, we conducted an in-depth analyses to investigate how the internal
representations of ReAlnet-fMRI differ from CORnet in encoding various object
dimensions. These findings provide the possibility of enhancing the
brain-likeness of visual models by integrating human neural data, helping to
bridge the gap between computer vision and visual neuroscience.",2024-07-15,"Zitong Lu, Yile Wang",http://arxiv.org/pdf/2407.10414v1,cs.LG
DeepGate3: Towards Scalable Circuit Representation Learning,"Circuit representation learning has shown promising results in advancing the
field of Electronic Design Automation (EDA). Existing models, such as DeepGate
Family, primarily utilize Graph Neural Networks (GNNs) to encode circuit
netlists into gate-level embeddings. However, the scalability of GNN-based
models is fundamentally constrained by architectural limitations, impacting
their ability to generalize across diverse and complex circuit designs. To
address these challenges, we introduce DeepGate3, an enhanced architecture that
integrates Transformer modules following the initial GNN processing. This novel
architecture not only retains the robust gate-level representation capabilities
of its predecessor, DeepGate2, but also enhances them with the ability to model
subcircuits through a novel pooling transformer mechanism. DeepGate3 is further
refined with multiple innovative supervision tasks, significantly enhancing its
learning process and enabling superior representation of both gate-level and
subcircuit structures. Our experiments demonstrate marked improvements in
scalability and generalizability over traditional GNN-based approaches,
establishing a significant step forward in circuit representation learning
technology.",2024-07-15,"Zhengyuan Shi, Ziyang Zheng, Sadaf Khan, Jianyuan Zhong, Min Li, Qiang Xu",http://arxiv.org/pdf/2407.11095v1,cs.LG
By My Eyes: Grounding Multimodal Large Language Models with Sensor Data via Visual Prompting,"Large language models (LLMs) have demonstrated exceptional abilities across
various domains. However, utilizing LLMs for ubiquitous sensing applications
remains challenging as existing text-prompt methods show significant
performance degradation when handling long sensor data sequences. We propose a
visual prompting approach for sensor data using multimodal LLMs (MLLMs). We
design a visual prompt that directs MLLMs to utilize visualized sensor data
alongside the target sensory task descriptions. Additionally, we introduce a
visualization generator that automates the creation of optimal visualizations
tailored to a given sensory task, eliminating the need for prior task-specific
knowledge. We evaluated our approach on nine sensory tasks involving four
sensing modalities, achieving an average of 10% higher accuracy than text-based
prompts and reducing token costs by 15.8 times. Our findings highlight the
effectiveness and cost-efficiency of visual prompts with MLLMs for various
sensory tasks. The source code is available at
https://github.com/diamond264/ByMyEyes.",2024-07-15,"Hyungjun Yoon, Biniyam Aschalew Tolera, Taesik Gong, Kimin Lee, Sung-Ju Lee",http://arxiv.org/pdf/2407.10385v2,cs.LG
"Learning to Represent Surroundings, Anticipate Motion and Take Informed Actions in Unstructured Environments","Contemporary robots have become exceptionally skilled at achieving specific
tasks in structured environments. However, they often fail when faced with the
limitless permutations of real-world unstructured environments. This motivates
robotics methods which learn from experience, rather than follow a pre-defined
set of rules. In this thesis, we present a range of learning-based methods
aimed at enabling robots, operating in dynamic and unstructured environments,
to better understand their surroundings, anticipate the actions of others, and
take informed actions accordingly.",2024-07-15,Weiming Zhi,http://arxiv.org/pdf/2407.10383v1,cs.LG
Accessing Vision Foundation Models via ImageNet-1K,"Vision foundation models are renowned for the generalization ability due to
massive training data. Nevertheless, they demand tremendous training resources,
and the training data is often inaccessible, e.g., CLIP, DINOv2, posing great
challenges to developing derivatives that could facilitate the research. In
this work, we offer a very simple and general solution, named \textit{Proteus},
to distill foundation models into smaller equivalents on ImageNet-1K without
access to the original training data. Specifically, we remove the designs from
conventional knowledge distillation settings that result in dataset bias and
present three levels of training objectives, i.e., token, patch, and feature,
to maximize the efficacy of knowledge transfer. In this manner, Proteus is
trained at ImageNet-level costs with surprising ability, facilitating the
accessibility of training foundation models for the broader research community.
When leveraging DINOv2-g/14 as the teacher, Proteus-L/14 matches the
performance of the Oracle method DINOv2-L/14 (142M training data) across 19
benchmarks and outperforms other vision foundation models including CLIP-L/14
(400M), OpenCLIP-L/14 (400M/2B) and SynCLR-L/14 (600M) with a significantly
smaller training set of 1.2M images.",2024-07-15,"Yitian Zhang, Xu Ma, Yue Bai, Huan Wang, Yun Fu",http://arxiv.org/pdf/2407.10366v2,cs.LG
Reinforcement Learning in High-frequency Market Making,"This paper establishes a new and comprehensive theoretical analysis for the
application of reinforcement learning (RL) in high-frequency market making. We
bridge the modern RL theory and the continuous-time statistical models in
high-frequency financial economics. Different with most existing literature on
methodological research about developing various RL methods for market making
problem, our work is a pilot to provide the theoretical analysis. We target the
effects of sampling frequency, and find an interesting tradeoff between error
and complexity of RL algorithm when tweaking the values of the time increment
$\Delta$ $-$ as $\Delta$ becomes smaller, the error will be smaller but the
complexity will be larger. We also study the two-player case under the
general-sum game framework and establish the convergence of Nash equilibrium to
the continuous-time game equilibrium as $\Delta\rightarrow0$. The Nash
Q-learning algorithm, which is an online multi-agent RL method, is applied to
solve the equilibrium. Our theories are not only useful for practitioners to
choose the sampling frequency, but also very general and applicable to other
high-frequency financial decision making problems, e.g., optimal executions, as
long as the time-discretization of a continuous-time markov decision process is
adopted. Monte Carlo simulation evidence support all of our theories.",2024-07-14,"Yuheng Zheng, Zihan Ding",http://arxiv.org/pdf/2407.21025v2,cs.LG
Affordance-Guided Reinforcement Learning via Visual Prompting,"Robots equipped with reinforcement learning (RL) have the potential to learn
a wide range of skills solely from a reward signal. However, obtaining a robust
and dense reward signal for general manipulation tasks remains a challenge.
Existing learning-based approaches require significant data, such as human
demonstrations of success and failure, to learn task-specific reward functions.
Recently, there is also a growing adoption of large multi-modal foundation
models for robotics that can perform visual reasoning in physical contexts and
generate coarse robot motions for manipulation tasks. Motivated by this range
of capability, in this work, we present Keypoint-based Affordance Guidance for
Improvements (KAGI), a method leveraging rewards shaped by vision-language
models (VLMs) for autonomous RL. State-of-the-art VLMs have demonstrated
impressive reasoning about affordances through keypoints in zero-shot, and we
use these to define dense rewards that guide autonomous robotic learning. On
real-world manipulation tasks specified by natural language descriptions, KAGI
improves the sample efficiency of autonomous RL and enables successful task
completion in 30K online fine-tuning steps. Additionally, we demonstrate the
robustness of KAGI to reductions in the number of in-domain demonstrations used
for pre-training, reaching similar performance in 45K online fine-tuning steps.
Project website: https://sites.google.com/view/affordance-guided-rl",2024-07-14,"Olivia Y. Lee, Annie Xie, Kuan Fang, Karl Pertsch, Chelsea Finn",http://arxiv.org/pdf/2407.10341v5,cs.LG
SENTINEL: Securing Indoor Localization against Adversarial Attacks with Capsule Neural Networks,"With the increasing demand for edge device powered location-based services in
indoor environments, Wi-Fi received signal strength (RSS) fingerprinting has
become popular, given the unavailability of GPS indoors. However, achieving
robust and efficient indoor localization faces several challenges, due to RSS
fluctuations from dynamic changes in indoor environments and heterogeneity of
edge devices, leading to diminished localization accuracy. While advances in
machine learning (ML) have shown promise in mitigating these phenomena, it
remains an open problem. Additionally, emerging threats from adversarial
attacks on ML-enhanced indoor localization systems, especially those introduced
by malicious or rogue access points (APs), can deceive ML models to further
increase localization errors. To address these challenges, we present SENTINEL,
a novel embedded ML framework utilizing modified capsule neural networks to
bolster the resilience of indoor localization solutions against adversarial
attacks, device heterogeneity, and dynamic RSS fluctuations. We also introduce
RSSRogueLoc, a novel dataset capturing the effects of rogue APs from several
real-world indoor environments. Experimental evaluations demonstrate that
SENTINEL achieves significant improvements, with up to 3.5x reduction in mean
error and 3.4x reduction in worst-case error compared to state-of-the-art
frameworks using simulated adversarial attacks. SENTINEL also achieves
improvements of up to 2.8x in mean error and 2.7x in worst-case error compared
to state-of-the-art frameworks when evaluated with the real-world RSSRogueLoc
dataset.",2024-07-14,"Danish Gufran, Pooja Anandathirtha, Sudeep Pasricha",http://arxiv.org/pdf/2407.11091v1,cs.LG
Thyroidiomics: An Automated Pipeline for Segmentation and Classification of Thyroid Pathologies from Scintigraphy Images,"The objective of this study was to develop an automated pipeline that
enhances thyroid disease classification using thyroid scintigraphy images,
aiming to decrease assessment time and increase diagnostic accuracy. Anterior
thyroid scintigraphy images from 2,643 patients were collected and categorized
into diffuse goiter (DG), multinodal goiter (MNG), and thyroiditis (TH) based
on clinical reports, and then segmented by an expert. A ResUNet model was
trained to perform auto-segmentation. Radiomic features were extracted from
both physician (scenario 1) and ResUNet segmentations (scenario 2), followed by
omitting highly correlated features using Spearman's correlation, and feature
selection using Recursive Feature Elimination (RFE) with XGBoost as the core.
All models were trained under leave-one-center-out cross-validation (LOCOCV)
scheme, where nine instances of algorithms were iteratively trained and
validated on data from eight centers and tested on the ninth for both scenarios
separately. Segmentation performance was assessed using the Dice similarity
coefficient (DSC), while classification performance was assessed using metrics,
such as precision, recall, F1-score, accuracy, area under the Receiver
Operating Characteristic (ROC AUC), and area under the precision-recall curve
(PRC AUC). ResUNet achieved DSC values of 0.84$\pm$0.03, 0.71$\pm$0.06, and
0.86$\pm$0.02 for MNG, TH, and DG, respectively. Classification in scenario 1
achieved an accuracy of 0.76$\pm$0.04 and a ROC AUC of 0.92$\pm$0.02 while in
scenario 2, classification yielded an accuracy of 0.74$\pm$0.05 and a ROC AUC
of 0.90$\pm$0.02. The automated pipeline demonstrated comparable performance to
physician segmentations on several classification metrics across different
classes, effectively reducing assessment time while maintaining high diagnostic
accuracy. Code available at: https://github.com/ahxmeds/thyroidiomics.git.",2024-07-14,"Maziar Sabouri, Shadab Ahamed, Azin Asadzadeh, Atlas Haddadi Avval, Soroush Bagheri, Mohsen Arabi, Seyed Rasoul Zakavi, Emran Askari, Ali Rasouli, Atena Aghaee, Mohaddese Sehati, Fereshteh Yousefirizi, Carlos Uribe, Ghasem Hajianfar, Habib Zaidi, Arman Rahmim",http://arxiv.org/pdf/2407.10336v2,cs.LG
Towards Adapting Reinforcement Learning Agents to New Tasks: Insights from Q-Values,"While contemporary reinforcement learning research and applications have
embraced policy gradient methods as the panacea of solving learning problems,
value-based methods can still be useful in many domains as long as we can
wrangle with how to exploit them in a sample efficient way. In this paper, we
explore the chaotic nature of DQNs in reinforcement learning, while
understanding how the information that they retain when trained can be
repurposed for adapting a model to different tasks. We start by designing a
simple experiment in which we are able to observe the Q-values for each state
and action in an environment. Then we train in eight different ways to explore
how these training algorithms affect the way that accurate Q-values are learned
(or not learned). We tested the adaptability of each trained model when
retrained to accomplish a slightly modified task. We then scaled our setup to
test the larger problem of an autonomous vehicle at an unprotected
intersection. We observed that the model is able to adapt to new tasks quicker
when the base model's Q-value estimates are closer to the true Q-values. The
results provide some insights and guidelines into what algorithms are useful
for sample efficient task adaptation.",2024-07-14,"Ashwin Ramaswamy, Ransalu Senanayake",http://arxiv.org/pdf/2407.10335v1,cs.LG
An Interpretable Neural Network for Vegetation Phenotyping with Visualization of Trait-Based Spectral Features,"Plant phenotyping is the assessment of a plant's traits and plant
identification is the process of determining the category such as genus and
species. In this paper we present an interpretable neural network trained on
the UPWINS spectral library which contains spectra with rich metadata across
variation in species, health, growth stage, annual variation, and environmental
conditions for 13 selected indicator species and natural common background
species. We show that the neurons in the network learn spectral indicators for
chemical and physiological traits through visualization of the network weights,
and we show how these traits are combined by the network for species
identification with an accuracy around 90% on a test set. While neural networks
are often perceived as `black box' classifiers, our work shows that they can be
in fact more explainable and informative than other machine learning methods.
We show that the neurons learn fundamental traits about the vegetation, for
example the composition of different types of chlorophyll present which
indicates species as well as response to illumination conditions. There is
clear excess training capacity in our network, and we expect that as the UPWINS
spectral library continues to grow the approach in this paper will provide
further foundational insights in understanding plant traits. This provides a
methodology for designing and interpreting neural networks on spectral data in
general, and provides a framework for using neural networks with hyperspectral
imagery for understanding vegetation that is extendable to other domains.",2024-07-14,"William Basener, Abigail Basener, Michael Luegering",http://arxiv.org/pdf/2407.10333v1,cs.LG
Ontology-driven Reinforcement Learning for Personalized Student Support,"In the search for more effective education, there is a widespread effort to
develop better approaches to personalize student education. Unassisted,
educators often do not have time or resources to personally support every
student in a given classroom. Motivated by this issue, and by recent
advancements in artificial intelligence, this paper presents a general-purpose
framework for personalized student support, applicable to any virtual
educational system such as a serious game or an intelligent tutoring system. To
fit any educational situation, we apply ontologies for their semantic
organization, combining them with data collection considerations and
multi-agent reinforcement learning. The result is a modular system that can be
adapted to any virtual educational software to provide useful personalized
assistance to students.",2024-07-14,"Ryan Hare, Ying Tang",http://arxiv.org/pdf/2407.10332v2,cs.LG
3D Foundation Models Enable Simultaneous Geometry and Pose Estimation of Grasped Objects,"Humans have the remarkable ability to use held objects as tools to interact
with their environment. For this to occur, humans internally estimate how hand
movements affect the object's movement. We wish to endow robots with this
capability. We contribute methodology to jointly estimate the geometry and pose
of objects grasped by a robot, from RGB images captured by an external camera.
Notably, our method transforms the estimated geometry into the robot's
coordinate frame, while not requiring the extrinsic parameters of the external
camera to be calibrated. Our approach leverages 3D foundation models, large
models pre-trained on huge datasets for 3D vision tasks, to produce initial
estimates of the in-hand object. These initial estimations do not have
physically correct scales and are in the camera's frame. Then, we formulate,
and efficiently solve, a coordinate-alignment problem to recover accurate
scales, along with a transformation of the objects to the coordinate frame of
the robot. Forward kinematics mappings can subsequently be defined from the
manipulator's joint angles to specified points on the object. These mappings
enable the estimation of points on the held object at arbitrary configurations,
enabling robot motion to be designed with respect to coordinates on the grasped
objects. We empirically evaluate our approach on a robot manipulator holding a
diverse set of real-world objects.",2024-07-14,"Weiming Zhi, Haozhan Tang, Tianyi Zhang, Matthew Johnson-Roberson",http://arxiv.org/pdf/2407.10331v1,cs.LG
Learning Unlabeled Clients Divergence for Federated Semi-Supervised Learning via Anchor Model Aggregation,"Federated semi-supervised learning (FedSemi) refers to scenarios where there
may be clients with fully labeled data, clients with partially labeled, and
even fully unlabeled clients while preserving data privacy. However, challenges
arise from client drift due to undefined heterogeneous class distributions and
erroneous pseudo-labels. Existing FedSemi methods typically fail to aggregate
models from unlabeled clients due to their inherent unreliability, thus
overlooking unique information from their heterogeneous data distribution,
leading to sub-optimal results. In this paper, we enable unlabeled client
aggregation through SemiAnAgg, a novel Semi-supervised Anchor-Based federated
Aggregation. SemiAnAgg learns unlabeled client contributions via an anchor
model, effectively harnessing their informative value. Our key idea is that by
feeding local client data to the same global model and the same consistently
initialized anchor model (i.e., random model), we can measure the importance of
each unlabeled client accordingly. Extensive experiments demonstrate that
SemiAnAgg achieves new state-of-the-art results on four widely used FedSemi
benchmarks, leading to substantial performance improvements: a 9% increase in
accuracy on CIFAR-100 and a 7.6% improvement in recall on the medical dataset
ISIC-18, compared with prior state-of-the-art. Code is available at:
https://github.com/xmed-lab/SemiAnAgg.",2024-07-14,"Marawan Elbatel, Hualiang Wang, Jixiang Chen, Hao Wang, Xiaomeng Li",http://arxiv.org/pdf/2407.10327v2,cs.LG
Order parameters and phase transitions of continual learning in deep neural networks,"Continual learning (CL) enables animals to learn new tasks without erasing
prior knowledge. CL in artificial neural networks (NNs) is challenging due to
catastrophic forgetting, where new learning degrades performance on older
tasks. While various techniques exist to mitigate forgetting, theoretical
insights into when and why CL fails in NNs are lacking. Here, we present a
statistical-mechanics theory of CL in deep, wide NNs, which characterizes the
network's input-output mapping as it learns a sequence of tasks. It gives rise
to order parameters (OPs) that capture how task relations and network
architecture influence forgetting and anterograde interference, as verified by
numerical evaluations. For networks with a shared readout for all tasks
(single-head CL), the relevant-feature and rule similarity between tasks,
respectively measured by two OPs, are sufficient to predict a wide range of CL
behaviors. In addition, the theory predicts that increasing the network depth
can effectively reduce interference between tasks, thereby lowering forgetting.
For networks with task-specific readouts (multi-head CL), the theory identifies
a phase transition where CL performance shifts dramatically as tasks become
less similar, as measured by another task-similarity OP. While forgetting is
relatively mild compared to single-head CL across all tasks, sufficiently low
similarity leads to catastrophic anterograde interference, where the network
retains old tasks perfectly but completely fails to generalize new learning.
Our results delineate important factors affecting CL performance and suggest
strategies for mitigating forgetting.",2024-07-14,"Haozhe Shan, Qianyi Li, Haim Sompolinsky",http://arxiv.org/pdf/2407.10315v2,cs.LG
Augmented prediction of a true class for Positive Unlabeled data under selection bias,"We introduce a new observational setting for Positive Unlabeled (PU) data
where the observations at prediction time are also labeled. This occurs
commonly in practice -- we argue that the additional information is important
for prediction, and call this task ""augmented PU prediction"". We allow for
labeling to be feature dependent. In such scenario, Bayes classifier and its
risk is established and compared with a risk of a classifier which for
unlabeled data is based only on predictors. We introduce several variants of
the empirical Bayes rule in such scenario and investigate their performance. We
emphasise dangers (and ease) of applying classical classification rule in the
augmented PU scenario -- due to no preexisting studies, an unaware researcher
is prone to skewing the obtained predictions. We conclude that the variant
based on recently proposed variational autoencoder designed for PU scenario
works on par or better than other considered variants and yields advantage over
feature-only based methods in terms of accuracy for unlabeled samples.",2024-07-14,"Jan Mielniczuk, Adam Wawrzeńczyk",http://arxiv.org/pdf/2407.10309v1,cs.LG
Numbers Matter! Bringing Quantity-awareness to Retrieval Systems,"Quantitative information plays a crucial role in understanding and
interpreting the content of documents. Many user queries contain quantities and
cannot be resolved without understanding their semantics, e.g., ``car that
costs less than $10k''. Yet, modern search engines apply the same ranking
mechanisms for both words and quantities, overlooking magnitude and unit
information. In this paper, we introduce two quantity-aware ranking techniques
designed to rank both the quantity and textual content either jointly or
independently. These techniques incorporate quantity information in available
retrieval systems and can address queries with numerical conditions equal,
greater than, and less than. To evaluate the effectiveness of our proposed
models, we introduce two novel quantity-aware benchmark datasets in the domains
of finance and medicine and compare our method against various lexical and
neural models. The code and data are available under
https://github.com/satya77/QuantityAwareRankers.",2024-07-14,"Satya Almasian, Milena Bruseva, Michael Gertz",http://arxiv.org/pdf/2407.10283v1,cs.LG
"Deep Learning Activation Functions: Fixed-Shape, Parametric, Adaptive, Stochastic, Miscellaneous, Non-Standard, Ensemble","In the architecture of deep learning models, inspired by biological neurons,
activation functions (AFs) play a pivotal role. They significantly influence
the performance of artificial neural networks. By modulating the non-linear
properties essential for learning complex patterns, AFs are fundamental in both
classification and regression tasks. This paper presents a comprehensive review
of various types of AFs, including fixed-shape, parametric, adaptive,
stochastic/probabilistic, non-standard, and ensemble/combining types. We begin
with a systematic taxonomy and detailed classification frameworks that
delineates the principal characteristics of AFs and organizes them based on
their structural and functional distinctions. Our in-depth analysis covers
primary groups such as sigmoid-based, ReLU-based, and ELU-based AFs, discussing
their theoretical foundations, mathematical formulations, and specific benefits
and limitations in different contexts. We also highlight key attributes of AFs
such as output range, monotonicity, and smoothness. Furthermore, we explore
miscellaneous AFs that do not conform to these categories but have shown unique
advantages in specialized applications. Non-standard AFs are also explored,
showcasing cutting-edge variations that challenge traditional paradigms and
offer enhanced adaptability and model performance. We examine strategies for
combining multiple AFs to leverage complementary properties. The paper
concludes with a comparative evaluation of 12 state-of-the-art AFs, using
rigorous statistical and experimental methodologies to assess their efficacy.
This analysis not only aids practitioners in selecting and designing the most
appropriate AFs for their specific deep learning tasks but also encourages
continued innovation in AF development within the machine learning community.",2024-07-14,M. M. Hammad,http://arxiv.org/pdf/2407.11090v1,cs.LG
Disrupting Diffusion-based Inpainters with Semantic Digression,"The fabrication of visual misinformation on the web and social media has
increased exponentially with the advent of foundational text-to-image diffusion
models. Namely, Stable Diffusion inpainters allow the synthesis of maliciously
inpainted images of personal and private figures, and copyrighted contents,
also known as deepfakes. To combat such generations, a disruption framework,
namely Photoguard, has been proposed, where it adds adversarial noise to the
context image to disrupt their inpainting synthesis. While their framework
suggested a diffusion-friendly approach, the disruption is not sufficiently
strong and it requires a significant amount of GPU and time to immunize the
context image. In our work, we re-examine both the minimal and favorable
conditions for a successful inpainting disruption, proposing DDD, a ""Digression
guided Diffusion Disruption"" framework. First, we identify the most
adversarially vulnerable diffusion timestep range with respect to the hidden
space. Within this scope of noised manifold, we pose the problem as a semantic
digression optimization. We maximize the distance between the inpainting
instance's hidden states and a semantic-aware hidden state centroid, calibrated
both by Monte Carlo sampling of hidden states and a discretely projected
optimization in the token space. Effectively, our approach achieves stronger
disruption and a higher success rate than Photoguard while lowering the GPU
memory requirement, and speeding the optimization up to three times faster.",2024-07-14,"Geonho Son, Juhun Lee, Simon S. Woo",http://arxiv.org/pdf/2407.10277v1,cs.LG
Enhancing Weakly-Supervised Histopathology Image Segmentation with Knowledge Distillation on MIL-Based Pseudo-Labels,"Segmenting tumors in histological images is vital for cancer diagnosis. While
fully supervised models excel with pixel-level annotations, creating such
annotations is labor-intensive and costly. Accurate histopathology image
segmentation under weakly-supervised conditions with coarse-grained image
labels is still a challenging problem. Although multiple instance learning
(MIL) has shown promise in segmentation tasks, surprisingly, no previous
pseudo-supervision methods have used MIL-based outputs as pseudo-masks for
training. We suspect this stems from concerns over noises in MIL results
affecting pseudo supervision quality. To explore the potential of leveraging
MIL-based segmentation for pseudo supervision, we propose a novel distillation
framework for histopathology image segmentation. This framework introduces a
iterative fusion-knowledge distillation strategy, enabling the student model to
learn directly from the teacher's comprehensive outcomes. Through dynamic role
reversal between the fixed teacher and learnable student models and the
incorporation of weighted cross-entropy loss for model optimization, our
approach prevents performance deterioration and noise amplification during
knowledge distillation. Experimental results on public histopathology datasets,
Camelyon16 and Digestpath2019, demonstrate that our approach not only
complements various MIL-based segmentation methods but also significantly
enhances their performance. Additionally, our method achieves new SOTA in the
field.",2024-07-14,"Yinsheng He, Xingyu Li, Roger J. Zemp",http://arxiv.org/pdf/2407.10274v1,cs.LG
psifx -- Psychological and Social Interactions Feature Extraction Package,"psifx is a plug-and-play multi-modal feature extraction toolkit, aiming to
facilitate and democratize the use of state-of-the-art machine learning
techniques for human sciences research. It is motivated by a need (a) to
automate and standardize data annotation processes, otherwise involving
expensive, lengthy, and inconsistent human labor, such as the transcription or
coding of behavior changes from audio and video sources; (b) to develop and
distribute open-source community-driven psychology research software; and (c)
to enable large-scale access and ease of use to non-expert users. The framework
contains an array of tools for tasks, such as speaker diarization,
closed-caption transcription and translation from audio, as well as body, hand,
and facial pose estimation and gaze tracking from video. The package has been
designed with a modular and task-oriented approach, enabling the community to
add or update new tools easily. We strongly hope that this package will provide
psychologists a simple and practical solution for efficiently a range of audio,
linguistic, and visual features from audio and video, thereby creating new
opportunities for in-depth study of real-time behavioral phenomena.",2024-07-14,"Guillaume Rochette, Matthew J. Vowels, Mathieu Rochat",http://arxiv.org/pdf/2407.10266v3,cs.LG
What Makes and Breaks Safety Fine-tuning? A Mechanistic Study,"Safety fine-tuning helps align Large Language Models (LLMs) with human
preferences for their safe deployment. To better understand the underlying
factors that make models safe via safety fine-tuning, we design a synthetic
data generation framework that captures salient aspects of an unsafe input by
modeling the interaction between the task the model is asked to perform (e.g.,
""design"") versus the specific concepts the task is asked to be performed upon
(e.g., a ""cycle"" vs. a ""bomb""). Using this, we investigate three well-known
safety fine-tuning methods -- supervised safety fine-tuning, direct preference
optimization, and unlearning -- and provide significant evidence demonstrating
that these methods minimally transform MLP weights to specifically align unsafe
inputs into its weights' null space. This yields a clustering of inputs based
on whether the model deems them safe or not. Correspondingly, when an
adversarial input (e.g., a jailbreak) is provided, its activations are closer
to safer samples, leading to the model processing such an input as if it were
safe. We validate our findings, wherever possible, on real-world models --
specifically, Llama-2 7B and Llama-3 8B.",2024-07-14,"Samyak Jain, Ekdeep Singh Lubana, Kemal Oksuz, Tom Joy, Philip H. S. Torr, Amartya Sanyal, Puneet K. Dokania",http://arxiv.org/pdf/2407.10264v3,cs.LG
Towards detailed and interpretable hybrid modeling of continental-scale bird migration,"Hybrid modeling aims to augment traditional theory-driven models with machine
learning components that learn unknown parameters, sub-models or correction
terms from data. In this work, we build on FluxRGNN, a recently developed
hybrid model of continental-scale bird migration, which combines a movement
model inspired by fluid dynamics with recurrent neural networks that capture
the complex decision-making processes of birds. While FluxRGNN has been shown
to successfully predict key migration patterns, its spatial resolution is
constrained by the typically sparse observations obtained from weather radars.
Additionally, its trainable components lack explicit incentives to adequately
predict take-off and landing events. Both aspects limit our ability to
interpret model results ecologically. To address this, we propose two major
modifications that allow for more detailed predictions on any desired
tessellation while providing control over the interpretability of model
components. In experiments on the U.S. weather radar network, the enhanced
model effectively leverages the underlying movement model, resulting in strong
extrapolation capabilities to unobserved locations.",2024-07-14,"Fiona Lippert, Bart Kranstauber, Patrick Forré, E. Emiel van Loon",http://arxiv.org/pdf/2407.10259v1,cs.LG
Deep Learning Algorithms for Early Diagnosis of Acute Lymphoblastic Leukemia,"Acute lymphoblastic leukemia (ALL) is a form of blood cancer that affects the
white blood cells. ALL constitutes approximately 25% of pediatric cancers.
Early diagnosis and treatment of ALL are crucial for improving patient
outcomes. The task of identifying immature leukemic blasts from normal cells
under the microscope can prove challenging, since the images of a healthy and
cancerous cell appear similar morphologically. In this study, we propose a
binary image classification model to assist in the diagnostic process of ALL.
Our model takes as input microscopic images of blood samples and outputs a
binary prediction of whether the sample is normal or cancerous. Our dataset
consists of 10661 images out of 118 subjects. Deep learning techniques on
convolutional neural network architectures were used to achieve accurate
classification results. Our proposed method achieved 94.3% accuracy and could
be used as an assisting tool for hematologists trying to predict the likelihood
of a patient developing ALL.",2024-07-14,"Dimitris Papaioannou, Ioannis Christou, Nikos Anagnou, Aristotelis Chatziioannou",http://arxiv.org/pdf/2407.10251v1,cs.LG
Explainable bank failure prediction models: Counterfactual explanations to reduce the failure risk,"The accuracy and understandability of bank failure prediction models are
crucial. While interpretable models like logistic regression are favored for
their explainability, complex models such as random forest, support vector
machines, and deep learning offer higher predictive performance but lower
explainability. These models, known as black boxes, make it difficult to derive
actionable insights. To address this challenge, using counterfactual
explanations is suggested. These explanations demonstrate how changes in input
variables can alter the model output and suggest ways to mitigate bank failure
risk. The key challenge lies in selecting the most effective method for
generating useful counterfactuals, which should demonstrate validity,
proximity, sparsity, and plausibility. The paper evaluates several
counterfactual generation methods: WhatIf, Multi Objective, and Nearest
Instance Counterfactual Explanation, and also explores resampling methods like
undersampling, oversampling, SMOTE, and the cost sensitive approach to address
data imbalance in bank failure prediction in the US. The results indicate that
the Nearest Instance Counterfactual Explanation method yields higher quality
counterfactual explanations, mainly using the cost sensitive approach. Overall,
the Multi Objective Counterfactual and Nearest Instance Counterfactual
Explanation methods outperform others regarding validity, proximity, and
sparsity metrics, with the cost sensitive approach providing the most desirable
counterfactual explanations. These findings highlight the variability in the
performance of counterfactual generation methods across different balancing
strategies and machine learning models, offering valuable strategies to enhance
the utility of black box bank failure prediction models.",2024-07-14,"Seyma Gunonu, Gizem Altun, Mustafa Cavus",http://arxiv.org/pdf/2407.11089v2,cs.LG
xLSTMTime : Long-term Time Series Forecasting With xLSTM,"In recent years, transformer-based models have gained prominence in
multivariate long-term time series forecasting (LTSF), demonstrating
significant advancements despite facing challenges such as high computational
demands, difficulty in capturing temporal dynamics, and managing long-term
dependencies. The emergence of LTSF-Linear, with its straightforward linear
architecture, has notably outperformed transformer-based counterparts,
prompting a reevaluation of the transformer's utility in time series
forecasting. In response, this paper presents an adaptation of a recent
architecture termed extended LSTM (xLSTM) for LTSF. xLSTM incorporates
exponential gating and a revised memory structure with higher capacity that has
good potential for LTSF. Our adopted architecture for LTSF termed as xLSTMTime
surpasses current approaches. We compare xLSTMTime's performance against
various state-of-the-art models across multiple real-world da-tasets,
demonstrating superior forecasting capabilities. Our findings suggest that
refined recurrent architectures can offer competitive alternatives to
transformer-based models in LTSF tasks, po-tentially redefining the landscape
of time series forecasting.",2024-07-14,"Musleh Alharthi, Ausif Mahmood",http://arxiv.org/pdf/2407.10240v3,cs.LG
Asymptotic Normality of Generalized Low-Rank Matrix Sensing via Riemannian Geometry,"We prove an asymptotic normality guarantee for generalized low-rank matrix
sensing -- i.e., matrix sensing under a general convex loss $\bar\ell(\langle
X,M\rangle,y^*)$, where $M\in\mathbb{R}^{d\times d}$ is the unknown rank-$k$
matrix, $X$ is a measurement matrix, and $y^*$ is the corresponding
measurement. Our analysis relies on tools from Riemannian geometry to handle
degeneracy of the Hessian of the loss due to rotational symmetry in the
parameter space. In particular, we parameterize the manifold of low-rank
matrices by $\bar\theta\bar\theta^\top$, where
$\bar\theta\in\mathbb{R}^{d\times k}$. Then, assuming the minimizer of the
empirical loss $\bar\theta^0\in\mathbb{R}^{d\times k}$ is in a constant size
ball around the true parameters $\bar\theta^*$, we prove
$\sqrt{n}(\phi^0-\phi^*)\xrightarrow{D}N(0,(H^*)^{-1})$ as $n\to\infty$, where
$\phi^0$ and $\phi^*$ are representations of $\bar\theta^*$ and $\bar\theta^0$
in the horizontal space of the Riemannian quotient manifold
$\mathbb{R}^{d\times k}/\text{O}(k)$, and $H^*$ is the Hessian of the true loss
in the same representation.",2024-07-14,Osbert Bastani,http://arxiv.org/pdf/2407.10238v2,cs.LG
Weighted Aggregation of Conformity Scores for Classification,"Conformal prediction is a powerful framework for constructing prediction sets
with valid coverage guarantees in multi-class classification. However, existing
methods often rely on a single score function, which can limit their efficiency
and informativeness. We propose a novel approach that combines multiple score
functions to improve the performance of conformal predictors by identifying
optimal weights that minimize prediction set size. Our theoretical analysis
establishes a connection between the weighted score functions and subgraph
classes of functions studied in Vapnik-Chervonenkis theory, providing a
rigorous mathematical basis for understanding the effectiveness of the proposed
method. Experiments demonstrate that our approach consistently outperforms
single-score conformal predictors while maintaining valid coverage, offering a
principled and data-driven way to enhance the efficiency and practicality of
conformal prediction in classification tasks.",2024-07-14,"Rui Luo, Zhixin Zhou",http://arxiv.org/pdf/2407.10230v2,cs.LG
On Large Language Model Continual Unlearning,"While large language models have demonstrated impressive performance across
various domains and tasks, their security issues have become increasingly
severe. Machine unlearning has emerged as a representative approach for model
safety and security by removing the influence of undesired data on the target
model. However, these methods do not sufficiently consider that unlearning
requests in real-world scenarios are continuously emerging, especially in the
context of LLMs, which may lead to accumulated model utility loss that
eventually becomes unacceptable. Moreover, existing LLM unlearning methods
often ignore previous data access limitations due to privacy concerns and
copyright protection. Without previous data, the utility preservation during
unlearning is much harder. To overcome these challenges, we propose the OOO
framework that includes an Orthogonal low-rank adapter (LoRA) for continually
unlearning requested data and an Out-Of-Distribution (OOD) detector to measure
the similarity between input and unlearning data. The orthogonal LoRA achieves
parameter disentanglement among continual unlearning requests. The OOD detector
is trained with a novel contrastive entropy loss and utilizes a glocal-aware
scoring mechanism. During inference, our OOO framework can decide whether and
to what extent to load the unlearning LoRA based on the OOD detector's
predicted similarity between the input and the unlearned knowledge. Notably,
OOO's effectiveness does not rely on any retained data. We conducted extensive
experiments on OOO and state-of-the-art LLM unlearning methods across three
tasks and seven datasets. The results indicate that OOO consistently achieves
the best unlearning effectiveness and utility preservation, especially when
facing continuous unlearning requests. The source codes can be found at
https://github.com/GCYZSL/O3-LLM-UNLEARNING.",2024-07-14,"Chongyang Gao, Lixu Wang, Kaize Ding, Chenkai Weng, Xiao Wang, Qi Zhu",http://arxiv.org/pdf/2407.10223v2,cs.LG
Learning to Steer Markovian Agents under Model Uncertainty,"Designing incentives for an adapting population is a ubiquitous problem in a
wide array of economic applications and beyond. In this work, we study how to
design additional rewards to steer multi-agent systems towards desired policies
\emph{without} prior knowledge of the agents' underlying learning dynamics.
Motivated by the limitation of existing works, we consider a new and general
category of learning dynamics called \emph{Markovian agents}. We introduce a
model-based non-episodic Reinforcement Learning (RL) formulation for our
steering problem. Importantly, we focus on learning a \emph{history-dependent}
steering strategy to handle the inherent model uncertainty about the agents'
learning dynamics. We introduce a novel objective function to encode the
desiderata of achieving a good steering outcome with reasonable cost.
Theoretically, we identify conditions for the existence of steering strategies
to guide agents to the desired policies. Complementing our theoretical
contributions, we provide empirical algorithms to approximately solve our
objective, which effectively tackles the challenge in learning
history-dependent strategies. We demonstrate the efficacy of our algorithms
through empirical evaluations.",2024-07-14,"Jiawei Huang, Vinzenz Thoma, Zebang Shen, Heinrich H. Nax, Niao He",http://arxiv.org/pdf/2407.10207v3,cs.LG
Improving Graph Out-of-distribution Generalization on Real-world Data,"Existing methods for graph out-of-distribution (OOD) generalization primarily
rely on empirical studies on synthetic datasets. Such approaches tend to
overemphasize the causal relationships between invariant sub-graphs and labels,
thereby neglecting the non-negligible role of environment in real-world
scenarios. In contrast to previous studies that impose rigid independence
assumptions on environments and invariant sub-graphs, this paper presents the
theorems of environment-label dependency and mutable rationale invariance,
where the former characterizes the usefulness of environments in determining
graph labels while the latter refers to the mutable importance of graph
rationales. Based on analytic investigations, a novel variational inference
based method named ``Probability Dependency on Environments and Rationales for
OOD Graphs on Real-world Data'' (DEROG) is introduced. To alleviate the adverse
effect of unknown prior knowledge on environments and rationales, DEROG
utilizes generalized Bayesian inference. Further, DEROG employs an EM-based
algorithm for optimization. Finally, extensive experiments on real-world
datasets under different distribution shifts are conducted to show the
superiority of DEROG. Our code is publicly available at
https://anonymous.4open.science/r/DEROG-536B.",2024-07-14,"Can Xu, Yao Cheng, Jianxiang Yu, Haosen Wang, Jingsong Lv, Xiang Li",http://arxiv.org/pdf/2407.10204v1,cs.LG
A3S: A General Active Clustering Method with Pairwise Constraints,"Active clustering aims to boost the clustering performance by integrating
human-annotated pairwise constraints through strategic querying. Conventional
approaches with semi-supervised clustering schemes encounter high query costs
when applied to large datasets with numerous classes. To address these
limitations, we propose a novel Adaptive Active Aggregation and Splitting (A3S)
framework, falling within the cluster-adjustment scheme in active clustering.
A3S features strategic active clustering adjustment on the initial cluster
result, which is obtained by an adaptive clustering algorithm. In particular,
our cluster adjustment is inspired by the quantitative analysis of Normalized
mutual information gain under the information theory framework and can provably
improve the clustering quality. The proposed A3S framework significantly
elevates the performance and scalability of active clustering. In extensive
experiments across diverse real-world datasets, A3S achieves desired results
with significantly fewer human queries compared with existing methods.",2024-07-14,"Xun Deng, Junlong Liu, Han Zhong, Fuli Feng, Chen Shen, Xiangnan He, Jieping Ye, Zheng Wang",http://arxiv.org/pdf/2407.10196v1,cs.LG
Curriculum Learning for Small Code Language Models,"Code language models have emerged as useful tools for various programming
tasks, yet they often struggle when it comes to complex ones. In this paper, we
explore the potential of curriculum learning in enhancing the performance of
these models. While prior research has suggested that curriculum learning does
not necessarily help in improving the performance of language models, our
results surprisingly show that this may not be the case for code language
models. We demonstrate that a well-designed curriculum learning approach
significantly improves the accuracy of small decoder-only code language models
on the task of code execution, while its effect on code completion is less
significant. To explore the potential of curriculum learning, we train multiple
GPT models with 1 million parameters each to predict the next token and
evaluate them on code completion and execution tasks. Our contributions include
proposing a novel code difficulty assessment metric by combining software code
measures, investigating the effectiveness of Curriculum Learning for code
language models, and introducing a Novel Curriculum Learning schedule that
enhances the performance of small decoder-only language models in code
execution tasks. The results of this paper open the door for more research on
the use of curriculum learning for code language models.",2024-07-14,"Marwa Naïr, Kamel Yamani, Lynda Said Lhadj, Riyadh Baghdadi",http://arxiv.org/pdf/2407.10194v1,cs.LG
Unexpected Benefits of Self-Modeling in Neural Systems,"Self-models have been a topic of great interest for decades in studies of
human cognition and more recently in machine learning. Yet what benefits do
self-models confer? Here we show that when artificial networks learn to predict
their internal states as an auxiliary task, they change in a fundamental way.
To better perform the self-model task, the network learns to make itself
simpler, more regularized, more parameter-efficient, and therefore more
amenable to being predictively modeled. To test the hypothesis of
self-regularizing through self-modeling, we used a range of network
architectures performing three classification tasks across two modalities. In
all cases, adding self-modeling caused a significant reduction in network
complexity. The reduction was observed in two ways. First, the distribution of
weights was narrower when self-modeling was present. Second, a measure of
network complexity, the real log canonical threshold (RLCT), was smaller when
self-modeling was present. Not only were measures of complexity reduced, but
the reduction became more pronounced as greater training weight was placed on
the auxiliary task of self-modeling. These results strongly support the
hypothesis that self-modeling is more than simply a network learning to predict
itself. The learning has a restructuring effect, reducing complexity and
increasing parameter efficiency. This self-regularization may help explain some
of the benefits of self-models reported in recent machine learning literature,
as well as the adaptive value of self-models to biological systems. In
particular, these findings may shed light on the possible interaction between
the ability to model oneself and the ability to be more easily modeled by
others in a social or cooperative context.",2024-07-14,"Vickram N. Premakumar, Michael Vaiana, Florin Pop, Judd Rosenblatt, Diogo Schwerz de Lucena, Kirsten Ziman, Michael S. A. Graziano",http://arxiv.org/pdf/2407.10188v2,cs.LG
The Hidden Influence of Latent Feature Magnitude When Learning with Imbalanced Data,"Machine learning (ML) models have difficulty generalizing when the number of
training class instances are numerically imbalanced. The problem of
generalization in the face of data imbalance has largely been attributed to the
lack of training data for under-represented classes and to feature overlap. The
typical remedy is to implement data augmentation for classes with fewer
instances or to assign a higher cost to minority class prediction errors or to
undersample the prevalent class. However, we show that one of the central
causes of impaired generalization when learning with imbalanced data is the
inherent manner in which ML models perform inference. These models have
difficulty generalizing due to their heavy reliance on the magnitude of encoded
signals. During inference, the models predict classes based on a combination of
encoded signal magnitudes that linearly sum to the largest scalar. We
demonstrate that even with aggressive data augmentation, which generally
improves minority class prediction accuracy, parametric ML models still
associate a class label with a limited number of feature combinations that sum
to a prediction, which can affect generalization.",2024-07-14,"Damien A. Dablain, Nitesh V. Chawla",http://arxiv.org/pdf/2407.10165v1,cs.LG
Pre-training with Fractional Denoising to Enhance Molecular Property Prediction,"Deep learning methods have been considered promising for accelerating
molecular screening in drug discovery and material design. Due to the limited
availability of labelled data, various self-supervised molecular pre-training
methods have been presented. While many existing methods utilize common
pre-training tasks in computer vision (CV) and natural language processing
(NLP), they often overlook the fundamental physical principles governing
molecules. In contrast, applying denoising in pre-training can be interpreted
as an equivalent force learning, but the limited noise distribution introduces
bias into the molecular distribution. To address this issue, we introduce a
molecular pre-training framework called fractional denoising (Frad), which
decouples noise design from the constraints imposed by force learning
equivalence. In this way, the noise becomes customizable, allowing for
incorporating chemical priors to significantly improve molecular distribution
modeling. Experiments demonstrate that our framework consistently outperforms
existing methods, establishing state-of-the-art results across force
prediction, quantum chemical properties, and binding affinity tasks. The
refined noise design enhances force accuracy and sampling coverage, which
contribute to the creation of physically consistent molecular representations,
ultimately leading to superior predictive performance.",2024-07-14,"Yuyan Ni, Shikun Feng, Xin Hong, Yuancheng Sun, Wei-Ying Ma, Zhi-Ming Ma, Qiwei Ye, Yanyan Lan",http://arxiv.org/pdf/2407.11086v1,cs.LG
RAPiD-Seg: Range-Aware Pointwise Distance Distribution Networks for 3D LiDAR Segmentation,"3D point clouds play a pivotal role in outdoor scene perception, especially
in the context of autonomous driving. Recent advancements in 3D LiDAR
segmentation often focus intensely on the spatial positioning and distribution
of points for accurate segmentation. However, these methods, while robust in
variable conditions, encounter challenges due to sole reliance on coordinates
and point intensity, leading to poor isometric invariance and suboptimal
segmentation. To tackle this challenge, our work introduces Range-Aware
Pointwise Distance Distribution (RAPiD) features and the associated RAPiD-Seg
architecture. Our RAPiD features exhibit rigid transformation invariance and
effectively adapt to variations in point density, with a design focus on
capturing the localized geometry of neighboring structures. They utilize
inherent LiDAR isotropic radiation and semantic categorization for enhanced
local representation and computational efficiency, while incorporating a 4D
distance metric that integrates geometric and surface material reflectivity for
improved semantic segmentation. To effectively embed high-dimensional RAPiD
features, we propose a double-nested autoencoder structure with a novel
class-aware embedding objective to encode high-dimensional features into
manageable voxel-wise embeddings. Additionally, we propose RAPiD-Seg which
incorporates a channel-wise attention fusion and two effective RAPiD-Seg
variants, further optimizing the embedding for enhanced performance and
generalization. Our method outperforms contemporary LiDAR segmentation work in
terms of mIoU on SemanticKITTI (76.1) and nuScenes (83.6) datasets.",2024-07-14,"Li Li, Hubert P. H. Shum, Toby P. Breckon",http://arxiv.org/pdf/2407.10159v3,cs.LG
SpreadFGL: Edge-Client Collaborative Federated Graph Learning with Adaptive Neighbor Generation,"Federated Graph Learning (FGL) has garnered widespread attention by enabling
collaborative training on multiple clients for semi-supervised classification
tasks. However, most existing FGL studies do not well consider the missing
inter-client topology information in real-world scenarios, causing insufficient
feature aggregation of multi-hop neighbor clients during model training.
Moreover, the classic FGL commonly adopts the FedAvg but neglects the high
training costs when the number of clients expands, resulting in the overload of
a single edge server. To address these important challenges, we propose a novel
FGL framework, named SpreadFGL, to promote the information flow in edge-client
collaboration and extract more generalized potential relationships between
clients. In SpreadFGL, an adaptive graph imputation generator incorporated with
a versatile assessor is first designed to exploit the potential links between
subgraphs, without sharing raw data. Next, a new negative sampling mechanism is
developed to make SpreadFGL concentrate on more refined information in
downstream tasks. To facilitate load balancing at the edge layer, SpreadFGL
follows a distributed training manner that enables fast model convergence.
Using real-world testbed and benchmark graph datasets, extensive experiments
demonstrate the effectiveness of the proposed SpreadFGL. The results show that
SpreadFGL achieves higher accuracy and faster convergence against
state-of-the-art algorithms.",2024-07-14,"Luying Zhong, Yueyang Pi, Zheyi Chen, Zhengxin Yu, Wang Miao, Xing Chen, Geyong Min",http://arxiv.org/pdf/2407.11085v1,cs.LG
Optimal Kernel Choice for Score Function-based Causal Discovery,"Score-based methods have demonstrated their effectiveness in discovering
causal relationships by scoring different causal structures based on their
goodness of fit to the data. Recently, Huang et al. proposed a generalized
score function that can handle general data distributions and causal
relationships by modeling the relations in reproducing kernel Hilbert space
(RKHS). The selection of an appropriate kernel within this score function is
crucial for accurately characterizing causal relationships and ensuring precise
causal discovery. However, the current method involves manual heuristic
selection of kernel parameters, making the process tedious and less likely to
ensure optimality. In this paper, we propose a kernel selection method within
the generalized score function that automatically selects the optimal kernel
that best fits the data. Specifically, we model the generative process of the
variables involved in each step of the causal graph search procedure as a
mixture of independent noise variables. Based on this model, we derive an
automatic kernel selection method by maximizing the marginal likelihood of the
variables involved in each search step. We conduct experiments on both
synthetic data and real-world benchmarks, and the results demonstrate that our
proposed method outperforms heuristic kernel selection methods.",2024-07-14,"Wenjie Wang, Biwei Huang, Feng Liu, Xinge You, Tongliang Liu, Kun Zhang, Mingming Gong",http://arxiv.org/pdf/2407.10132v1,cs.LG
A Bag of Tricks for Scaling CPU-based Deep FFMs to more than 300m Predictions per Second,"Field-aware Factorization Machines (FFMs) have emerged as a powerful model
for click-through rate prediction, particularly excelling in capturing complex
feature interactions. In this work, we present an in-depth analysis of our
in-house, Rust-based Deep FFM implementation, and detail its deployment on a
CPU-only, multi-data-center scale. We overview key optimizations devised for
both training and inference, demonstrated by previously unpublished benchmark
results in efficient model search and online training. Further, we detail an
in-house weight quantization that resulted in more than an order of magnitude
reduction in bandwidth footprint related to weight transfers across
data-centres. We disclose the engine and associated techniques under an
open-source license to contribute to the broader machine learning community.
This paper showcases one of the first successful CPU-only deployments of Deep
FFMs at such scale, marking a significant stride in practical, low-footprint
click-through rate prediction methodologies.",2024-07-14,"Blaž Škrlj, Benjamin Ben-Shalom, Grega Gašperšič, Adi Schwartz, Ramzi Hoseisi, Naama Ziporin, Davorin Kopič, Andraž Tori",http://arxiv.org/pdf/2407.10115v1,cs.LG
A Self-Supervised Learning Pipeline for Demographically Fair Facial Attribute Classification,"Published research highlights the presence of demographic bias in automated
facial attribute classification. The proposed bias mitigation techniques are
mostly based on supervised learning, which requires a large amount of labeled
training data for generalizability and scalability. However, labeled data is
limited, requires laborious annotation, poses privacy risks, and can perpetuate
human bias. In contrast, self-supervised learning (SSL) capitalizes on freely
available unlabeled data, rendering trained models more scalable and
generalizable. However, these label-free SSL models may also introduce biases
by sampling false negative pairs, especially at low-data regimes 200K images)
under low compute settings. Further, SSL-based models may suffer from
performance degradation due to a lack of quality assurance of the unlabeled
data sourced from the web. This paper proposes a fully self-supervised pipeline
for demographically fair facial attribute classifiers. Leveraging completely
unlabeled data pseudolabeled via pre-trained encoders, diverse data curation
techniques, and meta-learning-based weighted contrastive learning, our method
significantly outperforms existing SSL approaches proposed for downstream image
classification tasks. Extensive evaluations on the FairFace and CelebA datasets
demonstrate the efficacy of our pipeline in obtaining fair performance over
existing baselines. Thus, setting a new benchmark for SSL in the fairness of
facial attribute classification.",2024-07-14,"Sreeraj Ramachandran, Ajita Rattani",http://arxiv.org/pdf/2407.10104v1,cs.LG
ReactAIvate: A Deep Learning Approach to Predicting Reaction Mechanisms and Unmasking Reactivity Hotspots,"A chemical reaction mechanism (CRM) is a sequence of molecular-level events
involving bond-breaking/forming processes, generating transient intermediates
along the reaction pathway as reactants transform into products. Understanding
such mechanisms is crucial for designing and discovering new reactions. One of
the currently available methods to probe CRMs is quantum mechanical (QM)
computations. The resource-intensive nature of QM methods and the scarcity of
mechanism-based datasets motivated us to develop reliable ML models for
predicting mechanisms. In this study, we created a comprehensive dataset with
seven distinct classes, each representing uniquely characterized elementary
steps. Subsequently, we developed an interpretable attention-based GNN that
achieved near-unity and 96% accuracy, respectively for reaction step
classification and the prediction of reactive atoms in each such step,
capturing interactions between the broader reaction context and local active
regions. The near-perfect classification enables accurate prediction of both
individual events and the entire CRM, mitigating potential drawbacks of Seq2Seq
approaches, where a wrongly predicted character leads to incoherent CRM
identification. In addition to interpretability, our model adeptly identifies
key atom(s) even from out-of-distribution classes. This generalizabilty allows
for the inclusion of new reaction types in a modular fashion, thus will be of
value to experts for understanding the reactivity of new molecules.",2024-07-14,"Ajnabiul Hoque, Manajit Das, Mayank Baranwal, Raghavan B. Sunoj",http://arxiv.org/pdf/2407.10090v1,cs.LG
Revisiting Adaptive Cellular Recognition Under Domain Shifts: A Contextual Correspondence View,"Cellular nuclei recognition serves as a fundamental and essential step in the
workflow of digital pathology. However, with disparate source organs and
staining procedures among histology image clusters, the scanned tiles
inherently conform to a non-uniform data distribution, which induces
deteriorated promises for general cross-cohort usages. Despite the latest
efforts leveraging domain adaptation to mitigate distributional discrepancy,
those methods are subjected to modeling the morphological characteristics of
each cell individually, disregarding the hierarchical latent structure and
intrinsic contextual correspondences across the tumor micro-environment. In
this work, we identify the importance of implicit correspondences across
biological contexts for exploiting domain-invariant pathological composition
and thereby propose to exploit the dependence over various biological
structures for domain adaptive cellular recognition. We discover those
high-level correspondences via unsupervised contextual modeling and use them as
bridges to facilitate adaptation over diverse organs and stains. In addition,
to further exploit the rich spatial contexts embedded amongst nuclear
communities, we propose self-adaptive dynamic distillation to secure
instance-aware trade-offs across different model constituents. The proposed
method is extensively evaluated on a broad spectrum of cross-domain settings
under miscellaneous data distribution shifts and outperforms the
state-of-the-art methods by a substantial margin. Code is available at
https://github.com/camwew/CellularRecognition_DA_CC.",2024-07-14,"Jianan Fan, Dongnan Liu, Canran Li, Hang Chang, Heng Huang, Filip Braet, Mei Chen, Weidong Cai",http://arxiv.org/pdf/2407.12870v2,cs.LG
Have ASkotch: A Neat Solution for Large-scale Kernel Ridge Regression,"Kernel ridge regression (KRR) is a fundamental computational tool, appearing
in problems that range from computational chemistry to health analytics, with a
particular interest due to its starring role in Gaussian process regression.
However, full KRR solvers are challenging to scale to large datasets: both
direct (i.e., Cholesky decomposition) and iterative methods (i.e., PCG) incur
prohibitive computational and storage costs. The standard approach to scale KRR
to large datasets chooses a set of inducing points and solves an approximate
version of the problem, inducing points KRR. However, the resulting solution
tends to have worse predictive performance than the full KRR solution. In this
work, we introduce a new solver, ASkotch, for full KRR that provides better
solutions faster than state-of-the-art solvers for full and inducing points
KRR. ASkotch is a scalable, accelerated, iterative method for full KRR that
provably obtains linear convergence. Under appropriate conditions, we show that
ASkotch obtains condition-number-free linear convergence. This convergence
analysis rests on the theory of ridge leverage scores and determinantal point
processes. ASkotch outperforms state-of-the-art KRR solvers on a testbed of 23
large-scale KRR regression and classification tasks derived from a wide range
of application domains, demonstrating the superiority of full KRR over inducing
points KRR. Our work opens up the possibility of as-yet-unimagined applications
of full KRR across a number of disciplines.",2024-07-14,"Pratik Rathore, Zachary Frangella, Jiaming Yang, Michał Dereziński, Madeleine Udell",http://arxiv.org/pdf/2407.10070v2,cs.LG
MKDTI: Predicting drug-target interactions via multiple kernel fusion on graph attention network,"Drug-target relationships may now be predicted computationally using
bioinformatics data, which is a valuable tool for understanding pharmacological
effects, enhancing drug development efficiency, and advancing related research.
A number of structure-based, ligand-based and network-based approaches have now
emerged. Furthermore, the integration of graph attention networks with
intricate drug target studies is an application area of growing interest. In
our work, we formulate a model called MKDTI by extracting kernel information
from various layer embeddings of a graph attention network. This combination
improves the prediction ability with respect to novel drug-target
relationships. We first build a drug-target heterogeneous network using
heterogeneous data of drugs and targets, and then use a self-enhanced
multi-head graph attention network to extract potential features in each layer.
Next, we utilize embeddings of each layer to computationally extract kernel
matrices and fuse multiple kernel matrices. Finally, we use a Dual Laplacian
Regularized Least Squares framework to forecast novel drug-target entity
connections. This prediction can be facilitated by integrating the kernel
matrix associated with the drug-target. We measured our model's efficacy using
AUPR and AUC. Compared to the benchmark algorithms, our model outperforms them
in the prediction outcomes. In addition, we conducted an experiment on kernel
selection. The results show that the multi-kernel fusion approach combined with
the kernel matrix generated by the graph attention network provides
complementary insights into the model. The fusion of this information helps to
enhance the accuracy of the predictions.",2024-07-14,"Yuhuan Zhou, Yulin Wu, Weiwei Yuan, Xuan Wang, Junyi Li",http://arxiv.org/pdf/2407.10055v1,cs.LG
Harnessing Feature Clustering For Enhanced Anomaly Detection With Variational Autoencoder And Dynamic Threshold,"We introduce an anomaly detection method for multivariate time series data
with the aim of identifying critical periods and features influencing extreme
climate events like snowmelt in the Arctic. This method leverages the
Variational Autoencoder (VAE) integrated with dynamic thresholding and
correlation-based feature clustering. This framework enhances the VAE's ability
to identify localized dependencies and learn the temporal relationships in
climate data, thereby improving the detection of anomalies as demonstrated by
its higher F1-score on benchmark datasets. The study's main contributions
include the development of a robust anomaly detection method, improving feature
representation within VAEs through clustering, and creating a dynamic threshold
algorithm for localized anomaly detection. This method offers explainability of
climate anomalies across different regions.",2024-07-14,"Tolulope Ale, Nicole-Jeanne Schlegel, Vandana P. Janeja",http://arxiv.org/pdf/2407.10042v1,cs.LG
LeanQuant: Accurate and Scalable Large Language Model Quantization with Loss-error-aware Grid,"Large language models (LLMs) have shown immense potential across various
domains, but their high memory requirements and inference costs remain critical
challenges for deployment. Post-training quantization (PTQ) has emerged as a
promising technique to reduce memory requirements and decoding latency.
However, recent accurate quantization methods often depend on specialized
computations or custom data formats to achieve better model quality, which
limits their compatibility with popular frameworks, as they require dedicated
inference kernels tailored to specific hardware and software platforms,
hindering wider adoption. Furthermore, many competitive methods have high
resource requirements and computational overhead, making it challenging to
scale them to hundreds of billions of parameters. In response to these
challenges, we propose LeanQuant (Loss-error-aware Network Quantization), a
novel quantization method that is accurate, versatile, and scalable. In the
existing popular iterative loss-error-based quantization framework, we identify
a critical limitation in prior methods: the min-max affine quantization grid
fails to preserve model quality due to outliers in inverse Hessian diagonals.
To overcome this fundamental issue, we propose learning loss-error-aware grids,
instead of using non-adaptive min-max affine grids. Our approach not only
produces quantized models that are more accurate but also generalizes to a
wider range of quantization types, including affine and non-uniform
quantization, enhancing compatibility with more frameworks. Extensive empirical
evaluations on recent LLMs demonstrate that LeanQuant is highly accurate,
comparing favorably against recent competitive baselines in model quality, and
scalable, achieving very accurate quantization of Llama-3.1 405B, one of the
largest open-source LLMs to date, using two Quadro RTX 8000-48GB GPUs in 21
hours.",2024-07-14,"Tianyi Zhang, Anshumali Shrivastava",http://arxiv.org/pdf/2407.10032v2,cs.LG
Sim-to-Real Domain Adaptation for Deformation Classification,"Deformation detection is vital for enabling accurate assessment and
prediction of structural changes in materials, ensuring timely and effective
interventions to maintain safety and integrity. Automating deformation
detection through computer vision is crucial for efficient monitoring, but it
faces significant challenges in creating a comprehensive dataset of both
deformed and non-deformed objects, which can be difficult to obtain in many
scenarios. In this paper, we introduce a novel framework for generating
controlled synthetic data that simulates deformed objects. This approach allows
for the realistic modeling of object deformations under various conditions. Our
framework integrates an intelligent adapter network that facilitates
sim-to-real domain adaptation, enhancing classification results without
requiring real data from deformed objects. We conduct experiments on domain
adaptation and classification tasks and demonstrate that our framework improves
sim-to-real classification results compared to simulation baseline.",2024-07-13,"Joel Sol, Jamil Fayyad, Shadi Alijani, Homayoun Najjaran",http://arxiv.org/pdf/2407.10011v2,cs.LG
"Fine-grained Analysis of In-context Linear Estimation: Data, Architecture, and Beyond","Recent research has shown that Transformers with linear attention are capable
of in-context learning (ICL) by implementing a linear estimator through
gradient descent steps. However, the existing results on the optimization
landscape apply under stylized settings where task and feature vectors are
assumed to be IID and the attention weights are fully parameterized. In this
work, we develop a stronger characterization of the optimization and
generalization landscape of ICL through contributions on architectures,
low-rank parameterization, and correlated designs: (1) We study the landscape
of 1-layer linear attention and 1-layer H3, a state-space model. Under a
suitable correlated design assumption, we prove that both implement 1-step
preconditioned gradient descent. We show that thanks to its native convolution
filters, H3 also has the advantage of implementing sample weighting and
outperforming linear attention in suitable settings. (2) By studying correlated
designs, we provide new risk bounds for retrieval augmented generation (RAG)
and task-feature alignment which reveal how ICL sample complexity benefits from
distributional alignment. (3) We derive the optimal risk for low-rank
parameterized attention weights in terms of covariance spectrum. Through this,
we also shed light on how LoRA can adapt to a new distribution by capturing the
shift between task covariances. Experimental results corroborate our
theoretical findings. Overall, this work explores the optimization and risk
landscape of ICL in practically meaningful settings and contributes to a more
thorough understanding of its mechanics.",2024-07-13,"Yingcong Li, Ankit Singh Rawat, Samet Oymak",http://arxiv.org/pdf/2407.10005v1,cs.LG
A Dynamic Algorithm for Weighted Submodular Cover Problem,"We initiate the study of the submodular cover problem in dynamic setting
where the elements of the ground set are inserted and deleted.
  In the classical submodular cover problem, we are given a monotone submodular
function $f : 2^{V} \to \mathbb{R}^{\ge 0}$ and the goal is to obtain a set $S
\subseteq V$ that minimizes the cost subject to the constraint $f(S) = f(V)$.
This is a classical problem in computer science and generalizes the Set Cover
problem, 2-Set Cover, and dominating set problem among others.
  We consider this problem in a dynamic setting where there are updates to our
set $V$, in the form of insertions and deletions of elements from a ground set
$\mathcal{V}$, and the goal is to maintain an approximately optimal solution
with low query complexity per update. For this problem, we propose a randomized
algorithm that, in expectation, obtains a $(1-O(\epsilon),
O(\epsilon^{-1}))$-bicriteria approximation using polylogarithmic query
complexity per update.",2024-07-13,"Kiarash Banihashem, Samira Goudarzi, MohammadTaghi Hajiaghayi, Peyman Jabbarzade, Morteza Monemizadeh",http://arxiv.org/pdf/2407.10003v1,cs.LG
On Characterizing and Mitigating Imbalances in Multi-Instance Partial Label Learning,"*Multi-Instance Partial Label Learning* (MI-PLL) is a weakly-supervised
learning setting encompassing *partial label learning*, *latent structural
learning*, and *neurosymbolic learning*. Unlike supervised learning, in MI-PLL,
the inputs to the classifiers at training-time are tuples of instances
$\mathbf{x}$. At the same time, the supervision signal is generated by a
function $\sigma$ over the (hidden) gold labels of $\mathbf{x}$. In this work,
we make multiple contributions towards addressing a problem that hasn't been
studied so far in the context of MI-PLL: that of characterizing and mitigating
*learning imbalances*, i.e., major differences in the errors occurring when
classifying instances of different classes (aka *class-specific risks*). In
terms of theory, we derive class-specific risk bounds for MI-PLL, while making
minimal assumptions. Our theory reveals a unique phenomenon: that $\sigma$ can
greatly impact learning imbalances. This result is in sharp contrast with
previous research on supervised and weakly-supervised learning, which only
studies learning imbalances under the prism of data imbalances. On the
practical side, we introduce a technique for estimating the marginal of the
hidden labels using only MI-PLL data. Then, we introduce algorithms that
mitigate imbalances at training- and testing-time, by treating the marginal of
the hidden labels as a constraint. We demonstrate the effectiveness of our
techniques using strong baselines from neurosymbolic and long-tail learning,
suggesting performance improvements of up to 14\%.",2024-07-13,"Kaifu Wang, Efthymia Tsamoura, Dan Roth",http://arxiv.org/pdf/2407.10000v3,cs.LG
Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine,"High-performance computing (HPC) has revolutionized our ability to perform
detailed simulations of complex real-world processes. A prominent contemporary
example is from aerospace propulsion, where HPC is used for rotating detonation
rocket engine (RDRE) simulations in support of the design of next-generation
rocket engines; however, these simulations take millions of core hours even on
powerful supercomputers, which makes them impractical for engineering tasks
like design exploration and risk assessment. Data-driven reduced-order models
(ROMs) aim to address this limitation by constructing computationally cheap yet
sufficiently accurate approximations that serve as surrogates for the
high-fidelity model. This paper contributes a distributed memory algorithm that
achieves fast and scalable construction of predictive physics-based ROMs
trained from sparse datasets of extremely large state dimension. The algorithm
learns structured physics-based ROMs that approximate the dynamical systems
underlying those datasets.This enables model reduction for problems at a scale
and complexity that exceeds the capabilities of standard, serial approaches. We
demonstrate our algorithm's scalability using up to $2,048$ cores on the
Frontera supercomputer at the Texas Advanced Computing Center. We focus on a
real-world three-dimensional RDRE for which one millisecond of simulated
physical time requires one million core hours on a supercomputer. Using a
training dataset of $2,536$ snapshots each of state dimension $76$ million, our
distributed algorithm enables the construction of a predictive data-driven
reduced model in just $13$ seconds on $2,048$ cores on Frontera.",2024-07-13,"Ionut-Gabriel Farcas, Rayomand P. Gundevia, Ramakanth Munipalli, Karen E. Willcox",http://arxiv.org/pdf/2407.09994v2,cs.LG
Curriculum Is More Influential Than Haptic Information During Reinforcement Learning of Object Manipulation Against Gravity,"Learning to lift and rotate objects with the fingertips is necessary for
autonomous in-hand dexterous manipulation. In our study, we explore the impact
of various factors on successful learning strategies for this task.
Specifically, we investigate the role of curriculum learning and haptic
feedback in enabling the learning of dexterous manipulation. Using model-free
Reinforcement Learning, we compare different curricula and two haptic
information modalities (No-tactile vs. 3D-force sensing) for lifting and
rotating a ball against gravity with a three-fingered simulated robotic hand
with no visual input. Note that our best results were obtained when we used a
novel curriculum-based learning rate scheduler, which adjusts the
linearly-decaying learning rate when the reward is changed as it accelerates
convergence to higher rewards. Our findings demonstrate that the choice of
curriculum greatly biases the acquisition of different features of dexterous
manipulation. Surprisingly, successful learning can be achieved even in the
absence of tactile feedback, challenging conventional assumptions about the
necessity of haptic information for dexterous manipulation tasks. We
demonstrate the generalizability of our results to balls of different weights
and sizes, underscoring the robustness of our learning approach. This work,
therefore, emphasizes the importance of the choice curriculum and challenges
long-held notions about the need for tactile information to autonomously learn
in-hand dexterous manipulation.",2024-07-13,"Pegah Ojaghi, Romina Mir, Ali Marjaninejad, Andrew Erwin, Michael Wehner, Francisco J Valero-Cueva",http://arxiv.org/pdf/2407.09986v1,cs.LG
A Training Data Recipe to Accelerate A* Search with Language Models,"Combining Large Language Models (LLMs) with heuristic search algorithms like
A* holds the promise of enhanced LLM reasoning and scalable inference. To
accelerate training and reduce computational demands, we investigate the
coreset selection problem for the training data of LLM heuristic learning. Few
methods to learn the heuristic functions consider the interaction between the
search algorithm and the machine learning model. In this work, we empirically
disentangle the requirements of A* search algorithm from the requirements of
the LLM to generalise on this task. Surprisingly, we find an overlap between
their requirements; A* requires more accurate predictions on search nodes near
the goal, and LLMs need the same set of nodes for effective generalisation.
With these insights, we derive a data-selection distribution for learning
LLM-based heuristics. On three classical planning domains, maze navigation,
Sokoban and sliding tile puzzles, our technique reduces the number of
iterations required to find the solutions by up to 15x, with a wall-clock
speed-up of search up to 5x. The codebase is at
https://github.com/devaansh100/a_star.",2024-07-13,"Devaansh Gupta, Boyang Li",http://arxiv.org/pdf/2407.09985v2,cs.LG
Harvesting Private Medical Images in Federated Learning Systems with Crafted Models,"Federated learning (FL) allows a set of clients to collaboratively train a
machine-learning model without exposing local training samples. In this
context, it is considered to be privacy-preserving and hence has been adopted
by medical centers to train machine-learning models over private data. However,
in this paper, we propose a novel attack named MediLeak that enables a
malicious parameter server to recover high-fidelity patient images from the
model updates uploaded by the clients. MediLeak requires the server to generate
an adversarial model by adding a crafted module in front of the original model
architecture. It is published to the clients in the regular FL training process
and each client conducts local training on it to generate corresponding model
updates. Then, based on the FL protocol, the model updates are sent back to the
server and our proposed analytical method recovers private data from the
parameter updates of the crafted module. We provide a comprehensive analysis
for MediLeak and show that it can successfully break the state-of-the-art
cryptographic secure aggregation protocols, designed to protect the FL systems
from privacy inference attacks. We implement MediLeak on the MedMNIST and
COVIDx CXR-4 datasets. The results show that MediLeak can nearly perfectly
recover private images with high recovery rates and quantitative scores. We
further perform downstream tasks such as disease classification with the
recovered data, where our results show no significant performance degradation
compared to using the original training samples.",2024-07-13,"Shanghao Shi, Md Shahedul Haque, Abhijeet Parida, Marius George Linguraru, Y. Thomas Hou, Syed Muhammad Anwar, Wenjing Lou",http://arxiv.org/pdf/2407.09972v1,cs.LG
Partner in Crime: Boosting Targeted Poisoning Attacks against Federated Learning,"Federated Learning (FL) exposes vulnerabilities to targeted poisoning attacks
that aim to cause misclassification specifically from the source class to the
target class. However, using well-established defense frameworks, the poisoning
impact of these attacks can be greatly mitigated. We introduce a generalized
pre-training stage approach to Boost Targeted Poisoning Attacks against FL,
called BoTPA. Its design rationale is to leverage the model update
contributions of all data points, including ones outside of the source and
target classes, to construct an Amplifier set, in which we falsify the data
labels before the FL training process, as a means to boost attacks. We
comprehensively evaluate the effectiveness and compatibility of BoTPA on
various targeted poisoning attacks. Under data poisoning attacks, our
evaluations reveal that BoTPA can achieve a median Relative Increase in Attack
Success Rate (RI-ASR) between 15.3% and 36.9% across all possible source-target
class combinations, with varying percentages of malicious clients, compared to
its baseline. In the context of model poisoning, BoTPA attains RI-ASRs ranging
from 13.3% to 94.7% in the presence of the Krum and Multi-Krum defenses, from
2.6% to 49.2% under the Median defense, and from 2.9% to 63.5% under the Flame
defense.",2024-07-13,"Shihua Sun, Shridatt Sugrim, Angelos Stavrou, Haining Wang",http://arxiv.org/pdf/2407.09958v2,cs.LG
LFFR: Logistic Function For (single-output) Regression,"Privacy-preserving regression in machine learning is a crucial area of
research, aimed at enabling the use of powerful machine learning techniques
while protecting individuals' privacy. In this paper, we implement
privacy-preserving regression training using data encrypted under a fully
homomorphic encryption scheme. We first examine the common linear regression
algorithm and propose a (simplified) fixed Hessian for linear regression
training, which can be applied for any datasets even not normalized into the
range $[0, 1]$. We also generalize this constant Hessian matrix to the ridge
regression version, namely linear regression which includes a regularization
term to penalize large coefficients. However, our main contribution is to
develop a novel and efficient algorithm called LFFR for homomorphic regression
using the logistic function, which could model more complex relations between
input values and output prediction in comparison with linear regression. We
also find a constant simplified Hessian to train our LFFR algorithm using the
Newton-like method and compare it against to with our new fixed Hessian linear
regression training over two real-world datasets. We suggest normalizing not
only the data but also the target predictions even for the original linear
regression used in a privacy-preserving manner, which is helpful to remain
weights in a small range, say $[-5, +5]$ good for refreshing ciphertext setting
parameters, and avoid tuning the regularization parameter $\lambda$ via cross
validation. The linear regression with normalized predictions could be a viable
alternative to ridge regression.",2024-07-13,John Chiang,http://arxiv.org/pdf/2407.09955v2,cs.LG
PSO Fuzzy XGBoost Classifier Boosted with Neural Gas Features on EEG Signals in Emotion Recognition,"Emotion recognition is the technology-driven process of identifying and
categorizing human emotions from various data sources, such as facial
expressions, voice patterns, body motion, and physiological signals, such as
EEG. These physiological indicators, though rich in data, present challenges
due to their complexity and variability, necessitating sophisticated feature
selection and extraction methods. NGN, an unsupervised learning algorithm,
effectively adapts to input spaces without predefined grid structures,
improving feature extraction from physiological data. Furthermore, the
incorporation of fuzzy logic enables the handling of fuzzy data by introducing
reasoning that mimics human decision-making. The combination of PSO with
XGBoost aids in optimizing model performance through efficient hyperparameter
tuning and decision process optimization. This study explores the integration
of Neural-Gas Network (NGN), XGBoost, Particle Swarm Optimization (PSO), and
fuzzy logic to enhance emotion recognition using physiological signals. Our
research addresses three critical questions concerning the improvement of
XGBoost with PSO and fuzzy logic, NGN's effectiveness in feature selection, and
the performance comparison of the PSO-fuzzy XGBoost classifier with standard
benchmarks. Acquired results indicate that our methodologies enhance the
accuracy of emotion recognition systems and outperform other feature selection
techniques using the majority of classifiers, offering significant implications
for both theoretical advancement and practical application in emotion
recognition technology.",2024-07-13,Seyed Muhammad Hossein Mousavi,http://arxiv.org/pdf/2407.09950v2,cs.LG
Hydra: Bidirectional State Space Models Through Generalized Matrix Mixers,"A wide array of sequence models are built on a framework modeled after
Transformers, comprising alternating sequence mixer and channel mixer layers.
This paper studies a unifying matrix mixer view of sequence mixers that can be
conceptualized as a linear map on the input sequence. This framework
encompasses a broad range of well-known sequence models, including the
self-attention of Transformers as well as recent strong alternatives such as
structured state space models (SSMs), and allows understanding downstream
characteristics such as efficiency and expressivity through properties of their
structured matrix class. We identify a key axis of matrix parameterizations
termed sequence alignment, which increases the flexibility and performance of
matrix mixers, providing insights into the strong performance of Transformers
and recent SSMs such as Mamba. Furthermore, the matrix mixer framework offers a
systematic approach to developing sequence mixers with desired properties,
allowing us to develop several new sub-quadratic sequence models. In
particular, we propose a natural bidirectional extension of the Mamba model
(Hydra), parameterized as a quasiseparable matrix mixer, which demonstrates
superior performance over other sequence models including Transformers on
non-causal tasks. As a drop-in replacement for attention layers, Hydra
outperforms BERT by 0.8 points on the GLUE benchmark and ViT by 2% Top-1
accuracy on ImageNet.",2024-07-13,"Sukjun Hwang, Aakash Lahoti, Tri Dao, Albert Gu",http://arxiv.org/pdf/2407.09941v1,cs.LG
Evaluating the Impact of Different Quantum Kernels on the Classification Performance of Support Vector Machine Algorithm: A Medical Dataset Application,"The support vector machine algorithm with a quantum kernel estimator
(QSVM-Kernel), as a leading example of a quantum machine learning technique,
has undergone significant advancements. Nevertheless, its integration with
classical data presents unique challenges. While quantum computers primarily
interact with data in quantum states, embedding classical data into quantum
states using feature mapping techniques is essential for leveraging quantum
algorithms Despite the recognized importance of feature mapping, its specific
impact on data classification outcomes remains largely unexplored. This study
addresses this gap by comprehensively assessing the effects of various feature
mapping methods on classification results, taking medical data analysis as a
case study. In this study, the QSVM-Kernel method was applied to classification
problems in two different and publicly available medical datasets, namely, the
Wisconsin Breast Cancer (original) and The Cancer Genome Atlas (TCGA) Glioma
datasets. In the QSVM-Kernel algorithm, quantum kernel matrices obtained from 9
different quantum feature maps were used. Thus, the effects of these quantum
feature maps on the classification results of the QSVM-Kernel algorithm were
examined in terms of both classifier performance and total execution time. As a
result, in the Wisconsin Breast Cancer (original) and TCGA Glioma datasets,
when Rx and Ry rotational gates were used, respectively, as feature maps in the
QSVM-Kernel algorithm, the best classification performances were achieved both
in terms of classification performance and total execution time. The
contributions of this study are that (1) it highlights the significant impact
of feature mapping techniques on medical data classification outcomes using the
QSVM-Kernel algorithm, and (2) it also guides undertaking research for improved
QSVM classification performance.",2024-07-13,"Emine Akpinar, Sardar M. N. Islam, Murat Oduncuoglu",http://arxiv.org/pdf/2407.09930v2,cs.LG
Metric Learning for Clifford Group Equivariant Neural Networks,"Clifford Group Equivariant Neural Networks (CGENNs) leverage Clifford
algebras and multivectors as an alternative approach to incorporating group
equivariance to ensure symmetry constraints in neural representations. In
principle, this formulation generalizes to orthogonal groups and preserves
equivariance regardless of the metric signature. However, previous works have
restricted internal network representations to Euclidean or Minkowski
(pseudo-)metrics, handpicked depending on the problem at hand. In this work, we
propose an alternative method that enables the metric to be learned in a
data-driven fashion, allowing the CGENN network to learn more flexible
representations. Specifically, we populate metric matrices fully, ensuring they
are symmetric by construction, and leverage eigenvalue decomposition to
integrate this additional learnable component into the original CGENN
formulation in a principled manner. Additionally, we motivate our method using
insights from category theory, which enables us to explain Clifford algebras as
a categorical construction and guarantee the mathematical soundness of our
approach. We validate our method in various tasks and showcase the advantages
of learning more flexible latent metric representations. The code and data are
available at https://github.com/rick-ali/Metric-Learning-for-CGENNs",2024-07-13,"Riccardo Ali, Paulina Kulytė, Haitz Sáez de Ocáriz Borde, Pietro Liò",http://arxiv.org/pdf/2407.09926v1,cs.LG
SensEmo: Enabling Affective Learning through Real-time Emotion Recognition with Smartwatches,"Recent research has demonstrated the capability of physiological signals to
infer both user emotional and attention responses. This presents an opportunity
for leveraging widely available physiological sensors in smartwatches, to
detect real-time emotional cues in users, such as stress and excitement. In
this paper, we introduce SensEmo, a smartwatch-based system designed for
affective learning. SensEmo utilizes multiple physiological sensor data,
including heart rate and galvanic skin response, to recognize a student's
motivation and concentration levels during class. This recognition is
facilitated by a personalized emotion recognition model that predicts emotional
states based on degrees of valence and arousal. With real-time emotion and
attention feedback from students, we design a Markov decision process-based
algorithm to enhance student learning effectiveness and experience by by
offering suggestions to the teacher regarding teaching content and pacing. We
evaluate SensEmo with 22 participants in real-world classroom environments.
Evaluation results show that SensEmo recognizes student emotion with an average
of 88.9% accuracy. More importantly, SensEmo assists students to achieve better
online learning outcomes, e.g., an average of 40.0% higher grades in quizzes,
over the traditional learning without student emotional feedback.",2024-07-13,"Kushan Choksi, Hongkai Chen, Karan Joshi, Sukrutha Jade, Shahriar Nirjon, Shan Lin",http://arxiv.org/pdf/2407.09911v1,cs.LG
Global Reinforcement Learning: Beyond Linear and Convex Rewards via Submodular Semi-gradient Methods,"In classic Reinforcement Learning (RL), the agent maximizes an additive
objective of the visited states, e.g., a value function. Unfortunately,
objectives of this type cannot model many real-world applications such as
experiment design, exploration, imitation learning, and risk-averse RL to name
a few. This is due to the fact that additive objectives disregard interactions
between states that are crucial for certain tasks. To tackle this problem, we
introduce Global RL (GRL), where rewards are globally defined over trajectories
instead of locally over states. Global rewards can capture negative
interactions among states, e.g., in exploration, via submodularity, positive
interactions, e.g., synergetic effects, via supermodularity, while mixed
interactions via combinations of them. By exploiting ideas from submodular
optimization, we propose a novel algorithmic scheme that converts any GRL
problem to a sequence of classic RL problems and solves it efficiently with
curvature-dependent approximation guarantees. We also provide hardness of
approximation results and empirically demonstrate the effectiveness of our
method on several GRL instances.",2024-07-13,"Riccardo De Santi, Manish Prajapat, Andreas Krause",http://arxiv.org/pdf/2407.09905v1,cs.LG
Learning a Mini-batch Graph Transformer via Two-stage Interaction Augmentation,"Mini-batch Graph Transformer (MGT), as an emerging graph learning model, has
demonstrated significant advantages in semi-supervised node prediction tasks
with improved computational efficiency and enhanced model robustness. However,
existing methods for processing local information either rely on sampling or
simple aggregation, which respectively result in the loss and squashing of
critical neighbor information.Moreover, the limited number of nodes in each
mini-batch restricts the model's capacity to capture the global characteristic
of the graph. In this paper, we propose LGMformer, a novel MGT model that
employs a two-stage augmented interaction strategy, transitioning from local to
global perspectives, to address the aforementioned bottlenecks.The local
interaction augmentation (LIA) presents a neighbor-target interaction
Transformer (NTIformer) to acquire an insightful understanding of the
co-interaction patterns between neighbors and the target node, resulting in a
locally effective token list that serves as input for the MGT. In contrast,
global interaction augmentation (GIA) adopts a cross-attention mechanism to
incorporate entire graph prototypes into the target node epresentation, thereby
compensating for the global graph information to ensure a more comprehensive
perception. To this end, LGMformer achieves the enhancement of node
representations under the MGT paradigm.Experimental results related to node
classification on the ten benchmark datasets demonstrate the effectiveness of
the proposed method. Our code is available at
https://github.com/l-wd/LGMformer.",2024-07-13,"Wenda Li, Kaixuan Chen, Shunyu Liu, Tongya Zheng, Wenjie Huang, Mingli Song",http://arxiv.org/pdf/2407.09904v1,cs.LG
Empowering Graph Invariance Learning with Deep Spurious Infomax,"Recently, there has been a surge of interest in developing graph neural
networks that utilize the invariance principle on graphs to generalize the
out-of-distribution (OOD) data. Due to the limited knowledge about OOD data,
existing approaches often pose assumptions about the correlation strengths of
the underlying spurious features and the target labels. However, this prior is
often unavailable and will change arbitrarily in the real-world scenarios,
which may lead to severe failures of the existing graph invariance learning
methods. To bridge this gap, we introduce a novel graph invariance learning
paradigm, which induces a robust and general inductive bias. The paradigm is
built upon the observation that the infomax principle encourages learning
spurious features regardless of spurious correlation strengths. We further
propose the EQuAD framework that realizes this learning paradigm and employs
tailored learning objectives that provably elicit invariant features by
disentangling them from the spurious features learned through infomax. Notably,
EQuAD shows stable and enhanced performance across different degrees of bias in
synthetic datasets and challenging real-world datasets up to $31.76\%$. Our
code is available at \url{https://github.com/tianyao-aka/EQuAD}.",2024-07-13,"Tianjun Yao, Yongqiang Chen, Zhenhao Chen, Kai Hu, Zhiqiang Shen, Kun Zhang",http://arxiv.org/pdf/2407.11083v1,cs.LG
Imbalanced Graph-Level Anomaly Detection via Counterfactual Augmentation and Feature Learning,"Graph-level anomaly detection (GLAD) has already gained significant
importance and has become a popular field of study, attracting considerable
attention across numerous downstream works. The core focus of this domain is to
capture and highlight the anomalous information within given graph datasets. In
most existing studies, anomalies are often the instances of few. The stark
imbalance misleads current GLAD methods to focus on learning the patterns of
normal graphs more, further impacting anomaly detection performance. Moreover,
existing methods predominantly utilize the inherent features of nodes to
identify anomalous graph patterns which is approved suboptimal according to our
experiments. In this work, we propose an imbalanced GLAD method via
counterfactual augmentation and feature learning. Specifically, we first
construct anomalous samples based on counterfactual learning, aiming to expand
and balance the datasets. Additionally, we construct a module based on Graph
Neural Networks (GNNs), which allows us to utilize degree attributes to
complement the inherent attribute features of nodes. Then, we design an
adaptive weight learning module to integrate features tailored to different
datasets effectively to avoid indiscriminately treating all features as
equivalent. Furthermore, extensive baseline experiments conducted on public
datasets substantiate the robustness and effectiveness. Besides, we apply the
model to brain disease datasets, which can prove the generalization capability
of our work. The source code of our work is available online.",2024-07-13,"Zitong Wang, Xuexiong Luo, Enfeng Song, Qiuqing Bai, Fu Lin",http://arxiv.org/pdf/2407.11082v1,cs.LG
OptiBench Meets ReSocratic: Measure and Improve LLMs for Optimization Modeling,"Large language models (LLMs) have exhibited their problem-solving abilities
in mathematical reasoning. Solving realistic optimization (OPT) problems in
application scenarios requires advanced and applied mathematics ability.
However, current OPT benchmarks that merely solve linear programming are far
from complex realistic situations. In this work, we propose OptiBench, a
benchmark for End-to-end optimization problem-solving with human-readable
inputs and outputs. OptiBench contains rich optimization problems, including
linear and nonlinear programming with or without tabular data, which can
comprehensively evaluate LLMs' solving ability. In our benchmark, LLMs are
required to call a code solver to provide precise numerical answers.
Furthermore, to alleviate the data scarcity for optimization problems, and to
bridge the gap between open-source LLMs on a small scale (e.g., Llama-3-8b) and
closed-source LLMs (e.g., GPT-4), we further propose a data synthesis method
namely ReSocratic. Unlike general data synthesis methods that proceed from
questions to answers, \ReSocratic first incrementally synthesizes formatted
optimization demonstration with mathematical formulations step by step and then
back-translates the generated demonstrations into questions. Based on this, we
synthesize the ReSocratic-29k dataset. We further conduct supervised
fine-tuning with ReSocratic-29k on multiple open-source models. Experimental
results show that ReSocratic-29k significantly improves the performance of
open-source models.",2024-07-13,"Zhicheng Yang, Yiwei Wang, Yinya Huang, Zhijiang Guo, Wei Shi, Xiongwei Han, Liang Feng, Linqi Song, Xiaodan Liang, Jing Tang",http://arxiv.org/pdf/2407.09887v3,cs.LG
Model-free Distortion Canceling and Control of Quantum Devices,"Quantum devices need precise control to achieve their full capability. In
this work, we address the problem of controlling closed quantum systems,
tackling two main issues. First, in practice the control signals are usually
subject to unknown classical distortions that could arise from the device
fabrication, material properties and/or instruments generating those signals.
Second, in most cases modeling the system is very difficult or not even viable
due to uncertainties in the relations between some variables and
inaccessibility to some measurements inside the system. In this paper, we
introduce a general model-free control approach based on deep reinforcement
learning (DRL), that can work for any closed quantum system. We train a deep
neural network (NN), using the REINFORCE policy gradient algorithm to control
the state probability distribution of a closed quantum system as it evolves,
and drive it to different target distributions. We present a novel controller
architecture that comprises multiple NNs. This enables accommodating as many
different target state distributions as desired, without increasing the
complexity of the NN or its training process. The used DRL algorithm works
whether the control problem can be modeled as a Markov decision process (MDP)
or a partially observed MDP. Our method is valid whether the control signals
are discrete- or continuous-valued. We verified our method through numerical
simulations based on a photonic waveguide array chip. We trained a controller
to generate sequences of different target output distributions of the chip with
fidelity higher than 99%, where the controller showed superior performance in
canceling the classical signal distortions.",2024-07-13,"Ahmed F. Fouad, Akram Youssry, Ahmed El-Rafei, Sherif Hammad",http://arxiv.org/pdf/2407.09877v1,cs.LG
Generating In-store Customer Journeys from Scratch with GPT Architectures,"We propose a method that can generate customer trajectories and purchasing
behaviors in retail stores simultaneously using Transformer-based deep learning
structure. Utilizing customer trajectory data, layout diagrams, and retail
scanner data obtained from a retail store, we trained a GPT-2 architecture from
scratch to generate indoor trajectories and purchase actions. Additionally, we
explored the effectiveness of fine-tuning the pre-trained model with data from
another store. Results demonstrate that our method reproduces in-store
trajectories and purchase behaviors more accurately than LSTM and SVM models,
with fine-tuning significantly reducing the required training data.",2024-07-13,"Taizo Horikomi, Takayuki Mizuno",http://arxiv.org/pdf/2407.11081v1,cs.LG
Free-form Grid Structure Form Finding based on Machine Learning and Multi-objective Optimisation,"Free-form structural forms are widely used to design spatial structures for
their irregular spatial morphology. Current free-form form-finding methods
cannot adequately meet the material properties, structural requirements or
construction conditions, which brings the deviation between the initial 3D
geometric design model and the constructed free-form structure. Thus, the main
focus of this paper is to improve the rationality of free-form morphology
considering multiple objectives in line with the characteristics and
constraints of material. In this paper, glued laminated timber is selected as a
case. Firstly, machine learning is adopted based on the predictive capability.
By selecting a free-form timber grid structure and following the principles of
NURBS, the free-form structure is simplified into free-form curves. The
transformer is selected to train and predict the curvatures of the curves
considering the material characteristics. After predicting the curvatures, the
curves are transformed into vectors consisting of control points, weights, and
knot vectors. To ensure the constructability and robustness of the structure,
minimising the mass of the structure, stress and strain energy are the
optimisation objectives. Two parameters (weight and the z-coordinate of the
control points) of the free-from morphology are extracted as the variables of
the free-form morphology to conduct the optimisation. The evaluation algorithm
was selected as the optimal tool due to its capability to optimise multiple
parameters. While optimising the two variables, the mechanical performance
evaluation indexes such as the maximum displacement in the z-direction are
demonstrated in the 60th step. The optimisation results for structure mass,
stress and strain energy after 60 steps show the tendency of oscillation
convergence, which indicates the efficiency of the proposal multi-objective
optimisation.",2024-07-13,"Yiping Meng, Yiming Sun",http://arxiv.org/pdf/2407.09852v1,cs.LG
Text-Based Detection of On-Hold Scripts in Contact Center Calls,"Average hold time is a concern for call centers because it affects customer
satisfaction. Contact centers should instruct their agents to use special
on-hold scripts to maintain positive interactions with clients. This study
presents a natural language processing model that detects on-hold phrases in
customer service calls transcribed by automatic speech recognition technology.
The task of finding hold scripts in dialogue was formulated as a multiclass
text classification problem with three mutually exclusive classes: scripts for
putting a client on hold, scripts for returning to a client, and phrases
irrelevant to on-hold scripts. We collected an in-house dataset of calls and
labeled each dialogue turn in each call. We fine-tuned RuBERT on the dataset by
exploring various hyperparameter sets and achieved high model performance. The
developed model can help agent monitoring by providing a way to check whether
an agent follows predefined on-hold scripts.",2024-07-13,"Dmitrii Galimzianov, Viacheslav Vyshegorodtsev",http://arxiv.org/pdf/2407.09849v1,cs.LG
Towards Understanding Epoch-wise Double descent in Two-layer Linear Neural Networks,"Epoch-wise double descent is the phenomenon where generalisation performance
improves beyond the point of overfitting, resulting in a generalisation curve
exhibiting two descents under the course of learning. Understanding the
mechanisms driving this behaviour is crucial not only for understanding the
generalisation behaviour of machine learning models in general, but also for
employing conventional selection methods, such as the use of early stopping to
mitigate overfitting. While we ultimately want to draw conclusions of more
complex models, such as deep neural networks, a majority of theoretical results
regarding the underlying cause of epoch-wise double descent are based on simple
models, such as standard linear regression. In this paper, to take a step
towards more complex models in theoretical analysis, we study epoch-wise double
descent in two-layer linear neural networks. First, we derive a gradient flow
for the linear two-layer model, that bridges the learning dynamics of the
standard linear regression model, and the linear two-layer diagonal network
with quadratic weights. Second, we identify additional factors of epoch-wise
double descent emerging with the extra model layer, by deriving necessary
conditions for the generalisation error to follow a double descent pattern.
While epoch-wise double descent in linear regression has been attributed to
differences in input variance, in the two-layer model, also the singular values
of the input-output covariance matrix play an important role. This opens up for
further questions regarding unidentified factors of epoch-wise double descent
for truly deep models.",2024-07-13,"Amanda Olmin, Fredrik Lindsten",http://arxiv.org/pdf/2407.09845v3,cs.LG
Overcoming Catastrophic Forgetting in Federated Class-Incremental Learning via Federated Global Twin Generator,"Federated Class-Incremental Learning (FCIL) increasingly becomes important in
the decentralized setting, where it enables multiple participants to
collaboratively train a global model to perform well on a sequence of tasks
without sharing their private data. In FCIL, conventional Federated Learning
algorithms such as FedAVG often suffer from catastrophic forgetting, resulting
in significant performance declines on earlier tasks. Recent works, based on
generative models, produce synthetic images to help mitigate this issue across
all classes, but these approaches' testing accuracy on previous classes is
still much lower than recent classes, i.e., having better plasticity than
stability. To overcome these issues, this paper presents Federated Global Twin
Generator (FedGTG), an FCIL framework that exploits privacy-preserving
generative-model training on the global side without accessing client data.
Specifically, the server trains a data generator and a feature generator to
create two types of information from all seen classes, and then it sends the
synthetic data to the client side. The clients then use
feature-direction-controlling losses to make the local models retain knowledge
and learn new tasks well. We extensively analyze the robustness of FedGTG on
natural images, as well as its ability to converge to flat local minima and
achieve better-predicting confidence (calibration). Experimental results on
CIFAR-10, CIFAR-100, and tiny-ImageNet demonstrate the improvements in accuracy
and forgetting measures of FedGTG compared to previous frameworks.",2024-07-13,"Thinh Nguyen, Khoa D Doan, Binh T. Nguyen, Danh Le-Phuoc, Kok-Seng Wong",http://arxiv.org/pdf/2407.11078v1,cs.LG
IoT-LM: Large Multisensory Language Models for the Internet of Things,"The Internet of Things (IoT) network integrating billions of smart physical
devices embedded with sensors, software, and communication technologies is a
critical and rapidly expanding component of our modern world. The IoT ecosystem
provides a rich source of real-world modalities such as motion, thermal,
geolocation, imaging, depth, sensors, and audio to recognize the states of
humans and physical objects. Machine learning presents a rich opportunity to
automatically process IoT data at scale, enabling efficient inference for
understanding human wellbeing, controlling physical devices, and
interconnecting smart cities. To realize this potential, we introduce IoT-LM,
an open-source large multisensory language model tailored for the IoT
ecosystem. IoT-LM is enabled by two technical contributions: the first is
MultiIoT, the most expansive unified IoT dataset to date, encompassing over
1.15 million samples from 12 modalities and 8 tasks prepared for multisensory
pre-training and instruction-tuning. The second is a new multisensory multitask
adapter layer to condition pre-trained large language models on multisensory
IoT data. Not only does IoT-LM yield substantial improvements on 8 supervised
IoT classification tasks, but it also demonstrates new interactive
question-answering, reasoning, and dialog capabilities conditioned on IoT
sensors. We release IoT-LM's data sources and new multisensory language
modeling framework.",2024-07-13,"Shentong Mo, Russ Salakhutdinov, Louis-Philippe Morency, Paul Pu Liang",http://arxiv.org/pdf/2407.09801v1,cs.LG
Deep reinforcement learning with symmetric data augmentation applied for aircraft lateral attitude tracking control,"Symmetry is an essential property in some dynamical systems that can be
exploited for state transition prediction and control policy optimization. This
paper develops two symmetry-integrated Reinforcement Learning (RL) algorithms
based on standard Deep Deterministic Policy Gradient (DDPG),which leverage
environment symmetry to augment explored transition samples of a Markov
Decision Process(MDP). The firstly developed algorithm is named as Deep
Deterministic Policy Gradient with Symmetric Data Augmentation (DDPG-SDA),
which enriches dataset of standard DDPG algorithm by symmetric data
augmentation method under symmetry assumption of a dynamical system. To further
improve sample utilization efficiency, the second developed RL algorithm
incorporates one extra critic network, which is independently trained with
augmented dataset. A two-step approximate policy iteration method is proposed
to integrate training for two critic networks and one actor network. The
resulting RL algorithm is named as Deep Deterministic Policy Gradient with
Symmetric Critic Augmentation (DDPG-SCA). Simulation results demonstrate
enhanced sample efficiency and tracking performance of developed two RL
algorithms in aircraft lateral tracking control task.",2024-07-13,"Yifei Li, Erik-jan van Kampen",http://arxiv.org/pdf/2407.11077v1,cs.LG
Beyond KV Caching: Shared Attention for Efficient LLMs,"The efficiency of large language models (LLMs) remains a critical challenge,
particularly in contexts where computational resources are limited. Traditional
attention mechanisms in these models, while powerful, require significant
computational and memory resources due to the necessity of recalculating and
storing attention weights across different layers. This paper introduces a
novel Shared Attention (SA) mechanism, designed to enhance the efficiency of
LLMs by directly sharing computed attention weights across multiple layers.
Unlike previous methods that focus on sharing intermediate Key-Value (KV)
caches, our approach utilizes the isotropic tendencies of attention
distributions observed in advanced LLMs post-pretraining to reduce both the
computational flops and the size of the KV cache required during inference. We
empirically demonstrate that implementing SA across various LLMs results in
minimal accuracy loss on standard benchmarks. Our findings suggest that SA not
only conserves computational resources but also maintains robust model
performance, thereby facilitating the deployment of more efficient LLMs in
resource-constrained environments.",2024-07-13,"Bingli Liao, Danilo Vasconcellos Vargas",http://arxiv.org/pdf/2407.12866v1,cs.LG
Team up GBDTs and DNNs: Advancing Efficient and Effective Tabular Prediction with Tree-hybrid MLPs,"Tabular datasets play a crucial role in various applications. Thus,
developing efficient, effective, and widely compatible prediction algorithms
for tabular data is important. Currently, two prominent model types, Gradient
Boosted Decision Trees (GBDTs) and Deep Neural Networks (DNNs), have
demonstrated performance advantages on distinct tabular prediction tasks.
However, selecting an effective model for a specific tabular dataset is
challenging, often demanding time-consuming hyperparameter tuning. To address
this model selection dilemma, this paper proposes a new framework that
amalgamates the advantages of both GBDTs and DNNs, resulting in a DNN algorithm
that is as efficient as GBDTs and is competitively effective regardless of
dataset preferences for GBDTs or DNNs. Our idea is rooted in an observation
that deep learning (DL) offers a larger parameter space that can represent a
well-performing GBDT model, yet the current back-propagation optimizer
struggles to efficiently discover such optimal functionality. On the other
hand, during GBDT development, hard tree pruning, entropy-driven feature gate,
and model ensemble have proved to be more adaptable to tabular data. By
combining these key components, we present a Tree-hybrid simple MLP (T-MLP). In
our framework, a tensorized, rapidly trained GBDT feature gate, a DNN
architecture pruning approach, as well as a vanilla back-propagation optimizer
collaboratively train a randomly initialized MLP model. Comprehensive
experiments show that T-MLP is competitive with extensively tuned DNNs and
GBDTs in their dominating tabular benchmarks (88 datasets) respectively, all
achieved with compact model storage and significantly reduced training
duration.",2024-07-13,"Jiahuan Yan, Jintai Chen, Qianxing Wang, Danny Z. Chen, Jian Wu",http://arxiv.org/pdf/2407.09790v1,cs.LG
Convex space learning for tabular synthetic data generation,"Generating synthetic samples from the convex space of the minority class is a
popular oversampling approach for imbalanced classification problems. Recently,
deep-learning approaches have been successfully applied to modeling the convex
space of minority samples. Beyond oversampling, learning the convex space of
neighborhoods in training data has not been used to generate entire tabular
datasets. In this paper, we introduce a deep learning architecture
(NextConvGeN) with a generator and discriminator component that can generate
synthetic samples by learning to model the convex space of tabular data. The
generator takes data neighborhoods as input and creates synthetic samples
within the convex space of that neighborhood. Thereafter, the discriminator
tries to classify these synthetic samples against a randomly sampled batch of
data from the rest of the data space. We compared our proposed model with five
state-of-the-art tabular generative models across ten publicly available
datasets from the biomedical domain. Our analysis reveals that synthetic
samples generated by NextConvGeN can better preserve classification and
clustering performance across real and synthetic data than other synthetic data
generation models. Synthetic data generation by deep learning of the convex
space produces high scores for popular utility measures. We further compared
how diverse synthetic data generation strategies perform in the privacy-utility
spectrum and produced critical arguments on the necessity of high utility
models. Our research on deep learning of the convex space of tabular data opens
up opportunities in clinical research, machine learning model development,
decision support systems, and clinical data sharing.",2024-07-13,"Manjunath Mahendra, Chaithra Umesh, Saptarshi Bej, Kristian Schultz, Olaf Wolkenhauer",http://arxiv.org/pdf/2407.09789v2,cs.LG
Explanation is All You Need in Distillation: Mitigating Bias and Shortcut Learning,"Bias and spurious correlations in data can cause shortcut learning,
undermining out-of-distribution (OOD) generalization in deep neural networks.
Most methods require unbiased data during training (and/or hyper-parameter
tuning) to counteract shortcut learning. Here, we propose the use of
explanation distillation to hinder shortcut learning. The technique does not
assume any access to unbiased data, and it allows an arbitrarily sized student
network to learn the reasons behind the decisions of an unbiased teacher, such
as a vision-language model or a network processing debiased images. We found
that it is possible to train a neural network with explanation (e.g by Layer
Relevance Propagation, LRP) distillation only, and that the technique leads to
high resistance to shortcut learning, surpassing group-invariant learning,
explanation background minimization, and alternative distillation techniques.
In the COLOURED MNIST dataset, LRP distillation achieved 98.2% OOD accuracy,
while deep feature distillation and IRM achieved 92.1% and 60.2%, respectively.
In COCO-on-Places, the undesirable generalization gap between in-distribution
and OOD accuracy is only of 4.4% for LRP distillation, while the other two
techniques present gaps of 15.1% and 52.1%, respectively.",2024-07-13,"Pedro R. A. S. Bassi, Andrea Cavalli, Sergio Decherchi",http://arxiv.org/pdf/2407.09788v1,cs.LG
Graph Transformers: A Survey,"Graph transformers are a recent advancement in machine learning, offering a
new class of neural network models for graph-structured data. The synergy
between transformers and graph learning demonstrates strong performance and
versatility across various graph-related tasks. This survey provides an
in-depth review of recent progress and challenges in graph transformer
research. We begin with foundational concepts of graphs and transformers. We
then explore design perspectives of graph transformers, focusing on how they
integrate graph inductive biases and graph attention mechanisms into the
transformer architecture. Furthermore, we propose a taxonomy classifying graph
transformers based on depth, scalability, and pre-training strategies,
summarizing key principles for effective development of graph transformer
models. Beyond technical analysis, we discuss the applications of graph
transformer models for node-level, edge-level, and graph-level tasks, exploring
their potential in other application scenarios as well. Finally, we identify
remaining challenges in the field, such as scalability and efficiency,
generalization and robustness, interpretability and explainability, dynamic and
complex graphs, as well as data quality and diversity, charting future
directions for graph transformer research.",2024-07-13,"Ahsan Shehzad, Feng Xia, Shagufta Abid, Ciyuan Peng, Shuo Yu, Dongyu Zhang, Karin Verspoor",http://arxiv.org/pdf/2407.09777v1,cs.LG
Learning Weighted Finite Automata over the Max-Plus Semiring and its Termination,"Active learning of finite automata has been vigorously pursued for the
purposes of analysis and explanation of black-box systems. In this paper, we
study an L*-style learning algorithm for weighted automata over the max-plus
semiring. The max-plus setting exposes a ""consistency"" issue in the previously
studied semiring-generic extension of L*: we show that it can fail to maintain
consistency of tables, and can thus make equivalence queries on obviously wrong
hypothesis automata. We present a theoretical fix by a mathematically clean
notion of column-closedness. We also present a nontrivial and reasonably broad
class of weighted languages over the max-plus semiring in which our algorithm
terminates.",2024-07-13,"Takamasa Okudono, Masaki Waga, Taro Sekiyama, Ichiro Hasuo",http://arxiv.org/pdf/2407.09775v1,cs.LG
A Comprehensive Survey on Kolmogorov Arnold Networks (KAN),"Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have
gained a thorough understanding of its theoretical foundation, architectural
design, application scenarios, and current research progress. KAN, with its
unique architecture and flexible activation functions, excels in handling
complex data patterns and nonlinear relationships, demonstrating wide-ranging
application potential. While challenges remain, KAN is poised to pave the way
for innovative solutions in various fields, potentially revolutionizing how we
approach complex computational problems.",2024-07-13,"Tianrui Ji, Yuntian Hou, Di Zhang",http://arxiv.org/pdf/2407.11075v7,cs.LG
ST-RetNet: A Long-term Spatial-Temporal Traffic Flow Prediction Method,"Traffic flow forecasting is considered a critical task in the field of
intelligent transportation systems. In this paper, to address the issue of low
accuracy in long-term forecasting of spatial-temporal big data on traffic flow,
we propose an innovative model called Spatial-Temporal Retentive Network
(ST-RetNet). We extend the Retentive Network to address the task of traffic
flow forecasting. At the spatial scale, we integrate a topological graph
structure into Spatial Retentive Network(S-RetNet), utilizing an adaptive
adjacency matrix to extract dynamic spatial features of the road network. We
also employ Graph Convolutional Networks to extract static spatial features of
the road network. These two components are then fused to capture dynamic and
static spatial correlations. At the temporal scale, we propose the Temporal
Retentive Network(T-RetNet), which has been demonstrated to excel in capturing
long-term dependencies in traffic flow patterns compared to other time series
models, including Recurrent Neural Networks based and transformer models. We
achieve the spatial-temporal traffic flow forecasting task by integrating
S-RetNet and T-RetNet to form ST-RetNet. Through experimental comparisons
conducted on four real-world datasets, we demonstrate that ST-RetNet
outperforms the state-of-the-art approaches in traffic flow forecasting.",2024-07-13,"Baichao Long, Wang Zhu, Jianli Xiao",http://arxiv.org/pdf/2407.11074v1,cs.LG
Biased Backpressure Routing Using Link Features and Graph Neural Networks,"To reduce the latency of Backpressure (BP) routing in wireless multi-hop
networks, we propose to enhance the existing shortest path-biased BP (SP-BP)
and sojourn time-based backlog metrics, since they introduce no additional time
step-wise signaling overhead to the basic BP. Rather than relying on
hop-distance, we introduce a new edge-weighted shortest path bias built on the
scheduling duty cycle of wireless links, which can be predicted by a graph
convolutional neural network based on the topology and traffic of wireless
networks. Additionally, we tackle three long-standing challenges associated
with SP-BP: optimal bias scaling, efficient bias maintenance, and integration
of delay awareness. Our proposed solutions inherit the throughput optimality of
the basic BP, as well as its practical advantages of low complexity and fully
distributed implementation. Our approaches rely on common link features and
introduces only a one-time constant overhead to previous SP-BP schemes, or a
one-time overhead linear in the network size to the basic BP. Numerical
experiments show that our solutions can effectively address the major drawbacks
of slow startup, random walk, and the last packet problem in basic BP,
improving the end-to-end delay of existing low-overhead BP algorithms under
various settings of network traffic, interference, and mobility.",2024-07-13,"Zhongyuan Zhao, Bojan Radojičić, Gunjan Verma, Ananthram Swami, Santiago Segarra",http://arxiv.org/pdf/2407.09753v2,cs.LG
SocialRec: User Activity Based Post Weighted Dynamic Personalized Post Recommendation System in Social Media,"User activities can influence their subsequent interactions with a post,
generating interest in the user. Typically, users interact with posts from
friends by commenting and using reaction emojis, reflecting their level of
interest on social media such as Facebook, Twitter, and Reddit. Our objective
is to analyze user history over time, including their posts and engagement on
various topics. Additionally, we take into account the user's profile, seeking
connections between their activities and social media platforms. By integrating
user history, engagement, and persona, we aim to assess recommendation scores
based on relevant item sharing by Hit Rate (HR) and the quality of the ranking
system by Normalized Discounted Cumulative Gain (NDCG), where we achieve the
highest for NeuMF 0.80 and 0.6 respectively. Our hybrid approach solves the
cold-start problem when there is a new user, for new items cold-start problem
will never occur, as we consider the post category values. To improve the
performance of the model during cold-start we introduce collaborative filtering
by looking for similar users and ranking the users based on the highest
similarity scores.",2024-07-13,"Ismail Hossain, Sai Puppala, Md Jahangir Alam, Sajedul Talukder",http://arxiv.org/pdf/2407.09747v1,cs.LG
Active Learning for Derivative-Based Global Sensitivity Analysis with Gaussian Processes,"We consider the problem of active learning for global sensitivity analysis of
expensive black-box functions. Our aim is to efficiently learn the importance
of different input variables, e.g., in vehicle safety experimentation, we study
the impact of the thickness of various components on safety objectives. Since
function evaluations are expensive, we use active learning to prioritize
experimental resources where they yield the most value. We propose novel active
learning acquisition functions that directly target key quantities of
derivative-based global sensitivity measures (DGSMs) under Gaussian process
surrogate models. We showcase the first application of active learning directly
to DGSMs, and develop tractable uncertainty reduction and information gain
acquisition functions for these measures. Through comprehensive evaluation on
synthetic and real-world problems, our study demonstrates how these active
learning acquisition strategies substantially enhance the sample efficiency of
DGSM estimation, particularly with limited evaluation budgets. Our work paves
the way for more efficient and accurate sensitivity analysis in various
scientific and engineering applications.",2024-07-13,"Syrine Belakaria, Benjamin Letham, Janardhan Rao Doppa, Barbara Engelhardt, Stefano Ermon, Eytan Bakshy",http://arxiv.org/pdf/2407.09739v2,cs.LG
SemiAdv: Query-Efficient Black-Box Adversarial Attack with Unlabeled Images,"Adversarial attack has garnered considerable attention due to its profound
implications for the secure deployment of robots in sensitive security
scenarios. To potentially push for advances in the field, this paper studies
the adversarial attack in the black-box setting and proposes an unlabeled
data-driven adversarial attack method, called SemiAdv. Specifically, SemiAdv
achieves the following breakthroughs compared with previous works. First, by
introducing the semi-supervised learning technique into the adversarial attack,
SemiAdv substantially decreases the number of queries required for generating
adversarial samples. On average, SemiAdv only needs to query a few hundred
times to launch an effective attack with more than 90% success rate. Second,
many existing black-box adversarial attacks require massive labeled data to
mitigate the difference between the local substitute model and the remote
target model for a good attack performance. While SemiAdv relaxes this
limitation and is capable of utilizing unlabeled raw data to launch an
effective attack. Finally, our experiments show that SemiAdv saves up to 12x
query accesses for generating adversarial samples while maintaining a
competitive attack success rate compared with state-of-the-art attacks.",2024-07-13,"Mingyuan Fan, Yang Liu, Cen Chen, Ximeng Liu",http://arxiv.org/pdf/2407.11073v1,cs.LG
"Speech Slytherin: Examining the Performance and Efficiency of Mamba for Speech Separation, Recognition, and Synthesis","It is too early to conclude that Mamba is a better alternative to
transformers for speech before comparing Mamba with transformers in terms of
both performance and efficiency in multiple speech-related tasks. To reach this
conclusion, we propose and evaluate three models for three tasks: Mamba-TasNet
for speech separation, ConMamba for speech recognition, and VALL-M for speech
synthesis. We compare them with transformers of similar sizes in performance,
memory, and speed. Our Mamba or Mamba-transformer hybrid models show comparable
or higher performance than their transformer counterparts: Sepformer,
Conformer, and VALL-E. They are more efficient than transformers in memory and
speed for speech longer than a threshold duration, inversely related to the
resolution of a speech token. Mamba for separation is the most efficient, and
Mamba for recognition is the least. Further, we show that Mamba is not more
efficient than transformer for speech shorter than the threshold duration and
performs worse in models that require joint modeling of text and speech, such
as cross or masked attention of two inputs. Therefore, we argue that the
superiority of Mamba or transformer depends on particular problems and models.
Code available at https://github.com/xi-j/Mamba-TasNet and
https://github.com/xi-j/Mamba-ASR.",2024-07-13,"Xilin Jiang, Yinghao Aaron Li, Adrian Nicolas Florea, Cong Han, Nima Mesgarani",http://arxiv.org/pdf/2407.09732v1,cs.LG
"Neural Operator-Based Proxy for Reservoir Simulations Considering Varying Well Settings, Locations, and Permeability Fields","Simulating Darcy flows in porous media is fundamental to understand the
future flow behavior of fluids in hydrocarbon and carbon storage reservoirs.
Geological models of reservoirs are often associated with high uncertainly
leading to many numerical simulations for history matching and production
optimization. Machine learning models trained with simulation data can provide
a faster alternative to traditional simulators. In this paper we present a
single Fourier Neural Operator (FNO) surrogate that outperforms traditional
reservoir simulators by the ability to predict pressures and saturations on
varying permeability fields, well locations, well controls, and number of
wells. The maximum-mean relative error of 95\% of pressure and saturation
predictions is less than 5\%. This is achieved by employing a simple yet very
effective data augmentation technique that reduces the dataset size by 75\% and
reduces overfitting. Also, constructing the input tensor in a binary fashion
enables predictions on unseen well locations, well controls, and number of
wells. Such model can accelerate history matching and reservoir
characterization procedures by several orders of magnitude. The ability to
predict on new well locations, well controls, and number of wells enables
highly efficient reservoir management and optimization.",2024-07-13,"Daniel Badawi, Eduardo Gildin",http://arxiv.org/pdf/2407.09728v1,cs.LG
On Mitigating Code LLM Hallucinations with API Documentation,"In this study, we address the issue of API hallucinations in various software
engineering contexts. We introduce CloudAPIBench, a new benchmark designed to
measure API hallucination occurrences. CloudAPIBench also provides annotations
for frequencies of API occurrences in the public domain, allowing us to study
API hallucinations at various frequency levels. Our findings reveal that Code
LLMs struggle with low frequency APIs: for e.g., GPT-4o achieves only 38.58%
valid low frequency API invocations. We demonstrate that Documentation
Augmented Generation (DAG) significantly improves performance for low frequency
APIs (increase to 47.94% with DAG) but negatively impacts high frequency APIs
when using sub-optimal retrievers (a 39.02% absolute drop). To mitigate this,
we propose to intelligently trigger DAG where we check against an API index or
leverage Code LLMs' confidence scores to retrieve only when needed. We
demonstrate that our proposed methods enhance the balance between low and high
frequency API performance, resulting in more reliable API invocations (8.20%
absolute improvement on CloudAPIBench for GPT-4o).",2024-07-13,"Nihal Jain, Robert Kwiatkowski, Baishakhi Ray, Murali Krishna Ramanathan, Varun Kumar",http://arxiv.org/pdf/2407.09726v1,cs.LG
Optimized Multi-Token Joint Decoding with Auxiliary Model for LLM Inference,"Large language models (LLMs) have achieved remarkable success across diverse
tasks, yet their inference processes are hindered by substantial time and
energy demands due to single-token generation at each decoding step. While
previous methods such as speculative decoding mitigate these inefficiencies by
producing multiple tokens per step, each token is still generated by its
single-token distribution, thereby enhancing speed without improving
effectiveness. In contrast, our work simultaneously enhances inference speed
and improves the output effectiveness. We consider multi-token joint decoding
(MTJD), which generates multiple tokens from their joint distribution at each
iteration, theoretically reducing perplexity and enhancing task performance.
However, MTJD suffers from the high cost of sampling from the joint
distribution of multiple tokens. Inspired by speculative decoding, we introduce
multi-token assisted decoding (MTAD), a novel framework designed to accelerate
MTJD. MTAD leverages a smaller auxiliary model to approximate the joint
distribution of a larger model, incorporating a verification mechanism that not
only ensures the accuracy of this approximation, but also improves the decoding
efficiency over conventional speculative decoding. Theoretically, we
demonstrate that MTAD closely approximates exact MTJD with bounded error.
Empirical evaluations using Llama-2 and OPT models ranging from 13B to 70B
parameters across various tasks reveal that MTAD reduces perplexity by 21.2%
and improves downstream performance compared to standard single-token sampling.
Furthermore, MTAD achieves a 1.42x speed-up and consumes 1.54x less energy than
conventional speculative decoding methods. These results highlight MTAD's
ability to make multi-token joint decoding both effective and efficient,
promoting more sustainable and high-performance deployment of LLMs.",2024-07-12,"Zongyue Qin, Ziniu Hu, Zifan He, Neha Prakriya, Jason Cong, Yizhou Sun",http://arxiv.org/pdf/2407.09722v4,cs.LG
MSEval: A Dataset for Material Selection in Conceptual Design to Evaluate Algorithmic Models,"Material selection plays a pivotal role in many industries, from
manufacturing to construction. Material selection is usually carried out after
several cycles of conceptual design, during which designers iteratively refine
the design solution and the intended manufacturing approach. In design
research, material selection is typically treated as an optimization problem
with a single correct answer. Moreover, it is also often restricted to specific
types of objects or design functions, which can make the selection process
computationally expensive and time-consuming. In this paper, we introduce
MSEval, a novel dataset which is comprised of expert material evaluations
across a variety of design briefs and criteria. This data is designed to serve
as a benchmark to facilitate the evaluation and modification of machine
learning models in the context of material selection for conceptual design.",2024-07-12,"Yash Patawari Jain, Daniele Grandi, Allin Groom, Brandon Cramer, Christopher McComb",http://arxiv.org/pdf/2407.09719v1,cs.LG
Deep-TEMPEST: Using Deep Learning to Eavesdrop on HDMI from its Unintended Electromagnetic Emanations,"In this work, we address the problem of eavesdropping on digital video
displays by analyzing the electromagnetic waves that unintentionally emanate
from the cables and connectors, particularly HDMI. This problem is known as
TEMPEST. Compared to the analog case (VGA), the digital case is harder due to a
10-bit encoding that results in a much larger bandwidth and non-linear mapping
between the observed signal and the pixel's intensity. As a result,
eavesdropping systems designed for the analog case obtain unclear and
difficult-to-read images when applied to digital video. The proposed solution
is to recast the problem as an inverse problem and train a deep learning module
to map the observed electromagnetic signal back to the displayed image.
However, this approach still requires a detailed mathematical analysis of the
signal, firstly to determine the frequency at which to tune but also to produce
training samples without actually needing a real TEMPEST setup. This saves time
and avoids the need to obtain these samples, especially if several
configurations are being considered. Our focus is on improving the average
Character Error Rate in text, and our system improves this rate by over 60
percentage points compared to previous available implementations. The proposed
system is based on widely available Software Defined Radio and is fully
open-source, seamlessly integrated into the popular GNU Radio framework. We
also share the dataset we generated for training, which comprises both
simulated and over 1000 real captures. Finally, we discuss some countermeasures
to minimize the potential risk of being eavesdropped by systems designed based
on similar principles.",2024-07-12,"Santiago Fernández, Emilio Martínez, Gabriel Varela, Pablo Musé, Federico Larroca",http://arxiv.org/pdf/2407.09717v1,cs.LG
GOFA: A Generative One-For-All Model for Joint Graph Language Modeling,"Foundation models, such as Large Language Models (LLMs) or Large Vision
Models (LVMs), have emerged as one of the most powerful tools in the respective
fields. However, unlike text and image data, graph data do not have a
definitive structure, posing great challenges to developing a Graph Foundation
Model (GFM). For example, current attempts at designing general graph models
either transform graph data into a language format for LLM-based prediction or
still train a GNN model with LLM as an assistant. The former can handle
unlimited tasks, while the latter captures graph structure much better -- yet,
no existing work can achieve both simultaneously. In this paper, we identify
three key desirable properties of a GFM: self-supervised pretraining, fluidity
in tasks, and graph awareness. To account for these properties, we extend the
conventional language modeling to the graph domain and propose a novel
generative graph language model GOFA to solve the problem. The model
interleaves randomly initialized GNN layers into a frozen pre-trained LLM so
that the semantic and structural modeling abilities are organically combined.
GOFA is pre-trained on newly proposed graph-level next-word prediction,
question-answering, and structural tasks to obtain the above GFM properties.
The pre-trained model is further fine-tuned on downstream tasks to obtain
task-solving ability. The fine-tuned model is evaluated on various downstream
tasks, demonstrating a strong ability to solve structural and contextual
problems in zero-shot scenarios. The code is available at
https://github.com/JiaruiFeng/GOFA.",2024-07-12,"Lecheng Kong, Jiarui Feng, Hao Liu, Chengsong Huang, Jiaxin Huang, Yixin Chen, Muhan Zhang",http://arxiv.org/pdf/2407.09709v2,cs.LG
Investigating the Interplay of Prioritized Replay and Generalization,"Experience replay, the reuse of past data to improve sample efficiency, is
ubiquitous in reinforcement learning. Though a variety of smart sampling
schemes have been introduced to improve performance, uniform sampling by far
remains the most common approach. One exception is Prioritized Experience
Replay (PER), where sampling is done proportionally to TD errors, inspired by
the success of prioritized sweeping in dynamic programming. The original work
on PER showed improvements in Atari, but follow-up results were mixed. In this
paper, we investigate several variations on PER, to attempt to understand where
and when PER may be useful. Our findings in prediction tasks reveal that while
PER can improve value propagation in tabular settings, behavior is
significantly different when combined with neural networks. Certain mitigations
$-$ like delaying target network updates to control generalization and using
estimates of expected TD errors in PER to avoid chasing stochasticity $-$ can
avoid large spikes in error with PER and neural networks but generally do not
outperform uniform replay. In control tasks, none of the prioritized variants
consistently outperform uniform replay. We present new insight into the
interaction between prioritization, bootstrapping, and neural networks and
propose several improvements for PER in tabular settings and noisy domains.",2024-07-12,"Parham Mohammad Panahi, Andrew Patterson, Martha White, Adam White",http://arxiv.org/pdf/2407.09702v2,cs.LG
RIO-CPD: A Riemannian Geometric Method for Correlation-aware Online Change Point Detection,"Change point detection aims to identify abrupt shifts occurring at multiple
points within a data sequence. This task becomes particularly challenging in
the online setting, where different types of changes can occur, including
shifts in both the marginal and joint distributions of the data. In this paper,
we address these challenges by tracking the Riemannian geometry of correlation
matrices, allowing Riemannian metrics to compute the geodesic distance as an
accurate measure of correlation dynamics. We introduce Rio-CPD, a
non-parametric, correlation-aware online change point detection framework that
integrates the Riemannian geometry of the manifold of symmetric positive
definite matrices with the cumulative sum (CUSUM) statistic for detecting
change points. Rio-CPD employs a novel CUSUM design by computing the geodesic
distance between current observations and the Fr\'echet mean of prior
observations. With appropriate choices of Riemannian metrics, Rio-CPD offers a
simple yet effective and computationally efficient algorithm. Experimental
results on both synthetic and real-world datasets demonstrate that Rio-CPD
outperforms existing methods on detection accuracy, average detection delay and
efficiency.",2024-07-12,"Chengyuan Deng, Zhengzhang Chen, Xujiang Zhao, Haoyu Wang, Junxiang Wang, Haifeng Chen, Jie Gao",http://arxiv.org/pdf/2407.09698v2,cs.LG
"A Mathematical Framework, a Taxonomy of Modeling Paradigms, and a Suite of Learning Techniques for Neural-Symbolic Systems","The field of Neural-Symbolic (NeSy) systems is growing rapidly. Proposed
approaches show great promise in achieving symbiotic unions of neural and
symbolic methods. However, each NeSy system differs in fundamental ways. There
is a pressing need for a unifying theory to illuminate the commonalities and
differences in approaches and enable further progress. In this paper, we
introduce Neural-Symbolic Energy-Based Models (NeSy-EBMs), a unifying
mathematical framework for discriminative and generative modeling with
probabilistic and non-probabilistic NeSy approaches. We utilize NeSy-EBMs to
develop a taxonomy of modeling paradigms focusing on a system's neural-symbolic
interface and reasoning capabilities. Additionally, we introduce a suite of
learning techniques for NeSy-EBMs. Importantly, NeSy-EBMs allow the derivation
of general expressions for gradients of prominent learning losses, and we
provide four learning approaches that leverage methods from multiple domains,
including bilevel and stochastic policy optimization. Finally, we present
Neural Probabilistic Soft Logic (NeuPSL), an open-source NeSy-EBM library
designed for scalability and expressivity, facilitating real-world application
of NeSy systems. Through extensive empirical analysis across multiple datasets,
we demonstrate the practical advantages of NeSy-EBMs in various tasks,
including image classification, graph node labeling, autonomous vehicle
situation awareness, and question answering.",2024-07-12,"Charles Dickens, Connor Pryor, Changyu Gao, Alon Albalak, Eriq Augustine, William Wang, Stephen Wright, Lise Getoor",http://arxiv.org/pdf/2407.09693v1,cs.LG
EVOLVE: Predicting User Evolution and Network Dynamics in Social Media Using Fine-Tuned GPT-like Model,"Social media platforms are extensively used for sharing personal emotions,
daily activities, and various life events, keeping people updated with the
latest happenings. From the moment a user creates an account, they continually
expand their network of friends or followers, freely interacting with others by
posting, commenting, and sharing content. Over time, user behavior evolves
based on demographic attributes and the networks they establish. In this
research, we propose a predictive method to understand how a user evolves on
social media throughout their life and to forecast the next stage of their
evolution. We fine-tune a GPT-like decoder-only model (we named it E-GPT:
Evolution-GPT) to predict the future stages of a user's evolution in online
social media. We evaluate the performance of these models and demonstrate how
user attributes influence changes within their network by predicting future
connections and shifts in user activities on social media, which also addresses
other social media challenges such as recommendation systems.",2024-07-12,"Ismail Hossain, Md Jahangir Alam, Sai Puppala, Sajedul Talukder",http://arxiv.org/pdf/2407.09691v1,cs.LG
Private Heterogeneous Federated Learning Without a Trusted Server Revisited: Error-Optimal and Communication-Efficient Algorithms for Convex Losses,"We revisit the problem of federated learning (FL) with private data from
people who do not trust the server or other silos/clients. In this context,
every silo (e.g. hospital) has data from several people (e.g. patients) and
needs to protect the privacy of each person's data (e.g. health records), even
if the server and/or other silos try to uncover this data. Inter-Silo
Record-Level Differential Privacy (ISRL-DP) prevents each silo's data from
being leaked, by requiring that silo i's communications satisfy item-level
differential privacy. Prior work arXiv:2106.09779 characterized the optimal
excess risk bounds for ISRL-DP algorithms with homogeneous (i.i.d.) silo data
and convex loss functions. However, two important questions were left open: (1)
Can the same excess risk bounds be achieved with heterogeneous (non-i.i.d.)
silo data? (2) Can the optimal risk bounds be achieved with fewer communication
rounds? In this paper, we give positive answers to both questions. We provide
novel ISRL-DP FL algorithms that achieve the optimal excess risk bounds in the
presence of heterogeneous silo data. Moreover, our algorithms are more
communication-efficient than the prior state-of-the-art. For smooth loss
functions, our algorithm achieves the optimal excess risk bound and has
communication complexity that matches the non-private lower bound.
Additionally, our algorithms are more computationally efficient than the
previous state-of-the-art.",2024-07-12,"Changyu Gao, Andrew Lowy, Xingyu Zhou, Stephen J. Wright",http://arxiv.org/pdf/2407.09690v3,cs.LG
Accelerating the inference of string generation-based chemical reaction models for industrial applications,"Template-free SMILES-to-SMILES translation models for reaction prediction and
single-step retrosynthesis are of interest for industrial applications in
computer-aided synthesis planning systems due to their state-of-the-art
accuracy. However, they suffer from slow inference speed. We present a method
to accelerate inference in autoregressive SMILES generators through speculative
decoding by copying query string subsequences into target strings in the right
places. We apply our method to the molecular transformer implemented in Pytorch
Lightning and achieve over 3X faster inference in reaction prediction and
single-step retrosynthesis, with no loss in accuracy.",2024-07-12,"Mikhail Andronov, Natalia Andronova, Michael Wand, Jürgen Schmidhuber, Djork-Arné Clevert",http://arxiv.org/pdf/2407.09685v2,cs.LG
MonoSparse-CAM: Efficient Tree Model Processing via Monotonicity and Sparsity in CAMs,"While the tree-based machine learning (TBML) models exhibit superior
performance compared to neural networks on tabular data and hold promise for
energy-efficient acceleration using aCAM arrays, their ideal deployment on
hardware with explicit exploitation of TBML structure and aCAM circuitry
remains a challenging task. In this work, we present MonoSparse-CAM, a new
CAM-based optimization technique that exploits TBML sparsity and monotonicity
in CAM circuitry to further advance processing performance. Our results
indicate that MonoSparse-CAM reduces energy consumption by upto to 28.56x
compared to raw processing and by 18.51x compared to state-of-the-art
techniques, while improving the efficiency of computation by at least 1.68x.",2024-07-12,"Tergel Molom-Ochir, Brady Taylor, Hai Li, Yiran Chen",http://arxiv.org/pdf/2407.11071v2,cs.LG
Physics-Informed Learning of Characteristic Trajectories for Smoke Reconstruction,"We delve into the physics-informed neural reconstruction of smoke and
obstacles through sparse-view RGB videos, tackling challenges arising from
limited observation of complex dynamics. Existing physics-informed neural
networks often emphasize short-term physics constraints, leaving the proper
preservation of long-term conservation less explored. We introduce Neural
Characteristic Trajectory Fields, a novel representation utilizing Eulerian
neural fields to implicitly model Lagrangian fluid trajectories. This
topology-free, auto-differentiable representation facilitates efficient flow
map calculations between arbitrary frames as well as efficient velocity
extraction via auto-differentiation. Consequently, it enables end-to-end
supervision covering long-term conservation and short-term physics priors.
Building on the representation, we propose physics-informed trajectory learning
and integration into NeRF-based scene reconstruction. We enable advanced
obstacle handling through self-supervised scene decomposition and seamless
integrated boundary constraints. Our results showcase the ability to overcome
challenges like occlusion uncertainty, density-color ambiguity, and
static-dynamic entanglements. Code and sample tests are at
\url{https://github.com/19reborn/PICT_smoke}.",2024-07-12,"Yiming Wang, Siyu Tang, Mengyu Chu",http://arxiv.org/pdf/2407.09679v1,cs.LG
BoBa: Boosting Backdoor Detection through Data Distribution Inference in Federated Learning,"Federated learning, while being a promising approach for collaborative model
training, is susceptible to poisoning attacks due to its decentralized nature.
Backdoor attacks, in particular, have shown remarkable stealthiness, as they
selectively compromise predictions for inputs containing triggers. Previous
endeavors to detect and mitigate such attacks are based on the Independent and
Identically Distributed (IID) data assumption where benign model updates
exhibit high-level similarity in multiple feature spaces due to IID data. Thus,
outliers are detected as backdoor attacks. Nevertheless, non-IID data presents
substantial challenges in backdoor attack detection, as the data variety
introduces variance among benign models, making outlier detection-based
mechanisms less effective.
  We propose a novel distribution-aware anomaly detection mechanism, BoBa, to
address this problem. In order to differentiate outliers arising from data
variety versus backdoor attack, we propose to break down the problem into two
steps: clustering clients utilizing their data distribution followed by a
voting-based detection. Based on the intuition that clustering and subsequent
backdoor detection can drastically benefit from knowing client data
distributions, we propose a novel data distribution inference mechanism. To
improve detection robustness, we introduce an overlapping clustering method,
where each client is associated with multiple clusters, ensuring that the
trustworthiness of a model update is assessed collectively by multiple clusters
rather than a single cluster. Through extensive evaluations, we demonstrate
that BoBa can reduce the attack success rate to lower than 0.001 while
maintaining high main task accuracy across various attack strategies and
experimental settings.",2024-07-12,"Ning Wang, Shanghao Shi, Yang Xiao, Yimin Chen, Y. Thomas Hou, Wenjing Lou",http://arxiv.org/pdf/2407.09658v1,cs.LG
Hamilton-Jacobi Reachability in Reinforcement Learning: A Survey,"Recent literature has proposed approaches that learn control policies with
high performance while maintaining safety guarantees. Synthesizing
Hamilton-Jacobi (HJ) reachable sets has become an effective tool for verifying
safety and supervising the training of reinforcement learning-based control
policies for complex, high-dimensional systems. Previously, HJ reachability was
restricted to verifying low-dimensional dynamical systems primarily because the
computational complexity of the dynamic programming approach it relied on grows
exponentially with the number of system states. In recent years, a litany of
proposed methods addresses this limitation by computing the reachability value
function simultaneously with learning control policies to scale HJ reachability
analysis while still maintaining a reliable estimate of the true reachable set.
These HJ reachability approximations are used to improve the safety, and even
reward performance, of learned control policies and can solve challenging tasks
such as those with dynamic obstacles and/or with lidar-based or vision-based
observations. In this survey paper, we review the recent developments in the
field of HJ reachability estimation in reinforcement learning that would
provide a foundational basis for further research into reliability in
high-dimensional systems.",2024-07-12,"Milan Ganai, Sicun Gao, Sylvia Herbert",http://arxiv.org/pdf/2407.09645v2,cs.LG
Seq-to-Final: A Benchmark for Tuning from Sequential Distributions to a Final Time Point,"Distribution shift over time occurs in many settings. Leveraging historical
data is necessary to learn a model for the last time point when limited data is
available in the final period, yet few methods have been developed specifically
for this purpose. In this work, we construct a benchmark with different
sequences of synthetic shifts to evaluate the effectiveness of 3 classes of
methods that 1) learn from all data without adapting to the final period, 2)
learn from historical data with no regard to the sequential nature and then
adapt to the final period, and 3) leverage the sequential nature of historical
data when tailoring a model to the final period. We call this benchmark
Seq-to-Final to highlight the focus on using a sequence of time periods to
learn a model for the final time point. Our synthetic benchmark allows users to
construct sequences with different types of shift and compare different
methods. We focus on image classification tasks using CIFAR-10 and CIFAR-100 as
the base images for the synthetic sequences. We also evaluate the same methods
on the Portraits dataset to explore the relevance to real-world shifts over
time. Finally, we create a visualization to contrast the initializations and
updates from different methods at the final time step. Our results suggest
that, for the sequences in our benchmark, methods that disregard the sequential
structure and adapt to the final time point tend to perform well. The
approaches we evaluate that leverage the sequential nature do not offer any
improvement. We hope that this benchmark will inspire the development of new
algorithms that are better at leveraging sequential historical data or a deeper
understanding of why methods that disregard the sequential nature are able to
perform well.",2024-07-12,"Christina X Ji, Ahmed M Alaa, David Sontag",http://arxiv.org/pdf/2407.09642v1,cs.LG
Granger Causality in Extremes,"We introduce a rigorous mathematical framework for Granger causality in
extremes, designed to identify causal links from extreme events in time series.
Granger causality plays a pivotal role in uncovering directional relationships
among time-varying variables. While this notion gains heightened importance
during extreme and highly volatile periods, state-of-the-art methods primarily
focus on causality within the body of the distribution, often overlooking
causal mechanisms that manifest only during extreme events. Our framework is
designed to infer causality mainly from extreme events by leveraging the causal
tail coefficient. We establish equivalences between causality in extremes and
other causal concepts, including (classical) Granger causality, Sims causality,
and structural causality. We prove other key properties of Granger causality in
extremes and show that the framework is especially helpful under the presence
of hidden confounders. We also propose a novel inference method for detecting
the presence of Granger causality in extremes from data. Our method is
model-free, can handle non-linear and high-dimensional time series, outperforms
current state-of-the-art methods in all considered setups, both in performance
and speed, and was found to uncover coherent effects when applied to financial
and extreme weather observations.",2024-07-12,"Juraj Bodik, Olivier C. Pasche",http://arxiv.org/pdf/2407.09632v2,cs.LG
Optimal Defender Strategies for CAGE-2 using Causal Modeling and Tree Search,"The CAGE-2 challenge is considered a standard benchmark to compare methods
for autonomous cyber defense. Current state-of-the-art methods evaluated
against this benchmark are based on model-free (offline) reinforcement
learning, which does not provide provably optimal defender strategies. We
address this limitation and present a formal (causal) model of CAGE-2 together
with a method that produces a provably optimal defender strategy, which we call
Causal Partially Observable Monte-Carlo Planning (C-POMCP). It has two key
properties. First, it incorporates the causal structure of the target system,
i.e., the causal relationships among the system variables. This structure
allows for a significant reduction of the search space of defender strategies.
Second, it is an online method that updates the defender strategy at each time
step via tree search. Evaluations against the CAGE-2 benchmark show that
C-POMCP achieves state-of-the-art performance with respect to effectiveness and
is two orders of magnitude more efficient in computing time than the closest
competitor method.",2024-07-12,"Kim Hammar, Neil Dhir, Rolf Stadler",http://arxiv.org/pdf/2407.11070v2,cs.LG
Accelerating Electron Dynamics Simulations through Machine Learned Time Propagators,"Time-dependent density functional theory (TDDFT) is a widely used method to
investigate electron dynamics under various external perturbations such as
laser fields. In this work, we present a novel approach to accelerate real time
TDDFT based electron dynamics simulations using autoregressive neural operators
as time-propagators for the electron density. By leveraging physics-informed
constraints and high-resolution training data, our model achieves superior
accuracy and computational speed compared to traditional numerical solvers. We
demonstrate the effectiveness of our model on a class of one-dimensional
diatomic molecules. This method has potential in enabling real-time, on-the-fly
modeling of laser-irradiated molecules and materials with varying experimental
parameters.",2024-07-12,"Karan Shah, Attila Cangi",http://arxiv.org/pdf/2407.09628v2,cs.LG
"The Heterophilic Graph Learning Handbook: Benchmarks, Models, Theoretical Analysis, Applications and Challenges","Homophily principle, \ie{} nodes with the same labels or similar attributes
are more likely to be connected, has been commonly believed to be the main
reason for the superiority of Graph Neural Networks (GNNs) over traditional
Neural Networks (NNs) on graph-structured data, especially on node-level tasks.
However, recent work has identified a non-trivial set of datasets where GNN's
performance compared to the NN's is not satisfactory. Heterophily, i.e. low
homophily, has been considered the main cause of this empirical observation.
People have begun to revisit and re-evaluate most existing graph models,
including graph transformer and its variants, in the heterophily scenario
across various kinds of graphs, e.g. heterogeneous graphs, temporal graphs and
hypergraphs. Moreover, numerous graph-related applications are found to be
closely related to the heterophily problem. In the past few years, considerable
effort has been devoted to studying and addressing the heterophily issue.
  In this survey, we provide a comprehensive review of the latest progress on
heterophilic graph learning, including an extensive summary of benchmark
datasets and evaluation of homophily metrics on synthetic graphs, meticulous
classification of the most updated supervised and unsupervised learning
methods, thorough digestion of the theoretical analysis on
homophily/heterophily, and broad exploration of the heterophily-related
applications. Notably, through detailed experiments, we are the first to
categorize benchmark heterophilic datasets into three sub-categories:
malignant, benign and ambiguous heterophily. Malignant and ambiguous datasets
are identified as the real challenging datasets to test the effectiveness of
new models on the heterophily challenge. Finally, we propose several challenges
and future directions for heterophilic graph representation learning.",2024-07-12,"Sitao Luan, Chenqing Hua, Qincheng Lu, Liheng Ma, Lirong Wu, Xinyu Wang, Minkai Xu, Xiao-Wen Chang, Doina Precup, Rex Ying, Stan Z. Li, Jian Tang, Guy Wolf, Stefanie Jegelka",http://arxiv.org/pdf/2407.09618v1,cs.LG
Real-time gravitational-wave inference for binary neutron stars using machine learning,"Mergers of binary neutron stars (BNSs) emit signals in both the
gravitational-wave (GW) and electromagnetic (EM) spectra. Famously, the 2017
multi-messenger observation of GW170817 led to scientific discoveries across
cosmology, nuclear physics, and gravity. Central to these results were the sky
localization and distance obtained from GW data, which, in the case of
GW170817, helped to identify the associated EM transient, AT 2017gfo, 11 hours
after the GW signal. Fast analysis of GW data is critical for directing
time-sensitive EM observations; however, due to challenges arising from the
length and complexity of signals, it is often necessary to make approximations
that sacrifice accuracy. Here, we present a machine learning framework that
performs complete BNS inference in just one second without making any such
approximations. Our approach enhances multi-messenger observations by providing
(i) accurate localization even before the merger; (ii) improved localization
precision by $\sim30\%$ compared to approximate low-latency methods; and (iii)
detailed information on luminosity distance, inclination, and masses, which can
be used to prioritize expensive telescope time. Additionally, the flexibility
and reduced cost of our method open new opportunities for equation-of-state
studies. Finally, we demonstrate that our method scales to extremely long
signals, up to an hour in length, thus serving as a blueprint for data analysis
for next-generation ground- and space-based detectors.",2024-07-12,"Maximilian Dax, Stephen R. Green, Jonathan Gair, Nihar Gupte, Michael Pürrer, Vivien Raymond, Jonas Wildberger, Jakob H. Macke, Alessandra Buonanno, Bernhard Schölkopf",http://arxiv.org/pdf/2407.09602v2,cs.LG
Adaptive Prediction Ensemble: Improving Out-of-Distribution Generalization of Motion Forecasting,"Deep learning-based trajectory prediction models for autonomous driving often
struggle with generalization to out-of-distribution (OOD) scenarios, sometimes
performing worse than simple rule-based models. To address this limitation, we
propose a novel framework, Adaptive Prediction Ensemble (APE), which integrates
deep learning and rule-based prediction experts. A learned routing function,
trained concurrently with the deep learning model, dynamically selects the most
reliable prediction based on the input scenario. Our experiments on large-scale
datasets, including Waymo Open Motion Dataset (WOMD) and Argoverse, demonstrate
improvement in zero-shot generalization across datasets. We show that our
method outperforms individual prediction models and other variants,
particularly in long-horizon prediction and scenarios with a high proportion of
OOD data. This work highlights the potential of hybrid approaches for robust
and generalizable motion prediction in autonomous driving. More details can be
found on the project page: https://sites.google.com/view/ape-generalization.",2024-07-12,"Jinning Li, Jiachen Li, Sangjae Bae, David Isele",http://arxiv.org/pdf/2407.09475v2,cs.LG
"Beyond Euclid: An Illustrated Guide to Modern Machine Learning with Geometric, Topological, and Algebraic Structures","The enduring legacy of Euclidean geometry underpins classical machine
learning, which, for decades, has been primarily developed for data lying in
Euclidean space. Yet, modern machine learning increasingly encounters richly
structured data that is inherently nonEuclidean. This data can exhibit
intricate geometric, topological and algebraic structure: from the geometry of
the curvature of space-time, to topologically complex interactions between
neurons in the brain, to the algebraic transformations describing symmetries of
physical systems. Extracting knowledge from such non-Euclidean data
necessitates a broader mathematical perspective. Echoing the 19th-century
revolutions that gave rise to non-Euclidean geometry, an emerging line of
research is redefining modern machine learning with non-Euclidean structures.
Its goal: generalizing classical methods to unconventional data types with
geometry, topology, and algebra. In this review, we provide an accessible
gateway to this fast-growing field and propose a graphical taxonomy that
integrates recent advances into an intuitive unified framework. We subsequently
extract insights into current challenges and highlight exciting opportunities
for future development in this field.",2024-07-12,"Sophia Sanborn, Johan Mathe, Mathilde Papillon, Domas Buracas, Hansen J Lillemark, Christian Shewmake, Abby Bertics, Xavier Pennec, Nina Miolane",http://arxiv.org/pdf/2407.09468v1,cs.LG
"Weight Block Sparsity: Training, Compilation, and AI Engine Accelerators","Nowadays, increasingly larger Deep Neural Networks (DNNs) are being
developed, trained, and utilized. These networks require significant
computational resources, putting a strain on both advanced and limited devices.
Our solution is to implement {\em weight block sparsity}, which is a structured
sparsity that is friendly to hardware. By zeroing certain sections of the
convolution and fully connected layers parameters of pre-trained DNN models, we
can efficiently speed up the DNN's inference process. This results in a smaller
memory footprint, faster communication, and fewer operations.
  Our work presents a vertical system that allows for the training of
convolution and matrix multiplication weights to exploit 8x8 block sparsity on
a single GPU within a reasonable amount of time. Compilers recognize this
sparsity and use it for both data compaction and computation splitting into
threads. Blocks like these take full advantage of both spatial and temporal
locality, paving the way for fast vector operations and memory reuse. By using
this system on a Resnet50 model, we were able to reduce the weight by half with
minimal accuracy loss, resulting in a two-times faster inference speed. We will
present performance estimates using accurate and complete code generation for
AIE2 configuration sets (AMD Versal FPGAs) with Resnet50, Inception V3, and
VGG16 to demonstrate the necessary synergy between hardware overlay designs and
software stacks for compiling and executing machine learning applications.",2024-07-12,"Paolo D'Alberto, Taehee Jeong, Akshai Jain, Shreyas Manjunath, Mrinal Sarmah, Samuel Hsu, Yaswanth Raparti, Nitesh Pipralia",http://arxiv.org/pdf/2407.09453v1,cs.LG
Human-like Episodic Memory for Infinite Context LLMs,"Large language models (LLMs) have shown remarkable capabilities, but still
struggle with processing extensive contexts, limiting their ability to maintain
coherence and accuracy over long sequences. In contrast, the human brain excels
at organising and retrieving episodic experiences across vast temporal scales,
spanning a lifetime. In this work, we introduce EM-LLM, a novel approach that
integrates key aspects of human episodic memory and event cognition into LLMs
with no fine-tuning, enabling them to handle practically infinite context
lengths while maintaining computational efficiency. EM-LLM organises sequences
of tokens into coherent episodic events using a combination of Bayesian
surprise and graph-theoretic boundary refinement in an online fashion. When
needed, these events are retrieved through a two-stage memory process,
combining similarity-based and temporally contiguous retrieval for efficient
and human-like access to relevant information. Experiments on the LongBench and
InfiniteBench benchmarks demonstrate EM-LLM's superior performance,
consistently outperforming the state-of-the-art retrieval model InfLLM across
various baseline LLMs. In addition, EM-LLM outperforms its popular counterpart,
RAG, in a wide range of tasks, while requiring similar resources. Notably,
EM-LLM's performance even surpasses full-context models in most tasks, while
successfully performing retrieval across 10 million tokens - a scale
computationally infeasible for such models. Finally, our analysis reveals
strong correlations between EM-LLM's event segmentation and human-perceived
events, suggesting a bridge between this artificial system and its biological
counterpart, thereby offering a novel computational framework for exploring
human memory mechanisms.",2024-07-12,"Zafeirios Fountas, Martin A Benfeghoul, Adnan Oomerjee, Fenia Christopoulou, Gerasimos Lampouras, Haitham Bou-Ammar, Jun Wang",http://arxiv.org/pdf/2407.09450v2,cs.LG
The $μ\mathcal{G}$ Language for Programming Graph Neural Networks,"Graph neural networks form a class of deep learning architectures
specifically designed to work with graph-structured data. As such, they share
the inherent limitations and problems of deep learning, especially regarding
the issues of explainability and trustworthiness. We propose $\mu\mathcal{G}$,
an original domain-specific language for the specification of graph neural
networks that aims to overcome these issues. The language's syntax is
introduced, and its meaning is rigorously defined by a denotational semantics.
An equivalent characterization in the form of an operational semantics is also
provided and, together with a type system, is used to prove the type soundness
of $\mu\mathcal{G}$. We show how $\mu\mathcal{G}$ programs can be represented
in a more user-friendly graphical visualization, and provide examples of its
generality by showing how it can be used to define some of the most popular
graph neural network models, or to develop any custom graph processing
application.",2024-07-12,"Matteo Belenchia, Flavio Corradini, Michela Quadrini, Michele Loreti",http://arxiv.org/pdf/2407.09441v4,cs.LG
Diversifying the Expert Knowledge for Task-Agnostic Pruning in Sparse Mixture-of-Experts,"By increasing model parameters but activating them sparsely when performing a
task, the use of Mixture-of-Experts (MoE) architecture significantly improves
the performance of Large Language Models (LLMs) without increasing the
inference cost. However, the memory consumption due to the growing number of
experts presents a challenge to the deployment of these models in many real
world settings. Our empirical study reveals that some experts encode redundant
knowledge during pre-training. We thus propose a method of grouping and pruning
similar experts to improve the model's parameter efficiency. We validate the
effectiveness of our method by pruning three state-of-the-art MoE
architectures, including Mixtral, Deepseek-MoE, and Qwen. The evaluation shows
that our method outperforms other model pruning methods on a range of natural
language tasks. We will release our code to facilitate future research.",2024-07-12,"Zeliang Zhang, Xiaodong Liu, Hao Cheng, Chenliang Xu, Jianfeng Gao",http://arxiv.org/pdf/2407.09590v3,cs.LG
Foundation Models for the Electric Power Grid,"Foundation models (FMs) currently dominate news headlines. They employ
advanced deep learning architectures to extract structural information
autonomously from vast datasets through self-supervision. The resulting rich
representations of complex systems and dynamics can be applied to many
downstream applications. Therefore, FMs can find uses in electric power grids,
challenged by the energy transition and climate change. In this paper, we call
for the development of, and state why we believe in, the potential of FMs for
electric grids. We highlight their strengths and weaknesses amidst the
challenges of a changing grid. We argue that an FM learning from diverse grid
data and topologies could unlock transformative capabilities, pioneering a new
approach in leveraging AI to redefine how we manage complexity and uncertainty
in the electric grid. Finally, we discuss a power grid FM concept, namely
GridFM, based on graph neural networks and show how different downstream tasks
benefit.",2024-07-12,"Hendrik F. Hamann, Thomas Brunschwiler, Blazhe Gjorgiev, Leonardo S. A. Martins, Alban Puech, Anna Varbella, Jonas Weiss, Juan Bernabe-Moreno, Alexandre Blondin Massé, Seong Choi, Ian Foster, Bri-Mathias Hodge, Rishabh Jain, Kibaek Kim, Vincent Mai, François Mirallès, Martin De Montigny, Octavio Ramos-Leaños, Hussein Suprême, Le Xie, El-Nasser S. Youssef, Arnaud Zinflou, Alexander J. Belyi, Ricardo J. Bessa, Bishnu Prasad Bhattarai, Johannes Schmude, Stanislav Sobolevsky",http://arxiv.org/pdf/2407.09434v2,cs.LG
Flow-Based Generative Emulation of Grids of Stellar Evolutionary Models,"We present a flow-based generative approach to emulate grids of stellar
evolutionary models. By interpreting the input parameters and output properties
of these models as multi-dimensional probability distributions, we train
conditional normalizing flows to learn and predict the complex relationships
between grid inputs and outputs in the form of conditional joint distributions.
Leveraging the expressive power and versatility of these flows, we showcase
their ability to emulate a variety of evolutionary tracks and isochrones across
a continuous range of input parameters. In addition, we describe a simple
Bayesian approach for estimating stellar parameters using these flows and
demonstrate its application to asteroseismic datasets of red giants observed by
the Kepler mission. By applying this approach to red giants in open clusters
NGC 6791 and NGC 6819, we illustrate how large age uncertainties can arise when
fitting only to global asteroseismic and spectroscopic parameters without prior
information on initial helium abundances and mixing length parameter values. We
also conduct inference using the flow at a large scale by determining revised
estimates of masses and radii for 15,388 field red giants. These estimates show
improved agreement with results from existing grid-based modelling, reveal
distinct population-level features in the red clump, and suggest that the
masses of Kepler red giants previously determined using the corrected
asteroseismic scaling relations have been overestimated by 5-10%.",2024-07-12,"Marc Hon, Yaguang Li, Joel Ong",http://arxiv.org/pdf/2407.09427v1,cs.LG
A Benchmark Environment for Offline Reinforcement Learning in Racing Games,"Offline Reinforcement Learning (ORL) is a promising approach to reduce the
high sample complexity of traditional Reinforcement Learning (RL) by
eliminating the need for continuous environmental interactions. ORL exploits a
dataset of pre-collected transitions and thus expands the range of application
of RL to tasks in which the excessive environment queries increase training
time and decrease efficiency, such as in modern AAA games. This paper
introduces OfflineMania a novel environment for ORL research. It is inspired by
the iconic TrackMania series and developed using the Unity 3D game engine. The
environment simulates a single-agent racing game in which the objective is to
complete the track through optimal navigation. We provide a variety of datasets
to assess ORL performance. These datasets, created from policies of varying
ability and in different sizes, aim to offer a challenging testbed for
algorithm development and evaluation. We further establish a set of baselines
for a range of Online RL, ORL, and hybrid Offline to Online RL approaches using
our environment.",2024-07-12,"Girolamo Macaluso, Alessandro Sestini, Andrew D. Bagdanov",http://arxiv.org/pdf/2407.09415v1,cs.LG
Meta-Analysis with Untrusted Data,"[See paper for full abstract] Meta-analysis is a crucial tool for answering
scientific questions. It is usually conducted on a relatively small amount of
``trusted'' data -- ideally from randomized, controlled trials -- which allow
causal effects to be reliably estimated with minimal assumptions. We show how
to answer causal questions much more precisely by making two changes. First, we
incorporate untrusted data drawn from large observational databases, related
scientific literature and practical experience -- without sacrificing rigor or
introducing strong assumptions. Second, we train richer models capable of
handling heterogeneous trials, addressing a long-standing challenge in
meta-analysis. Our approach is based on conformal prediction, which
fundamentally produces rigorous prediction intervals, but doesn't handle
indirect observations: in meta-analysis, we observe only noisy effects due to
the limited number of participants in each trial. To handle noise, we develop a
simple, efficient version of fully-conformal kernel ridge regression, based on
a novel condition called idiocentricity. We introduce noise-correcting terms in
the residuals and analyze their interaction with a ``variance shaving''
technique. In multiple experiments on healthcare datasets, our algorithms
deliver tighter, sounder intervals than traditional ones. This paper charts a
new course for meta-analysis and evidence-based medicine, where heterogeneity
and untrusted data are embraced for more nuanced and precise predictions.",2024-07-12,"Shiva Kaul, Geoffrey J. Gordon",http://arxiv.org/pdf/2407.09387v1,cs.LG
The Effectiveness of Curvature-Based Rewiring and the Role of Hyperparameters in GNNs Revisited,"Message passing is the dominant paradigm in Graph Neural Networks (GNNs). The
efficiency of message passing, however, can be limited by the topology of the
graph. This happens when information is lost during propagation due to being
oversquashed when travelling through bottlenecks. To remedy this, recent
efforts have focused on graph rewiring techniques, which disconnect the input
graph originating from the data and the computational graph, on which message
passing is performed. A prominent approach for this is to use discrete graph
curvature measures, of which several variants have been proposed, to identify
and rewire around bottlenecks, facilitating information propagation. While
oversquashing has been demonstrated in synthetic datasets, in this work we
reevaluate the performance gains that curvature-based rewiring brings to
real-world datasets. We show that in these datasets, edges selected during the
rewiring process are not in line with theoretical criteria identifying
bottlenecks. This implies they do not necessarily oversquash information during
message passing. Subsequently, we demonstrate that SOTA accuracies on these
datasets are outliers originating from sweeps of hyperparameters -- both the
ones for training and dedicated ones related to the rewiring algorithm --
instead of consistent performance gains. In conclusion, our analysis nuances
the effectiveness of curvature-based rewiring in real-world datasets and brings
a new perspective on the methods to evaluate GNN accuracy improvements.",2024-07-12,"Floriano Tori, Vincent Holst, Vincent Ginis",http://arxiv.org/pdf/2407.09381v2,cs.LG
Graph Neural Network Causal Explanation via Neural Causal Models,"Graph neural network (GNN) explainers identify the important subgraph that
ensures the prediction for a given graph. Until now, almost all GNN explainers
are based on association, which is prone to spurious correlations. We propose
{\name}, a GNN causal explainer via causal inference. Our explainer is based on
the observation that a graph often consists of a causal underlying subgraph.
{\name} includes three main steps: 1) It builds causal structure and the
corresponding structural causal model (SCM) for a graph, which enables the
cause-effect calculation among nodes. 2) Directly calculating the cause-effect
in real-world graphs is computationally challenging. It is then enlightened by
the recent neural causal model (NCM), a special type of SCM that is trainable,
and design customized NCMs for GNNs. By training these GNN NCMs, the
cause-effect can be easily calculated. 3) It uncovers the subgraph that
causally explains the GNN predictions via the optimized GNN-NCMs. Evaluation
results on multiple synthetic and real-world graphs validate that {\name}
significantly outperforms existing GNN explainers in exact groundtruth
explanation identification",2024-07-12,"Arman Behnam, Binghui Wang",http://arxiv.org/pdf/2407.09378v1,cs.LG
HiPPO-Prophecy: State-Space Models can Provably Learn Dynamical Systems in Context,"This work explores the in-context learning capabilities of State Space Models
(SSMs) and presents, to the best of our knowledge, the first theoretical
explanation of a possible underlying mechanism. We introduce a novel weight
construction for SSMs, enabling them to predict the next state of any dynamical
system after observing previous states without parameter fine-tuning. This is
accomplished by extending the HiPPO framework to demonstrate that continuous
SSMs can approximate the derivative of any input signal. Specifically, we find
an explicit weight construction for continuous SSMs and provide an asymptotic
error bound on the derivative approximation. The discretization of this
continuous SSM subsequently yields a discrete SSM that predicts the next state.
Finally, we demonstrate the effectiveness of our parameterization empirically.
This work should be an initial step toward understanding how sequence models
based on SSMs learn in context.",2024-07-12,"Federico Arangath Joseph, Kilian Konstantin Haefeli, Noah Liniger, Caglar Gulcehre",http://arxiv.org/pdf/2407.09375v2,cs.LG
Towards Personalised Patient Risk Prediction Using Temporal Hospital Data Trajectories,"Quantifying a patient's health status provides clinicians with insight into
patient risk, and the ability to better triage and manage resources. Early
Warning Scores (EWS) are widely deployed to measure overall health status, and
risk of adverse outcomes, in hospital patients. However, current EWS are
limited both by their lack of personalisation and use of static observations.
We propose a pipeline that groups intensive care unit patients by the
trajectories of observations data throughout their stay as a basis for the
development of personalised risk predictions. Feature importance is considered
to provide model explainability. Using the MIMIC-IV dataset, six clusters were
identified, capturing differences in disease codes, observations, lengths of
admissions and outcomes. Applying the pipeline to data from just the first four
hours of each ICU stay assigns the majority of patients to the same cluster as
when the entire stay duration is considered. In-hospital mortality prediction
models trained on individual clusters had higher F1 score performance in five
of the six clusters when compared against the unclustered patient cohort. The
pipeline could form the basis of a clinical decision support tool, working to
improve the clinical characterisation of risk groups and the early detection of
patient deterioration.",2024-07-12,"Thea Barnes, Enrico Werner, Jeffrey N. Clark, Raul Santos-Rodriguez",http://arxiv.org/pdf/2407.09373v1,cs.LG
Learning High-Frequency Functions Made Easy with Sinusoidal Positional Encoding,"Fourier features based positional encoding (PE) is commonly used in machine
learning tasks that involve learning high-frequency features from
low-dimensional inputs, such as 3D view synthesis and time series regression
with neural tangent kernels. Despite their effectiveness, existing PEs require
manual, empirical adjustment of crucial hyperparameters, specifically the
Fourier features, tailored to each unique task. Further, PEs face challenges in
efficiently learning high-frequency functions, particularly in tasks with
limited data. In this paper, we introduce sinusoidal PE (SPE), designed to
efficiently learn adaptive frequency features closely aligned with the true
underlying function. Our experiments demonstrate that SPE, without
hyperparameter tuning, consistently achieves enhanced fidelity and faster
training across various tasks, including 3D view synthesis, Text-to-Speech
generation, and 1D regression. SPE is implemented as a direct replacement for
existing PEs. Its plug-and-play nature lets numerous tasks easily adopt and
benefit from SPE.",2024-07-12,"Chuanhao Sun, Zhihang Yuan, Kai Xu, Luo Mai, N. Siddharth, Shuo Chen, Mahesh K. Marina",http://arxiv.org/pdf/2407.09370v2,cs.LG
Novel clustered federated learning based on local loss,"This paper proposes LCFL, a novel clustering metric for evaluating clients'
data distributions in federated learning. LCFL aligns with federated learning
requirements, accurately assessing client-to-client variations in data
distribution. It offers advantages over existing clustered federated learning
methods, addressing privacy concerns, improving applicability to non-convex
models, and providing more accurate classification results. LCFL does not
require prior knowledge of clients' data distributions. We provide a rigorous
mathematical analysis, demonstrating the correctness and feasibility of our
framework. Numerical experiments with neural network instances highlight the
superior performance of LCFL over baselines on several clustered federated
learning benchmarks.",2024-07-12,"Endong Gu, Yongxin Chen, Hao Wen, Xingju Cai, Deren Han",http://arxiv.org/pdf/2407.09360v1,cs.LG
Any-Property-Conditional Molecule Generation with Self-Criticism using Spanning Trees,"Generating novel molecules is challenging, with most representations leading
to generative models producing many invalid molecules. Spanning Tree-based
Graph Generation (STGG) is a promising approach to ensure the generation of
valid molecules, outperforming state-of-the-art SMILES and graph diffusion
models for unconditional generation. In the real world, we want to be able to
generate molecules conditional on one or multiple desired properties rather
than unconditionally. Thus, in this work, we extend STGG to
multi-property-conditional generation. Our approach, STGG+, incorporates a
modern Transformer architecture, random masking of properties during training
(enabling conditioning on any subset of properties and classifier-free
guidance), an auxiliary property-prediction loss (allowing the model to
self-criticize molecules and select the best ones), and other improvements. We
show that STGG+ achieves state-of-the-art performance on in-distribution and
out-of-distribution conditional generation, and reward maximization.",2024-07-12,"Alexia Jolicoeur-Martineau, Aristide Baratin, Kisoo Kwon, Boris Knyazev, Yan Zhang",http://arxiv.org/pdf/2407.09357v2,cs.LG
Guidelines for Augmentation Selection in Contrastive Learning for Time Series Classification,"Self-supervised contrastive learning has become a key technique in deep
learning, particularly in time series analysis, due to its ability to learn
meaningful representations without explicit supervision. Augmentation is a
critical component in contrastive learning, where different augmentations can
dramatically impact performance, sometimes influencing accuracy by over 30%.
However, the selection of augmentations is predominantly empirical which can be
suboptimal, or grid searching that is time-consuming. In this paper, we
establish a principled framework for selecting augmentations based on dataset
characteristics such as trend and seasonality. Specifically, we construct 12
synthetic datasets incorporating trend, seasonality, and integration weights.
We then evaluate the effectiveness of 8 different augmentations across these
synthetic datasets, thereby inducing generalizable associations between time
series characteristics and augmentation efficiency. Additionally, we evaluated
the induced associations across 6 real-world datasets encompassing domains such
as activity recognition, disease diagnosis, traffic monitoring, electricity
usage, mechanical fault prognosis, and finance. These real-world datasets are
diverse, covering a range from 1 to 12 channels, 2 to 10 classes, sequence
lengths of 14 to 1280, and data frequencies from 250 Hz to daily intervals. The
experimental results show that our proposed trend-seasonality-based
augmentation recommendation algorithm can accurately identify the effective
augmentations for a given time series dataset, achieving an average Recall@3 of
0.667, outperforming baselines. Our work provides guidance for studies
employing contrastive learning in time series analysis, with wide-ranging
applications. All the code, datasets, and analysis results will be released at
https://github.com/DL4mHealth/TS-Contrastive-Augmentation-Recommendation.",2024-07-12,"Ziyu Liu, Azadeh Alavi, Minyi Li, Xiang Zhang",http://arxiv.org/pdf/2407.09336v1,cs.LG
Provable Privacy Advantages of Decentralized Federated Learning via Distributed Optimization,"Federated learning (FL) emerged as a paradigm designed to improve data
privacy by enabling data to reside at its source, thus embedding privacy as a
core consideration in FL architectures, whether centralized or decentralized.
Contrasting with recent findings by Pasquini et al., which suggest that
decentralized FL does not empirically offer any additional privacy or security
benefits over centralized models, our study provides compelling evidence to the
contrary. We demonstrate that decentralized FL, when deploying distributed
optimization, provides enhanced privacy protection - both theoretically and
empirically - compared to centralized approaches. The challenge of quantifying
privacy loss through iterative processes has traditionally constrained the
theoretical exploration of FL protocols. We overcome this by conducting a
pioneering in-depth information-theoretical privacy analysis for both
frameworks. Our analysis, considering both eavesdropping and passive adversary
models, successfully establishes bounds on privacy leakage. We show information
theoretically that the privacy loss in decentralized FL is upper bounded by the
loss in centralized FL. Compared to the centralized case where local gradients
of individual participants are directly revealed, a key distinction of
optimization-based decentralized FL is that the relevant information includes
differences of local gradients over successive iterations and the aggregated
sum of different nodes' gradients over the network. This information
complicates the adversary's attempt to infer private data. To bridge our
theoretical insights with practical applications, we present detailed case
studies involving logistic regression and deep neural networks. These examples
demonstrate that while privacy leakage remains comparable in simpler models,
complex models like deep neural networks exhibit lower privacy risks under
decentralized FL.",2024-07-12,"Wenrui Yu, Qiongxiu Li, Milan Lopuhaä-Zwakenberg, Mads Græsbøll Christensen, Richard Heusdens",http://arxiv.org/pdf/2407.09324v2,cs.LG
Clustering Time-Evolving Networks Using the Spatio-Temporal Graph Laplacian,"Time-evolving graphs arise frequently when modeling complex dynamical systems
such as social networks, traffic flow, and biological processes. Developing
techniques to identify and analyze communities in these time-varying graph
structures is an important challenge. In this work, we generalize existing
spectral clustering algorithms from static to dynamic graphs using canonical
correlation analysis (CCA) to capture the temporal evolution of clusters. Based
on this extended canonical correlation framework, we define the spatio-temporal
graph Laplacian and investigate its spectral properties. We connect these
concepts to dynamical systems theory via transfer operators, and illustrate the
advantages of our method on benchmark graphs by comparison with existing
methods. We show that the spatio-temporal graph Laplacian allows for a clear
interpretation of cluster structure evolution over time for directed and
undirected graphs.",2024-07-12,"Maia Trower, Nataša Djurdjevac Conrad, Stefan Klus",http://arxiv.org/pdf/2407.12864v3,cs.LG
Learning Distances from Data with Normalizing Flows and Score Matching,"Density-based distances (DBDs) offer an elegant solution to the problem of
metric learning. By defining a Riemannian metric which increases with
decreasing probability density, shortest paths naturally follow the data
manifold and points are clustered according to the modes of the data. We show
that existing methods to estimate Fermat distances, a particular choice of DBD,
suffer from poor convergence in both low and high dimensions due to i)
inaccurate density estimates and ii) reliance on graph-based paths which are
increasingly rough in high dimensions. To address these issues, we propose
learning the densities using a normalizing flow, a generative model with
tractable density estimation, and employing a smooth relaxation method using a
score model initialized from a graph-based proposal. Additionally, we introduce
a dimension-adapted Fermat distance that exhibits more intuitive behavior when
scaled to high dimensions and offers better numerical properties. Our work
paves the way for practical use of density-based distances, especially in
high-dimensional spaces.",2024-07-12,"Peter Sorrenson, Daniel Behrend-Uriarte, Christoph Schnörr, Ullrich Köthe",http://arxiv.org/pdf/2407.09297v1,cs.LG
Combining Federated Learning and Control: A Survey,"This survey provides an overview of combining Federated Learning (FL) and
control to enhance adaptability, scalability, generalization, and privacy in
(nonlinear) control applications. Traditional control methods rely on
controller design models, but real-world scenarios often require online model
retuning or learning. FL offers a distributed approach to model training,
enabling collaborative learning across distributed devices while preserving
data privacy. By keeping data localized, FL mitigates concerns regarding
privacy and security while reducing network bandwidth requirements for
communication. This survey summarizes the state-of-the-art concepts and ideas
of combining FL and control. The methodical benefits are further discussed,
culminating in a detailed overview of expected applications, from dynamical
system modeling over controller design, focusing on adaptive control, to
knowledge transfer in multi-agent decision-making systems.",2024-07-12,"Jakob Weber, Markus Gurtner, Amadeus Lobe, Adrian Trachte, Andreas Kugi",http://arxiv.org/pdf/2407.11069v2,cs.LG
H2O-Danube3 Technical Report,"We present H2O-Danube3, a series of small language models consisting of
H2O-Danube3-4B, trained on 6T tokens and H2O-Danube3-500M, trained on 4T
tokens. Our models are pre-trained on high quality Web data consisting of
primarily English tokens in three stages with different data mixes before final
supervised tuning for chat version. The models exhibit highly competitive
metrics across a multitude of academic, chat, and fine-tuning benchmarks.
Thanks to its compact architecture, H2O-Danube3 can be efficiently run on a
modern smartphone, enabling local inference and rapid processing capabilities
even on mobile devices. We make all models openly available under Apache 2.0
license further democratizing LLMs to a wider audience economically.",2024-07-12,"Pascal Pfeiffer, Philipp Singer, Yauhen Babakhin, Gabor Fodor, Nischay Dhankhar, Sri Satish Ambati",http://arxiv.org/pdf/2407.09276v1,cs.LG
"Unifying Sequences, Structures, and Descriptions for Any-to-Any Protein Generation with the Large Multimodal Model HelixProtX","Proteins are fundamental components of biological systems and can be
represented through various modalities, including sequences, structures, and
textual descriptions. Despite the advances in deep learning and scientific
large language models (LLMs) for protein research, current methodologies
predominantly focus on limited specialized tasks -- often predicting one
protein modality from another. These approaches restrict the understanding and
generation of multimodal protein data. In contrast, large multimodal models
have demonstrated potential capabilities in generating any-to-any content like
text, images, and videos, thus enriching user interactions across various
domains. Integrating these multimodal model technologies into protein research
offers significant promise by potentially transforming how proteins are
studied. To this end, we introduce HelixProtX, a system built upon the large
multimodal model, aiming to offer a comprehensive solution to protein research
by supporting any-to-any protein modality generation. Unlike existing methods,
it allows for the transformation of any input protein modality into any desired
protein modality. The experimental results affirm the advanced capabilities of
HelixProtX, not only in generating functional descriptions from amino acid
sequences but also in executing critical tasks such as designing protein
sequences and structures from textual descriptions. Preliminary findings
indicate that HelixProtX consistently achieves superior accuracy across a range
of protein-related tasks, outperforming existing state-of-the-art models. By
integrating multimodal large models into protein research, HelixProtX opens new
avenues for understanding protein biology, thereby promising to accelerate
scientific discovery.",2024-07-12,"Zhiyuan Chen, Tianhao Chen, Chenggang Xie, Yang Xue, Xiaonan Zhang, Jingbo Zhou, Xiaomin Fang",http://arxiv.org/pdf/2407.09274v1,cs.LG
iNeMo: Incremental Neural Mesh Models for Robust Class-Incremental Learning,"Different from human nature, it is still common practice today for vision
tasks to train deep learning models only initially and on fixed datasets. A
variety of approaches have recently addressed handling continual data streams.
However, extending these methods to manage out-of-distribution (OOD) scenarios
has not effectively been investigated. On the other hand, it has recently been
shown that non-continual neural mesh models exhibit strong performance in
generalizing to such OOD scenarios. To leverage this decisive property in a
continual learning setting, we propose incremental neural mesh models that can
be extended with new meshes over time. In addition, we present a latent space
initialization strategy that enables us to allocate feature space for future
unseen classes in advance and a positional regularization term that forces the
features of the different classes to consistently stay in respective latent
space regions. We demonstrate the effectiveness of our method through extensive
experiments on the Pascal3D and ObjectNet3D datasets and show that our approach
outperforms the baselines for classification by $2-6\%$ in the in-domain and by
$6-50\%$ in the OOD setting. Our work also presents the first incremental
learning approach for pose estimation. Our code and model can be found at
https://github.com/Fischer-Tom/iNeMo.",2024-07-12,"Tom Fischer, Yaoyao Liu, Artur Jesslen, Noor Ahmed, Prakhar Kaushik, Angtian Wang, Alan Yuille, Adam Kortylewski, Eddy Ilg",http://arxiv.org/pdf/2407.09271v2,cs.LG
Deep Adversarial Defense Against Multilevel-Lp Attacks,"Deep learning models have shown considerable vulnerability to adversarial
attacks, particularly as attacker strategies become more sophisticated. While
traditional adversarial training (AT) techniques offer some resilience, they
often focus on defending against a single type of attack, e.g., the
$\ell_\infty$-norm attack, which can fail for other types. This paper
introduces a computationally efficient multilevel $\ell_p$ defense, called the
Efficient Robust Mode Connectivity (EMRC) method, which aims to enhance a deep
learning model's resilience against multiple $\ell_p$-norm attacks. Similar to
analytical continuation approaches used in continuous optimization, the method
blends two $p$-specific adversarially optimal models, the $\ell_1$- and
$\ell_\infty$-norm AT solutions, to provide good adversarial robustness for a
range of $p$. We present experiments demonstrating that our approach performs
better on various attacks as compared to AT-$\ell_\infty$, E-AT, and MSD, for
datasets/architectures including: CIFAR-10, CIFAR-100 / PreResNet110,
WideResNet, ViT-Base.",2024-07-12,"Ren Wang, Yuxuan Li, Alfred Hero",http://arxiv.org/pdf/2407.09251v1,cs.LG
FedsLLM: Federated Split Learning for Large Language Models over Communication Networks,"Addressing the challenges of deploying large language models in wireless
communication networks, this paper combines low-rank adaptation technology
(LoRA) with the splitfed learning framework to propose the federated split
learning for large language models (FedsLLM) framework. The method introduced
in this paper utilizes LoRA technology to reduce processing loads by dividing
the network into client subnetworks and server subnetworks. It leverages a
federated server to aggregate and update client models. As the training data
are transmitted through a wireless network between clients and both main and
federated servers, the training delay is determined by the learning accuracy
and the allocation of communication bandwidth. This paper models the
minimization of the training delay by integrating computation and communication
optimization, simplifying the optimization problem into a convex problem to
find the optimal solution. Additionally, it presents a lemma that describes the
precise solutions to this problem. Simulation results demonstrate that the
proposed optimization algorithm reduces delays by an average of 47.63% compared
to unoptimized scenarios.",2024-07-12,"Kai Zhao, Zhaohui Yang, Chongwen Huang, Xiaoming Chen, Zhaoyang Zhang",http://arxiv.org/pdf/2407.09250v1,cs.LG
A Fair Ranking and New Model for Panoptic Scene Graph Generation,"In panoptic scene graph generation (PSGG), models retrieve interactions
between objects in an image which are grounded by panoptic segmentation masks.
Previous evaluations on panoptic scene graphs have been subject to an erroneous
evaluation protocol where multiple masks for the same object can lead to
multiple relation distributions per mask-mask pair. This can be exploited to
increase the final score. We correct this flaw and provide a fair ranking over
a wide range of existing PSGG models. The observed scores for existing methods
increase by up to 7.4 mR@50 for all two-stage methods, while dropping by up to
19.3 mR@50 for all one-stage methods, highlighting the importance of a correct
evaluation. Contrary to recent publications, we show that existing two-stage
methods are competitive to one-stage methods. Building on this, we introduce
the Decoupled SceneFormer (DSFormer), a novel two-stage model that outperforms
all existing scene graph models by a large margin of +11 mR@50 and +10 mNgR@50
on the corrected evaluation, thus setting a new SOTA. As a core design
principle, DSFormer encodes subject and object masks directly into feature
space.",2024-07-12,"Julian Lorenz, Alexander Pest, Daniel Kienzle, Katja Ludwig, Rainer Lienhart",http://arxiv.org/pdf/2407.09216v1,cs.LG
Generating $SROI^-$ Ontologies via Knowledge Graph Query Embedding Learning,"Query embedding approaches answer complex logical queries over incomplete
knowledge graphs (KGs) by computing and operating on low-dimensional vector
representations of entities, relations, and queries. However, current query
embedding models heavily rely on excessively parameterized neural networks and
cannot explain the knowledge learned from the graph. We propose a novel query
embedding method, AConE, which explains the knowledge learned from the graph in
the form of $SROI^-$ description logic axioms while being more
parameter-efficient than most existing approaches. AConE associates queries to
a $SROI^-$ description logic concept. Every $SROI^-$ concept is embedded as a
cone in complex vector space, and each $SROI^-$ relation is embedded as a
transformation that rotates and scales cones. We show theoretically that AConE
can learn $SROI^-$ axioms, and defines an algebra whose operations correspond
one to one to $SROI^-$ description logic concept constructs. Our empirical
study on multiple query datasets shows that AConE achieves superior results
over previous baselines with fewer parameters. Notably on the WN18RR dataset,
AConE achieves significant improvement over baseline models. We provide
comprehensive analyses showing that the capability to represent axioms
positively impacts the results of query answering.",2024-07-12,"Yunjie He, Daniel Hernandez, Mojtaba Nayyeri, Bo Xiong, Yuqicheng Zhu, Evgeny Kharlamov, Steffen Staab",http://arxiv.org/pdf/2407.09212v4,cs.LG
A Survey on Symbolic Knowledge Distillation of Large Language Models,"This survey paper delves into the emerging and critical area of symbolic
knowledge distillation in Large Language Models (LLMs). As LLMs like Generative
Pre-trained Transformer-3 (GPT-3) and Bidirectional Encoder Representations
from Transformers (BERT) continue to expand in scale and complexity, the
challenge of effectively harnessing their extensive knowledge becomes
paramount. This survey concentrates on the process of distilling the intricate,
often implicit knowledge contained within these models into a more symbolic,
explicit form. This transformation is crucial for enhancing the
interpretability, efficiency, and applicability of LLMs. We categorize the
existing research based on methodologies and applications, focusing on how
symbolic knowledge distillation can be used to improve the transparency and
functionality of smaller, more efficient Artificial Intelligence (AI) models.
The survey discusses the core challenges, including maintaining the depth of
knowledge in a comprehensible format, and explores the various approaches and
techniques that have been developed in this field. We identify gaps in current
research and potential opportunities for future advancements. This survey aims
to provide a comprehensive overview of symbolic knowledge distillation in LLMs,
spotlighting its significance in the progression towards more accessible and
efficient AI systems.",2024-07-12,"Kamal Acharya, Alvaro Velasquez, Houbing Herbert Song",http://arxiv.org/pdf/2408.10210v1,cs.LG
Variational Inference via Smoothed Particle Hydrodynamics,"A new variational inference method, SPH-ParVI, based on smoothed particle
hydrodynamics (SPH), is proposed for sampling partially known densities (e.g.
up to a constant) or sampling using gradients. SPH-ParVI simulates the flow of
a fluid under external effects driven by the target density; transient or
steady state of the fluid approximates the target density. The continuum fluid
is modelled as an interacting particle system (IPS) via SPH, where each
particle carries smoothed properties, interacts and evolves as per the
Navier-Stokes equations. This mesh-free, Lagrangian simulation method offers
fast, flexible, scalable and deterministic sampling and inference for a class
of probabilistic models such as those encountered in Bayesian inference and
generative modelling.",2024-07-12,Yongchao Huang,http://arxiv.org/pdf/2407.09186v2,cs.LG
Conformal Inductive Graph Neural Networks,"Conformal prediction (CP) transforms any model's output into prediction sets
guaranteed to include (cover) the true label. CP requires exchangeability, a
relaxation of the i.i.d. assumption, to obtain a valid distribution-free
coverage guarantee. This makes it directly applicable to transductive
node-classification. However, conventional CP cannot be applied in inductive
settings due to the implicit shift in the (calibration) scores caused by
message passing with the new nodes. We fix this issue for both cases of node
and edge-exchangeable graphs, recovering the standard coverage guarantee
without sacrificing statistical efficiency. We further prove that the guarantee
holds independently of the prediction time, e.g. upon arrival of a new
node/edge or at any subsequent moment.",2024-07-12,"Soroush H. Zargarbashi, Aleksandar Bojchevski",http://arxiv.org/pdf/2407.09173v1,cs.LG
SE(3)-bi-equivariant Transformers for Point Cloud Assembly,"Given a pair of point clouds, the goal of assembly is to recover a rigid
transformation that aligns one point cloud to the other. This task is
challenging because the point clouds may be non-overlapped, and they may have
arbitrary initial positions. To address these difficulties, we propose a
method, called SE(3)-bi-equivariant transformer (BITR), based on the
SE(3)-bi-equivariance prior of the task: it guarantees that when the inputs are
rigidly perturbed, the output will transform accordingly. Due to its
equivariance property, BITR can not only handle non-overlapped PCs, but also
guarantee robustness against initial positions. Specifically, BITR first
extracts features of the inputs using a novel $SE(3) \times SE(3)$-transformer,
and then projects the learned feature to group SE(3) as the output. Moreover,
we theoretically show that swap and scale equivariances can be incorporated
into BITR, thus it further guarantees stable performance under scaling and
swapping the inputs. We experimentally show the effectiveness of BITR in
practical tasks.",2024-07-12,"Ziming Wang, Rebecka Jörnsten",http://arxiv.org/pdf/2407.09167v3,cs.LG
Robust Yet Efficient Conformal Prediction Sets,"Conformal prediction (CP) can convert any model's output into prediction sets
guaranteed to include the true label with any user-specified probability.
However, same as the model itself, CP is vulnerable to adversarial test
examples (evasion) and perturbed calibration data (poisoning). We derive
provably robust sets by bounding the worst-case change in conformity scores.
Our tighter bounds lead to more efficient sets. We cover both continuous and
discrete (sparse) data and our guarantees work both for evasion and poisoning
attacks (on both features and labels).",2024-07-12,"Soroush H. Zargarbashi, Mohammad Sadegh Akhondzadeh, Aleksandar Bojchevski",http://arxiv.org/pdf/2407.09165v1,cs.LG
Exploring State Space and Reasoning by Elimination in Tsetlin Machines,"The Tsetlin Machine (TM) has gained significant attention in Machine Learning
(ML). By employing logical fundamentals, it facilitates pattern learning and
representation, offering an alternative approach for developing comprehensible
Artificial Intelligence (AI) with a specific focus on pattern classification in
the form of conjunctive clauses. In the domain of Natural Language Processing
(NLP), TM is utilised to construct word embedding and describe target words
using clauses. To enhance the descriptive capacity of these clauses, we study
the concept of Reasoning by Elimination (RbE) in clauses' formulation, which
involves incorporating feature negations to provide a more comprehensive
representation. In more detail, this paper employs the Tsetlin Machine
Auto-Encoder (TM-AE) architecture to generate dense word vectors, aiming at
capturing contextual information by extracting feature-dense vectors for a
given vocabulary. Thereafter, the principle of RbE is explored to improve
descriptivity and optimise the performance of the TM. Specifically, the
specificity parameter s and the voting margin parameter T are leveraged to
regulate feature distribution in the state space, resulting in a dense
representation of information for each clause. In addition, we investigate the
state spaces of TM-AE, especially for the forgotten/excluded features.
Empirical investigations on artificially generated data, the IMDB dataset, and
the 20 Newsgroups dataset showcase the robustness of the TM, with accuracy
reaching 90.62\% for the IMDB.",2024-07-12,"Ahmed K. Kadhim, Ole-Christoffer Granmo, Lei Jiao, Rishad Shafik",http://arxiv.org/pdf/2407.09162v2,cs.LG
Movie Recommendation with Poster Attention via Multi-modal Transformer Feature Fusion,"Pre-trained models learn general representations from large datsets which can
be fine-turned for specific tasks to significantly reduce training time.
Pre-trained models like generative pretrained transformers (GPT), bidirectional
encoder representations from transformers (BERT), vision transfomers (ViT) have
become a cornerstone of current research in machine learning. This study
proposes a multi-modal movie recommendation system by extract features of the
well designed posters for each movie and the narrative text description of the
movie. This system uses the BERT model to extract the information of text
modality, the ViT model applied to extract the information of poster/image
modality, and the Transformer architecture for feature fusion of all modalities
to predict users' preference. The integration of pre-trained foundational
models with some smaller data sets in downstream applications capture
multi-modal content features in a more comprehensive manner, thereby providing
more accurate recommendations. The efficiency of the proof-of-concept model is
verified by the standard benchmark problem the MovieLens 100K and 1M datasets.
The prediction accuracy of user ratings is enhanced in comparison to the
baseline algorithm, thereby demonstrating the potential of this cross-modal
algorithm to be applied for movie or video recommendation.",2024-07-12,"Linhan Xia, Yicheng Yang, Ziou Chen, Zheng Yang, Shengxin Zhu",http://arxiv.org/pdf/2407.09157v1,cs.LG
Evaluating the Adversarial Robustness of Semantic Segmentation: Trying Harder Pays Off,"Machine learning models are vulnerable to tiny adversarial input
perturbations optimized to cause a very large output error. To measure this
vulnerability, we need reliable methods that can find such adversarial
perturbations. For image classification models, evaluation methodologies have
emerged that have stood the test of time. However, we argue that in the area of
semantic segmentation, a good approximation of the sensitivity to adversarial
perturbations requires significantly more effort than what is currently
considered satisfactory. To support this claim, we re-evaluate a number of
well-known robust segmentation models in an extensive empirical study. We
propose new attacks and combine them with the strongest attacks available in
the literature. We also analyze the sensitivity of the models in fine detail.
The results indicate that most of the state-of-the-art models have a
dramatically larger sensitivity to adversarial perturbations than previously
reported. We also demonstrate a size-bias: small objects are often more easily
attacked, even if the large objects are robust, a phenomenon not revealed by
current evaluation metrics. Our results also demonstrate that a diverse set of
strong attacks is necessary, because different models are often vulnerable to
different attacks.",2024-07-12,"Levente Halmosi, Bálint Mohos, Márk Jelasity",http://arxiv.org/pdf/2407.09150v1,cs.LG
Accuracy is Not All You Need,"When Large Language Models (LLMs) are compressed using techniques such as
quantization, the predominant way to demonstrate the validity of such
techniques is by measuring the model's accuracy on various benchmarks.If the
accuracies of the baseline model and the compressed model are close, it is
assumed that there was negligible degradation in quality.However, even when the
accuracy of baseline and compressed model are similar, we observe the
phenomenon of flips, wherein answers change from correct to incorrect and vice
versa in proportion.We conduct a detailed study of metrics across multiple
compression techniques, models and datasets, demonstrating that the behavior of
compressed models as visible to end-users is often significantly different from
the baseline model, even when accuracy is similar.We further evaluate
compressed models qualitatively and quantitatively using MT-Bench and show that
compressed models are significantly worse than baseline models in this
free-form generative task.Thus, we argue that compression techniques should
also be evaluated using distance metrics.We propose two such metrics,
KL-Divergence and flips, and show that they are well correlated.",2024-07-12,"Abhinav Dutta, Sanjeev Krishnan, Nipun Kwatra, Ramachandran Ramjee",http://arxiv.org/pdf/2407.09141v1,cs.LG
Stepwise Verification and Remediation of Student Reasoning Errors with Large Language Model Tutors,"Large language models (LLMs) present an opportunity to scale high-quality
personalized education to all. A promising approach towards this means is to
build dialog tutoring models that scaffold students' problem-solving. However,
even though existing LLMs perform well in solving reasoning questions, they
struggle to precisely detect student's errors and tailor their feedback to
these errors. Inspired by real-world teaching practice where teachers identify
student errors and customize their response based on them, we focus on
verifying student solutions and show how grounding to such verification
improves the overall quality of tutor response generation. We collect a dataset
of 1K stepwise math reasoning chains with the first error step annotated by
teachers. We show empirically that finding the mistake in a student solution is
challenging for current models. We propose and evaluate several verifiers for
detecting these errors. Using both automatic and human evaluation we show that
the student solution verifiers steer the generation model towards highly
targeted responses to student errors which are more often correct with less
hallucinations compared to existing baselines.",2024-07-12,"Nico Daheim, Jakub Macina, Manu Kapur, Iryna Gurevych, Mrinmaya Sachan",http://arxiv.org/pdf/2407.09136v1,cs.LG
Robustness of Explainable Artificial Intelligence in Industrial Process Modelling,"eXplainable Artificial Intelligence (XAI) aims at providing understandable
explanations of black box models. In this paper, we evaluate current XAI
methods by scoring them based on ground truth simulations and sensitivity
analysis. To this end, we used an Electric Arc Furnace (EAF) model to better
understand the limits and robustness characteristics of XAI methods such as
SHapley Additive exPlanations (SHAP), Local Interpretable Model-agnostic
Explanations (LIME), as well as Averaged Local Effects (ALE) or Smooth
Gradients (SG) in a highly topical setting. These XAI methods were applied to
various types of black-box models and then scored based on their correctness
compared to the ground-truth sensitivity of the data-generating processes using
a novel scoring evaluation methodology over a range of simulated additive
noise. The resulting evaluation shows that the capability of the Machine
Learning (ML) models to capture the process accurately is, indeed, coupled with
the correctness of the explainability of the underlying data-generating
process. We furthermore show the differences between XAI methods in their
ability to correctly predict the true sensitivity of the modeled industrial
process.",2024-07-12,"Benedikt Kantz, Clemens Staudinger, Christoph Feilmayr, Johannes Wachlmayr, Alexander Haberl, Stefan Schuster, Franz Pernkopf",http://arxiv.org/pdf/2407.09127v2,cs.LG
Decentralized multi-agent reinforcement learning algorithm using a cluster-synchronized laser network,"Multi-agent reinforcement learning (MARL) studies crucial principles that are
applicable to a variety of fields, including wireless networking and autonomous
driving. We propose a photonic-based decision-making algorithm to address one
of the most fundamental problems in MARL, called the competitive multi-armed
bandit (CMAB) problem. Our numerical simulations demonstrate that chaotic
oscillations and cluster synchronization of optically coupled lasers, along
with our proposed decentralized coupling adjustment, efficiently balance
exploration and exploitation while facilitating cooperative decision-making
without explicitly sharing information among agents. Our study demonstrates how
decentralized reinforcement learning can be achieved by exploiting complex
physical processes controlled by simple algorithms.",2024-07-12,"Shun Kotoku, Takatomo Mihana, André Röhm, Ryoichi Horisaki",http://arxiv.org/pdf/2407.09124v1,cs.LG
URRL-IMVC: Unified and Robust Representation Learning for Incomplete Multi-View Clustering,"Incomplete multi-view clustering (IMVC) aims to cluster multi-view data that
are only partially available. This poses two main challenges: effectively
leveraging multi-view information and mitigating the impact of missing views.
Prevailing solutions employ cross-view contrastive learning and missing view
recovery techniques. However, they either neglect valuable complementary
information by focusing only on consensus between views or provide unreliable
recovered views due to the absence of supervision. To address these
limitations, we propose a novel Unified and Robust Representation Learning for
Incomplete Multi-View Clustering (URRL-IMVC). URRL-IMVC directly learns a
unified embedding that is robust to view missing conditions by integrating
information from multiple views and neighboring samples. Firstly, to overcome
the limitations of cross-view contrastive learning, URRL-IMVC incorporates an
attention-based auto-encoder framework to fuse multi-view information and
generate unified embeddings. Secondly, URRL-IMVC directly enhances the
robustness of the unified embedding against view-missing conditions through KNN
imputation and data augmentation techniques, eliminating the need for explicit
missing view recovery. Finally, incremental improvements are introduced to
further enhance the overall performance, such as the Clustering Module and the
customization of the Encoder. We extensively evaluate the proposed URRL-IMVC
framework on various benchmark datasets, demonstrating its state-of-the-art
performance. Furthermore, comprehensive ablation studies are performed to
validate the effectiveness of our design.",2024-07-12,"Ge Teng, Ting Mao, Chen Shen, Xiang Tian, Xuesong Liu, Yaowu Chen, Jieping Ye",http://arxiv.org/pdf/2407.09120v1,cs.LG
Inference Optimization of Foundation Models on AI Accelerators,"Powerful foundation models, including large language models (LLMs), with
Transformer architectures have ushered in a new era of Generative AI across
various industries. Industry and research community have witnessed a large
number of new applications, based on those foundation models. Such applications
include question and answer, customer services, image and video generation, and
code completions, among others. However, as the number of model parameters
reaches to hundreds of billions, their deployment incurs prohibitive inference
costs and high latency in real-world scenarios. As a result, the demand for
cost-effective and fast inference using AI accelerators is ever more higher. To
this end, our tutorial offers a comprehensive discussion on complementary
inference optimization techniques using AI accelerators. Beginning with an
overview of basic Transformer architectures and deep learning system
frameworks, we deep dive into system optimization techniques for fast and
memory-efficient attention computations and discuss how they can be implemented
efficiently on AI accelerators. Next, we describe architectural elements that
are key for fast transformer inference. Finally, we examine various model
compression and fast decoding strategies in the same context.",2024-07-12,"Youngsuk Park, Kailash Budhathoki, Liangfu Chen, Jonas Kübler, Jiaji Huang, Matthäus Kleindessner, Jun Huan, Volkan Cevher, Yida Wang, George Karypis",http://arxiv.org/pdf/2407.09111v2,cs.LG
Enhancing Training Efficiency Using Packing with Flash Attention,"Padding is often used in tuning LLM models by adding special tokens to
shorter training examples to match the length of the longest sequence in each
batch. While this ensures uniformity for batch processing, it introduces
inefficiencies by including irrelevant padding tokens in the computation and
wastes GPU resources. Hugging Face SFT trainer has always offered the option to
use packing to combine multiple training examples, allowing for maximal
utilization of GPU resources. However, up till now, it did not offer proper
masking of each packed training example. This capability has been added to
Hugging Face Transformers 4.44. We analyse this new feature and show the
benefits across different variations of packing.",2024-07-12,"Achintya Kundu, Rhui Dih Lee, Laura Wynter, Raghu Kiran Ganti, Mayank Mishra",http://arxiv.org/pdf/2407.09105v6,cs.LG
UserBoost: Generating User-specific Synthetic Data for Faster Enrolment into Behavioural Biometric Systems,"Behavioural biometric authentication systems entail an enrolment period that
is burdensome for the user. In this work, we explore generating synthetic
gestures from a few real user gestures with generative deep learning, with the
application of training a simple (i.e. non-deep-learned) authentication model.
Specifically, we show that utilising synthetic data alongside real data can
reduce the number of real datapoints a user must provide to enrol into a
biometric system. To validate our methods, we use the publicly available
dataset of WatchAuth, a system proposed in 2022 for authenticating smartwatch
payments using the physical gesture of reaching towards a payment terminal. We
develop a regularised autoencoder model for generating synthetic user-specific
wrist motion data representing these physical gestures, and demonstrate the
diversity and fidelity of our synthetic gestures. We show that using synthetic
gestures in training can improve classification ability for a real-world
system. Through this technique we can reduce the number of gestures required to
enrol a user into a WatchAuth-like system by more than 40% without negatively
impacting its error rates.",2024-07-12,"George Webber, Jack Sturgess, Ivan Martinovic",http://arxiv.org/pdf/2407.09104v1,cs.LG
STD-PLM: Understanding Both Spatial and Temporal Properties of Spatial-Temporal Data with PLM,"Spatial-temporal forecasting and imputation are important for real-world
intelligent systems. Most existing methods are tailored for individual
forecasting or imputation tasks but are not designed for both. Additionally,
they are less effective for zero-shot and few-shot learning. While pre-trained
language model (PLM) have exhibited strong pattern recognition and reasoning
abilities across various tasks, including few-shot and zero-shot learning,
their applications in spatial-temporal data understanding has been constrained
by insufficient modeling of complex correlations such as the temporal
correlations, spatial connectivity, non-pairwise and high-order
spatial-temporal correlations within data. In this paper, we propose STD-PLM
for understanding both spatial and temporal properties of
\underline{S}patial-\underline{T}emporal \underline{D}ata with \underline{PLM},
which is capable of implementing both spatial-temporal forecasting and
imputation tasks. STD-PLM understands spatial-temporal correlations via
explicitly designed spatial and temporal tokenizers. Topology-aware node
embeddings are designed for PLM to comprehend and exploit the topology
structure of data in inductive manner. Furthermore, to mitigate the efficiency
issues introduced by the PLM, we design a sandglass attention module (SGA)
combined with a specific constrained loss function, which significantly
improves the model's efficiency while ensuring performance. Extensive
experiments demonstrate that STD-PLM exhibits competitive performance and
generalization capabilities across the forecasting and imputation tasks on
various datasets. Moreover, STD-PLM achieves promising results on both few-shot
and zero-shot tasks. The code is made available at
\href{https://github.com/Hyheng/STD-PLM}{https://github.com/Hyheng/STD-PLM}",2024-07-12,"YiHeng Huang, Xiaowei Mao, Shengnan Guo, Yubin Chen, Junfeng Shen, Tiankuo Li, Youfang Lin, Huaiyu Wan",http://arxiv.org/pdf/2407.09096v4,cs.LG
On Exact Bit-level Reversible Transformers Without Changing Architectures,"Various reversible deep neural networks (DNN) models have been proposed to
reduce memory consumption in the training process. However, almost all existing
reversible DNNs either require special non-standard architectures or are
constructed by modifying existing DNN architectures considerably to enable
reversibility. In this work we present the BDIA-transformer, which is an exact
bit-level reversible transformer that uses an unchanged standard architecture
for inference. The basic idea is to first treat each transformer block as the
Euler integration approximation for solving an ordinary differential equation
(ODE) and then incorporate the technique of bidirectional integration
approximation (BDIA) into the neural architecture, together with activation
quantization to make it exactly bit-level reversible. In the training process,
we let a hyper-parameter $\gamma$ in BDIA-transformer randomly take one of the
two values $\{0.5, -0.5\}$ per training sample per transformer block for
averaging every two consecutive integration approximations. As a result,
BDIA-transformer can be viewed as training an ensemble of ODE solvers
parameterized by a set of binary random variables, which regularizes the model
and results in improved validation accuracy. Lightweight side information per
transformer block is required to be stored in the forward process to account
for binary quantization loss to enable exact bit-level reversibility. In the
inference procedure, the expectation $\mathbb{E}(\gamma)=0$ is taken to make
the resulting architectures of BDIA-transformer identical to transformers up to
activation quantization. Our experiments in both image classification and
language translation show that BDIA-transformers outperform their conventional
counterparts significantly in terms of validation performance while also
requiring considerably less training memory.",2024-07-12,"Guoqiang Zhang, J. P. Lewis, W. B. Kleijn",http://arxiv.org/pdf/2407.09093v2,cs.LG
On the Role of Discrete Tokenization in Visual Representation Learning,"In the realm of self-supervised learning (SSL), masked image modeling (MIM)
has gained popularity alongside contrastive learning methods. MIM involves
reconstructing masked regions of input images using their unmasked portions. A
notable subset of MIM methodologies employs discrete tokens as the
reconstruction target, but the theoretical underpinnings of this choice remain
underexplored. In this paper, we explore the role of these discrete tokens,
aiming to unravel their benefits and limitations. Building upon the connection
between MIM and contrastive learning, we provide a comprehensive theoretical
understanding on how discrete tokenization affects the model's generalization
capabilities. Furthermore, we propose a novel metric named TCAS, which is
specifically designed to assess the effectiveness of discrete tokens within the
MIM framework. Inspired by this metric, we contribute an innovative tokenizer
design and propose a corresponding MIM method named ClusterMIM. It demonstrates
superior performance on a variety of benchmark datasets and ViT backbones. Code
is available at https://github.com/PKU-ML/ClusterMIM.",2024-07-12,"Tianqi Du, Yifei Wang, Yisen Wang",http://arxiv.org/pdf/2407.09087v1,cs.LG
Multi-Modal Dataset Creation for Federated Learning with DICOM Structured Reports,"Purpose: Federated training is often hindered by heterogeneous datasets due
to divergent data storage options, inconsistent naming schemes, varied
annotation procedures, and disparities in label quality. This is particularly
evident in the emerging multi-modal learning paradigms, where dataset
harmonization including a uniform data representation and filtering options are
of paramount importance.
  Methods: DICOM structured reports enable the standardized linkage of
arbitrary information beyond the imaging domain and can be used within Python
deep learning pipelines with highdicom. Building on this, we developed an open
platform for data integration and interactive filtering capabilities that
simplifies the process of assembling multi-modal datasets.
  Results: In this study, we extend our prior work by showing its applicability
to more and divergent data types, as well as streamlining datasets for
federated training within an established consortium of eight university
hospitals in Germany. We prove its concurrent filtering ability by creating
harmonized multi-modal datasets across all locations for predicting the outcome
after minimally invasive heart valve replacement. The data includes DICOM data
(i.e. computed tomography images, electrocardiography scans) as well as
annotations (i.e. calcification segmentations, pointsets and pacemaker
dependency), and metadata (i.e. prosthesis and diagnoses).
  Conclusion: Structured reports bridge the traditional gap between imaging
systems and information systems. Utilizing the inherent DICOM reference system
arbitrary data types can be queried concurrently to create meaningful cohorts
for clinical studies. The graphical interface as well as example structured
report templates will be made publicly available.",2024-07-12,"Malte Tölle, Lukas Burger, Halvar Kelm, Florian André, Peter Bannas, Gerhard Diller, Norbert Frey, Philipp Garthe, Stefan Groß, Anja Hennemuth, Lars Kaderali, Nina Krüger, Andreas Leha, Simon Martin, Alexander Meyer, Eike Nagel, Stefan Orwat, Clemens Scherer, Moritz Seiffert, Jan Moritz Seliger, Stefan Simm, Tim Friede, Tim Seidler, Sandy Engelhardt",http://arxiv.org/pdf/2407.09064v2,cs.LG
Spectral Self-supervised Feature Selection,"Choosing a meaningful subset of features from high-dimensional observations
in unsupervised settings can greatly enhance the accuracy of downstream
analysis, such as clustering or dimensionality reduction, and provide valuable
insights into the sources of heterogeneity in a given dataset. In this paper,
we propose a self-supervised graph-based approach for unsupervised feature
selection. Our method's core involves computing robust pseudo-labels by
applying simple processing steps to the graph Laplacian's eigenvectors. The
subset of eigenvectors used for computing pseudo-labels is chosen based on a
model stability criterion. We then measure the importance of each feature by
training a surrogate model to predict the pseudo-labels from the observations.
Our approach is shown to be robust to challenging scenarios, such as the
presence of outliers and complex substructures. We demonstrate the
effectiveness of our method through experiments on real-world datasets, showing
its robustness across multiple domains, particularly its effectiveness on
biological datasets.",2024-07-12,"Daniel Segal, Ofir Lindenbaum, Ariel Jaffe",http://arxiv.org/pdf/2407.09061v2,cs.LG
Advanced Graph Clustering Methods: A Comprehensive and In-Depth Analysis,"Graph clustering, which aims to divide a graph into several homogeneous
groups, is a critical area of study with applications that span various fields
such as social network analysis, bioinformatics, and image segmentation. This
paper explores both traditional and more recent approaches to graph clustering.
Firstly, key concepts and definitions in graph theory are introduced. The
background section covers essential topics, including graph Laplacians and the
integration of Deep Learning in graph analysis. The paper then delves into
traditional clustering methods, including Spectral Clustering and the Leiden
algorithm. Following this, state-of-the-art clustering techniques that leverage
deep learning are examined. A comprehensive comparison of these methods is made
through experiments. The paper concludes with a discussion of the practical
applications of graph clustering and potential future research directions.",2024-07-12,"Timothé Watteau, Aubin Bonnefoy, Simon Illouz-Laurent, Joaquim Jusseau, Serge Iovleff",http://arxiv.org/pdf/2407.09055v1,cs.LG
Refusing Safe Prompts for Multi-modal Large Language Models,"Multimodal large language models (MLLMs) have become the cornerstone of
today's generative AI ecosystem, sparking intense competition among tech giants
and startups. In particular, an MLLM generates a text response given a prompt
consisting of an image and a question. While state-of-the-art MLLMs use safety
filters and alignment techniques to refuse unsafe prompts, in this work, we
introduce MLLM-Refusal, the first method that induces refusals for safe
prompts. In particular, our MLLM-Refusal optimizes a nearly-imperceptible
refusal perturbation and adds it to an image, causing target MLLMs to likely
refuse a safe prompt containing the perturbed image and a safe question.
Specifically, we formulate MLLM-Refusal as a constrained optimization problem
and propose an algorithm to solve it. Our method offers competitive advantages
for MLLM model providers by potentially disrupting user experiences of
competing MLLMs, since competing MLLM's users will receive unexpected refusals
when they unwittingly use these perturbed images in their prompts. We evaluate
MLLM-Refusal on four MLLMs across four datasets, demonstrating its
effectiveness in causing competing MLLMs to refuse safe prompts while not
affecting non-competing MLLMs. Furthermore, we explore three potential
countermeasures-adding Gaussian noise, DiffPure, and adversarial training. Our
results show that though they can mitigate MLLM-Refusal's effectiveness, they
also sacrifice the accuracy and/or efficiency of the competing MLLM. The code
is available at https://github.com/Sadcardation/MLLM-Refusal.",2024-07-12,"Zedian Shao, Hongbin Liu, Yuepeng Hu, Neil Zhenqiang Gong",http://arxiv.org/pdf/2407.09050v2,cs.LG
Overcoming Catastrophic Forgetting in Tabular Data Classification: A Pseudorehearsal-based approach,"Continual learning (CL) poses the important challenge of adapting to evolving
data distributions without forgetting previously acquired knowledge while
consolidating new knowledge. In this paper, we introduce a new methodology,
coined as Tabular-data Rehearsal-based Incremental Lifelong Learning framework
(TRIL3), designed to address the phenomenon of catastrophic forgetting in
tabular data classification problems. TRIL3 uses the prototype-based
incremental generative model XuILVQ to generate synthetic data to preserve old
knowledge and the DNDF algorithm, which was modified to run in an incremental
way, to learn classification tasks for tabular data, without storing old
samples. After different tests to obtain the adequate percentage of synthetic
data and to compare TRIL3 with other CL available proposals, we can conclude
that the performance of TRIL3 outstands other options in the literature using
only 50% of synthetic data.",2024-07-12,"Pablo García-Santaclara, Bruno Fernández-Castro, Rebeca P. Díaz-Redondo",http://arxiv.org/pdf/2407.09039v1,cs.LG
DRM Revisited: A Complete Error Analysis,"In this work, we address a foundational question in the theoretical analysis
of the Deep Ritz Method (DRM) under the over-parameteriztion regime: Given a
target precision level, how can one determine the appropriate number of
training samples, the key architectural parameters of the neural networks, the
step size for the projected gradient descent optimization procedure, and the
requisite number of iterations, such that the output of the gradient descent
process closely approximates the true solution of the underlying partial
differential equation to the specified precision?",2024-07-12,"Yuling Jiao, Ruoxuan Li, Peiying Wu, Jerry Zhijian Yang, Pingwen Zhang",http://arxiv.org/pdf/2407.09032v1,cs.LG
HPC: Hierarchical Progressive Coding Framework for Volumetric Video,"Volumetric video based on Neural Radiance Field (NeRF) holds vast potential
for various 3D applications, but its substantial data volume poses significant
challenges for compression and transmission. Current NeRF compression lacks the
flexibility to adjust video quality and bitrate within a single model for
various network and device capacities. To address these issues, we propose HPC,
a novel hierarchical progressive volumetric video coding framework achieving
variable bitrate using a single model. Specifically, HPC introduces a
hierarchical representation with a multi-resolution residual radiance field to
reduce temporal redundancy in long-duration sequences while simultaneously
generating various levels of detail. Then, we propose an end-to-end progressive
learning approach with a multi-rate-distortion loss function to jointly
optimize both hierarchical representation and compression. Our HPC trained only
once can realize multiple compression levels, while the current methods need to
train multiple fixed-bitrate models for different rate-distortion (RD)
tradeoffs. Extensive experiments demonstrate that HPC achieves flexible quality
levels with variable bitrate by a single model and exhibits competitive RD
performance, even outperforming fixed-bitrate models across various datasets.",2024-07-12,"Zihan Zheng, Houqiang Zhong, Qiang Hu, Xiaoyun Zhang, Li Song, Ya Zhang, Yanfeng Wang",http://arxiv.org/pdf/2407.09026v2,cs.LG
Aligning Diffusion Behaviors with Q-functions for Efficient Continuous Control,"Drawing upon recent advances in language model alignment, we formulate
offline Reinforcement Learning as a two-stage optimization problem: First
pretraining expressive generative policies on reward-free behavior datasets,
then fine-tuning these policies to align with task-specific annotations like
Q-values. This strategy allows us to leverage abundant and diverse behavior
data to enhance generalization and enable rapid adaptation to downstream tasks
using minimal annotations. In particular, we introduce Efficient Diffusion
Alignment (EDA) for solving continuous control problems. EDA utilizes diffusion
models for behavior modeling. However, unlike previous approaches, we represent
diffusion policies as the derivative of a scalar neural network with respect to
action inputs. This representation is critical because it enables direct
density calculation for diffusion models, making them compatible with existing
LLM alignment theories. During policy fine-tuning, we extend preference-based
alignment methods like Direct Preference Optimization (DPO) to align diffusion
behaviors with continuous Q-functions. Our evaluation on the D4RL benchmark
shows that EDA exceeds all baseline methods in overall performance. Notably,
EDA maintains about 95\% of performance and still outperforms several baselines
given only 1\% of Q-labelled data during fine-tuning.",2024-07-12,"Huayu Chen, Kaiwen Zheng, Hang Su, Jun Zhu",http://arxiv.org/pdf/2407.09024v2,cs.LG
AI-Driven Guided Response for Security Operation Centers with Microsoft Copilot for Security,"Security operation centers contend with a constant stream of security
incidents, ranging from straightforward to highly complex. To address this, we
developed Microsoft Copilot for Security Guided Response (CGR), an
industry-scale ML architecture that guides security analysts across three key
tasks -- (1) investigation, providing essential historical context by
identifying similar incidents; (2) triaging to ascertain the nature of the
incident -- whether it is a true positive, false positive, or benign positive;
and (3) remediation, recommending tailored containment actions. CGR is
integrated into the Microsoft Defender XDR product and deployed worldwide,
generating millions of recommendations across thousands of customers. Our
extensive evaluation, incorporating internal evaluation, collaboration with
security experts, and customer feedback, demonstrates that CGR delivers
high-quality recommendations across all three tasks. We provide a comprehensive
overview of the CGR architecture, setting a precedent as the first
cybersecurity company to openly discuss these capabilities in such depth.
Additionally, we release GUIDE, the largest public collection of real-world
security incidents, spanning 13M evidences across 1M incidents annotated with
ground-truth triage labels by customer security analysts. This dataset
represents the first large-scale cybersecurity resource of its kind, supporting
the development and evaluation of guided response systems and beyond.",2024-07-12,"Scott Freitas, Jovan Kalajdjieski, Amir Gharib, Robert McCann",http://arxiv.org/pdf/2407.09017v4,cs.LG
Procedural Content Generation via Generative Artificial Intelligence,"The attempt to utilize machine learning in PCG has been made in the past. In
this survey paper, we investigate how generative artificial intelligence (AI),
which saw a significant increase in interest in the mid-2010s, is being used
for PCG. We review applications of generative AI for the creation of various
types of content, including terrains, items, and even storylines. While
generative AI is effective for PCG, one significant issues it faces is that
building high-performance generative AI requires vast amounts of training data.
Because content generally highly customized, domain-specific training data is
scarce, and straightforward approaches to generative AI models may not work
well. For PCG research to advance further, issues related to limited training
data must be overcome. Thus, we also give special consideration to research
that addresses the challenges posed by limited training data.",2024-07-12,"Xinyu Mao, Wanli Yu, Kazunori D Yamada, Michael R. Zielewski",http://arxiv.org/pdf/2407.09013v1,cs.LG
"One Stone, Four Birds: A Comprehensive Solution for QA System Using Supervised Contrastive Learning","This paper presents a novel and comprehensive solution to enhance both the
robustness and efficiency of question answering (QA) systems through supervised
contrastive learning (SCL). Training a high-performance QA system has become
straightforward with pre-trained language models, requiring only a small amount
of data and simple fine-tuning. However, despite recent advances, existing QA
systems still exhibit significant deficiencies in functionality and training
efficiency. We address the functionality issue by defining four key tasks: user
input intent classification, out-of-domain input detection, new intent
discovery, and continual learning. We then leverage a unified SCL-based
representation learning method to efficiently build an intra-class compact and
inter-class scattered feature space, facilitating both known intent
classification and unknown intent detection and discovery. Consequently, with
minimal additional tuning on downstream tasks, our approach significantly
improves model efficiency and achieves new state-of-the-art performance across
all tasks.",2024-07-12,"Bo Wang, Tsunenori Mine",http://arxiv.org/pdf/2407.09011v2,cs.LG
Parameter inference from a non-stationary unknown process,"Non-stationary systems are found throughout the world, from climate patterns
under the influence of variation in carbon dioxide concentration, to brain
dynamics driven by ascending neuromodulation. Accordingly, there is a need for
methods to analyze non-stationary processes, and yet most time-series analysis
methods that are used in practice, on important problems across science and
industry, make the simplifying assumption of stationarity. One important
problem in the analysis of non-stationary systems is the problem class that we
refer to as Parameter Inference from a Non-stationary Unknown Process (PINUP).
Given an observed time series, this involves inferring the parameters that
drive non-stationarity of the time series, without requiring knowledge or
inference of a mathematical model of the underlying system. Here we review and
unify a diverse literature of algorithms for PINUP. We formulate the problem,
and categorize the various algorithmic contributions. This synthesis will allow
researchers to identify gaps in the literature and will enable systematic
comparisons of different methods. We also demonstrate that the most common
systems that existing methods are tested on - notably the non-stationary Lorenz
process and logistic map - are surprisingly easy to perform well on using
simple statistical features like windowed mean and variance, undermining the
practice of using good performance on these systems as evidence of algorithmic
performance. We then identify more challenging problems that many existing
methods perform poorly on and which can be used to drive methodological
advances in the field. Our results unify disjoint scientific contributions to
analyzing non-stationary systems and suggest new directions for progress on the
PINUP problem and the broader study of non-stationary phenomena.",2024-07-12,"Kieran S. Owens, Ben D. Fulcher",http://arxiv.org/pdf/2407.08987v1,cs.LG
Towards More Trustworthy and Interpretable LLMs for Code through Syntax-Grounded Explanations,"Trustworthiness and interpretability are inextricably linked concepts for
LLMs. The more interpretable an LLM is, the more trustworthy it becomes.
However, current techniques for interpreting LLMs when applied to code-related
tasks largely focus on accuracy measurements, measures of how models react to
change, or individual task performance instead of the fine-grained explanations
needed at prediction time for greater interpretability, and hence trust. To
improve upon this status quo, this paper introduces ASTrust, an
interpretability method for LLMs of code that generates explanations grounded
in the relationship between model confidence and syntactic structures of
programming languages. ASTrust explains generated code in the context of syntax
categories based on Abstract Syntax Trees and aids practitioners in
understanding model predictions at both local (individual code snippets) and
global (larger datasets of code) levels. By distributing and assigning model
confidence scores to well-known syntactic structures that exist within ASTs,
our approach moves beyond prior techniques that perform token-level confidence
mapping by offering a view of model confidence that directly aligns with
programming language concepts with which developers are familiar. To put
ASTrust into practice, we developed an automated visualization that illustrates
the aggregated model confidence scores superimposed on sequence, heat-map, and
graph-based visuals of syntactic structures from ASTs. We examine both the
practical benefit that ASTrust can provide through a data science study on 12
popular LLMs on a curated set of GitHub repos and the usefulness of ASTrust
through a human study.",2024-07-12,"David N. Palacio, Daniel Rodriguez-Cardenas, Alejandro Velasco, Dipin Khati, Kevin Moran, Denys Poshyvanyk",http://arxiv.org/pdf/2407.08983v1,cs.LG
Towards Chapter-to-Chapter Context-Aware Literary Translation via Large Language Models,"Discourse phenomena in existing document-level translation datasets are
sparse, which has been a fundamental obstacle in the development of
context-aware machine translation models. Moreover, most existing
document-level corpora and context-aware machine translation methods rely on an
unrealistic assumption on sentence-level alignments. To mitigate these issues,
we first curate a novel dataset of Chinese-English literature, which consists
of 160 books with intricate discourse structures. Then, we propose a more
pragmatic and challenging setting for context-aware translation, termed
chapter-to-chapter (Ch2Ch) translation, and investigate the performance of
commonly-used machine translation models under this setting. Furthermore, we
introduce a potential approach of finetuning large language models (LLMs)
within the domain of Ch2Ch literary translation, yielding impressive
improvements over baselines. Through our comprehensive analysis, we unveil that
literary translation under the Ch2Ch setting is challenging in nature, with
respect to both model learning methods and translation decoding algorithms.",2024-07-12,"Linghao Jin, Li An, Xuezhe Ma",http://arxiv.org/pdf/2407.08978v1,cs.LG
Computational-Statistical Trade-off in Kernel Two-Sample Testing with Random Fourier Features,"Recent years have seen a surge in methods for two-sample testing, among which
the Maximum Mean Discrepancy (MMD) test has emerged as an effective tool for
handling complex and high-dimensional data. Despite its success and widespread
adoption, the primary limitation of the MMD test has been its quadratic-time
complexity, which poses challenges for large-scale analysis. While various
approaches have been proposed to expedite the procedure, it has been unclear
whether it is possible to attain the same power guarantee as the MMD test at
sub-quadratic time cost. To fill this gap, we revisit the approximated MMD test
using random Fourier features, and investigate its computational-statistical
trade-off. We start by revealing that the approximated MMD test is pointwise
consistent in power only when the number of random features approaches
infinity. We then consider the uniform power of the test and study the
time-power trade-off under the minimax testing framework. Our result shows
that, by carefully choosing the number of random features, it is possible to
attain the same minimax separation rates as the MMD test within sub-quadratic
time. We demonstrate this point under different distributional assumptions such
as densities in a Sobolev ball. Our theoretical findings are corroborated by
simulation studies.",2024-07-12,"Ikjun Choi, Ilmun Kim",http://arxiv.org/pdf/2407.08976v1,cs.LG
Topology-enhanced machine learning model (Top-ML) for anticancer peptide prediction,"Recently, therapeutic peptides have demonstrated great promise for cancer
treatment. To explore powerful anticancer peptides, artificial intelligence
(AI)-based approaches have been developed to systematically screen potential
candidates. However, the lack of efficient featurization of peptides has become
a bottleneck for these machine-learning models. In this paper, we propose a
topology-enhanced machine learning model (Top-ML) for anticancer peptides
prediction. Our Top-ML employs peptide topological features derived from its
sequence ""connection"" information characterized by vector and spectral
descriptors. Our Top-ML model, employing an Extra-Trees classifier, has been
validated on the AntiCP 2.0 and mACPpred 2.0 benchmark datasets, achieving
state-of-the-art performance or results comparable to existing deep learning
models, while providing greater interpretability. Our results highlight the
potential of leveraging novel topology-based featurization to accelerate the
identification of anticancer peptides.",2024-07-12,"Joshua Zhi En Tan, JunJie Wee, Xue Gong, Kelin Xia",http://arxiv.org/pdf/2407.08974v4,cs.LG
Integrating White and Black Box Techniques for Interpretable Machine Learning,"In machine learning algorithm design, there exists a trade-off between the
interpretability and performance of the algorithm. In general, algorithms which
are simpler and easier for humans to comprehend tend to show worse performance
than more complex, less transparent algorithms. For example, a random forest
classifier is likely to be more accurate than a simple decision tree, but at
the expense of interpretability. In this paper, we present an ensemble
classifier design which classifies easier inputs using a highly-interpretable
classifier (i.e., white box model), and more difficult inputs using a more
powerful, but less interpretable classifier (i.e., black box model).",2024-07-12,"Eric M. Vernon, Naoki Masuyama, Yusuke Nojima",http://arxiv.org/pdf/2407.08973v1,cs.LG
Self-interpreting Adversarial Images,"We introduce a new type of indirect, cross-modal injection attacks against
visual language models that enable creation of self-interpreting images. These
images contain hidden ""meta-instructions"" that control how models answer users'
questions about the image and steer their outputs to express an
adversary-chosen style, sentiment, or point of view. Self-interpreting images
act as soft prompts, conditioning the model to satisfy the adversary's
(meta-)objective while still producing answers based on the image's visual
content. Meta-instructions are thus a stronger form of prompt injection.
Adversarial images look natural and the model's answers are coherent and
plausible--yet they also follow the adversary-chosen interpretation, e.g.,
political spin, or even objectives that are not achievable with explicit text
instructions. We evaluate the efficacy of self-interpreting images for a
variety of models, interpretations, and user prompts. We describe how these
attacks could cause harm by enabling creation of self-interpreting content that
carries spam, misinformation, or spin. Finally, we discuss defenses.",2024-07-12,"Tingwei Zhang, Collin Zhang, John X. Morris, Eugene Bagdasarian, Vitaly Shmatikov",http://arxiv.org/pdf/2407.08970v3,cs.LG
LAPT: Label-driven Automated Prompt Tuning for OOD Detection with Vision-Language Models,"Out-of-distribution (OOD) detection is crucial for model reliability, as it
identifies samples from unknown classes and reduces errors due to unexpected
inputs. Vision-Language Models (VLMs) such as CLIP are emerging as powerful
tools for OOD detection by integrating multi-modal information. However, the
practical application of such systems is challenged by manual prompt
engineering, which demands domain expertise and is sensitive to linguistic
nuances. In this paper, we introduce Label-driven Automated Prompt Tuning
(LAPT), a novel approach to OOD detection that reduces the need for manual
prompt engineering. We develop distribution-aware prompts with in-distribution
(ID) class names and negative labels mined automatically. Training samples
linked to these class labels are collected autonomously via image synthesis and
retrieval methods, allowing for prompt learning without manual effort. We
utilize a simple cross-entropy loss for prompt optimization, with cross-modal
and cross-distribution mixing strategies to reduce image noise and explore the
intermediate space between distributions, respectively. The LAPT framework
operates autonomously, requiring only ID class names as input and eliminating
the need for manual intervention. With extensive experiments, LAPT consistently
outperforms manually crafted prompts, setting a new standard for OOD detection.
Moreover, LAPT not only enhances the distinction between ID and OOD samples,
but also improves the ID classification accuracy and strengthens the
generalization robustness to covariate shifts, resulting in outstanding
performance in challenging full-spectrum OOD detection tasks. Codes are
available at \url{https://github.com/YBZh/LAPT}.",2024-07-12,"Yabin Zhang, Wenjie Zhu, Chenhang He, Lei Zhang",http://arxiv.org/pdf/2407.08966v1,cs.LG
Lite-SAM Is Actually What You Need for Segment Everything,"This paper introduces Lite-SAM, an efficient end-to-end solution for the
SegEvery task designed to reduce computational costs and redundancy. Lite-SAM
is composed of four main components: a streamlined CNN-Transformer hybrid
encoder (LiteViT), an automated prompt proposal network (AutoPPN), a
traditional prompt encoder, and a mask decoder. All these components are
integrated within the SAM framework. Our LiteViT, a high-performance
lightweight backbone network, has only 1.16M parameters, which is a 23%
reduction compared to the lightest existing backbone network Shufflenet. We
also introduce AutoPPN, an innovative end-to-end method for prompt boxes and
points generation. This is an improvement over traditional grid search sampling
methods, and its unique design allows for easy integration into any SAM series
algorithm, extending its usability. we have thoroughly benchmarked Lite-SAM
across a plethora of both public and private datasets. The evaluation
encompassed a broad spectrum of universal metrics, including the number of
parameters, SegEvery execution time, and accuracy. The findings reveal that
Lite-SAM, operating with a lean 4.2M parameters, significantly outpaces its
counterparts, demonstrating performance improvements of 43x, 31x, 20x, 21x, and
1.6x over SAM, MobileSAM, Edge-SAM, EfficientViT-SAM, and MobileSAM-v2
respectively, all the while maintaining competitive accuracy. This underscores
Lite-SAM's prowess in achieving an optimal equilibrium between performance and
precision, thereby setting a new state-of-the-art(SOTA) benchmark in the
domain.",2024-07-12,"Jianhai Fu, Yuanjie Yu, Ningchuan Li, Yi Zhang, Qichao Chen, Jianping Xiong, Jun Yin, Zhiyu Xiang",http://arxiv.org/pdf/2407.08965v1,cs.LG
Communication-Aware Reinforcement Learning for Cooperative Adaptive Cruise Control,"Cooperative Adaptive Cruise Control (CACC) plays a pivotal role in enhancing
traffic efficiency and safety in Connected and Autonomous Vehicles (CAVs).
Reinforcement Learning (RL) has proven effective in optimizing complex
decision-making processes in CACC, leading to improved system performance and
adaptability. Among RL approaches, Multi-Agent Reinforcement Learning (MARL)
has shown remarkable potential by enabling coordinated actions among multiple
CAVs through Centralized Training with Decentralized Execution (CTDE). However,
MARL often faces scalability issues, particularly when CACC vehicles suddenly
join or leave the platoon, resulting in performance degradation. To address
these challenges, we propose Communication-Aware Reinforcement Learning
(CA-RL). CA-RL includes a communication-aware module that extracts and
compresses vehicle communication information through forward and backward
information transmission modules. This enables efficient cyclic information
propagation within the CACC traffic flow, ensuring policy consistency and
mitigating the scalability problems of MARL in CACC. Experimental results
demonstrate that CA-RL significantly outperforms baseline methods in various
traffic scenarios, achieving superior scalability, robustness, and overall
system performance while maintaining reliable performance despite changes in
the number of participating vehicles.",2024-07-12,"Sicong Jiang, Seongjin Choi, Lijun Sun",http://arxiv.org/pdf/2407.08964v1,cs.LG
Attribution Methods in Asset Pricing: Do They Account for Risk?,"Over the past few decades, machine learning models have been extremely
successful. As a result of axiomatic attribution methods, feature contributions
have been explained more clearly and rigorously. There are, however, few
studies that have examined domain knowledge in conjunction with the axioms. In
this study, we examine asset pricing in finance, a field closely related to
risk management. Consequently, when applying machine learning models, we must
ensure that the attribution methods reflect the underlying risks accurately. In
this work, we present and study several axioms derived from asset pricing
domain knowledge. It is shown that while Shapley value and Integrated Gradients
preserve most axioms, neither can satisfy all axioms. Using extensive
analytical and empirical examples, we demonstrate how attribution methods can
reflect risks and when they should not be used.",2024-07-12,"Dangxing Chen, Yuan Gao",http://arxiv.org/pdf/2407.08953v1,cs.LG
ECG Signal Denoising Using Multi-scale Patch Embedding and Transformers,"Cardiovascular disease is a major life-threatening condition that is commonly
monitored using electrocardiogram (ECG) signals. However, these signals are
often contaminated by various types of noise at different intensities,
significantly interfering with downstream tasks. Therefore, denoising ECG
signals and increasing the signal-to-noise ratio is crucial for cardiovascular
monitoring. In this paper, we propose a deep learning method that combines a
one-dimensional convolutional layer with transformer architecture for denoising
ECG signals. The convolutional layer processes the ECG signal by various
kernel/patch sizes and generates an embedding called multi-scale patch
embedding. The embedding then is used as the input of a transformer network and
enhances the capability of the transformer for denoising the ECG signal.",2024-07-12,"Ding Zhu, Vishnu Kabir Chhabra, Mohammad Mahdi Khalili",http://arxiv.org/pdf/2407.11065v1,cs.LG
Constructing Concept-based Models to Mitigate Spurious Correlations with Minimal Human Effort,"Enhancing model interpretability can address spurious correlations by
revealing how models draw their predictions. Concept Bottleneck Models (CBMs)
can provide a principled way of disclosing and guiding model behaviors through
human-understandable concepts, albeit at a high cost of human efforts in data
annotation. In this paper, we leverage a synergy of multiple foundation models
to construct CBMs with nearly no human effort. We discover undesirable biases
in CBMs built on pre-trained models and propose a novel framework designed to
exploit pre-trained models while being immune to these biases, thereby reducing
vulnerability to spurious correlations. Specifically, our method offers a
seamless pipeline that adopts foundation models for assessing potential
spurious correlations in datasets, annotating concepts for images, and refining
the annotations for improved robustness. We evaluate the proposed method on
multiple datasets, and the results demonstrate its effectiveness in reducing
model reliance on spurious correlations while preserving its interpretability.",2024-07-12,"Jeeyung Kim, Ze Wang, Qiang Qiu",http://arxiv.org/pdf/2407.08947v1,cs.LG
Your Diffusion Model is Secretly a Noise Classifier and Benefits from Contrastive Training,"Diffusion models learn to denoise data and the trained denoiser is then used
to generate new samples from the data distribution. In this paper, we revisit
the diffusion sampling process and identify a fundamental cause of sample
quality degradation: the denoiser is poorly estimated in regions that are far
Outside Of the training Distribution (OOD), and the sampling process inevitably
evaluates in these OOD regions. This can become problematic for all sampling
methods, especially when we move to parallel sampling which requires us to
initialize and update the entire sample trajectory of dynamics in parallel,
leading to many OOD evaluations. To address this problem, we introduce a new
self-supervised training objective that differentiates the levels of noise
added to a sample, leading to improved OOD denoising performance. The approach
is based on our observation that diffusion models implicitly define a
log-likelihood ratio that distinguishes distributions with different amounts of
noise, and this expression depends on denoiser performance outside the standard
training distribution. We show by diverse experiments that the proposed
contrastive diffusion training is effective for both sequential and parallel
settings, and it improves the performance and speed of parallel samplers
significantly.",2024-07-12,"Yunshu Wu, Yingtao Luo, Xianghao Kong, Evangelos E. Papalexakis, Greg Ver Steeg",http://arxiv.org/pdf/2407.08946v2,cs.LG
Compositional Structures in Neural Embedding and Interaction Decompositions,"We describe a basic correspondence between linear algebraic structures within
vector embeddings in artificial neural networks and conditional independence
constraints on the probability distributions modeled by these networks. Our
framework aims to shed light on the emergence of structural patterns in data
representations, a phenomenon widely acknowledged but arguably still lacking a
solid formal grounding. Specifically, we introduce a characterization of
compositional structures in terms of ""interaction decompositions,"" and we
establish necessary and sufficient conditions for the presence of such
structures within the representations of a model.",2024-07-12,"Matthew Trager, Alessandro Achille, Pramuditha Perera, Luca Zancato, Stefano Soatto",http://arxiv.org/pdf/2407.08934v1,cs.LG
Machine Learning in High Volume Media Manufacturing,"Errors or failures in a high-volume manufacturing environment can have
significant impact that can result in both the loss of time and money.
Identifying such failures early has been a top priority for manufacturing
industries and various rule-based algorithms have been developed over the
years. However, catching these failures is time consuming and such algorithms
cannot adapt well to changes in designs, and sometimes variations in everyday
behavior. More importantly, the number of units to monitor in a high-volume
manufacturing environment is too big for manual monitoring or for a simple
program. Here we develop a novel program that combines both rule-based
decisions and machine learning models that can not only learn and adapt to such
day-to-day variations or long-term design changes, but also can be applied at
scale to the high number of manufacturing units in use today. Using the current
state-of-the-art technologies, we then deploy this program at-scale to handle
the needs of ever-increasing demand from the manufacturing environment.",2024-07-12,"Siddarth Reddy Karuka, Abhinav Sunderrajan, Zheng Zheng, Yong Woon Tiean, Ganesh Nagappan, Allan Luk",http://arxiv.org/pdf/2407.08933v1,cs.LG
Leveraging large language models for nano synthesis mechanism explanation: solid foundations or mere conjectures?,"With the rapid development of artificial intelligence (AI), large language
models (LLMs) such as GPT-4 have garnered significant attention in the
scientific community, demonstrating great potential in advancing scientific
discovery. This progress raises a critical question: are these LLMs
well-aligned with real-world physicochemical principles? Current evaluation
strategies largely emphasize fact-based knowledge, such as material property
prediction or name recognition, but they often lack an understanding of
fundamental physicochemical mechanisms that require logical reasoning. To
bridge this gap, our study developed a benchmark consisting of 775
multiple-choice questions focusing on the mechanisms of gold nanoparticle
synthesis. By reflecting on existing evaluation metrics, we question whether a
direct true-or-false assessment merely suggests conjecture. Hence, we propose a
novel evaluation metric, the confidence-based score (c-score), which probes the
output logits to derive the precise probability for the correct answer. Based
on extensive experiments, our results show that in the context of gold
nanoparticle synthesis, LLMs understand the underlying physicochemical
mechanisms rather than relying on conjecture. This study underscores the
potential of LLMs to grasp intrinsic scientific mechanisms and sets the stage
for developing more reliable and effective AI tools across various scientific
domains.",2024-07-12,"Yingming Pu, Liping Huang, Tao Lin, Hongyu Chen",http://arxiv.org/pdf/2407.08922v1,cs.LG
Unsupervised Anomaly Detection Using Diffusion Trend Analysis for Display Inspection,"Reconstruction-based anomaly detection via denoising diffusion model has
limitations in determining appropriate noise parameters that can degrade
anomalies while preserving normal characteristics. Also, normal regions can
fluctuate considerably during reconstruction, resulting in false detection. In
this paper, we propose a method to detect anomalies by analysis of
reconstruction trend depending on the degree of degradation, effectively
solving the both problems that impede practical application in display
inspection.",2024-07-12,"Eunwoo Kim, Un Yang, Cheol Lae Roh, Stefano Ermon",http://arxiv.org/pdf/2407.09578v2,cs.LG
"Transforming Movie Recommendations with Advanced Machine Learning: A Study of NMF, SVD,and K-Means Clustering","This study develops a robust movie recommendation system using various
machine learning techniques, including Non- Negative Matrix Factorization
(NMF), Truncated Singular Value Decomposition (SVD), and K-Means clustering.
The primary objective is to enhance user experience by providing personalized
movie recommendations. The research encompasses data preprocessing, model
training, and evaluation, highlighting the efficacy of the employed methods.
Results indicate that the proposed system achieves high accuracy and relevance
in recommendations, making significant contributions to the field of
recommendations systems.",2024-07-12,"Yubing Yan, Camille Moreau, Zhuoyue Wang, Wenhan Fan, Chengqian Fu",http://arxiv.org/pdf/2407.08916v1,cs.LG
PAIL: Performance based Adversarial Imitation Learning Engine for Carbon Neutral Optimization,"Achieving carbon neutrality within industrial operations has become
increasingly imperative for sustainable development. It is both a significant
challenge and a key opportunity for operational optimization in industry 4.0.
In recent years, Deep Reinforcement Learning (DRL) based methods offer
promising enhancements for sequential optimization processes and can be used
for reducing carbon emissions. However, existing DRL methods need a pre-defined
reward function to assess the impact of each action on the final sustainable
development goals (SDG). In many real applications, such a reward function
cannot be given in advance. To address the problem, this study proposes a
Performance based Adversarial Imitation Learning (PAIL) engine. It is a novel
method to acquire optimal operational policies for carbon neutrality without
any pre-defined action rewards. Specifically, PAIL employs a Transformer-based
policy generator to encode historical information and predict following actions
within a multi-dimensional space. The entire action sequence will be
iteratively updated by an environmental simulator. Then PAIL uses a
discriminator to minimize the discrepancy between generated sequences and
real-world samples of high SDG. In parallel, a Q-learning framework based
performance estimator is designed to estimate the impact of each action on SDG.
Based on these estimations, PAIL refines generated policies with the rewards
from both discriminator and performance estimator. PAIL is evaluated on
multiple real-world application cases and datasets. The experiment results
demonstrate the effectiveness of PAIL comparing to other state-of-the-art
baselines. In addition, PAIL offers meaningful interpretability for the
optimization in carbon neutrality.",2024-07-12,"Yuyang Ye, Lu-An Tang, Haoyu Wang, Runlong Yu, Wenchao Yu, Erhu He, Haifeng Chen, Hui Xiong",http://arxiv.org/pdf/2407.08910v1,cs.LG
Flash normalization: fast normalization for LLMs,"RMSNorm is used by many LLMs such as Llama, Mistral, and OpenELM. This paper
details FlashNorm, which is an exact but faster implementation of RMSNorm
followed by linear layers. FlashNorm also speeds up Layer Normalization and its
recently proposed replacement Dynamic Tanh (DyT) arXiv:2503.10622. See
https://github.com/OpenMachine-ai/transformer-tricks for code and more
transformer tricks.",2024-07-12,"Nils Graef, Matthew Clapp, Andrew Wasielewski",http://arxiv.org/pdf/2407.09577v2,cs.LG
IDAT: A Multi-Modal Dataset and Toolkit for Building and Evaluating Interactive Task-Solving Agents,"Seamless interaction between AI agents and humans using natural language
remains a key goal in AI research. This paper addresses the challenges of
developing interactive agents capable of understanding and executing grounded
natural language instructions through the IGLU competition at NeurIPS. Despite
advancements, challenges such as a scarcity of appropriate datasets and the
need for effective evaluation platforms persist. We introduce a scalable data
collection tool for gathering interactive grounded language instructions within
a Minecraft-like environment, resulting in a Multi-Modal dataset with around
9,000 utterances and over 1,000 clarification questions. Additionally, we
present a Human-in-the-Loop interactive evaluation platform for qualitative
analysis and comparison of agent performance through multi-turn communication
with human annotators. We offer to the community these assets referred to as
IDAT (IGLU Dataset And Toolkit) which aim to advance the development of
intelligent, interactive AI agents and provide essential resources for further
research.",2024-07-12,"Shrestha Mohanty, Negar Arabzadeh, Andrea Tupini, Yuxuan Sun, Alexey Skrynnik, Artem Zholus, Marc-Alexandre Côté, Julia Kiseleva",http://arxiv.org/pdf/2407.08898v1,cs.LG
Characterizing Prompt Compression Methods for Long Context Inference,"Long context inference presents challenges at the system level with increased
compute and memory requirements, as well as from an accuracy perspective in
being able to reason over long contexts. Recently, several methods have been
proposed to compress the prompt to reduce the context length. However, there
has been little work on comparing the different proposed methods across
different tasks through a standardized analysis. This has led to conflicting
results. To address this, here we perform a comprehensive characterization and
evaluation of different prompt compression methods. In particular, we analyze
extractive compression, summarization-based abstractive compression, and token
pruning methods. Surprisingly, we find that extractive compression often
outperforms all the other approaches, and enables up to 10x compression with
minimal accuracy degradation. Interestingly, we also find that despite several
recent claims, token pruning methods often lag behind extractive compression.
We only found marginal improvements on summarization tasks.",2024-07-11,"Siddharth Jha, Lutfi Eren Erdogan, Sehoon Kim, Kurt Keutzer, Amir Gholami",http://arxiv.org/pdf/2407.08892v1,cs.LG
DeepCodeProbe: Towards Understanding What Models Trained on Code Learn,"Machine learning models trained on code and related artifacts offer valuable
support for software maintenance but suffer from interpretability issues due to
their complex internal variables. These concerns are particularly significant
in safety-critical applications where the models' decision-making processes
must be reliable. The specific features and representations learned by these
models remain unclear, adding to the hesitancy in adopting them widely. To
address these challenges, we introduce DeepCodeProbe, a probing approach that
examines the syntax and representation learning abilities of ML models designed
for software maintenance tasks. Our study applies DeepCodeProbe to
state-of-the-art models for code clone detection, code summarization, and
comment generation. Findings reveal that while small models capture abstract
syntactic representations, their ability to fully grasp programming language
syntax is limited. Increasing model capacity improves syntax learning but
introduces trade-offs such as increased training time and overfitting.
DeepCodeProbe also identifies specific code patterns the models learn from
their training data. Additionally, we provide best practices for training
models on code to enhance performance and interpretability, supported by an
open-source replication package for broader application of DeepCodeProbe in
interpreting other code-related models.",2024-07-11,"Vahid Majdinasab, Amin Nikanjam, Foutse Khomh",http://arxiv.org/pdf/2407.08890v1,cs.LG
Uncovering Semantics and Topics Utilized by Threat Actors to Deliver Malicious Attachments and URLs,"Recent threat reports highlight that email remains the top vector for
delivering malware to endpoints. Despite these statistics, detecting malicious
email attachments and URLs often neglects semantic cues linguistic features and
contextual clues. Our study employs BERTopic unsupervised topic modeling to
identify common semantics and themes embedded in email to deliver malicious
attachments and call-to-action URLs. We preprocess emails by extracting and
sanitizing content and employ multilingual embedding models like BGE-M3 for
dense representations, which clustering algorithms(HDBSCAN and OPTICS) use to
group emails by semantic similarity. Phi3-Mini-4K-Instruct facilitates semantic
and hLDA aid in thematic analysis to understand threat actor patterns. Our
research will evaluate and compare different clustering algorithms on topic
quantity, coherence, and diversity metrics, concluding with insights into the
semantics and topics commonly used by threat actors to deliver malicious
attachments and URLs, a significant contribution to the field of threat
detection.",2024-07-11,"Andrey Yakymovych, Abhishek Singh",http://arxiv.org/pdf/2407.08888v1,cs.LG
Automatic Pruning of Fine-tuning Datasets for Transformer-based Language Models,"Transformer-based language models have shown state-of-the-art performance on
a variety of natural language understanding tasks. To achieve this performance,
these models are first pre-trained on general corpus and then fine-tuned on
downstream tasks. Previous work studied the effect of pruning the training set
of the downstream tasks on the performance of the model on its evaluation set.
In this work, we propose an automatic dataset pruning method for the training
set of fine-tuning tasks. Our method is based on the model's success rate in
correctly classifying each training data point. Unlike previous work which
relies on user feedback to determine subset size, our method automatically
extracts training subsets that are adapted for each pair of model and
fine-tuning task. Our method provides multiple subsets for use in dataset
pruning that navigate the trade-off between subset size and evaluation
accuracy. Our largest subset, which we also refer to as the winning ticket
subset, is on average $3 \times$ smaller than the original training set of the
fine-tuning task. Our experiments on 5 downstream tasks and 2 language models
show that, on average, fine-tuning on the winning ticket subsets results in a
$0.1 \%$ increase in the evaluation performance of the model.",2024-07-11,"Mohammadreza Tayaranian, Seyyed Hasan Mozafari, Brett H. Meyer, James J. Clark, Warren J. Gross",http://arxiv.org/pdf/2407.08887v1,cs.LG
Semi-Supervised Multi-Task Learning Based Framework for Power System Security Assessment,"This paper develops a novel machine learning-based framework using
Semi-Supervised Multi-Task Learning (SS-MTL) for power system dynamic security
assessment that is accurate, reliable, and aware of topological changes. The
learning algorithm underlying the proposed framework integrates conditional
masked encoders and employs multi-task learning for classification-aware
feature representation, which improves the accuracy and scalability to larger
systems. Additionally, this framework incorporates a confidence measure for its
predictions, enhancing its reliability and interpretability. A topological
similarity index has also been incorporated to add topological awareness to the
framework. Various experiments on the IEEE 68-bus system were conducted to
validate the proposed method, employing two distinct database generation
techniques to generate the required data to train the machine learning
algorithm. The results demonstrate that our algorithm outperforms existing
state-of-the-art machine learning based techniques for security assessment in
terms of accuracy and robustness. Finally, our work underscores the value of
employing auto-encoders for security assessment, highlighting improvements in
accuracy, reliability, and robustness. All datasets and codes used have been
made publicly available to ensure reproducibility and transparency.",2024-07-11,"Muhy Eddin Za'ter, Amirhossein Sajadi, Bri-Mathias Hodge",http://arxiv.org/pdf/2407.08886v1,cs.LG
Generalizable Physics-Informed Learning for Stochastic Safety-Critical Systems,"Accurate estimate of long-term risk is critical for safe decision-making, but
sampling from rare risk events and long-term trajectories can be prohibitively
costly. Risk gradient can be used in many first-order techniques for learning
and control methods, but gradient estimate is difficult to obtain using Monte
Carlo (MC) methods because the infinitesimal divisor may significantly amplify
sampling noise. Motivated by this gap, we propose an efficient method to
evaluate long-term risk probabilities and their gradients using short-term
samples without sufficient risk events. We first derive that four types of
long-term risk probability are solutions of certain partial differential
equations (PDEs). Then, we propose a physics-informed learning technique that
integrates data and physics information (aforementioned PDEs). The physics
information helps propagate information beyond available data and obtain
provable generalization beyond available data, which in turn enables long-term
risk to be estimated using short-term samples of safe events. Finally, we
demonstrate in simulation that the proposed technique has improved sample
efficiency, generalizes well to unseen regions, and adapts to changing system
parameters.",2024-07-11,"Zhuoyuan Wang, Albert Chern, Yorie Nakahira",http://arxiv.org/pdf/2407.08868v4,cs.LG
Inflationary Flows: Calibrated Bayesian Inference with Diffusion-Based Models,"Beyond estimating parameters of interest from data, one of the key goals of
statistical inference is to properly quantify uncertainty in these estimates.
In Bayesian inference, this uncertainty is provided by the posterior
distribution, the computation of which typically involves an intractable
high-dimensional integral. Among available approximation methods,
sampling-based approaches come with strong theoretical guarantees but scale
poorly to large problems, while variational approaches scale well but offer few
theoretical guarantees. In particular, variational methods are known to produce
overconfident estimates of posterior uncertainty and are typically
non-identifiable, with many latent variable configurations generating
equivalent predictions. Here, we address these challenges by showing how
diffusion-based models (DBMs), which have recently produced state-of-the-art
performance in generative modeling tasks, can be repurposed for performing
calibrated, identifiable Bayesian inference. By exploiting a previously
established connection between the stochastic and probability flow ordinary
differential equations (pfODEs) underlying DBMs, we derive a class of models,
inflationary flows, that uniquely and deterministically map high-dimensional
data to a lower-dimensional Gaussian distribution via ODE integration. This map
is both invertible and neighborhood-preserving, with controllable numerical
error, with the result that uncertainties in the data are correctly propagated
to the latent space. We demonstrate how such maps can be learned via standard
DBM training using a novel noise schedule and are effective at both preserving
and reducing intrinsic data dimensionality. The result is a class of highly
expressive generative models, uniquely defined on a low-dimensional latent
space, that afford principled Bayesian inference.",2024-07-11,"Daniela de Albuquerque, John Pearson",http://arxiv.org/pdf/2407.08843v3,cs.LG
Data-driven Model Reduction for Soft Robots via Lagrangian Operator Inference,"Data-driven model reduction methods provide a nonintrusive way of
constructing computationally efficient surrogates of high-fidelity models for
real-time control of soft robots. This work leverages the Lagrangian nature of
the model equations to derive structure-preserving linear reduced-order models
via Lagrangian Operator Inference and compares their performance with prominent
linear model reduction techniques through an anguilliform swimming soft robot
model example with 231,336 degrees of freedom. The case studies demonstrate
that preserving the underlying Lagrangian structure leads to learned models
with higher predictive accuracy and robustness to unseen inputs.",2024-07-11,"Harsh Sharma, Iman Adibnazari, Jacobo Cervera-Torralba, Michael T. Tolley, Boris Kramer",http://arxiv.org/pdf/2407.08840v1,cs.LG
"A Survey on the Application of Generative Adversarial Networks in Cybersecurity: Prospective, Direction and Open Research Scopes","With the proliferation of Artificial Intelligence, there has been a massive
increase in the amount of data required to be accumulated and disseminated
digitally. As the data are available online in digital landscapes with complex
and sophisticated infrastructures, it is crucial to implement various defense
mechanisms based on cybersecurity. Generative Adversarial Networks (GANs),
which are deep learning models, have emerged as powerful solutions for
addressing the constantly changing security issues. This survey studies the
significance of the deep learning model, precisely on GANs, in strengthening
cybersecurity defenses. Our survey aims to explore the various works completed
in GANs, such as Intrusion Detection Systems (IDS), Mobile and Network
Trespass, BotNet Detection, and Malware Detection. The focus is to examine how
GANs can be influential tools to strengthen cybersecurity defenses in these
domains. Further, the paper discusses the challenges and constraints of using
GANs in these areas and suggests future research directions. Overall, the paper
highlights the potential of GANs in enhancing cybersecurity measures and
addresses the need for further exploration in this field.",2024-07-11,"Md Mashrur Arifin, Md Shoaib Ahmed, Tanmai Kumar Ghosh, Ikteder Akhand Udoy, Jun Zhuang, Jyh-haw Yeh",http://arxiv.org/pdf/2407.08839v2,cs.LG
Deep Learning for Network Anomaly Detection under Data Contamination: Evaluating Robustness and Mitigating Performance Degradation,"Deep learning (DL) has emerged as a crucial tool in network anomaly detection
(NAD) for cybersecurity. While DL models for anomaly detection excel at
extracting features and learning patterns from data, they are vulnerable to
data contamination -- the inadvertent inclusion of attack-related data in
training sets presumed benign. This study evaluates the robustness of six
unsupervised DL algorithms against data contamination using our proposed
evaluation protocol. Results demonstrate significant performance degradation in
state-of-the-art anomaly detection algorithms when exposed to contaminated
data, highlighting the critical need for self-protection mechanisms in DL-based
NAD models. To mitigate this vulnerability, we propose an enhanced auto-encoder
with a constrained latent representation, allowing normal data to cluster more
densely around a learnable center in the latent space. Our evaluation reveals
that this approach exhibits improved resistance to data contamination compared
to existing methods, offering a promising direction for more robust NAD
systems.",2024-07-11,"D'Jeff K. Nkashama, Jordan Masakuna Félicien, Arian Soltani, Jean-Charles Verdier, Pierre-Martin Tardif, Marc Frappier, Froduald Kabanza",http://arxiv.org/pdf/2407.08838v2,cs.LG
Proving that Cryptic Crossword Clue Answers are Correct,"Cryptic crossword clues are challenging cognitive tasks, for which new test
sets are released on a daily basis by multiple international newspapers. Each
cryptic clue contains both the definition of the answer to be placed in the
crossword grid (in common with regular crosswords), and `wordplay' that proves
that the answer is correct (i.e. a human solver can be confident that an answer
is correct without needing crossing words to confirm it). Using an existing
cryptic wordplay proving framework (operating on Python proofs created by an
LLM), we show that it is possible to distinguish between correct answers and
almost-correct ones based upon whether the wordplay `works'.",2024-07-11,"Martin Andrews, Sam Witteveen",http://arxiv.org/pdf/2407.08824v1,cs.LG
HO-FMN: Hyperparameter Optimization for Fast Minimum-Norm Attacks,"Gradient-based attacks are a primary tool to evaluate robustness of
machine-learning models. However, many attacks tend to provide
overly-optimistic evaluations as they use fixed loss functions, optimizers,
step-size schedulers, and default hyperparameters. In this work, we tackle
these limitations by proposing a parametric variation of the well-known fast
minimum-norm attack algorithm, whose loss, optimizer, step-size scheduler, and
hyperparameters can be dynamically adjusted. We re-evaluate 12 robust models,
showing that our attack finds smaller adversarial perturbations without
requiring any additional tuning. This also enables reporting adversarial
robustness as a function of the perturbation budget, providing a more complete
evaluation than that offered by fixed-budget attacks, while remaining
efficient. We release our open-source code at https://github.com/pralab/HO-FMN.",2024-07-11,"Raffaele Mura, Giuseppe Floris, Luca Scionis, Giorgio Piras, Maura Pintor, Ambra Demontis, Giorgio Giacinto, Battista Biggio, Fabio Roli",http://arxiv.org/pdf/2407.08806v1,cs.LG
PID Accelerated Temporal Difference Algorithms,"Long-horizon tasks, which have a large discount factor, pose a challenge for
most conventional reinforcement learning (RL) algorithms. Algorithms such as
Value Iteration and Temporal Difference (TD) learning have a slow convergence
rate and become inefficient in these tasks. When the transition distributions
are given, PID VI was recently introduced to accelerate the convergence of
Value Iteration using ideas from control theory. Inspired by this, we introduce
PID TD Learning and PID Q-Learning algorithms for the RL setting, in which only
samples from the environment are available. We give a theoretical analysis of
the convergence of PID TD Learning and its acceleration compared to the
conventional TD Learning. We also introduce a method for adapting PID gains in
the presence of noise and empirically verify its effectiveness.",2024-07-11,"Mark Bedaywi, Amin Rakhsha, Amir-massoud Farahmand",http://arxiv.org/pdf/2407.08803v2,cs.LG
Local Clustering for Lung Cancer Image Classification via Sparse Solution Technique,"In this work, we propose to use a local clustering approach based on the
sparse solution technique to study the medical image, especially the lung
cancer image classification task. We view images as the vertices in a weighted
graph and the similarity between a pair of images as the edges in the graph.
The vertices within the same cluster can be assumed to share similar features
and properties, thus making the applications of graph clustering techniques
very useful for image classification. Recently, the approach based on the
sparse solutions of linear systems for graph clustering has been found to
identify clusters more efficiently than traditional clustering methods such as
spectral clustering. We propose to use the two newly developed local clustering
methods based on sparse solution of linear system for image classification. In
addition, we employ a box spline-based tight-wavelet-framelet method to clean
these images and help build a better adjacency matrix before clustering. The
performance of our methods is shown to be very effective in classifying images.
Our approach is significantly more efficient and either favorable or equally
effective compared with other state-of-the-art approaches. Finally, we shall
make a remark by pointing out two image deformation methods to build up more
artificial image data to increase the number of labeled images.",2024-07-11,"Jackson Hamel, Ming-Jun Lai, Zhaiming Shen, Ye Tian",http://arxiv.org/pdf/2407.08800v2,cs.LG
Deep Inverse Design for High-Level Synthesis,"High-level synthesis (HLS) has significantly advanced the automation of
digital circuits design, yet the need for expertise and time in pragma tuning
remains challenging. Existing solutions for the design space exploration (DSE)
adopt either heuristic methods, lacking essential information for further
optimization potential, or predictive models, missing sufficient generalization
due to the time-consuming nature of HLS and the exponential growth of the
design space. To address these challenges, we propose Deep Inverse Design for
HLS (DID4HLS), a novel approach that integrates graph neural networks and
generative models. DID4HLS iteratively optimizes hardware designs aimed at
compute-intensive algorithms by learning conditional distributions of design
features from post-HLS data. Compared to four state-of-the-art DSE baselines,
our method achieved an average improvement of 42.8% on average distance to
reference set (ADRS) compared to the best-performing baselines across six
benchmarks, while demonstrating high robustness and efficiency. The code is
available at https://github.com/PingChang818/DID4HLS.",2024-07-11,"Ping Chang, Tosiron Adegbija, Yuchao Liao, Claudio Talarico, Ao Li, Janet Roveda",http://arxiv.org/pdf/2407.08797v3,cs.LG
Video Diffusion Alignment via Reward Gradients,"We have made significant progress towards building foundational video
diffusion models. As these models are trained using large-scale unsupervised
data, it has become crucial to adapt these models to specific downstream tasks.
Adapting these models via supervised fine-tuning requires collecting target
datasets of videos, which is challenging and tedious. In this work, we utilize
pre-trained reward models that are learned via preferences on top of powerful
vision discriminative models to adapt video diffusion models. These models
contain dense gradient information with respect to generated RGB pixels, which
is critical to efficient learning in complex search spaces, such as videos. We
show that backpropagating gradients from these reward models to a video
diffusion model can allow for compute and sample efficient alignment of the
video diffusion model. We show results across a variety of reward models and
video diffusion models, demonstrating that our approach can learn much more
efficiently in terms of reward queries and computation than prior gradient-free
approaches. Our code, model weights,and more visualization are available at
https://vader-vid.github.io.",2024-07-11,"Mihir Prabhudesai, Russell Mendonca, Zheyang Qin, Katerina Fragkiadaki, Deepak Pathak",http://arxiv.org/pdf/2407.08737v1,cs.LG
Transformer Circuit Faithfulness Metrics are not Robust,"Mechanistic interpretability work attempts to reverse engineer the learned
algorithms present inside neural networks. One focus of this work has been to
discover 'circuits' -- subgraphs of the full model that explain behaviour on
specific tasks. But how do we measure the performance of such circuits? Prior
work has attempted to measure circuit 'faithfulness' -- the degree to which the
circuit replicates the performance of the full model. In this work, we survey
many considerations for designing experiments that measure circuit faithfulness
by ablating portions of the model's computation. Concerningly, we find existing
methods are highly sensitive to seemingly insignificant changes in the ablation
methodology. We conclude that existing circuit faithfulness scores reflect both
the methodological choices of researchers as well as the actual components of
the circuit - the task a circuit is required to perform depends on the ablation
used to test it. The ultimate goal of mechanistic interpretability work is to
understand neural networks, so we emphasize the need for more clarity in the
precise claims being made about circuits. We open source a library at
https://github.com/UFO-101/auto-circuit that includes highly efficient
implementations of a wide range of ablation methodologies and circuit discovery
algorithms.",2024-07-11,"Joseph Miller, Bilal Chughtai, William Saunders",http://arxiv.org/pdf/2407.08734v1,cs.LG
BiEquiFormer: Bi-Equivariant Representations for Global Point Cloud Registration,"The goal of this paper is to address the problem of global point cloud
registration (PCR) i.e., finding the optimal alignment between point clouds
irrespective of the initial poses of the scans. This problem is notoriously
challenging for classical optimization methods due to computational
constraints. First, we show that state-of-the-art deep learning methods suffer
from huge performance degradation when the point clouds are arbitrarily placed
in space. We propose that equivariant deep learning should be utilized for
solving this task and we characterize the specific type of bi-equivariance of
PCR. Then, we design BiEquiformer a novel and scalable bi-equivariant pipeline
i.e. equivariant to the independent transformations of the input point clouds.
While a naive approach would process the point clouds independently we design
expressive bi-equivariant layers that fuse the information from both point
clouds. This allows us to extract high-quality superpoint correspondences and
in turn, robust point-cloud registration. Extensive comparisons against
state-of-the-art methods show that our method achieves comparable performance
in the canonical setting and superior performance in the robust setting in both
the 3DMatch and the challenging low-overlap 3DLoMatch dataset.",2024-07-11,"Stefanos Pertigkiozoglou, Evangelos Chatzipantazis, Kostas Daniilidis",http://arxiv.org/pdf/2407.08729v2,cs.LG
Topological Generalization Bounds for Discrete-Time Stochastic Optimization Algorithms,"We present a novel set of rigorous and computationally efficient
topology-based complexity notions that exhibit a strong correlation with the
generalization gap in modern deep neural networks (DNNs). DNNs show remarkable
generalization properties, yet the source of these capabilities remains
elusive, defying the established statistical learning theory. Recent studies
have revealed that properties of training trajectories can be indicative of
generalization. Building on this insight, state-of-the-art methods have
leveraged the topology of these trajectories, particularly their fractal
dimension, to quantify generalization. Most existing works compute this
quantity by assuming continuous- or infinite-time training dynamics,
complicating the development of practical estimators capable of accurately
predicting generalization without access to test data. In this paper, we
respect the discrete-time nature of training trajectories and investigate the
underlying topological quantities that can be amenable to topological data
analysis tools. This leads to a new family of reliable topological complexity
measures that provably bound the generalization error, eliminating the need for
restrictive geometric assumptions. These measures are computationally friendly,
enabling us to propose simple yet effective algorithms for computing
generalization indices. Moreover, our flexible framework can be extended to
different domains, tasks, and architectures. Our experimental results
demonstrate that our new complexity measures correlate highly with
generalization error in industry-standards architectures such as transformers
and deep graph networks. Our approach consistently outperforms existing
topological bounds across a wide range of datasets, models, and optimizers,
highlighting the practical relevance and effectiveness of our complexity
measures.",2024-07-11,"Rayna Andreeva, Benjamin Dupuis, Rik Sarkar, Tolga Birdal, Umut Şimşekli",http://arxiv.org/pdf/2407.08723v2,cs.LG
Unifying 3D Representation and Control of Diverse Robots with a Single Camera,"Mirroring the complex structures and diverse functions of natural organisms
is a long-standing challenge in robotics. Modern fabrication techniques have
dramatically expanded feasible hardware, yet deploying these systems requires
control software to translate desired motions into actuator commands. While
conventional robots can easily be modeled as rigid links connected via joints,
it remains an open challenge to model and control bio-inspired robots that are
often multi-material or soft, lack sensing capabilities, and may change their
material properties with use. Here, we introduce Neural Jacobian Fields, an
architecture that autonomously learns to model and control robots from vision
alone. Our approach makes no assumptions about the robot's materials,
actuation, or sensing, requires only a single camera for control, and learns to
control the robot without expert intervention by observing the execution of
random commands. We demonstrate our method on a diverse set of robot
manipulators, varying in actuation, materials, fabrication, and cost. Our
approach achieves accurate closed-loop control and recovers the causal dynamic
structure of each robot. By enabling robot control with a generic camera as the
only sensor, we anticipate our work will dramatically broaden the design space
of robotic systems and serve as a starting point for lowering the barrier to
robotic automation.",2024-07-11,"Sizhe Lester Li, Annan Zhang, Boyuan Chen, Hanna Matusik, Chao Liu, Daniela Rus, Vincent Sitzmann",http://arxiv.org/pdf/2407.08722v1,cs.LG
Sensor-Aware Classifiers for Energy-Efficient Time Series Applications on IoT Devices,"Time-series data processing is an important component of many real-world
applications, such as health monitoring, environmental monitoring, and digital
agriculture. These applications collect distinct windows of sensor data (e.g.,
few seconds) and process them to assess the environment. Machine learning (ML)
models are being employed in time-series applications due to their
generalization abilities for classification. State-of-the-art time-series
applications wait for entire sensor data window to become available before
processing the data using ML algorithms, resulting in high sensor energy
consumption. However, not all situations require processing full sensor window
to make accurate inference. For instance, in activity recognition, sitting and
standing activities can be inferred with partial windows. Using this insight,
we propose to employ early exit classifiers with partial sensor windows to
minimize energy consumption while maintaining accuracy. Specifically, we first
utilize multiple early exits with successively increasing amount of data as
they become available in a window. If early exits provide inference with high
confidence, we return the label and enter low power mode for sensors. The
proposed approach has potential to enable significant energy savings in time
series applications. We utilize neural networks and random forest classifiers
to evaluate our approach. Our evaluations with six datasets show that the
proposed approach enables up to 50-60% energy savings on average without any
impact on accuracy. The energy savings can enable time-series applications in
remote locations with limited energy availability.",2024-07-11,"Dina Hussein, Lubah Nelson, Ganapati Bhat",http://arxiv.org/pdf/2407.08715v1,cs.LG
eyeballvul: a future-proof benchmark for vulnerability detection in the wild,"Long contexts of recent LLMs have enabled a new use case: asking models to
find security vulnerabilities in entire codebases. To evaluate model
performance on this task, we introduce eyeballvul: a benchmark designed to test
the vulnerability detection capabilities of language models at scale, that is
sourced and updated weekly from the stream of published vulnerabilities in
open-source repositories. The benchmark consists of a list of revisions in
different repositories, each associated with the list of known vulnerabilities
present at that revision. An LLM-based scorer is used to compare the list of
possible vulnerabilities returned by a model to the list of known
vulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+
vulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around
55GB in size.",2024-07-11,Timothee Chauvin,http://arxiv.org/pdf/2407.08708v2,cs.LG
Extracting Training Data from Document-Based VQA Models,"Vision-Language Models (VLMs) have made remarkable progress in document-based
Visual Question Answering (i.e., responding to queries about the contents of an
input document provided as an image). In this work, we show these models can
memorize responses for training samples and regurgitate them even when the
relevant visual information has been removed. This includes Personal
Identifiable Information (PII) repeated once in the training set, indicating
these models could divulge memorised sensitive information and therefore pose a
privacy risk. We quantitatively measure the extractability of information in
controlled experiments and differentiate between cases where it arises from
generalization capabilities or from memorization. We further investigate the
factors that influence memorization across multiple state-of-the-art models and
propose an effective heuristic countermeasure that empirically prevents the
extractability of PII.",2024-07-11,"Francesco Pinto, Nathalie Rauschmayr, Florian Tramèr, Philip Torr, Federico Tombari",http://arxiv.org/pdf/2407.08707v1,cs.LG
Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware,"This paper explores the synergistic potential of neuromorphic and edge
computing to create a versatile machine learning (ML) system tailored for
processing data captured by dynamic vision sensors. We construct and train
hybrid models, blending spiking neural networks (SNNs) and artificial neural
networks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture
integrates an SNN for temporal feature extraction and an ANN for
classification. We delve into the challenges of deploying such hybrid
structures on hardware. Specifically, we deploy individual components on
Intel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We
also propose an accumulator circuit to transfer data from the spiking to the
non-spiking domain. Furthermore, we conduct comprehensive performance analyses
of hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI
hardware, evaluating accuracy, latency, power, and energy consumption. Our
findings demonstrate that the hybrid spiking networks surpass the baseline ANN
model across all metrics and outperform the baseline SNN model in accuracy and
latency.",2024-07-11,"James Seekings, Peyton Chandarana, Mahsa Ardakani, MohammadReza Mohammadi, Ramtin Zand",http://arxiv.org/pdf/2407.08704v1,cs.LG
Flex-TPU: A Flexible TPU with Runtime Reconfigurable Dataflow Architecture,"Tensor processing units (TPUs) are one of the most well-known machine
learning (ML) accelerators utilized at large scale in data centers as well as
in tiny ML applications. TPUs offer several improvements and advantages over
conventional ML accelerators, like graphical processing units (GPUs), being
designed specifically to perform the multiply-accumulate (MAC) operations
required in the matrix-matrix and matrix-vector multiplies extensively present
throughout the execution of deep neural networks (DNNs). Such improvements
include maximizing data reuse and minimizing data transfer by leveraging the
temporal dataflow paradigms provided by the systolic array architecture. While
this design provides a significant performance benefit, the current
implementations are restricted to a single dataflow consisting of either input,
output, or weight stationary architectures. This can limit the achievable
performance of DNN inference and reduce the utilization of compute units.
Therefore, the work herein consists of developing a reconfigurable dataflow
TPU, called the Flex-TPU, which can dynamically change the dataflow per layer
during run-time. Our experiments thoroughly test the viability of the Flex-TPU
comparing it to conventional TPU designs across multiple well-known ML
workloads. The results show that our Flex-TPU design achieves a significant
performance increase of up to 2.75x compared to conventional TPU, with only
minor area and power overheads.",2024-07-11,"Mohammed Elbtity, Peyton Chandarana, Ramtin Zand",http://arxiv.org/pdf/2407.08700v1,cs.LG
Mitigating Catastrophic Forgetting in Language Transfer via Model Merging,"As open-weight large language models (LLMs) achieve ever more impressive
performances across a wide range of tasks in English, practitioners aim to
adapt these models to different languages. However, such language adaptation is
often accompanied by catastrophic forgetting of the base model's capabilities,
severely limiting the usefulness of the resulting model. We address this issue
by proposing Branch-and-Merge (BaM), a new adaptation method based on
iteratively merging multiple models, fine-tuned on a subset of the available
training data. BaM is based on the insight that this yields lower magnitude but
higher quality weight changes, reducing forgetting of the source domain while
maintaining learning on the target domain. We demonstrate in an extensive
empirical study on Bulgarian and German that BaM can significantly reduce
forgetting while matching or even improving target domain performance compared
to both standard continued pretraining and instruction finetuning across
different model architectures.",2024-07-11,"Anton Alexandrov, Veselin Raychev, Mark Niklas Müller, Ce Zhang, Martin Vechev, Kristina Toutanova",http://arxiv.org/pdf/2407.08699v2,cs.LG
Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight,"Runtime failure and performance degradation is commonplace in modern cloud
systems. For cloud providers, automatically determining the root cause of
incidents is paramount to ensuring high reliability and availability as prompt
fault localization can enable faster diagnosis and triage for timely
resolution. A compelling solution explored in recent work is causal reasoning
using causal graphs to capture relationships between varied cloud system
performance metrics. To be effective, however, systems developers must
correctly define the causal graph of their system, which is a time-consuming,
brittle, and challenging task that increases in difficulty for large and
dynamic systems and requires domain expertise. Alternatively, automated
data-driven approaches have limited efficacy for cloud systems due to the
inherent rarity of incidents. In this work, we present Atlas, a novel approach
to automatically synthesizing causal graphs for cloud systems. Atlas leverages
large language models (LLMs) to generate causal graphs using system
documentation, telemetry, and deployment feedback. Atlas is complementary to
data-driven causal discovery techniques, and we further enhance Atlas with a
data-driven validation step. We evaluate Atlas across a range of fault
localization scenarios and demonstrate that Atlas is capable of generating
causal graphs in a scalable and generalizable manner, with performance that far
surpasses that of data-driven algorithms and is commensurate to the
ground-truth baseline.",2024-07-11,"Zhiqiang Xie, Yujia Zheng, Lizi Ottens, Kun Zhang, Christos Kozyrakis, Jonathan Mace",http://arxiv.org/pdf/2407.08694v1,cs.LG
Robotic Control via Embodied Chain-of-Thought Reasoning,"A key limitation of learned robot control policies is their inability to
generalize outside their training data. Recent works on vision-language-action
models (VLAs) have shown that the use of large, internet pre-trained
vision-language models as the backbone of learned robot policies can
substantially improve their robustness and generalization ability. Yet, one of
the most exciting capabilities of large vision-language models in other domains
is their ability to reason iteratively through complex problems. Can that same
capability be brought into robotics to allow policies to improve performance by
reasoning about a given task before acting? Naive use of ""chain-of-thought""
(CoT) style prompting is significantly less effective with standard VLAs
because of the relatively simple training examples that are available to them.
Additionally, purely semantic reasoning about sub-tasks, as is common in
regular CoT, is insufficient for robot policies that need to ground their
reasoning in sensory observations and the robot state. To this end, we
introduce Embodied Chain-of-Thought Reasoning (ECoT) for VLAs, in which we
train VLAs to perform multiple steps of reasoning about plans, sub-tasks,
motions, and visually grounded features like object bounding boxes and end
effector positions, before predicting the robot action. We design a scalable
pipeline for generating synthetic training data for ECoT on large robot
datasets. We demonstrate, that ECoT increases the absolute success rate of
OpenVLA, the current strongest open-source VLA policy, by 28% across
challenging generalization tasks, without any additional robot training data.
Additionally, ECoT makes it easier for humans to interpret a policy's failures
and correct its behavior using natural language.",2024-07-11,"Michał Zawalski, William Chen, Karl Pertsch, Oier Mees, Chelsea Finn, Sergey Levine",http://arxiv.org/pdf/2407.08693v3,cs.LG
"Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers","As Artificial Intelligence (AI) tools are increasingly employed in diverse
real-world applications, there has been significant interest in regulating
these tools. To this end, several regulatory frameworks have been introduced by
different countries worldwide. For example, the European Union recently passed
the AI Act, the White House issued an Executive Order on safe, secure, and
trustworthy AI, and the White House Office of Science and Technology Policy
issued the Blueprint for an AI Bill of Rights (AI BoR). Many of these
frameworks emphasize the need for auditing and improving the trustworthiness of
AI tools, underscoring the importance of safety, privacy, explainability,
fairness, and human fallback options. Although these regulatory frameworks
highlight the necessity of enforcement, practitioners often lack detailed
guidance on implementing them. Furthermore, the extensive research on
operationalizing each of these aspects is frequently buried in technical papers
that are difficult for practitioners to parse. In this write-up, we address
this shortcoming by providing an accessible overview of existing literature
related to operationalizing regulatory principles. We provide
easy-to-understand summaries of state-of-the-art literature and highlight
various gaps that exist between regulatory guidelines and existing AI research,
including the trade-offs that emerge during operationalization. We hope that
this work not only serves as a starting point for practitioners interested in
learning more about operationalizing the regulatory guidelines outlined in the
Blueprint for an AI BoR but also provides researchers with a list of critical
open problems and gaps between regulations and state-of-the-art AI research.
Finally, we note that this is a working paper and we invite feedback in line
with the purpose of this document as described in the introduction.",2024-07-11,"Alex Oesterling, Usha Bhalla, Suresh Venkatasubramanian, Himabindu Lakkaraju",http://arxiv.org/pdf/2407.08689v1,cs.LG
Hardware Neural Control of CartPole and F1TENTH Race Car,"Nonlinear model predictive control (NMPC) has proven to be an effective
control method, but it is expensive to compute. This work demonstrates the use
of hardware FPGA neural network controllers trained to imitate NMPC with
supervised learning. We use these Neural Controllers (NCs) implemented on
inexpensive embedded FPGA hardware for high frequency control on physical
cartpole and F1TENTH race car. Our results show that the NCs match the control
performance of the NMPCs in simulation and outperform it in reality, due to the
faster control rate that is afforded by the quick FPGA NC inference. We
demonstrate kHz control rates for a physical cartpole and offloading control to
the FPGA hardware on the F1TENTH car. Code and hardware implementation for this
paper are available at https:// github.com/SensorsINI/Neural-Control-Tools.",2024-07-11,"Marcin Paluch, Florian Bolli, Xiang Deng, Antonio Rios Navarro, Chang Gao, Tobi Delbruck",http://arxiv.org/pdf/2407.08681v1,cs.LG
How to beat a Bayesian adversary,"Deep neural networks and other modern machine learning models are often
susceptible to adversarial attacks. Indeed, an adversary may often be able to
change a model's prediction through a small, directed perturbation of the
model's input - an issue in safety-critical applications. Adversarially robust
machine learning is usually based on a minmax optimisation problem that
minimises the machine learning loss under maximisation-based adversarial
attacks.
  In this work, we study adversaries that determine their attack using a
Bayesian statistical approach rather than maximisation. The resulting Bayesian
adversarial robustness problem is a relaxation of the usual minmax problem. To
solve this problem, we propose Abram - a continuous-time particle system that
shall approximate the gradient flow corresponding to the underlying learning
problem. We show that Abram approximates a McKean-Vlasov process and justify
the use of Abram by giving assumptions under which the McKean-Vlasov process
finds the minimiser of the Bayesian adversarial robustness problem. We discuss
two ways to discretise Abram and show its suitability in benchmark adversarial
deep learning experiments.",2024-07-11,"Zihan Ding, Kexin Jin, Jonas Latz, Chenguang Liu",http://arxiv.org/pdf/2407.08678v1,cs.LG
Estimation of spatio-temporal extremes via generative neural networks,"Recent methods in modeling spatial extreme events have focused on utilizing
parametric max-stable processes and their underlying dependence structure. In
this work, we provide a unified approach for analyzing spatial extremes with
little available data by estimating the distribution of model parameters or the
spatial dependence directly. By employing recent developments in generative
neural networks we predict a full sample-based distribution, allowing for
direct assessment of uncertainty regarding model parameters or other parameter
dependent functionals. We validate our method by fitting several simulated
max-stable processes, showing a high accuracy of the approach, regarding
parameter estimation, as well as uncertainty quantification. Additional
robustness checks highlight the generalization and extrapolation capabilities
of the model, while an application to precipitation extremes across Western
Germany demonstrates the usability of our approach in real-world scenarios.",2024-07-11,"Christopher Bülte, Lisa Leimenstoll, Melanie Schienle",http://arxiv.org/pdf/2407.08668v1,cs.LG
Controlling the Fidelity and Diversity of Deep Generative Models via Pseudo Density,"We introduce an approach to bias deep generative models, such as GANs and
diffusion models, towards generating data with either enhanced fidelity or
increased diversity. Our approach involves manipulating the distribution of
training and generated data through a novel metric for individual samples,
named pseudo density, which is based on the nearest-neighbor information from
real samples. Our approach offers three distinct techniques to adjust the
fidelity and diversity of deep generative models: 1) Per-sample perturbation,
enabling precise adjustments for individual samples towards either more common
or more unique characteristics; 2) Importance sampling during model inference
to enhance either fidelity or diversity in the generated data; 3) Fine-tuning
with importance sampling, which guides the generative model to learn an
adjusted distribution, thus controlling fidelity and diversity. Furthermore,
our fine-tuning method demonstrates the ability to improve the Frechet
Inception Distance (FID) for pre-trained generative models with minimal
iterations.",2024-07-11,"Shuangqi Li, Chen Liu, Tong Zhang, Hieu Le, Sabine Süsstrunk, Mathieu Salzmann",http://arxiv.org/pdf/2407.08659v2,cs.LG
SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss,"Identification of vessel structures of different sizes in biomedical images
is crucial in the diagnosis of many neurodegenerative diseases. However, the
sparsity of good-quality annotations of such images makes the task of vessel
segmentation challenging. Deep learning offers an efficient way to segment
vessels of different sizes by learning their high-level feature representations
and the spatial continuity of such features across dimensions. Semi-supervised
patch-based approaches have been effective in identifying small vessels of one
to two voxels in diameter. This study focuses on improving the segmentation
quality by considering the spatial correlation of the features using the
Maximum Intensity Projection~(MIP) as an additional loss criterion. Two methods
are proposed with the incorporation of MIPs of label segmentation on the
single~(z-axis) and multiple perceivable axes of the 3D volume. The proposed
MIP-based methods produce segmentations with improved vessel continuity, which
is evident in visual examinations of ROIs. Patch-based training is improved by
introducing an additional loss term, MIP loss, to penalise the predicted
discontinuity of vessels. A training set of 14 volumes is selected from the
StudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight~(ToF) Magnetic
Resonance Angiography (MRA) images. The generalisation performance of the
method is evaluated using the other unseen volumes in the dataset. It is
observed that the proposed method with multi-axes MIP loss produces better
quality segmentations with a median Dice of $80.245 \pm 0.129$. Also, the
method with single-axis MIP loss produces segmentations with a median Dice of
$79.749 \pm 0.109$. Furthermore, a visual comparison of the ROIs in the
predicted segmentation reveals a significant improvement in the continuity of
the vessels when MIP loss is incorporated into training.",2024-07-11,"Chethan Radhakrishna, Karthikesh Varma Chintalapati, Sri Chandana Hudukula Ram Kumar, Raviteja Sutrave, Hendrik Mattern, Oliver Speck, Andreas Nürnberger, Soumick Chatterjee",http://arxiv.org/pdf/2407.08655v1,cs.LG
"Have We Reached AGI? Comparing ChatGPT, Claude, and Gemini to Human Literacy and Education Benchmarks","Recent advancements in AI, particularly in large language models (LLMs) like
ChatGPT, Claude, and Gemini, have prompted questions about their proximity to
Artificial General Intelligence (AGI). This study compares LLM performance on
educational benchmarks with Americans' average educational attainment and
literacy levels, using data from the U.S. Census Bureau and technical reports.
Results show that LLMs significantly outperform human benchmarks in tasks such
as undergraduate knowledge and advanced reading comprehension, indicating
substantial progress toward AGI. However, true AGI requires broader cognitive
assessments. The study highlights the implications for AI development,
education, and societal impact, emphasizing the need for ongoing research and
ethical considerations.",2024-07-11,Mfon Akpan,http://arxiv.org/pdf/2407.09573v1,cs.LG
Adaptive Smooth Non-Stationary Bandits,"We study a $K$-armed non-stationary bandit model where rewards change
smoothly, as captured by H\""{o}lder class assumptions on rewards as functions
of time. Such smooth changes are parametrized by a H\""{o}lder exponent $\beta$
and coefficient $\lambda$. While various sub-cases of this general model have
been studied in isolation, we first establish the minimax dynamic regret rate
generally for all $K,\beta,\lambda$. Next, we show this optimal dynamic regret
can be attained adaptively, without knowledge of $\beta,\lambda$. To contrast,
even with parameter knowledge, upper bounds were only previously known for
limited regimes $\beta\leq 1$ and $\beta=2$ (Slivkins, 2014; Krishnamurthy and
Gopalan, 2021; Manegueu et al., 2021; Jia et al.,2023). Thus, our work resolves
open questions raised by these disparate threads of the literature.
  We also study the problem of attaining faster gap-dependent regret rates in
non-stationary bandits. While such rates are long known to be impossible in
general (Garivier and Moulines, 2011), we show that environments admitting a
safe arm (Suk and Kpotufe, 2022) allow for much faster rates than the
worst-case scaling with $\sqrt{T}$. While previous works in this direction
focused on attaining the usual logarithmic regret bounds, as summed over
stationary periods, our new gap-dependent rates reveal new optimistic regimes
of non-stationarity where even the logarithmic bounds are pessimistic. We show
our new gap-dependent rate is tight and that its achievability (i.e., as made
possible by a safe arm) has a surprisingly simple and clean characterization
within the smooth H\""{o}lder class model.",2024-07-11,Joe Suk,http://arxiv.org/pdf/2407.08654v2,cs.LG
Confidence-based Estimators for Predictive Performance in Model Monitoring,"After a machine learning model has been deployed into production, its
predictive performance needs to be monitored. Ideally, such monitoring can be
carried out by comparing the model's predictions against ground truth labels.
For this to be possible, the ground truth labels must be available relatively
soon after inference. However, there are many use cases where ground truth
labels are available only after a significant delay, or in the worst case, not
at all. In such cases, directly monitoring the model's predictive performance
is impossible.
  Recently, novel methods for estimating the predictive performance of a model
when ground truth is unavailable have been developed. Many of these methods
leverage model confidence or other uncertainty estimates and are experimentally
compared against a naive baseline method, namely Average Confidence (AC), which
estimates model accuracy as the average of confidence scores for a given set of
predictions. However, until now the theoretical properties of the AC method
have not been properly explored. In this paper, we try to fill this gap by
reviewing the AC method and show that under certain general assumptions, it is
an unbiased and consistent estimator of model accuracy with many desirable
properties. We also compare this baseline estimator against some more complex
estimators empirically and show that in many cases the AC method is able to
beat the others, although the comparative quality of the different estimators
is heavily case-dependent.",2024-07-11,"Juhani Kivimäki, Jakub Białek, Jukka K. Nurminen, Wojtek Kuberski",http://arxiv.org/pdf/2407.08649v2,cs.LG
From Real to Cloned Singer Identification,"Cloned voices of popular singers sound increasingly realistic and have gained
popularity over the past few years. They however pose a threat to the industry
due to personality rights concerns. As such, methods to identify the original
singer in synthetic voices are needed. In this paper, we investigate how singer
identification methods could be used for such a task. We present three
embedding models that are trained using a singer-level contrastive learning
scheme, where positive pairs consist of segments with vocals from the same
singers. These segments can be mixtures for the first model, vocals for the
second, and both for the third. We demonstrate that all three models are highly
capable of identifying real singers. However, their performance deteriorates
when classifying cloned versions of singers in our evaluation set. This is
especially true for models that use mixtures as an input. These findings
highlight the need to understand the biases that exist within singer
identification systems, and how they can influence the identification of voice
deepfakes in music.",2024-07-11,"Dorian Desblancs, Gabriel Meseguer-Brocal, Romain Hennequin, Manuel Moussallam",http://arxiv.org/pdf/2407.08647v1,cs.LG
How more data can hurt: Instability and regularization in next-generation reservoir computing,"It has been found recently that more data can, counter-intuitively, hurt the
performance of deep neural networks. Here, we show that a more extreme version
of the phenomenon occurs in data-driven models of dynamical systems. To
elucidate the underlying mechanism, we focus on next-generation reservoir
computing (NGRC) -- a popular framework for learning dynamics from data. We
find that, despite learning a better representation of the flow map with more
training data, NGRC can adopt an ill-conditioned ``integrator'' and lose
stability. We link this data-induced instability to the auxiliary dimensions
created by the delayed states in NGRC. Based on these findings, we propose
simple strategies to mitigate the instability, either by increasing
regularization strength in tandem with data size, or by carefully introducing
noise during training. Our results highlight the importance of proper
regularization in data-driven modeling of dynamical systems.",2024-07-11,"Yuanzhao Zhang, Edmilson Roque dos Santos, Sean P. Cornelius",http://arxiv.org/pdf/2407.08641v2,cs.LG
$β$-DPO: Direct Preference Optimization with Dynamic $β$,"Direct Preference Optimization (DPO) has emerged as a compelling approach for
training Large Language Models (LLMs) to adhere to human preferences. However,
the performance of DPO is sensitive to the fine-tuning of its trade-off
parameter $\beta$, as well as to the quality of the preference data. We analyze
the impact of $\beta$ and data quality on DPO, uncovering that optimal $\beta$
values vary with the informativeness of pairwise data. Addressing the
limitations of static $\beta$ values, we introduce a novel framework that
dynamically calibrates $\beta$ at the batch level, informed by data quality
considerations. Additionally, our method incorporates $\beta$-guided data
filtering to safeguard against the influence of outliers. Through empirical
evaluation, we demonstrate that our dynamic $\beta$ adjustment technique
significantly improves DPO's performance across a range of models and datasets,
offering a more robust and adaptable training paradigm for aligning LLMs with
human feedback. The code is available at
\url{https://github.com/junkangwu/beta-DPO}.",2024-07-11,"Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He",http://arxiv.org/pdf/2407.08639v2,cs.LG
Generalization Error Matters in Decentralized Learning Under Byzantine Attacks,"Recently, decentralized learning has emerged as a popular peer-to-peer signal
and information processing paradigm that enables model training across
geographically distributed agents in a scalable manner, without the presence of
any central server. When some of the agents are malicious (also termed as
Byzantine), resilient decentralized learning algorithms are able to limit the
impact of these Byzantine agents without knowing their number and identities,
and have guaranteed optimization errors. However, analysis of the
generalization errors, which are critical to implementations of the trained
models, is still lacking. In this paper, we provide the first analysis of the
generalization errors for a class of popular Byzantine-resilient decentralized
stochastic gradient descent (DSGD) algorithms. Our theoretical results reveal
that the generalization errors cannot be entirely eliminated because of the
presence of the Byzantine agents, even if the number of training samples are
infinitely large. Numerical experiments are conducted to confirm our
theoretical results.",2024-07-11,"Haoxiang Ye, Qing Ling",http://arxiv.org/pdf/2407.08632v1,cs.LG
RoboMorph: Evolving Robot Morphology using Large Language Models,"We introduce RoboMorph, an automated approach for generating and optimizing
modular robot designs using large language models (LLMs) and evolutionary
algorithms. In this framework, we represent each robot design as a grammar and
leverage the capabilities of LLMs to navigate the extensive robot design space,
which is traditionally time-consuming and computationally demanding. By
introducing a best-shot prompting technique and a reinforcement learning-based
control algorithm, RoboMorph iteratively improves robot designs through
feedback loops. Experimental results demonstrate that RoboMorph successfully
generates nontrivial robots optimized for different terrains while showcasing
improvements in robot morphology over successive evolutions. Our approach
highlights the potential of using LLMs for data-driven, modular robot design,
providing a promising methodology that can be extended to other domains with
similar design frameworks.",2024-07-11,"Kevin Qiu, Władysław Pałucki, Krzysztof Ciebiera, Paweł Fijałkowski, Marek Cygan, Łukasz Kuciński",http://arxiv.org/pdf/2407.08626v2,cs.LG
Surpassing Cosine Similarity for Multidimensional Comparisons: Dimension Insensitive Euclidean Metric,"Advances in computational power and hardware efficiency have enabled tackling
increasingly complex, high-dimensional problems. While artificial intelligence
(AI) achieves remarkable results, the interpretability of high-dimensional
solutions remains challenging. A critical issue is the comparison of
multidimensional quantities, essential in techniques like Principal Component
Analysis. Metrics such as cosine similarity are often used, for example in the
development of natural language processing algorithms or recommender systems.
However, the interpretability of such metrics diminishes as dimensions
increase. This paper analyzes the effects of dimensionality, revealing
significant limitations of cosine similarity, particularly its dependency on
the dimension of vectors, leading to biased and poorly interpretable outcomes.
To address this, we introduce a Dimension Insensitive Euclidean Metric (DIEM)
which demonstrates superior robustness and generalizability across dimensions.
DIEM maintains consistent variability and eliminates the biases observed in
traditional metrics, making it a reliable tool for high-dimensional
comparisons. An example of the advantages of DIEM over cosine similarity is
reported for a large language model application. This novel metric has the
potential to replace cosine similarity, providing a more accurate and
insightful method to analyze multidimensional data in fields ranging from
neuromotor control to machine learning.",2024-07-11,"Federico Tessari, Kunpeng Yao, Neville Hogan",http://arxiv.org/pdf/2407.08623v4,cs.LG
Semantic GUI Scene Learning and Video Alignment for Detecting Duplicate Video-based Bug Reports,"Video-based bug reports are increasingly being used to document bugs for
programs centered around a graphical user interface (GUI). However, developing
automated techniques to manage video-based reports is challenging as it
requires identifying and understanding often nuanced visual patterns that
capture key information about a reported bug. In this paper, we aim to overcome
these challenges by advancing the bug report management task of duplicate
detection for video-based reports. To this end, we introduce a new approach,
called JANUS, that adapts the scene-learning capabilities of vision
transformers to capture subtle visual and textual patterns that manifest on app
UI screens - which is key to differentiating between similar screens for
accurate duplicate report detection. JANUS also makes use of a video alignment
technique capable of adaptive weighting of video frames to account for typical
bug manifestation patterns. In a comprehensive evaluation on a benchmark
containing 7,290 duplicate detection tasks derived from 270 video-based bug
reports from 90 Android app bugs, the best configuration of our approach
achieves an overall mRR/mAP of 89.8%/84.7%, and for the large majority of
duplicate detection tasks, outperforms prior work by around 9% to a
statistically significant degree. Finally, we qualitatively illustrate how the
scene-learning capabilities provided by Janus benefits its performance.",2024-07-11,"Yanfu Yan, Nathan Cooper, Oscar Chaparro, Kevin Moran, Denys Poshyvanyk",http://arxiv.org/pdf/2407.08610v1,cs.LG
FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision,"Attention, as a core layer of the ubiquitous Transformer architecture, is the
bottleneck for large language models and long-context applications.
FlashAttention elaborated an approach to speed up attention on GPUs through
minimizing memory reads/writes. However, it has yet to take advantage of new
capabilities present in recent hardware, with FlashAttention-2 achieving only
35% utilization on the H100 GPU. We develop three main techniques to speed up
attention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to
(1) overlap overall computation and data movement via warp-specialization and
(2) interleave block-wise matmul and softmax operations, and (3) block
quantization and incoherent processing that leverages hardware support for FP8
low-precision. We demonstrate that our method, FlashAttention-3, achieves
speedup on H100 GPUs by 1.5-2.0$\times$ with FP16 reaching up to 740 TFLOPs/s
(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate
that FP8 FlashAttention-3 achieves 2.6$\times$ lower numerical error than a
baseline FP8 attention.",2024-07-11,"Jay Shah, Ganesh Bikshandi, Ying Zhang, Vijay Thakkar, Pradeep Ramani, Tri Dao",http://arxiv.org/pdf/2407.08608v2,cs.LG
Learning Program Behavioral Models from Synthesized Input-Output Pairs,"We introduce Modelizer - a novel framework that, given a black-box program,
learns a model from its input/output behavior using neural machine translation
algorithms. The resulting model mocks the original program: Given an input, the
model predicts the output that would have been produced by the program.
However, the model is also reversible - that is, the model can predict the
input that would have produced a given output. Finally, the model is
differentiable and can be efficiently restricted to predict only a certain
aspect of the program behavior. Modelizer uses grammars to synthesize and
inputs and unsupervised tokenizers to decompose the resulting outputs, allowing
it to learn sequence-to-sequence associations between token streams. Other than
input grammars, Modelizer only requires the ability to execute the program. The
resulting models are small, requiring fewer than 6.3 million parameters for
languages such as Markdown or HTML; and they are accurate, achieving up to
95.4% accuracy and a BLEU score of 0.98 with standard error 0.04 in mocking
real-world applications. As it learns from and predicts executions rather than
code, Modelizer departs from the LLM-centric research trend, opening new
opportunities for program-specific models that are fully tuned towards
individual programs. Indeed, we foresee several applications of these models,
especially as the output of the program can be any aspect of program behavior.
Beyond mocking and predicting program behavior, the models can also synthesize
inputs that are likely to produce a particular behavior, such as failures or
coverage, thus assisting in program understanding and maintenance.",2024-07-11,"Tural Mammadov, Dietrich Klakow, Alexander Koller, Andreas Zeller",http://arxiv.org/pdf/2407.08597v2,cs.LG
A Review of Nine Physics Engines for Reinforcement Learning Research,"We present a review of popular simulation engines and frameworks used in
reinforcement learning (RL) research, aiming to guide researchers in selecting
tools for creating simulated physical environments for RL and training setups.
It evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,
PyBullet, Webots, and Unity) based on their popularity, feature range, quality,
usability, and RL capabilities. We highlight the challenges in selecting and
utilizing physics engines for RL research, including the need for detailed
comparisons and an understanding of each framework's capabilities. Key findings
indicate MuJoCo as the leading framework due to its performance and
flexibility, despite usability challenges. Unity is noted for its ease of use
but lacks scalability and simulation fidelity. The study calls for further
development to improve simulation engines' usability and performance and
stresses the importance of transparency and reproducibility in RL research.
This review contributes to the RL community by offering insights into the
selection process for simulation engines, facilitating informed
decision-making.",2024-07-11,"Michael Kaup, Cornelius Wolff, Hyerim Hwang, Julius Mayer, Elia Bruni",http://arxiv.org/pdf/2407.08590v2,cs.LG
HACMan++: Spatially-Grounded Motion Primitives for Manipulation,"Although end-to-end robot learning has shown some success for robot
manipulation, the learned policies are often not sufficiently robust to
variations in object pose or geometry. To improve the policy generalization, we
introduce spatially-grounded parameterized motion primitives in our method
HACMan++. Specifically, we propose an action representation consisting of three
components: what primitive type (such as grasp or push) to execute, where the
primitive will be grounded (e.g. where the gripper will make contact with the
world), and how the primitive motion is executed, such as parameters specifying
the push direction or grasp orientation. These three components define a novel
discrete-continuous action space for reinforcement learning. Our framework
enables robot agents to learn to chain diverse motion primitives together and
select appropriate primitive parameters to complete long-horizon manipulation
tasks. By grounding the primitives on a spatial location in the environment,
our method is able to effectively generalize across object shape and pose
variations. Our approach significantly outperforms existing methods,
particularly in complex scenarios demanding both high-level sequential
reasoning and object generalization. With zero-shot sim-to-real transfer, our
policy succeeds in challenging real-world manipulation tasks, with
generalization to unseen objects. Videos can be found on the project website:
https://sgmp-rss2024.github.io.",2024-07-11,"Bowen Jiang, Yilin Wu, Wenxuan Zhou, Chris Paxton, David Held",http://arxiv.org/pdf/2407.08585v1,cs.LG
The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective,"The rapid development of large language models (LLMs) has been witnessed in
recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the
modality from text to a broader spectrum of domains, attracting widespread
attention due to the broader range of application scenarios. As LLMs and MLLMs
rely on vast amounts of model parameters and data to achieve emergent
capabilities, the importance of data is receiving increasingly widespread
attention and recognition. Tracing and analyzing recent data-oriented works for
MLLMs, we find that the development of models and data is not two separate
paths but rather interconnected. On the one hand, vaster and higher-quality
data contribute to better performance of MLLMs; on the other hand, MLLMs can
facilitate the development of data. The co-development of multi-modal data and
MLLMs requires a clear view of 1) at which development stages of MLLMs specific
data-centric approaches can be employed to enhance certain MLLM capabilities,
and 2) how MLLMs, utilizing those capabilities, can contribute to multi-modal
data in specific roles. To promote the data-model co-development for MLLM
community, we systematically review existing works related to MLLMs from the
data-model co-development perspective. A regularly maintained project
associated with this survey is accessible at
https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.",2024-07-11,"Zhen Qin, Daoyuan Chen, Wenhao Zhang, Liuyi Yao, Yilun Huang, Bolin Ding, Yaliang Li, Shuiguang Deng",http://arxiv.org/pdf/2407.08583v2,cs.LG
Multi-Group Proportional Representation in Retrieval,"Image search and retrieval tasks can perpetuate harmful stereotypes, erase
cultural identities, and amplify social disparities. Current approaches to
mitigate these representational harms balance the number of retrieved items
across population groups defined by a small number of (often binary)
attributes. However, most existing methods overlook intersectional groups
determined by combinations of group attributes, such as gender, race, and
ethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel
metric that measures representation across intersectional groups. We develop
practical methods for estimating MPR, provide theoretical guarantees, and
propose optimization algorithms to ensure MPR in retrieval. We demonstrate that
existing methods optimizing for equal and proportional representation metrics
may fail to promote MPR. Crucially, our work shows that optimizing MPR yields
more proportional representation across multiple intersectional groups
specified by a rich function class, often with minimal compromise in retrieval
accuracy.",2024-07-11,"Alex Oesterling, Claudio Mayrink Verdun, Carol Xuan Long, Alexander Glynn, Lucas Monteiro Paes, Sajani Vithana, Martina Cardone, Flavio P. Calmon",http://arxiv.org/pdf/2407.08571v2,cs.LG
Adaptive Parametric Activation,"The activation function plays a crucial role in model optimisation, yet the
optimal choice remains unclear. For example, the Sigmoid activation is the
de-facto activation in balanced classification tasks, however, in imbalanced
classification, it proves inappropriate due to bias towards frequent classes.
In this work, we delve deeper in this phenomenon by performing a comprehensive
statistical analysis in the classification and intermediate layers of both
balanced and imbalanced networks and we empirically show that aligning the
activation function with the data distribution, enhances the performance in
both balanced and imbalanced tasks. To this end, we propose the Adaptive
Parametric Activation (APA) function, a novel and versatile activation function
that unifies most common activation functions under a single formula. APA can
be applied in both intermediate layers and attention layers, significantly
outperforming the state-of-the-art on several imbalanced benchmarks such as
ImageNet-LT, iNaturalist2018, Places-LT, CIFAR100-LT and LVIS and balanced
benchmarks such as ImageNet1K, COCO and V3DET. The code is available at
https://github.com/kostas1515/AGLU.",2024-07-11,"Konstantinos Panagiotis Alexandridis, Jiankang Deng, Anh Nguyen, Shan Luo",http://arxiv.org/pdf/2407.08567v2,cs.LG
Causal inference through multi-stage learning and doubly robust deep neural networks,"Deep neural networks (DNNs) have demonstrated remarkable empirical
performance in large-scale supervised learning problems, particularly in
scenarios where both the sample size $n$ and the dimension of covariates $p$
are large. This study delves into the application of DNNs across a wide
spectrum of intricate causal inference tasks, where direct estimation falls
short and necessitates multi-stage learning. Examples include estimating the
conditional average treatment effect and dynamic treatment effect. In this
framework, DNNs are constructed sequentially, with subsequent stages building
upon preceding ones. To mitigate the impact of estimation errors from early
stages on subsequent ones, we integrate DNNs in a doubly robust manner. In
contrast to previous research, our study offers theoretical assurances
regarding the effectiveness of DNNs in settings where the dimensionality $p$
expands with the sample size. These findings are significant independently and
extend to degenerate single-stage learning problems.",2024-07-11,"Yuqian Zhang, Jelena Bradic",http://arxiv.org/pdf/2407.08560v1,cs.LG
Quantitative Evaluation of the Saliency Map for Alzheimer's Disease Classifier with Anatomical Segmentation,"Saliency maps have been widely used to interpret deep learning classifiers
for Alzheimer's disease (AD). However, since AD is heterogeneous and has
multiple subtypes, the pathological mechanism of AD remains not fully
understood and may vary from patient to patient. Due to the lack of such
understanding, it is difficult to comprehensively and effectively assess the
saliency map of AD classifier. In this paper, we utilize the anatomical
segmentation to allocate saliency values into different brain regions. By
plotting the distributions of saliency maps corresponding to AD and NC (Normal
Control), we can gain a comprehensive view of the model's decisions process. In
order to leverage the fact that the brain volume shrinkage happens in AD
patients during disease progression, we define a new evaluation metric, brain
volume change score (VCS), by computing the average Pearson correlation of the
brain volume changes and the saliency values of a model in different brain
regions for each patient. Thus, the VCS metric can help us gain some knowledge
of how saliency maps resulting from different models relate to the changes of
the volumes across different regions in the whole brain. We trained candidate
models on the ADNI dataset and tested on three different datasets. Our results
indicate: (i) models with higher VCSs tend to demonstrate saliency maps with
more details relevant to the AD pathology, (ii) using gradient-based
adversarial training strategies such as FGSM and stochastic masking can improve
the VCSs of the models.",2024-07-11,"Yihan Zhang, Xuanshuo Zhang, Wei Wu, Haohan Wang",http://arxiv.org/pdf/2407.08546v1,cs.LG
Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model,"Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world
relationships, drawing heightened interest in dynamic graph learning across
academia and industry. However, existing CTDG models encounter challenges
stemming from noise and limited historical data. Graph Data Augmentation (GDA)
emerges as a critical solution, yet current approaches primarily focus on
static graphs and struggle to effectively address the dynamics inherent in
CTDGs. Moreover, these methods often demand substantial domain expertise for
parameter tuning and lack theoretical guarantees for augmentation efficacy. To
address these issues, we propose Conda, a novel latent diffusion-based GDA
method tailored for CTDGs. Conda features a sandwich-like architecture,
incorporating a Variational Auto-Encoder (VAE) and a conditional diffusion
model, aimed at generating enhanced historical neighbor embeddings for target
nodes. Unlike conventional diffusion models trained on entire graphs via
pre-training, Conda requires historical neighbor sequence embeddings of target
nodes for training, thus facilitating more targeted augmentation. We integrate
Conda into the CTDG model and adopt an alternating training strategy to
optimize performance. Extensive experimentation across six widely used
real-world datasets showcases the consistent performance improvement of our
approach, particularly in scenarios with limited historical data.",2024-07-11,"Yuxing Tian, Yiyan Qi, Aiwen Jiang, Qi Huang, Jian Guo",http://arxiv.org/pdf/2407.08500v2,cs.LG
Robust Generalization of Graph Neural Networks for Carrier Scheduling,"Battery-free sensor tags are devices that leverage backscatter techniques to
communicate with standard IoT devices, thereby augmenting a network's sensing
capabilities in a scalable way. For communicating, a sensor tag relies on an
unmodulated carrier provided by a neighboring IoT device, with a schedule
coordinating this provisioning across the network. Carrier
scheduling--computing schedules to interrogate all sensor tags while minimizing
energy, spectrum utilization, and latency--is an NP-Hard optimization problem.
Recent work introduces learning-based schedulers that achieve resource savings
over a carefully-crafted heuristic, generalizing to networks of up to 60 nodes.
However, we find that their advantage diminishes in networks with hundreds of
nodes, and degrades further in larger setups. This paper introduces
RobustGANTT, a GNN-based scheduler that improves generalization (without
re-training) to networks up to 1000 nodes (100x training topology sizes).
RobustGANTT not only achieves better and more consistent generalization, but
also computes schedules requiring up to 2x less resources than existing
systems. Our scheduler exhibits average runtimes of hundreds of milliseconds,
allowing it to react fast to changing network conditions. Our work not only
improves resource utilization in large-scale backscatter networks, but also
offers valuable insights in learning-based scheduling.",2024-07-11,"Daniel F. Perez-Ramirez, Carlos Pérez-Penichet, Nicolas Tsiftes, Dejan Kostic, Magnus Boman, Thiemo Voigt",http://arxiv.org/pdf/2407.08479v1,cs.LG
TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware Representations,"Unsupervised goal-conditioned reinforcement learning (GCRL) is a promising
paradigm for developing diverse robotic skills without external supervision.
However, existing unsupervised GCRL methods often struggle to cover a wide
range of states in complex environments due to their limited exploration and
sparse or noisy rewards for GCRL. To overcome these challenges, we propose a
novel unsupervised GCRL method that leverages TemporaL Distance-aware
Representations (TLDR). Based on temporal distance, TLDR selects faraway goals
to initiate exploration and computes intrinsic exploration rewards and
goal-reaching rewards. Specifically, our exploration policy seeks states with
large temporal distances (i.e. covering a large state space), while the
goal-conditioned policy learns to minimize the temporal distance to the goal
(i.e. reaching the goal). Our results in six simulated locomotion environments
demonstrate that TLDR significantly outperforms prior unsupervised GCRL methods
in achieving a wide range of states.",2024-07-11,"Junik Bae, Kwanyoung Park, Youngwoon Lee",http://arxiv.org/pdf/2407.08464v2,cs.LG
Distributed Deep Reinforcement Learning Based Gradient Quantization for Federated Learning Enabled Vehicle Edge Computing,"Federated Learning (FL) can protect the privacy of the vehicles in vehicle
edge computing (VEC) to a certain extent through sharing the gradients of
vehicles' local models instead of local data. The gradients of vehicles' local
models are usually large for the vehicular artificial intelligence (AI)
applications, thus transmitting such large gradients would cause large
per-round latency. Gradient quantization has been proposed as one effective
approach to reduce the per-round latency in FL enabled VEC through compressing
gradients and reducing the number of bits, i.e., the quantization level, to
transmit gradients. The selection of quantization level and thresholds
determines the quantization error, which further affects the model accuracy and
training time. To do so, the total training time and quantization error (QE)
become two key metrics for the FL enabled VEC. It is critical to jointly
optimize the total training time and QE for the FL enabled VEC. However, the
time-varying channel condition causes more challenges to solve this problem. In
this paper, we propose a distributed deep reinforcement learning (DRL)-based
quantization level allocation scheme to optimize the long-term reward in terms
of the total training time and QE. Extensive simulations identify the optimal
weighted factors between the total training time and QE, and demonstrate the
feasibility and effectiveness of the proposed scheme.",2024-07-11,"Cui Zhang, Wenjun Zhang, Qiong Wu, Pingyi Fan, Qiang Fan, Jiangzhou Wang, Khaled B. Letaief",http://arxiv.org/pdf/2407.08462v1,cs.LG
Genus expansion for non-linear random matrix ensembles with applications to neural networks,"We present a unified approach to studying certain non-linear random matrix
ensembles and associated random neural networks at initialization. This begins
with a novel series expansion for neural networks which generalizes Fa\'a di
Bruno's formula to an arbitrary number of compositions. The role of monomials
is played by random multilinear maps indexed by directed graphs, whose edges
correspond to random matrices. Crucially, this expansion linearizes the effect
of the activation functions, allowing for the direct application of Wick's
principle and the genus expansion technique. As an application, we prove
several results about neural networks with random weights. We first give a new
proof of the fact that they converge to Gaussian processes as their width tends
to infinity. Secondly, we quantify the rate of convergence of the Neural
Tangent Kernel to its deterministic limit in Frobenius norm. Finally, we
compute the moments of the limiting spectral distribution of the Jacobian (only
the first two of which were previously known), expressing them as sums over
non-crossing partitions. All of these results are then generalised to the case
of neural networks with sparse and non-Gaussian weights, under moment
assumptions.",2024-07-11,"Nicola Muca Cirone, Jad Hamdan, Cristopher Salvi",http://arxiv.org/pdf/2407.08459v5,cs.LG
Joint Optimization of Age of Information and Energy Consumption in NR-V2X System based on Deep Reinforcement Learning,"Autonomous driving may be the most important application scenario of next
generation, the development of wireless access technologies enabling reliable
and low-latency vehicle communication becomes crucial. To address this, 3GPP
has developed Vehicle-to-Everything (V2X) specifications based on 5G New Radio
(NR) technology, where Mode 2 Side-Link (SL) communication resembles Mode 4 in
LTE-V2X, allowing direct communication between vehicles. This supplements SL
communication in LTE-V2X and represents the latest advancement in cellular V2X
(C-V2X) with improved performance of NR-V2X. However, in NR-V2X Mode 2,
resource collisions still occur, and thus degrade the age of information (AOI).
Therefore, a interference cancellation method is employed to mitigate this
impact by combining NR-V2X with Non-Orthogonal multiple access (NOMA)
technology. In NR-V2X, when vehicles select smaller resource reservation
interval (RRI), higher-frequency transmissions take ore energy to reduce AoI.
Hence, it is important to jointly consider AoI and communication energy
consumption based on NR-V2X communication. Then, we formulate such an
optimization problem and employ the Deep Reinforcement Learning (DRL) algorithm
to compute the optimal transmission RRI and transmission power for each
transmitting vehicle to reduce the energy consumption of each transmitting
vehicle and the AoI of each receiving vehicle. Extensive simulations have
demonstrated the performance of our proposed algorithm.",2024-07-11,"Shulin Song, Zheng Zhang, Qiong Wu, Qiang Fan, Pingyi Fan",http://arxiv.org/pdf/2407.08458v1,cs.LG
How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation,"We present a comprehensive analysis of deep learning approaches for
Electronic Health Record (EHR) time-series imputation, examining how
architectural and framework biases combine to influence model performance. Our
investigation reveals varying capabilities of deep imputers in capturing
complex spatiotemporal dependencies within EHRs, and that model effectiveness
depends on how its combined biases align with medical time-series
characteristics. Our experimental evaluation challenges common assumptions
about model complexity, demonstrating that larger models do not necessarily
improve performance. Rather, carefully designed architectures can better
capture the complex patterns inherent in clinical data. The study highlights
the need for imputation approaches that prioritise clinically meaningful data
reconstruction over statistical accuracy. Our experiments show imputation
performance variations of up to 20\% based on preprocessing and implementation
choices, emphasising the need for standardised benchmarking methodologies.
Finally, we identify critical gaps between current deep imputation methods and
medical requirements, highlighting the importance of integrating clinical
insights to achieve more reliable imputation approaches for healthcare
applications.",2024-07-11,"Linglong Qian, Tao Wang, Jun Wang, Hugh Logan Ellis, Robin Mitra, Richard Dobson, Zina Ibrahim",http://arxiv.org/pdf/2407.08442v2,cs.LG
Improve Load Forecasting in Energy Communities through Transfer Learning using Open-Access Synthetic Profiles,"According to a conservative estimate, a 1% reduction in forecast error for a
10 GW energy utility can save up to $ 1.6 million annually. In our context,
achieving precise forecasts of future power consumption is crucial for
operating flexible energy assets using model predictive control approaches.
Specifically, this work focuses on the load profile forecast of a first-year
energy community with the common practical challenge of limited historical data
availability. We propose to pre-train the load prediction models with
open-access synthetic load profiles using transfer learning techniques to
tackle this challenge. Results show that this approach improves both, the
training stability and prediction error. In a test case with 74 households, the
prediction mean squared error (MSE) decreased from 0.34 to 0.13, showing
transfer learning based on synthetic load profiles to be a viable approach to
compensate for a lack of historic data.",2024-07-11,"Lukas Moosbrugger, Valentin Seiler, Gerhard Huber, Peter Kepplinger",http://arxiv.org/pdf/2407.08434v1,cs.LG
Subgroup-Specific Risk-Controlled Dose Estimation in Radiotherapy,"Cancer remains a leading cause of death, highlighting the importance of
effective radiotherapy (RT). Magnetic resonance-guided linear accelerators
(MR-Linacs) enable imaging during RT, allowing for inter-fraction, and perhaps
even intra-fraction, adjustments of treatment plans. However, achieving this
requires fast and accurate dose calculations. While Monte Carlo simulations
offer accuracy, they are computationally intensive. Deep learning frameworks
show promise, yet lack uncertainty quantification crucial for high-risk
applications like RT. Risk-controlling prediction sets (RCPS) offer
model-agnostic uncertainty quantification with mathematical guarantees.
However, we show that naive application of RCPS may lead to only certain
subgroups such as the image background being risk-controlled. In this work, we
extend RCPS to provide prediction intervals with coverage guarantees for
multiple subgroups with unknown subgroup membership at test time. We evaluate
our algorithm on real clinical planing volumes from five different anatomical
regions and show that our novel subgroup RCPS (SG-RCPS) algorithm leads to
prediction intervals that jointly control the risk for multiple subgroups. In
particular, our method controls the risk of the crucial voxels along the
radiation beam significantly better than conventional RCPS.",2024-07-11,"Paul Fischer, Hannah Willms, Moritz Schneider, Daniela Thorwarth, Michael Muehlebach, Christian F. Baumgartner",http://arxiv.org/pdf/2407.08432v1,cs.LG
PredBench: Benchmarking Spatio-Temporal Prediction across Diverse Disciplines,"In this paper, we introduce PredBench, a benchmark tailored for the holistic
evaluation of spatio-temporal prediction networks. Despite significant progress
in this field, there remains a lack of a standardized framework for a detailed
and comparative analysis of various prediction network architectures. PredBench
addresses this gap by conducting large-scale experiments, upholding
standardized and appropriate experimental settings, and implementing
multi-dimensional evaluations. This benchmark integrates 12 widely adopted
methods with 15 diverse datasets across multiple application domains, offering
extensive evaluation of contemporary spatio-temporal prediction networks.
Through meticulous calibration of prediction settings across various
applications, PredBench ensures evaluations relevant to their intended use and
enables fair comparisons. Moreover, its multi-dimensional evaluation framework
broadens the analysis with a comprehensive set of metrics, providing deep
insights into the capabilities of models. The findings from our research offer
strategic directions for future developments in the field. Our codebase is
available at https://github.com/OpenEarthLab/PredBench.",2024-07-11,"ZiDong Wang, Zeyu Lu, Di Huang, Tong He, Xihui Liu, Wanli Ouyang, Lei Bai",http://arxiv.org/pdf/2407.08418v2,cs.LG
Unveiling the Potential of BERTopic for Multilingual Fake News Analysis -- Use Case: Covid-19,"Topic modeling is frequently being used for analysing large text corpora such
as news articles or social media data. BERTopic, consisting of sentence
embedding, dimension reduction, clustering, and topic extraction, is the newest
and currently the SOTA topic modeling method. However, current topic modeling
methods have room for improvement because, as unsupervised methods, they
require careful tuning and selection of hyperparameters, e.g., for dimension
reduction and clustering. This paper aims to analyse the technical application
of BERTopic in practice. For this purpose, it compares and selects different
methods and hyperparameters for each stage of BERTopic through density based
clustering validation and six different topic coherence measures. Moreover, it
also aims to analyse the results of topic modeling on real world data as a use
case. For this purpose, the German fake news dataset (GermanFakeNCovid) on
Covid-19 was created by us and in order to experiment with topic modeling in a
multilingual (English and German) setting combined with the FakeCovid dataset.
With the final results, we were able to determine thematic similarities between
the United States and Germany. Whereas, distinguishing the topics of fake news
from India proved to be more challenging.",2024-07-11,"Karla Schäfer, Jeong-Eun Choi, Inna Vogel, Martin Steinebach",http://arxiv.org/pdf/2407.08417v1,cs.LG
Parallelizing Autoregressive Generation with Variational State Space Models,"Attention-based models such as Transformers and recurrent models like state
space models (SSMs) have emerged as successful methods for autoregressive
sequence modeling. Although both enable parallel training, none enable parallel
generation due to their autoregressiveness. We propose the variational SSM
(VSSM), a variational autoencoder (VAE) where both the encoder and decoder are
SSMs. Since sampling the latent variables and decoding them with the SSM can be
parallelized, both training and generation can be conducted in parallel.
Moreover, the decoder recurrence allows generation to be resumed without
reprocessing the whole sequence. Finally, we propose the autoregressive VSSM
that can be conditioned on a partial realization of the sequence, as is common
in language generation tasks. Interestingly, the autoregressive VSSM still
enables parallel generation. We highlight on toy problems (MNIST, CIFAR) the
empirical gains in speed-up and show that it competes with traditional models
in terms of generation quality (Transformer, Mamba SSM).",2024-07-11,"Gaspard Lambrechts, Yann Claes, Pierre Geurts, Damien Ernst",http://arxiv.org/pdf/2407.08415v1,cs.LG
Scalar Function Topology Divergence: Comparing Topology of 3D Objects,"We propose a new topological tool for computer vision - Scalar Function
Topology Divergence (SFTD), which measures the dissimilarity of multi-scale
topology between sublevel sets of two functions having a common domain.
Functions can be defined on an undirected graph or Euclidean space of any
dimensionality. Most of the existing methods for comparing topology are based
on Wasserstein distance between persistence barcodes and they don't take into
account the localization of topological features. The minimization of SFTD
ensures that the corresponding topological features of scalar functions are
located in the same places. The proposed tool provides useful visualizations
depicting areas where functions have topological dissimilarities. We provide
applications of the proposed method to 3D computer vision. In particular,
experiments demonstrate that SFTD as an additional loss improves the
reconstruction of cellular 3D shapes from 2D fluorescence microscopy images,
and helps to identify topological errors in 3D segmentation. Additionally, we
show that SFTD outperforms Betti matching loss in 2D segmentation problems.",2024-07-11,"Ilya Trofimov, Daria Voronkova, Eduard Tulchinskii, Evgeny Burnaev, Serguei Barannikov",http://arxiv.org/pdf/2407.08364v3,cs.LG
STAL: Spike Threshold Adaptive Learning Encoder for Classification of Pain-Related Biosignal Data,"This paper presents the first application of spiking neural networks (SNNs)
for the classification of chronic lower back pain (CLBP) using the EmoPain
dataset. Our work has two main contributions. We introduce Spike Threshold
Adaptive Learning (STAL), a trainable encoder that effectively converts
continuous biosignals into spike trains. Additionally, we propose an ensemble
of Spiking Recurrent Neural Network (SRNN) classifiers for the multi-stream
processing of sEMG and IMU data. To tackle the challenges of small sample size
and class imbalance, we implement minority over-sampling with weighted sample
replacement during batch creation. Our method achieves outstanding performance
with an accuracy of 80.43%, AUC of 67.90%, F1 score of 52.60%, and Matthews
Correlation Coefficient (MCC) of 0.437, surpassing traditional rate-based and
latency-based encoding methods. The STAL encoder shows superior performance in
preserving temporal dynamics and adapting to signal characteristics.
Importantly, our approach (STAL-SRNN) outperforms the best deep learning method
in terms of MCC, indicating better balanced class prediction. This research
contributes to the development of neuromorphic computing for biosignal
analysis. It holds promise for energy-efficient, wearable solutions in chronic
pain management.",2024-07-11,"Freek Hens, Mohammad Mahdi Dehshibi, Leila Bagheriye, Mahyar Shahsavari, Ana Tajadura-Jiménez",http://arxiv.org/pdf/2407.08362v1,cs.LG
AutoBencher: Towards Declarative Benchmark Construction,"We present AutoBencher, a declarative framework for automatic benchmark
construction, and use it to scalably discover novel insights and
vulnerabilities of existing language models. Concretely, given a few desiderata
of benchmarks (e.g., question difficulty, topic salience), we operationalize
each desideratum and cast benchmark creation as an optimization problem.
Specifically, we experiment with two settings with different optimization
objectives: (i) for capability evaluation, we declare the goal of finding a
salient, difficult dataset that induces novel performance patterns; (ii) for
safety evaluation, we declare the goal of finding a dataset of unsafe prompts
that existing LMs fail to decline. To tackle this optimization problem, we use
a language model to iteratively propose and refine dataset descriptions, which
are then used to generate topic-specific questions and answers. These
descriptions are optimized to improve the declared desiderata. We use
AutoBencher (powered by GPT-4) to create datasets for math, multilinguality,
knowledge, and safety. The scalability of AutoBencher allows it to test
fine-grained categories and tail knowledge, creating datasets that elicit 22%
more model errors (i.e., difficulty) than existing benchmarks. On the novelty
ends, AutoBencher also helps identify specific gaps not captured by existing
benchmarks: e.g., Gemini-Pro has knowledge gaps on Permian Extinction and
Fordism while GPT-4o fails to decline harmful requests about cryptocurrency
scams.",2024-07-11,"Xiang Lisa Li, Farzaan Kaiyom, Evan Zheran Liu, Yifan Mai, Percy Liang, Tatsunori Hashimoto",http://arxiv.org/pdf/2407.08351v2,cs.LG
Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On,"In this paper, we investigate the underlying factors that potentially enhance
the mathematical reasoning capabilities of large language models (LLMs). We
argue that the data scaling law for math reasoning capabilities in modern LLMs
is far from being saturated, highlighting how the model's quality improves with
increases in data quantity. To support this claim, we introduce the
Skywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using
our proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved
impressive accuracies of 51.2% on the competition-level MATH benchmark and
83.9% on the GSM8K benchmark using only SFT data, outperforming an early
version of GPT-4 on MATH. The superior performance of Skywork-Math models
contributes to our novel two-stage data synthesis and model SFT pipelines,
which include three different augmentation methods and a diverse seed problem
set, ensuring both the quantity and quality of Skywork-MathQA dataset across
varying difficulty levels. Most importantly, we provide several practical
takeaways to enhance math reasoning abilities in LLMs for both research and
industry applications.",2024-07-11,"Liang Zeng, Liangjun Zhong, Liang Zhao, Tianwen Wei, Liu Yang, Jujie He, Cheng Cheng, Rui Hu, Yang Liu, Shuicheng Yan, Han Fang, Yahui Zhou",http://arxiv.org/pdf/2407.08348v2,cs.LG
SLRL: Structured Latent Representation Learning for Multi-view Clustering,"In recent years, Multi-View Clustering (MVC) has attracted increasing
attention for its potential to reduce the annotation burden associated with
large datasets. The aim of MVC is to exploit the inherent consistency and
complementarity among different views, thereby integrating information from
multiple perspectives to improve clustering outcomes.
  Despite extensive research in MVC, most existing methods focus predominantly
on harnessing complementary information across views to enhance clustering
effectiveness, often neglecting the structural information among samples, which
is crucial for exploring sample correlations. To address this gap, we introduce
a novel framework, termed Structured Latent Representation Learning based
Multi-View Clustering method (SLRL). SLRL leverages both the complementary and
structural information. Initially, it learns a common latent representation for
all views. Subsequently, to exploit the structural information among samples, a
k-nearest neighbor graph is constructed from this common latent representation.
This graph facilitates enhanced sample interaction through graph learning
techniques, leading to a structured latent representation optimized for
clustering. Extensive experiments demonstrate that SLRL not only competes well
with existing methods but also sets new benchmarks in various multi-view
datasets.",2024-07-11,"Zhangci Xiong, Meng Cao",http://arxiv.org/pdf/2407.08340v1,cs.LG
FedLog: Personalized Federated Classification with Less Communication and More Flexibility,"Federated representation learning (FRL) aims to learn personalized federated
models with effective feature extraction from local data. FRL algorithms that
share the majority of the model parameters face significant challenges with
huge communication overhead. This overhead stems from the millions of neural
network parameters and slow aggregation progress of the averaging heuristic. To
reduce the overhead, we propose to share sufficient data summaries instead of
raw model parameters. The data summaries encode minimal sufficient statistics
of an exponential family, and Bayesian inference is utilized for global
aggregation. It helps to reduce message sizes and communication frequency. To
further ensure formal privacy guarantee, we extend it with differential privacy
framework. Empirical results demonstrate high learning accuracy with low
communication overhead of our method.",2024-07-11,"Haolin Yu, Guojun Zhang, Pascal Poupart",http://arxiv.org/pdf/2407.08337v2,cs.LG
HDT: Hierarchical Document Transformer,"In this paper, we propose the Hierarchical Document Transformer (HDT), a
novel sparse Transformer architecture tailored for structured hierarchical
documents. Such documents are extremely important in numerous domains,
including science, law or medicine. However, most existing solutions are
inefficient and fail to make use of the structure inherent to documents. HDT
exploits document structure by introducing auxiliary anchor tokens and
redesigning the attention mechanism into a sparse multi-level hierarchy. This
approach facilitates information exchange between tokens at different levels
while maintaining sparsity, thereby enhancing computational and memory
efficiency while exploiting the document structure as an inductive bias. We
address the technical challenge of implementing HDT's sample-dependent
hierarchical attention pattern by developing a novel sparse attention kernel
that considers the hierarchical structure of documents. As demonstrated by our
experiments, utilizing structural information present in documents leads to
faster convergence, higher sample efficiency and better performance on
downstream tasks.",2024-07-11,"Haoyu He, Markus Flicke, Jan Buchmann, Iryna Gurevych, Andreas Geiger",http://arxiv.org/pdf/2407.08330v1,cs.LG
Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports,"This study applies Natural Language Processing techniques, including Latent
Dirichlet Allocation, to analyse anonymised maternity incident investigation
reports from the Healthcare Safety Investigation Branch. The reports underwent
preprocessing, annotation using the Safety Intelligence Research taxonomy, and
topic modelling to uncover prevalent topics and detect differences in maternity
care across ethnic groups. A combination of offline and online methods was
utilised to ensure data protection whilst enabling advanced analysis, with
offline processing for sensitive data and online processing for non-sensitive
data using the `Claude 3 Opus' language model. Interactive topic analysis and
semantic network visualisation were employed to extract and display thematic
topics and visualise semantic relationships among keywords. The analysis
revealed disparities in care among different ethnic groups, with distinct focus
areas for the Black, Asian, and White British ethnic groups. The study
demonstrates the effectiveness of topic modelling and NLP techniques in
analysing maternity incident investigation reports and highlighting disparities
in care. The findings emphasise the crucial role of advanced data analysis in
improving maternity care quality and equity.",2024-07-11,"Georgina Cosma, Mohit Kumar Singh, Patrick Waterson, Gyuchan Thomas Jun, Jonathan Back",http://arxiv.org/pdf/2407.08328v1,cs.LG
A Cantor-Kantorovich Metric Between Markov Decision Processes with Application to Transfer Learning,"We extend the notion of Cantor-Kantorovich distance between Markov chains
introduced by (Banse et al., 2023) in the context of Markov Decision Processes
(MDPs). The proposed metric is well-defined and can be efficiently approximated
given a finite horizon. Then, we provide numerical evidences that the latter
metric can lead to interesting applications in the field of reinforcement
learning. In particular, we show that it could be used for forecasting the
performance of transfer learning algorithms.",2024-07-11,"Adrien Banse, Venkatraman Renganathan, Raphaël M. Jungers",http://arxiv.org/pdf/2407.08324v1,cs.LG
Refining ADHD diagnosis with EEG: The impact of preprocessing and temporal segmentation on classification accuracy,"Background: EEG signals are commonly used in ADHD diagnosis, but they are
often affected by noise and artifacts. Effective preprocessing and segmentation
methods can significantly enhance the accuracy and reliability of ADHD
classification. Methods: We applied filtering, ASR, and ICA preprocessing
techniques to EEG data from children with ADHD and neurotypical controls. The
EEG recordings were segmented, and features were extracted and selected based
on statistical significance. Classification was performed using various EEG
segments and channels with Machine Learning models (SVM, KNN, and XGBoost) to
identify the most effective combinations for accurate ADHD diagnosis. Results:
Our findings show that models trained on later EEG segments achieved
significantly higher accuracy, indicating the potential role of cognitive
fatigue in distinguishing ADHD. The highest classification accuracy (86.1%) was
achieved using data from the P3, P4, and C3 channels, with key features such as
Kurtosis, Katz fractal dimension, and power spectrums in the Delta, Theta, and
Alpha bands contributing to the results. Conclusion: This study highlights the
importance of preprocessing and segmentation in improving the reliability of
ADHD diagnosis through EEG. The results suggest that further research on
cognitive fatigue and segmentation could enhance diagnostic accuracy in ADHD
patients.",2024-07-11,"Sandra García-Ponsoda, Alejandro Maté, Juan Trujillo",http://arxiv.org/pdf/2407.08316v2,cs.LG
Improving Molecular Modeling with Geometric GNNs: an Empirical Study,"Rapid advancements in machine learning (ML) are transforming materials
science by significantly speeding up material property calculations. However,
the proliferation of ML approaches has made it challenging for scientists to
keep up with the most promising techniques. This paper presents an empirical
study on Geometric Graph Neural Networks for 3D atomic systems, focusing on the
impact of different (1) canonicalization methods, (2) graph creation
strategies, and (3) auxiliary tasks, on performance, scalability and symmetry
enforcement. Our findings and insights aim to guide researchers in selecting
optimal modeling components for molecular modeling tasks.",2024-07-11,"Ali Ramlaoui, Théo Saulus, Basile Terver, Victor Schmidt, David Rolnick, Fragkiskos D. Malliaros, Alexandre Duval",http://arxiv.org/pdf/2407.08313v1,cs.LG
XAI-Guided Enhancement of Vegetation Indices for Crop Mapping,"Vegetation indices allow to efficiently monitor vegetation growth and
agricultural activities. Previous generations of satellites were capturing a
limited number of spectral bands, and a few expert-designed vegetation indices
were sufficient to harness their potential. New generations of multi- and
hyperspectral satellites can however capture additional bands, but are not yet
efficiently exploited. In this work, we propose an explainable-AI-based method
to select and design suitable vegetation indices. We first train a deep neural
network using multispectral satellite data, then extract feature importance to
identify the most influential bands. We subsequently select suitable existing
vegetation indices or modify them to incorporate the identified bands and
retrain our model. We validate our approach on a crop classification task. Our
results indicate that models trained on individual indices achieve comparable
results to the baseline model trained on all bands, while the combination of
two indices surpasses the baseline in certain cases.",2024-07-11,"Hiba Najjar, Francisco Mena, Marlon Nuske, Andreas Dengel",http://arxiv.org/pdf/2407.08298v1,cs.LG
Q-GaLore: Quantized GaLore with INT4 Projection and Layer-Adaptive Low-Rank Gradients,"Training Large Language Models (LLMs) is memory-intensive due to the large
number of parameters and associated optimization states. GaLore, a recent
method, reduces memory usage by projecting weight gradients into a low-rank
subspace without compromising performance. However, GaLore relies on
time-consuming Singular Value Decomposition (SVD) operations to identify the
subspace, and the frequent subspace updates lead to significant training time
overhead. Moreover, GaLore offers minimal improvements in accuracy and
efficiency compared to LoRA in more accessible fine-tuning scenarios. To
address these limitations, we introduce Q-Galore, a novel approach that
substantially reduces memory usage by combining quantization and low-rank
projection, surpassing the benefits of GaLore. Our method is based on two key
observations: (i) the gradient subspace exhibits diverse properties, with some
layers converging early in training while others are subject to frequent
changes; (ii) the projection matrices are highly resilient to low-bit
quantization. Leveraging these insights, Q-GaLore adaptively updates the
gradient subspace based on its convergence statistics, achieving comparable
performance while significantly reducing the number of SVD operations. We
maintain the projection matrices in INT4 format and weights in INT8 format,
incorporating stochastic rounding to capture accumulated gradient information.
This approach enables a high-precision training trajectory using only
low-precision weights. We demonstrate that Q-GaLore achieves highly competitive
performance with exceptional memory efficiency. At pre-training, Q-GaLore
facilitates training a LLaMA-7B model from scratch on a single NVIDIA RTX 4060
Ti with only 16 GB memory. At fine-tuning, it reduces memory consumption by up
to 50% compared to LoRA and GaLore, while consistently outperforming QLoRA at
the same memory cost.",2024-07-11,"Zhenyu Zhang, Ajay Jaiswal, Lu Yin, Shiwei Liu, Jiawei Zhao, Yuandong Tian, Zhangyang Wang",http://arxiv.org/pdf/2407.08296v1,cs.LG
Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data,"Cardiovascular diseases (CVDs) encompass a group of disorders affecting the
heart and blood vessels, including conditions such as coronary artery disease,
heart failure, stroke, and hypertension. In cardiovascular diseases, heart
failure is one of the main causes of death and also long-term suffering in
patients worldwide. Prediction is one of the risk factors that is highly
valuable for treatment and intervention to minimize heart failure. In this
work, an attention learning-based heart failure prediction approach is proposed
on EHR(electronic health record) cardiovascular data such as ejection fraction
and serum creatinine. Moreover, different optimizers with various learning rate
approaches are applied to fine-tune the proposed approach. Serum creatinine and
ejection fraction are the two most important features to predict the patient's
heart failure. The computational result shows that the RMSProp optimizer with
0.001 learning rate has a better prediction based on serum creatinine. On the
other hand, the combination of SGD optimizer with 0.01 learning rate exhibits
optimum performance based on ejection fraction features. Overall, the proposed
attention learning-based approach performs very efficiently in predicting heart
failure compared to the existing state-of-the-art such as LSTM approach.",2024-07-11,"Ershadul Haque, Manoranjan Paul, Faranak Tohidi",http://arxiv.org/pdf/2407.08289v1,cs.LG
AoA-Based Physical Layer Authentication in Analog Arrays under Impersonation Attacks,"We discuss the use of angle of arrival (AoA) as an authentication measure in
analog array multiple-input multiple-output (MIMO) systems. A base station
equipped with an analog array authenticates users based on the AoA estimated
from certified pilot transmissions, while active attackers manipulate their
transmitted signals to mount impersonation attacks. We study several attacks of
increasing intensity (captured through the availability of side information at
the attackers) and assess the performance of AoA-based authentication using
one-class classifiers. Our results show that some attack techniques with
knowledge of the combiners at the verifier are effective in falsifying the AoA
and compromising the security of the considered type of physical layer
authentication.",2024-07-11,"Muralikrishnan Srinivasan, Linda Senigagliesi, Hui Chen, Arsenia Chorti, Marco Baldi, Henk Wymeersch",http://arxiv.org/pdf/2407.08282v1,cs.LG
Explainability of Sub-Field Level Crop Yield Prediction using Remote Sensing,"Crop yield forecasting plays a significant role in addressing growing
concerns about food security and guiding decision-making for policymakers and
farmers. When deep learning is employed, understanding the learning and
decision-making processes of the models, as well as their interaction with the
input data, is crucial for establishing trust in the models and gaining insight
into their reliability. In this study, we focus on the task of crop yield
prediction, specifically for soybean, wheat, and rapeseed crops in Argentina,
Uruguay, and Germany. Our goal is to develop and explain predictive models for
these crops, using a large dataset of satellite images, additional data
modalities, and crop yield maps. We employ a long short-term memory network and
investigate the impact of using different temporal samplings of the satellite
data and the benefit of adding more relevant modalities. For model
explainability, we utilize feature attribution methods to quantify input
feature contributions, identify critical growth stages, analyze yield
variability at the field level, and explain less accurate predictions.
  The modeling results show an improvement when adding more modalities or using
all available instances of satellite data. The explainability results reveal
distinct feature importance patterns for each crop and region. We further found
that the most influential growth stages on the prediction are dependent on the
temporal sampling of the input data. We demonstrated how these critical growth
stages, which hold significant agronomic value, closely align with the existing
literature in agronomy and crop development biology.",2024-07-11,"Hiba Najjar, Miro Miranda, Marlon Nuske, Ribana Roscher, Andreas Dengel",http://arxiv.org/pdf/2407.08274v1,cs.LG
Gaussian process interpolation with conformal prediction: methods and comparative analysis,"This article advocates the use of conformal prediction (CP) methods for
Gaussian process (GP) interpolation to enhance the calibration of prediction
intervals. We begin by illustrating that using a GP model with parameters
selected by maximum likelihood often results in predictions that are not
optimally calibrated. CP methods can adjust the prediction intervals, leading
to better uncertainty quantification while maintaining the accuracy of the
underlying GP model. We compare different CP variants and introduce a novel
variant based on an asymmetric score. Our numerical experiments demonstrate the
effectiveness of CP methods in improving calibration without compromising
accuracy. This work aims to facilitate the adoption of CP methods in the GP
community.",2024-07-11,"Aurélien Pion, Emmanuel Vazquez",http://arxiv.org/pdf/2407.08271v1,cs.LG
SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories,"Assessing different material properties to predict specific attributes, such
as band gap, resistivity, young modulus, work function, and refractive index,
is a fundamental requirement for materials science-based applications. However,
the process is time-consuming and often requires extensive literature reviews
and numerous experiments. Our study addresses these challenges by leveraging
machine learning to analyze material properties with greater precision and
efficiency. By automating the data extraction process and using the extracted
information to train machine learning models, our developed model, SciQu,
optimizes material properties. As a proof of concept, we predicted the
refractive index of materials using data extracted from numerous research
articles with SciQu, considering input descriptors such as space group, volume,
and bandgap with Root Mean Square Error (RMSE) 0.068 and R2 0.94. Thus, SciQu
not only predicts the properties of materials but also plays a key role in
self-driving laboratories by optimizing the synthesis parameters to achieve
precise shape, size, and phase of the materials subjected to the input
parameters.",2024-07-11,Anand Babu,http://arxiv.org/pdf/2407.08270v1,cs.LG
Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear,"Models based on convolutional neural networks (CNN) and transformers have
steadily been improved. They also have been applied in various computer vision
downstream tasks. However, in object detection tasks, accurately localizing and
classifying almost infinite categories of foods in images remains challenging.
To address these problems, we first segmented the food as the
region-of-interest (ROI) by using the segment-anything model (SAM) and masked
the rest of the region except ROI as black pixels. This process simplified the
problems into a single classification for which annotation and training were
much simpler than object detection. The images in which only the ROI was
preserved were fed as inputs to fine-tune various off-the-shelf models that
encoded their own inductive biases. Among them, Data-efficient image
Transformers (DeiTs) had the best classification performance. Nonetheless, when
foods' shapes and textures were similar, the contextual features of the
ROI-only images were not enough for accurate classification. Therefore, we
introduced a novel type of combined architecture, RveRNet, which consisted of
ROI, extra-ROI, and integration modules that allowed it to account for both the
ROI's and global contexts. The RveRNet's F1 score was 10% better than other
individual models when classifying ambiguous food images. If the RveRNet's
modules were DeiT with the knowledge distillation from the CNN, performed the
best. We investigated how architectures can be made robust against input noise
caused by permutation and translocation. The results indicated that there was a
trade-off between how much the CNN teacher's knowledge could be distilled to
DeiT and DeiT's innate strength. Code is publicly available at:
https://github.com/Seonwhee-Genome/RveRNet.",2024-07-11,Seonwhee Jin,http://arxiv.org/pdf/2407.08257v1,cs.LG
Adaptive Compressed Sensing with Diffusion-Based Posterior Sampling,"Compressed Sensing (CS) facilitates rapid image acquisition by selecting a
small subset of measurements sufficient for high-fidelity reconstruction.
Adaptive CS seeks to further enhance this process by dynamically choosing
future measurements based on information gleaned from data that is already
acquired. However, many existing frameworks are often tailored to specific
tasks and require intricate training procedures. We propose AdaSense, a novel
Adaptive CS approach that leverages zero-shot posterior sampling with
pre-trained diffusion models. By sequentially sampling from the posterior
distribution, we can quantify the uncertainty of each possible future linear
measurement throughout the acquisition process. AdaSense eliminates the need
for additional training and boasts seamless adaptation to diverse domains with
minimal tuning requirements. Our experiments demonstrate the effectiveness of
AdaSense in reconstructing facial images from a small number of measurements.
Furthermore, we apply AdaSense for active acquisition of medical images in the
domains of magnetic resonance imaging (MRI) and computed tomography (CT),
highlighting its potential for tangible real-world acceleration.",2024-07-11,"Noam Elata, Tomer Michaeli, Michael Elad",http://arxiv.org/pdf/2407.08256v1,cs.LG
GraphMamba: An Efficient Graph Structure Learning Vision Mamba for Hyperspectral Image Classification,"Efficient extraction of spectral sequences and geospatial information has
always been a hot topic in hyperspectral image classification. In terms of
spectral sequence feature capture, RNN and Transformer have become mainstream
classification frameworks due to their long-range feature capture capabilities.
In terms of spatial information aggregation, CNN enhances the receptive field
to retain integrated spatial information as much as possible. However, the
spectral feature-capturing architectures exhibit low computational efficiency,
and CNNs lack the flexibility to perceive spatial contextual information. To
address these issues, this paper proposes GraphMamba--an efficient graph
structure learning vision Mamba classification framework that fully considers
HSI characteristics to achieve deep spatial-spectral information mining.
Specifically, we propose a novel hyperspectral visual GraphMamba processing
paradigm (HVGM) that preserves spatial-spectral features by constructing
spatial-spectral cubes and utilizes linear spectral encoding to enhance the
operability of subsequent tasks. The core components of GraphMamba include the
HyperMamba module for improving computational efficiency and the SpectralGCN
module for adaptive spatial context awareness. The HyperMamba mitigates clutter
interference by employing the global mask (GM) and introduces a parallel
training inference architecture to alleviate computational bottlenecks. The
SpatialGCN incorporates weighted multi-hop aggregation (WMA) spatial encoding
to focus on highly correlated spatial structural features, thus flexibly
aggregating contextual information while mitigating spatial noise interference.
Extensive experiments were conducted on three different scales of real HSI
datasets, and compared with the state-of-the-art classification frameworks,
GraphMamba achieved optimal performance.",2024-07-11,"Aitao Yang, Min Li, Yao Ding, Leyuan Fang, Yaoming Cai, Yujie He",http://arxiv.org/pdf/2407.08255v1,cs.LG
Gradient Boosting Reinforcement Learning,"Neural networks (NN) achieve remarkable results in various tasks, but lack
key characteristics: interpretability, support for categorical features, and
lightweight implementations suitable for edge devices. While ongoing efforts
aim to address these challenges, Gradient Boosting Trees (GBT) inherently meet
these requirements. As a result, GBTs have become the go-to method for
supervised learning tasks in many real-world applications and competitions.
However, their application in online learning scenarios, notably in
reinforcement learning (RL), has been limited. In this work, we bridge this gap
by introducing Gradient-Boosting RL (GBRL), a framework that extends the
advantages of GBT to the RL domain. Using the GBRL framework, we implement
various actor-critic algorithms and compare their performance with their NN
counterparts. Inspired by shared backbones in NN we introduce a tree-sharing
approach for policy and value functions with distinct learning rates, enhancing
learning efficiency over millions of interactions. GBRL achieves competitive
performance across a diverse array of tasks, excelling in domains with
structured or categorical features. Additionally, we present a
high-performance, GPU-accelerated implementation that integrates seamlessly
with widely-used RL libraries (available at https://github.com/NVlabs/gbrl).
GBRL expands the toolkit for RL practitioners, demonstrating the viability and
promise of GBT within the RL paradigm, particularly in domains characterized by
structured or categorical features.",2024-07-11,"Benjamin Fuhrer, Chen Tessler, Gal Dalal",http://arxiv.org/pdf/2407.08250v1,cs.LG
Feature Diversification and Adaptation for Federated Domain Generalization,"Federated learning, a distributed learning paradigm, utilizes multiple
clients to build a robust global model. In real-world applications, local
clients often operate within their limited domains, leading to a `domain shift'
across clients. Privacy concerns limit each client's learning to its own domain
data, which increase the risk of overfitting. Moreover, the process of
aggregating models trained on own limited domain can be potentially lead to a
significant degradation in the global model performance. To deal with these
challenges, we introduce the concept of federated feature diversification. Each
client diversifies the own limited domain data by leveraging global feature
statistics, i.e., the aggregated average statistics over all participating
clients, shared through the global model's parameters. This data
diversification helps local models to learn client-invariant representations
while preserving privacy. Our resultant global model shows robust performance
on unseen test domain data. To enhance performance further, we develop an
instance-adaptive inference approach tailored for test domain data. Our
proposed instance feature adapter dynamically adjusts feature statistics to
align with the test input, thereby reducing the domain gap between the test and
training domains. We show that our method achieves state-of-the-art performance
on several domain generalization benchmarks within a federated learning
setting.",2024-07-11,"Seunghan Yang, Seokeon Choi, Hyunsin Park, Sungha Choi, Simyung Chang, Sungrack Yun",http://arxiv.org/pdf/2407.08245v1,cs.LG
An Unsupervised Domain Adaptation Method for Locating Manipulated Region in partially fake Audio,"When the task of locating manipulation regions in partially-fake audio (PFA)
involves cross-domain datasets, the performance of deep learning models drops
significantly due to the shift between the source and target domains. To
address this issue, existing approaches often employ data augmentation before
training. However, they overlook the characteristics in target domain that are
absent in source domain. Inspired by the mixture-of-experts model, we propose
an unsupervised method named Samples mining with Diversity and Entropy (SDE).
Our method first learns from a collection of diverse experts that achieve great
performance from different perspectives in the source domain, but with
ambiguity on target samples. We leverage these diverse experts to select the
most informative samples by calculating their entropy. Furthermore, we
introduced a label generation method tailored for these selected samples that
are incorporated in the training process in source domain integrating the
target domain information. We applied our method to a cross-domain partially
fake audio detection dataset, ADD2023Track2. By introducing 10% of unknown
samples from the target domain, we achieved an F1 score of 43.84%, which
represents a relative increase of 77.2% compared to the second-best method.",2024-07-11,"Siding Zeng, Jiangyan Yi, Jianhua Tao, Yujie Chen, Shan Liang, Yong Ren, Xiaohui Zhang",http://arxiv.org/pdf/2407.08239v1,cs.LG
Differentially Private Neural Network Training under Hidden State Assumption,"We present a novel approach called differentially private stochastic block
coordinate descent (DP-SBCD) for training neural networks with provable
guarantees of differential privacy under the hidden state assumption. Our
methodology incorporates Lipschitz neural networks and decomposes the training
process of the neural network into sub-problems, each corresponding to the
training of a specific layer. By doing so, we extend the analysis of
differential privacy under the hidden state assumption to encompass non-convex
problems and algorithms employing proximal gradient descent. Furthermore, in
contrast to existing methods, we adopt a novel approach by utilizing calibrated
noise sampled from adaptive distributions, yielding improved empirical
trade-offs between utility and privacy.",2024-07-11,"Ding Chen, Chen Liu",http://arxiv.org/pdf/2407.08233v1,cs.LG
SwishReLU: A Unified Approach to Activation Functions for Enhanced Deep Neural Networks Performance,"ReLU, a commonly used activation function in deep neural networks, is prone
to the issue of ""Dying ReLU"". Several enhanced versions, such as ELU, SeLU, and
Swish, have been introduced and are considered to be less commonly utilized.
However, replacing ReLU can be somewhat challenging due to its inconsistent
advantages. While Swish offers a smoother transition similar to ReLU, its
utilization generally incurs a greater computational burden compared to ReLU.
This paper proposes SwishReLU, a novel activation function combining elements
of ReLU and Swish. Our findings reveal that SwishReLU outperforms ReLU in
performance with a lower computational cost than Swish. This paper undertakes
an examination and comparison of different types of ReLU variants with
SwishReLU. Specifically, we compare ELU and SeLU along with Tanh on three
datasets: CIFAR-10, CIFAR-100 and MNIST. Notably, applying SwishReLU in the
VGG16 model described in Algorithm 2 yields a 6% accuracy improvement on the
CIFAR-10 dataset.",2024-07-11,"Jamshaid Ul Rahman, Rubiqa Zulfiqar, Asad Khan, Nimra",http://arxiv.org/pdf/2407.08232v1,cs.LG
DALL-M: Context-Aware Clinical Data Augmentation with LLMs,"X-ray images are vital in medical diagnostics, but their effectiveness is
limited without clinical context. Radiologists often find chest X-rays
insufficient for diagnosing underlying diseases, necessitating the integration
of structured clinical features with radiology reports.
  To address this, we introduce DALL-M, a novel framework that enhances
clinical datasets by generating contextual synthetic data. DALL-M augments
structured patient data, including vital signs (e.g., heart rate, oxygen
saturation), radiology findings (e.g., lesion presence), and demographic
factors. It integrates this tabular data with contextual knowledge extracted
from radiology reports and domain-specific resources (e.g., Radiopaedia,
Wikipedia), ensuring clinical consistency and reliability.
  DALL-M follows a three-phase process: (i) clinical context storage, (ii)
expert query generation, and (iii) context-aware feature augmentation. Using
large language models (LLMs), it generates both contextual synthetic values for
existing clinical features and entirely new, clinically relevant features.
  Applied to 799 cases from the MIMIC-IV dataset, DALL-M expanded the original
9 clinical features to 91. Empirical validation with machine learning models
(including Decision Trees, Random Forests, XGBoost, and TabNET) demonstrated a
16.5% improvement in F1 score and a 25% increase in Precision and Recall.
  DALL-M bridges an important gap in clinical data augmentation by preserving
data integrity while enhancing predictive modeling in healthcare. Our results
show that integrating LLM-generated synthetic features significantly improves
model performance, making DALL-M a scalable and practical approach for
AI-driven medical diagnostics.",2024-07-11,"Chihcheng Hsieh, Catarina Moreira, Isabel Blanco Nobre, Sandra Costa Sousa, Chun Ouyang, Margot Brereton, Joaquim Jorge, Jacinto C. Nascimento",http://arxiv.org/pdf/2407.08227v3,cs.LG
Enhancing Performance and User Engagement in Everyday Stress Monitoring: A Context-Aware Active Reinforcement Learning Approach,"In today's fast-paced world, accurately monitoring stress levels is crucial.
Sensor-based stress monitoring systems often need large datasets for training
effective models. However, individual-specific models are necessary for
personalized and interactive scenarios. Traditional methods like Ecological
Momentary Assessments (EMAs) assess stress but struggle with efficient data
collection without burdening users. The challenge is to timely send EMAs,
especially during stress, balancing monitoring efficiency and user convenience.
This paper introduces a novel context-aware active reinforcement learning (RL)
algorithm for enhanced stress detection using Photoplethysmography (PPG) data
from smartwatches and contextual data from smartphones. Our approach
dynamically selects optimal times for deploying EMAs, utilizing the user's
immediate context to maximize label accuracy and minimize intrusiveness.
Initially, the study was executed in an offline environment to refine the label
collection process, aiming to increase accuracy while reducing user burden.
Later, we integrated a real-time label collection mechanism, transitioning to
an online methodology. This shift resulted in an 11% improvement in stress
detection efficiency. Incorporating contextual data improved model accuracy by
4%. Personalization studies indicated a 10% enhancement in AUC-ROC scores,
demonstrating better stress level differentiation. This research marks a
significant move towards personalized, context-driven real-time stress
monitoring methods.",2024-07-11,"Seyed Amir Hossein Aqajari, Ziyu Wang, Ali Tazarv, Sina Labbaf, Salar Jafarlou, Brenda Nguyen, Nikil Dutt, Marco Levorato, Amir M. Rahmani",http://arxiv.org/pdf/2407.08215v1,cs.LG
Towards stable training of parallel continual learning,"Parallel Continual Learning (PCL) tasks investigate the training methods for
continual learning with multi-source input, where data from different tasks are
learned as they arrive. PCL offers high training efficiency and is well-suited
for complex multi-source data systems, such as autonomous vehicles equipped
with multiple sensors. However, at any time, multiple tasks need to be trained
simultaneously, leading to severe training instability in PCL. This instability
manifests during both forward and backward propagation, where features are
entangled and gradients are conflict. This paper introduces Stable Parallel
Continual Learning (SPCL), a novel approach that enhances the training
stability of PCL for both forward and backward propagation. For the forward
propagation, we apply Doubly-block Toeplit (DBT) Matrix based orthogonality
constraints to network parameters to ensure stable and consistent propagation.
For the backward propagation, we employ orthogonal decomposition for gradient
management stabilizes backpropagation and mitigates gradient conflicts across
tasks. By optimizing gradients by ensuring orthogonality and minimizing the
condition number, SPCL effectively stabilizing the gradient descent in complex
optimization tasks. Experimental results demonstrate that SPCL outperforms
state-of-the-art methjods and achieve better training stability.",2024-07-11,"Li Yuepan, Fan Lyu, Yuyang Li, Wei Feng, Guangcan Liu, Fanhua Shang",http://arxiv.org/pdf/2407.08214v1,cs.LG
OPIMA: Optical Processing-In-Memory for Convolutional Neural Network Acceleration,"Recent advances in machine learning (ML) have spotlighted the pressing need
for computing architectures that bridge the gap between memory bandwidth and
processing power. The advent of deep neural networks has pushed traditional Von
Neumann architectures to their limits due to the high latency and energy
consumption costs associated with data movement between the processor and
memory for these workloads. One of the solutions to overcome this bottleneck is
to perform computation within the main memory through processing-in-memory
(PIM), thereby limiting data movement and the costs associated with it.
However, DRAM-based PIM struggles to achieve high throughput and energy
efficiency due to internal data movement bottlenecks and the need for frequent
refresh operations. In this work, we introduce OPIMA, a PIM-based ML
accelerator, architected within an optical main memory. OPIMA has been designed
to leverage the inherent massive parallelism within main memory while
performing high-speed, low-energy optical computation to accelerate ML models
based on convolutional neural networks. We present a comprehensive analysis of
OPIMA to guide design choices and operational mechanisms. Additionally, we
evaluate the performance and energy consumption of OPIMA, comparing it with
conventional electronic computing systems and emerging photonic PIM
architectures. The experimental results show that OPIMA can achieve 2.98x
higher throughput and 137x better energy efficiency than the best-known prior
work.",2024-07-11,"Febin Sunny, Amin Shafiee, Abhishek Balasubramaniam, Mahdi Nikdast, Sudeep Pasricha",http://arxiv.org/pdf/2407.08205v1,cs.LG
Approximating G(t)/GI/1 queues with deep learning,"In this paper, we apply a supervised machine-learning approach to solve a
fundamental problem in queueing theory: estimating the transient distribution
of the number in the system for a G(t)/GI/1. We develop a neural network
mechanism that provides a fast and accurate predictor of these distributions
for moderate horizon lengths and practical settings. It is based on using a
Recurrent Neural Network (RNN) architecture based on the first several moments
of the time-dependant inter-arrival and the stationary service time
distributions; we call it the Moment-Based Recurrent Neural Network (RNN)
method (MBRNN ). Our empirical study suggests MBRNN requires only the first
four inter-arrival and service time moments. We use simulation to generate a
substantial training dataset and present a thorough performance evaluation to
examine the accuracy of our method using two different test sets. We show that
even under the configuration with the worst performance errors, the mean number
of customers over the entire timeline has an error of less than 3%. While
simulation modeling can achieve high accuracy, the advantage of the MBRNN over
simulation is runtime, while the MBRNN analyzes hundreds of systems within a
fraction of a second. This paper focuses on a G(t)/GI/1; however, the MBRNN
approach demonstrated here can be extended to other queueing systems, as the
training data labeling is based on simulations (which can be applied to more
complex systems) and the training is based on deep learning, which can capture
very complex time sequence tasks. In summary, the MBRNN can potentially
revolutionize our ability to perform transient analyses of queueing systems.",2024-07-11,"Eliran Sherzer, Opher Baron, Dmitry Krass, Yehezkel Resheff",http://arxiv.org/pdf/2407.08765v1,cs.LG
Dynamic Co-Optimization Compiler: Leveraging Multi-Agent Reinforcement Learning for Enhanced DNN Accelerator Performance,"This paper introduces a novel Dynamic Co-Optimization Compiler (DCOC), which
employs an adaptive Multi-Agent Reinforcement Learning (MARL) framework to
enhance the efficiency of mapping machine learning (ML) models, particularly
Deep Neural Networks (DNNs), onto diverse hardware platforms. DCOC incorporates
three specialized actor-critic agents within MARL, each dedicated to different
optimization facets: one for hardware and two for software. This cooperative
strategy results in an integrated hardware/software co-optimization approach,
improving the precision and speed of DNN deployments. By focusing on
high-confidence configurations, DCOC effectively reduces the search space,
achieving remarkable performance over existing methods. Our results demonstrate
that DCOC enhances throughput by up to 37.95% while reducing optimization time
by up to 42.2% across various DNN models, outperforming current
state-of-the-art frameworks.",2024-07-11,"Arya Fayyazi, Mehdi Kamal, Massoud Pedram",http://arxiv.org/pdf/2407.08192v3,cs.LG
"Position: Measure Dataset Diversity, Don't Just Claim It","Machine learning (ML) datasets, often perceived as neutral, inherently
encapsulate abstract and disputed social constructs. Dataset curators
frequently employ value-laden terms such as diversity, bias, and quality to
characterize datasets. Despite their prevalence, these terms lack clear
definitions and validation. Our research explores the implications of this
issue by analyzing ""diversity"" across 135 image and text datasets. Drawing from
social sciences, we apply principles from measurement theory to identify
considerations and offer recommendations for conceptualizing, operationalizing,
and evaluating diversity in datasets. Our findings have broader implications
for ML research, advocating for a more nuanced and precise approach to handling
value-laden properties in dataset construction.",2024-07-11,"Dora Zhao, Jerone T. A. Andrews, Orestis Papakyriakopoulos, Alice Xiang",http://arxiv.org/pdf/2407.08188v1,cs.LG
CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP,"Machine learning models are increasingly used in areas such as loan approvals
and hiring, yet they often function as black boxes, obscuring their
decision-making processes. Transparency is crucial, and individuals need
explanations to understand decisions, especially for the ones not desired by
the user. Ethical and legal considerations require informing individuals of
changes in input attribute values (features) that could lead to a desired
outcome for the user. Our work aims to generate counterfactual explanations by
considering causal dependencies between features. We present the CoGS
(Counterfactual Generation with s(CASP)) framework that utilizes the
goal-directed Answer Set Programming system s(CASP) to generate counterfactuals
from rule-based machine learning models, specifically the FOLD-SE algorithm.
CoGS computes realistic and causally consistent changes to attribute values
taking causal dependencies between them into account. It finds a path from an
undesired outcome to a desired one using counterfactuals. We present details of
the CoGS framework along with its evaluation.",2024-07-11,"Sopam Dasgupta, Joaquín Arias, Elmer Salazar, Gopal Gupta",http://arxiv.org/pdf/2407.08179v1,cs.LG
Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software,"By treating data and models as the source code, Foundation Models (FMs)
become a new type of software. Mirroring the concept of software crisis, the
increasing complexity of FMs making FM crisis a tangible concern in the coming
decade, appealing for new theories and methodologies from the field of software
engineering. In this paper, we outline our vision of introducing Foundation
Model (FM) engineering, a strategic response to the anticipated FM crisis with
principled engineering methodologies. FM engineering aims to mitigate potential
issues in FM development and application through the introduction of
declarative, automated, and unified programming interfaces for both data and
model management, reducing the complexities involved in working with FMs by
providing a more structured and intuitive process for developers. Through the
establishment of FM engineering, we aim to provide a robust, automated, and
extensible framework that addresses the imminent challenges, and discovering
new research opportunities for the software engineering field.",2024-07-11,"Dezhi Ran, Mengzhou Wu, Wei Yang, Tao Xie",http://arxiv.org/pdf/2407.08176v1,cs.LG
The Approximate Fisher Influence Function: Faster Estimation of Data Influence in Statistical Models,"Quantifying the influence of infinitesimal changes in training data on model
performance is crucial for understanding and improving machine learning models.
In this work, we reformulate this problem as a weighted empirical risk
minimization and enhance existing influence function-based methods by using
information geometry to derive a new algorithm to estimate influence. Our
formulation proves versatile across various applications, and we further
demonstrate in simulations how it remains informative even in non-convex cases.
Furthermore, we show that our method offers significant computational
advantages over current Newton step-based methods.",2024-07-11,"Omri Lev, Ashia C. Wilson",http://arxiv.org/pdf/2407.08169v2,cs.LG
Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder,"The electroretinogram (ERG) is a clinical test that records the retina's
electrical response to light. The ERG is a promising way to study different
neurodevelopmental and neurodegenerative disorders, including autism spectrum
disorder (ASD) - a neurodevelopmental condition that impacts language,
communication, and reciprocal social interactions. However, in heterogeneous
populations, such as ASD, where the ability to collect large datasets is
limited, the application of artificial intelligence (AI) is complicated.
Synthetic ERG signals generated from real ERG recordings carry similar
information as natural ERGs and, therefore, could be used as an extension for
natural data to increase datasets so that AI applications can be fully
utilized. As proof of principle, this study presents a Generative Adversarial
Network capable of generating synthetic ERG signals of children with ASD and
typically developing control individuals. We applied a Time Series Transformer
and Visual Transformer with Continuous Wavelet Transform to enhance
classification results on the extended synthetic signals dataset. This approach
may support classification models in related psychiatric conditions where the
ERG may help classify disorders.",2024-07-11,"Mikhail Kulyabin, Paul A. Constable, Aleksei Zhdanov, Irene O. Lee, David H. Skuse, Dorothy A. Thompson, Andreas Maier",http://arxiv.org/pdf/2407.08166v1,cs.LG
Model-agnostic clean-label backdoor mitigation in cybersecurity environments,"The training phase of machine learning models is a delicate step, especially
in cybersecurity contexts. Recent research has surfaced a series of insidious
training-time attacks that inject backdoors in models designed for security
classification tasks without altering the training labels. With this work, we
propose new techniques that leverage insights in cybersecurity threat models to
effectively mitigate these clean-label poisoning attacks, while preserving the
model utility. By performing density-based clustering on a carefully chosen
feature subspace, and progressively isolating the suspicious clusters through a
novel iterative scoring procedure, our defensive mechanism can mitigate the
attacks without requiring many of the common assumptions in the existing
backdoor defense literature. To show the generality of our proposed mitigation,
we evaluate it on two clean-label model-agnostic attacks on two different
classic cybersecurity data modalities: network flows classification and malware
classification, using gradient boosting and neural network models.",2024-07-11,"Giorgio Severi, Simona Boboila, John Holodnak, Kendra Kratkiewicz, Rauf Izmailov, Michael J. De Lucia, Alina Oprea",http://arxiv.org/pdf/2407.08159v4,cs.LG
Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models (Extended Version),"Deduplication is a vital preprocessing step that enhances machine learning
model performance and saves training time and energy. However, enhancing
federated learning through deduplication poses challenges, especially regarding
scalability and potential privacy violations if deduplication involves sharing
all clients' data. In this paper, we address the problem of deduplication in a
federated setup by introducing a pioneering protocol, Efficient
Privacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes
duplicates from multiple clients' datasets without compromising data privacy.
EP-MPD is constructed in a modular fashion, utilizing two novel variants of the
Private Set Intersection protocol. Our extensive experiments demonstrate the
significant benefits of deduplication in federated learning of large language
models. For instance, we observe up to 19.62\% improvement in perplexity and up
to 27.95\% reduction in running time while varying the duplication level
between 10\% and 30\%. EP-MPD effectively balances privacy and performance in
federated learning, making it a valuable solution for large-scale applications.",2024-07-11,"Aydin Abadi, Vishnu Asutosh Dasu, Sumanta Sarkar",http://arxiv.org/pdf/2407.08152v2,cs.LG
Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates,"Surface reconstruction from point clouds is a fundamental challenge in
computer graphics and medical imaging. In this paper, we explore the
application of advanced neural network architectures for the accurate and
efficient reconstruction of surfaces from data points. We introduce a novel
variant of the Highway network (Hw) called Square-Highway (SqrHw) within the
context of multilayer perceptrons and investigate its performance alongside
plain neural networks and a simplified Hw in various numerical examples. These
examples include the reconstruction of simple and complex surfaces, such as
spheres, human hands, and intricate models like the Stanford Bunny. We analyze
the impact of factors such as the number of hidden layers, interior and
exterior points, and data distribution on surface reconstruction quality. Our
results show that the proposed SqrHw architecture outperforms other neural
network configurations, achieving faster convergence and higher-quality surface
reconstructions. Additionally, we demonstrate the SqrHw's ability to predict
surfaces over missing data, a valuable feature for challenging applications
like medical imaging. Furthermore, our study delves into further details,
demonstrating that the proposed method based on highway networks yields more
stable weight norms and backpropagation gradients compared to the Plain Network
architecture. This research not only advances the field of computer graphics
but also holds utility for other purposes such as function interpolation and
physics-informed neural networks, which integrate multilayer perceptrons into
their algorithms.",2024-07-11,"A. Noorizadegan, Y. C. Hon, D. L. Young, C. S. Chen",http://arxiv.org/pdf/2407.08134v1,cs.LG
Real-Time Summarization of Twitter,"In this paper, we describe our approaches to TREC Real-Time Summarization of
Twitter. We focus on real time push notification scenario, which requires a
system monitors the stream of sampled tweets and returns the tweets relevant
and novel to given interest profiles. Dirichlet score with and with very little
smoothing (baseline) are employed to classify whether a tweet is relevant to a
given interest profile. Using metrics including Mean Average Precision (MAP,
cumulative gain (CG) and discount cumulative gain (DCG), the experiment
indicates that our approach has a good performance. It is also desired to
remove the redundant tweets from the pushing queue. Due to the precision limit,
we only describe the algorithm in this paper.",2024-07-11,"Yixin Jin, Meiqi Wang, Meng Li, Wenjing Zhou, Yi Shen, Hao Liu",http://arxiv.org/pdf/2407.08125v2,cs.LG
How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities,"Long sequences occur in abundance within real-world scenarios, hence properly
modelling them opens numerous down-stream use-cases. Deep neural networks,
however, have often struggled with these for a variety of reasons. Recent
advances, both in system engineering as well as model design, have enabled the
scaling up of model that are purported to support extended context length. In
particular, the state-space and linear recurrent neural network families of
models hypothetically can entend to infinite sequence lenth. However, is this
too good to be true? We conduct an evaluation to show that while such claims
may be sound theoretically, there remain large practical gaps that are
empirically observed. In particular, recurrent models still suffer in the same
settings as long-context LLMs with attention. We further show that different
inductive biases have inconsistent extrapolation capabilities, highlighting the
need to further study such paradigms and investigate why long-context models
seemingly fail to behave as one might expect.",2024-07-11,Jerry Huang,http://arxiv.org/pdf/2407.08112v3,cs.LG
Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter,"Urban waterlogging poses a major risk to public safety and infrastructure.
Conventional methods using water-level sensors need high-maintenance to hardly
achieve full coverage. Recent advances employ surveillance camera imagery and
deep learning for detection, yet these struggle amidst scarce data and adverse
environmental conditions. In this paper, we establish a challenging Urban
Waterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance
real-world applications. We propose a Large-Small Model co-adapter paradigm
(LSM-adapter), which harnesses the substantial generic segmentation potential
of large model and the specific task-directed guidance of small model.
Specifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt
Combiner are proposed to generate then merge multiple prompts for mask decoder
adaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to
infuse the image specific information for image encoder adaptation. Results and
analysis show the challenge and superiority of our developed benchmark and
algorithm. Project page: \url{https://github.com/zhang-chenxu/LSM-Adapter}",2024-07-11,"Suqi Song, Chenxu Zhang, Peng Zhang, Pengkun Li, Fenglong Song, Lei Zhang",http://arxiv.org/pdf/2407.08109v1,cs.LG
CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data,"Deep learning recommendation models (DLRMs) are at the heart of the current
e-commerce industry. However, the amount of training data used to train these
large models is growing exponentially, leading to substantial training hurdles.
The training dataset contains two primary types of information: content-based
information (features of users and items) and collaborative information
(interactions between users and items). One approach to reduce the training
dataset is to remove user-item interactions. But that significantly diminishes
collaborative information, which is crucial for maintaining accuracy due to its
inclusion of interaction histories. This loss profoundly impacts DLRM
performance.
  This paper makes an important observation that if one can capture the
user-item interaction history to enrich the user and item embeddings, then the
interaction history can be compressed without losing model accuracy. Thus, this
work, Collaborative Aware Data Compression (CADC), takes a two-step approach to
training dataset compression. In the first step, we use matrix factorization of
the user-item interaction matrix to create a novel embedding representation for
both the users and items. Once the user and item embeddings are enriched by the
interaction history information the approach then applies uniform random
sampling of the training dataset to drastically reduce the training dataset
size while minimizing model accuracy drop. The source code of CADC is available
at
\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.",2024-07-11,"Hossein Entezari Zarch, Abdulla Alshabanah, Chaoyi Jiang, Murali Annavaram",http://arxiv.org/pdf/2407.08108v2,cs.LG
Advanced Meta-Ensemble Machine Learning Models for Early and Accurate Sepsis Prediction to Improve Patient Outcomes,"Sepsis, a critical condition from the body's response to infection, poses a
major global health crisis affecting all age groups. Timely detection and
intervention are crucial for reducing healthcare expenses and improving patient
outcomes. This paper examines the limitations of traditional sepsis screening
tools like Systemic Inflammatory Response Syndrome, Modified Early Warning
Score, and Quick Sequential Organ Failure Assessment, highlighting the need for
advanced approaches. We propose using machine learning techniques - Random
Forest, Extreme Gradient Boosting, and Decision Tree models - to predict sepsis
onset. Our study evaluates these models individually and in a combined
meta-ensemble approach using key metrics such as Accuracy, Precision, Recall,
F1 score, and Area Under the Receiver Operating Characteristic Curve. Results
show that the meta-ensemble model outperforms individual models, achieving an
AUC-ROC score of 0.96, indicating superior predictive accuracy for early sepsis
detection. The Random Forest model also performs well with an AUC-ROC score of
0.95, while Extreme Gradient Boosting and Decision Tree models score 0.94 and
0.90, respectively.",2024-07-11,"MohammadAmin Ansari Khoushabar, Parviz Ghafariasl",http://arxiv.org/pdf/2407.08107v1,cs.LG
Non-convergence of Adam and other adaptive stochastic gradient descent optimization methods for non-vanishing learning rates,"Deep learning algorithms - typically consisting of a class of deep neural
networks trained by a stochastic gradient descent (SGD) optimization method -
are nowadays the key ingredients in many artificial intelligence (AI) systems
and have revolutionized our ways of working and living in modern societies. For
example, SGD methods are used to train powerful large language models (LLMs)
such as versions of ChatGPT and Gemini, SGD methods are employed to create
successful generative AI based text-to-image creation models such as
Midjourney, DALL-E, and Stable Diffusion, but SGD methods are also used to
train DNNs to approximately solve scientific models such as partial
differential equation (PDE) models from physics and biology and optimal control
and stopping problems from engineering. It is known that the plain vanilla
standard SGD method fails to converge even in the situation of several convex
optimization problems if the learning rates are bounded away from zero.
However, in many practical relevant training scenarios, often not the plain
vanilla standard SGD method but instead adaptive SGD methods such as the
RMSprop and the Adam optimizers, in which the learning rates are modified
adaptively during the training process, are employed. This naturally rises the
question whether such adaptive optimizers, in which the learning rates are
modified adaptively during the training process, do converge in the situation
of non-vanishing learning rates. In this work we answer this question
negatively by proving that adaptive SGD methods such as the popular Adam
optimizer fail to converge to any possible random limit point if the learning
rates are asymptotically bounded away from zero. In our proof of this
non-convergence result we establish suitable pathwise a priori bounds for a
class of accelerated and adaptive SGD methods, which are also of independent
interest.",2024-07-11,"Steffen Dereich, Robin Graeber, Arnulf Jentzen",http://arxiv.org/pdf/2407.08100v1,cs.LG
Density Estimation via Binless Multidimensional Integration,"We introduce the Binless Multidimensional Thermodynamic Integration (BMTI)
method for nonparametric, robust, and data-efficient density estimation. BMTI
estimates the logarithm of the density by initially computing log-density
differences between neighbouring data points. Subsequently, such differences
are integrated, weighted by their associated uncertainties, using a
maximum-likelihood formulation. This procedure can be seen as an extension to a
multidimensional setting of the thermodynamic integration, a technique
developed in statistical physics. The method leverages the manifold hypothesis,
estimating quantities within the intrinsic data manifold without defining an
explicit coordinate map. It does not rely on any binning or space partitioning,
but rather on the construction of a neighbourhood graph based on an adaptive
bandwidth selection procedure. BMTI mitigates the limitations commonly
associated with traditional nonparametric density estimators, effectively
reconstructing smooth profiles even in high-dimensional embedding spaces. The
method is tested on a variety of complex synthetic high-dimensional datasets,
where it is shown to outperform traditional estimators, and is benchmarked on
realistic datasets from the chemical physics literature.",2024-07-10,"Matteo Carli, Alex Rodriguez, Alessandro Laio, Aldo Glielmo",http://arxiv.org/pdf/2407.08094v2,cs.LG
"The GeometricKernels Package: Heat and Matérn Kernels for Geometric Learning on Manifolds, Meshes, and Graphs","Kernels are a fundamental technical primitive in machine learning. In recent
years, kernel-based methods such as Gaussian processes are becoming
increasingly important in applications where quantifying uncertainty is of key
interest. In settings that involve structured data defined on graphs, meshes,
manifolds, or other related spaces, defining kernels with good
uncertainty-quantification behavior, and computing their value numerically, is
less straightforward than in the Euclidean setting. To address this difficulty,
we present GeometricKernels, a software package which implements the geometric
analogs of classical Euclidean squared exponential - also known as heat - and
Mat\'ern kernels, which are widely-used in settings where uncertainty is of key
interest. As a byproduct, we obtain the ability to compute Fourier-feature-type
expansions, which are widely used in their own right, on a wide set of
geometric spaces. Our implementation supports automatic differentiation in
every major current framework simultaneously via a backend-agnostic design. In
this companion paper to the package and its documentation, we outline the
capabilities of the package and present an illustrated example of its
interface. We also include a brief overview of the theory the package is built
upon and provide some historic context in the appendix.",2024-07-10,"Peter Mostowsky, Vincent Dutordoir, Iskander Azangulov, Noémie Jaquier, Michael John Hutchinson, Aditya Ravuri, Leonel Rozo, Alexander Terenin, Viacheslav Borovitskiy",http://arxiv.org/pdf/2407.08086v1,cs.LG
ImPORTance: Machine Learning-Driven Analysis of Global Port Significance and Network Dynamics for Improved Operational Efficiency,"Seaports play a crucial role in the global economy, and researchers have
sought to understand their significance through various studies. In this paper,
we aim to explore the common characteristics shared by important ports by
analyzing the network of connections formed by vessel movement among them. To
accomplish this task, we adopt a bottom-up network construction approach that
combines three years' worth of AIS (Automatic Identification System) data from
around the world, constructing a Ports Network that represents the connections
between different ports. Through this representation, we utilize machine
learning to assess the relative significance of various port features. Our
model examined such features and revealed that geographical characteristics and
the port's depth are indicators of a port's importance to the Ports Network.
Accordingly, this study employs a data-driven approach and utilizes machine
learning to provide a comprehensive understanding of the factors contributing
to the extent of ports. Our work aims to inform decision-making processes
related to port development, resource allocation, and infrastructure planning
within the industry.",2024-07-10,"Emanuele Carlini, Domenico Di Gangi, Vinicius Monteiro de Lira, Hanna Kavalionak, Amilcar Soares, Gabriel Spadon",http://arxiv.org/pdf/2407.09571v3,cs.LG
Smooth Like Butter: Evaluating Multi-Lattice Transitions in Property-Augmented Latent Spaces,"Additive manufacturing has revolutionized structural optimization by
enhancing component strength and reducing material requirements. One approach
used to achieve these improvements is the application of multi-lattice
structures, where the macro-scale performance relies on the detailed design of
mesostructural lattice elements. Many current approaches to designing such
structures use data-driven design to generate multi-lattice transition regions,
making use of machine learning models that are informed solely by the geometry
of the mesostructures. However, it remains unclear if the integration of
mechanical properties into the dataset used to train such machine learning
models would be beneficial beyond using geometric data alone. To address this
issue, this work implements and evaluates a hybrid geometry/property
Variational Autoencoder (VAE) for generating multi-lattice transition regions.
In our study, we found that hybrid VAEs demonstrate enhanced performance in
maintaining stiffness continuity through transition regions, indicating their
suitability for design tasks requiring smooth mechanical properties.",2024-07-10,"Martha Baldwin, Nicholas A. Meisel, Christopher McComb",http://arxiv.org/pdf/2407.08074v1,cs.LG
NDST: Neural Driving Style Transfer for Human-Like Vision-Based Autonomous Driving,"Autonomous Vehicles (AV) and Advanced Driver Assistant Systems (ADAS)
prioritize safety over comfort. The intertwining factors of safety and comfort
emerge as pivotal elements in ensuring the effectiveness of Autonomous Driving
(AD). Users often experience discomfort when AV or ADAS drive the vehicle on
their behalf. Providing a personalized human-like AD experience, tailored to
match users' unique driving styles while adhering to safety prerequisites,
presents a significant opportunity to boost the acceptance of AVs. This paper
proposes a novel approach, Neural Driving Style Transfer (NDST), inspired by
Neural Style Transfer (NST), to address this issue. NDST integrates a
Personalized Block (PB) into the conventional Baseline Driving Model (BDM),
allowing for the transfer of a user's unique driving style while adhering to
safety parameters. The PB serves as a self-configuring system, learning and
adapting to an individual's driving behavior without requiring modifications to
the BDM. This approach enables the personalization of AV models, aligning the
driving style more closely with user preferences while ensuring baseline safety
critical actuation. Two contrasting driving styles (Style A and Style B) were
used to validate the proposed NDST methodology, demonstrating its efficacy in
transferring personal driving styles to the AV system. Our work highlights the
potential of NDST to enhance user comfort in AVs by providing a personalized
and familiar driving experience. The findings affirm the feasibility of
integrating NDST into existing AV frameworks to bridge the gap between safety
and individualized driving styles, promoting wider acceptance and improved user
experiences.",2024-07-10,"Donghyun Kim, Aws Khalil, Haewoon Nam, Jaerock Kwon",http://arxiv.org/pdf/2407.08073v1,cs.LG
Towards Interpretable Foundation Models of Robot Behavior: A Task Specific Policy Generation Approach,"Foundation models are a promising path toward general-purpose and
user-friendly robots. The prevalent approach involves training a generalist
policy that, like a reinforcement learning policy, uses observations to output
actions. Although this approach has seen much success, several concerns arise
when considering deployment and end-user interaction with these systems. In
particular, the lack of modularity between tasks means that when model weights
are updated (e.g., when a user provides feedback), the behavior in other,
unrelated tasks may be affected. This can negatively impact the system's
interpretability and usability. We present an alternative approach to the
design of robot foundation models, Diffusion for Policy Parameters (DPP), which
generates stand-alone, task-specific policies. Since these policies are
detached from the foundation model, they are updated only when a user wants,
either through feedback or personalization, allowing them to gain a high degree
of familiarity with that policy. We demonstrate a proof-of-concept of DPP in
simulation then discuss its limitations and the future of interpretable
foundation models.",2024-07-10,"Isaac Sheidlower, Reuben Aronson, Elaine Schaertl Short",http://arxiv.org/pdf/2407.08065v1,cs.LG
TinyGraph: Joint Feature and Node Condensation for Graph Neural Networks,"Training graph neural networks (GNNs) on large-scale graphs can be
challenging due to the high computational expense caused by the massive number
of nodes and high-dimensional nodal features. Existing graph condensation
studies tackle this problem only by reducing the number of nodes in the graph.
However, the resulting condensed graph data can still be cumbersome.
Specifically, although the nodes of the Citeseer dataset are reduced to 0.9%
(30 nodes) in training, the number of features is 3,703, severely exceeding the
training sample magnitude. Faced with this challenge, we study the problem of
joint condensation for both features and nodes in large-scale graphs. This task
is challenging mainly due to 1) the intertwined nature of the node features and
the graph structure calls for the feature condensation solver to be
structure-aware; and 2) the difficulty of keeping useful information in the
condensed graph. To address these challenges, we propose a novel framework
TinyGraph, to condense features and nodes simultaneously in graphs.
Specifically, we cast the problem as matching the gradients of GNN weights
trained on the condensed graph and the gradients obtained from training over
the original graph, where the feature condensation is achieved by a trainable
function. The condensed graph obtained by minimizing the matching loss along
the training trajectory can henceforth retain critical information in the
original graph. Extensive experiments were carried out to demonstrate the
effectiveness of the proposed TinyGraph. For example, a GNN trained with
TinyGraph retains 98.5% and 97.5% of the original test accuracy on the Cora and
Citeseer datasets, respectively, while significantly reducing the number of
nodes by 97.4% and 98.2%, and the number of features by 90.0% on both datasets.",2024-07-10,"Yezi Liu, Yanning Shen",http://arxiv.org/pdf/2407.08064v1,cs.LG
Pareto Low-Rank Adapters: Efficient Multi-Task Learning with Preferences,"Multi-task trade-offs in machine learning can be addressed via Pareto Front
Learning (PFL) methods that parameterize the Pareto Front (PF) with a single
model. PFL permits to select the desired operational point during inference,
contrary to traditional Multi-Task Learning (MTL) that optimizes for a single
trade-off decided prior to training. However, recent PFL methodologies suffer
from limited scalability, slow convergence, and excessive memory requirements,
while exhibiting inconsistent mappings from preference to objective space. We
introduce PaLoRA, a novel parameter-efficient method that addresses these
limitations in two ways. First, we augment any neural network architecture with
task-specific low-rank adapters and continuously parameterize the PF in their
convex hull. Our approach steers the original model and the adapters towards
learning general and task-specific features, respectively. Second, we propose a
deterministic sampling schedule of preference vectors that reinforces this
division of labor, enabling faster convergence and strengthening the validity
of the mapping from preference to objective space throughout training. Our
experiments show that PaLoRA outperforms state-of-the-art MTL and PFL baselines
across various datasets, scales to large networks, reducing the memory overhead
$23.8-31.7$ times compared with competing PFL baselines in scene understanding
benchmarks.",2024-07-10,"Nikolaos Dimitriadis, Pascal Frossard, Francois Fleuret",http://arxiv.org/pdf/2407.08056v2,cs.LG
Spatial-Temporal Attention Model for Traffic State Estimation with Sparse Internet of Vehicles,"The growing number of connected vehicles offers an opportunity to leverage
internet of vehicles (IoV) data for traffic state estimation (TSE) which plays
a crucial role in intelligent transportation systems (ITS). By utilizing only a
portion of IoV data instead of the entire dataset, the significant overheads
associated with collecting and processing large amounts of data can be avoided.
In this paper, we introduce a novel framework that utilizes sparse IoV data to
achieve cost-effective TSE. Particularly, we propose a novel spatial-temporal
attention model called the convolutional retentive network (CRNet) to improve
the TSE accuracy by mining spatial-temporal traffic state correlations. The
model employs the convolutional neural network (CNN) for spatial correlation
aggregation and the retentive network (RetNet) based on the attention mechanism
to extract temporal correlations. Extensive simulations on a real-world IoV
dataset validate the advantage of the proposed TSE approach in achieving
accurate TSE using sparse IoV data, demonstrating its cost effectiveness and
practicality for real-world applications.",2024-07-10,"Jianzhe Xue, Dongcheng Yuan, Yu Sun, Tianqi Zhang, Wenchao Xu, Haibo Zhou, Xuemin, Shen",http://arxiv.org/pdf/2407.08047v2,cs.LG
RoLoRA: Fine-tuning Rotated Outlier-free LLMs for Effective Weight-Activation Quantization,"Low-Rank Adaptation (LoRA), as a representative Parameter-Efficient
Fine-Tuning (PEFT)method, significantly enhances the training efficiency by
updating only a small portion of the weights in Large Language Models (LLMs).
Recently, weight-only quantization techniques have also been applied to LoRA
methods to reduce the memory footprint of fine-tuning. However, applying
weight-activation quantization to the LoRA pipeline is under-explored, and we
observe substantial performance degradation primarily due to the presence of
activation outliers. In this work, we propose RoLoRA, the first LoRA-based
scheme for effective weight-activation quantization. RoLoRA utilizes rotation
for outlier elimination and proposes rotation-aware fine-tuning to preserve the
outlier-free characteristics in rotated LLMs. Experimental results show RoLoRA
consistently improves low-bit LoRA convergence and post-training quantization
robustness in weight-activation settings. We evaluate RoLoRA across
LLaMA2-7B/13B, LLaMA3-8B models, achieving up to 29.5% absolute accuracy gain
of 4-bit weight-activation quantized LLaMA2- 13B on commonsense reasoning tasks
compared to LoRA baseline. We further demonstrate its effectiveness on Large
Multimodal Models (LLaVA-1.5-7B). Codes are available at
https://github.com/HuangOwen/RoLoRA",2024-07-10,"Xijie Huang, Zechun Liu, Shih-Yang Liu, Kwang-Ting Cheng",http://arxiv.org/pdf/2407.08044v2,cs.LG
A Critical Review of Causal Reasoning Benchmarks for Large Language Models,"Numerous benchmarks aim to evaluate the capabilities of Large Language Models
(LLMs) for causal inference and reasoning. However, many of them can likely be
solved through the retrieval of domain knowledge, questioning whether they
achieve their purpose. In this review, we present a comprehensive overview of
LLM benchmarks for causality. We highlight how recent benchmarks move towards a
more thorough definition of causal reasoning by incorporating interventional or
counterfactual reasoning. We derive a set of criteria that a useful benchmark
or set of benchmarks should aim to satisfy. We hope this work will pave the way
towards a general framework for the assessment of causal understanding in LLMs
and the design of novel benchmarks.",2024-07-10,"Linying Yang, Vik Shirvaikar, Oscar Clivio, Fabian Falck",http://arxiv.org/pdf/2407.08029v1,cs.LG
Deep Reinforcement Learning for Sequential Combinatorial Auctions,"Revenue-optimal auction design is a challenging problem with significant
theoretical and practical implications. Sequential auction mechanisms, known
for their simplicity and strong strategyproofness guarantees, are often limited
by theoretical results that are largely existential, except for certain
restrictive settings. Although traditional reinforcement learning methods such
as Proximal Policy Optimization (PPO) and Soft Actor-Critic (SAC) are
applicable in this domain, they struggle with computational demands and
convergence issues when dealing with large and continuous action spaces. In
light of this and recognizing that we can model transitions differentiable for
our settings, we propose using a new reinforcement learning framework tailored
for sequential combinatorial auctions that leverages first-order gradients. Our
extensive evaluations show that our approach achieves significant improvement
in revenue over both analytical baselines and standard reinforcement learning
algorithms. Furthermore, we scale our approach to scenarios involving up to 50
agents and 50 items, demonstrating its applicability in complex, real-world
auction settings. As such, this work advances the computational tools available
for auction design and contributes to bridging the gap between theoretical
results and practical implementations in sequential auction design.",2024-07-10,"Sai Srivatsa Ravindranath, Zhe Feng, Di Wang, Manzil Zaheer, Aranyak Mehta, David C. Parkes",http://arxiv.org/pdf/2407.08022v1,cs.LG
LEMoN: Label Error Detection using Multimodal Neighbors,"Large repositories of image-caption pairs are essential for the development
of vision-language models. However, these datasets are often extracted from
noisy data scraped from the web, and contain many mislabeled examples. In order
to improve the reliability of downstream models, it is important to identify
and filter images with incorrect captions. However, beyond filtering based on
image-caption embedding similarity, no prior works have proposed other methods
to filter noisy multimodal data, or concretely assessed the impact of noisy
captioning data on downstream training. In this work, we propose LEMoN, a
method to automatically identify label errors in multimodal datasets. Our
method leverages the multimodal neighborhood of image-caption pairs in the
latent space of contrastively pretrained multimodal models. We find that our
method outperforms the baselines in label error identification, and that
training on datasets filtered using our method improves downstream
classification and captioning performance.",2024-07-10,"Haoran Zhang, Aparna Balagopalan, Nassim Oufattole, Hyewon Jeong, Yan Wu, Jiacheng Zhu, Marzyeh Ghassemi",http://arxiv.org/pdf/2407.18941v1,cs.LG
A Self-organizing Interval Type-2 Fuzzy Neural Network for Multi-Step Time Series Prediction,"Data uncertainty is inherent in many real-world applications and poses
significant challenges for accurate time series predictions. The interval type
2 fuzzy neural network (IT2FNN) has shown exceptional performance in
uncertainty modelling for single-step prediction tasks. However, extending it
for multi-step ahead predictions introduces further issues in uncertainty
handling as well as model interpretability and accuracy. To address these
issues, this paper proposes a new selforganizing interval type-2 fuzzy neural
network with multiple outputs (SOIT2FNN-MO). Differing from the traditional
six-layer IT2FNN, a nine-layer network architecture is developed. First, a new
co-antecedent layer and a modified consequent layer are devised to improve the
interpretability of the fuzzy model for multi-step time series prediction
problems. Second, a new link layer is created to improve the accuracy by
building temporal connections between multi-step predictions. Third, a new
transformation layer is designed to address the problem of the vanishing rule
strength caused by high-dimensional inputs. Furthermore, a two-stage,
self-organizing learning mechanism is developed to automatically extract fuzzy
rules from data and optimize network parameters. Experimental results on
chaotic and microgrid prediction problems demonstrate that SOIT2FNN-MO
outperforms state-of-the-art methods, by achieving a better accuracy ranging
from 1.6% to 30% depending on the level of noises in data. Additionally, the
proposed model is more interpretable, offering deeper insights into the
prediction process.",2024-07-10,"Fulong Yao, Wanqing Zhao, Matthew Forshaw, Yang Song",http://arxiv.org/pdf/2407.08010v2,cs.LG
Machine Learning for ALSFRS-R Score Prediction: Making Sense of the Sensor Data,"Amyotrophic Lateral Sclerosis (ALS) is characterized as a rapidly progressive
neurodegenerative disease that presents individuals with limited treatment
options in the realm of medical interventions and therapies. The disease
showcases a diverse range of onset patterns and progression trajectories,
emphasizing the critical importance of early detection of functional decline to
enable tailored care strategies and timely therapeutic interventions. The
present investigation, spearheaded by the iDPP@CLEF 2024 challenge, focuses on
utilizing sensor-derived data obtained through an app. This data is used to
construct various machine learning models specifically designed to forecast the
advancement of the ALS Functional Rating Scale-Revised (ALSFRS-R) score,
leveraging the dataset provided by the organizers. In our analysis, multiple
predictive models were evaluated to determine their efficacy in handling ALS
sensor data. The temporal aspect of the sensor data was compressed and
amalgamated using statistical methods, thereby augmenting the interpretability
and applicability of the gathered information for predictive modeling
objectives. The models that demonstrated optimal performance were a naive
baseline and ElasticNet regression. The naive model achieved a Mean Absolute
Error (MAE) of 0.20 and a Root Mean Square Error (RMSE) of 0.49, slightly
outperforming the ElasticNet model, which recorded an MAE of 0.22 and an RMSE
of 0.50. Our comparative analysis suggests that while the naive approach
yielded marginally better predictive accuracy, the ElasticNet model provides a
robust framework for understanding feature contributions.",2024-07-10,"Ritesh Mehta, Aleksandar Pramov, Shashank Verma",http://arxiv.org/pdf/2407.08003v1,cs.LG
What's the score? Automated Denoising Score Matching for Nonlinear Diffusions,"Reversing a diffusion process by learning its score forms the heart of
diffusion-based generative modeling and for estimating properties of scientific
systems. The diffusion processes that are tractable center on linear processes
with a Gaussian stationary distribution. This limits the kinds of models that
can be built to those that target a Gaussian prior or more generally limits the
kinds of problems that can be generically solved to those that have
conditionally linear score functions. In this work, we introduce a family of
tractable denoising score matching objectives, called local-DSM, built using
local increments of the diffusion process. We show how local-DSM melded with
Taylor expansions enables automated training and score estimation with
nonlinear diffusion processes. To demonstrate these ideas, we use automated-DSM
to train generative models using non-Gaussian priors on challenging low
dimensional distributions and the CIFAR10 image dataset. Additionally, we use
the automated-DSM to learn the scores for nonlinear processes studied in
statistical physics.",2024-07-10,"Raghav Singhal, Mark Goldstein, Rajesh Ranganath",http://arxiv.org/pdf/2407.07998v1,cs.LG
ICD Codes are Insufficient to Create Datasets for Machine Learning: An Evaluation Using All of Us Data for Coccidioidomycosis and Myocardial Infarction,"In medicine, machine learning (ML) datasets are often built using the
International Classification of Diseases (ICD) codes. As new models are being
developed, there is a need for larger datasets. However, ICD codes are intended
for billing. We aim to determine how suitable ICD codes are for creating
datasets to train ML models. We focused on a rare and common disease using the
All of Us database. First, we compared the patient cohort created using ICD
codes for Valley fever (coccidioidomycosis, CM) with that identified via
serological confirmation. Second, we compared two similarly created patient
cohorts for myocardial infarction (MI) patients. We identified significant
discrepancies between these two groups, and the patient overlap was small. The
CM cohort had 811 patients in the ICD-10 group, 619 patients in the
positive-serology group, and 24 with both. The MI cohort had 14,875 patients in
the ICD-10 group, 23,598 in the MI laboratory-confirmed group, and 6,531 in
both. Demographics, rates of disease symptoms, and other clinical data varied
across our case study cohorts.",2024-07-10,"Abigail E. Whitlock, Gondy Leroy, Fariba M. Donovan, John N. Galgiani",http://arxiv.org/pdf/2407.07997v1,cs.LG
Automating Weak Label Generation for Data Programming with Clinicians in the Loop,"Large Deep Neural Networks (DNNs) are often data hungry and need high-quality
labeled data in copious amounts for learning to converge. This is a challenge
in the field of medicine since high quality labeled data is often scarce. Data
programming has been the ray of hope in this regard, since it allows us to
label unlabeled data using multiple weak labeling functions. Such functions are
often supplied by a domain expert. Data-programming can combine multiple weak
labeling functions and suggest labels better than simple majority voting over
the different functions. However, it is not straightforward to express such
weak labeling functions, especially in high-dimensional settings such as images
and time-series data. What we propose in this paper is a way to bypass this
issue, using distance functions. In high-dimensional spaces, it is easier to
find meaningful distance metrics which can generalize across different labeling
tasks. We propose an algorithm that queries an expert for labels of a few
representative samples of the dataset. These samples are carefully chosen by
the algorithm to capture the distribution of the dataset. The labels assigned
by the expert on the representative subset induce a labeling on the full
dataset, thereby generating weak labels to be used in the data programming
pipeline. In our medical time series case study, labeling a subset of 50 to 130
out of 3,265 samples showed 17-28% improvement in accuracy and 13-28%
improvement in F1 over the baseline using clinician-defined labeling functions.
In our medical image case study, labeling a subset of about 50 to 120 images
from 6,293 unlabeled medical images using our approach showed significant
improvement over the baseline method, Snuba, with an increase of approximately
5-15% in accuracy and 12-19% in F1 score.",2024-07-10,"Jean Park, Sydney Pugh, Kaustubh Sridhar, Mengyu Liu, Navish Yarna, Ramneet Kaur, Souradeep Dutta, Elena Bernardis, Oleg Sokolsky, Insup Lee",http://arxiv.org/pdf/2407.07982v1,cs.LG
Deconstructing What Makes a Good Optimizer for Language Models,"Training language models becomes increasingly expensive with scale, prompting
numerous attempts to improve optimization efficiency. Despite these efforts,
the Adam optimizer remains the most widely used, due to a prevailing view that
it is the most effective approach. We aim to compare several optimization
algorithms, including SGD, Adafactor, Adam, Lion, and Sophia in the context of
autoregressive language modeling across a range of model sizes,
hyperparameters, and architecture variants. Our findings indicate that, except
for SGD, these algorithms all perform comparably both in their optimal
performance and also in terms of how they fare across a wide range of
hyperparameter choices. Our results suggest to practitioners that the choice of
optimizer can be guided by practical considerations like memory constraints and
ease of implementation, as no single algorithm emerged as a clear winner in
terms of performance or stability to hyperparameter misspecification. Given our
findings, we further dissect these approaches, examining two simplified
versions of Adam: a) signed momentum (Signum) which we see recovers both the
performance and hyperparameter stability of Adam and b) Adalayer, a layerwise
variant of Adam which we introduce to study the impact on Adam's
preconditioning for different layers of the network. Examining Adalayer leads
us to the conclusion that, perhaps surprisingly, adaptivity on both the last
layer and LayerNorm parameters in particular are necessary for retaining
performance and stability to learning rate.",2024-07-10,"Rosie Zhao, Depen Morwani, David Brandfonbrener, Nikhil Vyas, Sham Kakade",http://arxiv.org/pdf/2407.07972v2,cs.LG
LitSearch: A Retrieval Benchmark for Scientific Literature Search,"Literature search questions, such as ""Where can I find research on the
evaluation of consistency in generated summaries?"" pose significant challenges
for modern search engines and retrieval systems. These questions often require
a deep understanding of research concepts and the ability to reason across
entire articles. In this work, we introduce LitSearch, a retrieval benchmark
comprising 597 realistic literature search queries about recent ML and NLP
papers. LitSearch is constructed using a combination of (1) questions generated
by GPT-4 based on paragraphs containing inline citations from research papers
and (2) questions manually written by authors about their recently published
papers. All LitSearch questions were manually examined or edited by experts to
ensure high quality. We extensively benchmark state-of-the-art retrieval models
and also evaluate two LLM-based reranking pipelines. We find a significant
performance gap between BM25 and state-of-the-art dense retrievers, with a
24.8% absolute difference in recall@5. The LLM-based reranking strategies
further improve the best-performing dense retriever by 4.4%. Additionally,
commercial search engines and research tools like Google Search perform poorly
on LitSearch, lagging behind the best dense retriever by up to 32 recall
points. Taken together, these results show that LitSearch is an informative new
testbed for retrieval systems while catering to a real-world use case.",2024-07-10,"Anirudh Ajith, Mengzhou Xia, Alexis Chevalier, Tanya Goyal, Danqi Chen, Tianyu Gao",http://arxiv.org/pdf/2407.18940v2,cs.LG
Pentagonal Photonic Crystal Mirrors: Scalable Lightsails with Enhanced Acceleration via Neural Topology Optimization,"The Starshot Breakthrough Initiative aims to send one-gram microchip probes
to Alpha Centauri within 20 years, using gram-scale lightsails propelled by
laser-based radiation pressure, reaching velocities nearing a fifth of light
speed. This mission requires lightsail materials that challenge the
fundamentals of nanotechnology, requiring innovations in optics, material
science and structural engineering. Unlike the microchip payload, which must be
minimized in every dimension, such lightsails need meter-scale dimensions with
nanoscale thickness and billions of nanoscale holes to enhance reflectivity and
reduce mass. Our study employs neural topology optimization, revealing a novel
pentagonal lattice-based photonic crystal (PhC) reflector. The optimized
designs shorten acceleration times, therefore lowering launch costs
significantly. Crucially, these designs also enable lightsail material
fabrication with orders-of-magnitude reduction in costs. We have fabricated a
60 x 60 mm$^2$, 200nm thick, single-layer reflector perforated with over a
billion nanoscale features; the highest aspect-ratio nanophotonic element to
date. We achieve this with nearly 9,000 times cost reduction per m$^2$.
Starshot lightsails will have several stringent requirements but will
ultimately be driven by costs to build at scale. Here we highlight challenges
and possible solutions in developing lightsail materials - showcasing the
potential of scaling nanophotonics for cost-effective next-generation space
exploration.",2024-07-10,"L. Norder, S. Yin, M. J. de Jong, F. Stallone, H. Aydogmus, P. M. Sberna, M. A. Bessa, R. A. Norte",http://arxiv.org/pdf/2407.07896v1,cs.LG
"LLaVA-NeXT-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models","Visual instruction tuning has made considerable strides in enhancing the
capabilities of Large Multimodal Models (LMMs). However, existing open LMMs
largely focus on single-image tasks, their applications to multi-image
scenarios remains less explored. Additionally, prior LMM research separately
tackles different scenarios, leaving it impossible to generalize cross
scenarios with new emerging capabilities. To this end, we introduce
LLaVA-NeXT-Interleave, which simultaneously tackles Multi-image, Multi-frame
(video), Multi-view (3D), and Multi-patch (single-image) scenarios in LMMs. To
enable these capabilities, we regard the interleaved data format as a general
template and compile the M4-Instruct dataset with 1,177.6k samples, spanning 4
primary domains with 14 tasks and 41 datasets. We also curate the
LLaVA-Interleave Bench to comprehensively evaluate the multi-image performance
of LMMs. Through extensive experiments, LLaVA-NeXT-Interleave achieves leading
results in multi-image, video, and 3D benchmarks, while maintaining the
performance of single-image tasks. Besides, our model also exhibits several
emerging capabilities, e.g., transferring tasks across different settings and
modalities. Code is available at https://github.com/LLaVA-VL/LLaVA-NeXT",2024-07-10,"Feng Li, Renrui Zhang, Hao Zhang, Yuanhan Zhang, Bo Li, Wei Li, Zejun Ma, Chunyuan Li",http://arxiv.org/pdf/2407.07895v2,cs.LG
Training on the Test Task Confounds Evaluation and Emergence,"We study a fundamental problem in the evaluation of large language models
that we call training on the test task. Unlike wrongful practices like training
on the test data, leakage, or data contamination, training on the test task is
not a malpractice. Rather, the term describes a growing set of practices that
utilize knowledge about evaluation tasks at training time. We demonstrate that
training on the test task confounds both relative model evaluations and claims
about emergent capabilities. We argue that the seeming superiority of one model
family over another may be explained by a different degree of training on the
test task. To this end, we propose an effective method to adjust for the effect
of training on the test task on benchmark evaluations. Put simply, to fine-tune
each model under comparison on the same task-relevant data prior to evaluation.
We then show that instances of emergent behavior disappear gradually as models
train on the test task. Our work promotes a new perspective on the evaluation
of large language models, with broad implications for benchmarking and the
study of emergent capabilities.",2024-07-10,"Ricardo Dominguez-Olmedo, Florian E. Dorner, Moritz Hardt",http://arxiv.org/pdf/2407.07890v3,cs.LG
AdaptiGraph: Material-Adaptive Graph-Based Neural Dynamics for Robotic Manipulation,"Predictive models are a crucial component of many robotic systems. Yet,
constructing accurate predictive models for a variety of deformable objects,
especially those with unknown physical properties, remains a significant
challenge. This paper introduces AdaptiGraph, a learning-based dynamics
modeling approach that enables robots to predict, adapt to, and control a wide
array of challenging deformable materials with unknown physical properties.
AdaptiGraph leverages the highly flexible graph-based neural dynamics (GBND)
framework, which represents material bits as particles and employs a graph
neural network (GNN) to predict particle motion. Its key innovation is a
unified physical property-conditioned GBND model capable of predicting the
motions of diverse materials with varying physical properties without
retraining. Upon encountering new materials during online deployment,
AdaptiGraph utilizes a physical property optimization process for a few-shot
adaptation of the model, enhancing its fit to the observed interaction data.
The adapted models can precisely simulate the dynamics and predict the motion
of various deformable materials, such as ropes, granular media, rigid boxes,
and cloth, while adapting to different physical properties, including
stiffness, granular size, and center of pressure. On prediction and
manipulation tasks involving a diverse set of real-world deformable objects,
our method exhibits superior prediction accuracy and task proficiency over
non-material-conditioned and non-adaptive models. The project page is available
at https://robopil.github.io/adaptigraph/ .",2024-07-10,"Kaifeng Zhang, Baoyu Li, Kris Hauser, Yunzhu Li",http://arxiv.org/pdf/2407.07889v1,cs.LG
EfficientQAT: Efficient Quantization-Aware Training for Large Language Models,"Large language models (LLMs) are crucial in modern natural language
processing and artificial intelligence. However, they face challenges in
managing their significant memory requirements. Although quantization-aware
training (QAT) offers a solution by reducing memory consumption through low-bit
representations with minimal accuracy loss, it is impractical due to
substantial training resources. To address this, we propose Efficient
Quantization-Aware Training (EfficientQAT), a more feasible QAT algorithm.
EfficientQAT involves two consecutive phases: Block-wise training of all
parameters (Block-AP) and end-to-end training of quantization parameters
(E2E-QP). To the best of our knowledge, Block-AP is the first method to enable
direct training of all parameters in a block-wise manner, reducing accuracy
loss in low-bit scenarios by enhancing the solution space during optimization.
E2E-QP then trains only the quantization parameters (step sizes) end-to-end,
further improving the performance of quantized models by considering
interactions among all sub-modules. Extensive experiments demonstrate that
EfficientQAT outperforms previous quantization methods across a range of
models, including base LLMs, instruction-tuned LLMs, and multimodal LLMs, with
scales from 7B to 70B parameters at various quantization bits. For instance,
EfficientQAT obtains a 2-bit Llama-2-70B model on a single A100-80GB GPU in 41
hours, with less than 3 points accuracy degradation compared to the full
precision (69.48 vs. 72.41). Code is available at
https://github.com/OpenGVLab/EfficientQAT.",2024-07-10,"Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo",http://arxiv.org/pdf/2407.11062v3,cs.LG
Learning In-Hand Translation Using Tactile Skin With Shear and Normal Force Sensing,"Recent progress in reinforcement learning (RL) and tactile sensing has
significantly advanced dexterous manipulation. However, these methods often
utilize simplified tactile signals due to the gap between tactile simulation
and the real world. We introduce a sensor model for tactile skin that enables
zero-shot sim-to-real transfer of ternary shear and binary normal forces. Using
this model, we develop an RL policy that leverages sliding contact for
dexterous in-hand translation. We conduct extensive real-world experiments to
assess how tactile sensing facilitates policy adaptation to various unseen
object properties and robot hand orientations. We demonstrate that our 3-axis
tactile policies consistently outperform baselines that use only shear forces,
only normal forces, or only proprioception. Website:
https://jessicayin.github.io/tactile-skin-rl/",2024-07-10,"Jessica Yin, Haozhi Qi, Jitendra Malik, James Pikul, Mark Yim, Tess Hellebrekers",http://arxiv.org/pdf/2407.07885v2,cs.LG
Vegetable Peeling: A Case Study in Constrained Dexterous Manipulation,"Recent studies have made significant progress in addressing dexterous
manipulation problems, particularly in in-hand object reorientation. However,
there are few existing works that explore the potential utilization of
developed dexterous manipulation controllers for downstream tasks. In this
study, we focus on constrained dexterous manipulation for food peeling. Food
peeling presents various constraints on the reorientation controller, such as
the requirement for the hand to securely hold the object after reorientation
for peeling. We propose a simple system for learning a reorientation controller
that facilitates the subsequent peeling task. Videos are available at:
https://taochenshh.github.io/projects/veg-peeling.",2024-07-10,"Tao Chen, Eric Cousineau, Naveen Kuppuswamy, Pulkit Agrawal",http://arxiv.org/pdf/2407.07884v1,cs.LG
Towards Robust Alignment of Language Models: Distributionally Robustifying Direct Preference Optimization,"This study addresses the challenge of noise in training datasets for Direct
Preference Optimization (DPO), a method for aligning Large Language Models
(LLMs) with human preferences. We categorize noise into pointwise noise, which
includes low-quality data points, and pairwise noise, which encompasses
erroneous data pair associations that affect preference rankings. Utilizing
Distributionally Robust Optimization (DRO), we enhance DPO's resilience to
these types of noise. Our theoretical insights reveal that DPO inherently
embeds DRO principles, conferring robustness to pointwise noise, with the
regularization coefficient $\beta$ playing a critical role in its noise
resistance. Extending this framework, we introduce Distributionally
Robustifying DPO (Dr. DPO), which integrates pairwise robustness by optimizing
against worst-case pairwise scenarios. The novel hyperparameter $\beta'$ in Dr.
DPO allows for fine-tuned control over data pair reliability, providing a
strategic balance between exploration and exploitation in noisy training
environments. Empirical evaluations demonstrate that Dr. DPO substantially
improves the quality of generated text and response accuracy in preference
datasets, showcasing enhanced performance in both noisy and noise-free
settings. The code is available at https://github.com/junkangwu/Dr_DPO.",2024-07-10,"Junkang Wu, Yuexiang Xie, Zhengyi Yang, Jiancan Wu, Jiawei Chen, Jinyang Gao, Bolin Ding, Xiang Wang, Xiangnan He",http://arxiv.org/pdf/2407.07880v2,cs.LG
Generative Image as Action Models,"Image-generation diffusion models have been fine-tuned to unlock new
capabilities such as image-editing and novel view synthesis. Can we similarly
unlock image-generation models for visuomotor control? We present GENIMA, a
behavior-cloning agent that fine-tunes Stable Diffusion to 'draw joint-actions'
as targets on RGB images. These images are fed into a controller that maps the
visual targets into a sequence of joint-positions. We study GENIMA on 25
RLBench and 9 real-world manipulation tasks. We find that, by lifting actions
into image-space, internet pre-trained diffusion models can generate policies
that outperform state-of-the-art visuomotor approaches, especially in
robustness to scene perturbations and generalizing to novel objects. Our method
is also competitive with 3D agents, despite lacking priors such as depth,
keypoints, or motion-planners.",2024-07-10,"Mohit Shridhar, Yat Long Lo, Stephen James",http://arxiv.org/pdf/2407.07875v2,cs.LG
Toto: Time Series Optimized Transformer for Observability,"This technical report describes the Time Series Optimized Transformer for
Observability (Toto), a new state of the art foundation model for time series
forecasting developed by Datadog. In addition to advancing the state of the art
on generalized time series benchmarks in domains such as electricity and
weather, this model is the first general-purpose time series forecasting
foundation model to be specifically tuned for observability metrics.
  Toto was trained on a dataset of one trillion time series data points, the
largest among all currently published time series foundation models. Alongside
publicly available time series datasets, 75% of the data used to train Toto
consists of fully anonymous numerical metric data points from the Datadog
platform.
  In our experiments, Toto outperforms existing time series foundation models
on observability data. It does this while also excelling at general-purpose
forecasting tasks, achieving state-of-the-art zero-shot performance on multiple
open benchmark datasets.",2024-07-10,"Ben Cohen, Emaad Khwaja, Kan Wang, Charles Masson, Elise Ramé, Youssef Doubli, Othmane Abou-Amal",http://arxiv.org/pdf/2407.07874v2,cs.LG
Dynamical Measure Transport and Neural PDE Solvers for Sampling,"The task of sampling from a probability density can be approached as
transporting a tractable density function to the target, known as dynamical
measure transport. In this work, we tackle it through a principled unified
framework using deterministic or stochastic evolutions described by partial
differential equations (PDEs). This framework incorporates prior
trajectory-based sampling methods, such as diffusion models or Schr\""odinger
bridges, without relying on the concept of time-reversals. Moreover, it allows
us to propose novel numerical methods for solving the transport task and thus
sampling from complicated targets without the need for the normalization
constant or data samples. We employ physics-informed neural networks (PINNs) to
approximate the respective PDE solutions, implying both conceptional and
computational advantages. In particular, PINNs allow for simulation- and
discretization-free optimization and can be trained very efficiently, leading
to significantly better mode coverage in the sampling task compared to
alternative methods. Moreover, they can readily be fine-tuned with Gauss-Newton
methods to achieve high accuracy in sampling.",2024-07-10,"Jingtong Sun, Julius Berner, Lorenz Richter, Marius Zeinhofer, Johannes Müller, Kamyar Azizzadenesheli, Anima Anandkumar",http://arxiv.org/pdf/2407.07873v1,cs.LG
Green Screen Augmentation Enables Scene Generalisation in Robotic Manipulation,"Generalising vision-based manipulation policies to novel environments remains
a challenging area with limited exploration. Current practices involve
collecting data in one location, training imitation learning or reinforcement
learning policies with this data, and deploying the policy in the same
location. However, this approach lacks scalability as it necessitates data
collection in multiple locations for each task. This paper proposes a novel
approach where data is collected in a location predominantly featuring green
screens. We introduce Green-screen Augmentation (GreenAug), employing a chroma
key algorithm to overlay background textures onto a green screen. Through
extensive real-world empirical studies with over 850 training demonstrations
and 8.2k evaluation episodes, we demonstrate that GreenAug surpasses no
augmentation, standard computer vision augmentation, and prior generative
augmentation methods in performance. While no algorithmic novelties are
claimed, our paper advocates for a fundamental shift in data collection
practices. We propose that real-world demonstrations in future research should
utilise green screens, followed by the application of GreenAug. We believe
GreenAug unlocks policy generalisation to visually distinct novel locations,
addressing the current scene generalisation limitations in robot learning.",2024-07-10,"Eugene Teoh, Sumit Patidar, Xiao Ma, Stephen James",http://arxiv.org/pdf/2407.07868v2,cs.LG
FACTS About Building Retrieval Augmented Generation-based Chatbots,"Enterprise chatbots, powered by generative AI, are emerging as key
applications to enhance employee productivity. Retrieval Augmented Generation
(RAG), Large Language Models (LLMs), and orchestration frameworks like
Langchain and Llamaindex are crucial for building these chatbots. However,
creating effective enterprise chatbots is challenging and requires meticulous
RAG pipeline engineering. This includes fine-tuning embeddings and LLMs,
extracting documents from vector databases, rephrasing queries, reranking
results, designing prompts, honoring document access controls, providing
concise responses, including references, safeguarding personal information, and
building orchestration agents. We present a framework for building RAG-based
chatbots based on our experience with three NVIDIA chatbots: for IT/HR
benefits, financial earnings, and general content. Our contributions are
three-fold: introducing the FACTS framework (Freshness, Architectures, Cost,
Testing, Security), presenting fifteen RAG pipeline control points, and
providing empirical results on accuracy-latency tradeoffs between large and
small LLMs. To the best of our knowledge, this is the first paper of its kind
that provides a holistic view of the factors as well as solutions for building
secure enterprise-grade chatbots.""",2024-07-10,"Rama Akkiraju, Anbang Xu, Deepak Bora, Tan Yu, Lu An, Vishal Seth, Aaditya Shukla, Pritam Gundecha, Hridhay Mehta, Ashwin Jha, Prithvi Raj, Abhinav Balasubramanian, Murali Maram, Guru Muthusamy, Shivakesh Reddy Annepally, Sidney Knowles, Min Du, Nick Burnett, Sean Javiya, Ashok Marannan, Mamta Kumari, Surbhi Jha, Ethan Dereszenski, Anupam Chakraborty, Subhash Ranjan, Amina Terfai, Anoop Surya, Tracey Mercer, Vinodh Kumar Thanigachalam, Tamar Bar, Sanjana Krishnan, Samy Kilaru, Jasmine Jaksic, Nave Algarici, Jacob Liberman, Joey Conway, Sonu Nayyar, Justin Boitano",http://arxiv.org/pdf/2407.07858v1,cs.LG
OpenDiLoCo: An Open-Source Framework for Globally Distributed Low-Communication Training,"OpenDiLoCo is an open-source implementation and replication of the
Distributed Low-Communication (DiLoCo) training method for large language
models. We provide a reproducible implementation of the DiLoCo experiments,
offering it within a scalable, decentralized training framework using the
Hivemind library. We demonstrate its effectiveness by training a model across
two continents and three countries, while maintaining 90-95% compute
utilization. Additionally, we conduct ablations studies focusing on the
algorithm's compute efficiency, scalability in the number of workers and show
that its gradients can be all-reduced using FP16 without any performance
degradation. Furthermore, we scale OpenDiLoCo to 3x the size of the original
work, demonstrating its effectiveness for billion parameter models.",2024-07-10,"Sami Jaghouar, Jack Min Ong, Johannes Hagemann",http://arxiv.org/pdf/2407.07852v1,cs.LG
Uncovering Layer-Dependent Activation Sparsity Patterns in ReLU Transformers,"Previous work has demonstrated that MLPs within ReLU Transformers exhibit
high levels of sparsity, with many of their activations equal to zero for any
given token. We build on that work to more deeply explore how token-level
sparsity evolves over the course of training, and how it connects to broader
sparsity patterns over the course of a sequence or batch, demonstrating that
the different layers within small transformers exhibit distinctly
layer-specific patterns on both of these fronts. In particular, we demonstrate
that the first and last layer of the network have distinctive and in many ways
inverted relationships to sparsity, and explore implications for the structure
of feature representations being learned at different depths of the model. We
additionally explore the phenomenon of ReLU dimensions ""turning off"", and show
evidence suggesting that ""neuron death"" is being primarily driven by the
dynamics of training, rather than simply occurring randomly or accidentally as
a result of outliers.",2024-07-10,"Cody Wild, Jesper Anderson",http://arxiv.org/pdf/2407.07848v1,cs.LG
Applying generative neural networks for fast simulations of the ALICE (CERN) experiment,"This thesis investigates the application of state-of-the-art advances in
generative neural networks for fast simulation of the Zero Degree Calorimeter
(ZDC) neutron detector in the ALICE experiment at CERN. Traditional simulation
methods using the GEANT Monte Carlo toolkit, while accurate, are
computationally demanding. With increasing computational needs at CERN,
efficient simulation techniques are essential. The thesis provides a
comprehensive literature review on the application of neural networks in
computer vision, fast simulations using machine learning, and generative neural
networks in high-energy physics. The theory of the analyzed models is also
discussed, along with technical aspects and the challenges associated with a
practical implementation. The experiments evaluate various neural network
architectures, including convolutional neural networks, vision transformers,
and MLP-Mixers, as well as generative frameworks such as autoencoders,
generative adversarial networks, vector quantization models, and diffusion
models. Key contributions include the implementation and evaluation of these
models, a significant improvement in the Wasserstein metric compared to
existing methods with a low generation time of 5 milliseconds per sample, and
the formulation of a list of recommendations for developing models for fast ZDC
simulation. Open-source code and detailed hyperparameter settings are provided
for reproducibility. Additionally, the thesis outlines future research
directions to further enhance simulation fidelity and efficiency.",2024-07-10,Maksymilian Wojnar,http://arxiv.org/pdf/2407.16704v1,cs.LG
Disentangled Representation Learning with the Gromov-Monge Gap,"Learning disentangled representations from unlabelled data is a fundamental
challenge in machine learning. Solving it may unlock other problems, such as
generalization, interpretability, or fairness. Although remarkably challenging
to solve in theory, disentanglement is often achieved in practice through prior
matching. Furthermore, recent works have shown that prior matching approaches
can be enhanced by leveraging geometrical considerations, e.g., by learning
representations that preserve geometric features of the data, such as distances
or angles between points. However, matching the prior while preserving
geometric features is challenging, as a mapping that fully preserves these
features while aligning the data distribution with the prior does not exist in
general. To address these challenges, we introduce a novel approach to
disentangled representation learning based on quadratic optimal transport. We
formulate the problem using Gromov-Monge maps that transport one distribution
onto another with minimal distortion of predefined geometric features,
preserving them as much as can be achieved. To compute such maps, we propose
the Gromov-Monge-Gap (GMG), a regularizer quantifying whether a map moves a
reference distribution with minimal geometry distortion. We demonstrate the
effectiveness of our approach for disentanglement across four standard
benchmarks, outperforming other methods leveraging geometric considerations.",2024-07-10,"Théo Uscidda, Luca Eyring, Karsten Roth, Fabian Theis, Zeynep Akata, Marco Cuturi",http://arxiv.org/pdf/2407.07829v2,cs.LG
Estimating the stability number of a random graph using convolutional neural networks,"Graph combinatorial optimization problems are widely applicable and
notoriously difficult to compute; for example, consider the traveling salesman
or facility location problems. In this paper, we explore the feasibility of
using convolutional neural networks (CNNs) on graph images to predict the
cardinality of combinatorial properties of random graphs and networks.
Specifically, we use image representations of modified adjacency matrices of
random graphs as training samples for a CNN model to predict the stability
number of random graphs; where the stability number is the cardinality of a
maximum set of vertices in a graph that contains no pairwise adjacency between
vertices. The model and results presented in this study suggest potential for
applying deep learning in combinatorial optimization problems previously not
considered by simple deep learning techniques.",2024-07-10,Randy Davila,http://arxiv.org/pdf/2407.07827v2,cs.LG
When to Accept Automated Predictions and When to Defer to Human Judgment?,"Ensuring the reliability and safety of automated decision-making is crucial.
It is well-known that data distribution shifts in machine learning can produce
unreliable outcomes. This paper proposes a new approach for measuring the
reliability of predictions under distribution shifts. We analyze how the
outputs of a trained neural network change using clustering to measure
distances between outputs and class centroids. We propose this distance as a
metric to evaluate the confidence of predictions under distribution shifts. We
assign each prediction to a cluster with centroid representing the mean softmax
output for all correct predictions of a given class. We then define a safety
threshold for a class as the smallest distance from an incorrect prediction to
the given class centroid. We evaluate the approach on the MNIST and CIFAR-10
datasets using a Convolutional Neural Network and a Vision Transformer,
respectively. The results show that our approach is consistent across these
data sets and network models, and indicate that the proposed metric can offer
an efficient way of determining when automated predictions are acceptable and
when they should be deferred to human operators given a distribution shift.",2024-07-10,"Daniel Sikar, Artur Garcez, Tillman Weyde, Robin Bloomfield, Kaleem Peeroo",http://arxiv.org/pdf/2407.07821v2,cs.LG
The Misclassification Likelihood Matrix: Some Classes Are More Likely To Be Misclassified Than Others,"This study introduces the Misclassification Likelihood Matrix (MLM) as a
novel tool for quantifying the reliability of neural network predictions under
distribution shifts. The MLM is obtained by leveraging softmax outputs and
clustering techniques to measure the distances between the predictions of a
trained neural network and class centroids. By analyzing these distances, the
MLM provides a comprehensive view of the model's misclassification tendencies,
enabling decision-makers to identify the most common and critical sources of
errors. The MLM allows for the prioritization of model improvements and the
establishment of decision thresholds based on acceptable risk levels. The
approach is evaluated on the MNIST dataset using a Convolutional Neural Network
(CNN) and a perturbed version of the dataset to simulate distribution shifts.
The results demonstrate the effectiveness of the MLM in assessing the
reliability of predictions and highlight its potential in enhancing the
interpretability and risk mitigation capabilities of neural networks. The
implications of this work extend beyond image classification, with ongoing
applications in autonomous systems, such as self-driving cars, to improve the
safety and reliability of decision-making in complex, real-world environments.",2024-07-10,"Daniel Sikar, Artur Garcez, Robin Bloomfield, Tillman Weyde, Kaleem Peeroo, Naman Singh, Maeve Hutchinson, Dany Laksono, Mirela Reljan-Delaney",http://arxiv.org/pdf/2407.07818v3,cs.LG
Transformer Block Coupling and its Correlation with Generalization in LLMs,"Large Language Models (LLMs) have made significant strides in natural
language processing, and a precise understanding of the internal mechanisms
driving their success is essential. In this work, we analyze the trajectories
of token embeddings as they pass through transformer blocks, linearizing the
system along these trajectories through their Jacobian matrices. By examining
the relationships between these block Jacobians, we uncover the phenomenon of
\textbf{transformer block coupling} in a multitude of LLMs, characterized by
the coupling of their top singular vectors across tokens and depth. Our
findings reveal that coupling \textit{positively correlates} with model
performance, and that this relationship is stronger than with other
hyperparameters such as parameter count, model depth, and embedding dimension.
We further investigate how these properties emerge during training, observing a
progressive development of coupling, increased linearity, and layer-wise
exponential growth in token trajectories. Additionally, experiments with Vision
Transformers (ViTs) corroborate the emergence of coupling and its relationship
with generalization, reinforcing our findings in LLMs. Collectively, these
insights offer a novel perspective on token interactions in transformers,
opening new directions for studying their mechanisms as well as improving
training and generalization.",2024-07-10,"Murdock Aubry, Haoming Meng, Anton Sugolov, Vardan Papyan",http://arxiv.org/pdf/2407.07810v5,cs.LG
ROSA: Random Subspace Adaptation for Efficient Fine-Tuning,"Model training requires significantly more memory, compared with inference.
Parameter efficient fine-tuning (PEFT) methods provide a means of adapting
large models to downstream tasks using less memory. However, existing methods
such as adapters, prompt tuning or low-rank adaptation (LoRA) either introduce
latency overhead at inference time or achieve subpar downstream performance
compared with full fine-tuning. In this work we propose Random Subspace
Adaptation (ROSA), a method that outperforms previous PEFT methods by a
significant margin, while maintaining a zero latency overhead during inference
time. In contrast to previous methods, ROSA is able to adapt subspaces of
arbitrarily large dimension, better approximating full-finetuning. We
demonstrate both theoretically and experimentally that this makes ROSA strictly
more expressive than LoRA, without consuming additional memory during runtime.
As PEFT methods are especially useful in the natural language processing
domain, where models operate on scales that make full fine-tuning very
expensive, we evaluate ROSA in two common NLP scenarios: natural language
generation (NLG) and natural language understanding (NLU) with GPT-2 and
RoBERTa, respectively. We show that on almost every GLUE task ROSA outperforms
LoRA by a significant margin, while also outperforming LoRA on NLG tasks. Our
code is available at https://github.com/rosa-paper/rosa",2024-07-10,"Marawan Gamal Abdel Hameed, Aristides Milios, Siva Reddy, Guillaume Rabusseau",http://arxiv.org/pdf/2407.07802v1,cs.LG
AVCap: Leveraging Audio-Visual Features as Text Tokens for Captioning,"In recent years, advancements in representation learning and language models
have propelled Automated Captioning (AC) to new heights, enabling the
generation of human-level descriptions. Leveraging these advancements, we
propose AVCap, an Audio-Visual Captioning framework, a simple yet powerful
baseline approach applicable to audio-visual captioning. AVCap utilizes
audio-visual features as text tokens, which has many advantages not only in
performance but also in the extensibility and scalability of the model. AVCap
is designed around three pivotal dimensions: the exploration of optimal
audio-visual encoder architectures, the adaptation of pre-trained models
according to the characteristics of generated text, and the investigation into
the efficacy of modality fusion in captioning. Our method outperforms existing
audio-visual captioning methods across all metrics and the code is available on
https://github.com/JongSuk1/AVCap",2024-07-10,"Jongsuk Kim, Jiwon Shin, Junmo Kim",http://arxiv.org/pdf/2407.07801v2,cs.LG
Evaluating Large Language Models with Grid-Based Game Competitions: An Extensible LLM Benchmark and Leaderboard,"We introduce a novel and extensible benchmark for large language models
(LLMs) through grid-based games such as Tic-Tac-Toe, Connect Four, and Gomoku.
The open-source game simulation code, available on GitHub, allows LLMs to
compete and generates detailed data files in JSON, CSV, TXT, and PNG formats
for leaderboard rankings and further analysis. We present the results of games
among leading LLMs, including Claude 3.5 Sonnet and Claude 3 Sonnet by
Anthropic, Gemini 1.5 Pro and Gemini 1.5 Flash by Google, GPT-4 Turbo and
GPT-4o by OpenAI, and Llama3-70B by Meta. We also encourage submissions of
results from other LLMs. In total, we simulated 2,310 matches (5 sessions for
each pair among 7 LLMs and a random player) across three types of games, using
three distinct prompt types: list, illustration, and image. The results
revealed significant variations in LLM performance across different games and
prompt types, with analysis covering win and disqualification rates, missed
opportunity analysis, and invalid move analysis. The details of the leaderboard
and result matrix data are available as open-access data on GitHub. This study
enhances our understanding of LLMs' capabilities in playing games they were not
specifically trained for, helping to assess their rule comprehension and
strategic thinking. On the path to Artificial General Intelligence (AGI), this
study lays the groundwork for future exploration into their utility in complex
decision-making scenarios, illuminating their strategic thinking abilities and
offering directions for further inquiry into the limits of LLMs within
game-based frameworks.",2024-07-10,"Oguzhan Topsakal, Colby Jacob Edell, Jackson Bailey Harper",http://arxiv.org/pdf/2407.07796v2,cs.LG
Reinforcement Learning of Adaptive Acquisition Policies for Inverse Problems,"A promising way to mitigate the expensive process of obtaining a
high-dimensional signal is to acquire a limited number of low-dimensional
measurements and solve an under-determined inverse problem by utilizing the
structural prior about the signal. In this paper, we focus on adaptive
acquisition schemes to save further the number of measurements. To this end, we
propose a reinforcement learning-based approach that sequentially collects
measurements to better recover the underlying signal by acquiring fewer
measurements. Our approach applies to general inverse problems with continuous
action spaces and jointly learns the recovery algorithm. Using insights
obtained from theoretical analysis, we also provide a probabilistic design for
our methods using variational formulation. We evaluate our approach on multiple
datasets and with two measurement spaces (Gaussian, Radon). Our results confirm
the benefits of adaptive strategies in low-acquisition horizon settings.",2024-07-10,"Gianluigi Silvestri, Fabio Valerio Massoli, Tribhuvanesh Orekondy, Afshin Abdi, Arash Behboodi",http://arxiv.org/pdf/2407.07794v1,cs.LG
"Exploring the Boundaries of On-Device Inference: When Tiny Falls Short, Go Hierarchical","On-device inference holds great potential for increased energy efficiency,
responsiveness, and privacy in edge ML systems. However, due to less capable ML
models that can be embedded in resource-limited devices, use cases are limited
to simple inference tasks such as visual keyword spotting, gesture recognition,
and predictive analytics. In this context, the Hierarchical Inference (HI)
system has emerged as a promising solution that augments the capabilities of
the local ML by offloading selected samples to an edge server or cloud for
remote ML inference. Existing works demonstrate through simulation that HI
improves accuracy. However, they do not account for the latency and energy
consumption on the device, nor do they consider three key heterogeneous
dimensions that characterize ML systems: hardware, network connectivity, and
models. In contrast, this paper systematically compares the performance of HI
with on-device inference based on measurements of accuracy, latency, and energy
for running embedded ML models on five devices with different capabilities and
three image classification datasets. For a given accuracy requirement, the HI
systems we designed achieved up to 73% lower latency and up to 77% lower device
energy consumption than an on-device inference system. The key to building an
efficient HI system is the availability of small-size, reasonably accurate
on-device models whose outputs can be effectively differentiated for samples
that require remote inference. Despite the performance gains, HI requires
on-device inference for all samples, which adds a fixed overhead to its latency
and energy consumption. Therefore, we design a hybrid system, Early Exit with
HI (EE-HI), and demonstrate that compared to HI, EE-HI reduces the latency by
up to 59.7% and lowers the device's energy consumption by up to 60.4%.",2024-07-10,"Adarsh Prasad Behera, Paulius Daubaris, Iñaki Bravo, José Gallego, Roberto Morabito, Joerg Widmer, Jaya Prakash Varma Champati",http://arxiv.org/pdf/2407.11061v2,cs.LG
BiGym: A Demo-Driven Mobile Bi-Manual Manipulation Benchmark,"We introduce BiGym, a new benchmark and learning environment for mobile
bi-manual demo-driven robotic manipulation. BiGym features 40 diverse tasks set
in home environments, ranging from simple target reaching to complex kitchen
cleaning. To capture the real-world performance accurately, we provide
human-collected demonstrations for each task, reflecting the diverse modalities
found in real-world robot trajectories. BiGym supports a variety of
observations, including proprioceptive data and visual inputs such as RGB, and
depth from 3 camera views. To validate the usability of BiGym, we thoroughly
benchmark the state-of-the-art imitation learning algorithms and demo-driven
reinforcement learning algorithms within the environment and discuss the future
opportunities.",2024-07-10,"Nikita Chernyadev, Nicholas Backshall, Xiao Ma, Yunfan Lu, Younggyo Seo, Stephen James",http://arxiv.org/pdf/2407.07788v2,cs.LG
Continuous Control with Coarse-to-fine Reinforcement Learning,"Despite recent advances in improving the sample-efficiency of reinforcement
learning (RL) algorithms, designing an RL algorithm that can be practically
deployed in real-world environments remains a challenge. In this paper, we
present Coarse-to-fine Reinforcement Learning (CRL), a framework that trains RL
agents to zoom-into a continuous action space in a coarse-to-fine manner,
enabling the use of stable, sample-efficient value-based RL algorithms for
fine-grained continuous control tasks. Our key idea is to train agents that
output actions by iterating the procedure of (i) discretizing the continuous
action space into multiple intervals and (ii) selecting the interval with the
highest Q-value to further discretize at the next level. We then introduce a
concrete, value-based algorithm within the CRL framework called Coarse-to-fine
Q-Network (CQN). Our experiments demonstrate that CQN significantly outperforms
RL and behavior cloning baselines on 20 sparsely-rewarded RLBench manipulation
tasks with a modest number of environment interactions and expert
demonstrations. We also show that CQN robustly learns to solve real-world
manipulation tasks within a few minutes of online training.",2024-07-10,"Younggyo Seo, Jafar Uruç, Stephen James",http://arxiv.org/pdf/2407.07787v1,cs.LG
Mitigating Cognitive Biases in Multi-Criteria Crowd Assessment,"Crowdsourcing is an easy, cheap, and fast way to perform large scale quality
assessment; however, human judgments are often influenced by cognitive biases,
which lowers their credibility. In this study, we focus on cognitive biases
associated with a multi-criteria assessment in crowdsourcing; crowdworkers who
rate targets with multiple different criteria simultaneously may provide biased
responses due to prominence of some criteria or global impressions of the
evaluation targets. To identify and mitigate such biases, we first create
evaluation datasets using crowdsourcing and investigate the effect of
inter-criteria cognitive biases on crowdworker responses. Then, we propose two
specific model structures for Bayesian opinion aggregation models that consider
inter-criteria relations. Our experiments show that incorporating our proposed
structures into the aggregation model is effective to reduce the cognitive
biases and help obtain more accurate aggregation results.",2024-07-10,"Shun Ito, Hisashi Kashima",http://arxiv.org/pdf/2407.18938v1,cs.LG
Ramsey Theorems for Trees and a General 'Private Learning Implies Online Learning' Theorem,"This work continues to investigate the link between differentially private
(DP) and online learning. Alon, Livni, Malliaris, and Moran (2019) showed that
for binary concept classes, DP learnability of a given class implies that it
has a finite Littlestone dimension (equivalently, that it is online learnable).
Their proof relies on a model-theoretic result by Hodges (1997), which
demonstrates that any binary concept class with a large Littlestone dimension
contains a large subclass of thresholds. In a follow-up work, Jung, Kim, and
Tewari (2020) extended this proof to multiclass PAC learning with a bounded
number of labels. Unfortunately, Hodges's result does not apply in other
natural settings such as multiclass PAC learning with an unbounded label space,
and PAC learning of partial concept classes.
  This naturally raises the question of whether DP learnability continues to
imply online learnability in more general scenarios: indeed, Alon, Hanneke,
Holzman, and Moran (2021) explicitly leave it as an open question in the
context of partial concept classes, and the same question is open in the
general multiclass setting. In this work, we give a positive answer to these
questions showing that for general classification tasks, DP learnability
implies online learnability. Our proof reasons directly about Littlestone
trees, without relying on thresholds. We achieve this by establishing several
Ramsey-type theorems for trees, which might be of independent interest.",2024-07-10,"Simone Fioravanti, Steve Hanneke, Shay Moran, Hilla Schefler, Iska Tsubari",http://arxiv.org/pdf/2407.07765v2,cs.LG
A review of graph neural network applications in mechanics-related domains,"Mechanics-related problems often present unique challenges in achieving
accurate geometric and physical representations, particularly for non-uniform
structures. Graph neural networks (GNNs) have emerged as a promising tool to
tackle these challenges by adeptly learning from graph data with irregular
underlying structures. Consequently, recent years have witnessed a surge in
complex mechanics-related applications inspired by the advancements of GNNs.
Despite this process, there is a notable absence of a systematic review
addressing the recent advancement of GNNs in solving mechanics-related
problems. To bridge this gap, this review article aims to provide an in-depth
overview of the GNN applications in mechanics-related domains while identifying
key challenges and outlining potential future research directions. In this
review article, we begin by introducing the fundamental algorithms of GNNs that
are widely employed in mechanics-related applications. We provide a concise
explanation of their underlying principles to establish a solid understanding
that will serve as a basis for exploring the applications of GNNs in
mechanics-related domains. The scope of this paper is intended to cover the
categorisation of literature into solid mechanics, fluid mechanics, and
interdisciplinary mechanics-related domains, providing a comprehensive summary
of graph representation methodologies, GNN architectures, and further
discussions in their respective subdomains. Additionally, open data and source
codes relevant to these applications are summarised for the convenience of
future researchers. This article promotes an interdisciplinary integration of
GNNs and mechanics and provides a guide for researchers interested in applying
GNNs to solve complex mechanics-related problems.",2024-07-10,"Yingxue Zhao, Haoran Li, Haosu Zhou, Hamid Reza Attar, Tobias Pfaff, Nan Li",http://arxiv.org/pdf/2407.11060v1,cs.LG
Fine-Tuning Large Language Models with User-Level Differential Privacy,"We investigate practical and scalable algorithms for training large language
models (LLMs) with user-level differential privacy (DP) in order to provably
safeguard all the examples contributed by each user. We study two variants of
DP-SGD with: (1) example-level sampling (ELS) and per-example gradient
clipping, and (2) user-level sampling (ULS) and per-user gradient clipping. We
derive a novel user-level DP accountant that allows us to compute provably
tight privacy guarantees for ELS. Using this, we show that while ELS can
outperform ULS in specific settings, ULS generally yields better results when
each user has a diverse collection of examples. We validate our findings
through experiments in synthetic mean estimation and LLM fine-tuning tasks
under fixed compute budgets. We find that ULS is significantly better in
settings where either (1) strong privacy guarantees are required, or (2) the
compute budget is large. Notably, our focus on LLM-compatible training
algorithms allows us to scale to models with hundreds of millions of parameters
and datasets with hundreds of thousands of users.",2024-07-10,"Zachary Charles, Arun Ganesh, Ryan McKenna, H. Brendan McMahan, Nicole Mitchell, Krishna Pillutla, Keith Rush",http://arxiv.org/pdf/2407.07737v1,cs.LG
PaliGemma: A versatile 3B VLM for transfer,"PaliGemma is an open Vision-Language Model (VLM) that is based on the
SigLIP-So400m vision encoder and the Gemma-2B language model. It is trained to
be a versatile and broadly knowledgeable base model that is effective to
transfer. It achieves strong performance on a wide variety of open-world tasks.
We evaluate PaliGemma on almost 40 diverse tasks including standard VLM
benchmarks, but also more specialized tasks such as remote-sensing and
segmentation.",2024-07-10,"Lucas Beyer, Andreas Steiner, André Susano Pinto, Alexander Kolesnikov, Xiao Wang, Daniel Salz, Maxim Neumann, Ibrahim Alabdulmohsin, Michael Tschannen, Emanuele Bugliarello, Thomas Unterthiner, Daniel Keysers, Skanda Koppula, Fangyu Liu, Adam Grycner, Alexey Gritsenko, Neil Houlsby, Manoj Kumar, Keran Rong, Julian Eisenschlos, Rishabh Kabra, Matthias Bauer, Matko Bošnjak, Xi Chen, Matthias Minderer, Paul Voigtlaender, Ioana Bica, Ivana Balazevic, Joan Puigcerver, Pinelopi Papalampidi, Olivier Henaff, Xi Xiong, Radu Soricut, Jeremiah Harmsen, Xiaohua Zhai",http://arxiv.org/pdf/2407.07726v2,cs.LG
Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs,"Continuous-time dynamic graphs (CTDGs) are essential for modeling
interconnected, evolving systems. Traditional methods for extracting knowledge
from these graphs often depend on feature engineering or deep learning. Feature
engineering is limited by the manual and time-intensive nature of crafting
features, while deep learning approaches suffer from high inference latency,
making them impractical for real-time applications. This paper introduces
Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for
efficient representation learning on CTDGs with low-latency inference
requirements. We benchmark DGS against state-of-the-art (SOTA) feature
engineering and graph neural network methods using five diverse datasets. The
results indicate that DGS achieves competitive performance while inference
speed improves between 4x and 12x compared to other deep learning approaches on
our benchmark datasets. Our method effectively bridges the gap between deep
representation learning and low-latency application requirements for CTDGs.",2024-07-10,"Ahmad Naser Eddin, Jacopo Bono, David Aparício, Hugo Ferreira, Pedro Ribeiro, Pedro Bizarro",http://arxiv.org/pdf/2407.07712v3,cs.LG
Split Conformal Prediction under Data Contamination,"Conformal prediction is a non-parametric technique for constructing
prediction intervals or sets from arbitrary predictive models under the
assumption that the data is exchangeable. It is popular as it comes with
theoretical guarantees on the marginal coverage of the prediction sets and the
split conformal prediction variant has a very low computational cost compared
to model training. We study the robustness of split conformal prediction in a
data contamination setting, where we assume a small fraction of the calibration
scores are drawn from a different distribution than the bulk. We quantify the
impact of the corrupted data on the coverage and efficiency of the constructed
sets when evaluated on ""clean"" test points, and verify our results with
numerical experiments. Moreover, we propose an adjustment in the classification
setting which we call Contamination Robust Conformal Prediction, and verify the
efficacy of our approach using both synthetic and real datasets.",2024-07-10,"Jase Clarkson, Wenkai Xu, Mihai Cucuringu, Gesine Reinert",http://arxiv.org/pdf/2407.07700v2,cs.LG
Towards Human-Like Driving: Active Inference in Autonomous Vehicle Control,"This paper presents a novel approach to Autonomous Vehicle (AV) control
through the application of active inference, a theory derived from neuroscience
that conceptualizes the brain as a predictive machine. Traditional autonomous
driving systems rely heavily on Modular Pipelines, Imitation Learning, or
Reinforcement Learning, each with inherent limitations in adaptability,
generalization, and computational efficiency. Active inference addresses these
challenges by minimizing prediction error (termed ""surprise"") through a dynamic
model that balances perception and action. Our method integrates active
inference with deep learning to manage lateral control in AVs, enabling them to
perform lane following maneuvers within a simulated urban environment. We
demonstrate that our model, despite its simplicity, effectively learns and
generalizes from limited data without extensive retraining, significantly
reducing computational demands. The proposed approach not only enhances the
adaptability and performance of AVs in dynamic scenarios but also aligns
closely with human-like driving behavior, leveraging a generative model to
predict and adapt to environmental changes. Results from extensive experiments
in the CARLA simulator show promising outcomes, outperforming traditional
methods in terms of adaptability and efficiency, thereby advancing the
potential of active inference in real-world autonomous driving applications.",2024-07-10,"Elahe Delavari, John Moore, Junho Hong, Jaerock Kwon",http://arxiv.org/pdf/2407.07684v2,cs.LG
"Advancements in Recommender Systems: A Comprehensive Analysis Based on Data, Algorithms, and Evaluation","Using 286 research papers collected from Web of Science, ScienceDirect,
SpringerLink, arXiv, and Google Scholar databases, a systematic review
methodology was adopted to review and summarize the current challenges and
potential future developments in data, algorithms, and evaluation aspects of
RSs. It was found that RSs involve five major research topics, namely
algorithmic improvement, domain applications, user behavior & cognition, data
processing & modeling, and social impact & ethics. Collaborative filtering and
hybrid recommendation techniques are mainstream. The performance of RSs is
jointly limited by four types of eight data issues, two types of twelve
algorithmic issues, and two evaluation issues. Notably, data-related issues
such as cold start, data sparsity, and data poisoning, algorithmic issues like
interest drift, device-cloud collaboration, non-causal driven, and multitask
conflicts, along with evaluation issues such as offline data leakage and
multi-objective balancing, have prominent impacts. Fusing physiological signals
for multimodal modeling, defending against data poisoning through user
information behavior, evaluating generative recommendations via social
experiments, fine-tuning pre-trained large models to schedule device-cloud
resource, enhancing causal inference with deep reinforcement learning, training
multi-task models based on probability distributions, using cross-temporal
dataset partitioning, and evaluating recommendation objectives across the full
lifecycle are feasible solutions to address the aforementioned prominent
challenges and unlock the power and value of RSs.The collected literature is
mainly based on major international databases, and future research will further
expand upon it.",2024-07-10,"Xin Ma, Mingyue Li, Xuguang Liu",http://arxiv.org/pdf/2407.18937v1,cs.LG
Feasibility Study on Active Learning of Smart Surrogates for Scientific Simulations,"High-performance scientific simulations, important for comprehension of
complex systems, encounter computational challenges especially when exploring
extensive parameter spaces. There has been an increasing interest in developing
deep neural networks (DNNs) as surrogate models capable of accelerating the
simulations. However, existing approaches for training these DNN surrogates
rely on extensive simulation data which are heuristically selected and
generated with expensive computation -- a challenge under-explored in the
literature. In this paper, we investigate the potential of incorporating active
learning into DNN surrogate training. This allows intelligent and objective
selection of training simulations, reducing the need to generate extensive
simulation data as well as the dependency of the performance of DNN surrogates
on pre-defined training simulations. In the problem context of constructing DNN
surrogates for diffusion equations with sources, we examine the efficacy of
diversity- and uncertainty-based strategies for selecting training simulations,
considering two different DNN architecture. The results set the groundwork for
developing the high-performance computing infrastructure for Smart Surrogates
that supports on-the-fly generation of simulation data steered by active
learning strategies to potentially improve the efficiency of scientific
simulations.",2024-07-10,"Pradeep Bajracharya, Javier Quetzalcóatl Toledo-Marín, Geoffrey Fox, Shantenu Jha, Linwei Wang",http://arxiv.org/pdf/2407.07674v2,cs.LG
Stochastic Gradient Descent for Two-layer Neural Networks,"This paper presents a comprehensive study on the convergence rates of the
stochastic gradient descent (SGD) algorithm when applied to overparameterized
two-layer neural networks. Our approach combines the Neural Tangent Kernel
(NTK) approximation with convergence analysis in the Reproducing Kernel Hilbert
Space (RKHS) generated by NTK, aiming to provide a deep understanding of the
convergence behavior of SGD in overparameterized two-layer neural networks. Our
research framework enables us to explore the intricate interplay between kernel
methods and optimization processes, shedding light on the optimization dynamics
and convergence properties of neural networks. In this study, we establish
sharp convergence rates for the last iterate of the SGD algorithm in
overparameterized two-layer neural networks. Additionally, we have made
significant advancements in relaxing the constraints on the number of neurons,
which have been reduced from exponential dependence to polynomial dependence on
the sample size or number of iterations. This improvement allows for more
flexibility in the design and scaling of neural networks, and will deepen our
theoretical understanding of neural network models trained with SGD.",2024-07-10,"Dinghao Cao, Zheng-Chu Guo, Lei Shi",http://arxiv.org/pdf/2407.07670v1,cs.LG
How to Leverage Predictive Uncertainty Estimates for Reducing Catastrophic Forgetting in Online Continual Learning,"Many real-world applications require machine-learning models to be able to
deal with non-stationary data distributions and thus learn autonomously over an
extended period of time, often in an online setting. One of the main challenges
in this scenario is the so-called catastrophic forgetting (CF) for which the
learning model tends to focus on the most recent tasks while experiencing
predictive degradation on older ones. In the online setting, the most effective
solutions employ a fixed-size memory buffer to store old samples used for
replay when training on new tasks. Many approaches have been presented to
tackle this problem. However, it is not clear how predictive uncertainty
information for memory management can be leveraged in the most effective manner
and conflicting strategies are proposed to populate the memory. Are the
easiest-to-forget or the easiest-to-remember samples more effective in
combating CF? Starting from the intuition that predictive uncertainty provides
an idea of the samples' location in the decision space, this work presents an
in-depth analysis of different uncertainty estimates and strategies for
populating the memory. The investigation provides a better understanding of the
characteristics data points should have for alleviating CF. Then, we propose an
alternative method for estimating predictive uncertainty via the generalised
variance induced by the negative log-likelihood. Finally, we demonstrate that
the use of predictive uncertainty measures helps in reducing CF in different
settings.",2024-07-10,"Giuseppe Serra, Ben Werner, Florian Buettner",http://arxiv.org/pdf/2407.07668v2,cs.LG
A Coding-Theoretic Analysis of Hyperspherical Prototypical Learning Geometry,"Hyperspherical Prototypical Learning (HPL) is a supervised approach to
representation learning that designs class prototypes on the unit hypersphere.
The prototypes bias the representations to class separation in a scale
invariant and known geometry. Previous approaches to HPL have either of the
following shortcomings: (i) they follow an unprincipled optimisation procedure;
or (ii) they are theoretically sound, but are constrained to only one possible
latent dimension. In this paper, we address both shortcomings. To address (i),
we present a principled optimisation procedure whose solution we show is
optimal. To address (ii), we construct well-separated prototypes in a wide
range of dimensions using linear block codes. Additionally, we give a full
characterisation of the optimal prototype placement in terms of achievable and
converse bounds, showing that our proposed methods are near-optimal.",2024-07-10,"Martin Lindström, Borja Rodríguez-Gálvez, Ragnar Thobaben, Mikael Skoglund",http://arxiv.org/pdf/2407.07664v2,cs.LG
The Selective G-Bispectrum and its Inversion: Applications to G-Invariant Networks,"An important problem in signal processing and deep learning is to achieve
\textit{invariance} to nuisance factors not relevant for the task. Since many
of these factors are describable as the action of a group $G$ (e.g. rotations,
translations, scalings), we want methods to be $G$-invariant. The
$G$-Bispectrum extracts every characteristic of a given signal up to group
action: for example, the shape of an object in an image, but not its
orientation. Consequently, the $G$-Bispectrum has been incorporated into deep
neural network architectures as a computational primitive for
$G$-invariance\textemdash akin to a pooling mechanism, but with greater
selectivity and robustness. However, the computational cost of the
$G$-Bispectrum ($\mathcal{O}(|G|^2)$, with $|G|$ the size of the group) has
limited its widespread adoption. Here, we show that the $G$-Bispectrum
computation contains redundancies that can be reduced into a \textit{selective
$G$-Bispectrum} with $\mathcal{O}(|G|)$ complexity. We prove desirable
mathematical properties of the selective $G$-Bispectrum and demonstrate how its
integration in neural networks enhances accuracy and robustness compared to
traditional approaches, while enjoying considerable speeds-up compared to the
full $G$-Bispectrum.",2024-07-10,"Simon Mataigne, Johan Mathe, Sophia Sanborn, Christopher Hillar, Nina Miolane",http://arxiv.org/pdf/2407.07655v2,cs.LG
Explaining Graph Neural Networks for Node Similarity on Graphs,"Similarity search is a fundamental task for exploiting information in various
applications dealing with graph data, such as citation networks or knowledge
graphs. While this task has been intensively approached from heuristics to
graph embeddings and graph neural networks (GNNs), providing explanations for
similarity has received less attention. In this work we are concerned with
explainable similarity search over graphs, by investigating how GNN-based
methods for computing node similarities can be augmented with explanations.
Specifically, we evaluate the performance of two prominent approaches towards
explanations in GNNs, based on the concepts of mutual information (MI), and
gradient-based explanations (GB). We discuss their suitability and empirically
validate the properties of their explanations over different popular graph
benchmarks. We find that unlike MI explanations, gradient-based explanations
have three desirable properties. First, they are actionable: selecting inputs
depending on them results in predictable changes in similarity scores. Second,
they are consistent: the effect of selecting certain inputs overlaps very
little with the effect of discarding them. Third, they can be pruned
significantly to obtain sparse explanations that retain the effect on
similarity scores.",2024-07-10,"Daniel Daza, Cuong Xuan Chu, Trung-Kien Tran, Daria Stepanova, Michael Cochez, Paul Groth",http://arxiv.org/pdf/2407.07639v1,cs.LG
MoVEInt: Mixture of Variational Experts for Learning Human-Robot Interactions from Demonstrations,"Shared dynamics models are important for capturing the complexity and
variability inherent in Human-Robot Interaction (HRI). Therefore, learning such
shared dynamics models can enhance coordination and adaptability to enable
successful reactive interactions with a human partner. In this work, we propose
a novel approach for learning a shared latent space representation for HRIs
from demonstrations in a Mixture of Experts fashion for reactively generating
robot actions from human observations. We train a Variational Autoencoder (VAE)
to learn robot motions regularized using an informative latent space prior that
captures the multimodality of the human observations via a Mixture Density
Network (MDN). We show how our formulation derives from a Gaussian Mixture
Regression formulation that is typically used approaches for learning HRI from
demonstrations such as using an HMM/GMM for learning a joint distribution over
the actions of the human and the robot. We further incorporate an additional
regularization to prevent ""mode collapse"", a common phenomenon when using
latent space mixture models with VAEs. We find that our approach of using an
informative MDN prior from human observations for a VAE generates more accurate
robot motions compared to previous HMM-based or recurrent approaches of
learning shared latent representations, which we validate on various HRI
datasets involving interactions such as handshakes, fistbumps, waving, and
handovers. Further experiments in a real-world human-to-robot handover scenario
show the efficacy of our approach for generating successful interactions with
four different human interaction partners.",2024-07-10,"Vignesh Prasad, Alap Kshirsagar, Dorothea Koert, Ruth Stock-Homburg, Jan Peters, Georgia Chalvatzaki",http://arxiv.org/pdf/2407.07636v2,cs.LG
A Machine Learning and Explainable AI Framework Tailored for Unbalanced Experimental Catalyst Discovery,"The successful application of machine learning (ML) in catalyst design relies
on high-quality and diverse data to ensure effective generalization to novel
compositions, thereby aiding in catalyst discovery. However, due to complex
interactions, catalyst design has long relied on trial-and-error, a costly and
labor-intensive process leading to scarce data that is heavily biased towards
undesired, low-yield catalysts. Despite the rise of ML in this field, most
efforts have not focused on dealing with the challenges presented by such
experimental data. To address these challenges, we introduce a robust machine
learning and explainable AI (XAI) framework to accurately classify the
catalytic yield of various compositions and identify the contributions of
individual components. This framework combines a series of ML practices
designed to handle the scarcity and imbalance of catalyst data. We apply the
framework to classify the yield of various catalyst compositions in oxidative
methane coupling, and use it to evaluate the performance of a range of ML
models: tree-based models, logistic regression, support vector machines, and
neural networks. These experiments demonstrate that the methods used in our
framework lead to a significant improvement in the performance of all but one
of the evaluated models. Additionally, the decision-making process of each ML
model is analyzed by identifying the most important features for predicting
catalyst performance using XAI methods. Our analysis found that XAI methods,
providing class-aware explanations, such as Layer-wise Relevance Propagation,
identified key components that contribute specifically to high-yield catalysts.
These findings align with chemical intuition and existing literature,
reinforcing their validity. We believe that such insights can assist chemists
in the development and identification of novel catalysts with superior
performance.",2024-07-10,"Parastoo Semnani, Mihail Bogojeski, Florian Bley, Zizheng Zhang, Qiong Wu, Thomas Kneib, Jan Herrmann, Christoph Weisser, Florina Patcas, Klaus-Robert Müller",http://arxiv.org/pdf/2407.18935v1,cs.LG
Pessimism Meets Risk: Risk-Sensitive Offline Reinforcement Learning,"We study risk-sensitive reinforcement learning (RL), a crucial field due to
its ability to enhance decision-making in scenarios where it is essential to
manage uncertainty and minimize potential adverse outcomes. Particularly, our
work focuses on applying the entropic risk measure to RL problems. While
existing literature primarily investigates the online setting, there remains a
large gap in understanding how to efficiently derive a near-optimal policy
based on this risk measure using only a pre-collected dataset. We center on the
linear Markov Decision Process (MDP) setting, a well-regarded theoretical
framework that has yet to be examined from a risk-sensitive standpoint. In
response, we introduce two provably sample-efficient algorithms. We begin by
presenting a risk-sensitive pessimistic value iteration algorithm, offering a
tight analysis by leveraging the structure of the risk-sensitive performance
measure. To further improve the obtained bounds, we propose another pessimistic
algorithm that utilizes variance information and reference-advantage
decomposition, effectively improving both the dependence on the space dimension
$d$ and the risk-sensitivity factor. To the best of our knowledge, we obtain
the first provably efficient risk-sensitive offline RL algorithms.",2024-07-10,"Dake Zhang, Boxiang Lyu, Shuang Qiu, Mladen Kolar, Tong Zhang",http://arxiv.org/pdf/2407.07631v1,cs.LG
Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments,"We consider the challenging problem of estimating causal effects from purely
observational data in the bi-directional Mendelian randomization (MR), where
some invalid instruments, as well as unmeasured confounding, usually exist. To
address this problem, most existing methods attempt to find proper valid
instrumental variables (IVs) for the target causal effect by expert knowledge
or by assuming that the causal model is a one-directional MR model. As such, in
this paper, we first theoretically investigate the identification of the
bi-directional MR from observational data. In particular, we provide necessary
and sufficient conditions under which valid IV sets are correctly identified
such that the bi-directional MR model is identifiable, including the causal
directions of a pair of phenotypes (i.e., the treatment and outcome). Moreover,
based on the identification theory, we develop a cluster fusion-like method to
discover valid IV sets and estimate the causal effects of interest. We
theoretically demonstrate the correctness of the proposed algorithm.
Experimental results show the effectiveness of our method for estimating causal
effects in bi-directional MR.",2024-07-10,"Feng Xie, Zhen Yao, Lin Xie, Yan Zeng, Zhi Geng",http://arxiv.org/pdf/2407.07933v2,cs.LG
Randomness Helps Rigor: A Probabilistic Learning Rate Scheduler Bridging Theory and Deep Learning Practice,"Learning rate schedulers have shown great success in speeding up the
convergence of learning algorithms in practice. However, their convergence to a
minimum has not been proven theoretically. This difficulty mainly arises from
the fact that, while traditional convergence analysis prescribes to
monotonically decreasing (or constant) learning rates, schedulers opt for rates
that often increase and decrease through the training epochs. In this work, we
aim to bridge the gap by proposing a probabilistic learning rate scheduler
(PLRS) that does not conform to the monotonically decreasing condition, with
provable convergence guarantees. To cement the relevance and utility of our
work in modern day applications, we show experimental results on deep neural
network architectures such as ResNet, WRN, VGG, and DenseNet on CIFAR-10,
CIFAR-100, and Tiny ImageNet datasets. We show that PLRS performs as well as or
better than existing state-of-the-art learning rate schedulers in terms of
convergence as well as accuracy. For example, while training ResNet-110 on the
CIFAR-100 dataset, we outperform the state-of-the-art knee scheduler by
$1.56\%$ in terms of classification accuracy. Furthermore, on the Tiny ImageNet
dataset using ResNet-50 architecture, we show a significantly more stable
convergence than the cosine scheduler and a better classification accuracy than
the existing schedulers.",2024-07-10,"Dahlia Devapriya, Thulasi Tholeti, Janani Suresh, Sheetal Kalyani",http://arxiv.org/pdf/2407.07613v2,cs.LG
Teaching Transformers Causal Reasoning through Axiomatic Training,"For text-based AI systems to interact in the real world, causal reasoning is
an essential skill. Since active interventions are costly, we study to what
extent a system can learn causal reasoning from symbolic demonstrations of
causal axioms. Specifically, we present an axiomatic training method where the
system learns from multiple demonstrations of a causal axiom (or rule), rather
than incorporating the axiom as an inductive bias or inferring it from data
values. A key question is whether the system would learn to generalize from the
axiom demonstrations to more complex scenarios. Our results, based on applying
axiomatic training to learn the transitivity axiom and d-separation rule,
indicate that such generalization is possible. To avoid data contamination
issues, we start with a 67 million parameter transformer model and train it
from scratch. On both tasks, we find that a model trained on linear causal
chains (along with some noisy variations) can generalize well to complex
graphs, including longer causal chains, causal chains with reversed order, and
graphs with branching.To handle diverse text inputs, the same method is
extended to finetune language models. Finetuning Llama-3.1 8B model on our
axiomatic data leads to significant gains on causal benchmarks such as
Corr2Cause and CLEAR, in some cases providing state-of-the-art performance
surpassing GPT-4.",2024-07-10,"Aniket Vashishtha, Abhinav Kumar, Atharva Pandey, Abbavaram Gowtham Reddy, Kabir Ahuja, Vineeth N Balasubramanian, Amit Sharma",http://arxiv.org/pdf/2407.07612v2,cs.LG
"Physics-Informed Geometric Operators to Support Surrogate, Dimension Reduction and Generative Models for Engineering Design","In this work, we propose a set of physics-informed geometric operators (GOs)
to enrich the geometric data provided for training surrogate/discriminative
models, dimension reduction, and generative models, typically employed for
performance prediction, dimension reduction, and creating data-driven
parameterisations, respectively. However, as both the input and output streams
of these models consist of low-level shape representations, they often fail to
capture shape characteristics essential for performance analyses. Therefore,
the proposed GOs exploit the differential and integral properties of
shapes--accessed through Fourier descriptors, curvature integrals, geometric
moments, and their invariants--to infuse high-level intrinsic geometric
information and physics into the feature vector used for training, even when
employing simple model architectures or low-level parametric descriptions. We
showed that for surrogate modelling, along with the inclusion of the notion of
physics, GOs enact regularisation to reduce over-fitting and enhance
generalisation to new, unseen designs. Furthermore, through extensive
experimentation, we demonstrate that for dimension reduction and generative
models, incorporating the proposed GOs enriches the training data with compact
global and local geometric features. This significantly enhances the quality of
the resulting latent space, thereby facilitating the generation of valid and
diverse designs. Lastly, we also show that GOs can enable learning parametric
sensitivities to a great extent. Consequently, these enhancements accelerate
the convergence rate of shape optimisers towards optimal solutions.",2024-07-10,"Shahroz Khan, Zahid Masood, Muhammad Usama, Konstantinos Kostas, Panagiotis Kaklis, Wei, Chen",http://arxiv.org/pdf/2407.07611v1,cs.LG
Targeted Augmented Data for Audio Deepfake Detection,"The availability of highly convincing audio deepfake generators highlights
the need for designing robust audio deepfake detectors. Existing works often
rely solely on real and fake data available in the training set, which may lead
to overfitting, thereby reducing the robustness to unseen manipulations. To
enhance the generalization capabilities of audio deepfake detectors, we propose
a novel augmentation method for generating audio pseudo-fakes targeting the
decision boundary of the model. Inspired by adversarial attacks, we perturb
original real data to synthesize pseudo-fakes with ambiguous prediction
probabilities. Comprehensive experiments on two well-known architectures
demonstrate that the proposed augmentation contributes to improving the
generalization capabilities of these architectures.",2024-07-10,"Marcella Astrid, Enjie Ghorbel, Djamila Aouada",http://arxiv.org/pdf/2407.07598v1,cs.LG
Learning treatment effects while treating those in need,"Many social programs attempt to allocate scarce resources to people with the
greatest need. Indeed, public services increasingly use algorithmic risk
assessments motivated by this goal. However, targeting the highest-need
recipients often conflicts with attempting to evaluate the causal effect of the
program as a whole, as the best evaluations would be obtained by randomizing
the allocation. We propose a framework to design randomized allocation rules
which optimally balance targeting high-need individuals with learning treatment
effects, presenting policymakers with a Pareto frontier between the two goals.
We give sample complexity guarantees for the policy learning problem and
provide a computationally efficient strategy to implement it. We then apply our
framework to data from human services in Allegheny County, Pennsylvania.
Optimized policies can substantially mitigate the tradeoff between learning and
targeting. For example, it is often possible to obtain 90% of the optimal
utility in targeting high-need individuals while ensuring that the average
treatment effect can be estimated with less than 2 times the samples that a
randomized controlled trial would require. Mechanisms for targeting public
services often focus on measuring need as accurately as possible. However, our
results suggest that algorithmic systems in public services can be most
impactful if they incorporate program evaluation as an explicit goal alongside
targeting.",2024-07-10,"Bryan Wilder, Pim Welle",http://arxiv.org/pdf/2407.07596v1,cs.LG
Simplifying Source-Free Domain Adaptation for Object Detection: Effective Self-Training Strategies and Performance Insights,"This paper focuses on source-free domain adaptation for object detection in
computer vision. This task is challenging and of great practical interest, due
to the cost of obtaining annotated data sets for every new domain. Recent
research has proposed various solutions for Source-Free Object Detection
(SFOD), most being variations of teacher-student architectures with diverse
feature alignment, regularization and pseudo-label selection strategies. Our
work investigates simpler approaches and their performance compared to more
complex SFOD methods in several adaptation scenarios. We highlight the
importance of batch normalization layers in the detector backbone, and show
that adapting only the batch statistics is a strong baseline for SFOD. We
propose a simple extension of a Mean Teacher with strong-weak augmentation in
the source-free setting, Source-Free Unbiased Teacher (SF-UT), and show that it
actually outperforms most of the previous SFOD methods. Additionally, we
showcase that an even simpler strategy consisting in training on a fixed set of
pseudo-labels can achieve similar performance to the more complex
teacher-student mutual learning, while being computationally efficient and
mitigating the major issue of teacher-student collapse. We conduct experiments
on several adaptation tasks using benchmark driving datasets including
(Foggy)Cityscapes, Sim10k and KITTI, and achieve a notable improvement of 4.7\%
AP50 on Cityscapes$\rightarrow$Foggy-Cityscapes compared with the latest
state-of-the-art in SFOD. Source code is available at
https://github.com/EPFL-IMOS/simple-SFOD.",2024-07-10,"Yan Hao, Florent Forest, Olga Fink",http://arxiv.org/pdf/2407.07586v1,cs.LG
Resource Allocation for Twin Maintenance and Computing Task Processing in Digital Twin Vehicular Edge Computing Network,"As a promising technology, vehicular edge computing (VEC) can provide
computing and caching services by deploying VEC servers near vehicles. However,
VEC networks still face challenges such as high vehicle mobility. Digital twin
(DT), an emerging technology, can predict, estimate, and analyze real-time
states by digitally modeling objects in the physical world. By integrating DT
with VEC, a virtual vehicle DT can be created in the VEC server to monitor the
real-time operating status of vehicles. However, maintaining the vehicle DT
model requires ongoing attention from the VEC server, which also needs to offer
computing services for the vehicles. Therefore, effective allocation and
scheduling of VEC server resources are crucial. This study focuses on a general
VEC network with a single VEC service and multiple vehicles, examining the two
types of delays caused by twin maintenance and computational processing within
the network. By transforming the problem using satisfaction functions, we
propose an optimization problem aimed at maximizing each vehicle's resource
utility to determine the optimal resource allocation strategy. Given the
non-convex nature of the issue, we employ multi-agent Markov decision processes
to reformulate the problem. Subsequently, we propose the twin maintenance and
computing task processing resource collaborative scheduling (MADRL-CSTC)
algorithm, which leverages multi-agent deep reinforcement learning. Through
experimental comparisons with alternative algorithms, it demonstrates that our
proposed approach is effective in terms of resource allocation.",2024-07-10,"Yu Xie, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Jiangzhou Wang, Khaled B. Letaief",http://arxiv.org/pdf/2407.07575v1,cs.LG
Instrumentation and Analysis of Native ML Pipelines via Logical Query Plans,"Machine Learning (ML) is increasingly used to automate impactful decisions,
which leads to concerns regarding their correctness, reliability, and fairness.
We envision highly-automated software platforms to assist data scientists with
developing, validating, monitoring, and analysing their ML pipelines. In
contrast to existing work, our key idea is to extract ""logical query plans""
from ML pipeline code relying on popular libraries. Based on these plans, we
automatically infer pipeline semantics and instrument and rewrite the ML
pipelines to enable diverse use cases without requiring data scientists to
manually annotate or rewrite their code.
  First, we developed such an abstract ML pipeline representation together with
machinery to extract it from Python code. Next, we used this representation to
efficiently instrument static ML pipelines and apply provenance tracking, which
enables lightweight screening for common data preparation issues. Finally, we
built machinery to automatically rewrite ML pipelines to perform more advanced
what-if analyses and proposed using multi-query optimisation for the resulting
workloads. In future work, we aim to interactively assist data scientists as
they work on their ML pipelines.",2024-07-10,Stefan Grafberger,http://arxiv.org/pdf/2407.07560v1,cs.LG
Was it Slander? Towards Exact Inversion of Generative Language Models,"Training large language models (LLMs) requires a substantial investment of
time and money. To get a good return on investment, the developers spend
considerable effort ensuring that the model never produces harmful and
offensive outputs. However, bad-faith actors may still try to slander the
reputation of an LLM by publicly reporting a forged output. In this paper, we
show that defending against such slander attacks requires reconstructing the
input of the forged output or proving that it does not exist. To do so, we
propose and evaluate a search based approach for targeted adversarial attacks
for LLMs. Our experiments show that we are rarely able to reconstruct the exact
input of an arbitrary output, thus demonstrating that LLMs are still vulnerable
to slander attacks.",2024-07-10,"Adrians Skapars, Edoardo Manino, Youcheng Sun, Lucas C. Cordeiro",http://arxiv.org/pdf/2407.11059v1,cs.LG
Machine Unlearning for Medical Imaging,"Machine unlearning is the process of removing the impact of a particular set
of training samples from a pretrained model. It aims to fulfill the ""right to
be forgotten"", which grants the individuals such as patients the right to
reconsider their contribution in models including medical imaging models. In
this study, we evaluate the effectiveness (performance) and computational
efficiency of different unlearning algorithms in medical imaging domain. Our
evaluations demonstrate that the considered unlearning algorithms perform well
on the retain set (samples whose influence on the model is allowed to be
retained) and forget set (samples whose contribution to the model should be
eliminated), and show no bias against male or female samples. They, however,
adversely impact the generalization of the model, especially for larger forget
set sizes. Moreover, they might be biased against easy or hard samples, and
need additional computational overhead for hyper-parameter tuning. In
conclusion, machine unlearning seems promising for medical imaging, but the
existing unlearning algorithms still needs further improvements to become more
practical for medical applications.",2024-07-10,"Reza Nasirigerdeh, Nader Razmi, Julia A. Schnabel, Daniel Rueckert, Georgios Kaissis",http://arxiv.org/pdf/2407.07539v1,cs.LG
How Aligned are Different Alignment Metrics?,"In recent years, various methods and benchmarks have been proposed to
empirically evaluate the alignment of artificial neural networks to human
neural and behavioral data. But how aligned are different alignment metrics? To
answer this question, we analyze visual data from Brain-Score (Schrimpf et al.,
2018), including metrics from the model-vs-human toolbox (Geirhos et al.,
2021), together with human feature alignment (Linsley et al., 2018; Fel et al.,
2022) and human similarity judgements (Muttenthaler et al., 2022). We find that
pairwise correlations between neural scores and behavioral scores are quite low
and sometimes even negative. For instance, the average correlation between
those 80 models on Brain-Score that were fully evaluated on all 69 alignment
metrics we considered is only 0.198. Assuming that all of the employed metrics
are sound, this implies that alignment with human perception may best be
thought of as a multidimensional concept, with different methods measuring
fundamentally different aspects. Our results underline the importance of
integrative benchmarking, but also raise questions about how to correctly
combine and aggregate individual metrics. Aggregating by taking the arithmetic
average, as done in Brain-Score, leads to the overall performance currently
being dominated by behavior (95.25% explained variance) while the neural
predictivity plays a less important role (only 33.33% explained variance). As a
first step towards making sure that different alignment metrics all contribute
fairly towards an integrative benchmark score, we therefore conclude by
comparing three different aggregation options.",2024-07-10,"Jannis Ahlert, Thomas Klein, Felix Wichmann, Robert Geirhos",http://arxiv.org/pdf/2407.07530v1,cs.LG
MLRS-PDS: A Meta-learning recommendation of dynamic ensemble selection pipelines,"Dynamic Selection (DS), where base classifiers are chosen from a classifier's
pool for each new instance at test time, has shown to be highly effective in
pattern recognition. However, instability and redundancy in the classifier
pools can impede computational efficiency and accuracy in dynamic ensemble
selection. This paper introduces a meta-learning recommendation system (MLRS)
to recommend the optimal pool generation scheme for DES methods tailored to
individual datasets. The system employs a meta-model built from dataset
meta-features to predict the most suitable pool generation scheme and DES
method for a given dataset. Through an extensive experimental study
encompassing 288 datasets, we demonstrate that this meta-learning
recommendation system outperforms traditional fixed pool or DES method
selection strategies, highlighting the efficacy of a meta-learning approach in
refining DES method selection. The source code, datasets, and supplementary
results can be found in this project's GitHub repository:
https://github.com/Menelau/MLRS-PDS.",2024-07-10,"Hesam Jalalian, Rafael M. O. Cruz",http://arxiv.org/pdf/2407.07528v1,cs.LG
CHILLI: A data context-aware perturbation method for XAI,"The trustworthiness of Machine Learning (ML) models can be difficult to
assess, but is critical in high-risk or ethically sensitive applications. Many
models are treated as a `black-box' where the reasoning or criteria for a final
decision is opaque to the user. To address this, some existing Explainable AI
(XAI) approaches approximate model behaviour using perturbed data. However,
such methods have been criticised for ignoring feature dependencies, with
explanations being based on potentially unrealistic data. We propose a novel
framework, CHILLI, for incorporating data context into XAI by generating
contextually aware perturbations, which are faithful to the training data of
the base model being explained. This is shown to improve both the soundness and
accuracy of the explanations.",2024-07-10,"Saif Anwar, Nathan Griffiths, Abhir Bhalerao, Thomas Popham",http://arxiv.org/pdf/2407.07521v1,cs.LG
Fine-Grained Classification for Poisonous Fungi Identification with Transfer Learning,"FungiCLEF 2024 addresses the fine-grained visual categorization (FGVC) of
fungi species, with a focus on identifying poisonous species. This task is
challenging due to the size and class imbalance of the dataset, subtle
inter-class variations, and significant intra-class variability amongst
samples. In this paper, we document our approach in tackling this challenge
through the use of ensemble classifier heads on pre-computed image embeddings.
Our team (DS@GT) demonstrate that state-of-the-art self-supervised vision
models can be utilized as robust feature extractors for downstream application
of computer vision tasks without the need for task-specific fine-tuning on the
vision backbone. Our approach achieved the best Track 3 score (0.345), accuracy
(78.4%) and macro-F1 (0.577) on the private test set in post competition
evaluation. Our code is available at
https://github.com/dsgt-kaggle-clef/fungiclef-2024.",2024-07-10,"Christopher Chiu, Maximilian Heil, Teresa Kim, Anthony Miyaguchi",http://arxiv.org/pdf/2407.07492v1,cs.LG
Rigorous Probabilistic Guarantees for Robust Counterfactual Explanations,"We study the problem of assessing the robustness of counterfactual
explanations for deep learning models. We focus on $\textit{plausible model
shifts}$ altering model parameters and propose a novel framework to reason
about the robustness property in this setting. To motivate our solution, we
begin by showing for the first time that computing the robustness of
counterfactuals with respect to plausible model shifts is NP-complete. As this
(practically) rules out the existence of scalable algorithms for exactly
computing robustness, we propose a novel probabilistic approach which is able
to provide tight estimates of robustness with strong guarantees while
preserving scalability. Remarkably, and differently from existing solutions
targeting plausible model shifts, our approach does not impose requirements on
the network to be analyzed, thus enabling robustness analysis on a wider range
of architectures. Experiments on four binary classification datasets indicate
that our method improves the state of the art in generating robust
explanations, outperforming existing methods on a range of metrics.",2024-07-10,"Luca Marzari, Francesco Leofante, Ferdinando Cicalese, Alessandro Farinelli",http://arxiv.org/pdf/2407.07482v1,cs.LG
SPIN: SE(3)-Invariant Physics Informed Network for Binding Affinity Prediction,"Accurate prediction of protein-ligand binding affinity is crucial for rapid
and efficient drug development. Recently, the importance of predicting binding
affinity has led to increased attention on research that models the
three-dimensional structure of protein-ligand complexes using graph neural
networks to predict binding affinity. However, traditional methods often fail
to accurately model the complex's spatial information or rely solely on
geometric features, neglecting the principles of protein-ligand binding. This
can lead to overfitting, resulting in models that perform poorly on independent
datasets and ultimately reducing their usefulness in real drug development. To
address this issue, we propose SPIN, a model designed to achieve superior
generalization by incorporating various inductive biases applicable to this
task, beyond merely training on empirical data from datasets. For prediction,
we defined two types of inductive biases: a geometric perspective that
maintains consistent binding affinity predictions regardless of the complexs
rotations and translations, and a physicochemical perspective that necessitates
minimal binding free energy along their reaction coordinate for effective
protein-ligand binding. These prior knowledge inputs enable the SPIN to
outperform comparative models in benchmark sets such as CASF-2016 and CSAR HiQ.
Furthermore, we demonstrated the practicality of our model through virtual
screening experiments and validated the reliability and potential of our
proposed model based on experiments assessing its interpretability.",2024-07-10,"Seungyeon Choi, Sangmin Seo, Sanghyun Park",http://arxiv.org/pdf/2407.11057v1,cs.LG
Dynamic Encoder Size Based on Data-Driven Layer-wise Pruning for Speech Recognition,"Varying-size models are often required to deploy ASR systems under different
hardware and/or application constraints such as memory and latency. To avoid
redundant training and optimization efforts for individual models of different
sizes, we present the dynamic encoder size approach, which jointly trains
multiple performant models within one supernet from scratch. These subnets of
various sizes are layer-wise pruned from the supernet, and thus, enjoy full
parameter sharing. By combining score-based pruning with supernet training, we
propose two novel methods, Simple-Top-k and Iterative-Zero-Out, to
automatically select the best-performing subnets in a data-driven manner,
avoiding resource-intensive search efforts. Our experiments using CTC on both
Librispeech and TED-LIUM-v2 corpora show that our methods can achieve on-par
performance as individually trained models of each size category. Also, our
approach consistently brings small performance improvements for the full-size
supernet.",2024-07-10,"Jingjing Xu, Wei Zhou, Zijian Yang, Eugen Beck, Ralf Schlueter",http://arxiv.org/pdf/2407.18930v1,cs.LG
MAN TruckScenes: A multimodal dataset for autonomous trucking in diverse conditions,"Autonomous trucking is a promising technology that can greatly impact modern
logistics and the environment. Ensuring its safety on public roads is one of
the main duties that requires an accurate perception of the environment. To
achieve this, machine learning methods rely on large datasets, but to this day,
no such datasets are available for autonomous trucks. In this work, we present
MAN TruckScenes, the first multimodal dataset for autonomous trucking. MAN
TruckScenes allows the research community to come into contact with
truck-specific challenges, such as trailer occlusions, novel sensor
perspectives, and terminal environments for the first time. It comprises more
than 740 scenes of 20s each within a multitude of different environmental
conditions. The sensor set includes 4 cameras, 6 lidar, 6 radar sensors, 2
IMUs, and a high-precision GNSS. The dataset's 3D bounding boxes were manually
annotated and carefully reviewed to achieve a high quality standard. Bounding
boxes are available for 27 object classes, 15 attributes, and a range of more
than 230m. The scenes are tagged according to 34 distinct scene tags, and all
objects are tracked throughout the scene to promote a wide range of
applications. Additionally, MAN TruckScenes is the first dataset to provide 4D
radar data with 360{\deg} coverage and is thereby the largest radar dataset
with annotated 3D bounding boxes. Finally, we provide extensive dataset
analysis and baseline results. The dataset, development kit, and more are
available online.",2024-07-10,"Felix Fent, Fabian Kuttenreich, Florian Ruch, Farija Rizwin, Stefan Juergens, Lorenz Lechermann, Christian Nissler, Andrea Perl, Ulrich Voll, Min Yan, Markus Lienkamp",http://arxiv.org/pdf/2407.07462v2,cs.LG
Machine Learning Assisted Design of mmWave Wireless Transceiver Circuits,"As fifth-generation (5G) and upcoming sixth-generation (6G) communications
exhibit tremendous demands in providing high data throughput with a relatively
low latency, millimeter-wave (mmWave) technologies manifest themselves as the
key enabling components to achieve the envisioned performance and tasks. In
this context, mmWave integrated circuits (IC) have attracted significant
research interests over the past few decades, ranging from individual block
design to complex system design. However, the highly nonlinear properties and
intricate trade-offs involved render the design of analog or RF circuits a
complicated process. The rapid evolution of fabrication technology also results
in an increasingly long time allocated in the design process due to more
stringent requirements. In this thesis, 28-GHz transceiver circuits are first
investigated with detailed schematics and associated performance metrics. In
this case, two target systems comprising heterogeneous individual blocks are
selected and demonstrated on both the transmitter and receiver sides.
Subsequently, some conventional and large-scale machine learning (ML)
approaches are integrated into the design pipeline of the chosen systems to
predict circuit parameters based on desired specifications, thereby
circumventing the typical time-consuming iterations found in traditional
methods. Finally, some potential research directions are discussed from the
perspectives of circuit design and ML algorithms.",2024-07-10,Xuzhe Zhao,http://arxiv.org/pdf/2407.07458v1,cs.LG
GLBench: A Comprehensive Benchmark for Graph with Large Language Models,"The emergence of large language models (LLMs) has revolutionized the way we
interact with graphs, leading to a new paradigm called GraphLLM. Despite the
rapid development of GraphLLM methods in recent years, the progress and
understanding of this field remain unclear due to the lack of a benchmark with
consistent experimental protocols. To bridge this gap, we introduce GLBench,
the first comprehensive benchmark for evaluating GraphLLM methods in both
supervised and zero-shot scenarios. GLBench provides a fair and thorough
evaluation of different categories of GraphLLM methods, along with traditional
baselines such as graph neural networks. Through extensive experiments on a
collection of real-world datasets with consistent data processing and splitting
strategies, we have uncovered several key findings. Firstly, GraphLLM methods
outperform traditional baselines in supervised settings, with LLM-as-enhancers
showing the most robust performance. However, using LLMs as predictors is less
effective and often leads to uncontrollable output issues. We also notice that
no clear scaling laws exist for current GraphLLM methods. In addition, both
structures and semantics are crucial for effective zero-shot transfer, and our
proposed simple baseline can even outperform several models tailored for
zero-shot scenarios. The data and code of the benchmark can be found at
https://github.com/NineAbyss/GLBench.",2024-07-10,"Yuhan Li, Peisong Wang, Xiao Zhu, Aochuan Chen, Haiyun Jiang, Deng Cai, Victor Wai Kin Chan, Jia Li",http://arxiv.org/pdf/2407.07457v4,cs.LG
CM-DQN: A Value-Based Deep Reinforcement Learning Model to Simulate Confirmation Bias,"In human decision-making tasks, individuals learn through trials and
prediction errors. When individuals learn the task, some are more influenced by
good outcomes, while others weigh bad outcomes more heavily. Such confirmation
bias can lead to different learning effects. In this study, we propose a new
algorithm in Deep Reinforcement Learning, CM-DQN, which applies the idea of
different update strategies for positive or negative prediction errors, to
simulate the human decision-making process when the task's states are
continuous while the actions are discrete. We test in Lunar Lander environment
with confirmatory, disconfirmatory bias and non-biased to observe the learning
effects. Moreover, we apply the confirmation model in a multi-armed bandit
problem (environment in discrete states and discrete actions), which utilizes
the same idea as our proposed algorithm, as a contrast experiment to
algorithmically simulate the impact of different confirmation bias in
decision-making process. In both experiments, confirmatory bias indicates a
better learning effect.",2024-07-10,"Jiacheng Shen, Lihan Feng",http://arxiv.org/pdf/2407.07454v3,cs.LG
Using Low-Discrepancy Points for Data Compression in Machine Learning: An Experimental Comparison,"Low-discrepancy points (also called Quasi-Monte Carlo points) are
deterministically and cleverly chosen point sets in the unit cube, which
provide an approximation of the uniform distribution. We explore two methods
based on such low-discrepancy points to reduce large data sets in order to
train neural networks. The first one is the method of Dick and Feischl [4],
which relies on digital nets and an averaging procedure. Motivated by our
experimental findings, we construct a second method, which again uses digital
nets, but Voronoi clustering instead of averaging. Both methods are compared to
the supercompress approach of [14], which is a variant of the K-means
clustering algorithm. The comparison is done in terms of the compression error
for different objective functions and the accuracy of the training of a neural
network.",2024-07-10,"Simone Göttlich, Jacob Heieck, Andreas Neuenkirch",http://arxiv.org/pdf/2407.07450v2,cs.LG
Industrial-Grade Time-Dependent Counterfactual Root Cause Analysis through the Unanticipated Point of Incipient Failure: a Proof of Concept,"This paper describes the development of a counterfactual Root Cause Analysis
diagnosis approach for an industrial multivariate time series environment. It
drives the attention toward the Point of Incipient Failure, which is the moment
in time when the anomalous behavior is first observed, and where the root cause
is assumed to be found before the issue propagates. The paper presents the
elementary but essential concepts of the solution and illustrates them
experimentally on a simulated setting. Finally, it discusses avenues of
improvement for the maturity of the causal technology to meet the robustness
challenges of increasingly complex environments in the industry.",2024-07-10,"Alexandre Trilla, Rajesh Rajendran, Ossee Yiboe, Quentin Possamaï, Nenad Mijatovic, Jordi Vitrià",http://arxiv.org/pdf/2407.11056v1,cs.LG
Federated PCA on Grassmann Manifold for IoT Anomaly Detection,"With the proliferation of the Internet of Things (IoT) and the rising
interconnectedness of devices, network security faces significant challenges,
especially from anomalous activities. While traditional machine learning-based
intrusion detection systems (ML-IDS) effectively employ supervised learning
methods, they possess limitations such as the requirement for labeled data and
challenges with high dimensionality. Recent unsupervised ML-IDS approaches such
as AutoEncoders and Generative Adversarial Networks (GAN) offer alternative
solutions but pose challenges in deployment onto resource-constrained IoT
devices and in interpretability. To address these concerns, this paper proposes
a novel federated unsupervised anomaly detection framework, FedPCA, that
leverages Principal Component Analysis (PCA) and the Alternating Directions
Method Multipliers (ADMM) to learn common representations of distributed
non-i.i.d. datasets. Building on the FedPCA framework, we propose two
algorithms, FEDPE in Euclidean space and FEDPG on Grassmann manifolds. Our
approach enables real-time threat detection and mitigation at the device level,
enhancing network resilience while ensuring privacy. Moreover, the proposed
algorithms are accompanied by theoretical convergence rates even under a
subsampling scheme, a novel result. Experimental results on the UNSW-NB15 and
TON-IoT datasets show that our proposed methods offer performance in anomaly
detection comparable to nonlinear baselines, while providing significant
improvements in communication and memory efficiency, underscoring their
potential for securing IoT networks.",2024-07-10,"Tung-Anh Nguyen, Long Tan Le, Tuan Dung Nguyen, Wei Bao, Suranga Seneviratne, Choong Seon Hong, Nguyen H. Tran",http://arxiv.org/pdf/2407.07421v1,cs.LG
"Search, Examine and Early-Termination: Fake News Detection with Annotation-Free Evidences","Pioneer researches recognize evidences as crucial elements in fake news
detection apart from patterns. Existing evidence-aware methods either require
laborious pre-processing procedures to assure relevant and high-quality
evidence data, or incorporate the entire spectrum of available evidences in all
news cases, regardless of the quality and quantity of the retrieved data. In
this paper, we propose an approach named \textbf{SEE} that retrieves useful
information from web-searched annotation-free evidences with an
early-termination mechanism. The proposed SEE is constructed by three main
phases: \textbf{S}earching online materials using the news as a query and
directly using their titles as evidences without any annotating or filtering
procedure, sequentially \textbf{E}xamining the news alongside with each piece
of evidence via attention mechanisms to produce new hidden states with
retrieved information, and allowing \textbf{E}arly-termination within the
examining loop by assessing whether there is adequate confidence for producing
a correct prediction. We have conducted extensive experiments on datasets with
unprocessed evidences, i.e., Weibo21, GossipCop, and pre-processed evidences,
namely Snopes and PolitiFact. The experimental results demonstrate that the
proposed method outperforms state-of-the-art approaches.",2024-07-10,"Yuzhou Yang, Yangming Zhou, Qichao Ying, Zhenxing Qian, Xinpeng Zhang",http://arxiv.org/pdf/2407.07931v1,cs.LG
Token-Mol 1.0: Tokenized drug design with large language model,"Significant interests have recently risen in leveraging sequence-based large
language models (LLMs) for drug design. However, most current applications of
LLMs in drug discovery lack the ability to comprehend three-dimensional (3D)
structures, thereby limiting their effectiveness in tasks that explicitly
involve molecular conformations. In this study, we introduced Token-Mol, a
token-only 3D drug design model. This model encodes all molecular information,
including 2D and 3D structures, as well as molecular property data, into
tokens, which transforms classification and regression tasks in drug discovery
into probabilistic prediction problems, thereby enabling learning through a
unified paradigm. Token-Mol is built on the transformer decoder architecture
and trained using random causal masking techniques. Additionally, we proposed
the Gaussian cross-entropy (GCE) loss function to overcome the challenges in
regression tasks, significantly enhancing the capacity of LLMs to learn
continuous numerical values. Through a combination of fine-tuning and
reinforcement learning (RL), Token-Mol achieves performance comparable to or
surpassing existing task-specific methods across various downstream tasks,
including pocket-based molecular generation, conformation generation, and
molecular property prediction. Compared to existing molecular pre-trained
models, Token-Mol exhibits superior proficiency in handling a wider range of
downstream tasks essential for drug design. Notably, our approach improves
regression task accuracy by approximately 30% compared to similar token-only
methods. Token-Mol overcomes the precision limitations of token-only models and
has the potential to integrate seamlessly with general models such as ChatGPT,
paving the way for the development of a universal artificial intelligence drug
design model that facilitates rapid and high-quality drug design by experts.",2024-07-10,"Jike Wang, Rui Qin, Mingyang Wang, Meijing Fang, Yangyang Zhang, Yuchen Zhu, Qun Su, Qiaolin Gou, Chao Shen, Odin Zhang, Zhenxing Wu, Dejun Jiang, Xujun Zhang, Huifeng Zhao, Xiaozhe Wan, Zhourui Wu, Liwei Liu, Yu Kang, Chang-Yu Hsieh, Tingjun Hou",http://arxiv.org/pdf/2407.07930v2,cs.LG
Mutual Information calculation on different appearances,"Mutual information has many applications in image alignment and matching,
mainly due to its ability to measure the statistical dependence between two
images, even if the two images are from different modalities (e.g., CT and
MRI). It considers not only the pixel intensities of the images but also the
spatial relationships between the pixels. In this project, we apply the mutual
information formula to image matching, where image A is the moving object and
image B is the target object and calculate the mutual information between them
to evaluate the similarity between the images. For comparison, we also used
entropy and information-gain methods to test the dependency of the images. We
also investigated the effect of different environments on the mutual
information of the same image and used experiments and plots to demonstrate.",2024-07-10,"Jiecheng Liao, Junhao Lu, Jeff Ji, Jiacheng He",http://arxiv.org/pdf/2407.07410v1,cs.LG
"Gumbel-Softmax Discretization Constraint, Differentiable IDS Channel, and an IDS-Correcting Code for DNA Storage","Insertion, deletion, and substitution (IDS) error-correcting codes have
garnered increased attention with recent advancements in DNA storage
technology. However, a universal method for designing IDS-correcting codes
across varying channel settings remains underexplored. We present an
autoencoder-based method, THEA-code, aimed at efficiently generating
IDS-correcting codes for complex IDS channels. In the work, a Gumbel-Softmax
discretization constraint is proposed to discretize the features of the
autoencoder, and a simulated differentiable IDS channel is developed as a
differentiable alternative for IDS operations. These innovations facilitate the
successful convergence of the autoencoder, resulting in channel-customized
IDS-correcting codes with commendable performance across complex IDS channels.",2024-07-10,"Alan J. X. Guo, Mengyi Wei, Yufan Dai, Yali Wei, Pengchen Zhang",http://arxiv.org/pdf/2407.18929v3,cs.LG
Malicious Path Manipulations via Exploitation of Representation Vulnerabilities of Vision-Language Navigation Systems,"Building on the unprecedented capabilities of large language models for
command understanding and zero-shot recognition of multi-modal vision-language
transformers, visual language navigation (VLN) has emerged as an effective way
to address multiple fundamental challenges toward a natural language interface
to robot navigation. However, such vision-language models are inherently
vulnerable due to the lack of semantic meaning of the underlying embedding
space. Using a recently developed gradient based optimization procedure, we
demonstrate that images can be modified imperceptibly to match the
representation of totally different images and unrelated texts for a
vision-language model. Building on this, we develop algorithms that can
adversarially modify a minimal number of images so that the robot will follow a
route of choice for commands that require a number of landmarks. We demonstrate
that experimentally using a recently proposed VLN system; for a given
navigation command, a robot can be made to follow drastically different routes.
We also develop an efficient algorithm to detect such malicious modifications
reliably based on the fact that the adversarially modified images have much
higher sensitivity to added Gaussian noise than the original images.",2024-07-10,"Chashi Mahiul Islam, Shaeke Salman, Montasir Shams, Xiuwen Liu, Piyush Kumar",http://arxiv.org/pdf/2407.07392v1,cs.LG
Deep(er) Reconstruction of Imaging Cherenkov Detectors with Swin Transformers and Normalizing Flow Models,"Imaging Cherenkov detectors are crucial for particle identification (PID) in
nuclear and particle physics experiments. Fast reconstruction algorithms are
essential for near real-time alignment, calibration, data quality control, and
efficient analysis. At the future Electron-Ion Collider (EIC), the ePIC
detector will feature a dual Ring Imaging Cherenkov (dual-RICH) detector in the
hadron direction, a Detector of Internally Reflected Cherenkov (DIRC) in the
barrel, and a proximity focus RICH in the electron direction. This paper
focuses on the DIRC detector, which presents complex hit patterns and is also
used for PID of pions and kaons in the GlueX experiment at JLab. We present
Deep(er)RICH, an extension of the seminal DeepRICH work, offering improved and
faster PID compared to traditional methods and, for the first time, fast and
accurate simulation. This advancement addresses a major bottleneck in Cherenkov
detector simulations involving photon tracking through complex optical
elements. Our results leverage advancements in Vision Transformers,
specifically hierarchical Swin Transformer and normalizing flows. These methods
enable direct learning from real data and the reconstruction of complex
topologies. We conclude by discussing the implications and future extensions of
this work, which can offer capabilities for PID for multiple cutting-edge
experiments like the future EIC.",2024-07-10,"Cristiano Fanelli, James Giroux, Justin Stevens",http://arxiv.org/pdf/2407.07376v1,cs.LG
Automatic Extraction of Disease Risk Factors from Medical Publications,"We present a novel approach to automating the identification of risk factors
for diseases from medical literature, leveraging pre-trained models in the
bio-medical domain, while tuning them for the specific task. Faced with the
challenges of the diverse and unstructured nature of medical articles, our
study introduces a multi-step system to first identify relevant articles, then
classify them based on the presence of risk factor discussions and, finally,
extract specific risk factor information for a disease through a
question-answering model.
  Our contributions include the development of a comprehensive pipeline for the
automated extraction of risk factors and the compilation of several datasets,
which can serve as valuable resources for further research in this area. These
datasets encompass a wide range of diseases, as well as their associated risk
factors, meticulously identified and validated through a fine-grained
evaluation scheme. We conducted both automatic and thorough manual evaluation,
demonstrating encouraging results. We also highlight the importance of
improving models and expanding dataset comprehensiveness to keep pace with the
rapidly evolving field of medical research.",2024-07-10,"Maxim Rubchinsky, Ella Rabinovich, Adi Shraibman, Netanel Golan, Tali Sahar, Dorit Shweiki",http://arxiv.org/pdf/2407.07373v1,cs.LG
Semi-Supervised Model-Free Bayesian State Estimation from Compressed Measurements,"We consider data-driven Bayesian state estimation from compressed
measurements (BSCM) of a model-free process. The dimension of the temporal
measurement vector is lower than that of the temporal state vector to be
estimated, leading to an under-determined inverse problem. The underlying
dynamical model of the state's evolution is unknown for a 'model-free process.'
Hence, it is difficult to use traditional model-driven methods, for example,
Kalman and particle filters. Instead, we consider data-driven methods. We
experimentally show that two existing unsupervised learning-based data-driven
methods fail to address the BSCM problem in a model-free process. The methods
are -- data-driven nonlinear state estimation (DANSE) and deep Markov model
(DMM). While DANSE provides good predictive/forecasting performance to model
the temporal measurement data as a time series, its unsupervised learning lacks
suitable regularization for tackling the BSCM task. We then propose a
semi-supervised learning approach and develop a semi-supervised learning-based
DANSE method, referred to as SemiDANSE. In SemiDANSE, we use a large amount of
unlabelled data along with a limited amount of labelled data, i.e., pairwise
measurement-and-state data, which provides the desired regularization. Using
three benchmark dynamical systems, we empirically show that the data-driven
SemiDANSE provides competitive state estimation performance for BSCM using a
handful of different measurement systems, against a hybrid method called
KalmanNet and two model-driven methods (extended Kalman filter and unscented
Kalman filter) that know the dynamical models exactly.",2024-07-10,"Anubhab Ghosh, Yonina C. Eldar, Saikat Chatterjee",http://arxiv.org/pdf/2407.07368v5,cs.LG
Real-time system optimal traffic routing under uncertainties -- Can physics models boost reinforcement learning?,"System optimal traffic routing can mitigate congestion by assigning routes
for a portion of vehicles so that the total travel time of all vehicles in the
transportation system can be reduced. However, achieving real-time optimal
routing poses challenges due to uncertain demands and unknown system dynamics,
particularly in expansive transportation networks. While physics model-based
methods are sensitive to uncertainties and model mismatches, model-free
reinforcement learning struggles with learning inefficiencies and
interpretability issues. Our paper presents TransRL, a novel algorithm that
integrates reinforcement learning with physics models for enhanced performance,
reliability, and interpretability. TransRL begins by establishing a
deterministic policy grounded in physics models, from which it learns from and
is guided by a differentiable and stochastic teacher policy. During training,
TransRL aims to maximize cumulative rewards while minimizing the Kullback
Leibler (KL) divergence between the current policy and the teacher policy. This
approach enables TransRL to simultaneously leverage interactions with the
environment and insights from physics models. We conduct experiments on three
transportation networks with up to hundreds of links. The results demonstrate
TransRL's superiority over traffic model-based methods for being adaptive and
learning from the actual network data. By leveraging the information from
physics models, TransRL consistently outperforms state-of-the-art reinforcement
learning algorithms such as proximal policy optimization (PPO) and soft actor
critic (SAC). Moreover, TransRL's actions exhibit higher reliability and
interpretability compared to baseline reinforcement learning approaches like
PPO and SAC.",2024-07-10,"Zemian Ke, Qiling Zou, Jiachao Liu, Sean Qian",http://arxiv.org/pdf/2407.07364v1,cs.LG
Characterizing Encrypted Application Traffic through Cellular Radio Interface Protocol,"Modern applications are end-to-end encrypted to prevent data from being read
or secretly modified. 5G tech nology provides ubiquitous access to these
applications without compromising the application-specific performance and
latency goals. In this paper, we empirically demonstrate that 5G radio
communication becomes the side channel to precisely infer the user's
applications in real-time. The key idea lies in observing the 5G physical and
MAC layer interactions over time that reveal the application's behavior. The
MAC layer receives the data from the application and requests the network to
assign the radio resource blocks. The network assigns the radio resources as
per application requirements, such as priority, Quality of Service (QoS) needs,
amount of data to be transmitted, and buffer size. The adversary can passively
observe the radio resources to fingerprint the applications. We empirically
demonstrate this attack by considering four different categories of
applications: online shopping, voice/video conferencing, video streaming, and
Over-The-Top (OTT) media platforms. Finally, we have also demonstrated that an
attacker can differentiate various types of applications in real-time within
each category.",2024-07-10,"Md Ruman Islam, Raja Hasnain Anwar, Spyridon Mastorakis, Muhammad Taqi Raza",http://arxiv.org/pdf/2407.07361v2,cs.LG
Towards a text-based quantitative and explainable histopathology image analysis,"Recently, vision-language pre-trained models have emerged in computational
pathology. Previous works generally focused on the alignment of image-text
pairs via the contrastive pre-training paradigm. Such pre-trained models have
been applied to pathology image classification in zero-shot learning or
transfer learning fashion. Herein, we hypothesize that the pre-trained
vision-language models can be utilized for quantitative histopathology image
analysis through a simple image-to-text retrieval. To this end, we propose a
Text-based Quantitative and Explainable histopathology image analysis, which we
call TQx. Given a set of histopathology images, we adopt a pre-trained
vision-language model to retrieve a word-of-interest pool. The retrieved words
are then used to quantify the histopathology images and generate understandable
feature embeddings due to the direct mapping to the text description. To
evaluate the proposed method, the text-based embeddings of four histopathology
image datasets are utilized to perform clustering and classification tasks. The
results demonstrate that TQx is able to quantify and analyze histopathology
images that are comparable to the prevalent visual models in computational
pathology.",2024-07-10,"Anh Tien Nguyen, Trinh Thi Le Vuong, Jin Tae Kwak",http://arxiv.org/pdf/2407.07360v1,cs.LG
SGM-PINN: Sampling Graphical Models for Faster Training of Physics-Informed Neural Networks,"SGM-PINN is a graph-based importance sampling framework to improve the
training efficacy of Physics-Informed Neural Networks (PINNs) on parameterized
problems. By applying a graph decomposition scheme to an undirected
Probabilistic Graphical Model (PGM) built from the training dataset, our method
generates node clusters encoding conditional dependence between training
samples. Biasing sampling towards more important clusters allows smaller
mini-batches and training datasets, improving training speed and accuracy. We
additionally fuse an efficient robustness metric with residual losses to
determine regions requiring additional sampling. Experiments demonstrate the
advantages of the proposed framework, achieving $3\times$ faster convergence
compared to prior state-of-the-art sampling methods.",2024-07-10,"John Anticev, Ali Aghdaei, Wuxinlin Cheng, Zhuo Feng",http://arxiv.org/pdf/2407.07358v1,cs.LG
A deep graph model for the signed interaction prediction in biological network,"Predicting signed interactions in biological networks is crucial for
understanding drug mechanisms and facilitating drug repurposing. While deep
graph models have demonstrated success in modeling complex biological systems,
existing approaches often fail to distinguish between positive and negative
interactions, limiting their utility for precise pharmacological predictions.
In this study, we propose a novel deep graph model, \textbf{RGCNTD} (Relational
Graph Convolutional Network with Tensor Decomposition), designed to predict
both polar (e.g., activation, inhibition) and non-polar (e.g., binding, affect)
chemical-gene interactions. Our model integrates graph convolutional networks
with tensor decomposition to enhance feature representation and incorporates a
conflict-aware sampling strategy to resolve polarity ambiguities. We introduce
new evaluation metrics, \textit{AUC\textsubscript{polarity}} and
\textit{CP@500}, to assess the model's ability to differentiate interaction
types. Experimental results demonstrate that \textbf{RGCNTD} outperforms
baseline models, achieving superior classification accuracy and improved
discrimination of polar edges. Furthermore, we analyze the impact of subgraph
components on predictive performance, revealing that additional network
structures do not always enhance accuracy. These findings highlight the
importance of polarity-aware modeling in drug discovery and network
pharmacology, providing a robust framework for predicting complex biological
interactions.",2024-07-10,"Shuyi Jin, Mengji Zhang, Meijie Wang, Lun Yu",http://arxiv.org/pdf/2407.07357v2,cs.LG
Long-Term Fairness in Sequential Multi-Agent Selection with Positive Reinforcement,"While much of the rapidly growing literature on fair decision-making focuses
on metrics for one-shot decisions, recent work has raised the intriguing
possibility of designing sequential decision-making to positively impact
long-term social fairness. In selection processes such as college admissions or
hiring, biasing slightly towards applicants from under-represented groups is
hypothesized to provide positive feedback that increases the pool of
under-represented applicants in future selection rounds, thus enhancing
fairness in the long term. In this paper, we examine this hypothesis and its
consequences in a setting in which multiple agents are selecting from a common
pool of applicants. We propose the Multi-agent Fair-Greedy policy, that
balances greedy score maximization and fairness. Under this policy, we prove
that the resource pool and the admissions converge to a long-term fairness
target set by the agents when the score distributions across the groups in the
population are identical. We provide empirical evidence of existence of
equilibria under non-identical score distributions through synthetic and
adapted real-world datasets. We then sound a cautionary note for more complex
applicant pool evolution models, under which uncoordinated behavior by the
agents can cause negative reinforcement, leading to a reduction in the fraction
of under-represented applicants. Our results indicate that, while positive
reinforcement is a promising mechanism for long-term fairness, policies must be
designed carefully to be robust to variations in the evolution model, with a
number of open issues that remain to be explored by algorithm designers, social
scientists, and policymakers.",2024-07-10,"Bhagyashree Puranik, Ozgur Guldogan, Upamanyu Madhow, Ramtin Pedarsani",http://arxiv.org/pdf/2407.07350v1,cs.LG
INSIGHT: Universal Neural Simulator for Analog Circuits Harnessing Autoregressive Transformers,"Analog front-end design heavily relies on specialized human expertise and
costly trial-and-error simulations, which motivated many prior works on analog
design automation. However, efficient and effective exploration of the vast and
complex design space remains constrained by the time-consuming nature of SPICE
simulations, making effective design automation a challenging endeavor. In this
paper, we introduce INSIGHT, a GPU-powered, technology-agnostic, effective
universal neural simulator in the analog front-end design automation loop.
INSIGHT accurately predicts the performance metrics of analog circuits across
various technologies with just a few microseconds of inference time. Notably,
its autoregressive capabilities enable INSIGHT to accurately predict
simulation-costly critical transient specifications leveraging less expensive
performance metric information. The low cost and high fidelity feature make
INSIGHT a good substitute for standard simulators in analog front-end
optimization frameworks. INSIGHT is compatible with any optimization framework,
facilitating enhanced design space exploration for sample efficiency through
sophisticated offline learning and adaptation techniques. Our experiments
demonstrate that INSIGHT-M, a model-based batch reinforcement learning sizing
framework with INSIGHT as the accurate surrogate, only requires < 20 real-time
simulations with 100-1000x lower simulation costs and significant speedup over
existing sizing methods.",2024-07-10,"Souradip Poddar, Youngmin Oh, Yao Lai, Hanqing Zhu, Bosun Hwang, David Z. Pan",http://arxiv.org/pdf/2407.07346v3,cs.LG
Towards Complete Causal Explanation with Expert Knowledge,"We study the problem of restricting a Markov equivalence class of maximal
ancestral graphs (MAGs) to only those MAGs that contain certain edge marks,
which we refer to as expert knowledge. Such a restriction of the Markov
equivalence class can be uniquely represented by a restricted essential
ancestral graph. Our contributions are several-fold. First, we prove certain
properties for the entire Markov equivalence class including a conjecture from
Ali et al. (2009). Second, we present several new sound graphical orientation
rules for adding expert knowledge to an essential ancestral graph. We also show
that some orientation rules of Zhang (2008b) are not needed for restricting the
Markov equivalence class with expert knowledge. Third, we provide an algorithm
for including this expert knowledge and show that in certain settings the
output of our algorithm is a restricted essential ancestral graph. Finally,
outside of the specified settings, we provide an algorithm for checking whether
a graph is a restricted essential graph and discuss its runtime. This work can
be seen as a generalization of Meek (1995) to settings which allow for latent
confounding.",2024-07-10,"Aparajithan Venkateswaran, Emilija Perković",http://arxiv.org/pdf/2407.07338v2,cs.LG
Mitigating Partial Observability in Sequential Decision Processes via the Lambda Discrepancy,"Reinforcement learning algorithms typically rely on the assumption that the
environment dynamics and value function can be expressed in terms of a
Markovian state representation. However, when state information is only
partially observable, how can an agent learn such a state representation, and
how can it detect when it has found one? We introduce a metric that can
accomplish both objectives, without requiring access to -- or knowledge of --
an underlying, unobservable state space. Our metric, the $\lambda$-discrepancy,
is the difference between two distinct temporal difference (TD) value
estimates, each computed using TD($\lambda$) with a different value of
$\lambda$. Since TD($\lambda{=}0$) makes an implicit Markov assumption and
TD($\lambda{=}1$) does not, a discrepancy between these estimates is a
potential indicator of a non-Markovian state representation. Indeed, we prove
that the $\lambda$-discrepancy is exactly zero for all Markov decision
processes and almost always non-zero for a broad class of partially observable
environments. We also demonstrate empirically that, once detected, minimizing
the $\lambda$-discrepancy can help with learning a memory function to mitigate
the corresponding partial observability. We then train a reinforcement learning
agent that simultaneously constructs two recurrent value networks with
different $\lambda$ parameters and minimizes the difference between them as an
auxiliary loss. The approach scales to challenging partially observable
domains, where the resulting agent frequently performs significantly better
(and never performs worse) than a baseline recurrent agent with only a single
value network.",2024-07-10,"Cameron Allen, Aaron Kirtland, Ruo Yu Tao, Sam Lobel, Daniel Scott, Nicholas Petrocelli, Omer Gottesman, Ronald Parr, Michael L. Littman, George Konidaris",http://arxiv.org/pdf/2407.07333v3,cs.LG
CATP: Context-Aware Trajectory Prediction with Competition Symbiosis,"Contextual information is vital for accurate trajectory prediction. For
instance, the intricate flying behavior of migratory birds hinges on their
analysis of environmental cues such as wind direction and air pressure.
However, the diverse and dynamic nature of contextual information renders it an
arduous task for AI models to comprehend its impact on trajectories and
consequently predict them accurately. To address this issue, we propose a
``manager-worker'' framework to unleash the full potential of contextual
information and construct CATP model, an implementation of the framework for
Context-Aware Trajectory Prediction. The framework comprises a manager model,
several worker models, and a tailored training mechanism inspired by
competition symbiosis in nature. Taking CATP as an example, each worker needs
to compete against others for training data and develop an advantage in
predicting specific moving patterns. The manager learns the workers'
performance in different contexts and selects the best one in the given context
to predict trajectories, enabling CATP as a whole to operate in a symbiotic
manner. We conducted two comparative experiments and an ablation study to
quantitatively evaluate the proposed framework and CATP model. The results
showed that CATP could outperform SOTA models, and the framework could be
generalized to different context-aware tasks.",2024-07-10,"Jiang Wu, Dongyu Liu, Yuchen Lin, Yingcai Wu",http://arxiv.org/pdf/2407.07328v1,cs.LG
Flow to Rare Events: An Application of Normalizing Flow in Temporal Importance Sampling for Automated Vehicle Validation,"Automated Vehicle (AV) validation based on simulated testing requires
unbiased evaluation and high efficiency. One effective solution is to increase
the exposure to risky rare events while reweighting the probability measure.
However, characterizing the distribution of risky events is particularly
challenging due to the paucity of samples and the temporality of continuous
scenario variables. To solve it, we devise a method to represent, generate, and
reweight the distribution of risky rare events. We decompose the temporal
evolution of continuous variables into distribution components based on
conditional probability. By introducing the Risk Indicator Function, the
distribution of risky rare events is theoretically precipitated out of
naturalistic driving distribution. This targeted distribution is practically
generated via Normalizing Flow, which achieves exact and tractable probability
evaluation of intricate distribution. The rare event distribution is then
demonstrated as the advantageous Importance Sampling distribution. We also
promote the technique of temporal Importance Sampling. The combined method,
named as TrimFlow, is executed to estimate the collision rate of Car-following
scenarios as a tentative practice. The results showed that sampling background
vehicle maneuvers from rare event distribution could evolve testing scenarios
to hazardous states. TrimFlow reduced 86.1% of tests compared to generating
testing scenarios according to their exposure in the naturalistic driving
environment. In addition, the TrimFlow method is not limited to one specific
type of functional scenario.",2024-07-10,"Yichun Ye, He Zhang, Ye Tian, Jian Sun, Karl Meinke",http://arxiv.org/pdf/2407.07320v2,cs.LG
ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting,"Time series forecasting (TSF) possesses great practical values in various
fields, including power and energy, transportation, etc. TSF methods have been
studied based on knowledge from classical statistics to modern deep learning.
Yet, all of them were developed based on one fundamental concept, the numerical
data fitting. Thus, the models developed have been long known for being
problem-specific and lacking application generalizability. A TSF foundation
model serving TSF tasks across different applications can reverse such an
impression. The central question is then how to develop such a TSF foundation
model. This paper offers a pioneering study in developing a TSF foundation
model and proposes a vision intelligence-powered framework, ViTime, for the
first time. In ViTime, a method synthesizing authentic time series periodic and
trend patterns is developed to enrich sample pattern diversity. A deep
architecture operating TSF in image metric space is designed to achieve
significantly enhanced TSF generalizability. Extensive experiments demonstrate
ViTime's SOTA performance across multiple settings. In zero-shot scenarios,
ViTime outperforms TimesFM by 9-15%. With just 10% fine-tuning data, ViTime
surpasses both foundation models and fully-supervised benchmarks trained on
complete datasets, with this performance gap widening further at 100\%
fine-tuning. Additionally, ViTime exhibits exceptional robustness, handling
missing data without imputation and outperforming TimesFM by 20-30% under
various data perturbations.",2024-07-10,"Luoxiao Yang, Yun Wang, Xinqi Fan, Israel Cohen, Jingdong Chen, Yue Zhao, Zijun Zhang",http://arxiv.org/pdf/2407.07311v3,cs.LG
Grounding and Evaluation for Large Language Models: Practical Challenges and Lessons Learned (Survey),"With the ongoing rapid adoption of Artificial Intelligence (AI)-based systems
in high-stakes domains, ensuring the trustworthiness, safety, and observability
of these systems has become crucial. It is essential to evaluate and monitor AI
systems not only for accuracy and quality-related metrics but also for
robustness, bias, security, interpretability, and other responsible AI
dimensions. We focus on large language models (LLMs) and other generative AI
models, which present additional challenges such as hallucinations, harmful and
manipulative content, and copyright infringement. In this survey article
accompanying our KDD 2024 tutorial, we highlight a wide range of harms
associated with generative AI systems, and survey state of the art approaches
(along with open challenges) to address these harms.",2024-07-10,"Krishnaram Kenthapadi, Mehrnoosh Sameki, Ankur Taly",http://arxiv.org/pdf/2407.12858v1,cs.LG
Analyzing Machine Learning Performance in a Hybrid Quantum Computing and HPC Environment,"We explored the possible benefits of integrating quantum simulators in a
""hybrid"" quantum machine learning (QML) workflow that uses both classical and
quantum computations in a high-performance computing (HPC) environment. Here,
we used two Oak Ridge Leadership Computing Facility HPC systems, Andes (a
commodity-type Linux cluster) and Frontier (an HPE Cray EX supercomputer),
along with quantum computing simulators from PennyLane and IBMQ to evaluate a
hybrid QML program -- using a ""ground up"" approach. Using 1 GPU on Frontier, we
found ~56% and ~77% speedups when compared to using Frontier's CPU and a local,
non-HPC system, respectively. Analyzing performance on a larger dataset using
multiple threads, the Frontier GPUs performed ~92% and ~48% faster than the
Andes and Frontier CPUs, respectively. More impressively, this is a ~226%
speedup over a local, non-HPC system's runtime using the same simulator and
number of threads. We hope that this proof of concept will motivate more
intensive hybrid QC/HPC scaling studies in the future.",2024-07-10,"Samuel T. Bieberich, Michael A. Sandoval",http://arxiv.org/pdf/2407.07294v1,cs.LG
Causal Discovery in Semi-Stationary Time Series,"Discovering causal relations from observational time series without making
the stationary assumption is a significant challenge. In practice, this
challenge is common in many areas, such as retail sales, transportation
systems, and medical science. Here, we consider this problem for a class of
non-stationary time series. The structural causal model (SCM) of this type of
time series, called the semi-stationary time series, exhibits that a finite
number of different causal mechanisms occur sequentially and periodically
across time. This model holds considerable practical utility because it can
represent periodicity, including common occurrences such as seasonality and
diurnal variation. We propose a constraint-based, non-parametric algorithm for
discovering causal relations in this setting. The resulting algorithm,
PCMCI$_{\Omega}$, can capture the alternating and recurring changes in the
causal mechanisms and then identify the underlying causal graph with
conditional independence (CI) tests. We show that this algorithm is sound in
identifying causal relations on discrete time series. We validate the algorithm
with extensive experiments on continuous and discrete simulated data. We also
apply our algorithm to a real-world climate dataset.",2024-07-10,"Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu",http://arxiv.org/pdf/2407.07291v1,cs.LG
Causal Discovery-Driven Change Point Detection in Time Series,"Change point detection in time series seeks to identify times when the
probability distribution of time series changes. It is widely applied in many
areas, such as human-activity sensing and medical science. In the context of
multivariate time series, this typically involves examining the joint
distribution of high-dimensional data: If any one variable changes, the whole
time series is assumed to have changed. However, in practical applications, we
may be interested only in certain components of the time series, exploring
abrupt changes in their distributions in the presence of other time series.
Here, assuming an underlying structural causal model that governs the
time-series data generation, we address this problem by proposing a two-stage
non-parametric algorithm that first learns parts of the causal structure
through constraint-based discovery methods. The algorithm then uses conditional
relative Pearson divergence estimation to identify the change points. The
conditional relative Pearson divergence quantifies the distribution disparity
between consecutive segments in the time series, while the causal discovery
method enables a focus on the causal mechanism, facilitating access to
independent and identically distributed (IID) samples. Theoretically, the
typical assumption of samples being IID in conventional change point detection
methods can be relaxed based on the Causal Markov Condition. Through
experiments on both synthetic and real-world datasets, we validate the
correctness and utility of our approach.",2024-07-10,"Shanyun Gao, Raghavendra Addanki, Tong Yu, Ryan A. Rossi, Murat Kocaoglu",http://arxiv.org/pdf/2407.07290v1,cs.LG
Towards a theory of learning dynamics in deep state space models,"State space models (SSMs) have shown remarkable empirical performance on many
long sequence modeling tasks, but a theoretical understanding of these models
is still lacking. In this work, we study the learning dynamics of linear SSMs
to understand how covariance structure in data, latent state size, and
initialization affect the evolution of parameters throughout learning with
gradient descent. We show that focusing on the learning dynamics in the
frequency domain affords analytical solutions under mild assumptions, and we
establish a link between one-dimensional SSMs and the dynamics of deep linear
feed-forward networks. Finally, we analyze how latent state
over-parameterization affects convergence time and describe future work in
extending our results to the study of deep SSMs with nonlinear connections.
This work is a step toward a theory of learning dynamics in deep state space
models.",2024-07-10,"Jakub Smékal, Jimmy T. H. Smith, Michael Kleinman, Dan Biderman, Scott W. Linderman",http://arxiv.org/pdf/2407.07279v1,cs.LG
Lifestyle-Informed Personalized Blood Biomarker Prediction via Novel Representation Learning,"Blood biomarkers are an essential tool for healthcare providers to diagnose,
monitor, and treat a wide range of medical conditions. Current reference values
and recommended ranges often rely on population-level statistics, which may not
adequately account for the influence of inter-individual variability driven by
factors such as lifestyle and genetics. In this work, we introduce a novel
framework for predicting future blood biomarker values and define personalized
references through learned representations from lifestyle data (physical
activity and sleep) and blood biomarkers. Our proposed method learns a
similarity-based embedding space that captures the complex relationship between
biomarkers and lifestyle factors. Using the UK Biobank (257K participants), our
results show that our deep-learned embeddings outperform traditional and
current state-of-the-art representation learning techniques in predicting
clinical diagnosis. Using a subset of UK Biobank of 6440 participants who have
follow-up visits, we validate that the inclusion of these embeddings and
lifestyle factors directly in blood biomarker models improves the prediction of
future lab values from a single lab visit. This personalized modeling approach
provides a foundation for developing more accurate risk stratification tools
and tailoring preventative care strategies. In clinical settings, this
translates to the potential for earlier disease detection, more timely
interventions, and ultimately, a shift towards personalized healthcare.",2024-07-09,"A. Ali Heydari, Naghmeh Rezaei, Javier L. Prieto, Shwetak N. Patel, Ahmed A. Metwally",http://arxiv.org/pdf/2407.07277v1,cs.LG
Predicting 3D Rigid Body Dynamics with Deep Residual Network,"This study investigates the application of deep residual networks for
predicting the dynamics of interacting three-dimensional rigid bodies. We
present a framework combining a 3D physics simulator implemented in C++ with a
deep learning model constructed using PyTorch. The simulator generates training
data encompassing linear and angular motion, elastic collisions, fluid
friction, gravitational effects, and damping. Our deep residual network,
consisting of an input layer, multiple residual blocks, and an output layer, is
designed to handle the complexities of 3D dynamics. We evaluate the network's
performance using a datasetof 10,000 simulated scenarios, each involving 3-5
interacting rigid bodies. The model achieves a mean squared error of 0.015 for
position predictions and 0.022 for orientation predictions, representing a 25%
improvement over baseline methods. Our results demonstrate the network's
ability to capture intricate physical interactions, with particular success in
predicting elastic collisions and rotational dynamics. This work significantly
contributes to physics-informed machine learning by showcasing the immense
potential of deep residual networks in modeling complex 3D physical systems. We
discuss our approach's limitations and propose future directions for improving
generalization to more diverse object shapes and materials.",2024-07-09,Abiodun Finbarrs Oketunji,http://arxiv.org/pdf/2407.18798v1,cs.LG
Remastering Divide and Remaster: A Cinematic Audio Source Separation Dataset with Multilingual Support,"Cinematic audio source separation (CASS), as a problem of extracting the
dialogue, music, and effects stems from their mixture, is a relatively new
subtask of audio source separation. To date, only one publicly available
dataset exists for CASS, that is, the Divide and Remaster (DnR) dataset, which
is currently at version 2. While DnR v2 has been an incredibly useful resource
for CASS, several areas of improvement have been identified, particularly
through its use in the 2023 Sound Demixing Challenge. In this work, we develop
version 3 of the DnR dataset, addressing issues relating to vocal content in
non-dialogue stems, loudness distributions, mastering process, and linguistic
diversity. In particular, the dialogue stem of DnR v3 includes speech content
from more than 30 languages from multiple families including but not limited to
the Germanic, Romance, Indo-Aryan, Dravidian, Malayo-Polynesian, and Bantu
families. Benchmark results using the Bandit model indicated that training on
multilingual data yields significant generalizability to the model even in
languages with low data availability. Even in languages with high data
availability, the multilingual model often performs on par or better than
dedicated models trained on monolingual CASS datasets. Dataset and model
implementation will be made available at
https://github.com/kwatcharasupat/source-separation-landing.",2024-07-09,"Karn N. Watcharasupat, Chih-Wei Wu, Iroro Orife",http://arxiv.org/pdf/2407.07275v2,cs.LG
Identification of emotions on Twitter during the 2022 electoral process in Colombia,"The study of Twitter as a means for analyzing social phenomena has gained
interest in recent years due to the availability of large amounts of data in a
relatively spontaneous environment. Within opinion-mining tasks, emotion
detection is specially relevant, as it allows for the identification of
people's subjective responses to different social events in a more granular way
than traditional sentiment analysis based on polarity. In the particular case
of political events, the analysis of emotions in social networks can provide
valuable information on the perception of candidates, proposals, and other
important aspects of the public debate. In spite of this importance, there are
few studies on emotion detection in Spanish and, to the best of our knowledge,
few resources are public for opinion mining in Colombian Spanish, highlighting
the need for generating resources addressing the specific cultural
characteristics of this variety. In this work, we present a small corpus of
tweets in Spanish related to the 2022 Colombian presidential elections,
manually labeled with emotions using a fine-grained taxonomy. We perform
classification experiments using supervised state-of-the-art models (BERT
models) and compare them with GPT-3.5 in few-shot learning settings. We make
our dataset and code publicly available for research purposes.",2024-07-09,"Juan Jose Iguaran Fernandez, Juan Manuel Perez, German Rosati",http://arxiv.org/pdf/2407.07258v1,cs.LG
Knowledge boosting during low-latency inference,"Models for low-latency, streaming applications could benefit from the
knowledge capacity of larger models, but edge devices cannot run these models
due to resource constraints. A possible solution is to transfer hints during
inference from a large model running remotely to a small model running
on-device. However, this incurs a communication delay that breaks real-time
requirements and does not guarantee that both models will operate on the same
data at the same time. We propose knowledge boosting, a novel technique that
allows a large model to operate on time-delayed input during inference, while
still boosting small model performance. Using a streaming neural network that
processes 8 ms chunks, we evaluate different speech separation and enhancement
tasks with communication delays of up to six chunks or 48 ms. Our results show
larger gains where the performance gap between the small and large models is
wide, demonstrating a promising method for large-small model collaboration for
low-latency applications. Code, dataset, and audio samples available at
https://knowledgeboosting.cs.washington.edu/.",2024-07-09,"Vidya Srinivas, Malek Itani, Tuochao Chen, Sefik Emre Eskimez, Takuya Yoshioka, Shyamnath Gollakota",http://arxiv.org/pdf/2407.11055v3,cs.LG
RotRNN: Modelling Long Sequences with Rotations,"Linear recurrent neural networks, such as State Space Models (SSMs) and
Linear Recurrent Units (LRUs), have recently shown state-of-the-art performance
on long sequence modelling benchmarks. Despite their success, their empirical
performance is not well understood and they come with a number of drawbacks,
most notably their complex initialisation and normalisation schemes. In this
work, we address some of these issues by proposing RotRNN -- a linear recurrent
model which utilises the convenient properties of rotation matrices. We show
that RotRNN provides a simple and efficient model with a robust normalisation
procedure, and a practical implementation that remains faithful to its
theoretical derivation. RotRNN also achieves competitive performance to
state-of-the-art linear recurrent models on several long sequence modelling
datasets.",2024-07-09,"Kai Biegun, Rares Dolga, Jake Cunningham, David Barber",http://arxiv.org/pdf/2407.07239v2,cs.LG
The Quantum Imitation Game: Reverse Engineering of Quantum Machine Learning Models,"Quantum Machine Learning (QML) amalgamates quantum computing paradigms with
machine learning models, providing significant prospects for solving complex
problems. However, with the expansion of numerous third-party vendors in the
Noisy Intermediate-Scale Quantum (NISQ) era of quantum computing, the security
of QML models is of prime importance, particularly against reverse engineering,
which could expose trained parameters and algorithms of the models. We assume
the untrusted quantum cloud provider is an adversary having white-box access to
the transpiled user-designed trained QML model during inference. Reverse
engineering (RE) to extract the pre-transpiled QML circuit will enable
re-transpilation and usage of the model for various hardware with completely
different native gate sets and even different qubit technology. Such
flexibility may not be obtained from the transpiled circuit which is tied to a
particular hardware and qubit technology. The information about the number of
parameters, and optimized values can allow further training of the QML model to
alter the QML model, tamper with the watermark, and/or embed their own
watermark or refine the model for other purposes. In this first effort to
investigate the RE of QML circuits, we perform RE and compare the training
accuracy of original and reverse-engineered Quantum Neural Networks (QNNs) of
various sizes. We note that multi-qubit classifiers can be reverse-engineered
under specific conditions with a mean error of order 1e-2 in a reasonable time.
We also propose adding dummy fixed parametric gates in the QML models to
increase the RE overhead for defense. For instance, adding 2 dummy qubits and 2
layers increases the overhead by ~1.76 times for a classifier with 2 qubits and
3 layers with a performance overhead of less than 9%. We note that RE is a very
powerful attack model which warrants further efforts on defenses.",2024-07-09,"Archisman Ghosh, Swaroop Ghosh",http://arxiv.org/pdf/2407.07237v2,cs.LG
Speech After Gender: A Trans-Feminine Perspective on Next Steps for Speech Science and Technology,"As experts in voice modification, trans-feminine gender-affirming voice
teachers have unique perspectives on voice that confound current understandings
of speaker identity. To demonstrate this, we present the Versatile Voice
Dataset (VVD), a collection of three speakers modifying their voices along
gendered axes. The VVD illustrates that current approaches in speaker modeling,
based on categorical notions of gender and a static understanding of vocal
texture, fail to account for the flexibility of the vocal tract. Utilizing
publicly-available speaker embeddings, we demonstrate that gender
classification systems are highly sensitive to voice modification, and speaker
verification systems fail to identify voices as coming from the same speaker as
voice modification becomes more drastic. As one path towards moving beyond
categorical and static notions of speaker identity, we propose modeling
individual qualities of vocal texture such as pitch, resonance, and weight.",2024-07-09,"Robin Netzorg, Alyssa Cote, Sumi Koshin, Klo Vivienne Garoute, Gopala Krishna Anumanchipalli",http://arxiv.org/pdf/2407.07235v1,cs.LG
ConvNLP: Image-based AI Text Detection,"The potentials of Generative-AI technologies like Large Language models
(LLMs) to revolutionize education are undermined by ethical considerations
around their misuse which worsens the problem of academic dishonesty. LLMs like
GPT-4 and Llama 2 are becoming increasingly powerful in generating
sophisticated content and answering questions, from writing academic essays to
solving complex math problems. Students are relying on these LLMs to complete
their assignments and thus compromising academic integrity. Solutions to detect
LLM-generated text are compute-intensive and often lack generalization. This
paper presents a novel approach for detecting LLM-generated AI-text using a
visual representation of word embedding. We have formulated a novel
Convolutional Neural Network called ZigZag ResNet, as well as a scheduler for
improving generalization, named ZigZag Scheduler. Through extensive evaluation
using datasets of text generated by six different state-of-the-art LLMs, our
model demonstrates strong intra-domain and inter-domain generalization
capabilities. Our best model detects AI-generated text with an impressive
average detection rate (over inter- and intra-domain test data) of 88.35%.
Through an exhaustive ablation study, our ZigZag ResNet and ZigZag Scheduler
provide a performance improvement of nearly 4% over the vanilla ResNet. The
end-to-end inference latency of our model is below 2.5ms per sentence. Our
solution offers a lightweight, computationally efficient, and faster
alternative to existing tools for AI-generated text detection, with better
generalization performance. It can help academic institutions in their fight
against the misuse of LLMs in academic settings. Through this work, we aim to
contribute to safeguarding the principles of academic integrity and ensuring
the trustworthiness of student work in the era of advanced LLMs.",2024-07-09,"Suriya Prakash Jambunathan, Ashwath Shankarnarayan, Parijat Dube",http://arxiv.org/pdf/2407.07225v1,cs.LG
SPINEX-Clustering: Similarity-based Predictions with Explainable Neighbors Exploration for Clustering Problems,"This paper presents a novel clustering algorithm from the SPINEX
(Similarity-based Predictions with Explainable Neighbors Exploration)
algorithmic family. The newly proposed clustering variant leverages the concept
of similarity and higher-order interactions across multiple subspaces to group
data into clusters. To showcase the merit of SPINEX, a thorough set of
benchmarking experiments was carried out against 13 algorithms, namely,
Affinity Propagation, Agglomerative, Birch, DBSCAN, Gaussian Mixture, HDBSCAN,
K-Means, KMedoids, Mean Shift, MiniBatch K-Means, OPTICS, Spectral Clustering,
and Ward Hierarchical. Then, the performance of all algorithms was examined
across 51 synthetic and real datasets from various domains, dimensions, and
complexities. Furthermore, we present a companion complexity analysis to
compare the complexity of SPINEX to that of the aforementioned algorithms. Our
results demonstrate that SPINEX can outperform commonly adopted clustering
algorithms by ranking within the top-5 best performing algorithms and has
moderate complexity. Finally, a demonstration of the explainability
capabilities of SPINEX, along with future research needs, is presented.",2024-07-09,"MZ Naser, Ahmed Naser",http://arxiv.org/pdf/2407.07222v1,cs.LG
Weak baselines and reporting biases lead to overoptimism in machine learning for fluid-related partial differential equations,"One of the most promising applications of machine learning (ML) in
computational physics is to accelerate the solution of partial differential
equations (PDEs). The key objective of ML-based PDE solvers is to output a
sufficiently accurate solution faster than standard numerical methods, which
are used as a baseline comparison. We first perform a systematic review of the
ML-for-PDE solving literature. Of articles that use ML to solve a fluid-related
PDE and claim to outperform a standard numerical method, we determine that 79%
(60/76) compare to a weak baseline. Second, we find evidence that reporting
biases, especially outcome reporting bias and publication bias, are widespread.
We conclude that ML-for-PDE solving research is overoptimistic: weak baselines
lead to overly positive results, while reporting biases lead to underreporting
of negative results. To a large extent, these issues appear to be caused by
factors similar to those of past reproducibility crises: researcher degrees of
freedom and a bias towards positive results. We call for bottom-up cultural
changes to minimize biased reporting as well as top-down structural reforms
intended to reduce perverse incentives for doing so.",2024-07-09,"Nick McGreivy, Ammar Hakim",http://arxiv.org/pdf/2407.07218v1,cs.LG
Commute-Time-Optimised Graphs for GNNs,"We explore graph rewiring methods that optimise commute time. Recent graph
rewiring approaches facilitate long-range interactions in sparse graphs, making
such rewirings commute-time-optimal on average. However, when an expert prior
exists on which node pairs should or should not interact, a superior rewiring
would favour short commute times between these privileged node pairs. We
construct two synthetic datasets with known priors reflecting realistic
settings, and use these to motivate two bespoke rewiring methods that
incorporate the known prior. We investigate the regimes where our rewiring
improves test performance on the synthetic datasets. Finally, we perform a case
study on a real-world citation graph to investigate the practical implications
of our work.",2024-07-09,"Igor Sterner, Shiye Su, Petar Veličković",http://arxiv.org/pdf/2407.08762v3,cs.LG
TrackFormers: In Search of Transformer-Based Particle Tracking for the High-Luminosity LHC Era,"High-Energy Physics experiments are facing a multi-fold data increase with
every new iteration. This is certainly the case for the upcoming
High-Luminosity LHC upgrade. Such increased data processing requirements forces
revisions to almost every step of the data processing pipeline. One such step
in need of an overhaul is the task of particle track reconstruction, a.k.a.,
tracking. A Machine Learning-assisted solution is expected to provide
significant improvements, since the most time-consuming step in tracking is the
assignment of hits to particles or track candidates. This is the topic of this
paper.
  We take inspiration from large language models. As such, we consider two
approaches: the prediction of the next word in a sentence (next hit point in a
track), as well as the one-shot prediction of all hits within an event. In an
extensive design effort, we have experimented with three models based on the
Transformer architecture and one model based on the U-Net architecture,
performing track association predictions for collision event hit points. In our
evaluation, we consider a spectrum of simple to complex representations of the
problem, eliminating designs with lower metrics early on. We report extensive
results, covering both prediction accuracy (score) and computational
performance. We have made use of the REDVID simulation framework, as well as
reductions applied to the TrackML data set, to compose five data sets from
simple to complex, for our experiments. The results highlight distinct
advantages among different designs in terms of prediction accuracy and
computational performance, demonstrating the efficiency of our methodology.
Most importantly, the results show the viability of a one-shot
encoder-classifier based Transformer solution as a practical approach for the
task of tracking.",2024-07-09,"Sascha Caron, Nadezhda Dobreva, Antonio Ferrer Sánchez, José D. Martín-Guerrero, Uraz Odyurt, Roberto Ruiz de Austri Bazan, Zef Wolffs, Yue Zhao",http://arxiv.org/pdf/2407.07179v3,cs.LG
FBI-LLM: Scaling Up Fully Binarized LLMs from Scratch via Autoregressive Distillation,"This work presents a Fully BInarized Large Language Model (FBI-LLM),
demonstrating for the first time how to train a large-scale binary language
model from scratch (not the partial binary or ternary LLM like BitNet b1.58) to
match the performance of its full-precision counterparts (e.g., FP16 or BF16)
in transformer-based LLMs. It achieves this by employing an autoregressive
distillation (AD) loss with maintaining equivalent model dimensions (130M,
1.3B, 7B) and training data volume as regular LLM pretraining, while delivering
competitive results in terms of perplexity and task-specific effectiveness.
Intriguingly, by analyzing the training trajectory, we find that the pretrained
weight is not necessary for training binarized LLMs from scratch. This research
encourages a new computational framework and may facilitate the future design
of specialized hardware tailored for fully 1-bit LLMs. We make all models,
code, and training dataset fully accessible and transparent to support further
research (Code: https://github.com/LiqunMa/FBI-LLM. Model:
https://huggingface.co/LiqunMa/).",2024-07-09,"Liqun Ma, Mingjie Sun, Zhiqiang Shen",http://arxiv.org/pdf/2407.07093v1,cs.LG
Fine-Tuning Attention Modules Only: Enhancing Weight Disentanglement in Task Arithmetic,"In recent years, task arithmetic has garnered increasing attention. This
approach edits pre-trained models directly in weight space by combining the
fine-tuned weights of various tasks into a unified model. Its efficiency and
cost-effectiveness stem from its training-free combination, contrasting with
traditional methods that require model training on large datasets for multiple
tasks. However, applying such a unified model to individual tasks can lead to
interference from other tasks (lack of weight disentanglement). To address this
issue, Neural Tangent Kernel (NTK) linearization has been employed to leverage
a ""kernel behavior"", facilitating weight disentanglement and mitigating adverse
effects from unrelated tasks. Despite its benefits, NTK linearization presents
drawbacks, including doubled training costs, as well as reduced performance of
individual models. To tackle this problem, we propose a simple yet effective
and efficient method that is to finetune the attention modules only in the
Transformer. Our study reveals that the attention modules exhibit kernel
behavior, and fine-tuning the attention modules only significantly improves
weight disentanglement. To further understand how our method improves the
weight disentanglement of task arithmetic, we present a comprehensive study of
task arithmetic by differentiating the role of the representation module and
task-specific module. In particular, we find that the representation module
plays an important role in improving weight disentanglement whereas the
task-specific modules such as the classification heads can degenerate the
weight disentanglement performance. (The code is available at
https://github.com/kyrie-23/task_arithmetic_tangent)",2024-07-09,"Ruochen Jin, Bojian Hou, Jiancong Xiao, Weijie Su, Li Shen",http://arxiv.org/pdf/2407.07089v2,cs.LG
CopyBench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation,"Evaluating the degree of reproduction of copyright-protected content by
language models (LMs) is of significant interest to the AI and legal
communities. Although both literal and non-literal similarities are considered
by courts when assessing the degree of reproduction, prior research has focused
only on literal similarities. To bridge this gap, we introduce CopyBench, a
benchmark designed to measure both literal and non-literal copying in LM
generations. Using copyrighted fiction books as text sources, we provide
automatic evaluation protocols to assess literal and non-literal copying,
balanced against the model utility in terms of the ability to recall facts from
the copyrighted works and generate fluent completions. We find that, although
literal copying is relatively rare, two types of non-literal copying -- event
copying and character copying -- occur even in models as small as 7B
parameters. Larger models demonstrate significantly more copying, with literal
copying rates increasing from 0.2\% to 10.5\% and non-literal copying from
2.3\% to 5.9\% when comparing Llama3-8B and 70B models, respectively. We
further evaluate the effectiveness of current strategies for mitigating copying
and show that (1) training-time alignment can reduce literal copying but may
increase non-literal copying, and (2) current inference-time mitigation methods
primarily reduce literal but not non-literal copying.",2024-07-09,"Tong Chen, Akari Asai, Niloofar Mireshghallah, Sewon Min, James Grimmelmann, Yejin Choi, Hannaneh Hajishirzi, Luke Zettlemoyer, Pang Wei Koh",http://arxiv.org/pdf/2407.07087v2,cs.LG
Cardinality-Aware Set Prediction and Top-$k$ Classification,"We present a detailed study of cardinality-aware top-$k$ classification, a
novel approach that aims to learn an accurate top-$k$ set predictor while
maintaining a low cardinality. We introduce a new target loss function tailored
to this setting that accounts for both the classification error and the
cardinality of the set predicted. To optimize this loss function, we propose
two families of surrogate losses: cost-sensitive comp-sum losses and
cost-sensitive constrained losses. Minimizing these loss functions leads to new
cardinality-aware algorithms that we describe in detail in the case of both
top-$k$ and threshold-based classifiers. We establish $H$-consistency bounds
for our cardinality-aware surrogate loss functions, thereby providing a strong
theoretical foundation for our algorithms. We report the results of extensive
experiments on CIFAR-10, CIFAR-100, ImageNet, and SVHN datasets demonstrating
the effectiveness and benefits of our cardinality-aware algorithms.",2024-07-09,"Corinna Cortes, Anqi Mao, Christopher Mohri, Mehryar Mohri, Yutao Zhong",http://arxiv.org/pdf/2407.07140v1,cs.LG
Stabilized Proximal-Point Methods for Federated Optimization,"In developing efficient optimization algorithms, it is crucial to account for
communication constraints -- a significant challenge in modern Federated
Learning. The best-known communication complexity among non-accelerated
algorithms is achieved by DANE, a distributed proximal-point algorithm that
solves local subproblems at each iteration and that can exploit second-order
similarity among individual functions. However, to achieve such communication
efficiency, the algorithm requires solving local subproblems sufficiently
accurately resulting in slightly sub-optimal local complexity. Inspired by the
hybrid-projection proximal-point method, in this work, we propose a novel
distributed algorithm S-DANE. Compared to DANE, this method uses an auxiliary
sequence of prox-centers while maintaining the same deterministic communication
complexity. Moreover, the accuracy condition for solving the subproblem is
milder, leading to enhanced local computation efficiency. Furthermore, S-DANE
supports partial client participation and arbitrary stochastic local solvers,
making it attractive in practice. We further accelerate S-DANE and show that
the resulting algorithm achieves the best-known communication complexity among
all existing methods for distributed convex optimization while still enjoying
good local computation efficiency as S-DANE. Finally, we propose adaptive
variants of both methods using line search, obtaining the first provably
efficient adaptive algorithms that could exploit local second-order similarity
without the prior knowledge of any parameters.",2024-07-09,"Xiaowen Jiang, Anton Rodomanov, Sebastian U. Stich",http://arxiv.org/pdf/2407.07084v2,cs.LG
Can Learned Optimization Make Reinforcement Learning Less Difficult?,"While reinforcement learning (RL) holds great potential for decision making
in the real world, it suffers from a number of unique difficulties which often
need specific consideration. In particular: it is highly non-stationary;
suffers from high degrees of plasticity loss; and requires exploration to
prevent premature convergence to local optima and maximize return. In this
paper, we consider whether learned optimization can help overcome these
problems. Our method, Learned Optimization for Plasticity, Exploration and
Non-stationarity (OPEN), meta-learns an update rule whose input features and
output structure are informed by previously proposed solutions to these
difficulties. We show that our parameterization is flexible enough to enable
meta-learning in diverse learning contexts, including the ability to use
stochasticity for exploration. Our experiments demonstrate that when
meta-trained on single and small sets of environments, OPEN outperforms or
equals traditionally used optimizers. Furthermore, OPEN shows strong
generalization characteristics across a range of environments and agent
architectures.",2024-07-09,"Alexander David Goldie, Chris Lu, Matthew Thomas Jackson, Shimon Whiteson, Jakob Nicolaus Foerster",http://arxiv.org/pdf/2407.07082v3,cs.LG
Lookback Lens: Detecting and Mitigating Contextual Hallucinations in Large Language Models Using Only Attention Maps,"When asked to summarize articles or answer questions given a passage, large
language models (LLMs) can hallucinate details and respond with unsubstantiated
answers that are inaccurate with respect to the input context. This paper
describes a simple approach for detecting such contextual hallucinations. We
hypothesize that contextual hallucinations are related to the extent to which
an LLM attends to information in the provided context versus its own
generations. Based on this intuition, we propose a simple hallucination
detection model whose input features are given by the ratio of attention
weights on the context versus newly generated tokens (for each attention head).
We find that a linear classifier based on these lookback ratio features is as
effective as a richer detector that utilizes the entire hidden states of an LLM
or a text-based entailment model. The lookback ratio-based detector -- Lookback
Lens -- is found to transfer across tasks and even models, allowing a detector
that is trained on a 7B model to be applied (without retraining) to a larger
13B model. We further apply this detector to mitigate contextual
hallucinations, and find that a simple classifier-guided decoding approach is
able to reduce the amount of hallucination, for example by 9.6% in the XSum
summarization task.",2024-07-09,"Yung-Sung Chuang, Linlu Qiu, Cheng-Yu Hsieh, Ranjay Krishna, Yoon Kim, James Glass",http://arxiv.org/pdf/2407.07071v2,cs.LG
Explainable Differential Privacy-Hyperdimensional Computing for Balancing Privacy and Transparency in Additive Manufacturing Monitoring,"Machine Learning (ML) models integrated with in-situ sensing offer
transformative solutions for defect detection in Additive Manufacturing (AM),
but this integration brings critical challenges in safeguarding sensitive data,
such as part designs and material compositions. Differential Privacy (DP),
which introduces mathematically controlled noise, provides a balance between
data utility and privacy. However, black-box Artificial Intelligence (AI)
models often obscure how this noise impacts model accuracy, complicating the
optimization of privacy-accuracy trade-offs. This study introduces the
Differential Privacy-Hyperdimensional Computing (DP-HD) framework, a novel
approach combining Explainable AI (XAI) and vector symbolic paradigms to
quantify and predict noise effects on accuracy using a Signal-to-Noise Ratio
(SNR) metric. DP-HD enables precise tuning of DP noise levels, ensuring an
optimal balance between privacy and performance. The framework has been
validated using real-world AM data, demonstrating its applicability to
industrial environments. Experimental results demonstrate DP-HD's capability to
achieve state-of-the-art accuracy (94.43%) with robust privacy protections in
anomaly detection for AM, even under significant noise conditions. Beyond AM,
DP-HD holds substantial promise for broader applications in privacy-sensitive
domains such as healthcare, financial services, and government data management,
where securing sensitive data while maintaining high ML performance is
paramount.",2024-07-09,"Fardin Jalil Piran, Prathyush P. Poduval, Hamza Errahmouni Barkam, Mohsen Imani, Farhad Imani",http://arxiv.org/pdf/2407.07066v4,cs.LG
Prompting Techniques for Secure Code Generation: A Systematic Investigation,"Large Language Models (LLMs) are gaining momentum in software development
with prompt-driven programming enabling developers to create code from natural
language (NL) instructions. However, studies have questioned their ability to
produce secure code and, thereby, the quality of prompt-generated software.
Alongside, various prompting techniques that carefully tailor prompts have
emerged to elicit optimal responses from LLMs. Still, the interplay between
such prompting strategies and secure code generation remains under-explored and
calls for further investigations. OBJECTIVE: In this study, we investigate the
impact of different prompting techniques on the security of code generated from
NL instructions by LLMs. METHOD: First we perform a systematic literature
review to identify the existing prompting techniques that can be used for code
generation tasks. A subset of these techniques are evaluated on GPT-3, GPT-3.5,
and GPT-4 models for secure code generation. For this, we used an existing
dataset consisting of 150 NL security-relevant code-generation prompts.
RESULTS: Our work (i) classifies potential prompting techniques for code
generation (ii) adapts and evaluates a subset of the identified techniques for
secure code generation tasks and (iii) observes a reduction in security
weaknesses across the tested LLMs, especially after using an existing technique
called Recursive Criticism and Improvement (RCI), contributing valuable
insights to the ongoing discourse on LLM-generated code security.",2024-07-09,"Catherine Tony, Nicolás E. Díaz Ferreyra, Markus Mutas, Salem Dhiff, Riccardo Scandariato",http://arxiv.org/pdf/2407.07064v2,cs.LG
Differentiable Optimization of Similarity Scores Between Models and Brains,"How do we know if two systems - biological or artificial - process
information in a similar way? Similarity measures such as linear regression,
Centered Kernel Alignment (CKA), Normalized Bures Similarity (NBS), and angular
Procrustes distance, are often used to quantify this similarity. However, it is
currently unclear what drives high similarity scores and even what constitutes
a ""good"" score. Here, we introduce a novel tool to investigate these questions
by differentiating through similarity measures to directly maximize the score.
Surprisingly, we find that high similarity scores do not guarantee encoding
task-relevant information in a manner consistent with neural data; and this is
particularly acute for CKA and even some variations of cross-validated and
regularized linear regression. We find no consistent threshold for a good
similarity score - it depends on both the measure and the dataset. In addition,
synthetic datasets optimized to maximize similarity scores initially learn the
highest variance principal component of the target dataset, but some methods
like angular Procrustes capture lower variance dimensions much earlier than
methods like CKA. To shed light on this, we mathematically derive the
sensitivity of CKA, angular Procrustes, and NBS to the variance of principal
component dimensions, and explain the emphasis CKA places on high variance
components. Finally, by jointly optimizing multiple similarity measures, we
characterize their allowable ranges and reveal that some similarity measures
are more constraining than others. While current measures offer a seemingly
straightforward way to quantify the similarity between neural systems, our work
underscores the need for careful interpretation. We hope the tools we developed
will be used by practitioners to better understand current and future
similarity measures.",2024-07-09,"Nathan Cloos, Moufan Li, Markus Siegel, Scott L. Brincat, Earl K. Miller, Guangyu Robert Yang, Christopher J. Cueva",http://arxiv.org/pdf/2407.07059v3,cs.LG
Multicell-Fold: geometric learning in folding multicellular life,"During developmental processes such as embryogenesis, how a group of cells
fold into specific structures, is a central question in biology that defines
how living organisms form. Establishing tissue-level morphology critically
relies on how every single cell decides to position itself relative to its
neighboring cells. Despite its importance, it remains a major challenge to
understand and predict the behavior of every cell within the living tissue over
time during such intricate processes. To tackle this question, we propose a
geometric deep learning model that can predict multicellular folding and
embryogenesis, accurately capturing the highly convoluted spatial interactions
among cells. We demonstrate that multicellular data can be represented with
both granular and foam-like physical pictures through a unified graph data
structure, considering both cellular interactions and cell junction networks.
We successfully use our model to achieve two important tasks, interpretable 4-D
morphological sequence alignment, and predicting local cell rearrangements
before they occur at single-cell resolution. Furthermore, using an activation
map and ablation studies, we demonstrate that cell geometries and cell junction
networks together regulate local cell rearrangement which is critical for
embryo morphogenesis. This approach provides a novel paradigm to study
morphogenesis, highlighting a unified data structure and harnessing the power
of geometric deep learning to accurately model the mechanisms and behaviors of
cells during development. It offers a pathway toward creating a unified dynamic
morphological atlas for a variety of developmental processes such as
embryogenesis.",2024-07-09,"Haiqian Yang, Anh Q. Nguyen, Dapeng Bi, Markus J. Buehler, Ming Guo",http://arxiv.org/pdf/2407.07055v2,cs.LG
A Differentially Private Blockchain-Based Approach for Vertical Federated Learning,"We present the Differentially Private Blockchain-Based Vertical Federal
Learning (DP-BBVFL) algorithm that provides verifiability and privacy
guarantees for decentralized applications. DP-BBVFL uses a smart contract to
aggregate the feature representations, i.e., the embeddings, from clients
transparently. We apply local differential privacy to provide privacy for
embeddings stored on a blockchain, hence protecting the original data. We
provide the first prototype application of differential privacy with blockchain
for vertical federated learning. Our experiments with medical data show that
DP-BBVFL achieves high accuracy with a tradeoff in training time due to
on-chain aggregation. This innovative fusion of differential privacy and
blockchain technology in DP-BBVFL could herald a new era of collaborative and
trustworthy machine learning applications across several decentralized
application domains.",2024-07-09,"Linh Tran, Sanjay Chari, Md. Saikat Islam Khan, Aaron Zachariah, Stacy Patterson, Oshani Seneviratne",http://arxiv.org/pdf/2407.07054v1,cs.LG
End-To-End Causal Effect Estimation from Unstructured Natural Language Data,"Knowing the effect of an intervention is critical for human decision-making,
but current approaches for causal effect estimation rely on manual data
collection and structuring, regardless of the causal assumptions. This
increases both the cost and time-to-completion for studies. We show how large,
diverse observational text data can be mined with large language models (LLMs)
to produce inexpensive causal effect estimates under appropriate causal
assumptions. We introduce NATURAL, a novel family of causal effect estimators
built with LLMs that operate over datasets of unstructured text. Our estimators
use LLM conditional distributions (over variables of interest, given the text
data) to assist in the computation of classical estimators of causal effect. We
overcome a number of technical challenges to realize this idea, such as
automating data curation and using LLMs to impute missing information. We
prepare six (two synthetic and four real) observational datasets, paired with
corresponding ground truth in the form of randomized trials, which we used to
systematically evaluate each step of our pipeline. NATURAL estimators
demonstrate remarkable performance, yielding causal effect estimates that fall
within 3 percentage points of their ground truth counterparts, including on
real-world Phase 3/4 clinical trials. Our results suggest that unstructured
text data is a rich source of causal effect information, and NATURAL is a first
step towards an automated pipeline to tap this resource.",2024-07-09,"Nikita Dhawan, Leonardo Cotta, Karen Ullrich, Rahul G. Krishnan, Chris J. Maddison",http://arxiv.org/pdf/2407.07018v3,cs.LG
Empirical analysis of Binding Precedent efficiency in the Brazilian Supreme Court via Similar Case Retrieval,"Binding precedents (S\'umulas Vinculantes) constitute a juridical instrument
unique to the Brazilian legal system and whose objectives include the
protection of the Federal Supreme Court against repetitive demands. Studies of
the effectiveness of these instruments in decreasing the Court's exposure to
similar cases, however, indicate that they tend to fail in such a direction,
with some of the binding precedents seemingly creating new demands. We
empirically assess the legal impact of five binding precedents, 11, 14, 17, 26
and 37, at the highest court level through their effects on the legal subjects
they address. This analysis is only possible through the comparison of the
Court's ruling about the precedents' themes before they are created, which
means that these decisions should be detected through techniques of Similar
Case Retrieval. The contributions of this article are therefore twofold: on the
mathematical side, we compare the uses of different methods of Natural Language
Processing -- TF-IDF, LSTM, BERT, and regex -- for Similar Case Retrieval,
whereas on the legal side, we contrast the inefficiency of these binding
precedents with a set of hypotheses that may justify their repeated usage. We
observe that the deep learning models performed significantly worse in the
specific Similar Case Retrieval task and that the reasons for binding
precedents to fail in responding to repetitive demand are heterogeneous and
case-dependent, making it impossible to single out a specific cause.",2024-07-09,"Raphaël Tinarrage, Henrique Ennes, Lucas E. Resck, Lucas T. Gomes, Jean R. Ponciano, Jorge Poco",http://arxiv.org/pdf/2407.07004v2,cs.LG
Etalon: Holistic Performance Evaluation Framework for LLM Inference Systems,"Serving large language models (LLMs) in production can incur substantial
costs, which has prompted recent advances in inference system optimizations.
Today, these systems are evaluated against conventional latency and throughput
metrics (eg. TTFT, TBT, Normalised Latency and TPOT). However, these metrics
fail to fully capture the nuances of LLM inference, leading to an incomplete
assessment of user-facing performance crucial for real-time applications such
as chat and translation. In this paper, we first identify the pitfalls of
current performance metrics in evaluating LLM inference systems. We then
propose Etalon, a comprehensive performance evaluation framework that includes
fluidity-index -- a novel metric designed to reflect the intricacies of the LLM
inference process and its impact on real-time user experience. Finally, we
evaluate various existing open-source platforms and model-as-a-service
offerings using Etalon, discussing their strengths and weaknesses. Etalon is
available at https://github.com/project-etalon/etalon.",2024-07-09,"Amey Agrawal, Anmol Agarwal, Nitin Kedia, Jayashree Mohan, Souvik Kundu, Nipun Kwatra, Ramachandran Ramjee, Alexey Tumanov",http://arxiv.org/pdf/2407.07000v2,cs.LG
Changepoint Detection in Highly-Attributed Dynamic Graphs,"Detecting anomalous behavior in dynamic networks remains a constant
challenge. This problem is further exacerbated when the underlying topology of
these networks is affected by individual highly-dimensional node attributes. We
address this issue by tracking a network's modularity as a proxy of its
community structure. We leverage Graph Neural Networks (GNNs) to estimate each
snapshot's modularity. GNNs can account for both network structure and
high-dimensional node attributes, providing a comprehensive approach for
estimating network statistics. Our method is validated through simulations that
demonstrate its ability to detect changes in highly-attributed networks by
analyzing shifts in modularity. Moreover, we find our method is able to detect
a real-world event within the \#Iran Twitter reply network, where each node has
high-dimensional textual attributes.",2024-07-09,"Emiliano Penaloza, Nathaniel Stevens",http://arxiv.org/pdf/2407.06998v1,cs.LG
Robust Neural Information Retrieval: An Adversarial and Out-of-distribution Perspective,"Recent advances in neural information retrieval (IR) models have
significantly enhanced their effectiveness over various IR tasks. The
robustness of these models, essential for ensuring their reliability in
practice, has also garnered significant attention. With a wide array of
research on robust IR being proposed, we believe it is the opportune moment to
consolidate the current status, glean insights from existing methodologies, and
lay the groundwork for future development. We view the robustness of IR to be a
multifaceted concept, emphasizing its necessity against adversarial attacks,
out-of-distribution (OOD) scenarios and performance variance. With a focus on
adversarial and OOD robustness, we dissect robustness solutions for dense
retrieval models (DRMs) and neural ranking models (NRMs), respectively,
recognizing them as pivotal components of the neural IR pipeline. We provide an
in-depth discussion of existing methods, datasets, and evaluation metrics,
shedding light on challenges and future directions in the era of large language
models. To the best of our knowledge, this is the first comprehensive survey on
the robustness of neural IR models, and we will also be giving our first
tutorial presentation at SIGIR 2024
\url{https://sigir2024-robust-information-retrieval.github.io}. Along with the
organization of existing work, we introduce a Benchmark for robust IR (BestIR),
a heterogeneous evaluation benchmark for robust neural information retrieval,
which is publicly available at \url{https://github.com/Davion-Liu/BestIR}. We
hope that this study provides useful clues for future research on the
robustness of IR models and helps to develop trustworthy search engines
\url{https://github.com/Davion-Liu/Awesome-Robustness-in-Information-Retrieval}.",2024-07-09,"Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Yixing Fan, Xueqi Cheng",http://arxiv.org/pdf/2407.06992v2,cs.LG
Can virtual staining for high-throughput screening generalize?,"The large volume and variety of imaging data from high-throughput screening
(HTS) in the pharmaceutical industry present an excellent resource for training
virtual staining models. However, the potential of models trained under one set
of experimental conditions to generalize to other conditions remains
underexplored. This study systematically investigates whether data from three
cell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic
conditions) commonly found in HTS can effectively train virtual staining models
to generalize across three typical HTS distribution shifts: unseen phenotypes,
unseen cell types, and the combination of both. Utilizing a dataset of 772,416
paired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we
evaluate the generalization capabilities of models across pixel-based,
instance-wise, and biological-feature-based levels. Our findings indicate that
training virtual nuclei and cytoplasm models on non-toxic condition samples not
only generalizes to toxic condition samples but leads to improved performance
across all evaluation levels compared to training on toxic condition samples.
Generalization to unseen cell types shows variability depending on the cell
type; models trained on ovarian or lung cell samples often perform well under
other conditions, while those trained on breast cell samples consistently show
poor generalization. Generalization to unseen cell types and phenotypes shows
good generalization across all levels of evaluation compared to addressing
unseen cell types alone. This study represents the first large-scale,
data-centric analysis of the generalization capability of virtual staining
models trained on diverse HTS datasets, providing valuable strategies for
experimental training data generation.",2024-07-09,"Samuel Tonks, Cuong Nguyen, Steve Hood, Ryan Musso, Ceridwen Hopely, Steve Titus, Minh Doan, Iain Styles, Alexander Krull",http://arxiv.org/pdf/2407.06979v3,cs.LG
Improving Out-of-Distribution Detection by Combining Existing Post-hoc Methods,"Since the seminal paper of Hendrycks et al. arXiv:1610.02136, Post-hoc deep
Out-of-Distribution (OOD) detection has expanded rapidly. As a result,
practitioners working on safety-critical applications and seeking to improve
the robustness of a neural network now have a plethora of methods to choose
from. However, no method outperforms every other on every dataset
arXiv:2210.07242, so the current best practice is to test all the methods on
the datasets at hand. This paper shifts focus from developing new methods to
effectively combining existing ones to enhance OOD detection. We propose and
compare four different strategies for integrating multiple detection scores
into a unified OOD detector, based on techniques such as majority vote,
empirical and copulas-based Cumulative Distribution Function modeling, and
multivariate quantiles based on optimal transport. We extend common OOD
evaluation metrics -- like AUROC and FPR at fixed TPR rates -- to these
multi-dimensional OOD detectors, allowing us to evaluate them and compare them
with individual methods on extensive benchmarks. Furthermore, we propose a
series of guidelines to choose what OOD detectors to combine in more realistic
settings, i.e. in the absence of known OOD data, relying on principles drawn
from Outlier Exposure arXiv:1812.04606. The code is available at
https://github.com/paulnovello/multi-ood.",2024-07-09,"Paul Novello, Yannick Prudent, Joseba Dalmau, Corentin Friedrich, Yann Pequignot",http://arxiv.org/pdf/2407.07135v1,cs.LG
RoboCAS: A Benchmark for Robotic Manipulation in Complex Object Arrangement Scenarios,"Foundation models hold significant potential for enabling robots to perform
long-horizon general manipulation tasks. However, the simplicity of tasks and
the uniformity of environments in existing benchmarks restrict their effective
deployment in complex scenarios. To address this limitation, this paper
introduces the \textit{RoboCAS} benchmark, the first benchmark specifically
designed for complex object arrangement scenarios in robotic manipulation. This
benchmark employs flexible and concise scripted policies to efficiently collect
a diverse array of demonstrations, showcasing scattered, orderly, and stacked
object arrangements within a highly realistic physical simulation environment.
It includes complex processes such as target retrieval, obstacle clearance, and
robot manipulation, testing agents' abilities to perform long-horizon planning
for spatial reasoning and predicting chain reactions under ambiguous
instructions. Extensive experiments on multiple baseline models reveal their
limitations in managing complex object arrangement scenarios, underscoring the
urgent need for intelligent agents capable of performing long-horizon
operations in practical deployments and providing valuable insights for future
research directions. Project website:
\url{https://github.com/notFoundThisPerson/RoboCAS-v0}.",2024-07-09,"Liming Zheng, Feng Yan, Fanfan Liu, Chengjian Feng, Zhuoliang Kang, Lin Ma",http://arxiv.org/pdf/2407.06951v1,cs.LG
Self-Recognition in Language Models,"A rapidly growing number of applications rely on a small set of closed-source
language models (LMs). This dependency might introduce novel security risks if
LMs develop self-recognition capabilities. Inspired by human identity
verification methods, we propose a novel approach for assessing
self-recognition in LMs using model-generated ""security questions"". Our test
can be externally administered to monitor frontier models as it does not
require access to internal model parameters or output probabilities. We use our
test to examine self-recognition in ten of the most capable open- and
closed-source LMs currently publicly available. Our extensive experiments found
no empirical evidence of general or consistent self-recognition in any examined
LM. Instead, our results suggest that given a set of alternatives, LMs seek to
pick the ""best"" answer, regardless of its origin. Moreover, we find indications
that preferences about which models produce the best answers are consistent
across LMs. We additionally uncover novel insights on position bias
considerations for LMs in multiple-choice settings.",2024-07-09,"Tim R. Davidson, Viacheslav Surkov, Veniamin Veselovsky, Giuseppe Russo, Robert West, Caglar Gulcehre",http://arxiv.org/pdf/2407.06946v2,cs.LG
Bayesian Federated Learning with Hamiltonian Monte Carlo: Algorithm and Theory,"This work introduces a novel and efficient Bayesian federated learning
algorithm, namely, the Federated Averaging stochastic Hamiltonian Monte Carlo
(FA-HMC), for parameter estimation and uncertainty quantification. We establish
rigorous convergence guarantees of FA-HMC on non-iid distributed data sets,
under the strong convexity and Hessian smoothness assumptions. Our analysis
investigates the effects of parameter space dimension, noise on gradients and
momentum, and the frequency of communication (between the central node and
local nodes) on the convergence and communication costs of FA-HMC. Beyond that,
we establish the tightness of our analysis by showing that the convergence rate
cannot be improved even for continuous FA-HMC process. Moreover, extensive
empirical studies demonstrate that FA-HMC outperforms the existing Federated
Averaging-Langevin Monte Carlo (FA-LD) algorithm.",2024-07-09,"Jiajun Liang, Qian Zhang, Wei Deng, Qifan Song, Guang Lin",http://arxiv.org/pdf/2407.06935v1,cs.LG
Synthetic Data: Revisiting the Privacy-Utility Trade-off,"Synthetic data has been considered a better privacy-preserving alternative to
traditionally sanitized data across various applications. However, a recent
article challenges this notion, stating that synthetic data does not provide a
better trade-off between privacy and utility than traditional anonymization
techniques, and that it leads to unpredictable utility loss and highly
unpredictable privacy gain. The article also claims to have identified a breach
in the differential privacy guarantees provided by PATE-GAN and PrivBayes. When
a study claims to refute or invalidate prior findings, it is crucial to verify
and validate the study. In our work, we analyzed the implementation of the
privacy game described in the article and found that it operated in a highly
specialized and constrained environment, which limits the applicability of its
findings to general cases. Our exploration also revealed that the game did not
satisfy a crucial precondition concerning data distributions, which contributed
to the perceived violation of the differential privacy guarantees offered by
PATE-GAN and PrivBayes. We also conducted a privacy-utility trade-off analysis
in a more general and unconstrained environment. Our experimentation
demonstrated that synthetic data indeed achieves a more favorable
privacy-utility trade-off compared to the provided implementation of
k-anonymization, thereby reaffirming earlier conclusions.",2024-07-09,"Fatima Jahan Sarmin, Atiquer Rahman Sarkar, Yang Wang, Noman Mohammed",http://arxiv.org/pdf/2407.07926v2,cs.LG
Fine-grained large-scale content recommendations for MSX sellers,"One of the most critical tasks of Microsoft sellers is to meticulously track
and nurture potential business opportunities through proactive engagement and
tailored solutions. Recommender systems play a central role to help sellers
achieve their goals. In this paper, we present a content recommendation model
which surfaces various types of content (technical documentation, comparison
with competitor products, customer success stories etc.) that sellers can share
with their customers or use for their own self-learning. The model operates at
the opportunity level which is the lowest possible granularity and the most
relevant one for sellers. It is based on semantic matching between metadata
from the contents and carefully selected attributes of the opportunities.
Considering the volume of seller-managed opportunities in organizations such as
Microsoft, we show how to perform efficient semantic matching over a very large
number of opportunity-content combinations. The main challenge is to ensure
that the top-5 relevant contents for each opportunity are recommended out of a
total of $\approx 40,000$ published contents. We achieve this target through an
extensive comparison of different model architectures and feature selection.
Finally, we further examine the quality of the recommendations in a
quantitative manner using a combination of human domain experts as well as by
using the recently proposed ""LLM as a judge"" framework.",2024-07-09,"Manpreet Singh, Ravdeep Pasricha, Ravi Prasad Kondapalli, Kiran R, Nitish Singh, Akshita Agarwalla, Manoj R, Manish Prabhakar, Laurent Boué",http://arxiv.org/pdf/2407.06910v1,cs.LG
Intercepting Unauthorized Aerial Robots in Controlled Airspace Using Reinforcement Learning,"The proliferation of unmanned aerial vehicles (UAVs) in controlled airspace
presents significant risks, including potential collisions, disruptions to air
traffic, and security threats. Ensuring the safe and efficient operation of
airspace, particularly in urban environments and near critical infrastructure,
necessitates effective methods to intercept unauthorized or non-cooperative
UAVs. This work addresses the critical need for robust, adaptive systems
capable of managing such threats through the use of Reinforcement Learning
(RL). We present a novel approach utilizing RL to train fixed-wing UAV pursuer
agents for intercepting dynamic evader targets. Our methodology explores both
model-based and model-free RL algorithms, specifically DreamerV3, Truncated
Quantile Critics (TQC), and Soft Actor-Critic (SAC). The training and
evaluation of these algorithms were conducted under diverse scenarios,
including unseen evasion strategies and environmental perturbations. Our
approach leverages high-fidelity flight dynamics simulations to create
realistic training environments. This research underscores the importance of
developing intelligent, adaptive control systems for UAV interception,
significantly contributing to the advancement of secure and efficient airspace
management. It demonstrates the potential of RL to train systems capable of
autonomously achieving these critical tasks.",2024-07-09,"Francisco Giral, Ignacio Gómez, Soledad Le Clainche",http://arxiv.org/pdf/2407.06909v1,cs.LG
Learning From Crowdsourced Noisy Labels: A Signal Processing Perspective,"One of the primary catalysts fueling advances in artificial intelligence (AI)
and machine learning (ML) is the availability of massive, curated datasets. A
commonly used technique to curate such massive datasets is crowdsourcing, where
data are dispatched to multiple annotators. The annotator-produced labels are
then fused to serve downstream learning and inference tasks. This annotation
process often creates noisy labels due to various reasons, such as the limited
expertise, or unreliability of annotators, among others. Therefore, a core
objective in crowdsourcing is to develop methods that effectively mitigate the
negative impact of such label noise on learning tasks. This feature article
introduces advances in learning from noisy crowdsourced labels. The focus is on
key crowdsourcing models and their methodological treatments, from classical
statistical models to recent deep learning-based approaches, emphasizing
analytical insights and algorithmic developments. In particular, this article
reviews the connections between signal processing (SP) theory and methods, such
as identifiability of tensor and nonnegative matrix factorization, and novel,
principled solutions of longstanding challenges in crowdsourcing -- showing how
SP perspectives drive the advancements of this field. Furthermore, this article
touches upon emerging topics that are critical for developing cutting-edge
AI/ML systems, such as crowdsourcing in reinforcement learning with human
feedback (RLHF) and direct preference optimization (DPO) that are key
techniques for fine-tuning large language models (LLMs).",2024-07-09,"Shahana Ibrahim, Panagiotis A. Traganitis, Xiao Fu, Georgios B. Giannakis",http://arxiv.org/pdf/2407.06902v1,cs.LG
A Complete Set of Quadratic Constraints for Repeated ReLU and Generalizations,"This paper derives a complete set of quadratic constraints (QCs) for the
repeated ReLU. The complete set of QCs is described by a collection of matrix
copositivity conditions. We also show that only two functions satisfy all QCs
in our complete set: the repeated ReLU and flipped ReLU. Thus our complete set
of QCs bounds the repeated ReLU as tight as possible up to the sign invariance
inherent in quadratic forms. We derive a similar complete set of incremental
QCs for repeated ReLU, which can potentially lead to less conservative
Lipschitz bounds for ReLU networks than the standard LipSDP approach. The basic
constructions are also used to derive the complete sets of QCs for other
piecewise linear activation functions such as leaky ReLU, MaxMin, and
HouseHolder. Finally, we illustrate the use of the complete set of QCs to
assess stability and performance for recurrent neural networks with ReLU
activation functions. We rely on a standard copositivity relaxation to
formulate the stability/performance condition as a semidefinite program. Simple
examples are provided to illustrate that the complete sets of QCs and
incremental QCs can yield less conservative bounds than existing sets.",2024-07-09,"Sahel Vahedi Noori, Bin Hu, Geir Dullerud, Peter Seiler",http://arxiv.org/pdf/2407.06888v2,cs.LG
Aligning Cyber Space with Physical World: A Comprehensive Survey on Embodied AI,"Embodied Artificial Intelligence (Embodied AI) is crucial for achieving
Artificial General Intelligence (AGI) and serves as a foundation for various
applications that bridge cyberspace and the physical world. Recently, the
emergence of Multi-modal Large Models (MLMs) and World Models (WMs) have
attracted significant attention due to their remarkable perception,
interaction, and reasoning capabilities, making them a promising architecture
for the brain of embodied agents. However, there is no comprehensive survey for
Embodied AI in the era of MLMs. In this survey, we give a comprehensive
exploration of the latest advancements in Embodied AI. Our analysis firstly
navigates through the forefront of representative works of embodied robots and
simulators, to fully understand the research focuses and their limitations.
Then, we analyze four main research targets: 1) embodied perception, 2)
embodied interaction, 3) embodied agent, and 4) sim-to-real adaptation,
covering the state-of-the-art methods, essential paradigms, and comprehensive
datasets. Additionally, we explore the complexities of MLMs in virtual and real
embodied agents, highlighting their significance in facilitating interactions
in dynamic digital and physical environments. Finally, we summarize the
challenges and limitations of embodied AI and discuss their potential future
directions. We hope this survey will serve as a foundational reference for the
research community and inspire continued innovation. The associated project can
be found at https://github.com/HCPLab-SYSU/Embodied_AI_Paper_List.",2024-07-09,"Yang Liu, Weixing Chen, Yongjie Bai, Xiaodan Liang, Guanbin Li, Wen Gao, Liang Lin",http://arxiv.org/pdf/2407.06886v7,cs.LG
Energy Efficient Fair STAR-RIS for Mobile Users,"In this work, we propose a method to improve the energy efficiency and
fairness of simultaneously transmitting and reflecting reconfigurable
intelligent surfaces (STAR-RIS) for mobile users, ensuring reduced power
consumption while maintaining reliable communication. To achieve this, we
introduce a new parameter known as the subsurface assignment variable, which
determines the number of STAR-RIS elements allocated to each user. We then
formulate a novel optimization problem by concurrently optimizing the phase
shifts of the STAR-RIS and subsurface assignment variable. We leverage the deep
reinforcement learning (DRL) technique to address this optimization problem.
The DRL model predicts the phase shifts of the STAR-RIS and efficiently
allocates elements of STAR-RIS to the users. Additionally, we incorporate a
penalty term in the DRL model to facilitate intelligent deactivation of
STAR-RIS elements when not in use to enhance energy efficiency. Through
extensive experiments, we show that the proposed method can achieve fairly high
and nearly equal data rates for all users in both the transmission and
reflection spaces in an energy-efficient manner.",2024-07-09,"Ashok S. Kumar, Nancy Nayak, Sheetal Kalyani, Himal A. Suraweera",http://arxiv.org/pdf/2407.06868v1,cs.LG
Trust and Resilience in Federated Learning Through Smart Contracts Enabled Decentralized Systems,"In this paper, we present a study of a Federated Learning (FL) system, based
on the use of decentralized architectures to ensure trust and increase
reliability. The system is based on the idea that the FL collaborators upload
the (ciphered) model parameters on the Inter-Planetary File System (IPFS) and
interact with a dedicated smart contract to track their behavior. Thank to this
smart contract, the phases of parameter updates are managed efficiently,
thereby strengthening data security. We have carried out an experimental study
that exploits two different methods of weight aggregation, i.e., a classic
averaging scheme and a federated proximal aggregation. The results confirm the
feasibility of the proposal.",2024-07-09,"Lorenzo Cassano, Jacopo D'Abramo, Siraj Munir, Stefano Ferretti",http://arxiv.org/pdf/2407.06862v1,cs.LG
Mobile Edge Intelligence for Large Language Models: A Contemporary Survey,"On-device large language models (LLMs), referring to running LLMs on edge
devices, have raised considerable interest since they are more cost-effective,
latency-efficient, and privacy-preserving compared with the cloud paradigm.
Nonetheless, the performance of on-device LLMs is intrinsically constrained by
resource limitations on edge devices. Sitting between cloud and on-device AI,
mobile edge intelligence (MEI) presents a viable solution by provisioning AI
capabilities at the edge of mobile networks, enabling end users to offload
heavy AI computation to capable edge servers nearby. This article provides a
contemporary survey on harnessing MEI for LLMs. We begin by illustrating
several killer applications to demonstrate the urgent need for deploying LLMs
at the network edge. Next, we present the preliminaries of LLMs and MEI,
followed by resource-efficient LLM techniques. We then present an architectural
overview of MEI for LLMs (MEI4LLM), outlining its core components and how it
supports the deployment of LLMs. Subsequently, we delve into various aspects of
MEI4LLM, extensively covering edge LLM caching and delivery, edge LLM training,
and edge LLM inference. Finally, we identify future research opportunities. We
hope this article inspires researchers in the field to leverage mobile edge
computing to facilitate LLM deployment, thereby unleashing the potential of
LLMs across various privacy- and delay-sensitive applications.",2024-07-09,"Guanqiao Qu, Qiyuan Chen, Wei Wei, Zheng Lin, Xianhao Chen, Kaibin Huang",http://arxiv.org/pdf/2407.18921v2,cs.LG
Performance Evaluation of Knowledge Graph Embedding Approaches under Non-adversarial Attacks,"Knowledge Graph Embedding (KGE) transforms a discrete Knowledge Graph (KG)
into a continuous vector space facilitating its use in various AI-driven
applications like Semantic Search, Question Answering, or Recommenders. While
KGE approaches are effective in these applications, most existing approaches
assume that all information in the given KG is correct. This enables attackers
to influence the output of these approaches, e.g., by perturbing the input.
Consequently, the robustness of such KGE approaches has to be addressed. Recent
work focused on adversarial attacks. However, non-adversarial attacks on all
attack surfaces of these approaches have not been thoroughly examined. We close
this gap by evaluating the impact of non-adversarial attacks on the performance
of 5 state-of-the-art KGE algorithms on 5 datasets with respect to attacks on 3
attack surfaces-graph, parameter, and label perturbation. Our evaluation
results suggest that label perturbation has a strong effect on the KGE
performance, followed by parameter perturbation with a moderate and graph with
a low effect.",2024-07-09,"Sourabh Kapoor, Arnab Sharma, Michael Röder, Caglar Demir, Axel-Cyrille Ngonga Ngomo",http://arxiv.org/pdf/2407.06855v1,cs.LG
Uncertainty-preserving deep knowledge tracing with state-space models,"A central goal of both knowledge tracing and traditional assessment is to
quantify student knowledge and skills at a given point in time. Deep knowledge
tracing flexibly considers a student's response history but does not quantify
epistemic uncertainty, while IRT and CDM compute measurement error but only
consider responses to individual tests in isolation from a student's past
responses. Elo and BKT could bridge this divide, but the simplicity of the
underlying models limits information sharing across skills and imposes strong
inductive biases. To overcome these limitations, we introduce Dynamic LENS, a
modeling paradigm that combines the flexible uncertainty-preserving properties
of variational autoencoders with the principled information integration of
Bayesian state-space models. Dynamic LENS allows information from student
responses to be collected across time, while treating responses from the same
test as exchangeable observations generated by a shared latent state. It
represents student knowledge as Gaussian distributions in high-dimensional
space and combines estimates both within tests and across time using Bayesian
updating. We show that Dynamic LENS has similar predictive performance to
competing models, while preserving the epistemic uncertainty - the deep
learning analogue to measurement error - that DKT models lack. This approach
provides a conceptual bridge across an important divide between models designed
for formative practice and summative assessment.",2024-07-09,"S. Thomas Christie, Carson Cook, Anna N. Rafferty",http://arxiv.org/pdf/2407.17427v1,cs.LG
TeVAE: A Variational Autoencoder Approach for Discrete Online Anomaly Detection in Variable-state Multivariate Time-series Data,"As attention to recorded data grows in the realm of automotive testing and
manual evaluation reaches its limits, there is a growing need for automatic
online anomaly detection. This real-world data is complex in many ways and
requires the modelling of testee behaviour. To address this, we propose a
temporal variational autoencoder (TeVAE) that can detect anomalies with minimal
false positives when trained on unlabelled data. Our approach also avoids the
bypass phenomenon and introduces a new method to remap individual windows to a
continuous time series. Furthermore, we propose metrics to evaluate the
detection delay and root-cause capability of our approach and present results
from experiments on a real-world industrial data set. When properly configured,
TeVAE flags anomalies only 6% of the time wrongly and detects 65% of anomalies
present. It also has the potential to perform well with a smaller training and
validation subset but requires a more sophisticated threshold estimation
method.",2024-07-09,"Lucas Correia, Jan-Christoph Goos, Philipp Klein, Thomas Bäck, Anna V. Kononova",http://arxiv.org/pdf/2407.06849v1,cs.LG
AI AI Bias: Large Language Models Favor Their Own Generated Content,"Are large language models (LLMs) biased towards text generated by LLMs over
text authored by humans, leading to possible anti-human bias? Utilizing a
classical experimental design inspired by employment discrimination studies, we
tested widely-used LLMs, including GPT-3.5 and GPT4, in binary-choice
scenarios. These involved LLM-based agents selecting between products and
academic papers described either by humans or LLMs under identical conditions.
Our results show a consistent tendency for LLM-based AIs to prefer
LLM-generated content. This suggests the possibility of AI systems implicitly
discriminating against humans, giving AI agents an unfair advantage.",2024-07-09,"Walter Laurito, Benjamin Davis, Peli Grietzer, Tomáš Gavenčiak, Ada Böhm, Jan Kulveit",http://arxiv.org/pdf/2407.12856v1,cs.LG
A Comprehensive Analysis of Machine Learning Models for Algorithmic Trading of Bitcoin,"This study evaluates the performance of 41 machine learning models, including
21 classifiers and 20 regressors, in predicting Bitcoin prices for algorithmic
trading. By examining these models under various market conditions, we
highlight their accuracy, robustness, and adaptability to the volatile
cryptocurrency market. Our comprehensive analysis reveals the strengths and
limitations of each model, providing critical insights for developing effective
trading strategies. We employ both machine learning metrics (e.g., Mean
Absolute Error, Root Mean Squared Error) and trading metrics (e.g., Profit and
Loss percentage, Sharpe Ratio) to assess model performance. Our evaluation
includes backtesting on historical data, forward testing on recent unseen data,
and real-world trading scenarios, ensuring the robustness and practical
applicability of our models. Key findings demonstrate that certain models, such
as Random Forest and Stochastic Gradient Descent, outperform others in terms of
profit and risk management. These insights offer valuable guidance for traders
and researchers aiming to leverage machine learning for cryptocurrency trading.",2024-07-09,"Abdul Jabbar, Syed Qaisar Jalil",http://arxiv.org/pdf/2407.18334v1,cs.LG
A Scenario-Oriented Benchmark for Assessing AIOps Algorithms in Microservice Management,"AIOps algorithms play a crucial role in the maintenance of microservice
systems. Many previous benchmarks' performance leaderboard provides valuable
guidance for selecting appropriate algorithms. However, existing AIOps
benchmarks mainly utilize offline datasets to evaluate algorithms. They cannot
consistently evaluate the performance of algorithms using real-time datasets,
and the operation scenarios for evaluation are static, which is insufficient
for effective algorithm selection. To address these issues, we propose an
evaluation-consistent and scenario-oriented evaluation framework named
MicroServo. The core idea is to build a live microservice benchmark to generate
real-time datasets and consistently simulate the specific operation scenarios
on it. MicroServo supports different leaderboards by selecting specific
algorithms and datasets according to the operation scenarios. It also supports
the deployment of various types of algorithms, enabling algorithms
hot-plugging. At last, we test MicroServo with three typical microservice
operation scenarios to demonstrate its efficiency and usability.",2024-07-09,"Yongqian Sun, Jiaju Wang, Zhengdan Li, Xiaohui Nie, Minghua Ma, Shenglin Zhang, Yuhe Ji, Lu Zhang, Wen Long, Hengmao Chen, Yongnan Luo, Dan Pei",http://arxiv.org/pdf/2407.14532v1,cs.LG
Neuromimetic metaplasticity for adaptive continual learning,"Conventional intelligent systems based on deep neural network (DNN) models
encounter challenges in achieving human-like continual learning due to
catastrophic forgetting. Here, we propose a metaplasticity model inspired by
human working memory, enabling DNNs to perform catastrophic forgetting-free
continual learning without any pre- or post-processing. A key aspect of our
approach involves implementing distinct types of synapses from stable to
flexible, and randomly intermixing them to train synaptic connections with
different degrees of flexibility. This strategy allowed the network to
successfully learn a continuous stream of information, even under unexpected
changes in input length. The model achieved a balanced tradeoff between memory
capacity and performance without requiring additional training or structural
modifications, dynamically allocating memory resources to retain both old and
new information. Furthermore, the model demonstrated robustness against data
poisoning attacks by selectively filtering out erroneous memories, leveraging
the Hebb repetition effect to reinforce the retention of significant data.",2024-07-09,"Suhee Cho, Hyeonsu Lee, Seungdae Baek, Se-Bum Paik",http://arxiv.org/pdf/2407.07133v1,cs.LG
Learn and Don't Forget: Adding a New Language to ASR Foundation Models,"Foundation ASR models often support many languages, e.g. 100 languages in
Whisper. However, there has been limited work on integrating an additional,
typically low-resource, language, while maintaining performance on the original
language set. Fine-tuning, while simple, may degrade the accuracy of the
original set. We compare three approaches that exploit adaptation parameters:
soft language code tuning, train only the language code; soft prompt tuning,
train prepended tokens; and LoRA where a small set of additional parameters are
optimised. Elastic Weight Consolidation (EWC) offers an alternative compromise
with the potential to maintain performance in specific target languages.
Results show that direct fine-tuning yields the best performance for the new
language but degrades existing language capabilities. EWC can address this
issue for specific languages. If only adaptation parameters are used, the
language capabilities are maintained but at the cost of performance in the new
language.",2024-07-09,"Mengjie Qian, Siyuan Tang, Rao Ma, Kate M. Knill, Mark J. F. Gales",http://arxiv.org/pdf/2407.06800v3,cs.LG
ED-VAE: Entropy Decomposition of ELBO in Variational Autoencoders,"Traditional Variational Autoencoders (VAEs) are constrained by the
limitations of the Evidence Lower Bound (ELBO) formulation, particularly when
utilizing simplistic, non-analytic, or unknown prior distributions. These
limitations inhibit the VAE's ability to generate high-quality samples and
provide clear, interpretable latent representations. This work introduces the
Entropy Decomposed Variational Autoencoder (ED-VAE), a novel re-formulation of
the ELBO that explicitly includes entropy and cross-entropy components. This
reformulation significantly enhances model flexibility, allowing for the
integration of complex and non-standard priors. By providing more detailed
control over the encoding and regularization of latent spaces, ED-VAE not only
improves interpretability but also effectively captures the complex
interactions between latent variables and observed data, thus leading to better
generative performance.",2024-07-09,"Fotios Lygerakis, Elmar Rueckert",http://arxiv.org/pdf/2407.06797v1,cs.LG
Towards physics-informed neural networks for landslide prediction,"For decades, solutions to regional scale landslide prediction have mostly
relied on data-driven models, by definition, disconnected from the physics of
the failure mechanism. The success and spread of such tools came from the
ability to exploit proxy variables rather than explicit geotechnical ones, as
the latter are prohibitive to acquire over broad landscapes. Our work
implements a Physics Informed Neural Network (PINN) approach, thereby adding to
a standard data-driven architecture, an intermediate constraint to solve for
the permanent deformation typical of Newmark slope stability methods. This
translates into a neural network tasked with explicitly retrieving geotechnical
parameters from common proxy variables and then minimize a loss function with
respect to the available coseismic landside inventory. The results are very
promising, because our model not only produces excellent predictive performance
in the form of standard susceptibility output, but in the process, also
generates maps of the expected geotechnical properties at a regional scale.
Such architecture is therefore framed to tackle coseismic landslide prediction,
something that, if confirmed in other studies, could open up towards PINN-based
near-real-time predictions.",2024-07-09,"Ashok Dahal, Luigi Lombardo",http://arxiv.org/pdf/2407.06785v1,cs.LG
Convergence rates for Poisson learning to a Poisson equation with measure data,"In this paper we prove discrete to continuum convergence rates for Poisson
Learning, a graph-based semi-supervised learning algorithm that is based on
solving the graph Poisson equation with a source term consisting of a linear
combination of Dirac deltas located at labeled points and carrying label
information. The corresponding continuum equation is a Poisson equation with
measure data in a Euclidean domain $\Omega \subset \mathbb{R}^d$. The singular
nature of these equations is challenging and requires an approach with several
distinct parts: (1) We prove quantitative error estimates when convolving the
measure data of a Poisson equation with (approximately) radial function
supported on balls. (2) We use quantitative variational techniques to prove
discrete to continuum convergence rates on random geometric graphs with
bandwidth $\varepsilon>0$ for bounded source terms. (3) We show how to
regularize the graph Poisson equation via mollification with the graph heat
kernel, and we study fine asymptotics of the heat kernel on random geometric
graphs. Combining these three pillars we obtain $L^1$ convergence rates that
scale, up to logarithmic factors, like $O(\varepsilon^{\frac{1}{d+2}})$ for
general data distributions, and $O(\varepsilon^{\frac{2-\sigma}{d+4}})$ for
uniformly distributed data, where $\sigma>0$. These rates are valid with high
probability if $\varepsilon\gg\left({\log n}/{n}\right)^q$ where $n$ denotes
the number of vertices of the graph and $q \approx \frac{1}{3d}$.",2024-07-09,"Leon Bungert, Jeff Calder, Max Mihailescu, Kodjo Houssou, Amber Yuan",http://arxiv.org/pdf/2407.06783v1,cs.LG
Temporal Convolution Derived Multi-Layered Reservoir Computing,"The prediction of time series is a challenging task relevant in such diverse
applications as analyzing financial data, forecasting flow dynamics or
understanding biological processes. Especially chaotic time series that depend
on a long history pose an exceptionally difficult problem. While machine
learning has shown to be a promising approach for predicting such time series,
it either demands long training time and much training data when using deep
Recurrent Neural Networks. Alternative, when using a Reservoir Computing
approach it comes with high uncertainty and typically a high number of random
initializations and extensive hyper-parameter tuning. In this paper, we focus
on the Reservoir Computing approach and propose a new mapping of input data
into the reservoir's state space. Furthermore, we incorporate this method in
two novel network architectures increasing parallelizability, depth and
predictive capabilities of the neural network while reducing the dependence on
randomness. For the evaluation, we approximate a set of time series from the
Mackey-Glass equation, inhabiting non-chaotic as well as chaotic behavior as
well as the SantaFe Laser dataset and compare our approaches in regard to their
predictive capabilities to Echo State Networks, Autoencoder connected Echo
State Networks and Gated Recurrent Units. For the chaotic time series, we
observe an error reduction of up to $85.45\%$ compared to Echo State Networks
and $90.72\%$ compared to Gated Recurrent Units. Furthermore, we also observe
tremendous improvements for non-chaotic time series of up to $99.99\%$ in
contrast to the existing approaches.",2024-07-09,"Johannes Viehweg, Dominik Walther, Patrick Mäder",http://arxiv.org/pdf/2407.06771v2,cs.LG
A Generalization Bound for Nearly-Linear Networks,"We consider nonlinear networks as perturbations of linear ones. Based on this
approach, we present novel generalization bounds that become non-vacuous for
networks that are close to being linear. The main advantage over the previous
works which propose non-vacuous generalization bounds is that our bounds are
a-priori: performing the actual training is not required for evaluating the
bounds. To the best of our knowledge, they are the first non-vacuous
generalization bounds for neural nets possessing this property.",2024-07-09,Eugene Golikov,http://arxiv.org/pdf/2407.06765v1,cs.LG
Large Language Models can impersonate politicians and other public figures,"Modern AI technology like Large language models (LLMs) has the potential to
pollute the public information sphere with made-up content, which poses a
significant threat to the cohesion of societies at large. A wide range of
research has shown that LLMs are capable of generating text of impressive
quality, including persuasive political speech, text with a pre-defined style,
and role-specific content. But there is a crucial gap in the literature: We
lack large-scale and systematic studies of how capable LLMs are in
impersonating political and societal representatives and how the general public
judges these impersonations in terms of authenticity, relevance and coherence.
We present the results of a study based on a cross-section of British society
that shows that LLMs are able to generate responses to debate questions that
were part of a broadcast political debate programme in the UK. The impersonated
responses are judged to be more authentic and relevant than the original
responses given by people who were impersonated. This shows two things: (1)
LLMs can be made to contribute meaningfully to the public political debate and
(2) there is a dire need to inform the general public of the potential harm
this can have on society.",2024-07-09,"Steffen Herbold, Alexander Trautsch, Zlata Kikteva, Annette Hautli-Janisz",http://arxiv.org/pdf/2407.12855v1,cs.LG
Frequency and Generalisation of Periodic Activation Functions in Reinforcement Learning,"Periodic activation functions, often referred to as learned Fourier features
have been widely demonstrated to improve sample efficiency and stability in a
variety of deep RL algorithms. Potentially incompatible hypotheses have been
made about the source of these improvements. One is that periodic activations
learn low frequency representations and as a result avoid overfitting to
bootstrapped targets. Another is that periodic activations learn high frequency
representations that are more expressive, allowing networks to quickly fit
complex value functions. We analyse these claims empirically, finding that
periodic representations consistently converge to high frequencies regardless
of their initialisation frequency. We also find that while periodic activation
functions improve sample efficiency, they exhibit worse generalization on
states with added observation noise -- especially when compared to otherwise
equivalent networks with ReLU activation functions. Finally, we show that
weight decay regularization is able to partially offset the overfitting of
periodic activation functions, delivering value functions that learn quickly
while also generalizing.",2024-07-09,"Augustine N. Mavor-Parker, Matthew J. Sargent, Caswell Barry, Lewis Griffin, Clare Lyle",http://arxiv.org/pdf/2407.06756v2,cs.LG
Modularity aided consistent attributed graph clustering via coarsening,"Graph clustering is an important unsupervised learning technique for
partitioning graphs with attributes and detecting communities. However, current
methods struggle to accurately capture true community structures and
intra-cluster relations, be computationally efficient, and identify smaller
communities. We address these challenges by integrating coarsening and
modularity maximization, effectively leveraging both adjacency and node
features to enhance clustering accuracy. We propose a loss function
incorporating log-determinant, smoothness, and modularity components using a
block majorization-minimization technique, resulting in superior clustering
outcomes. The method is theoretically consistent under the Degree-Corrected
Stochastic Block Model (DC-SBM), ensuring asymptotic error-free performance and
complete label recovery. Our provably convergent and time-efficient algorithm
seamlessly integrates with graph neural networks (GNNs) and variational graph
autoencoders (VGAEs) to learn enhanced node features and deliver exceptional
clustering performance. Extensive experiments on benchmark datasets demonstrate
its superiority over existing state-of-the-art methods for both attributed and
non-attributed graphs.",2024-07-09,"Samarth Bhatia, Yukti Makhija, Manoj Kumar, Sandeep Kumar",http://arxiv.org/pdf/2407.07128v2,cs.LG
Sustainable techniques to improve Data Quality for training image-based explanatory models for Recommender Systems,"Visual explanations based on user-uploaded images are an effective and
self-contained approach to provide transparency to Recommender Systems (RS),
but intrinsic limitations of data used in this explainability paradigm cause
existing approaches to use bad quality training data that is highly sparse and
suffers from labelling noise. Popular training enrichment approaches like model
enlargement or massive data gathering are expensive and environmentally
unsustainable, thus we seek to provide better visual explanations to RS
aligning with the principles of Responsible AI. In this work, we research the
intersection of effective and sustainable training enrichment strategies for
visual-based RS explainability models by developing three novel strategies that
focus on training Data Quality: 1) selection of reliable negative training
examples using Positive-unlabelled Learning, 2) transform-based data
augmentation, and 3) text-to-image generative-based data augmentation. The
integration of these strategies in three state-of-the-art explainability models
increases 5% the performance in relevant ranking metrics of these visual-based
RS explainability models without penalizing their practical long-term
sustainability, as tested in multiple real-world restaurant recommendation
explanation datasets.",2024-07-09,"Jorge Paz-Ruza, David Esteban-Martínez, Amparo Alonso-Betanzos, Bertha Guijarro-Berdiñas",http://arxiv.org/pdf/2407.06740v2,cs.LG
Graph-Based Captioning: Enhancing Visual Descriptions by Interconnecting Region Captions,"Humans describe complex scenes with compositionality, using simple text
descriptions enriched with links and relationships. While vision-language
research has aimed to develop models with compositional understanding
capabilities, this is not reflected yet in existing datasets which, for the
most part, still use plain text to describe images. In this work, we propose a
new annotation strategy, graph-based captioning (GBC) that describes an image
using a labeled graph structure, with nodes of various types. The nodes in GBC
are created through a two-stage process: first, identifying and describing
entity nodes; second, linking these nodes by highlighting \textit{compositions}
and \textit{relations} among them. Since \textit{all} GBC nodes hold plain text
descriptions, GBC retains the flexibility found in natural language, but can
also encode hierarchical information in its edges. We demonstrate that GBC can
be produced automatically, using off-the-shelf multimodal LLMs and object
detection models, by building a new dataset GBC10M that gathers GBC annotations
for about 10M images of the CC12M dataset. Through CLIP training on GBC10M, we
show that leveraging GBC nodes' annotations -- particularly those in
composition and relation nodes -- significantly boosts the model's performance
across various benchmarks compared to when other annotations are used. To
further explore the opportunities provided by GBC, we also investigate the use
of GBC as middleware for text-to-image generation, and show the extra benefits
of incorporating the graph structure in this task. Our code and datasets are
released at https://github.com/apple/ml-gbc and
https://huggingface.co/graph-based-captions.",2024-07-09,"Yu-Guan Hsieh, Cheng-Yu Hsieh, Shih-Ying Yeh, Louis Béthune, Hadi Pour Ansari, Pavan Kumar Anasosalu Vasu, Chun-Liang Li, Ranjay Krishna, Oncel Tuzel, Marco Cuturi",http://arxiv.org/pdf/2407.06723v2,cs.LG
"MDP Geometry, Normalization and Reward Balancing Solvers","We present a new geometric interpretation of Markov Decision Processes (MDPs)
with a natural normalization procedure that allows us to adjust the value
function at each state without altering the advantage of any action with
respect to any policy. This advantage-preserving transformation of the MDP
motivates a class of algorithms which we call Reward Balancing, which solve
MDPs by iterating through these transformations, until an approximately optimal
policy can be trivially found. We provide a convergence analysis of several
algorithms in this class, in particular showing that for MDPs for unknown
transition probabilities we can improve upon state-of-the-art sample complexity
results.",2024-07-09,"Arsenii Mustafin, Aleksei Pakharev, Alex Olshevsky, Ioannis Ch. Paschalidis",http://arxiv.org/pdf/2407.06712v4,cs.LG
Top-K Pairwise Ranking: Bridging the Gap Among Ranking-Based Measures for Multi-Label Classification,"Multi-label ranking, which returns multiple top-ranked labels for each
instance, has a wide range of applications for visual tasks. Due to its
complicated setting, prior arts have proposed various measures to evaluate
model performances. However, both theoretical analysis and empirical
observations show that a model might perform inconsistently on different
measures. To bridge this gap, this paper proposes a novel measure named Top-K
Pairwise Ranking (TKPR), and a series of analyses show that TKPR is compatible
with existing ranking-based measures. In light of this, we further establish an
empirical surrogate risk minimization framework for TKPR. On one hand, the
proposed framework enjoys convex surrogate losses with the theoretical support
of Fisher consistency. On the other hand, we establish a sharp generalization
bound for the proposed framework based on a novel technique named
data-dependent contraction. Finally, empirical results on benchmark datasets
validate the effectiveness of the proposed framework.",2024-07-09,"Zitai Wang, Qianqian Xu, Zhiyong Yang, Peisong Wen, Yuan He, Xiaochun Cao, Qingming Huang",http://arxiv.org/pdf/2407.06709v1,cs.LG
Self-supervised visual learning from interactions with objects,"Self-supervised learning (SSL) has revolutionized visual representation
learning, but has not achieved the robustness of human vision. A reason for
this could be that SSL does not leverage all the data available to humans
during learning. When learning about an object, humans often purposefully turn
or move around objects and research suggests that these interactions can
substantially enhance their learning. Here we explore whether such
object-related actions can boost SSL. For this, we extract the actions
performed to change from one ego-centric view of an object to another in four
video datasets. We then introduce a new loss function to learn visual and
action embeddings by aligning the performed action with the representations of
two images extracted from the same clip. This permits the performed actions to
structure the latent visual representation. Our experiments show that our
method consistently outperforms previous methods on downstream category
recognition. In our analysis, we find that the observed improvement is
associated with a better viewpoint-wise alignment of different objects from the
same category. Overall, our work demonstrates that embodied interactions with
objects can improve SSL of object categories.",2024-07-09,"Arthur Aubret, Céline Teulière, Jochen Triesch",http://arxiv.org/pdf/2407.06704v2,cs.LG
HERMES: Holographic Equivariant neuRal network model for Mutational Effect and Stability prediction,"Predicting the stability and fitness effects of amino acid mutations in
proteins is a cornerstone of biological discovery and engineering. Various
experimental techniques have been developed to measure mutational effects,
providing us with extensive datasets across a diverse range of proteins. By
training on these data, traditional computational modeling and more recent
machine learning approaches have advanced significantly in predicting
mutational effects. Here, we introduce HERMES, a 3D rotationally equivariant
structure-based neural network model for mutational effect and stability
prediction. Pre-trained to predict amino acid propensity from its surrounding
3D structure, HERMES can be fine-tuned for mutational effects using our
open-source code. We present a suite of HERMES models, pre-trained with
different strategies, and fine-tuned to predict the stability effect of
mutations. Benchmarking against other models shows that HERMES often
outperforms or matches their performance in predicting mutational effect on
stability, binding, and fitness. HERMES offers versatile tools for evaluating
mutational effects and can be fine-tuned for specific predictive objectives.",2024-07-09,"Gian Marco Visani, Michael N. Pun, William Galvin, Eric Daniel, Kevin Borisiak, Utheri Wagura, Armita Nourmohammad",http://arxiv.org/pdf/2407.06703v1,cs.LG
"Generative AI for Health Technology Assessment: Opportunities, Challenges, and Policy Considerations","This review introduces the transformative potential of generative Artificial
Intelligence (AI) and foundation models, including large language models
(LLMs), for health technology assessment (HTA). We explore their applications
in four critical areas, evidence synthesis, evidence generation, clinical
trials and economic modeling: (1) Evidence synthesis: Generative AI has the
potential to assist in automating literature reviews and meta-analyses by
proposing search terms, screening abstracts, and extracting data with notable
accuracy; (2) Evidence generation: These models can potentially facilitate
automating the process and analyze the increasingly available large collections
of real-world data (RWD), including unstructured clinical notes and imaging,
enhancing the speed and quality of real-world evidence (RWE) generation; (3)
Clinical trials: Generative AI can be used to optimize trial design, improve
patient matching, and manage trial data more efficiently; and (4) Economic
modeling: Generative AI can also aid in the development of health economic
models, from conceptualization to validation, thus streamlining the overall HTA
process. Despite their promise, these technologies, while rapidly improving,
are still nascent and continued careful evaluation in their applications to HTA
is required. To ensure their responsible use and implementation, both
developers and users of research incorporating these tools, should familiarize
themselves with their current limitations, including the issues related to
scientific validity, risk of bias, and consider equity and ethical
implications. We also surveyed the current policy landscape and provide
suggestions for HTA agencies on responsibly integrating generative AI into
their workflows, emphasizing the importance of human oversight and the
fast-evolving nature of these tools.",2024-07-09,"Rachael Fleurence, Jiang Bian, Xiaoyan Wang, Hua Xu, Dalia Dawoud, Mitch Higashi, Jagpreet Chhatwal",http://arxiv.org/pdf/2407.11054v3,cs.LG
PSPU: Enhanced Positive and Unlabeled Learning by Leveraging Pseudo Supervision,"Positive and Unlabeled (PU) learning, a binary classification model trained
with only positive and unlabeled data, generally suffers from overfitted risk
estimation due to inconsistent data distributions. To address this, we
introduce a pseudo-supervised PU learning framework (PSPU), in which we train
the PU model first, use it to gather confident samples for the pseudo
supervision, and then apply these supervision to correct the PU model's weights
by leveraging non-PU objectives. We also incorporate an additional consistency
loss to mitigate noisy sample effects. Our PSPU outperforms recent PU learning
methods significantly on MNIST, CIFAR-10, CIFAR-100 in both balanced and
imbalanced settings, and enjoys competitive performance on MVTecAD for
industrial anomaly detection.",2024-07-09,"Chengjie Wang, Chengming Xu, Zhenye Gan, Jianlong Hu, Wenbing Zhu, Lizhuag Ma",http://arxiv.org/pdf/2407.06698v1,cs.LG
Certified Continual Learning for Neural Network Regression,"On the one hand, there has been considerable progress on neural network
verification in recent years, which makes certifying neural networks a
possibility. On the other hand, neural networks in practice are often
re-trained over time to cope with new data distribution or for solving
different tasks (a.k.a. continual learning). Once re-trained, the verified
correctness of the neural network is likely broken, particularly in the
presence of the phenomenon known as catastrophic forgetting. In this work, we
propose an approach called certified continual learning which improves existing
continual learning methods by preserving, as long as possible, the established
correctness properties of a verified network. Our approach is evaluated with
multiple neural networks and on two different continual learning methods. The
results show that our approach is efficient and the trained models preserve
their certified correctness and often maintain high utility.",2024-07-09,"Long H. Pham, Jun Sun",http://arxiv.org/pdf/2407.06697v1,cs.LG
Hierarchical Average-Reward Linearly-solvable Markov Decision Processes,"We introduce a novel approach to hierarchical reinforcement learning for
Linearly-solvable Markov Decision Processes (LMDPs) in the infinite-horizon
average-reward setting. Unlike previous work, our approach allows learning
low-level and high-level tasks simultaneously, without imposing limiting
restrictions on the low-level tasks. Our method relies on partitions of the
state space that create smaller subtasks that are easier to solve, and the
equivalence between such partitions to learn more efficiently. We then exploit
the compositionality of low-level tasks to exactly represent the value function
of the high-level task. Experiments show that our approach can outperform flat
average-reward reinforcement learning by one or several orders of magnitude.",2024-07-09,"Guillermo Infante, Anders Jonsson, Vicenç Gómez",http://arxiv.org/pdf/2407.06690v1,cs.LG
A Predictive Model Based on Transformer with Statistical Feature Embedding in Manufacturing Sensor Dataset,"In the manufacturing process, sensor data collected from equipment is crucial
for building predictive models to manage processes and improve productivity.
However, in the field, it is challenging to gather sufficient data to build
robust models. This study proposes a novel predictive model based on the
Transformer, utilizing statistical feature embedding and window positional
encoding. Statistical features provide an effective representation of sensor
data, and the embedding enables the Transformer to learn both time- and
sensor-related information. Window positional encoding captures precise time
details from the feature embedding. The model's performance is evaluated in two
problems: fault detection and virtual metrology, showing superior results
compared to baseline models. This improvement is attributed to the efficient
use of parameters, which is particularly beneficial for sensor data that often
has limited sample sizes. The results support the model's applicability across
various manufacturing industries, demonstrating its potential for enhancing
process management and yield.",2024-07-09,"Gyeong Taek Lee, Oh-Ran Kwon",http://arxiv.org/pdf/2407.06682v1,cs.LG
Accelerating Online Mapping and Behavior Prediction via Direct BEV Feature Attention,"Understanding road geometry is a critical component of the autonomous vehicle
(AV) stack. While high-definition (HD) maps can readily provide such
information, they suffer from high labeling and maintenance costs. Accordingly,
many recent works have proposed methods for estimating HD maps online from
sensor data. The vast majority of recent approaches encode multi-camera
observations into an intermediate representation, e.g., a bird's eye view (BEV)
grid, and produce vector map elements via a decoder. While this architecture is
performant, it decimates much of the information encoded in the intermediate
representation, preventing downstream tasks (e.g., behavior prediction) from
leveraging them. In this work, we propose exposing the rich internal features
of online map estimation methods and show how they enable more tightly
integrating online mapping with trajectory forecasting. In doing so, we find
that directly accessing internal BEV features yields up to 73% faster inference
speeds and up to 29% more accurate predictions on the real-world nuScenes
dataset.",2024-07-09,"Xunjiang Gu, Guanyu Song, Igor Gilitschenski, Marco Pavone, Boris Ivanovic",http://arxiv.org/pdf/2407.06683v1,cs.LG
Sampling and active learning methods for network reliability estimation using K-terminal spanning tree,"Network reliability analysis remains a challenge due to the increasing size
and complexity of networks. This paper presents a novel sampling method and an
active learning method for efficient and accurate network reliability
estimation under node failure and edge failure scenarios. The proposed sampling
method adopts Monte Carlo technique to sample component lifetimes and the
K-terminal spanning tree algorithm to accelerate structure function
computation. Unlike existing methods that compute only one structure function
value per sample, our method generates multiple component state vectors and
corresponding structure function values from each sample. Network reliability
is estimated based on survival signatures derived from these values. A
transformation technique extends this method to handle both node failure and
edge failure. To enhance efficiency of proposed sampling method and achieve
adaptability to network topology changes, we introduce an active learning
method utilizing a random forest (RF) classifier. This classifier directly
predicts structure function values, integrates network behaviors across diverse
topologies, and undergoes iterative refinement to enhance predictive accuracy.
Importantly, the trained RF classifier can directly predict reliability for
variant networks, a capability beyond the sampling method alone. Through
investigating several network examples and two practical applications, the
effectiveness of both proposed methods is demonstrated.",2024-07-09,"Chen Ding, Pengfei Wei, Yan Shi, Jinxing Liu, Matteo Broggi, Michael Beer",http://arxiv.org/pdf/2407.11053v1,cs.LG
Scaling Retrieval-Based Language Models with a Trillion-Token Datastore,"Scaling laws with respect to the amount of training data and the number of
parameters allow us to predict the cost-benefit trade-offs of pretraining
language models (LMs) in different configurations. In this paper, we consider
another dimension of scaling: the amount of data available at inference time.
Specifically, we find that increasing the size of the datastore used by a
retrieval-based LM monotonically improves language modeling and several
downstream tasks without obvious saturation, such that a smaller model
augmented with a large datastore outperforms a larger LM-only model on
knowledge-intensive tasks. By plotting compute-optimal scaling curves with
varied datastore, model, and pretraining data sizes, we show that using larger
datastores can significantly improve model performance for the same training
compute budget. We carry out our study by constructing a 1.4 trillion-token
datastore named MassiveDS, which is the largest and the most diverse
open-sourced datastore for retrieval-based LMs to date, and designing an
efficient pipeline for studying datastore scaling in a computationally
accessible manner. Finally, we analyze the effect of improving the retriever,
datastore quality filtering, and other design choices on our observed scaling
trends. Overall, our results show that datastore size should be considered as
an integral part of LM efficiency and performance trade-offs. To facilitate
future research, we open-source our datastore and code at
https://github.com/RulinShao/retrieval-scaling.",2024-07-09,"Rulin Shao, Jacqueline He, Akari Asai, Weijia Shi, Tim Dettmers, Sewon Min, Luke Zettlemoyer, Pang Wei Koh",http://arxiv.org/pdf/2407.12854v1,cs.LG
Across-subject ensemble-learning alleviates the need for large samples for fMRI decoding,"Decoding cognitive states from functional magnetic resonance imaging is
central to understanding the functional organization of the brain.
Within-subject decoding avoids between-subject correspondence problems but
requires large sample sizes to make accurate predictions; obtaining such large
sample sizes is both challenging and expensive. Here, we investigate an
ensemble approach to decoding that combines the classifiers trained on data
from other subjects to decode cognitive states in a new subject. We compare it
with the conventional decoding approach on five different datasets and
cognitive tasks. We find that it outperforms the conventional approach by up to
20% in accuracy, especially for datasets with limited per-subject data. The
ensemble approach is particularly advantageous when the classifier is trained
in voxel space. Furthermore, a Multi-layer Perceptron turns out to be a good
default choice as an ensemble method. These results show that the pre-training
strategy reduces the need for large per-subject data.",2024-07-09,"Himanshu Aggarwal, Liza Al-Shikhley, Bertrand Thirion",http://arxiv.org/pdf/2407.12056v1,cs.LG
Variational Learning ISTA,"Compressed sensing combines the power of convex optimization techniques with
a sparsity-inducing prior on the signal space to solve an underdetermined
system of equations. For many problems, the sparsifying dictionary is not
directly given, nor its existence can be assumed. Besides, the sensing matrix
can change across different scenarios. Addressing these issues requires solving
a sparse representation learning problem, namely dictionary learning, taking
into account the epistemic uncertainty of the learned dictionaries and,
finally, jointly learning sparse representations and reconstructions under
varying sensing matrix conditions. We address both concerns by proposing a
variant of the LISTA architecture. First, we introduce Augmented Dictionary
Learning ISTA (A-DLISTA), which incorporates an augmentation module to adapt
parameters to the current measurement setup. Then, we propose to learn a
distribution over dictionaries via a variational approach, dubbed Variational
Learning ISTA (VLISTA). VLISTA exploits A-DLISTA as the likelihood model and
approximates a posterior distribution over the dictionaries as part of an
unfolded LISTA-based recovery algorithm. As a result, VLISTA provides a
probabilistic way to jointly learn the dictionary distribution and the
reconstruction algorithm with varying sensing matrices. We provide theoretical
and experimental support for our architecture and show that our model learns
calibrated uncertainties.",2024-07-09,"Fabio Valerio Massoli, Christos Louizos, Arash Behboodi",http://arxiv.org/pdf/2407.06646v1,cs.LG
Entropy Law: The Story Behind Data Compression and LLM Performance,"Data is the cornerstone of large language models (LLMs), but not all data is
useful for model learning. Carefully selected data can better elicit the
capabilities of LLMs with much less computational overhead. Most methods
concentrate on evaluating the quality of individual samples in data selection,
while the combinatorial effects among samples are neglected. Even if each
sample is of perfect quality, their combinations may be suboptimal in teaching
LLMs due to their intrinsic homogeneity or contradiction. In this paper, we aim
to uncover the underlying relationships between LLM performance and data
selection. Inspired by the information compression nature of LLMs, we uncover
an ``entropy law'' that connects LLM performance with data compression ratio
and first-epoch training loss, which reflect the information redundancy of a
dataset and the mastery of inherent knowledge encoded in this dataset,
respectively. Through both theoretical deduction and empirical evaluation, we
find that model performance is negatively correlated to the compression ratio
of training data, which usually yields a lower training loss. Based on the
findings of the entropy law, we propose a quite efficient and universal data
selection method named \textbf{ZIP} for training LLMs, which aim to prioritize
data subsets exhibiting a low compression ratio. Based on a multi-stage
algorithm that selects diverse data in a greedy manner, we can obtain a good
data subset with satisfactory diversity. Extensive experiments have been
conducted to validate the entropy law and the superiority of ZIP across
different LLM backbones and alignment stages. We also present an interesting
application of entropy law that can detect potential performance risks at the
beginning of model training.",2024-07-09,"Mingjia Yin, Chuhan Wu, Yufei Wang, Hao Wang, Wei Guo, Yasheng Wang, Yong Liu, Ruiming Tang, Defu Lian, Enhong Chen",http://arxiv.org/pdf/2407.06645v3,cs.LG
Early Detection of Network Service Degradation: An Intra-Flow Approach,"This research presents a novel method for predicting service degradation (SD)
in computer networks by leveraging early flow features. Our approach focuses on
the observable (O) segments of network flows, particularly analyzing Packet
Inter-Arrival Time (PIAT) values and other derived metrics, to infer the
behavior of non-observable (NO) segments. Through a comprehensive evaluation,
we identify an optimal O/NO split threshold of 10 observed delay samples,
balancing prediction accuracy and resource utilization. Evaluating models
including Logistic Regression, XGBoost, and Multi-Layer Perceptron, we find
XGBoost outperforms others, achieving an F1-score of 0.74, balanced accuracy of
0.84, and AUROC of 0.97. Our findings highlight the effectiveness of
incorporating comprehensive early flow features and the potential of our method
to offer a practical solution for monitoring network traffic in
resource-constrained environments. This approach ensures enhanced user
experience and network performance by preemptively addressing potential SD,
providing the basis for a robust framework for maintaining high-quality network
services.",2024-07-09,"Balint Bicski, Adrian Pekar",http://arxiv.org/pdf/2407.06637v2,cs.LG
AI-based Automatic Segmentation of Prostate on Multi-modality Images: A Review,"Prostate cancer represents a major threat to health. Early detection is vital
in reducing the mortality rate among prostate cancer patients. One approach
involves using multi-modality (CT, MRI, US, etc.) computer-aided diagnosis
(CAD) systems for the prostate region. However, prostate segmentation is
challenging due to imperfections in the images and the prostate's complex
tissue structure. The advent of precision medicine and a significant increase
in clinical capacity have spurred the need for various data-driven tasks in the
field of medical imaging. Recently, numerous machine learning and data mining
tools have been integrated into various medical areas, including image
segmentation. This article proposes a new classification method that
differentiates supervision types, either in number or kind, during the training
phase. Subsequently, we conducted a survey on artificial intelligence
(AI)-based automatic prostate segmentation methods, examining the advantages
and limitations of each. Additionally, we introduce variants of evaluation
metrics for the verification and performance assessment of the segmentation
method and summarize the current challenges. Finally, future research
directions and development trends are discussed, reflecting the outcomes of our
literature survey, suggesting high-precision detection and treatment of
prostate cancer as a promising avenue.",2024-07-09,"Rui Jin, Derun Li, Dehui Xiang, Lei Zhang, Hailing Zhou, Fei Shi, Weifang Zhu, Jing Cai, Tao Peng, Xinjian Chen",http://arxiv.org/pdf/2407.06612v1,cs.LG
Iteratively Refined Image Reconstruction with Learned Attentive Regularizers,"We propose a regularization scheme for image reconstruction that leverages
the power of deep learning while hinging on classic sparsity-promoting models.
Many deep-learning-based models are hard to interpret and cumbersome to analyze
theoretically. In contrast, our scheme is interpretable because it corresponds
to the minimization of a series of convex problems. For each problem in the
series, a mask is generated based on the previous solution to refine the
regularization strength spatially. In this way, the model becomes progressively
attentive to the image structure. For the underlying update operator, we prove
the existence of a fixed point. As a special case, we investigate a mask
generator for which the fixed-point iterations converge to a critical point of
an explicit energy functional. In our experiments, we match the performance of
state-of-the-art learned variational models for the solution of inverse
problems. Additionally, we offer a promising balance between interpretability,
theoretical guarantees, reliability, and performance.",2024-07-09,"Mehrsa Pourya, Sebastian Neumayer, Michael Unser",http://arxiv.org/pdf/2407.06608v1,cs.LG
Solving General Natural-Language-Description Optimization Problems with Large Language Models,"Optimization problems seek to find the best solution to an objective under a
set of constraints, and have been widely investigated in real-world
applications. Modeling and solving optimization problems in a specific domain
typically require a combination of domain knowledge, mathematical skills, and
programming ability, making it difficult for general users and even domain
professionals. In this paper, we propose a novel framework called OptLLM that
augments LLMs with external solvers. Specifically, OptLLM accepts user queries
in natural language, convert them into mathematical formulations and
programming codes, and calls the solvers to calculate the results for
decision-making. In addition, OptLLM supports multi-round dialogues to
gradually refine the modeling and solving of optimization problems. To
illustrate the effectiveness of OptLLM, we provide tutorials on three typical
optimization applications and conduct experiments on both prompt-based GPT
models and a fine-tuned Qwen model using a large-scale selfdeveloped
optimization dataset. Experimental results show that OptLLM works with various
LLMs, and the fine-tuned model achieves an accuracy boost compared to the
promptbased models. Some features of OptLLM framework have been available for
trial since June 2023 (https://opt.alibabacloud.com/chat or
https://opt.aliyun.com/chat).",2024-07-09,"Jihai Zhang, Wei Wang, Siyan Guo, Li Wang, Fangquan Lin, Cheng Yang, Wotao Yin",http://arxiv.org/pdf/2407.07924v1,cs.LG
"Revisiting, Benchmarking and Understanding Unsupervised Graph Domain Adaptation","Unsupervised Graph Domain Adaptation (UGDA) involves the transfer of
knowledge from a label-rich source graph to an unlabeled target graph under
domain discrepancies. Despite the proliferation of methods designed for this
emerging task, the lack of standard experimental settings and fair performance
comparisons makes it challenging to understand which and when models perform
well across different scenarios. To fill this gap, we present the first
comprehensive benchmark for unsupervised graph domain adaptation named
GDABench, which encompasses 16 algorithms across 5 datasets with 74 adaptation
tasks. Through extensive experiments, we observe that the performance of
current UGDA models varies significantly across different datasets and
adaptation scenarios. Specifically, we recognize that when the source and
target graphs face significant distribution shifts, it is imperative to
formulate strategies to effectively address and mitigate graph structural
shifts. We also find that with appropriate neighbourhood aggregation
mechanisms, simple GNN variants can even surpass state-of-the-art UGDA
baselines. To facilitate reproducibility, we have developed an easy-to-use
library PyGDA for training and evaluating existing UGDA methods, providing a
standardized platform in this community. Our source codes and datasets can be
found at: https://github.com/pygda-team/pygda.",2024-07-09,"Meihan Liu, Zhen Zhang, Jiachen Tang, Jiajun Bu, Bingsheng He, Sheng Zhou",http://arxiv.org/pdf/2407.11052v2,cs.LG
AutoTask: Task Aware Multi-Faceted Single Model for Multi-Task Ads Relevance,"Ads relevance models are crucial in determining the relevance between user
search queries and ad offers, often framed as a classification problem. The
complexity of modeling increases significantly with multiple ad types and
varying scenarios that exhibit both similarities and differences. In this work,
we introduce a novel multi-faceted attention model that performs task aware
feature combination and cross task interaction modeling. Our technique
formulates the feature combination problem as ""language"" modeling with
auto-regressive attentions across both feature and task dimensions.
Specifically, we introduce a new dimension of task ID encoding for task
representations, thereby enabling precise relevance modeling across diverse ad
scenarios with substantial improvement in generality capability for unseen
tasks. We demonstrate that our model not only effectively handles the increased
computational and maintenance demands as scenarios proliferate, but also
outperforms generalized DNN models and even task-specific models across a
spectrum of ad applications using a single unified model.",2024-07-09,"Shouchang Guo, Sonam Damani, Keng-hao Chang",http://arxiv.org/pdf/2407.06549v1,cs.LG
Multiple Instance Verification,"We explore multiple-instance verification, a problem setting where a query
instance is verified against a bag of target instances with heterogeneous,
unknown relevancy. We show that naive adaptations of attention-based multiple
instance learning (MIL) methods and standard verification methods like Siamese
neural networks are unsuitable for this setting: directly combining
state-of-the-art (SOTA) MIL methods and Siamese networks is shown to be no
better, and sometimes significantly worse, than a simple baseline model.
Postulating that this may be caused by the failure of the representation of the
target bag to incorporate the query instance, we introduce a new pooling
approach named ``cross-attention pooling'' (CAP). Under the CAP framework, we
propose two novel attention functions to address the challenge of
distinguishing between highly similar instances in a target bag. Through
empirical studies on three different verification tasks, we demonstrate that
CAP outperforms adaptations of SOTA MIL methods and the baseline by substantial
margins, in terms of both classification accuracy and quality of the
explanations provided for the classifications. Ablation studies confirm the
superior ability of the new attention functions to identify key instances.",2024-07-09,"Xin Xu, Eibe Frank, Geoffrey Holmes",http://arxiv.org/pdf/2407.06544v1,cs.LG
DriftGAN: Using historical data for Unsupervised Recurring Drift Detection,"In real-world applications, input data distributions are rarely static over a
period of time, a phenomenon known as concept drift. Such concept drifts
degrade the model's prediction performance, and therefore we require methods to
overcome these issues. The initial step is to identify concept drifts and have
a training method in place to recover the model's performance. Most concept
drift detection methods work on detecting concept drifts and signalling the
requirement to retrain the model. However, in real-world cases, there could be
concept drifts that recur over a period of time. In this paper, we present an
unsupervised method based on Generative Adversarial Networks(GAN) to detect
concept drifts and identify whether a specific concept drift occurred in the
past. Our method reduces the time and data the model requires to get up to
speed for recurring drifts. Our key results indicate that our proposed model
can outperform the current state-of-the-art models in most datasets. We also
test our method on a real-world use case from astrophysics, where we detect the
bow shock and magnetopause crossings with better results than the existing
methods in the domain.",2024-07-09,"Christofer Fellicious, Sahib Julka, Lorenz Wendlinger, Michael Granitzer",http://arxiv.org/pdf/2407.06543v1,cs.LG
LETS-C: Leveraging Language Embedding for Time Series Classification,"Recent advancements in language modeling have shown promising results when
applied to time series data. In particular, fine-tuning pre-trained large
language models (LLMs) for time series classification tasks has achieved
state-of-the-art (SOTA) performance on standard benchmarks. However, these
LLM-based models have a significant drawback due to the large model size, with
the number of trainable parameters in the millions. In this paper, we propose
an alternative approach to leveraging the success of language modeling in the
time series domain. Instead of fine-tuning LLMs, we utilize a language
embedding model to embed time series and then pair the embeddings with a simple
classification head composed of convolutional neural networks (CNN) and
multilayer perceptron (MLP). We conducted extensive experiments on
well-established time series classification benchmark datasets. We demonstrated
LETS-C not only outperforms the current SOTA in classification accuracy but
also offers a lightweight solution, using only 14.5% of the trainable
parameters on average compared to the SOTA model. Our findings suggest that
leveraging language encoders to embed time series data, combined with a simple
yet effective classification head, offers a promising direction for achieving
high-performance time series classification while maintaining a lightweight
model architecture.",2024-07-09,"Rachneet Kaur, Zhen Zeng, Tucker Balch, Manuela Veloso",http://arxiv.org/pdf/2407.06533v1,cs.LG
Advanced Financial Fraud Detection Using GNN-CL Model,"The innovative GNN-CL model proposed in this paper marks a breakthrough in
the field of financial fraud detection by synergistically combining the
advantages of graph neural networks (gnn), convolutional neural networks (cnn)
and long short-term memory (LSTM) networks. This convergence enables
multifaceted analysis of complex transaction patterns, improving detection
accuracy and resilience against complex fraudulent activities. A key novelty of
this paper is the use of multilayer perceptrons (MLPS) to estimate node
similarity, effectively filtering out neighborhood noise that can lead to false
positives. This intelligent purification mechanism ensures that only the most
relevant information is considered, thereby improving the model's understanding
of the network structure. Feature weakening often plagues graph-based models
due to the dilution of key signals. In order to further address the challenge
of feature weakening, GNN-CL adopts reinforcement learning strategies. By
dynamically adjusting the weights assigned to central nodes, it reinforces the
importance of these influential entities to retain important clues of fraud
even in less informative data. Experimental evaluations on Yelp datasets show
that the results highlight the superior performance of GNN-CL compared to
existing methods.",2024-07-09,"Yu Cheng, Junjie Guo, Shiqing Long, You Wu, Mengfang Sun, Rong Zhang",http://arxiv.org/pdf/2407.06529v1,cs.LG
Graph Neural Networks and Deep Reinforcement Learning Based Resource Allocation for V2X Communications,"In the rapidly evolving landscape of Internet of Vehicles (IoV) technology,
Cellular Vehicle-to-Everything (C-V2X) communication has attracted much
attention due to its superior performance in coverage, latency, and throughput.
Resource allocation within C-V2X is crucial for ensuring the transmission of
safety information and meeting the stringent requirements for ultra-low latency
and high reliability in Vehicle-to-Vehicle (V2V) communication. This paper
proposes a method that integrates Graph Neural Networks (GNN) with Deep
Reinforcement Learning (DRL) to address this challenge. By constructing a
dynamic graph with communication links as nodes and employing the Graph Sample
and Aggregation (GraphSAGE) model to adapt to changes in graph structure, the
model aims to ensure a high success rate for V2V communication while minimizing
interference on Vehicle-to-Infrastructure (V2I) links, thereby ensuring the
successful transmission of V2V link information and maintaining high
transmission rates for V2I links. The proposed method retains the global
feature learning capabilities of GNN and supports distributed network
deployment, allowing vehicles to extract low-dimensional features that include
structural information from the graph network based on local observations and
to make independent resource allocation decisions. Simulation results indicate
that the introduction of GNN, with a modest increase in computational load,
effectively enhances the decision-making quality of agents, demonstrating
superiority to other methods. This study not only provides a theoretically
efficient resource allocation strategy for V2V and V2I communications but also
paves a new technical path for resource management in practical IoV
environments.",2024-07-09,"Maoxin Ji, Qiong Wu, Pingyi Fan, Nan Cheng, Wen Chen, Jiangzhou Wang, Khaled B. Letaief",http://arxiv.org/pdf/2407.06518v1,cs.LG
FedClust: Tackling Data Heterogeneity in Federated Learning through Weight-Driven Client Clustering,"Federated learning (FL) is an emerging distributed machine learning paradigm
that enables collaborative training of machine learning models over
decentralized devices without exposing their local data. One of the major
challenges in FL is the presence of uneven data distributions across client
devices, violating the well-known assumption of
independent-and-identically-distributed (IID) training samples in conventional
machine learning. To address the performance degradation issue incurred by such
data heterogeneity, clustered federated learning (CFL) shows its promise by
grouping clients into separate learning clusters based on the similarity of
their local data distributions. However, state-of-the-art CFL approaches
require a large number of communication rounds to learn the distribution
similarities during training until the formation of clusters is stabilized.
Moreover, some of these algorithms heavily rely on a predefined number of
clusters, thus limiting their flexibility and adaptability. In this paper, we
propose {\em FedClust}, a novel approach for CFL that leverages the correlation
between local model weights and the data distribution of clients. {\em
FedClust} groups clients into clusters in a one-shot manner by measuring the
similarity degrees among clients based on the strategically selected partial
weights of locally trained models. We conduct extensive experiments on four
benchmark datasets with different non-IID data settings. Experimental results
demonstrate that {\em FedClust} achieves higher model accuracy up to $\sim$45\%
as well as faster convergence with a significantly reduced communication cost
up to 2.7$\times$ compared to its state-of-the-art counterparts.",2024-07-09,"Md Sirajul Islam, Simin Javaherian, Fei Xu, Xu Yuan, Li Chen, Nian-Feng Tzeng",http://arxiv.org/pdf/2407.07124v1,cs.LG
Economic span selection of bridge based on deep reinforcement learning,"Deep Q-network algorithm is used to select economic span of bridge. Selection
of bridge span has a significant impact on the total cost of bridge, and a
reasonable selection of span can reduce engineering cost. Economic span of
bridge is theoretically analyzed, and the theoretical solution formula of
economic span is deduced. Construction process of bridge simulation environment
is described in detail, including observation space, action space and reward
function of the environment. Agent is constructed, convolutional neural network
is used to approximate Q function,{\epsilon} greedy policy is used for action
selection, and experience replay is used for training. The test verifies that
the agent can successfully learn optimal policy and realize economic span
selection of bridge. This study provides a potential decision-making tool for
bridge design.",2024-07-09,"Leye Zhang, Xiangxiang Tian, Chengli Zhang, Hongjun Zhang",http://arxiv.org/pdf/2407.06507v1,cs.LG
Preference-Guided Reinforcement Learning for Efficient Exploration,"In this paper, we investigate preference-based reinforcement learning (PbRL)
that allows reinforcement learning (RL) agents to learn from human feedback.
This is particularly valuable when defining a fine-grain reward function is not
feasible. However, this approach is inefficient and impractical for promoting
deep exploration in hard-exploration tasks with long horizons and sparse
rewards. To tackle this issue, we introduce LOPE: Learning Online with
trajectory Preference guidancE, an end-to-end preference-guided RL framework
that enhances exploration efficiency in hard-exploration tasks. Our intuition
is that LOPE directly adjusts the focus of online exploration by considering
human feedback as guidance, avoiding learning a separate reward model from
preferences. Specifically, LOPE includes a two-step sequential policy
optimization process consisting of trust-region-based policy improvement and
preference guidance steps. We reformulate preference guidance as a novel
trajectory-wise state marginal matching problem that minimizes the maximum mean
discrepancy distance between the preferred trajectories and the learned policy.
Furthermore, we provide a theoretical analysis to characterize the performance
improvement bound and evaluate the LOPE's effectiveness. When assessed in
various challenging hard-exploration environments, LOPE outperforms several
state-of-the-art methods regarding convergence rate and overall performance.
The code used in this study is available at
\url{https://github.com/buaawgj/LOPE}.",2024-07-09,"Guojian Wang, Faguo Wu, Xiao Zhang, Tianyuan Chen, Xuyang Chen, Lin Zhao",http://arxiv.org/pdf/2407.06503v1,cs.LG
It's Our Loss: No Privacy Amplification for Hidden State DP-SGD With Non-Convex Loss,"Differentially Private Stochastic Gradient Descent (DP-SGD) is a popular
iterative algorithm used to train machine learning models while formally
guaranteeing the privacy of users. However, the privacy analysis of DP-SGD
makes the unrealistic assumption that all intermediate iterates (aka internal
state) of the algorithm are released since, in practice, only the final trained
model, i.e., the final iterate of the algorithm is released. In this hidden
state setting, prior work has provided tighter analyses, albeit only when the
loss function is constrained, e.g., strongly convex and smooth or linear. On
the other hand, the privacy leakage observed empirically from hidden state
DP-SGD, even when using non-convex loss functions, suggests that there is in
fact a gap between the theoretical privacy analysis and the privacy guarantees
achieved in practice. Therefore, it remains an open question whether hidden
state privacy amplification for DP-SGD is possible for all (possibly
non-convex) loss functions in general.
  In this work, we design a counter-example and show, both theoretically and
empirically, that a hidden state privacy amplification result for DP-SGD for
all loss functions in general is not possible. By carefully constructing a loss
function for DP-SGD, we show that for specific loss functions, the final
iterate of DP-SGD alone leaks as much information as the sequence of all
iterates combined. Furthermore, we empirically verify this result by evaluating
the privacy leakage from the final iterate of DP-SGD with our loss function and
show that this exactly matches the theoretical upper bound guaranteed by DP.
Therefore, we show that the current privacy analysis for DP-SGD is tight for
general loss functions and conclude that no privacy amplification is possible
for DP-SGD in general for all (possibly non-convex) loss functions.",2024-07-09,Meenatchi Sundaram Muthu Selva Annamalai,http://arxiv.org/pdf/2407.06496v3,cs.LG
DiffPhyCon: A Generative Approach to Control Complex Physical Systems,"Controlling the evolution of complex physical systems is a fundamental task
across science and engineering. Classical techniques suffer from limited
applicability or huge computational costs. On the other hand, recent deep
learning and reinforcement learning-based approaches often struggle to optimize
long-term control sequences under the constraints of system dynamics. In this
work, we introduce Diffusion Physical systems Control (DiffPhyCon), a new class
of method to address the physical systems control problem. DiffPhyCon excels by
simultaneously minimizing both the learned generative energy function and the
predefined control objectives across the entire trajectory and control
sequence. Thus, it can explore globally and plan near-optimal control
sequences. Moreover, we enhance DiffPhyCon with prior reweighting, enabling the
discovery of control sequences that significantly deviate from the training
distribution. We test our method on three tasks: 1D Burgers' equation, 2D
jellyfish movement control, and 2D high-dimensional smoke control, where our
generated jellyfish dataset is released as a benchmark for complex physical
system control research. Our method outperforms widely applied classical
approaches and state-of-the-art deep learning and reinforcement learning
methods. Notably, DiffPhyCon unveils an intriguing fast-close-slow-open pattern
observed in the jellyfish, aligning with established findings in the field of
fluid dynamics. The project website, jellyfish dataset, and code can be found
at https://github.com/AI4Science-WestlakeU/diffphycon.",2024-07-09,"Long Wei, Peiyan Hu, Ruiqi Feng, Haodong Feng, Yixuan Du, Tao Zhang, Rui Wang, Yue Wang, Zhi-Ming Ma, Tailin Wu",http://arxiv.org/pdf/2407.06494v4,cs.LG
Automated Justification Production for Claim Veracity in Fact Checking: A Survey on Architectures and Approaches,"Automated Fact-Checking (AFC) is the automated verification of claim
accuracy. AFC is crucial in discerning truth from misinformation, especially
given the huge amounts of content are generated online daily. Current research
focuses on predicting claim veracity through metadata analysis and language
scrutiny, with an emphasis on justifying verdicts. This paper surveys recent
methodologies, proposing a comprehensive taxonomy and presenting the evolution
of research in that landscape. A comparative analysis of methodologies and
future directions for improving fact-checking explainability are also
discussed.",2024-07-09,"Islam Eldifrawi, Shengrui Wang, Amine Trabelsi",http://arxiv.org/pdf/2407.12853v1,cs.LG
Towards Understanding Multi-Task Learning (Generalization) of LLMs via Detecting and Exploring Task-Specific Neurons,"While large language models (LLMs) have demonstrated superior multi-task
capabilities, understanding the learning mechanisms behind this is still a
challenging problem. In this paper, we attempt to understand such mechanisms
from the perspective of neurons. Specifically, we detect task-sensitive neurons
in LLMs via gradient attribution on task-specific data. Through extensive
deactivation and fine-tuning experiments, we demonstrate that the detected
neurons are highly correlated with the given task, which we term as
task-specific neurons. With these identified task-specific neurons, we delve
into two common problems in multi-task learning and continuous learning:
Generalization and Catastrophic Forgetting. We find that the overlap of
task-specific neurons is strongly associated with generalization and
specialization across tasks. Interestingly, at certain layers of LLMs, there is
a high similarity in the parameters of different task-specific neurons, and
such similarity is highly correlated with the generalization performance.
Inspired by these findings, we propose a neuron-level continuous fine-tuning
method that only fine-tunes the current task-specific neurons during continuous
learning, and extensive experiments demonstrate the effectiveness of the
proposed method. Our study provides insights into the interpretability of LLMs
in multi-task learning.",2024-07-09,"Yongqi Leng, Deyi Xiong",http://arxiv.org/pdf/2407.06488v2,cs.LG
CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community,"Artificial Intelligence of Things (AIoT) is an emerging frontier based on the
deep fusion of Internet of Things (IoT) and Artificial Intelligence (AI)
technologies. Although advanced deep learning techniques enhance the efficient
data processing and intelligent analysis of complex IoT data, they still suffer
from notable challenges when deployed to practical AIoT applications, such as
constrained resources, and diverse task requirements. Knowledge transfer is an
effective method to enhance learning performance by avoiding the exorbitant
costs associated with data recollection and model retraining. Notably, although
there are already some valuable and impressive surveys on transfer learning,
these surveys introduce approaches in a relatively isolated way and lack the
recent advances of various knowledge transfer techniques for AIoT field. This
survey endeavors to introduce a new concept of knowledge transfer, referred to
as Crowd Knowledge Transfer (CrowdTransfer), which aims to transfer prior
knowledge learned from a crowd of agents to reduce the training cost and as
well as improve the performance of the model in real-world complicated
scenarios. Particularly, we present four transfer modes from the perspective of
crowd intelligence, including derivation, sharing, evolution and fusion modes.
Building upon conventional transfer learning methods, we further delve into
advanced crowd knowledge transfer models from three perspectives for various
AIoT applications. Furthermore, we explore some applications of AIoT areas,
such as human activity recognition, urban computing, multi-robot system, and
smart factory. Finally, we discuss the open issues and outline future research
directions of knowledge transfer in AIoT community.",2024-07-09,"Yan Liu, Bin Guo, Nuo Li, Yasan Ding, Zhouyangzi Zhang, Zhiwen Yu",http://arxiv.org/pdf/2407.06485v1,cs.LG
Composable Interventions for Language Models,"Test-time interventions for language models can enhance factual accuracy,
mitigate harmful outputs, and improve model efficiency without costly
retraining. But despite a flood of new methods, different types of
interventions are largely developing independently. In practice, multiple
interventions must be applied sequentially to the same model, yet we lack
standardized ways to study how interventions interact. We fill this gap by
introducing composable interventions, a framework to study the effects of using
multiple interventions on the same language models, featuring new metrics and a
unified codebase. Using our framework, we conduct extensive experiments and
compose popular methods from three emerging intervention categories --
Knowledge Editing, Model Compression, and Machine Unlearning. Our results from
310 different compositions uncover meaningful interactions: compression hinders
editing and unlearning, composing interventions hinges on their order of
application, and popular general-purpose metrics are inadequate for assessing
composability. Taken together, our findings showcase clear gaps in
composability, suggesting a need for new multi-objective interventions. All of
our code is public:
https://github.com/hartvigsen-group/composable-interventions.",2024-07-09,"Arinbjorn Kolbeinsson, Kyle O'Brien, Tianjin Huang, Shanghua Gao, Shiwei Liu, Jonathan Richard Schwarz, Anurag Vaidya, Faisal Mahmood, Marinka Zitnik, Tianlong Chen, Thomas Hartvigsen",http://arxiv.org/pdf/2407.06483v2,cs.LG
MolTRES: Improving Chemical Language Representation Learning for Molecular Property Prediction,"Chemical representation learning has gained increasing interest due to the
limited availability of supervised data in fields such as drug and materials
design. This interest particularly extends to chemical language representation
learning, which involves pre-training Transformers on SMILES sequences --
textual descriptors of molecules. Despite its success in molecular property
prediction, current practices often lead to overfitting and limited scalability
due to early convergence. In this paper, we introduce a novel chemical language
representation learning framework, called MolTRES, to address these issues.
MolTRES incorporates generator-discriminator training, allowing the model to
learn from more challenging examples that require structural understanding. In
addition, we enrich molecular representations by transferring knowledge from
scientific literature by integrating external materials embedding. Experimental
results show that our model outperforms existing state-of-the-art models on
popular molecular property prediction tasks.",2024-07-09,"Jun-Hyung Park, Yeachan Kim, Mingyu Lee, Hyuntae Park, SangKeun Lee",http://arxiv.org/pdf/2408.01426v1,cs.LG
Sinkhorn algorithms and linear programming solvers for optimal partial transport problems,"In this note, we generalize the classical optimal partial transport (OPT)
problem by modifying the mass destruction/creation term to function-based
terms, introducing what we term ``generalized optimal partial transport''
problems. We then discuss the dual formulation of these problems and the
associated Sinkhorn solver. Finally, we explore how these new OPT problems
relate to classical optimal transport (OT) problems and introduce a linear
programming solver tailored for these generalized scenarios.",2024-07-09,Yikun Bai,http://arxiv.org/pdf/2407.06481v1,cs.LG
How Much Progress Did I Make? An Unexplored Human Feedback Signal for Teaching Robots,"Enhancing the expressiveness of human teaching is vital for both improving
robots' learning from humans and the human-teaching-robot experience. In this
work, we characterize and test a little-used teaching signal:
\textit{progress}, designed to represent the completion percentage of a task.
We conducted two online studies with 76 crowd-sourced participants and one
public space study with 40 non-expert participants to validate the capability
of this progress signal. We find that progress indicates whether the task is
successfully performed, reflects the degree of task completion, identifies
unproductive but harmless behaviors, and is likely to be more consistent across
participants. Furthermore, our results show that giving progress does not
require extra workload and time. An additional contribution of our work is a
dataset of 40 non-expert demonstrations from the public space study through an
ice cream topping-adding task, which we observe to be multi-policy and
sub-optimal, with sub-optimality not only from teleoperation errors but also
from exploratory actions and attempts. The dataset is available at
\url{https://github.com/TeachingwithProgress/Non-Expert\_Demonstrations}.",2024-07-08,"Hang Yu, Qidi Fang, Shijie Fang, Reuben M. Aronson, Elaine Schaertl Short",http://arxiv.org/pdf/2407.06459v1,cs.LG
Geospatial Trajectory Generation via Efficient Abduction: Deployment for Independent Testing,"The ability to generate artificial human movement patterns while meeting
location and time constraints is an important problem in the security
community, particularly as it enables the study of the analog problem of
detecting such patterns while maintaining privacy. We frame this problem as an
instance of abduction guided by a novel parsimony function represented as an
aggregate truth value over an annotated logic program. This approach has the
added benefit of affording explainability to an analyst user. By showing that
any subset of such a program can provide a lower bound on this parsimony
requirement, we are able to abduce movement trajectories efficiently through an
informed (i.e., A*) search. We describe how our implementation was enhanced
with the application of multiple techniques in order to be scaled and
integrated with a cloud-based software stack that included bottom-up rule
learning, geolocated knowledge graph retrieval/management, and interfaces with
government systems for independently conducted government-run tests for which
we provide results. We also report on our own experiments showing that we not
only provide exact results but also scale to very large scenarios and provide
realistic agent trajectories that can go undetected by machine learning anomaly
detectors.",2024-07-08,"Divyagna Bavikadi, Dyuman Aditya, Devendra Parkar, Paulo Shakarian, Graham Mueller, Chad Parvis, Gerardo I. Simari",http://arxiv.org/pdf/2407.06447v2,cs.LG
SOLO: A Single Transformer for Scalable Vision-Language Modeling,"We present SOLO, a single transformer for Scalable visiOn-Language mOdeling.
Current large vision-language models (LVLMs) such as LLaVA mostly employ
heterogeneous architectures that connect pre-trained visual encoders with large
language models (LLMs) to facilitate visual recognition and complex reasoning.
Although achieving remarkable performance with relatively lightweight training,
we identify four primary scalability limitations: (1) The visual capacity is
constrained by pre-trained visual encoders, which are typically an order of
magnitude smaller than LLMs. (2) The heterogeneous architecture complicates the
use of established hardware and software infrastructure. (3) Study of scaling
laws on such architecture must consider three separate components - visual
encoder, connector, and LLMs, which complicates the analysis. (4) The use of
existing visual encoders typically requires following a pre-defined
specification of image inputs pre-processing, for example, by reshaping inputs
to fixed-resolution square images, which presents difficulties in processing
and training on high-resolution images or those with unusual aspect ratio. A
unified single Transformer architecture, like SOLO, effectively addresses these
scalability concerns in LVLMs; however, its limited adoption in the modern
context likely stems from the absence of reliable training recipes that balance
both modalities and ensure stable training for billion-scale models. In this
paper, we introduce the first open-source training recipe for developing SOLO,
an open-source 7B LVLM using moderate academic resources. The training recipe
involves initializing from LLMs, sequential pre-training on ImageNet and
web-scale data, and instruction fine-tuning on our curated high-quality
datasets. On extensive evaluation, SOLO demonstrates performance comparable to
LLaVA-v1.5-7B, particularly excelling in visual mathematical reasoning.",2024-07-08,"Yangyi Chen, Xingyao Wang, Hao Peng, Heng Ji",http://arxiv.org/pdf/2407.06438v3,cs.LG
System stabilization with policy optimization on unstable latent manifolds,"Stability is a basic requirement when studying the behavior of dynamical
systems. However, stabilizing dynamical systems via reinforcement learning is
challenging because only little data can be collected over short time horizons
before instabilities are triggered and data become meaningless. This work
introduces a reinforcement learning approach that is formulated over latent
manifolds of unstable dynamics so that stabilizing policies can be trained from
few data samples. The unstable manifolds are minimal in the sense that they
contain the lowest dimensional dynamics that are necessary for learning
policies that guarantee stabilization. This is in stark contrast to generic
latent manifolds that aim to approximate all -- stable and unstable -- system
dynamics and thus are higher dimensional and often require higher amounts of
data. Experiments demonstrate that the proposed approach stabilizes even
complex physical systems from few data samples for which other methods that
operate either directly in the system state space or on generic latent
manifolds fail.",2024-07-08,"Steffen W. R. Werner, Benjamin Peherstorfer",http://arxiv.org/pdf/2407.06418v1,cs.LG
"If You Don't Understand It, Don't Use It: Eliminating Trojans with Filters Between Layers","Large language models (LLMs) sometimes exhibit dangerous unintended
behaviors. Finding and fixing these is challenging because the attack surface
is massive -- it is not tractable to exhaustively search for all possible
inputs that may elicit such behavior. One specific and particularly challenging
case is that if data-poisoning-injected trojans, since there is no way to know
what they are to search for them. To our knowledge, there is no generally
applicable method to unlearn unknown trojans injected during pre-training. This
work seeks to provide a general purpose recipe (filters) and a specific
implementation (LoRA) filters that work in practice on small to medium sized
models. The focus is primarily empirical, though some perplexing behavior opens
the door to the fundamental question of how LLMs store and process information.
Not unexpectedly, we find that our filters work best on the residual stream and
the latest layers.",2024-07-08,Adriano Hernandez,http://arxiv.org/pdf/2407.06411v1,cs.LG
JANET: Joint Adaptive predictioN-region Estimation for Time-series,"Conformal prediction provides machine learning models with prediction sets
that offer theoretical guarantees, but the underlying assumption of
exchangeability limits its applicability to time series data. Furthermore,
existing approaches struggle to handle multi-step ahead prediction tasks, where
uncertainty estimates across multiple future time points are crucial. We
propose JANET (Joint Adaptive predictioN-region Estimation for Time-series), a
novel framework for constructing conformal prediction regions that are valid
for both univariate and multivariate time series. JANET generalises the
inductive conformal framework and efficiently produces joint prediction regions
with controlled K-familywise error rates, enabling flexible adaptation to
specific application needs. Our empirical evaluation demonstrates JANET's
superior performance in multi-step prediction tasks across diverse time series
datasets, highlighting its potential for reliable and interpretable uncertainty
quantification in sequential data.",2024-07-08,"Eshant English, Eliot Wong-Toi, Matteo Fontana, Stephan Mandt, Padhraic Smyth, Christoph Lippert",http://arxiv.org/pdf/2407.06390v1,cs.LG
Non-Robust Features are Not Always Useful in One-Class Classification,"The robustness of machine learning models has been questioned by the
existence of adversarial examples. We examine the threat of adversarial
examples in practical applications that require lightweight models for
one-class classification. Building on Ilyas et al. (2019), we investigate the
vulnerability of lightweight one-class classifiers to adversarial attacks and
possible reasons for it. Our results show that lightweight one-class
classifiers learn features that are not robust (e.g. texture) under stronger
attacks. However, unlike in multi-class classification (Ilyas et al., 2019),
these non-robust features are not always useful for the one-class task,
suggesting that learning these unpredictive and non-robust features is an
unwanted consequence of training.",2024-07-08,"Matthew Lau, Haoran Wang, Alec Helbling, Matthew Hul, ShengYun Peng, Martin Andreoni, Willian T. Lunardi, Wenke Lee",http://arxiv.org/pdf/2407.06372v1,cs.LG
High-Dimensional Distributed Sparse Classification with Scalable Communication-Efficient Global Updates,"As the size of datasets used in statistical learning continues to grow,
distributed training of models has attracted increasing attention. These
methods partition the data and exploit parallelism to reduce memory and
runtime, but suffer increasingly from communication costs as the data size or
the number of iterations grows. Recent work on linear models has shown that a
surrogate likelihood can be optimized locally to iteratively improve on an
initial solution in a communication-efficient manner. However, existing
versions of these methods experience multiple shortcomings as the data size
becomes massive, including diverging updates and efficiently handling sparsity.
In this work we develop solutions to these problems which enable us to learn a
communication-efficient distributed logistic regression model even beyond
millions of features. In our experiments we demonstrate a large improvement in
accuracy over distributed algorithms with only a few distributed update steps
needed, and similar or faster runtimes. Our code is available at
\url{https://github.com/FutureComputing4AI/ProxCSL}.",2024-07-08,"Fred Lu, Ryan R. Curtin, Edward Raff, Francis Ferraro, James Holt",http://arxiv.org/pdf/2407.06346v1,cs.LG
Novel Models for High-Dimensional Imaging: High-Resolution fMRI Acceleration and Quantification,"The goals of functional Magnetic Resonance Imaging (fMRI) include high
spatial and temporal resolutions with a high signal-to-noise ratio (SNR). To
simultaneously improve spatial and temporal resolutions and maintain the high
SNR advantage of OSSI, we present novel pipelines for fast acquisition and
high-resolution fMRI reconstruction and physics parameter quantification. We
propose a patch-tensor low-rank model, a physics-based manifold model, and a
voxel-wise attention network. With novel models for acquisition and
reconstruction, we demonstrate that we can improve SNR and resolution
simultaneously without compromising scan time. All the proposed models
outperform other comparison approaches with higher resolution and more
functional information.",2024-07-08,Shouchang Guo,http://arxiv.org/pdf/2407.06343v1,cs.LG
A third-order finite difference weighted essentially non-oscillatory scheme with shallow neural network,"In this paper, we introduce the finite difference weighted essentially
non-oscillatory (WENO) scheme based on the neural network for hyperbolic
conservation laws. We employ the supervised learning and design two loss
functions, one with the mean squared error and the other with the mean squared
logarithmic error, where the WENO3-JS weights are computed as the labels. Each
loss function consists of two components where the first component compares the
difference between the weights from the neural network and WENO3-JS weights,
while the second component matches the output weights of the neural network and
the linear weights. The former of the loss function enforces the neural network
to follow the WENO properties, implying that there is no need for the
post-processing layer. Additionally the latter leads to better performance
around discontinuities. As a neural network structure, we choose the shallow
neural network (SNN) for computational efficiency with the Delta layer
consisting of the normalized undivided differences. These constructed WENO3-SNN
schemes show the outperformed results in one-dimensional examples and improved
behavior in two-dimensional examples, compared with the simulations from
WENO3-JS and WENO3-Z.",2024-07-08,"Kwanghyuk Park, Xinjuan Chen, Dongjin Lee, Jiaxi Gu, Jae-Hun Jung",http://arxiv.org/pdf/2407.06333v2,cs.LG
Solving Multi-Model MDPs by Coordinate Ascent and Dynamic Programming,"Multi-model Markov decision process (MMDP) is a promising framework for
computing policies that are robust to parameter uncertainty in MDPs. MMDPs aim
to find a policy that maximizes the expected return over a distribution of MDP
models. Because MMDPs are NP-hard to solve, most methods resort to
approximations. In this paper, we derive the policy gradient of MMDPs and
propose CADP, which combines a coordinate ascent method and a dynamic
programming algorithm for solving MMDPs. The main innovation of CADP compared
with earlier algorithms is to take the coordinate ascent perspective to adjust
model weights iteratively to guarantee monotone policy improvements to a local
maximum. A theoretical analysis of CADP proves that it never performs worse
than previous dynamic programming algorithms like WSU. Our numerical results
indicate that CADP substantially outperforms existing methods on several
benchmark problems.",2024-07-08,"Xihong Su, Marek Petrik",http://arxiv.org/pdf/2407.06329v1,cs.LG
CONGO: Compressive Online Gradient Optimization,"We address the challenge of zeroth-order online convex optimization where the
objective function's gradient exhibits sparsity, indicating that only a small
number of dimensions possess non-zero gradients. Our aim is to leverage this
sparsity to obtain useful estimates of the objective function's gradient even
when the only information available is a limited number of function samples.
Our motivation stems from the optimization of large-scale queueing networks
that process time-sensitive jobs. Here, a job must be processed by potentially
many queues in sequence to produce an output, and the service time at any queue
is a function of the resources allocated to that queue. Since resources are
costly, the end-to-end latency for jobs must be balanced with the overall cost
of the resources used. While the number of queues is substantial, the latency
function primarily reacts to resource changes in only a few, rendering the
gradient sparse. We tackle this problem by introducing the Compressive Online
Gradient Optimization framework which allows compressive sensing methods
previously applied to stochastic optimization to achieve regret bounds with an
optimal dependence on the time horizon without the full problem dimension
appearing in the bound. For specific algorithms, we reduce the samples required
per gradient estimate to scale with the gradient's sparsity factor rather than
its full dimensionality. Numerical simulations and real-world microservices
benchmarks demonstrate CONGO's superiority over gradient descent approaches
that do not account for sparsity.",2024-07-08,"Jeremy Carleton, Prathik Vijaykumar, Divyanshu Saxena, Dheeraj Narasimha, Srinivas Shakkottai, Aditya Akella",http://arxiv.org/pdf/2407.06325v4,cs.LG
B'MOJO: Hybrid State Space Realizations of Foundation Models with Eidetic and Fading Memory,"We describe a family of architectures to support transductive inference by
allowing memory to grow to a finite but a-priori unknown bound while making
efficient use of finite resources for inference. Current architectures use such
resources to represent data either eidetically over a finite span (""context"" in
Transformers), or fading over an infinite span (in State Space Models, or
SSMs). Recent hybrid architectures have combined eidetic and fading memory, but
with limitations that do not allow the designer or the learning process to
seamlessly modulate the two, nor to extend the eidetic memory span. We leverage
ideas from Stochastic Realization Theory to develop a class of models called
B'MOJO to seamlessly combine eidetic and fading memory within an elementary
composable module. The overall architecture can be used to implement models
that can access short-term eidetic memory ""in-context,"" permanent structural
memory ""in-weights,"" fading memory ""in-state,"" and long-term eidetic memory
""in-storage"" by natively incorporating retrieval from an asynchronously updated
memory. We show that Transformers, existing SSMs such as Mamba, and hybrid
architectures such as Jamba are special cases of B'MOJO and describe a basic
implementation, to be open sourced, that can be stacked and scaled efficiently
in hardware. We test B'MOJO on transductive inference tasks, such as
associative recall, where it outperforms existing SSMs and Hybrid models; as a
baseline, we test ordinary language modeling where B'MOJO achieves perplexity
comparable to similarly-sized Transformers and SSMs up to 1.4B parameters,
while being up to 10% faster to train. Finally, we show that B'MOJO's ability
to modulate eidetic and fading memory results in better inference on longer
sequences tested up to 32K tokens, four-fold the length of the longest
sequences seen during training.",2024-07-08,"Luca Zancato, Arjun Seshadri, Yonatan Dukler, Aditya Golatkar, Yantao Shen, Benjamin Bowman, Matthew Trager, Alessandro Achille, Stefano Soatto",http://arxiv.org/pdf/2407.06324v1,cs.LG
Graph Neural Networks and Spatial Information Learning for Post-Processing Ensemble Weather Forecasts,"Ensemble forecasts from numerical weather prediction models show systematic
errors that require correction via post-processing. While there has been
substantial progress in flexible neural network-based post-processing methods
over the past years, most station-based approaches still treat every input data
point separately which limits the capabilities for leveraging spatial
structures in the forecast errors. In order to improve information sharing
across locations, we propose a graph neural network architecture for ensemble
post-processing, which represents the station locations as nodes on a graph and
utilizes an attention mechanism to identify relevant predictive information
from neighboring locations. In a case study on 2-m temperature forecasts over
Europe, the graph neural network model shows substantial improvements over a
highly competitive neural network-based post-processing method.",2024-07-08,"Moritz Feik, Sebastian Lerch, Jan Stühmer",http://arxiv.org/pdf/2407.11050v1,cs.LG
MagMax: Leveraging Model Merging for Seamless Continual Learning,"This paper introduces a continual learning approach named MagMax, which
utilizes model merging to enable large pre-trained models to continuously learn
from new data without forgetting previously acquired knowledge. Distinct from
traditional continual learning methods that aim to reduce forgetting during
task training, MagMax combines sequential fine-tuning with a maximum magnitude
weight selection for effective knowledge integration across tasks. Our initial
contribution is an extensive examination of model merging techniques, revealing
that simple approaches like weight averaging and random weight selection
surprisingly hold up well in various continual learning contexts. More
importantly, we present MagMax, a novel model-merging strategy that enables
continual learning of large pre-trained models for successive tasks. Our
thorough evaluation demonstrates the superiority of MagMax in various
scenarios, including class- and domain-incremental learning settings. The code
is available at this URL: https://github.com/danielm1405/magmax.",2024-07-08,"Daniel Marczak, Bartłomiej Twardowski, Tomasz Trzciński, Sebastian Cygert",http://arxiv.org/pdf/2407.06322v2,cs.LG
Open Problem: Tight Bounds for Kernelized Multi-Armed Bandits with Bernoulli Rewards,"We consider Kernelized Bandits (KBs) to optimize a function $f : \mathcal{X}
\rightarrow [0,1]$ belonging to the Reproducing Kernel Hilbert Space (RKHS)
$\mathcal{H}_k$. Mainstream works on kernelized bandits focus on a subgaussian
noise model in which observations of the form $f(\mathbf{x}_t)+\epsilon_t$,
being $\epsilon_t$ a subgaussian noise, are available (Chowdhury and Gopalan,
2017). Differently, we focus on the case in which we observe realizations $y_t
\sim \text{Ber}(f(\mathbf{x}_t))$ sampled from a Bernoulli distribution with
parameter $f(\mathbf{x}_t)$. While the Bernoulli model has been investigated
successfully in multi-armed bandits (Garivier and Capp\'e, 2011), logistic
bandits (Faury et al., 2022), bandits in metric spaces (Magureanu et al.,
2014), it remains an open question whether tight results can be obtained for
KBs. This paper aims to draw the attention of the online learning community to
this open problem.",2024-07-08,"Marco Mussi, Simone Drago, Alberto Maria Metelli",http://arxiv.org/pdf/2407.06321v1,cs.LG
Shedding More Light on Robust Classifiers under the lens of Energy-based Models,"By reinterpreting a robust discriminative classifier as Energy-based Model
(EBM), we offer a new take on the dynamics of adversarial training (AT). Our
analysis of the energy landscape during AT reveals that untargeted attacks
generate adversarial images much more in-distribution (lower energy) than the
original data from the point of view of the model. Conversely, we observe the
opposite for targeted attacks. On the ground of our thorough analysis, we
present new theoretical and practical results that show how interpreting AT
energy dynamics unlocks a better understanding: (1) AT dynamic is governed by
three phases and robust overfitting occurs in the third phase with a drastic
divergence between natural and adversarial energies (2) by rewriting the loss
of TRadeoff-inspired Adversarial DEfense via Surrogate-loss minimization
(TRADES) in terms of energies, we show that TRADES implicitly alleviates
overfitting by means of aligning the natural energy with the adversarial one
(3) we empirically show that all recent state-of-the-art robust classifiers are
smoothing the energy landscape and we reconcile a variety of studies about
understanding AT and weighting the loss function under the umbrella of EBMs.
Motivated by rigorous evidence, we propose Weighted Energy Adversarial Training
(WEAT), a novel sample weighting scheme that yields robust accuracy matching
the state-of-the-art on multiple benchmarks such as CIFAR-10 and SVHN and going
beyond in CIFAR-100 and Tiny-ImageNet. We further show that robust classifiers
vary in the intensity and quality of their generative capabilities, and offer a
simple method to push this capability, reaching a remarkable Inception Score
(IS) and FID using a robust classifier without training for generative
modeling. The code to reproduce our results is available at
http://github.com/OmnAI-Lab/Robust-Classifiers-under-the-lens-of-EBM/ .",2024-07-08,"Mujtaba Hussain Mirza, Maria Rosaria Briglia, Senad Beadini, Iacopo Masi",http://arxiv.org/pdf/2407.06315v3,cs.LG
Limits and Powers of Koopman Learning,"Dynamical systems provide a comprehensive way to study complex and changing
behaviors across various sciences. Many modern systems are too complicated to
analyze directly or we do not have access to models, driving significant
interest in learning methods. Koopman operators have emerged as a dominant
approach because they allow the study of nonlinear dynamics using linear
techniques by solving an infinite-dimensional spectral problem. However,
current algorithms face challenges such as lack of convergence, hindering
practical progress. This paper addresses a fundamental open question:
\textit{When can we robustly learn the spectral properties of Koopman operators
from trajectory data of dynamical systems, and when can we not?} Understanding
these boundaries is crucial for analysis, applications, and designing
algorithms. We establish a foundational approach that combines computational
analysis and ergodic theory, revealing the first fundamental barriers --
universal for any algorithm -- associated with system geometry and complexity,
regardless of data quality and quantity. For instance, we demonstrate
well-behaved smooth dynamical systems on tori where non-trivial eigenfunctions
of the Koopman operator cannot be determined by any sequence of (even
randomized) algorithms, even with unlimited training data. Additionally, we
identify when learning is possible and introduce optimal algorithms with
verification that overcome issues in standard methods. These results pave the
way for a sharp classification theory of data-driven dynamical systems based on
how many limits are needed to solve a problem. These limits characterize all
previous methods, presenting a unified view. Our framework systematically
determines when and how Koopman spectral properties can be learned.",2024-07-08,"Matthew J. Colbrook, Igor Mezić, Alexei Stepanenko",http://arxiv.org/pdf/2407.06312v1,cs.LG
Homogeneous Speaker Features for On-the-Fly Dysarthric and Elderly Speaker Adaptation,"The application of data-intensive automatic speech recognition (ASR)
technologies to dysarthric and elderly adult speech is confronted by their
mismatch against healthy and nonaged voices, data scarcity and large
speaker-level variability. To this end, this paper proposes two novel
data-efficient methods to learn homogeneous dysarthric and elderly
speaker-level features for rapid, on-the-fly test-time adaptation of DNN/TDNN
and Conformer ASR models. These include: 1) speaker-level variance-regularized
spectral basis embedding (VR-SBE) features that exploit a special
regularization term to enforce homogeneity of speaker features in adaptation;
and 2) feature-based learning hidden unit contributions (f-LHUC) transforms
that are conditioned on VR-SBE features. Experiments are conducted on four
tasks across two languages: the English UASpeech and TORGO dysarthric speech
datasets, the English DementiaBank Pitt and Cantonese JCCOCC MoCA elderly
speech corpora. The proposed on-the-fly speaker adaptation techniques
consistently outperform baseline iVector and xVector adaptation by
statistically significant word or character error rate reductions up to 5.32%
absolute (18.57% relative) and batch-mode LHUC speaker adaptation by 2.24%
absolute (9.20% relative), while operating with real-time factors speeding up
to 33.6 times against xVectors during adaptation. The efficacy of the proposed
adaptation techniques is demonstrated in a comparison against current ASR
technologies including SSL pre-trained systems on UASpeech, where our best
system produces a state-of-the-art WER of 23.33%. Analyses show VR-SBE features
and f-LHUC transforms are insensitive to speaker-level data quantity in
testtime adaptation. T-SNE visualization reveals they have stronger
speaker-level homogeneity than baseline iVectors, xVectors and batch-mode LHUC
transforms.",2024-07-08,"Mengzhe Geng, Xurong Xie, Jiajun Deng, Zengrui Jin, Guinan Li, Tianzi Wang, Shujie Hu, Zhaoqing Li, Helen Meng, Xunying Liu",http://arxiv.org/pdf/2407.06310v1,cs.LG
Unsupervised Fault Detection using SAM with a Moving Window Approach,"Automated f ault detection and monitoring in engineering are critical but
frequently difficult owing to the necessity for collecting and labeling large
amounts of defective samples . We present an unsupervised method that uses the
high end Segment Anything Model (SAM) and a moving window approach. SAM has
gained recognition in AI image segmentation communities for its accuracy and
versatility. However, its performance can be inconsistent when dealing with
certain unexpected shapes , such as shadows and subtle surface irregularities.
This limitation raise s concerns about its applicability for fault detection in
real world scenarios We aim to overcome these challenges without requiring fine
tun ing or labeled data. Our technique divides pictures into smaller windows,
which are subsequently processed using SAM. This increases the accuracy of
fault identification by focusing on localized details. We compute the sizes of
the segmented sections and then us e a clustering technique to discover
consistent fault areas while filtering out noise. To further improve the
method's robustness , we propose adding the Exponentially Weighted Moving
Average (EWMA) technique for continuous monitoring in industrial settings,
which would improve the method's capacity to trace faults over time. We compare
our method to various well established methods u sing a real case study where
our model achieve s 0.96 accuracy compared to 0. 8 5 for the second best
method. W e also compare our method us ing two open source datasets where our
model attains a consistent 0. 86 accuracy across the datasets compared to 0.53
and 0.54 for second best model s.",2024-07-08,"Ahmed Maged, Herman Shen",http://arxiv.org/pdf/2407.06303v1,cs.LG
Accelerating Drug Safety Assessment using Bidirectional-LSTM for SMILES Data,"Computational methods are useful in accelerating the pace of drug discovery.
Drug discovery carries several steps such as target identification and
validation, lead discovery, and lead optimisation etc., In the phase of lead
optimisation, the absorption, distribution, metabolism, excretion, and toxicity
properties of lead compounds are assessed. To address the issue of predicting
toxicity and solubility in the lead compounds, represented in Simplified
Molecular Input Line Entry System (SMILES) notation. Among the different
approaches that work on SMILES data, the proposed model was built using a
sequence-based approach. The proposed Bi-Directional Long Short Term Memory
(BiLSTM) is a variant of Recurrent Neural Network (RNN) that processes input
molecular sequences for the comprehensive examination of the structural
features of molecules from both forward and backward directions. The proposed
work aims to understand the sequential patterns encoded in the SMILES strings,
which are then utilised for predicting the toxicity of the molecules. The
proposed model on the ClinTox dataset surpasses previous approaches such as
Trimnet and Pre-training Graph neural networks(GNN) by achieving a ROC accuracy
of 0.96. BiLSTM outperforms the previous model on FreeSolv dataset with a low
RMSE value of 1.22 in solubility prediction.",2024-07-08,"K. Venkateswara Rao, Kunjam Nageswara Rao, G. Sita Ratnam",http://arxiv.org/pdf/2407.18919v1,cs.LG
Multi-Label Plant Species Classification with Self-Supervised Vision Transformers,"We present a transfer learning approach using a self-supervised Vision
Transformer (DINOv2) for the PlantCLEF 2024 competition, focusing on the
multi-label plant species classification. Our method leverages both base and
fine-tuned DINOv2 models to extract generalized feature embeddings. We train
classifiers to predict multiple plant species within a single image using these
rich embeddings. To address the computational challenges of the large-scale
dataset, we employ Spark for distributed data processing, ensuring efficient
memory management and processing across a cluster of workers. Our data
processing pipeline transforms images into grids of tiles, classifying each
tile, and aggregating these predictions into a consolidated set of
probabilities. Our results demonstrate the efficacy of combining transfer
learning with advanced data processing techniques for multi-label image
classification tasks. Our code is available at
https://github.com/dsgt-kaggle-clef/plantclef-2024.",2024-07-08,"Murilo Gustineli, Anthony Miyaguchi, Ian Stalter",http://arxiv.org/pdf/2407.06298v1,cs.LG
Engineering morphogenesis of cell clusters with differentiable programming,"Understanding the rules underlying organismal development is a major unsolved
problem in biology. Each cell in a developing organism responds to signals in
its local environment by dividing, excreting, consuming, or reorganizing, yet
how these individual actions coordinate over a macroscopic number of cells to
grow complex structures with exquisite functionality is unknown. Here we use
recent advances in automatic differentiation to discover local interaction
rules and genetic networks that yield emergent, systems-level characteristics
in a model of development. We consider a growing tissue with cellular
interactions mediated by morphogen diffusion, cell adhesion and mechanical
stress. Each cell has an internal genetic network that is used to make
decisions based on the cell's local environment. We show that one can learn the
parameters governing cell interactions in the form of interpretable genetic
networks for complex developmental scenarios, including directed axial
elongation, cell type homeostasis via chemical signaling and homogenization of
growth via mechanical stress. When combined with recent experimental advances
measuring spatio-temporal dynamics and gene expression of cells in a growing
tissue, the methodology outlined here offers a promising path to unraveling the
cellular bases of development.",2024-07-08,"Ramya Deshpande, Francesco Mottes, Ariana-Dalia Vlad, Michael P. Brenner, Alma dal Co",http://arxiv.org/pdf/2407.06295v3,cs.LG
Characterization of topological structures in different neural network architectures,"One of the most crucial tasks in the future will be to understand what is
going on in neural networks, as they will become even more powerful and widely
deployed. This work aims to use TDA methods to analyze neural representations.
We develop methods for analyzing representations from different architectures
and check how one should use them to obtain valid results. Our findings
indicate that removing outliers does not have much impact on the results and
that we should compare representations with the same number of elements. We
applied these methods for ResNet, VGG19, and ViT architectures and found
substantial differences along with some similarities. Additionally, we
determined that models with similar architecture tend to have a similar
topology of representations and models with a larger number of layers change
their topology more smoothly. Furthermore, we found that the topology of
pre-trained and finetuned models starts to differ in the middle and final
layers while remaining quite similar in the initial layers. These findings
demonstrate the efficacy of TDA in the analysis of neural network behavior.",2024-07-08,Paweł Świder,http://arxiv.org/pdf/2407.06286v1,cs.LG
4D Contrastive Superflows are Dense 3D Representation Learners,"In the realm of autonomous driving, accurate 3D perception is the foundation.
However, developing such models relies on extensive human annotations -- a
process that is both costly and labor-intensive. To address this challenge from
a data representation learning perspective, we introduce SuperFlow, a novel
framework designed to harness consecutive LiDAR-camera pairs for establishing
spatiotemporal pretraining objectives. SuperFlow stands out by integrating two
key designs: 1) a dense-to-sparse consistency regularization, which promotes
insensitivity to point cloud density variations during feature learning, and 2)
a flow-based contrastive learning module, carefully crafted to extract
meaningful temporal cues from readily available sensor calibrations. To further
boost learning efficiency, we incorporate a plug-and-play view consistency
module that enhances the alignment of the knowledge distilled from camera
views. Extensive comparative and ablation studies across 11 heterogeneous LiDAR
datasets validate our effectiveness and superiority. Additionally, we observe
several interesting emerging properties by scaling up the 2D and 3D backbones
during pretraining, shedding light on the future research of 3D foundation
models for LiDAR-based perception.",2024-07-08,"Xiang Xu, Lingdong Kong, Hui Shuai, Wenwei Zhang, Liang Pan, Kai Chen, Ziwei Liu, Qingshan Liu",http://arxiv.org/pdf/2407.06190v2,cs.LG
Stepping on the Edge: Curvature Aware Learning Rate Tuners,"Curvature information -- particularly, the largest eigenvalue of the loss
Hessian, known as the sharpness -- often forms the basis for learning rate
tuners. However, recent work has shown that the curvature information undergoes
complex dynamics during training, going from a phase of increasing sharpness to
eventual stabilization. We analyze the closed-loop feedback effect between
learning rate tuning and curvature. We find that classical learning rate tuners
may yield greater one-step loss reduction, yet they ultimately underperform in
the long term when compared to constant learning rates in the full batch
regime. These models break the stabilization of the sharpness, which we explain
using a simplified model of the joint dynamics of the learning rate and the
curvature. To further investigate these effects, we introduce a new learning
rate tuning method, Curvature Dynamics Aware Tuning (CDAT), which prioritizes
long term curvature stabilization over instantaneous progress on the objective.
In the full batch regime, CDAT shows behavior akin to prefixed warm-up
schedules on deep learning objectives, outperforming tuned constant learning
rates. In the mini batch regime, we observe that stochasticity introduces
confounding effects that explain the previous success of some learning rate
tuners at appropriate batch sizes. Our findings highlight the critical role of
understanding the joint dynamics of the learning rate and curvature, beyond
greedy minimization, to diagnose failures and design effective adaptive
learning rate tuners.",2024-07-08,"Vincent Roulet, Atish Agarwala, Jean-Bastien Grill, Grzegorz Swirszcz, Mathieu Blondel, Fabian Pedregosa",http://arxiv.org/pdf/2407.06183v1,cs.LG
Transfer Learning with Self-Supervised Vision Transformers for Snake Identification,"We present our approach for the SnakeCLEF 2024 competition to predict snake
species from images. We explore and use Meta's DINOv2 vision transformer model
for feature extraction to tackle species' high variability and visual
similarity in a dataset of 182,261 images. We perform exploratory analysis on
embeddings to understand their structure, and train a linear classifier on the
embeddings to predict species. Despite achieving a score of 39.69, our results
show promise for DINOv2 embeddings in snake identification. All code for this
project is available at https://github.com/dsgt-kaggle-clef/snakeclef-2024.",2024-07-08,"Anthony Miyaguchi, Murilo Gustineli, Austin Fischer, Ryan Lundqvist",http://arxiv.org/pdf/2407.06178v1,cs.LG
Potential Based Diffusion Motion Planning,"Effective motion planning in high dimensional spaces is a long-standing open
problem in robotics. One class of traditional motion planning algorithms
corresponds to potential-based motion planning. An advantage of potential based
motion planning is composability -- different motion constraints can be easily
combined by adding corresponding potentials. However, constructing motion paths
from potentials requires solving a global optimization across configuration
space potential landscape, which is often prone to local minima. We propose a
new approach towards learning potential based motion planning, where we train a
neural network to capture and learn an easily optimizable potentials over
motion planning trajectories. We illustrate the effectiveness of such approach,
significantly outperforming both classical and recent learned motion planning
approaches and avoiding issues with local minima. We further illustrate its
inherent composability, enabling us to generalize to a multitude of different
motion constraints.",2024-07-08,"Yunhao Luo, Chen Sun, Joshua B. Tenenbaum, Yilun Du",http://arxiv.org/pdf/2407.06169v1,cs.LG
DεpS: Delayed ε-Shrinking for Faster Once-For-All Training,"CNNs are increasingly deployed across different hardware, dynamic
environments, and low-power embedded devices. This has led to the design and
training of CNN architectures with the goal of maximizing accuracy subject to
such variable deployment constraints. As the number of deployment scenarios
grows, there is a need to find scalable solutions to design and train
specialized CNNs. Once-for-all training has emerged as a scalable approach that
jointly co-trains many models (subnets) at once with a constant training cost
and finds specialized CNNs later. The scalability is achieved by training the
full model and simultaneously reducing it to smaller subnets that share model
weights (weight-shared shrinking). However, existing once-for-all training
approaches incur huge training costs reaching 1200 GPU hours. We argue this is
because they either start the process of shrinking the full model too early or
too late. Hence, we propose Delayed $\epsilon$-Shrinking (D$\epsilon$pS) that
starts the process of shrinking the full model when it is partially trained
(~50%) which leads to training cost improvement and better in-place knowledge
distillation to smaller models. The proposed approach also consists of novel
heuristics that dynamically adjust subnet learning rates incrementally (E),
leading to improved weight-shared knowledge distillation from larger to smaller
subnets as well. As a result, DEpS outperforms state-of-the-art once-for-all
training techniques across different datasets including CIFAR10/100,
ImageNet-100, and ImageNet-1k on accuracy and cost. It achieves 1.83% higher
ImageNet-1k top1 accuracy or the same accuracy with 1.3x reduction in FLOPs and
2.5x drop in training cost (GPU*hrs)",2024-07-08,"Aditya Annavajjala, Alind Khare, Animesh Agrawal, Igor Fedorov, Hugo Latapie, Myungjin Lee, Alexey Tumanov",http://arxiv.org/pdf/2407.06167v1,cs.LG
Structured Generations: Using Hierarchical Clusters to guide Diffusion Models,"This paper introduces Diffuse-TreeVAE, a deep generative model that
integrates hierarchical clustering into the framework of Denoising Diffusion
Probabilistic Models (DDPMs). The proposed approach generates new images by
sampling from a root embedding of a learned latent tree VAE-based structure, it
then propagates through hierarchical paths, and utilizes a second-stage DDPM to
refine and generate distinct, high-quality images for each data cluster. The
result is a model that not only improves image clarity but also ensures that
the generated samples are representative of their respective clusters,
addressing the limitations of previous VAE-based methods and advancing the
state of clustering-based generative modeling.",2024-07-08,"Jorge da Silva Goncalves, Laura Manduchi, Moritz Vandenhirtz, Julia E. Vogt",http://arxiv.org/pdf/2407.06124v2,cs.LG
Periodic agent-state based Q-learning for POMDPs,"The standard approach for Partially Observable Markov Decision Processes
(POMDPs) is to convert them to a fully observed belief-state MDP. However, the
belief state depends on the system model and is therefore not viable in
reinforcement learning (RL) settings. A widely used alternative is to use an
agent state, which is a model-free, recursively updateable function of the
observation history. Examples include frame stacking and recurrent neural
networks. Since the agent state is model-free, it is used to adapt standard RL
algorithms to POMDPs. However, standard RL algorithms like Q-learning learn a
stationary policy. Our main thesis that we illustrate via examples is that
because the agent state does not satisfy the Markov property, non-stationary
agent-state based policies can outperform stationary ones. To leverage this
feature, we propose PASQL (periodic agent-state based Q-learning), which is a
variant of agent-state-based Q-learning that learns periodic policies. By
combining ideas from periodic Markov chains and stochastic approximation, we
rigorously establish that PASQL converges to a cyclic limit and characterize
the approximation error of the converged periodic policy. Finally, we present a
numerical experiment to highlight the salient features of PASQL and demonstrate
the benefit of learning periodic policies over stationary policies.",2024-07-08,"Amit Sinha, Matthieu Geist, Aditya Mahajan",http://arxiv.org/pdf/2407.06121v3,cs.LG
Sketchy Moment Matching: Toward Fast and Provable Data Selection for Finetuning,"We revisit data selection in a modern context of finetuning from a
fundamental perspective. Extending the classical wisdom of variance
minimization in low dimensions to high-dimensional finetuning, our
generalization analysis unveils the importance of additionally reducing bias
induced by low-rank approximation. Inspired by the variance-bias tradeoff in
high dimensions from the theory, we introduce Sketchy Moment Matching (SkMM), a
scalable data selection scheme with two stages. (i) First, the bias is
controlled using gradient sketching that explores the finetuning parameter
space for an informative low-dimensional subspace $\mathcal{S}$; (ii) then the
variance is reduced over $\mathcal{S}$ via moment matching between the original
and selected datasets. Theoretically, we show that gradient sketching is fast
and provably accurate: selecting $n$ samples by reducing variance over
$\mathcal{S}$ preserves the fast-rate generalization $O(\dim(\mathcal{S})/n)$,
independent of the parameter dimension. Empirically, we concretize the
variance-bias balance via synthetic experiments and demonstrate the
effectiveness of SkMM for finetuning in real vision tasks.",2024-07-08,"Yijun Dong, Hoang Phan, Xiang Pan, Qi Lei",http://arxiv.org/pdf/2407.06120v3,cs.LG
Leveraging data-driven weather models for improving numerical weather prediction skill through large-scale spectral nudging,"Operational meteorological forecasting has long relied on physics-based
numerical weather prediction (NWP) models. Recently, this landscape is facing
disruption by the advent of data-driven artificial intelligence (AI)-based
weather models, which offer tremendous computational performance and
competitive forecasting skill. However, data-driven models for medium-range
forecasting generally suffer from major limitations, including low effective
resolution and a narrow range of predicted variables. This study illustrates
the relative strengths and weaknesses of these competing paradigms using the
GEM (Global Environmental Multiscale) and GraphCast models to represent
physics-based and AI-based approaches, respectively. By analyzing global
predictions from these two models against observations and analyses in both
physical and spectral spaces, this study demonstrates that GraphCast-predicted
large scales outperform GEM, particularly for longer lead times. Building on
this insight, a hybrid NWP-AI system is proposed, wherein GEM-predicted
large-scale state variables are spectrally nudged toward GraphCast predictions,
while allowing GEM to freely generate fine-scale details critical for weather
extremes. Results indicate that this hybrid approach is capable of leveraging
the strengths of GraphCast to enhance the prediction skill of the GEM model.
Importantly, trajectories of tropical cyclones are predicted with enhanced
accuracy without significant changes in intensity. Furthermore, this new hybrid
system ensures that meteorologists have access to a complete set of forecast
variables, including those relevant for high-impact weather events.",2024-07-08,"Syed Zahid Husain, Leo Separovic, Jean-François Caron, Rabah Aider, Mark Buehner, Stéphane Chamberland, Ervig Lapalme, Ron McTaggart-Cowan, Christopher Subich, Paul A. Vaillancourt, Jing Yang, Ayrton Zadra",http://arxiv.org/pdf/2407.06100v2,cs.LG
Physics-Informed Machine Learning Towards A Real-Time Spacecraft Thermal Simulator,"Modeling thermal states for complex space missions, such as the surface
exploration of airless bodies, requires high computation, whether used in
ground-based analysis for spacecraft design or during onboard reasoning for
autonomous operations. For example, a finite-element thermal model with
hundreds of elements can take significant time to simulate, which makes it
unsuitable for onboard reasoning during time-sensitive scenarios such as
descent and landing, proximity operations, or in-space assembly. Further, the
lack of fast and accurate thermal modeling drives thermal designs to be more
conservative and leads to spacecraft with larger mass and higher power budgets.
The emerging paradigm of physics-informed machine learning (PIML) presents a
class of hybrid modeling architectures that address this challenge by combining
simplified physics models with machine learning (ML) models resulting in models
which maintain both interpretability and robustness. Such techniques enable
designs with reduced mass and power through onboard thermal-state estimation
and control and may lead to improved onboard handling of off-nominal states,
including unplanned down-time. The PIML model or hybrid model presented here
consists of a neural network which predicts reduced nodalizations (distribution
and size of coarse mesh) given on-orbit thermal load conditions, and
subsequently a (relatively coarse) finite-difference model operates on this
mesh to predict thermal states. We compare the computational performance and
accuracy of the hybrid model to a data-driven neural net model, and a
high-fidelity finite-difference model of a prototype Earth-orbiting small
spacecraft. The PIML based active nodalization approach provides significantly
better generalization than the neural net model and coarse mesh model, while
reducing computing cost by up to 1.7x compared to the high-fidelity model.",2024-07-08,"Manaswin Oddiraju, Zaki Hasnain, Saptarshi Bandyopadhyay, Eric Sunada, Souma Chowdhury",http://arxiv.org/pdf/2407.06099v2,cs.LG
Assessing Cardiomegaly in Dogs Using a Simple CNN Model,"This paper introduces DogHeart, a dataset comprising 1400 training, 200
validation, and 400 test images categorized as small, normal, and large based
on VHS score. A custom CNN model is developed, featuring a straightforward
architecture with 4 convolutional layers and 4 fully connected layers. Despite
the absence of data augmentation, the model achieves a 72\% accuracy in
classifying cardiomegaly severity. The study contributes to automated
assessment of cardiac conditions in dogs, highlighting the potential for early
detection and intervention in veterinary care.",2024-07-08,Nikhil Deekonda,http://arxiv.org/pdf/2407.06092v1,cs.LG
MERGE -- A Bimodal Dataset for Static Music Emotion Recognition,"The Music Emotion Recognition (MER) field has seen steady developments in
recent years, with contributions from feature engineering, machine learning,
and deep learning. The landscape has also shifted from audio-centric systems to
bimodal ensembles that combine audio and lyrics. However, a severe lack of
public and sizeable bimodal databases has hampered the development and
improvement of bimodal audio-lyrics systems. This article proposes three new
audio, lyrics, and bimodal MER research datasets, collectively called MERGE,
created using a semi-automatic approach. To comprehensively assess the proposed
datasets and establish a baseline for benchmarking, we conducted several
experiments for each modality, using feature engineering, machine learning, and
deep learning methodologies. In addition, we propose and validate fixed
train-validate-test splits. The obtained results confirm the viability of the
proposed datasets, achieving the best overall result of 79.21% F1-score for
bimodal classification using a deep neural network.",2024-07-08,"Pedro Lima Louro, Hugo Redinho, Ricardo Santos, Ricardo Malheiro, Renato Panda, Rui Pedro Paiva",http://arxiv.org/pdf/2407.06060v2,cs.LG
Variational Best-of-N Alignment,"Best-of-N (BoN) is a popular and effective algorithm for aligning language
models to human preferences. The algorithm works as follows: at inference time,
N samples are drawn from the language model, and the sample with the highest
reward, as judged by a reward model, is returned as the output. Despite its
effectiveness, BoN is computationally expensive; it reduces sampling throughput
by a factor of N. To make BoN more efficient at inference time, one strategy is
to fine-tune the language model to mimic what BoN does during inference. To
achieve this, we derive the distribution induced by the BoN algorithm. We then
propose to fine-tune the language model to minimize backward KL divergence to
the BoN distribution. Our approach is analogous to mean-field variational
inference and, thus, we term it variational BoN (vBoN). To the extent this
fine-tuning is successful and we end up with a good approximation, we have
reduced the inference cost by a factor of N. Our experiments on controlled
generation and summarization tasks show that BoN is the most effective
alignment method, and our variational approximation to BoN achieves the closest
performance to BoN and surpasses models fine-tuned using the standard
KL-constrained RL objective. In the controlled generation task, vBoN appears
more frequently on the Pareto frontier of reward and KL divergence compared to
other alignment methods. In the summarization task, vBoN achieves high reward
values across various sampling temperatures.",2024-07-08,"Afra Amini, Tim Vieira, Elliott Ash, Ryan Cotterell",http://arxiv.org/pdf/2407.06057v3,cs.LG
Learning local equivariant representations for quantum operators,"Predicting quantum operator matrices such as Hamiltonian, overlap, and
density matrices in the density functional theory (DFT) framework is crucial
for material science. Current methods often focus on individual operators and
struggle with efficiency and scalability for large systems. Here we introduce a
novel deep learning model, SLEM (strictly localized equivariant
message-passing) for predicting multiple quantum operators, that achieves
state-of-the-art accuracy while dramatically improving computational
efficiency. SLEM's key innovation is its strict locality-based design for
equivariant representations of quantum tensors while preserving physical
symmetries. This enables complex many-body dependency without expanding the
effective receptive field, leading to superior data efficiency and
transferability. Using an innovative SO(2) convolution and invariant overlap
parameterization, SLEM reduces the computational complexity of high-order
tensor products and is therefore capable of handling systems requiring the $f$
and $g$ orbitals in their basis sets. We demonstrate SLEM's capabilities across
diverse 2D and 3D materials, achieving high accuracy even with limited training
data. SLEM's design facilitates efficient parallelization, potentially
extending DFT simulations to systems with device-level sizes, opening new
possibilities for large-scale quantum simulations and high-throughput materials
discovery.",2024-07-08,"Zhanghao Zhouyin, Zixi Gan, MingKang Liu, Shishir Kumar Pandey, Linfeng Zhang, Qiangqiang Gu",http://arxiv.org/pdf/2407.06053v4,cs.LG
Leveraging Transformers for Weakly Supervised Object Localization in Unconstrained Videos,"Weakly-Supervised Video Object Localization (WSVOL) involves localizing an
object in videos using only video-level labels, also referred to as tags.
State-of-the-art WSVOL methods like Temporal CAM (TCAM) rely on class
activation mapping (CAM) and typically require a pre-trained CNN classifier.
However, their localization accuracy is affected by their tendency to minimize
the mutual information between different instances of a class and exploit
temporal information during training for downstream tasks, e.g., detection and
tracking. In the absence of bounding box annotation, it is challenging to
exploit precise information about objects from temporal cues because the model
struggles to locate objects over time. To address these issues, a novel method
called transformer based CAM for videos (TrCAM-V), is proposed for WSVOL. It
consists of a DeiT backbone with two heads for classification and localization.
The classification head is trained using standard classification loss (CL),
while the localization head is trained using pseudo-labels that are extracted
using a pre-trained CLIP model. From these pseudo-labels, the high and low
activation values are considered to be foreground and background regions,
respectively. Our TrCAM-V method allows training a localization network by
sampling pseudo-pixels on the fly from these regions. Additionally, a
conditional random field (CRF) loss is employed to align the object boundaries
with the foreground map. During inference, the model can process individual
frames for real-time localization applications. Extensive experiments on
challenging YouTube-Objects unconstrained video datasets show that our TrCAM-V
method achieves new state-of-the-art performance in terms of classification and
localization accuracy.",2024-07-08,"Shakeeb Murtaza, Marco Pedersoli, Aydin Sarraf, Eric Granger",http://arxiv.org/pdf/2407.06018v1,cs.LG
Simulation-based Benchmarking for Causal Structure Learning in Gene Perturbation Experiments,"Causal structure learning (CSL) refers to the task of learning causal
relationships from data. Advances in CSL now allow learning of causal graphs in
diverse application domains, which has the potential to facilitate data-driven
causal decision-making. Real-world CSL performance depends on a number of
$\textit{context-specific}$ factors, including context-specific data
distributions and non-linear dependencies, that are important in practical
use-cases. However, our understanding of how to assess and select CSL methods
in specific contexts remains limited. To address this gap, we present
$\textit{CausalRegNet}$, a multiplicative effect structural causal model that
allows for generating observational and interventional data incorporating
context-specific properties, with a focus on the setting of gene perturbation
experiments. Using real-world gene perturbation data, we show that CausalRegNet
generates accurate distributions and scales far better than current simulation
frameworks. We illustrate the use of CausalRegNet in assessing CSL methods in
the context of interventional experiments in biology.",2024-07-08,"Luka Kovačević, Izzy Newsham, Sach Mukherjee, John Whittaker",http://arxiv.org/pdf/2407.06015v1,cs.LG
KidSat: satellite imagery to map childhood poverty dataset and benchmark,"Satellite imagery has emerged as an important tool to analyse demographic,
health, and development indicators. While various deep learning models have
been built for these tasks, each is specific to a particular problem, with few
standard benchmarks available. We propose a new dataset pairing satellite
imagery and high-quality survey data on child poverty to benchmark satellite
feature representations. Our dataset consists of 33,608 images, each 10 km
$\times$ 10 km, from 19 countries in Eastern and Southern Africa in the time
period 1997-2022. As defined by UNICEF, multidimensional child poverty covers
six dimensions and it can be calculated from the face-to-face Demographic and
Health Surveys (DHS) Program . As part of the benchmark, we test spatial as
well as temporal generalization, by testing on unseen locations, and on data
after the training years. Using our dataset we benchmark multiple models, from
low-level satellite imagery models such as MOSAIKS , to deep learning
foundation models, which include both generic vision models such as
Self-Distillation with no Labels (DINOv2) models and specific satellite imagery
models such as SatMAE. We provide open source code for building the satellite
dataset, obtaining ground truth data from DHS and running various models
assessed in our work.",2024-07-08,"Makkunda Sharma, Fan Yang, Duy-Nhat Vo, Esra Suel, Swapnil Mishra, Samir Bhatt, Oliver Fiala, William Rudgard, Seth Flaxman",http://arxiv.org/pdf/2407.05986v1,cs.LG
MTL-Split: Multi-Task Learning for Edge Devices using Split Computing,"Split Computing (SC), where a Deep Neural Network (DNN) is intelligently
split with a part of it deployed on an edge device and the rest on a remote
server is emerging as a promising approach. It allows the power of DNNs to be
leveraged for latency-sensitive applications that do not allow the entire DNN
to be deployed remotely, while not having sufficient computation bandwidth
available locally. In many such embedded systems scenarios, such as those in
the automotive domain, computational resource constraints also necessitate
Multi-Task Learning (MTL), where the same DNN is used for multiple inference
tasks instead of having dedicated DNNs for each task, which would need more
computing bandwidth. However, how to partition such a multi-tasking DNN to be
deployed within a SC framework has not been sufficiently studied. This paper
studies this problem, and MTL-Split, our novel proposed architecture, shows
encouraging results on both synthetic and real-world data. The source code is
available at https://github.com/intelligolabs/MTL-Split.",2024-07-08,"Luigi Capogrosso, Enrico Fraccaroli, Samarjit Chakraborty, Franco Fummi, Marco Cristani",http://arxiv.org/pdf/2407.05982v1,cs.LG
Active Label Refinement for Robust Training of Imbalanced Medical Image Classification Tasks in the Presence of High Label Noise,"The robustness of supervised deep learning-based medical image classification
is significantly undermined by label noise. Although several methods have been
proposed to enhance classification performance in the presence of noisy labels,
they face some challenges: 1) a struggle with class-imbalanced datasets,
leading to the frequent overlooking of minority classes as noisy samples; 2) a
singular focus on maximizing performance using noisy datasets, without
incorporating experts-in-the-loop for actively cleaning the noisy labels. To
mitigate these challenges, we propose a two-phase approach that combines
Learning with Noisy Labels (LNL) and active learning. This approach not only
improves the robustness of medical image classification in the presence of
noisy labels, but also iteratively improves the quality of the dataset by
relabeling the important incorrect labels, under a limited annotation budget.
Furthermore, we introduce a novel Variance of Gradients approach in LNL phase,
which complements the loss-based sample selection by also sampling
under-represented samples. Using two imbalanced noisy medical classification
datasets, we demonstrate that that our proposed technique is superior to its
predecessors at handling class imbalance by not misidentifying clean samples
from minority classes as mostly noisy samples.",2024-07-08,"Bidur Khanal, Tianhong Dai, Binod Bhattarai, Cristian Linte",http://arxiv.org/pdf/2407.05973v3,cs.LG
Parsimonious Universal Function Approximator for Elastic and Elasto-Plastic Cavity Expansion Problems,"Cavity expansion is a canonical problem in geotechnics, which can be
described by partial differential equations (PDEs) and ordinary differential
equations (ODEs). This study explores the potential of using a new solver, a
physics-informed neural network (PINN), to calculate the stress field in an
expanded cavity in the elastic and elasto-plastic regimes. Whilst PINNs have
emerged as an effective universal function approximator for deriving the
solutions of a wide range of governing PDEs/ODEs, their ability to solve
elasto-plastic problems remains uncertain. A novel parsimonious loss function
is first proposed to balance the simplicity and accuracy of PINN. The proposed
method is applied to diverse material behaviours in the cavity expansion
problem including isotropic, anisotropic elastic media, and elastic-perfectly
plastic media with Tresca and Mohr-Coulomb yield criteria. The results indicate
that the use of a parsimonious prior information-based loss function is highly
beneficial to deriving the approximate solutions of complex PDEs with high
accuracy. The present method allows for accurate derivation of solutions for
both elastic and plastic mechanical responses of an expanded cavity. It also
provides insights into how PINNs can be further advanced to solve more complex
problems in geotechnical practice.",2024-07-08,"Xiao-Xuan Chen, Pin Zhang, Hai-Sui Yu, Zhen-Yu Yin, Brian Sheil",http://arxiv.org/pdf/2407.19074v1,cs.LG
On Bellman equations for continuous-time policy evaluation I: discretization and approximation,"We study the problem of computing the value function from a
discretely-observed trajectory of a continuous-time diffusion process. We
develop a new class of algorithms based on easily implementable numerical
schemes that are compatible with discrete-time reinforcement learning (RL) with
function approximation. We establish high-order numerical accuracy as well as
the approximation error guarantees for the proposed approach. In contrast to
discrete-time RL problems where the approximation factor depends on the
effective horizon, we obtain a bounded approximation factor using the
underlying elliptic structures, even if the effective horizon diverges to
infinity.",2024-07-08,"Wenlong Mou, Yuhua Zhu",http://arxiv.org/pdf/2407.05966v1,cs.LG
T2VSafetyBench: Evaluating the Safety of Text-to-Video Generative Models,"The recent development of Sora leads to a new era in text-to-video (T2V)
generation. Along with this comes the rising concern about its security risks.
The generated videos may contain illegal or unethical content, and there is a
lack of comprehensive quantitative understanding of their safety, posing a
challenge to their reliability and practical deployment. Previous evaluations
primarily focus on the quality of video generation. While some evaluations of
text-to-image models have considered safety, they cover fewer aspects and do
not address the unique temporal risk inherent in video generation. To bridge
this research gap, we introduce T2VSafetyBench, a new benchmark designed for
conducting safety-critical assessments of text-to-video models. We define 12
critical aspects of video generation safety and construct a malicious prompt
dataset including real-world prompts, LLM-generated prompts and jailbreak
attack-based prompts. Based on our evaluation results, we draw several
important findings, including: 1) no single model excels in all aspects, with
different models showing various strengths; 2) the correlation between GPT-4
assessments and manual reviews is generally high; 3) there is a trade-off
between the usability and safety of text-to-video generative models. This
indicates that as the field of video generation rapidly advances, safety risks
are set to surge, highlighting the urgency of prioritizing video safety. We
hope that T2VSafetyBench can provide insights for better understanding the
safety of video generation in the era of generative AI.",2024-07-08,"Yibo Miao, Yifan Zhu, Yinpeng Dong, Lijia Yu, Jun Zhu, Xiao-Shan Gao",http://arxiv.org/pdf/2407.05965v3,cs.LG
Learning by the F-adjoint,"A recent paper by Boughammoura (2023) describes the back-propagation
algorithm in terms of an alternative formulation called the F-adjoint method.
In particular, by the F-adjoint algorithm the computation of the loss gradient,
with respect to each weight within the network, is straightforward and can
simply be done. In this work, we develop and investigate this theoretical
framework to improve some supervised learning algorithm for feed-forward neural
network. Our main result is that by introducing some neural dynamical model
combined by the gradient descent algorithm, we derived an equilibrium F-adjoint
process which yields to some local learning rule for deep feed-forward networks
setting. Experimental results on MNIST and Fashion-MNIST datasets, demonstrate
that the proposed approach provide a significant improvements on the standard
back-propagation training procedure.",2024-07-08,Ahmed Boughammoura,http://arxiv.org/pdf/2407.11049v1,cs.LG
Magnitude and Rotation Invariant Detection of Transportation Modes with Missing Data Modalities,"This work presents the solution of the Signal Sleuths team for the 2024 SHL
recognition challenge. The challenge involves detecting transportation modes
using shuffled, non-overlapping 5-second windows of phone movement data, with
exactly one of the three available modalities (accelerometer, gyroscope,
magnetometer) randomly missing. Data analysis indicated a significant
distribution shift between train and validation data, necessitating a magnitude
and rotation-invariant approach. We utilize traditional machine learning,
focusing on robust processing, feature extraction, and rotation-invariant
aggregation. An ablation study showed that relying solely on the frequently
used signal magnitude vector results in the poorest performance. Conversely,
our proposed rotation-invariant aggregation demonstrated substantial
improvement over using rotation-aware features, while also reducing the feature
vector length. Moreover, z-normalization proved crucial for creating robust
spectral features.",2024-07-08,"Jeroen Van Der Donckt, Jonas Van Der Donckt, Sofie Van Hoecke",http://arxiv.org/pdf/2407.11048v1,cs.LG
Graph Anomaly Detection with Noisy Labels by Reinforcement Learning,"Graph anomaly detection (GAD) has been widely applied in many areas, e.g.,
fraud detection in finance and robot accounts in social networks. Existing
methods are dedicated to identifying the outlier nodes that deviate from normal
ones. While they heavily rely on high-quality annotation, which is hard to
obtain in real-world scenarios, this could lead to severely degraded
performance based on noisy labels. Thus, we are motivated to cut the edges of
suspicious nodes to alleviate the impact of noise. However, it remains
difficult to precisely identify the nodes with noisy labels. Moreover, it is
hard to quantitatively evaluate the regret of cutting the edges, which may have
either positive or negative influences. To this end, we propose a novel
framework REGAD, i.e., REinforced Graph Anomaly Detector. Specifically, we aim
to maximize the performance improvement (AUC) of a base detector by cutting
noisy edges approximated through the nodes with high-confidence labels. (i) We
design a tailored action and search space to train a policy network to
carefully prune edges step by step, where only a few suspicious edges are
prioritized in each step. (ii) We design a policy-in-the-loop mechanism to
iteratively optimize the policy based on the feedback from base detector. The
overall performance is evaluated by the cumulative rewards. Extensive
experiments are conducted on three datasets under different anomaly ratios. The
results indicate the superior performance of our proposed REGAD.",2024-07-08,"Zhu Wang, Shuang Zhou, Junnan Dong, Chang Yang, Xiao Huang, Shengjie Zhao",http://arxiv.org/pdf/2407.05934v1,cs.LG
Improving AlphaFlow for Efficient Protein Ensembles Generation,"Investigating conformational landscapes of proteins is a crucial way to
understand their biological functions and properties. AlphaFlow stands out as a
sequence-conditioned generative model that introduces flexibility into
structure prediction models by fine-tuning AlphaFold under the flow-matching
framework. Despite the advantages of efficient sampling afforded by
flow-matching, AlphaFlow still requires multiple runs of AlphaFold to finally
generate one single conformation. Due to the heavy consumption of AlphaFold,
its applicability is limited in sampling larger set of protein ensembles or the
longer chains within a constrained timeframe. In this work, we propose a
feature-conditioned generative model called AlphaFlow-Lit to realize efficient
protein ensembles generation. In contrast to the full fine-tuning on the entire
structure, we focus solely on the light-weight structure module to reconstruct
the conformation. AlphaFlow-Lit performs on-par with AlphaFlow and surpasses
its distilled version without pretraining, all while achieving a significant
sampling acceleration of around 47 times. The advancement in efficiency
showcases the potential of AlphaFlow-Lit in enabling faster and more scalable
generation of protein ensembles.",2024-07-08,"Shaoning Li, Mingyu Li, Yusong Wang, Xinheng He, Nanning Zheng, Jian Zhang, Pheng-Ann Heng",http://arxiv.org/pdf/2407.12053v1,cs.LG
TAPVid-3D: A Benchmark for Tracking Any Point in 3D,"We introduce a new benchmark, TAPVid-3D, for evaluating the task of
long-range Tracking Any Point in 3D (TAP-3D). While point tracking in two
dimensions (TAP) has many benchmarks measuring performance on real-world
videos, such as TAPVid-DAVIS, three-dimensional point tracking has none. To
this end, leveraging existing footage, we build a new benchmark for 3D point
tracking featuring 4,000+ real-world videos, composed of three different data
sources spanning a variety of object types, motion patterns, and indoor and
outdoor environments. To measure performance on the TAP-3D task, we formulate a
collection of metrics that extend the Jaccard-based metric used in TAP to
handle the complexities of ambiguous depth scales across models, occlusions,
and multi-track spatio-temporal smoothness. We manually verify a large sample
of trajectories to ensure correct video annotations, and assess the current
state of the TAP-3D task by constructing competitive baselines using existing
tracking models. We anticipate this benchmark will serve as a guidepost to
improve our ability to understand precise 3D motion and surface deformation
from monocular video. Code for dataset download, generation, and model
evaluation is available at https://tapvid3d.github.io",2024-07-08,"Skanda Koppula, Ignacio Rocco, Yi Yang, Joe Heyward, João Carreira, Andrew Zisserman, Gabriel Brostow, Carl Doersch",http://arxiv.org/pdf/2407.05921v2,cs.LG
LPGD: A General Framework for Backpropagation through Embedded Optimization Layers,"Embedding parameterized optimization problems as layers into machine learning
architectures serves as a powerful inductive bias. Training such architectures
with stochastic gradient descent requires care, as degenerate derivatives of
the embedded optimization problem often render the gradients uninformative. We
propose Lagrangian Proximal Gradient Descent (LPGD) a flexible framework for
training architectures with embedded optimization layers that seamlessly
integrates into automatic differentiation libraries. LPGD efficiently computes
meaningful replacements of the degenerate optimization layer derivatives by
re-running the forward solver oracle on a perturbed input. LPGD captures
various previously proposed methods as special cases, while fostering deep
links to traditional optimization methods. We theoretically analyze our method
and demonstrate on historical and synthetic data that LPGD converges faster
than gradient descent even in a differentiable setup.",2024-07-08,"Anselm Paulus, Georg Martius, Vít Musil",http://arxiv.org/pdf/2407.05920v1,cs.LG
Fostering Trust and Quantifying Value of AI and ML,"Artificial Intelligence (AI) and Machine Learning (ML) providers have a
responsibility to develop valid and reliable systems. Much has been discussed
about trusting AI and ML inferences (the process of running live data through a
trained AI model to make a prediction or solve a task), but little has been
done to define what that means. Those in the space of ML- based products are
familiar with topics such as transparency, explainability, safety, bias, and so
forth. Yet, there are no frameworks to quantify and measure those. Producing
ever more trustworthy machine learning inferences is a path to increase the
value of products (i.e., increased trust in the results) and to engage in
conversations with users to gather feedback to improve products. In this paper,
we begin by examining the dynamic of trust between a provider (Trustor) and
users (Trustees). Trustors are required to be trusting and trustworthy, whereas
trustees need not be trusting nor trustworthy. The challenge for trustors is to
provide results that are good enough to make a trustee increase their level of
trust above a minimum threshold for: 1- doing business together; 2-
continuation of service. We conclude by defining and proposing a framework, and
a set of viable metrics, to be used for computing a trust score and objectively
understand how trustworthy a machine learning system can claim to be, plus
their behavior over time.",2024-07-08,"Dalmo Cirne, Veena Calambur",http://arxiv.org/pdf/2407.05919v1,cs.LG
An open source Multi-Agent Deep Reinforcement Learning Routing Simulator for satellite networks,"This paper introduces an open source simulator for packet routing in Low
Earth Orbit Satellite Constellations (LSatCs) considering the dynamic system
uncertainties. The simulator, implemented in Python, supports traditional
Dijkstra's based routing as well as more advanced learning solutions,
specifically Q-Routing and Multi-Agent Deep Reinforcement Learning (MA-DRL)
from our previous work. It uses an event-based approach with the SimPy module
to accurately simulate packet creation, routing and queuing, providing
real-time tracking of queues and latency. The simulator is highly configurable,
allowing adjustments in routing policies, traffic, ground and space layer
topologies, communication parameters, and learning hyperparameters. Key
features include the ability to visualize system motion and track packet paths.
Results highlight significant improvements in end-to-end (E2E) latency using
Reinforcement Learning (RL)-based routing policies compared to traditional
methods. The source code, the documentation and a Jupyter notebook with
post-processing results and analysis are available on GitHub.",2024-07-08,"Federico Lozano-Cuadra, Mathias D. Thorsager, Israel Leyva-Mayorga, Beatriz Soret",http://arxiv.org/pdf/2407.11047v2,cs.LG
ORAN-Bench-13K: An Open Source Benchmark for Assessing LLMs in Open Radio Access Networks,"Large Language Models (LLMs) can revolutionize how we deploy and operate Open
Radio Access Networks (O-RAN) by enhancing network analytics, anomaly
detection, and code generation and significantly increasing the efficiency and
reliability of a plethora of O-RAN tasks. In this paper, we present
ORAN-Bench-13K, the first comprehensive benchmark designed to evaluate the
performance of Large Language Models (LLMs) within the context of O-RAN. Our
benchmark consists of 13,952 meticulously curated multiple-choice questions
generated from 116 O-RAN specification documents. We leverage a novel
three-stage LLM framework, and the questions are categorized into three
distinct difficulties to cover a wide spectrum of ORAN-related knowledge. We
thoroughly evaluate the performance of several state-of-the-art LLMs, including
Gemini, Chat-GPT, and Mistral. Additionally, we propose ORANSight, a
Retrieval-Augmented Generation (RAG)-based pipeline that demonstrates superior
performance on ORAN-Bench-13K compared to other tested closed-source models.
Our findings indicate that current popular LLM models are not proficient in
O-RAN, highlighting the need for specialized models. We observed a noticeable
performance improvement when incorporating the RAG-based ORANSight pipeline,
with a Macro Accuracy of 0.784 and a Weighted Accuracy of 0.776, which was on
average 21.55% and 22.59% better than the other tested LLMs.",2024-07-08,"Pranshav Gajjar, Vijay K. Shah",http://arxiv.org/pdf/2407.06245v2,cs.LG
Link Representation Learning for Probabilistic Travel Time Estimation,"Travel time estimation is a crucial application in navigation apps and web
mapping services. Current deterministic and probabilistic methods primarily
focus on modeling individual trips, assuming independence among trips. However,
in real-world scenarios, we often observe strong inter-trip correlations due to
factors such as weather conditions, traffic management, and road works. In this
paper, we propose to model trip-level link travel time using a Gaussian
hierarchical model, which can characterize both inter-trip and intra-trip
correlations. The joint distribution of travel time of multiple trips becomes a
multivariate Gaussian parameterized by learnable link representations. To
effectively use the sparse GPS trajectories, we also propose a data
augmentation method based on trip sub-sampling, which allows for fine-grained
gradient backpropagation in learning link representations. During inference, we
estimate the probability distribution of the travel time of a queried trip
conditional on the completed trips that are spatiotemporally adjacent. We refer
to the overall framework as ProbTTE. We evaluate ProbTTE on two real-world GPS
trajectory datasets, and the results demonstrate its superior performance
compared to state-of-the-art deterministic and probabilistic baselines.
Additionally, we find that the learned link representations align well with the
physical geometry of the network, making them suitable as input for other
applications.",2024-07-08,"Chen Xu, Qiang Wang, Lijun Sun",http://arxiv.org/pdf/2407.05895v1,cs.LG
Generation and De-Identification of Indian Clinical Discharge Summaries using LLMs,"The consequences of a healthcare data breach can be devastating for the
patients, providers, and payers. The average financial impact of a data breach
in recent months has been estimated to be close to USD 10 million. This is
especially significant for healthcare organizations in India that are managing
rapid digitization while still establishing data governance procedures that
align with the letter and spirit of the law. Computer-based systems for
de-identification of personal information are vulnerable to data drift, often
rendering them ineffective in cross-institution settings. Therefore, a rigorous
assessment of existing de-identification against local health datasets is
imperative to support the safe adoption of digital health initiatives in India.
Using a small set of de-identified patient discharge summaries provided by an
Indian healthcare institution, in this paper, we report the nominal performance
of de-identification algorithms (based on language models) trained on publicly
available non-Indian datasets, pointing towards a lack of cross-institutional
generalization. Similarly, experimentation with off-the-shelf de-identification
systems reveals potential risks associated with the approach. To overcome data
scarcity, we explore generating synthetic clinical reports (using publicly
available and Indian summaries) by performing in-context learning over Large
Language Models (LLMs). Our experiments demonstrate the use of generated
reports as an effective strategy for creating high-performing de-identification
systems with good generalization capabilities.",2024-07-08,"Sanjeet Singh, Shreya Gupta, Niralee Gupta, Naimish Sharma, Lokesh Srivastava, Vibhu Agarwal, Ashutosh Modi",http://arxiv.org/pdf/2407.05887v1,cs.LG
Efficiently Training Neural Networks for Imperfect Information Games by Sampling Information Sets,"In imperfect information games, the evaluation of a game state not only
depends on the observable world but also relies on hidden parts of the
environment. As accessing the obstructed information trivialises state
evaluations, one approach to tackle such problems is to estimate the value of
the imperfect state as a combination of all states in the information set,
i.e., all possible states that are consistent with the current imperfect
information. In this work, the goal is to learn a function that maps from the
imperfect game information state to its expected value. However, constructing a
perfect training set, i.e. an enumeration of the whole information set for
numerous imperfect states, is often infeasible. To compute the expected values
for an imperfect information game like \textit{Reconnaissance Blind Chess}, one
would need to evaluate thousands of chess positions just to obtain the training
target for a single state. Still, the expected value of a state can already be
approximated with appropriate accuracy from a much smaller set of evaluations.
Thus, in this paper, we empirically investigate how a budget of perfect
information game evaluations should be distributed among training samples to
maximise the return. Our results show that sampling a small number of states,
in our experiments roughly 3, for a larger number of separate positions is
preferable over repeatedly sampling a smaller quantity of states. Thus, we find
that in our case, the quantity of different samples seems to be more important
than higher target quality.",2024-07-08,"Timo Bertram, Johannes Fürnkranz, Martin Müller",http://arxiv.org/pdf/2407.05876v1,cs.LG
Scaling Exponents Across Parameterizations and Optimizers,"Robust and effective scaling of models from small to large width typically
requires the precise adjustment of many algorithmic and architectural details,
such as parameterization and optimizer choices. In this work, we propose a new
perspective on parameterization by investigating a key assumption in prior work
about the alignment between parameters and data and derive new theoretical
results under weaker assumptions and a broader set of optimizers. Our extensive
empirical investigation includes tens of thousands of models trained with all
combinations of three optimizers, four parameterizations, several alignment
assumptions, more than a dozen learning rates, and fourteen model sizes up to
26.8B parameters. We find that the best learning rate scaling prescription
would often have been excluded by the assumptions in prior work. Our results
show that all parameterizations, not just maximal update parameterization
(muP), can achieve hyperparameter transfer; moreover, our novel per-layer
learning rate prescription for standard parameterization outperforms muP.
Finally, we demonstrate that an overlooked aspect of parameterization, the
epsilon parameter in Adam, must be scaled correctly to avoid gradient underflow
and propose Adam-atan2, a new numerically stable, scale-invariant version of
Adam that eliminates the epsilon hyperparameter entirely.",2024-07-08,"Katie Everett, Lechao Xiao, Mitchell Wortsman, Alexander A. Alemi, Roman Novak, Peter J. Liu, Izzeddin Gur, Jascha Sohl-Dickstein, Leslie Pack Kaelbling, Jaehoon Lee, Jeffrey Pennington",http://arxiv.org/pdf/2407.05872v2,cs.LG
A Survey on LoRA of Large Language Models,"Low-Rank Adaptation~(LoRA), which updates the dense neural network layers
with pluggable low-rank matrices, is one of the best performed parameter
efficient fine-tuning paradigms. Furthermore, it has significant advantages in
cross-task generalization and privacy-preserving. Hence, LoRA has gained much
attention recently, and the number of related literature demonstrates
exponential growth. It is necessary to conduct a comprehensive overview of the
current progress on LoRA. This survey categorizes and reviews the progress from
the perspectives of (1) downstream adaptation improving variants that improve
LoRA's performance on downstream tasks; (2) cross-task generalization methods
that mix multiple LoRA plugins to achieve cross-task generalization; (3)
efficiency-improving methods that boost the computation-efficiency of LoRA; (4)
data privacy-preserving methods that use LoRA in federated learning; (5)
application. Besides, this survey also discusses the future directions in this
field. At last, we provide a Github
page~\footnote{\href{https://github.com/ZJU-LLMs/Awesome-LoRAs.git}{https://github.com/ZJU-LLMs/Awesome-LoRAs.git}}
for readers to check the updates and initiate discussions on this survey paper.",2024-07-08,"Yuren Mao, Yuhang Ge, Yijiang Fan, Wenyi Xu, Yu Mi, Zhonghao Hu, Yunjun Gao",http://arxiv.org/pdf/2407.11046v4,cs.LG
Neural Network-based Information Set Weighting for Playing Reconnaissance Blind Chess,"In imperfect information games, the game state is generally not fully
observable to players. Therefore, good gameplay requires policies that deal
with the different information that is hidden from each player. To combat this,
effective algorithms often reason about information sets; the sets of all
possible game states that are consistent with a player's observations. While
there is no way to distinguish between the states within an information set,
this property does not imply that all states are equally likely to occur in
play. We extend previous research on assigning weights to the states in an
information set in order to facilitate better gameplay in the imperfect
information game of Reconnaissance Blind Chess. For this, we train two
different neural networks which estimate the likelihood of each state in an
information set from historical game data. Experimentally, we find that a
Siamese neural network is able to achieve higher accuracy and is more efficient
than a classical convolutional neural network for the given domain. Finally, we
evaluate an RBC-playing agent that is based on the generated weightings and
compare different parameter settings that influence how strongly it should rely
on them. The resulting best player is ranked 5th on the public leaderboard.",2024-07-08,"Timo Bertram, Johannes Fürnkranz, Martin Müller",http://arxiv.org/pdf/2407.05864v1,cs.LG
Vulnerability Detection in Smart Contracts: A Comprehensive Survey,"In the growing field of blockchain technology, smart contracts exist as
transformative digital agreements that execute transactions autonomously in
decentralised networks. However, these contracts face challenges in the form of
security vulnerabilities, posing significant financial and operational risks.
While traditional methods to detect and mitigate vulnerabilities in smart
contracts are limited due to a lack of comprehensiveness and effectiveness,
integrating advanced machine learning technologies presents an attractive
approach to increasing effective vulnerability countermeasures. We endeavour to
fill an important gap in the existing literature by conducting a rigorous
systematic review, exploring the intersection between machine learning and
smart contracts. Specifically, the study examines the potential of machine
learning techniques to improve the detection and mitigation of vulnerabilities
in smart contracts. We analysed 88 articles published between 2018 and 2023
from the following databases: IEEE, ACM, ScienceDirect, Scopus, and Google
Scholar. The findings reveal that classical machine learning techniques,
including KNN, RF, DT, XG-Boost, and SVM, outperform static tools in
vulnerability detection. Moreover, multi-model approaches integrating deep
learning and classical machine learning show significant improvements in
precision and recall, while hybrid models employing various techniques achieve
near-perfect performance in vulnerability detection accuracy.
  By integrating state-of-the-art solutions, this work synthesises current
methods, thoroughly investigates research gaps, and suggests directions for
future studies. The insights gathered from this study are intended to serve as
a seminal reference for academics, industry experts, and bodies interested in
leveraging machine learning to enhance smart contract security.",2024-07-08,"Christopher De Baets, Basem Suleiman, Armin Chitizadeh, Imran Razzak",http://arxiv.org/pdf/2407.07922v1,cs.LG
An Empirical Comparison of Vocabulary Expansion and Initialization Approaches for Language Models,"Language Models (LMs) excel in natural language processing tasks for English
but show reduced performance in most other languages. This problem is commonly
tackled by continually pre-training and fine-tuning these models for said
languages. A significant issue in this process is the limited vocabulary
coverage in the original model's tokenizer, leading to inadequate
representation of new languages and necessitating an expansion of the
tokenizer. The initialization of the embeddings corresponding to new vocabulary
items presents a further challenge. Current strategies require cross-lingual
embeddings and lack a solid theoretical foundation as well as comparisons with
strong baselines. In this paper, we first establish theoretically that
initializing within the convex hull of existing embeddings is a good
initialization, followed by a novel but simple approach, Constrained Word2Vec
(CW2V), which does not require cross-lingual embeddings. Our study evaluates
different initialization methods for expanding RoBERTa and LLaMA 2 across four
languages and five tasks. The results show that CW2V performs equally well or
even better than more advanced techniques. Additionally, simpler approaches
like multivariate initialization perform on par with these advanced methods
indicating that efficient large-scale multilingual continued pretraining can be
achieved even with simpler initialization methods. We release our code publicly
(https://github.com/AI4Bharat/VocabAdaptation_LLM/tree/CW2V).",2024-07-08,"Nandini Mundra, Aditya Nanda Kishore, Raj Dabre, Ratish Puduppully, Anoop Kunchukuttan, Mitesh M. Khapra",http://arxiv.org/pdf/2407.05841v2,cs.LG
A Machine Learning Approach to Detecting Albedo Anomalies on the Lunar Surface,"This study introduces a data-driven approach using machine learning (ML)
techniques to explore and predict albedo anomalies on the Moon's surface. The
research leverages diverse planetary datasets, including
high-spatial-resolution albedo maps and element maps (LPFe, LPK, LPTh, LPTi)
derived from laser and gamma-ray measurements. The primary objective is to
identify relationships between chemical elements and albedo, thereby expanding
our understanding of planetary surfaces and offering predictive capabilities
for areas with incomplete datasets. To bridge the gap in resolution between the
albedo and element maps, we employ Gaussian blurring techniques, including an
innovative adaptive Gaussian blur. Our methodology culminates in the deployment
of an Extreme Gradient Boosting Regression Model, optimized to predict full
albedo based on elemental composition. Furthermore, we present an interactive
analytical tool to visualize prediction errors, delineating their spatial and
chemical characteristics. The findings not only pave the way for a more
comprehensive understanding of the Moon's surface but also provide a framework
for similar studies on other celestial bodies.",2024-07-08,"Sofia Strukova, Sergei Gleyzer, Patrick Peplowski, Jason P. Terry",http://arxiv.org/pdf/2407.05832v2,cs.LG
Graph Reasoning Networks,"Graph neural networks (GNNs) are the predominant approach for graph-based
machine learning. While neural networks have shown great performance at
learning useful representations, they are often criticized for their limited
high-level reasoning abilities. In this work, we present Graph Reasoning
Networks (GRNs), a novel approach to combine the strengths of fixed and learned
graph representations and a reasoning module based on a differentiable
satisfiability solver. While results on real-world datasets show comparable
performance to GNN, experiments on synthetic datasets demonstrate the potential
of the newly proposed method.",2024-07-08,"Markus Zopf, Francesco Alesiani",http://arxiv.org/pdf/2407.05816v1,cs.LG
FedMRL: Data Heterogeneity Aware Federated Multi-agent Deep Reinforcement Learning for Medical Imaging,"Despite recent advancements in federated learning (FL) for medical image
diagnosis, addressing data heterogeneity among clients remains a significant
challenge for practical implementation. A primary hurdle in FL arises from the
non-IID nature of data samples across clients, which typically results in a
decline in the performance of the aggregated global model. In this study, we
introduce FedMRL, a novel federated multi-agent deep reinforcement learning
framework designed to address data heterogeneity. FedMRL incorporates a novel
loss function to facilitate fairness among clients, preventing bias in the
final global model. Additionally, it employs a multi-agent reinforcement
learning (MARL) approach to calculate the proximal term $(\mu)$ for the
personalized local objective function, ensuring convergence to the global
optimum. Furthermore, FedMRL integrates an adaptive weight adjustment method
using a Self-organizing map (SOM) on the server side to counteract distribution
shifts among clients' local data distributions. We assess our approach using
two publicly available real-world medical datasets, and the results demonstrate
that FedMRL significantly outperforms state-of-the-art techniques, showing its
efficacy in addressing data heterogeneity in federated learning. The code can
be found here~{\url{https://github.com/Pranabiitp/FedMRL}}.",2024-07-08,"Pranab Sahoo, Ashutosh Tripathi, Sriparna Saha, Samrat Mondal",http://arxiv.org/pdf/2407.05800v1,cs.LG
A Primal-Dual Online Learning Approach for Dynamic Pricing of Sequentially Displayed Complementary Items under Sale Constraints,"We address the challenging problem of dynamically pricing complementary items
that are sequentially displayed to customers. An illustrative example is the
online sale of flight tickets, where customers navigate through multiple web
pages. Initially, they view the ticket cost, followed by ancillary expenses
such as insurance and additional luggage fees. Coherent pricing policies for
complementary items are essential because optimizing the pricing of each item
individually is ineffective. Our scenario also involves a sales constraint,
which specifies a minimum number of items to sell, and uncertainty regarding
customer demand curves. To tackle this problem, we originally formulate it as a
Markov Decision Process with constraints. Leveraging online learning tools, we
design a primal-dual online optimization algorithm. We empirically evaluate our
approach using synthetic settings randomly generated from real-world data,
covering various configurations from stationary to non-stationary, and compare
its performance in terms of constraints violation and regret against well-known
baselines optimizing each state singularly.",2024-07-08,"Francesco Emanuele Stradi, Filippo Cipriani, Lorenzo Ciampiconi, Marco Leonardi, Alessandro Rozza, Nicola Gatti",http://arxiv.org/pdf/2407.05793v1,cs.LG
CANDID DAC: Leveraging Coupled Action Dimensions with Importance Differences in DAC,"High-dimensional action spaces remain a challenge for dynamic algorithm
configuration (DAC). Interdependencies and varying importance between action
dimensions are further known key characteristics of DAC problems. We argue that
these Coupled Action Dimensions with Importance Differences (CANDID) represent
aspects of the DAC problem that are not yet fully explored. To address this
gap, we introduce a new white-box benchmark within the DACBench suite that
simulates the properties of CANDID. Further, we propose sequential policies as
an effective strategy for managing these properties. Such policies factorize
the action space and mitigate exponential growth by learning a policy per
action dimension. At the same time, these policies accommodate the
interdependence of action dimensions by fostering implicit coordination. We
show this in an experimental study of value-based policies on our new
benchmark. This study demonstrates that sequential policies significantly
outperform independent learning of factorized policies in CANDID action spaces.
In addition, they overcome the scalability limitations associated with learning
a single policy across all action dimensions. The code used for our experiments
is available under https://github.com/PhilippBordne/candidDAC.",2024-07-08,"Philipp Bordne, M. Asif Hasan, Eddie Bergman, Noor Awad, André Biedenkapp",http://arxiv.org/pdf/2407.05789v2,cs.LG
Limits to Predicting Online Speech Using Large Language Models,"We study the predictability of online speech on social media, and whether
predictability improves with information outside a user's own posts. Recent
theoretical results suggest that posts from a user's social circle are as
predictive of the user's future posts as that of the user's past posts.
Motivated by the success of large language models, we empirically test this
hypothesis. We define predictability as a measure of the model's uncertainty,
i.e., its negative log-likelihood on future tokens given context. As the basis
of our study, we collect 10M tweets for ``tweet-tuning'' base models and a
further 6.25M posts from more than five thousand X (previously Twitter) users
and their peers. Across four large language models ranging in size from 1.5
billion to 70 billion parameters, we find that predicting a user's posts from
their peers' posts performs poorly. Moreover, the value of the user's own posts
for prediction is consistently higher than that of their peers'. We extend our
investigation with a detailed analysis on what's learned in-context and the
robustness of our findings. From context, base models learn to correctly
predict @-mentions and hashtags. Moreover, our results replicate if instead of
prompting the model with additional context, we finetune on it. Across the
board, we find that predicting the posts of individual users remains hard.",2024-07-08,"Mina Remeli, Moritz Hardt, Robert C. Williamson",http://arxiv.org/pdf/2407.12850v2,cs.LG
Automated Computational Energy Minimization of ML Algorithms using Constrained Bayesian Optimization,"Bayesian optimization (BO) is an efficient framework for optimization of
black-box objectives when function evaluations are costly and gradient
information is not easily accessible. BO has been successfully applied to
automate the task of hyperparameter optimization (HPO) in machine learning (ML)
models with the primary objective of optimizing predictive performance on
held-out data. In recent years, however, with ever-growing model sizes, the
energy cost associated with model training has become an important factor for
ML applications. Here we evaluate Constrained Bayesian Optimization (CBO) with
the primary objective of minimizing energy consumption and subject to the
constraint that the generalization performance is above some threshold. We
evaluate our approach on regression and classification tasks and demonstrate
that CBO achieves lower energy consumption without compromising the predictive
performance of ML models.",2024-07-08,"Pallavi Mitra, Felix Biessmann",http://arxiv.org/pdf/2407.05788v1,cs.LG
Sequential Contrastive Audio-Visual Learning,"Contrastive learning has emerged as a powerful technique in audio-visual
representation learning, leveraging the natural co-occurrence of audio and
visual modalities in webscale video datasets. However, conventional contrastive
audio-visual learning (CAV) methodologies often rely on aggregated
representations derived through temporal aggregation, neglecting the intrinsic
sequential nature of the data. This oversight raises concerns regarding the
ability of standard approaches to capture and utilize fine-grained information
within sequences. In response to this limitation, we propose sequential
contrastive audiovisual learning (SCAV), which contrasts examples based on
their non-aggregated representation space using multidimensional sequential
distances. Audio-visual retrieval experiments with the VGGSound and Music
datasets demonstrate the effectiveness of SCAV, with up to 3.5x relative
improvements in recall against traditional aggregation-based contrastive
learning and other previously proposed methods, which utilize more parameters
and data. We also show that models trained with SCAV exhibit a significant
degree of flexibility regarding the metric employed for retrieval, allowing us
to use a hybrid retrieval approach that is both effective and efficient.",2024-07-08,"Ioannis Tsiamas, Santiago Pascual, Chunghsin Yeh, Joan Serrà",http://arxiv.org/pdf/2407.05782v2,cs.LG
Regret Analysis of Multi-task Representation Learning for Linear-Quadratic Adaptive Control,"Representation learning is a powerful tool that enables learning over large
multitudes of agents or domains by enforcing that all agents operate on a
shared set of learned features. However, many robotics or controls applications
that would benefit from collaboration operate in settings with changing
environments and goals, whereas most guarantees for representation learning are
stated for static settings. Toward rigorously establishing the benefit of
representation learning in dynamic settings, we analyze the regret of
multi-task representation learning for linear-quadratic control. This setting
introduces unique challenges. Firstly, we must account for and balance the
$\textit{misspecification}$ introduced by an approximate representation.
Secondly, we cannot rely on the parameter update schemes of single-task online
LQR, for which least-squares often suffices, and must devise a novel scheme to
ensure sufficient improvement. We demonstrate that for settings where
exploration is ""benign"", the regret of any agent after $T$ timesteps scales as
$\tilde O(\sqrt{T/H})$, where $H$ is the number of agents. In settings with
""difficult"" exploration, the regret scales as $\tilde O(\sqrt{d_u d_\theta}
\sqrt{T} + T^{3/4}/H^{1/5})$, where $d_x$ is the state-space dimension, $d_u$
is the input dimension, and $d_\theta$ is the task-specific parameter count. In
both cases, by comparing to the minimax single-task regret $O(\sqrt{d_x
d_u^2}\sqrt{T})$, we see a benefit of a large number of agents. Notably, in the
difficult exploration case, by sharing a representation across tasks, the
effective task-specific parameter count can often be small $d_\theta < d_x
d_u$. Lastly, we provide numerical validation of the trends we predict.",2024-07-08,"Bruce D. Lee, Leonardo F. Toso, Thomas T. Zhang, James Anderson, Nikolai Matni",http://arxiv.org/pdf/2407.05781v2,cs.LG
LDGCN: An Edge-End Lightweight Dual GCN Based on Single-Channel EEG for Driver Drowsiness Monitoring,"Driver drowsiness electroencephalography (EEG) signal monitoring can timely
alert drivers of their drowsiness status, thereby reducing the probability of
traffic accidents. Graph convolutional networks (GCNs) have shown significant
advancements in processing the non-stationary, time-varying, and non-Euclidean
nature of EEG signals. However, the existing single-channel EEG adjacency graph
construction process lacks interpretability, which hinders the ability of GCNs
to effectively extract adjacency graph features, thus affecting the performance
of drowsiness monitoring. To address this issue, we propose an edge-end
lightweight dual graph convolutional network (LDGCN). Specifically, we are the
first to incorporate neurophysiological knowledge to design a Baseline
Drowsiness Status Adjacency Graph (BDSAG), which characterizes driver
drowsiness status. Additionally, to express more features within limited EEG
data, we introduce the Augmented Graph-level Module (AGM). This module captures
global and local information at the graph level, ensuring that BDSAG features
remain intact while enhancing effective feature expression capability.
Furthermore, to deploy our method on the fourth-generation Raspberry Pi, we
utilize Adaptive Pruning Optimization (APO) on both channels and neurons,
reducing inference latency by almost half. Experiments on benchmark datasets
demonstrate that LDGCN offers the best trade-off between monitoring performance
and hardware resource utilization compared to existing state-of-the-art
algorithms. All our source code can be found at
https://github.com/BryantDom/Driver-Drowsiness-Monitoring.",2024-07-08,"Jingwei Huang, Chuansheng Wang, Jiayan Huang, Haoyi Fan, Antoni Grau, Fuquan Zhang",http://arxiv.org/pdf/2407.05749v1,cs.LG
Analyzing Speech Unit Selection for Textless Speech-to-Speech Translation,"Recent advancements in textless speech-to-speech translation systems have
been driven by the adoption of self-supervised learning techniques. Although
most state-of-the-art systems adopt a similar architecture to transform source
language speech into sequences of discrete representations in the target
language, the criteria for selecting these target speech units remains an open
question. This work explores the selection process through a study of
downstream tasks such as automatic speech recognition, speech synthesis,
speaker recognition, and emotion recognition. Interestingly, our findings
reveal a discrepancy in the optimization of discrete speech units: units that
perform well in resynthesis performance do not necessarily correlate with those
that enhance translation efficacy. This discrepancy underscores the nuanced
complexity of target feature selection and its impact on the overall
performance of speech-to-speech translation systems.",2024-07-08,"Jarod Duret, Yannick Estève, Titouan Parcollet",http://arxiv.org/pdf/2407.18332v1,cs.LG
FairPFN: Transformers Can do Counterfactual Fairness,"Machine Learning systems are increasingly prevalent across healthcare, law
enforcement, and finance but often operate on historical data, which may carry
biases against certain demographic groups. Causal and counterfactual fairness
provides an intuitive way to define fairness that closely aligns with legal
standards. Despite its theoretical benefits, counterfactual fairness comes with
several practical limitations, largely related to the reliance on domain
knowledge and approximate causal discovery techniques in constructing a causal
model. In this study, we take a fresh perspective on counterfactually fair
prediction, building upon recent work in in context learning (ICL) and prior
fitted networks (PFNs) to learn a transformer called FairPFN. This model is
pretrained using synthetic fairness data to eliminate the causal effects of
protected attributes directly from observational data, removing the requirement
of access to the correct causal model in practice. In our experiments, we
thoroughly assess the effectiveness of FairPFN in eliminating the causal impact
of protected attributes on a series of synthetic case studies and real world
datasets. Our findings pave the way for a new and promising research area:
transformers for causal and counterfactual fairness.",2024-07-08,"Jake Robertson, Noah Hollmann, Noor Awad, Frank Hutter",http://arxiv.org/pdf/2407.05732v1,cs.LG
"The 2023/24 VIEWS Prediction Challenge: Predicting the Number of Fatalities in Armed Conflict, with Uncertainty","This draft article outlines a prediction challenge where the target is to
forecast the number of fatalities in armed conflicts, in the form of the UCDP
`best' estimates, aggregated to the VIEWS units of analysis. It presents the
format of the contributions, the evaluation metric, and the procedures, and a
brief summary of the contributions. The article serves a function analogous to
a pre-analysis plan: a statement of the forecasting models made publicly
available before the true future prediction window commences. More information
on the challenge, and all data referred to in this document, can be found at
https://viewsforecasting.org/research/prediction-challenge-2023.",2024-07-08,"Håvard Hegre, Paola Vesco, Michael Colaresi, Jonas Vestby, Alexa Timlick, Noorain Syed Kazmi, Friederike Becker, Marco Binetti, Tobias Bodentien, Tobias Bohne, Patrick T. Brandt, Thomas Chadefaux, Simon Drauz, Christoph Dworschak, Vito D'Orazio, Cornelius Fritz, Hannah Frank, Kristian Skrede Gleditsch, Sonja Häffner, Martin Hofer, Finn L. Klebe, Luca Macis, Alexandra Malaga, Marius Mehrl, Nils W. Metternich, Daniel Mittermaier, David Muchlinski, Hannes Mueller, Christian Oswald, Paola Pisano, David Randahl, Christopher Rauh, Lotta Rüter, Thomas Schincariol, Benjamin Seimon, Elena Siletti, Marco Tagliapietra, Chandler Thornhill, Johan Vegelius, Julian Walterskirchen",http://arxiv.org/pdf/2407.11045v1,cs.LG
Narrowing the Gap between Adversarial and Stochastic MDPs via Policy Optimization,"We consider the problem of learning in adversarial Markov decision processes
[MDPs] with an oblivious adversary in a full-information setting. The agent
interacts with an environment during $T$ episodes, each of which consists of
$H$ stages, and each episode is evaluated with respect to a reward function
that will be revealed only at the end of the episode. We propose an algorithm,
called APO-MVP, that achieves a regret bound of order
$\tilde{\mathcal{O}}(\mathrm{poly}(H)\sqrt{SAT})$, where $S$ and $A$ are sizes
of the state and action spaces, respectively. This result improves upon the
best-known regret bound by a factor of $\sqrt{S}$, bridging the gap between
adversarial and stochastic MDPs, and matching the minimax lower bound
$\Omega(\sqrt{H^3SAT})$ as far as the dependencies in $S,A,T$ are concerned.
The proposed algorithm and analysis completely avoid the typical tool given by
occupancy measures; instead, it performs policy optimization based only on
dynamic programming and on a black-box online linear optimization strategy run
over estimated advantage functions, making it easy to implement. The analysis
leverages two recent techniques: policy optimization based on online linear
optimization strategies (Jonckheere et al., 2023) and a refined martingale
analysis of the impact on values of estimating transitions kernels (Zhang et
al., 2023).",2024-07-08,"Daniil Tiapkin, Evgenii Chzhen, Gilles Stoltz",http://arxiv.org/pdf/2407.05704v2,cs.LG
On the Limitations of Compute Thresholds as a Governance Strategy,"At face value, this essay is about understanding a fairly esoteric governance
tool called compute thresholds. However, in order to grapple with whether these
thresholds will achieve anything, we must first understand how they came to be.
To do so, we need to engage with a decades-old debate at the heart of computer
science progress, namely, is bigger always better? Does a certain inflection
point of compute result in changes to the risk profile of a model? Hence, this
essay may be of interest not only to policymakers and the wider public but also
to computer scientists interested in understanding the role of compute in
unlocking breakthroughs. This discussion is timely given the wide adoption of
compute thresholds in both the White House Executive Orders on AI Safety (EO)
and the EU AI Act to identify more risky systems. A key conclusion of this
essay is that compute thresholds, as currently implemented, are shortsighted
and likely to fail to mitigate risk. The relationship between compute and risk
is highly uncertain and rapidly changing. Relying upon compute thresholds
overestimates our ability to predict what abilities emerge at different scales.
This essay ends with recommendations for a better way forward.",2024-07-08,Sara Hooker,http://arxiv.org/pdf/2407.05694v2,cs.LG
Sub-SA: Strengthen In-context Learning via Submodular Selective Annotation,"In-context learning (ICL) leverages in-context examples as prompts for the
predictions of Large Language Models (LLMs). These prompts play a crucial role
in achieving strong performance. However, the selection of suitable prompts
from a large pool of labeled examples often entails significant annotation
costs. To address this challenge, we propose Sub-SA (Submodular Selective
Annotation), a submodule-based selective annotation method. The aim of Sub-SA
is to reduce annotation costs while improving the quality of in-context
examples and minimizing the time consumption of the selection process. In
Sub-SA, we design a submodular function that facilitates effective subset
selection for annotation and demonstrates the characteristics of monotonically
and submodularity from the theoretical perspective. Specifically, we propose
RPR (Reward and Penalty Regularization) to better balance the diversity and
representativeness of the unlabeled dataset attributed to a reward term and a
penalty term, respectively. Consequently, the selection for annotations can be
effectively addressed with a simple yet effective greedy search algorithm based
on the submodular function. Finally, we apply the similarity prompt retrieval
to get the examples for ICL.",2024-07-08,"Jian Qian, Miao Sun, Sifan Zhou, Ziyu Zhao, Ruizhi Hun, Patrick Chiang",http://arxiv.org/pdf/2407.05693v2,cs.LG
Multi-Fidelity Bayesian Neural Network for Uncertainty Quantification in Transonic Aerodynamic Loads,"Multi-fidelity models are becoming more prevalent in engineering,
particularly in aerospace, as they combine both the computational efficiency of
low-fidelity models with the high accuracy of higher-fidelity simulations.
Various state-of-the-art techniques exist for fusing data from different
fidelity sources, including Co-Kriging and transfer learning in neural
networks. This paper aims to implement a multi-fidelity Bayesian neural network
model that applies transfer learning to fuse data generated by models at
different fidelities. Bayesian neural networks use probability distributions
over network weights, enabling them to provide predictions along with estimates
of their confidence. This approach harnesses the predictive and data fusion
capabilities of neural networks while also quantifying uncertainty. The results
demonstrate that the multi-fidelity Bayesian model outperforms the
state-of-the-art Co-Kriging in terms of overall accuracy and robustness on
unseen data.",2024-07-08,"Andrea Vaiuso, Gabriele Immordino, Marcello Righi, Andrea Da Ronch",http://arxiv.org/pdf/2407.05684v1,cs.LG
